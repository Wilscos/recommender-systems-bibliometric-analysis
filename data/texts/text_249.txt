Abstract—The paper presents open-source computational workﬂows for assessing the “Exposure to sunlight” and “View out” criteria as deﬁned in the European standard EN 17037 “Daylight in Buildings”, issued by the European Committee for Standardization. In addition to these factors, the standard document also addresses daylight provision and protection from glare, both of which fall out of the scope of this paper. The purpose of the standard is stated as ‘encouraging building designers to assess and ensure successfully daylit spaces’. The standard document proposes veriﬁcation methods for performing such assessments, albeit without recommending a simulation procedure for computing the aforementioned criteria. The workﬂows proposed in this paper are arguably the ﬁrst attempt to standardize these assessment methods using de-facto open-source standard technologies currently used in practice. The approach of this work is twofold: establish that the compliance check can be systematically performed on a 3D model by a novel simulation tool developed by the authors; and highlighting the additional assumptions that need to be implemented to build a robust and unambiguous tool within existing open-source frameworks. Formulating procedures for computational assessment of EN 17037 criteria for sunlight exposure and view out Standardizing inputs and outputs for the proposed computational assessment procedures Devising Python workﬂows utilizing the Radiance simulation engine and Honeybee from Ladybug Tools for running sunlight exposure and view analyses The tool presented in this paper offers an open-source solution to check compliance with EN 17037 criteria for “View out” and “Exposure to sunlight”. The tool will be made available to designers, consultants and researchers. Furthermore, the paper presents suggestions to policy-makers on how the compliance procedures could be made more robust and better integrated into computational design workﬂows. In 2018 a new European standard on “Daylight in Buildings”, EN 17037 [1] was introduced and ratiﬁed in all European Union countries, largely superseding existing national daylighting standards. The document includes recommendations for: 1) Indoor daylight provision; (2) View out; (3) Exposure to sunlight; and (4) Protection from glare. Previous works focused mainly on the implementation of the “Indoor daylight provision” and “Protection from glare” criteria [2]–[5]. Instead, the proposed paper focuses on the “View out” and “Exposure to sunlight” sections; namely, it introduces a computational approach to facilitate compliance assessment at early design stages. The analyses required by these two sections of the standard are exclusively dependent on the geometrical characteristics of the building under assessment and its surroundings. The veriﬁcation procedures suggested in the standard are largely based on geometrical measurements on 2D plan and section views. Separate options are given for the veriﬁcation via photographs – only for existing buildings – or via rendered images. For the assessment of view quality, the theoretical basis and a description of the advanced veriﬁcation method can be found in [6] [7], respectively. As for sunlight exposure, the veriﬁcation procedure is delineated by [8] and is based on evidence of the beneﬁts of direct sunlight in buildings found by [9]. We argue that being able to assess all four criteria with a single computational tool would facilitate the uptake and application of the new standard from early design decisionmaking. Additionally, being able to assess the “View out” and “Exposure to sunlight” with procedures based on direct ray-tracing is deemed to be more efﬁcient than generating rendered images, and better suited for computational design processes. The approach of this work is twofold: establish that the compliance check can be systematically performed on a 3D model by a novel simulation tool developed by the authors; and highlighting the additional assumptions that need to be implemented to build a robust and unambiguous tool within existing open-source frameworks. Given that the veriﬁcation procedures proposed in the standard document are developed primarily for manual geometrical assessment, several challenges and problems surfaced in developing the equivalent simulation procedures. The present paper describes how we reinterpreted this standard for a computational assessment based on ray-tracing. The main problems addressed in this paper are the standardization of deﬁnitions, data models and procedures for performing the proposed assessments. Ideally, this should be carried out in such an unambiguous way that an algorithm can perform the assessment and put out a conclusion without the need for a human interpreter during intermediate steps. In this section we present in detail the procedures devised to determine target levels recommended by sections 5.2 and 5.3 of EN 17037:2018, respectively addressing the assessments of “View out” and “Exposure to sunlight”. The chosen performance indicators and recommended target values are listed in Table I and explained below. TABLE I: Performance level indicators and recommended target The combination of the ﬁrst three indicators should in principle provide a comprehensive assessment of the quality of the view out. The overall performance level (classiﬁed as minimum, medium or high) is equivalent to that of the indicator that scores the lowest among the three. The horizontal sight angle describes the width of a window as seen by an observer’s point of view. The distance to obstructions is the distance between the interior surface of a window and the “major” outdoor obstructions to a view of the sky. The number of layers gives an indication of how varied the outside view is by considering the presence of at least one of the three types of elements: a view of the ground, a view of the landscape (natural, architectural or of the horizon), and a view of the sky. The fourth indicator from Table I refers to the exposure to sunlight recommendations and indicates the number of hours during which a point on the inner the surface of a window receives direct sunlight. Besides the imprecision inherent in the deﬁnition of some key factors in determining the quantity of these performance indicators, a number of variables are left for the user/designer to decide. Among these, two were identiﬁed as critical for understanding the variability of results: the view-point location for the view out analysis, and the date for the sunlight exposure analysis. The variability of performance indicators due to these two variables was investigated using the newly developed tools and is presented in the Result section. The following sections describe the computational approach and the test scene used for the analysis. To maximize accessibility and ease of use, we adopted existing technical frameworks and built on top of them. The developed toolset is primarily available as a Python package. The simulation core utilizes the Radiance ray-tracer [10] through the utility functions and methods of the Ladybug Tools software [11], [12]. 1) View Out: The “Context View” recipe assesses the view of a vantage point inside the room towards outside through a window, by computing the horizontal view angle, the distance to outdoor obstructions, and the view layers that are visible from that point. The standard does not constraint choosing the horizontal positioning of the vantage point (as long as it is in the so-called utilized area), but it limits the point height to 1.2 m for a sitting eye level and 1.7 m for a standing eye level. As in the case of sunlight exposure, the standard proposes two methods: one based on ﬁsh-eye photographs and one geometrical method. In the ﬁsh-eye method, it is suggested to superimpose a diagram on the photograph, in order to measure the horizontal angle and counting the different types of layer (sky, ground, landscape) present in the photograph. In the geometrical method, a straight line should be drawn from the vantage point towards the upper sill and lower sill in the section view and extended towards the outside scene until it hits an obstacle. This line represents the bounds of what is visible from the vantage point. Based on this drawing, the number of visible layers can be counted. The horizontal sight angle can be determined via a set of graphs relating the width of the window to the depth of the room. To translate this procedure into a simulation workﬂow, we discretize the horizontal plane of the room at a height of 1.2 m and 1.7 m into a grid of vantage points. Then, from each vantage point, rays are shot towards a homogenous discretization (subdivided icosahedron) of a sphere, mapping the distance and type of objects in all directions. Distance to obstructions: For all shot rays, we retrieve the distance to the ﬁrst and last intersection points. The difference between these two values enables us to identify the rays that have passed the window. Given that the standard speciﬁes that the distance to outside obstructions should be measured perpendicular to the window surface, the distance can be computed as: wherenis the window surface normal,ris the ray direction,δ is the distance of the vantage point to the ﬁrst intersection, and δis the distance of the vantage point to the last intersection. As further elaborated in the discussion, the standard document does not specify the nature of the scene as a geo-spatial data model. We have pragmatically considered the maximum extent of our scene model (circa 500 metres) as the farthest intersection distance for the test case discussed here. However, it must be noted that without specifying the extents of the scene there might be a range of unforeseen issues arising out of such an ambiguity in the standard document, especially for a computational assessment. Namely, an arbitrary choice of such a distance will inevitably affect the reproducibility of the results and thus the reliability of the standard. Furthermore, in regions where the shape of the terrain is non-trivially blocking the sunlight hours (e.g. because of a mountain range behind a building, even if far away) then the results obtained as such cannot be reliable. At such a scale, i.e. major terrain obstacles, even the curvature of the earth will play a role. Past a certain distance, e.g. circa 8 km away from a 4000 meters high mountain peak, it will not be visible on the horizon due to the curvature of the earth. However, in closer ranges high mountainous ranges can potentially block the sunlight hours. Horizontal sight angle: To compute the horizontal sight angle, we assess the ratio of the horizontal rays that have passed the window (ρ) to all the horizontal rays (%), i.e. the portion of a horizontal circle covered by the window from a speciﬁc vantage point. Given that rays are shot toward a homogenous discretization of the sphere, the horizontal sight angle can be computed as the following: View layers: On each grid point, we count the number of ﬁnal ray intersections for each object type. Consequently, we can compute how many view layers were in the sight of each vantage point and what portion of the view sphere is occupied by them. If these portions are beyond a certain threshold, we can establish that the object is visible and perceivable by building occupants. The need for such a threshold and its speciﬁcation will be further examined in the discussion section. 2) Exposure to Sunlight: The “Exposure to Sunlight” recipe is a measure of the minimum number of hours that sun is visible from a vantage pointPdeﬁned in the horizontal centre of the window with the minimum height of 1.2 m above the ﬂoor or 0.3 m above the sill. The standard speciﬁes that the selected date for measurement should be between February 1st and March 21st. To compute this measure, two methods are proposed in the document: one based on a ﬁsh-eye photograph taken from the vantage point, and one based on geometrical calculations. In the ﬁsheye method, a sun path diagram is superimposed on the photograph, so that the number of hours that directly see the sun can be counted. In the geometrical method,αis deﬁned as the horizontal acceptance angle of the window spanning from the right side to the left side of the window fromP, excluding major external obstacles. Next, the sun path for different geographical locations can be identiﬁed via a lookup table. Finally, with the help of the angle between window normal and North direction, the overlap betweenα and the sun path span is determined. It is clear that such assessment of the overlap of the sun path with the opening of the window is extremely sensitive to the precision of drawings and measurements. Moreover, the more complex the outdoor scene becomes, the less feasible is to compute the effect of obstructions with this procedure. Consequently, to translate this procedure into a simulation workﬂow (illustrated in Figure 2), we computed the position of the sun throughout the year in half an hour intervals based on the geolocation of the building. Then, by considering the geometry of the context as obstacles we checked for a clear sight-line from the vantage point of the window (P) in the direction of the sun. Aggregating this information for each day indicates the number of sunlight exposure hours. Two different 3D models were combined to recreate a ﬁctitious – yet realistic – test scene for the evaluation. For the urban environment, an existing model of Rotterdam city centre was used [13]. Such a model includes the Blaaktoren tower, where the Massachusetts Institute of Technology (MIT) reference ofﬁce model was inserted, namely on the third ﬂoor. The ofﬁce model represents a deep-plan, side-lit room used for benchmarking daylighting and glare analyses [14]. Figure 3 shows the test scene and indicates the position of the ofﬁce Fig. 2: Exposure to Sunlight simulation diagram. room, as well as the sun path diagram for the coordinates of Rotterdam city centre. The ofﬁce window is oriented towards the South-East and overlooks the view represented in Figure 4. The ‘view layers’ visible in this example are colour-coded in a similar way to [15]. The ﬁrst set of results concerns the assessment of view quality. The performance criteria related to “View Out” (number of view layers and horizontal sight angle) were computed and visualized, for two grids of points: one at the height of 1.2 m above the ﬂoor and the other at 1.7 m. The ﬁrst grid represents the view of a sitting person, whereas the second grid represents the view of a standing person. The third criterion to assess view quality – distance to obstructions – was calculated for multiple points on the window surface, as the standard does not deﬁne a speciﬁc point for this assessment. The minimum distance was found to be 16 m and the maximum was 351 m. If the minimum distance was to be considered, then the view performance of this room would result in a ‘Minimum’ score. Oppositely, if the point chosen for the assessment would result in a distance of 351 m, then the view would score a ‘High’ performance level. The placement of the room in the urban model and the resulting variability in obstruction distances were purely Fig. 3: Bird view of the scene indicating the relative positioning of the test-case, in red; urban surrounding in light grey; hourly sun positions, as dark orange spheres; and bi-weekly sun paths as light Fig. 4: Outdoor view as seen from a point within the room, at a height of 1.2 m above the ﬂoor. From this speciﬁc viewpoint, it is possible to see all the three ‘view layers’: (1) Sky, in blue; (2) Landscape, in green (2); and (3) Ground, in red. coincidental. However, it is reasonable to expect that most rooms with a high number of view layers will be characterised by a large variety of distances to major obstructions. Hence, such an assessment would beneﬁt from the deﬁnition of a single statistical indicator that can give a meaningful indication of the overall performance, for example, the median value of all computed distances. Figure 5 shows the analysis on the number of view layers for a grid at 1.7 m. From the ﬁrst plot on the left, it looks as if from almost the entire room is possible to see all three view layers. For such a deep plan room, it is surprising that the ground can be seen even when standing at the furthest point from the window. What happens is that the count of view layer is equally sensitive to very large or very small portions of each view element. That is, even if only one ray hits, e.g., the ground, then such layer is included in the overall count. An additional investigation was therefore conducted on the effect of adding a minimum threshold value for a layer to be counted as effectively part of the view. The other plots in Figure 5 illustrate how the evaluation changes depending on the set minimum threshold. It is also possible to notice that the back portion of the room does not see any view layer. Although a view out of the window is always present, from those points none of the layers covers a solid angle exceeding the deﬁned threshold. Thus, the introduction of such a threshold could be used to indicate when the view out is too distant from the selected vantage point, effectively removing the need to assess the horizontal sight angle. Fig. 5:Number of view layers visible across a grid of analysis points 1.7 m high. (t) is the visibility threshold for counting a layer as visible and is measured in steradians. The window is on the top side. Figure 6 shows the variation in horizontal sight angle values when calculated from different points in the room. As expected, the angle decreases as the distance from the window increases. The maximum angle found for the reference room is 158 and the minimum is 11. If the point within the room with the minimum horizontal sight angle was to be considered for the evaluation, the room would not comply with any of the recommended performance levels. Given that this reference ofﬁce room is characterized by a deep plan, this outcome was expected too. The second set of results shows the “Exposure to sunlight” performance of the test scene. The direct view of the sun was evaluated for the whole period suggested by the standard, from the 1of February to the 21of March. The standard requires to choose only one day within this period for the evaluation of the cumulative number of hours of direct sunlight. In the analysed case, no major differences were found among different days, and the number of hours exceeded the threshold for the ‘High’ performance level independently of the chosen day. For this analysis, a decision on the timestep to adopt when“Exposure to Sunlight” criterion, considerations concerning deﬁning sun positions had to be taken. In Figure 7, results obtained using a one-hour timestep are compared to those Fig. 6: Values of horizontal sight angles across a grid of analysis points 1.7 m high. The window is on the left side. obtained using a ﬁve-minute timestep. In this case, a timestep of one hour led to a slight underestimation of exposure hours (-3%). More analyses are required to assess the sensitivity of this performance criterion to the chosen timestep. In any case, specifying an exact value in the standard document would help reducing this uncertainty and making it more robust. Fig. 7: Solar access at the evaluation point, within the period 01/02-21/03, for clear sky conditions. The plots show both the time at which direct sunlight access occurs (left y axis) and the cumulative number of ‘direct sunlight hours’ per day (right y axis). Plot (a) shows results when using a 1 hour time step; plot (b) shows Besides considerations on detailed parameters within the the integration of this analysis with the other criteria in the standard document are important. Such a high incidence of direct sunlight should raise concerns about potential glare risk. To effectively inform designers of the need for shading devices and their optimal characteristics, the two criteria “Exposure to sunlight” and “Protection from glare” should be assessed in parallel. However, for such comparison to be possible, the two criteria should have more similar temporal and spatial requirements, as highlighted in the following section. The main scope of this work was to develop and present a tool that enables designers to check compliance with EN 17037 criteria. During its development, however, several inconsistent or missing variables were identiﬁed in the standard document. While it is true that the tool has been tested on a very limited number of geometries, the authors have sought to develop procedures that can be scaled and generalised to a wide range of scenarios. We discuss here the issues that we consider more relevant to ensure robust and consistent assessments of EN 17037 “View out” and “Exposure to sunlight” criteria, as well as general issues concerning all criteria in the standard. Leaving unclear and ambiguous deﬁnitions may lead to various interpretations and implementations by a single developer, hence to several different results and performance assessments. We argue that the implementation of additional parameters or thresholds should be the subject of discussion among the simulation and lighting community, ultimately resulting in modiﬁcations to the standard document itself. The suggested methods for ensuring the recommended levels of quality in the standard document are accompanied by a variety of 2D drawings and normative geometric methods that are supposed to help building designers attain the aforementioned qualities. While these drawings can be helpful in a didactic sense, they are not directly interpretable as unambiguous“View out” and “Exposure to sunlight” parts of the EN procedures for computing the values in question. The ambiguity17037 standard. The challenge lies with the selection of the arises speciﬁcally when translating the manual methods given in the standard into technical ‘recipes’ that could be used for assessing 3D scenes. The absence of rigorous mathematical speciﬁcation of the criteria increases the ambiguity of the computation procedures. As an example, when counting the visible layers in the view out criteria, a human’s perception will discard miniscule visible patches of layers; but in the simulation environment, the rays will be likely to intersect with such objects. Then there has to be a deﬁned threshold of solid angles in steradians, to identify the visibility of that layer unambiguously. As illustrated in Figure 6, the problem of determining the number of visibility layers may lead to unexpected results if such computational details are not considered in the standard deﬁnitions. Lastly, it would be extremely valuable to consider the use of EN 17037 performance assessments within the wider ﬁeld of urban and architectural design. This becomes particularly important for the “View out” assessment, which requires a fairly detailed description of the environment surrounding the building under analysis. The typical data models used by building simulation practitioners either lack semantic information (in the case of geometric models such as Wavefront OBJ or AutoCAD DXF made by Computer Graphics or Computer-Aided Design software) or their semantic layers do not correspond to the ones offered by the standard (in case of geometric-semantic data models such as gbXML and CityGML made by Building Information Modelling software or obtained from 3D City Information Models). In both cases, there is a need for a standardized semantic mapping between established data models and the semantic layers proposed by the standard (‘ground’, ‘landscapes’, and ‘sky’). The two sections that were not investigated in this paper, concerned with “Daylight sufﬁciency” and “Protection from glare”, proposed their own spatial and temporal aggregators. In the daylight sufﬁciency part, the annual evaluation option produces at least 8760 hourly values (of which about half are daylight hours) for each of the points in the analysis grid. Temporally, 50% of the daylight hours should comply with the requirements. Spatially, two target performance values are deﬁned: 50% of the analysis grid should meet a target illuminance (e.g., 300 lx) and 95% of the analysis grid should meet a minimum illuminance (e.g., 100 lx). In the protection from glare part, the annual evaluation option considers only occupied hours in a year (8:00 to 18:00, Monday to Friday), for a total of about 2600 values at each evaluated position. Of these hours, a maximum of 5% should report a Daylight Glare Probability lower than a target value (e.g., 0.35). The evaluation position in the space should be decided by the designer and should correspond to the expected worse condition, i.e., close to the facade, with the sun shining in the occupant’s ﬁeld of view. Similar aggregators could be easily devised also for the most appropriate aggregator, as for it to be a meaningful representation of occupants’ experience, more studies on human perception of view and sunlight would be required. Furthermore, more research is necessary for a more complete understanding of how the four criteria recommended by the standard interact with each other, and whether a design can achieve compliance with multiple criteria at once. This paper presented a computational toolset developed by the authors to assess the “Exposure to sunlight” and the “View out” criteria as deﬁned by the EN 17037 standard “Daylight in Buildings”. Besides illustrating the assumptions that had to be taken when interpreting the standard requirements, the present work aimed at suggesting more robust and unambiguous approaches for verifying compliance to the standard criteria. The analyses were carried out only for a single test scene, which is not necessarily representative of a typical ofﬁce or an urban context. Yet, even the application of the standard requirements on a relatively simple room highlighted a number of issues that can affect the generalisation – and hence the adoption – of the standard. Among such issues, the major ones were: the absence of a deﬁned point to assess the distance to obstructions; a deﬁnition of “major obstructions”; a minimum solid angle threshold to account for view layers; and, a clearer procedure to choose the analysis day and timestep for the “Exposure to sunlight” assessment. Furthermore, the paper discussed in more detail considerations about creating robust deﬁnitions, models and veriﬁcation procedures for computational implementations; choosing result aggregators that more closely represent the human’s perception of view and direct sunlight; and the need for integration among the four criteria covered by EN 17037. The latter aspect, i.e., the transition from simulation results to assessment labels invites further research in the direction of congruence with green building certiﬁcations such as BREEAM, LEED, and WELL. Furthermore, considering the demonstrated possibility of automated computational evaluation, a reconsideration of the evaluation paradigm from discrete labels to continuous scores would make the standard suitable for direct application in computational design workﬂows, especially for integration in objective functions for design optimization. [1] The authors would like to acknowledge Mostapha Roudsari’s help with understanding the Ladybug[+] and Honeybee[+] ‘recipes’ structure. The source code of the toolbox is available at the following repository: https://github.com/shervinazadi/EN 17037 Compliance. Links to supplementary materials such as documentation, examples and online reproduction of the presented procedure are also available in the repository.