Key words: missing data, causal inference, targeted maximum likelihood estimation, multiple imputation   Abstract    Causal inference from longitudinal studies is central to epidemiologic research. Targeted Maximum  Likelihood Estimation (TMLE) is an established double-robust causal effect estimation method, but how  missing data should be handled when using TMLE with data-adaptive approaches is unclear. Based on  motivating data from the Victorian Adolescent Health Cohort Study, we conducted simulation and case  studies to evaluate the performance of methods for handling missing data when using TMLE. These were  complete-case analysis; an extended TMLE method incorporating a model for outcome missingness  mechanism; missing indicator method for missing covariate data; and six multiple imputation (MI)  approaches using parametric or machine-learning approaches to handle missing outcome, exposure, and  covariate data. The simulation study considered a simple scenario (the exposure and outcome generated  from main-effects regressions), and two complex scenarios (models also included interactions), alongside  eleven missingness mechanisms defined using causal diagrams. No approach performed well across all  scenarios and missingness mechanisms. For non-MI methods, bias depended on missingness mechanism  (little when outcome did not influence missingness in any variable). For parametric MI, bias depended on  missingness mechanism (smaller when outcome did not directly influence outcome missingness) and data  generation scenario (larger for the complex scenarios). Including interaction terms in the imputation model  improved performance. For MI using machine learning, bias depended on missingness mechanism (smaller  when no variable with missing data directly influenced outcome missingness). We recommend considering  missing data mechanism and, if using MI, opting for a saturated parametric or data-adaptive imputation  model for handling missing data in TMLE estimation.    1 Introduction   A crucial component of epidemiologic research is causal inference from longitudinal cohort studies, where  interest is commonly in estimating the average causal effect (ACE) of an exposure on an outcome. Targeted Maximum Likelihood Estimation (TMLE) is an established doubly robust causal effect estimation  method, combining  a model for the outcome and a model for the exposure, and offers several appealing  properties.  Only one of the two models (outcome or exposure model) needs to be consistently estimated to  obtain an unbiased estimate of the causal effect, and when both are consistently estimated, TMLE is an  asymptotically efficient estimator under the Donsker class condition (which requires that outcome and  propensity score estimators not to heavily overfit the data).  Under this condition, valid statistical inference  can be obtained with TMLE even when data-adaptive methods are used for the exposure and outcome  models.  Data-adaptive methods refer to a broad range of techniques to fit prediction models that can  flexibly learn from the data and are attractive because they allow relaxation of parametric modelling  assumptions, thereby reducing misspecification bias.  In causal inference, application of most data-adaptive  methods needs to be limited to doubly robust estimators because when used with singly robust methods,  such as g-computation or inverse probability weighting, they yield biased estimates and invalid confidence  intervals (CIs). Recently, interest in the application of TMLE for ACE estimation has grown, as reflected by the increasing  number of papers using the approach (Figure 1).   Nonetheless, guidance on how missing data should be  handled when using TMLE with data-adaptive approaches is currently lacking. This is problematic given  that missing data are ubiquitous and can lead to biased estimates and loss of precision if handled  inappropriately. A review of the literature suggests that in studies using TMLE for ACE estimation, multiple imputation (MI)  is one of the most commonly used approaches to handle missing data.  MI is a two-step  process. First, multiple completed datasets are generated where missing data are replaced with values drawn  from their posterior predictive distribution conditional on the observed data. Then each imputed dataset is  analysed and results are pooled to obtain the final MI estimate and standard error (SE).  A requirement of  MI is that the imputation model must be compatible with the analysis model, which implies that the  imputation model must not be less general than the analysis model and should incorporate all relationships  assumed to hold in the latter.  However, how this can be achieved when data-adaptive methods are used for  the exposure and/or outcome models in TMLE is unclear and poses a challenge for using MI in conjunction  with this approach.   Complete-case analysis, where records with missing data for any of the variables in the exposure or outcome  models are excluded, is another commonly used approach for handling missing data with  TMLE.  Although this approach does not necessarily inflict bias, it generally leads to loss  of precision.  Extending TMLE to handle missing outcome data  and a missing covariate missing  indicator (MCMI) approach for handling missing confounder data  are other approaches that have been  used to handle missing data in a number of studies using TMLE. For the extended TMLE approach, the  TMLE implementation includes, in addition to models for the exposure and outcome, a model for the  probability of having non-missing outcome conditional on the exposure and confounders.  This approach is  expected to perform well when the exposure and confounders are complete. However, incompleteness in  exposure and confounders is common in cohort studies, in which case researchers using this approach need  to delete records with incomplete data for these variables, leading to loss of precision or potential bias.  Alternatively, they might use the MCMI approach to handle incomplete confounders, which relies on  extending the confounder vector to include missingness indicators for these.  This approach is only  guaranteed to be unbiased under certain stringent assumptions about the missingness mechanism.  Like  extended TMLE, MCMI does not deal with incomplete exposure data. Overall, the optimal implementation  of MI and its performance compared with these other available approaches are unknown.  In this paper, we seek to evaluate and compare the performance of a range of approaches for dealing with  missing data when using TMLE with data-adaptive methods to estimate the ACE, including several potential  implementations of MI. The article is organized as follows. First, we introduce the motivating example,  which investigated the causal effect of frequent cannabis use in adolescent females on their mental health in  young adulthood using data from the Victorian Adolescent Health Cohort Study (VAHCS). Then, we briefly  review the ACE definition, identifiability conditions and the TMLE estimation approach in the absence of  missing data. Then we describe methods for handling missing data with TMLE and the simulation study we  conducted based on the VAHCS example to evaluate and compare the performance of these approaches.  Finally, we illustrate the assessed approaches in the VACHS case study and conclude with a general  discussion.    2 Motivating example   For our case study, the question of interest was “what is the causal effect of frequent cannabis use in  adolescent females on their mental health in young adulthood?”. It was based on a previous investigation  using VAHCS data, which estimated an approximately two times higher odds of depression and anxiety in  young adulthood for females who reported frequent cannabis use during adolescence compared with those  who did not (odds ratio (OR) 1.9; 95% confidence interval (CI) 1.1, 3.3). VAHCS is a longitudinal study of 1,943 participants (1,000 females), who were recruited when they were  aged 14-15 years between 1992 and 1993 from 45 randomly selected schools across the state of Victoria,  Australia.  Data were collected from participants every six months during their adolescence (waves one to  six), using self-administered questionnaires or telephone interviews. Wave seven, conducted in 1998, was  the young adulthood survey, at which data collection was conducted using computer-assisted telephone  interviews. At each wave of the adolescent phase, the frequency of cannabis use in the previous six months was selfreported. Participants were classified as frequent users if they reported at least weekly use at any wave  across waves two to six. The computerized revised clinical interview schedule (CIS-R) administered at all  the waves was used to assess mental health. Here, instead of dichotomizing the outcome variable as in the  previous investigation, we used the log-transformed and standardized CIS-R total score at wave seven as the  outcome. Following the previously published paper, we considered five confounders.  These were parental  divorce, antisocial behaviour, depression and anxiety, alcohol use, and parental education, all measured  across waves two to six, treated as binary variables, and assumed to be proxies for pre-exposure  conditions.  Table 1 shows descriptive statistics and proportions with missing data among the VAHCS  female participants for these variables as well as  age at wave two, which we made use of as an auxiliary  variable (a variable that is a predictor of missing values but is not included in the analysis model ) in this  study.  The aim of our target analysis was to estimate the ACE, as defined in the next section, of frequent  cannabis use during adolescence on CIS-R score in young adulthood among VAHCS female  participants.   3 Overview of ACE estimation with TMLE   For a binary exposure, the ACE is defined as the difference between the average potential outcome if  everybody in the population was set to be exposed and the average potential outcome if everybody were set  to be unexposed, i.e.,      where   and  are respectively the potential outcomes  under exposure (  ) and no exposure (  ).  In the absence of missing data, and under the  assumptions of exchangeability, consistency, and positivity, it is possible to identify the ACE from   observable data by the g-formula:             where  is a vector of confounders  and the outer expectation averages over its distribution in the population. Exchangeability (no unmeasured  confounding) is formally defined as , for all values of . Consistency is the equality between  individual’s counterfactual outcome under their exposure history and their observed outcome, i.e.,     when   . Positivity requires a non-zero probability of receiving the exposure across all combinations of  confounder strata, i.e.,          for   for all values of z that occur in the population.   Several estimators are available for estimating the ACE in the absence of missing data. Here, we focus on  TMLE which is a doubly robust estimator, combining a model for the outcome and a model for the  exposure.  Simply put, the implementation of TMLE in a point-exposure study involves (i) estimating a  model for the expected outcome conditional on exposure and confounders (   ) and using it to predict  the outcome for all records under exposure and no exposure; (ii) estimating a model for the probability of  receiving the exposure conditional on confounders (i.e., the propensity score; (    )); (iii)  incorporating information from the propensity score to improve the initial outcome predictions so that they  solve the parameter’s efficient influence curve  ; and (iv) plugging in the updated predictions (denoted  by   ) in the g-formula to estimate the ACE.  Influence curve is a function that describes estimator  behaviour when the empirical distribution of the data is slightly perturbed. For a target parameter, an  efficient influence curve is the influence curve with the smallest variance.  The standard approach for  standard error (SE) estimation with TMLE is to take the standard deviation (SD) of the influence curve,  which is attractive due to its easiness.  The so-called targeting step of the TMLE procedure, step (iii),  ensures that the estimator is doubly robust and thereby exhibits the desirable statistical properties previously  described. We refer the reader to the existing literature  for a detailed explanation of TMLE and its  theoretical underpinnings.  4 Methods for handling missing data   In the following section, we describe the methods we identified for handling missing data when estimating  the ACE using TMLE. These are broadly categorised under non-MI and MI methods.   4.1.1 Complete-case analysis   The simplest approach for handling missing data is a complete-case analysis. For this approach, participants  with missing data for any of the variables in the target analysis are excluded and the analysis is performed  using records with complete data only. In general, this approach can lead to bias, depending on the  missingness mechanism, and loss of precision. 4.1.2 Extended TMLE in the sample with complete exposure and confounders (Ext TMLE):  The second approach is the extended TMLE method  to handle missingness in the outcome, with records  with missing exposure or confounder data being excluded. In this approach, the initial model for   is  estimated among records with complete , ,  data, and the predictions of the outcome are updated in the  targeting step using information from both the model fitted for P[X=1|Z] as well as a model fitted for  P[ =0|X,Z] (probability of having observed outcome conditional on the exposure and confounders, where   is the missingness indicator for the outcome and coded 1 if the variable is missing and 0 if observed).  Updated predictions for the outcome under exposure and no exposure are obtained for all records, regardless  of their missing outcome status, and are then plugged into the g-formula to estimate the ACE.  As with the  exposure and outcome models, the model for   can be fitted using data-adaptive approaches. In the  absence of incomplete exposure and confounders, the extended TMLE method has been shown to be  unbiased under an extended exchangeability assumption (namely,    and   for   ). This method is available in the R TMLE implementation. 4.1.3 Extended TMLE plus missing covariate missing indicator (MCMI) approach (Ext TMLE+MCMI):   For the third approach, missing outcome data are handled as above, using the extended TMLE approach, and  missing confounder data are handled using the missing covariate missing indicator (MCMI) approach, by  including missingness indicators for the incomplete confounders in the confounding adjustment set. Records  with missing exposure data are excluded. Blake et al. have previously shown that the MCMI approach can  be expected to yield an unbiased estimate of the ACE under an extended exchangeability assumption  (   for   where  is the vector of missingness indicators for the incomplete confounders),  and the assumption that the exposure or outcome only depend on the confounder when the confounder is  observed.  It is possible to imagine scenarios where this assumption might be plausible, such as in  electronic health record data, where, for example, the decision to prescribe a medication is influenced by  family history of disease only when the clinician has the relevant information.    4.2. MI approaches to handle missing data   We identified various approaches to MI within the fully conditional specification (FCS) framework  to  simultaneously handle missing exposure, confounder, and outcome data. In FCS, univariate models are  specified for each incomplete variable conditional on other variables in the imputation model, and  imputations are drawn sequentially until convergence, usually achieved after five cycles. The whole process  is repeated multiple times to generate multiple completed datasets. Then, TMLE is performed within each  complete dataset and the results are pooled to obtain the final MI estimate of the ACE and its SE using  Rubin’s rules.  In MI approaches, it is recommended that all variables in the target analysis (i.e., exposure,  outcome, confounders) as well as auxiliary variables (e.g. age in the VAHCS example) be included in the  imputation model, i.e., as predictors in each univariate model.  4.2.1 Parametric MI with no interaction – linear regression to impute missing outcome (MI, no int (linear))  In this approach, the binary exposure and confounders are multiply imputed using logistic regression and the  continuous outcome using linear regression. No interaction terms are included in the univariate models.  4.2.2 Parametric MI with no interaction – predictive mean matching to impute missing outcome (MI, no int)  This approach is like the previous one, but predictive mean matching (PMM) is used to multiply impute the  outcome, where imputed values are drawn using the nearest observed value after fitting a linear regression. We considered this approach as, like classification and regression trees (CART) or random forest (RF)  (approaches 3.2.5 and 3.2.6 described below) it can handle nonlinear associations. 4.2.3 Parametric MI with two-way interactions (MI,2-way int)  This approach uses logistic regression to impute the exposure and confounders, PMM to impute the  outcome, and includes in the relevant univariate FCS models two-way interactions between exposure and  outcome, exposure and each confounder, each confounder and outcome, and all two-way confounderconfounder interactions. Interaction terms are themselves imputed using the R mice “passive” approach, i.e.,  generated within each cycle of the MI algorithm from current values of relevant variables involved in the  interaction term. 4.2.4 Parametric MI with two-, three-, and four-way interactions (MI, higher int)  The models with two-way interactions described above are further extended in this approach to additionally  include three- and four-way interactions between the confounders.    4.2.5 MI using classification and regression trees (MI, CART)  In the two final MI approaches, all variables with missing data are multiply imputed using a recursive  partitioning technique, using either CART or RF. Both of these methods are available in the mice package in   and have been proposed to enable imputation that can more flexibly allow for interactions and nonlinearities.  In CART, for a given variable with missing data, a tree is fitted, with all other variables in the  imputation as predictors. Each record will belong to a donor leaf, from which a randomly selected value for  the variable will be taken as the imputed value. 4.2.6 MI using random forest (MI, RF)  In RF, multiple bootstrap samples are drawn from the complete dataset and for each of these a separate tree  is fitted. Each tree contributes a donor leaf, and a randomly selected value for the variable will be taken from  all these donors. To compare the performance of the above-described methods for handling missing data, we performed a  simulation study, based on the VAHCS case study. We simulated 2,000 datasets, each including 2,000  records, as outlined below.  We used samples of size 2,000, which was larger than the number of VACHS  female participants (n=1,000), because we did not want sample size to be an issue and it is known that dataadaptive algorithms perform better with larger sample sizes.  In all scenarios, we determined the values of  parameters for the data generation models by fitting similar models to the available data in VAHCS except  where noted otherwise. Supplementary Table 1 shows the parameter values used for simulating the data  and Supplementary Table 2 the distribution of the variables in the simulated data based on the specified  parameter values.   5.1 Generating the complete data    We generated variables sequentially according to the DAG shown in Figure 2.   We used parametric regression models to generate the data and considered three scenarios (simple, complex  1, and complex 2) with increasing levels of complexity in terms of confounder-confounder interaction terms  involved. Specifically, for all scenarios we generated a normally distributed auxiliary variable  and a set of  binary confounders     , ,  , ) where confounders  , , and  were generated via regression  on . The models for generating these variables are detailed below (where it is assumed that all binary  variables are coded 0/1 and        :  In generating confounders  and  , we changed the coefficient value for  from what it was in VAHCS,  so that it was a stronger auxiliary variable, and modified the intercepts so that the prevalence of the variables  remained the same as in the VAHCS dataset.   The scenarios differed in the exposure and outcome generation models:   Simple scenario: we generated a binary exposure  via a main-effects logistic regression on  and , and a  continuous outcome  via a main-effects linear regression on  and  (Figure 2):                                    Complex scenarios: we generated  via regression on , , and two-way confounder-confounder  interactions, and  via regression on , , and two-, three-, and four-way confounder-confounder  interactions. The exposure and outcome models did not include interactions with   because of the low  prevalence (15%) of the confounder:                                                                              and -1.2 to 1.7 respectively in the exposure and outcome models for the complex scenario 1 and from -3.2 to  0.5 and -2.4 to 3.4 respectively in the exposure and outcome models for the complex scenario 2. In terms of  the other regression coefficients, for the exposure model, we modified the coefficient value for , so that it  was a stronger auxiliary variable and the coefficient value for  , so that it was less strongly associated with  . We modified the intercept so that the prevalence of  was approximately 15% in the simulated data (12%  in VAHCS) in all scenarios. For the outcome model, we modified the coefficient values for  ,  , and  so that they were stronger confounders (the coefficient values for the confounders ranged from 0.1 (for  to 0.7 (for  ) in the simulation study). Under all outcome generation models, we set the coefficient value  for  ( ), which is the true value of the ACE, to 0.2. This is a moderately sized effect in that the null  hypothesis of no causal effect is formally rejected (p < 0.05) in approximately 80% of the simulated  datasets. We modified the intercept in the outcome model so that the mean of  remained 0.   5.2 Imposing missing data   We considered 11 missingness scenarios, defined by m-DAGs (causal diagrams with missingness indicators  for each variable with incomplete data as nodes in the DAG). These causal diagrams differ in the presence  of arrows from confounders, exposure, and outcome to the missingness indicators for other variables or to  their own missingness indicators, and thereby in the set of conditional independencies they imply.  These  m-DAGs represent all missingness scenarios in point-exposure epidemiological studies that are distinct in  terms of the implications of these conditional independencies for the identifiability of key parameters  (Figure 3, also refer to the paper by Moreno-Betancur et al.  for details on the development of these  representative m-DAGs).   To reflect the real VAHCS data, we imposed missingness on  ,  ,  ,  and , through generating  missingness indicators  ,  ,  ,   and  , coded 1 if the variable was missing and 0 if observed.  We considered variables ,  , and  , which had a small proportion of missing values within VAHCS  (<10% each, Table 1) as fully observed in the simulation study. The models used for generating the  missingness indicators were as below:                                                                                                               the missingness indicator  , the model for   included   and  , the model for   included  coefficient values for these missingness indicators and the intercepts so that the missingness proportion for  each variable and the overall proportions with missing data were the same across all missingness scenarios  and approximately the same as in the real VAHCS dataset, except for the outcome, for which the proportion  with missing data was increased to 20% (13% in the VACHS data). Also, we set the proportion with missing  data for any of the confounders or exposure to 40% (34% in the VAHCS data) and the proportion with  missing data for any variables used in the target analysis (exposure, confounders, and outcome) to 50%  (40% in the VAHCS data).   5.3 Analysis of the simulated data   For each simulated dataset, we first estimated the ACE of  on  on the complete data (prior to generating  missingness), using TMLE with data-adaptive methods and   to   as confounders. We used the TMLE  package in R  and fitted the exposure and outcome models using Super Learner.  Super Learner is an  ensemble learning method that combines predictions from a library of chosen algorithms using a weighting  approach, where the weights are proportional to the predictive performance of each algorithm assessed using  cross-validation.  We followed the current general advice for selecting the candidate algorithms for the  Super Learner library, which is to include a range of parametric, semiparametric, and non-parametric  methods.  We compared the performance of different combinations of methods in terms of bias and  computational time  (Supplementary Table 3) to select the methods for the Super Learner library used in  all analyses for this simulation study: mean (the average), glm (generalized linear model), glm.interaction  (generalized linear model with 2-way interactions between all pairs of variables), bayesglm (Bayesian  generalized linear model), gam (generalized additive model), glmnet (elastic net regression), earth  (multivariate adaptive regression splines), rpart (recursive partitioning and regression trees), rpartPrune  (recursive partitioning with pruning), ranger (random forest).  interaction terms in the relevant univariate FCS models: ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  , and  . This approach included all the interaction terms that were included in the  regression model for generating the exposure, but not the outcome, under the complex data generation  scenarios. In addition to these two-way interactions, in the MI version with two-, three-, and four-way  interactions (MI, higher int), we included the  ,  ,  ,  ,  interaction terms  in the relevant univariate models. This approach encompassed all the interaction terms included in the  regression models for generating the exposure and outcome in the complex scenarios. Supplementary  Tables 4 and 5 show the variables and interaction terms included in each imputation model for MI, 2-way  int and MI, higher int approaches respectively. In MI, CART and MI, RF we used the default settings of the  mice package for the hyperparameters (i.e., complexity parameter = 0.0001 and minimum leaf size = 5 for  CART, number of trees to grow = 10 for RF). 5.4 Evaluation criteria   We compared the performance of the approaches for handling missing data by calculating bias (the  difference in the estimated ACE averaged over 2000 simulated datasets and the true value of the ACE) and  relative bias (bias divided by the true ACE, expressed as a percentage). We also calculated the empirical and  model-based SEs, percent error in average model-based SE relative to the empirical SE, the coverage  probability of the 95% CI, and the bias-eliminated coverage probability. For all measures, Monte-Carlo SEs  were obtained. The formulae used for these calculations can be found in Morris et al All analyses were performed in R version 3.6.1. 6.1 TMLE performance in the complete data   Supplementary Table 6 shows the performance of TMLE in estimating the ACE in the simulated complete  datasets (before generating missingness), compared with a main-effects regression approach as well as a gcomputation approach that included all two-way confounder-confounder interactions, excluding interactions  with  . The relative bias was <1% for the three approaches in the simple scenario, it was 32% for outcome  regression and <2% using the other two methods in the complex scenario 1, and 107% for outcome  regression, 8% for g-computation, and 1% for TMLE in the complex scenario 2. These results confirm that a  main-effects regression model would suffer from misspecification bias under the complex scenarios 1 and 2,  and so would g-computation in the complex scenario 2, though to a lesser extent.   performance measures and Monte-Carlo SEs). Complete-case analysis and Ext TMLE yielded small biases  (relative bias  5%) for m-DAGs T, A, B, D, and E across all the scenarios. For the same m-DAGs, the Ext  TMLE+MCMI approach was more biased (relative bias 6%-16%) compared with complete-case analysis  and Ext TMLE. Of all the m-DAGs, for all the scenarios, the three non-MI approaches led to largest biases  for m-DAGs H, I, J (relative bias 9%-25%).   Within each of the three scenarios, the performances of the parametric MI approaches that used either a  linear regression or PMM to impute outcome data and did not include any interaction terms were similar to  each other. In the simple scenario, these approaches produced small bias for m-DAGs T, A, B, C, D, E, F, I  (relative bias  9%), and higher bias for m-DAGs G, H, J (relative bias 11%-21%). Compared with the  simple scenario, these approaches led to higher bias for m-DAGs T, A, D, E, F for the complex scenario 1  (relative bias 12%-18%) and all m-DAGS for the complex scenario 2 (relative bias 14%-59%). Across all  the scenarios, the highest bias was observed for m-DAG H.   The parametric MI approaches that included the two-way interactions and two-, three-, and four-way  interactions had comparable performance to each other within each of the three scenarios. Including  interaction terms in the imputation model did not have a large impact on the results for the simple scenario,  but it reduced the bias seen with MI without interactions for m-DAGs T, A, D, E, F for the complex scenario  1 (relative bias 0%-5%) and all m-DAGs for the complex scenario 2 (relative bias 19%).   Across the three scenarios, MI, CART produced estimates with similar bias. Also, MI, RF yielded estimates  with similar bias for the scenarios, which was consistently higher than MI, CART (relative bias 27% for  MI, CART and 18%-50% for MI, RF). For both approaches, of all the m-DAGs, bias was smallest for mDAGs T, A, D, and F. Compared with the parametric MI approaches without interaction, MI, CART and  MI, RF performed worse for all the m-DAGs under the simple scenario, while MI, CART performed better  for m-DAGs T, A, D, F under the complex scenario 1 and all the m-DAGs under the complex scenario 2.  MI, RF performed better than the parametric MI approaches without interaction for m-DAGs T, A, D, and F  under the complex scenario 2. When compared with parametric MI approaches with interactions, MI, RF  performed less well across the three scenarios and all the m-DAGs. Also, MI, CART performed less well  than parametric MI approaches with interactions under the simple scenario and complex scenario 1, but its  performance was more similar to parametric MI approaches with interactions under the complex scenario 2.   6.2.2 Empirical standard error and relative error in model-based standard error  For each missing data method, the empirical SEs (Figure 5) were generally similar across all the m-DAGs  and scenarios. The SEs using complete-case analysis and Ext TMLE were similar (both between 0.11-0.15)  and were somewhat larger compared with the Ext TMLE+MCMI (0.10-0.14) and all the MI approaches  (0.06-0.14). Except for MI, RF, which had a lower empirical SE (0.6-0.8), the SEs obtained from the MI  approaches were broadly similar with each other (0.09-0.14) and with the Ext TMLE+MCMI approach.   The model SEs were underestimated (Figure 6) using non-MI methods and overestimated using MI  methods, across all scenarios and m-DAGs, with the degree of error lowest under the simple scenario and  highest under the complex scenario 2. Within each scenario, the performance of non-MI approaches was  similar. The performance of the MI approaches was also generally similar within each scenario, except MI,  RF, which produced model SEs with considerably larger error.   6.2.3 Coverage  The coverage probabilities of the 95% CI (Figure 7) for the three non-MI approaches were similar within  each of the scenarios, with ranges 89%-94%, 89%-92%, and 84%-90% for the simple, complex scenario 1  and 2, respectively. They were also broadly similar for the MI approaches, with ranges 94%-96%, 95%97%, and 91%-99% for the simple scenario, and complex scenarios 1 and 2 respectively, except for MI, RF,  for which it was somewhat larger, ranging from 96% to 100% across the three scenarios.    Similar to the analysis of the simulated data, we conducted the analysis of the VAHCS case study using the  TMLE package in R,  fitting the models using Super Learner,  including the following methods in the  Super Learner library: mean, glm, glm.interaction, bayesglm, gam, glmnet, earth, rpart, rpartPrune, ranger.  We applied the same nine missing data methods described previously. Unlike in the simulations, a small  proportion of participants had missing data for parental divorce (  and parental education (  (Table 1),  which were handled here in the same way as missing data for the other confounders. Also, the auxiliary  variable age ( had 9.3% missing data, which was multiply imputed in all the MI approaches. For the MI  approaches, 100 imputations were performed. Results are shown in Table 2. The obtained effect sizes were  small and largely similar using different methods, with the exception of MI, no int (linear) and MI, no int  which yielded somewhat larger effect sizes. The standard errors for MI approaches were larger than the nonMI methods. This finding could be explained by the downward and upward biases in model SEs for non-MI  and MI approaches, respectively, which we observed in our simulation study (Figure 5). For example, using  the relative percent error in model SEs averaged over all m-DAGs and the three scenarios in the simulations,  the corrected SEs in the case study would be 0.14 for complete-case analysis, 0.13 for MI, linear, and 0.11  for MI, RF (average relative % error in model SE for the three approaches were respectively -11.91, 12.43,  and 61.88).  Of the MI approaches, MI, RF took the longest to run, followed by MI, CART. Adding interaction terms to  parametric MI approaches had a small impact on the time. There were no imputation failures for any of the  approaches.   We compared the performance of currently available methods for handling missing data when estimating the  ACE using a TMLE approach where data-adaptive methods were used for exposure and outcome models.  We considered one simple and two complex scenarios for the exposure and outcome data generating models,  and eleven missingness mechanisms which represented the range of plausible and distinct missingness  mechanisms in epidemiological longitudinal cohort studies.  Overall, no approach was found to perform  well across all scenarios and missingness mechanisms. For the non-MI methods, the degree of bias  depended on the missingness mechanism and was generally smaller for the missingness mechanisms where  outcome did not influence missingness in any of the variables. For parametric MI approaches, bias was  generally smaller for the missingness mechanisms where outcome variable did not directly influence  missingness in the outcome. For these approaches, bias additionally depended on the complexity of the data  generation scenario, getting increasingly larger as the data generation became more complex. This bias was  reduced when interaction terms were included in the imputation model. The bias of MI approaches using  machine learning algorithms (MI, CART and MI, RF) was also influenced by the missingness mechanism,  but not the data generation, and was smaller for missingness mechanisms where missingness in the outcome  was not influenced by the outcome or any other variable with missing data. Of all the assessed approaches,  MI, RF yielded estimates with the highest bias across all missingness mechanisms and scenarios. For each  missing data method, the precision around the effect estimate was similar in all the missingness mechanisms  and scenarios. It was slightly larger for complete-case analysis and extended TMLE, and was smallest for  MI, RF. For all the non-MI methods, the model SEs had a downward bias. The model SEs were broadly  similar across the three scenarios and missingness mechanisms but larger for the complex scenarios. For the  MI approaches, the model SEs were upwardly biased, similar across the different missingness mechanisms  for each approach, and larger for the complex scenarios. Except for MI, RF, which had a considerably  higher error, the errors in model SEs were similar for the MI approaches.   In our simulation study, under m-DAGs where missingness did not depended on the outcome for any  variable and the conditional distribution of the outcome was recoverable by a complete-case analysis (mDAGs T, A, B, D, E  ), the complete case analysis and extended TMLE in the sample with complete  exposure and confounders produced estimates with small bias as expected, regardless of the complexity of  the data generation procedure. The extended TMLE+MCMI approach yielded estimates with higher bias  across these scenarios. A key assumption under which the MCMI approach has been shown to be unbiased  is when the exposure or outcome only depend on the confounder when the confounder is observed.  This  assumption is unlikely to be plausible in a prospective cohort study, such as VAHCS, where the data are not  being used for medical decision-making. Therefore, we did not evaluate the methods under missingness  scenarios where this assumption held.  Our results illustrate the difficulty of using MI to handle missing data when TMLE with data-adaptive  approaches are used for ACE estimation. Under the simple scenario, the performance of the parametric MI  model with no interactions generally led to smaller bias under missingness mechanisms where outcome  variable did not directly influence missingness in the outcome (m-DAGs T, A, B, C, D, E, F, I) and higher  bias under missingness mechanisms where outcome directly influenced missingness in the outcome (G, H,  J). In contrast, for the complex scenarios, where the imputation model with no interactions was misspecified  and likely incompatible with the analysis model (because Super Learner makes it uncertain which model has  more weight), these MI approaches produced estimates with higher bias, even for m-DAGs T, A, B, C, D, E,  F, I. Including interaction terms in the imputation model improved the performance of parametric MI in  these scenarios. This could be explained by the fact that in this simulation study the complex scenarios were  defined based on the presence and strength of confounder-confounder interaction terms in the regression  models for generating exposure and outcome, meaning that the MI models with interactions would be  approximately correctly specified. Unfortunately, however, in practice the data generating process  underlying observational data is rarely fully understood. This limited knowledge, which itself is a motivation  for using TMLE with data-adaptive approaches, makes defining parametric imputation models that are  compatible with analysis models challenging.   strength of interaction terms in the regression models for generating exposure and outcome. Put together  with the considerations that the MI, CART implementation might be more convenient than attempting to  incorporate interactions and non-linearities in an imputation model, and that the functional relation between  variables is often unknown, these results suggest that MI, CART might be an attractive alternative to  parametric MI, especially when working with datasets with many covariates.   In the present study, all non-MI approaches underestimated the model SE and led to below nominal 95%  CIs. This was also the case for TMLE performed using the complete data and was not surprising. The TMLE  variance estimation is valid if both the exposure and outcome models are consistently estimated and the  Donsker class condition is satisfied.  It is, however, unclear if the latter is met when data-adaptive  approaches are used for exposure and outcome models.  This bias has been observed in other simulation  studies,  and developing approaches to tackle it is an area of ongoing research. In addition, the MI  Rubin variance estimator is expected to perform poorly in the presence of incompatibility,  which might  explain the error we observed in model SEs for the MI approaches. This indicates that incompatibility is the  key challenge of using MI together with TMLE where models are fitted using Super Learner, not only in  terms of bias of point estimates, but also in terms of bias in variance estimates. A promising alternative  approach for obtaining MI SE in the presence of incompatibility has been recently proposed using the  bootstrap,  but we did not explore this because of the computational constraints.   Our simulation study was broadly based on VAHCS to emulate a realistic scenario. We considered 11  missingness mechanisms, which allowed us to evaluate the performance of different approaches to handle  missing data using a finer-grained framework for illustrating and assessing missing data assumptions than  the more commonly used missing at random (MAR)-missing not at random (MNAR) framework.  For each  MI approach, due to computational constraints we generated five completed datasets, which is fewer than  we would do in practice.  We do not expect it to have affected the comparison between MI approaches, but  it could have affected comparison of non-MI with MI methods. Our simulated data had a fairly simple  structure across the three assessed scenarios, with five binary confounders, a continuous outcome, and no  effect modification. Even under this simple structure, our results could provide useful guidance for handling  missing data when estimating the ACE using a TMLE approach. Extensions of our study could investigate  the performance of these missing data methods for datasets with high-dimensional confounders, binary  outcomes, and in the presence of effect modification.   approach in the sample with complete exposure and confounder data could produce estimates with small  bias regardless of the data generation, but potentially with some degree of loss of precision. Parametric MI  could also be expected to perform well in terms of bias, particularly for missingness mechanisms where  outcome variable does not directly influence missingness in the outcome, when the imputation models are  correctly specified. While, in practice, knowledge on what a correctly specified model would be is often  limited, opting for saturated imputation models within the limits of the data might be a helpful strategy for  improving the performance of parametric MI approaches. In settings with many covariates with likely  interactions and non-linearities, it could quickly become cumbersome to model these in parametric MI, in  which case MI, CART might be a useful alternative. We recommend considering missing data mechanism  and, if using MI, opting for a saturated parametric or data-adaptive imputation model for handling missing  data in TMLE estimation.    Acknowledgements   This article used unit record data from the Victorian Adolescent Health Cohort Study. We thank the families  that participated in the VAHCS, the study research team and the Principal Investigator, Professor George  Patton. We also thank Anthony Charsley for his contributions to the coding in the preliminary stages of this  work.   Funding   Ian White was supported by the Medical Research Council Programme MC_UU_00004/07. Katherine Lee  was funded by a National Health and Medical Research Council Career Development Fellowship (ID  1127984). Margarita Moreno-Betancur is the recipient of an Australian Research Council Discovery Early  Career Researcher Award (project number DE190101326) funded by the Australian Government. The work  was supported from the National Health and Medical Research Council Project Grant (ID 1166023). The  Murdoch Children’s Research Institute is supported by the Victorian Government’s Operational  Infrastructure Support Program.   Author Contributions   All authors participated in planning the simulation and case studies, the manuscript, and interpretation of the  results. SGD and MMB performed the simulation and case study analyses. SGD led the writing of the  manuscript. All authors read and contributed to the manuscript.   Data availability statement   Data from the Victorian Adolescent Health Cohort Study (VAHCS) are not publicly available. Those  interested in replicating these findings are welcome to contact the corresponding author, or the VAHCS  team (https://www.mcri.edu.au/research/projects/2000-stories/information-researchers). 