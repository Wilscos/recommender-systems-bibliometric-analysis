Center for Statistical Science, Department of Industrial Engineering, Tsinghua University, Beijing, 100084, China. Center for Statistical Science, Department of Industrial Engineering, Tsinghua University, Beijing, 100084, China. Yuehan Yang† School of Statistics and Mathematics, Central University of Finance and Economics, Beijing, 102206, China. Summary. Blocking, a special case of rerandomization, is routinely implemented in the design stage of randomized experiments to balance baseline covariates. Regression adjustment is highly encouraged in the analysis stage to adjust for the remaining covariate imbalances. Researchers have recommended combining these techniques; however, the research on this combination in a randomization-based inference framework with a large number of covariates is limited. This paper proposes several methods that combine the blocking, rerandomization, and regression adjustment techniques in randomized experiments with high-dimensional covariates. In the design stage, we suggest the implementation of blocking or rerandomization or both techniques to balance a ﬁxed number of covariates most relevant to the outcomes. For the analysis stage, we propose regression adjustment methods based on the Lasso to adjust for the remaining imbalances in the additional high-dimensional covariates. Moreover, we establish the asymptotic properties of the proposed Lasso-adjusted average treatment effect estimators and outline conditions under which these estimators are more efﬁcient than the unadjusted estimators. In addition, we provide conservative variance estimators to facilitate valid inferences. Our analysis is randomization-based, allowing the outcome data generating models to be misspeciﬁed. Simulation studies and two real data analyses demonstrate the advantages of the proposed methods. Keywords: Lasso, Randomization inference, Regression adjustment, Rerandomization, Stratiﬁed randomization Randomized experiments are the basis for evaluating the eﬀect of a treatment on an outcome and are widely used in the ﬁelds of industry, social sciences, and biomedical sciences (see, e.g., Fisher, 1935; Box et al., 2005; Imbens and Rubin, 2015; Rosenberger †Corresponding author: yyh@cufe.edu.cn and Lachin, 2015). In randomized experiments, complete randomization of the treatment assignments can balance the baseline covariates on average. However, scholars recognized that covariate imbalances often occur in a particular treatment assignment (see, e.g., Fisher, 1926; Rosenberger and Sverdlov, 2008; Morgan and Rubin, 2012; Athey and Imbens, 2017). To increase the estimation eﬃciency of the treatment eﬀect, certain researchers have recommended balancing the key covariates in the design stage (Fisher, 1926; Efron, 1971; Zelen, 1974; Morgan and Rubin, 2012; Krieger et al., 2019), whereas other researchers have recommended implementing adjustments for the covariate imbalances in the analysis stage (Fisher, 1935; Yang and Tsiatis, 2001; Miratrix et al., 2013; Lin, 2013; Bloniarz et al., 2016). Fisher (1926) was the ﬁrst to recommend the use of blocking or stratiﬁcation in the design stage to balance a few discrete covariates that were the most relevant to the outcomes. Since this research, blocking as an experimental design method has been widely used and investigated (see, e.g., Wilk, 1955; Green and Byar, 1978; Imai et al., 2008; Imbens, 2011; Higgins et al., 2015; Schochet, 2016; Pashley and Miratrix, 2020). While blocking can eﬀectively balance discrete covariates, the balancing of continuous covariates through this approach is less intuitive. Rerandomization is a more general approach to balance both discrete and continuous covariates (Morgan and Rubin, 2012, 2015; Branson et al., 2016; Zhou et al., 2018; Li et al., 2018, 2020). Recently, scholars have recommended combining blocking and rerandomization techniques (Schultzberg and Johansson, 2019; Wang et al., 2020). D. B. Rubin summarized this design strategy as “Block what you can and rerandomize what you cannot”. Notably, blocking or rerandomization or their combination can balance only a ﬁxed number of covariates. However, in modern randomized experiments, a large number of baseline covariates are often collected, and the number of covariates can be larger than the sample size. For example, in a clinical trial, the researcher may record the demographic and genetic information of each patient. Bloniarz et al. (2016) highlighted that in such high-dimensional settings, most of the covariates may not be related to the outcomes, and thus, the important covariates must be selected to realize eﬃcient treatment eﬀect estimation. In the design stage, in the event in which pre-experimental data (outcomes and covariates) were available, Johansson and Schultzberg (2020) used the Lasso (Tibshirani, 1996) for variable selection and rerandomization to balance those selected covariates. However, when pre-experimental outcome information is not available, it is diﬃcult to perform covariate selection in the design stage. A more realistic approach is to use the Lasso in the analysis stage to simultaneously perform covariate selection and regression adjustment. Regression adjustment has been widely used to analyze randomized experiments and increase the associated eﬃciency (see, e.g., Fisher, 1935; Miratrix et al., 2013; Lin, 2013; Bloniarz et al., 2016; Liu and Yang, 2020). Li and Ding (2020) showed that regression adjustment is equivalent to rerandomization (with a threshold tending to zero) for a certain set of covariates. In contrast to regression adjustment based on the Lasso, blocking and rerandomization techniques do not use the outcome data and thus can avoid bias due to the speciﬁcation search of the outcome model. Many scholars have indicated that it is preferable to avoid the occurrence of covariate imbalances before treatment is administered, rather than performing post-treatment regression adjustment (Cox, 2007; Freedman, 2008a,b; Rosenbaum, 2010). In this context, a trade-oﬀ method is to combine blocking, rerandomization, and high-dimensional regression adjustment. In such a method, blocking or rerandomization or both are implemented in the design stage to balance a few covariates that most signiﬁcantly aﬀect the outcomes. Next, we perform covariate selection and regression adjustment by using, for example, the Lasso in the analysis stage to adjust for the remaining imbalances in the additional high-dimensional covariates and further increase the eﬃciency. Recently, researchers have proposed methods to combine blocking, rerandomization, and regression adjustment in randomized experiments with low-dimensional covariates. Bugni et al. (2018) showed that the regression of the outcome on the treatment and stratum indicators can increase the estimation eﬃciency of the average treatment eﬀect in covariate-adaptive randomized experiments, including the randomized block (stratiﬁed randomized) experiments as special cases. When the propensity scores (proportion of treated units in each block) diﬀer across blocks, this method yields an inconsistent estimator. To address this issue, Bugni et al. (2019) proposed a weighted regression-adjusted estimator. Moreover, several scholars have discussed regression adjustment based on additional covariates beyond the stratum indicators Ma et al. (2020a); Wang et al. (2019); Ye et al. (2021); Ma et al. (2020b); Ye et al. (2020); Liu et al. (2020). Notably, these studies considered a supper-population framework and assumed that the number of blocks was ﬁxed with their sizes tending to inﬁnity. Considering a ﬁnite population framework, Liu and Yang (2020) proposed a weighted regression adjustment method for randomized block experiments and demonstrated that this approach could increase the eﬃciency even when the number of blocks tended to inﬁnity with the block sizes being ﬁxed. However, this method assumes homogeneous propensity scores across blocks, can manage only low-dimensional covariates, and cannot consider rerandomization in the design stage. Li and Ding (2020) established a uniﬁed theory for rerandomization followed by regression adjustment. However, the authors did not consider high-dimensional covariates or the combination of blocking and rerandomization in the design stage. Overall, the research on the simultaneous implementation of blocking, rerandomization, and regression adjustment and consideration of high-dimensional covariates is limited. To address this aspect, in this study, we develop approaches and theoretical guarantees for the abovementioned combination in general settings with both homogeneous and heterogeneous block sizes, propensity scores, and treatment eﬀects. Our asymptotic results are obtained under a ﬁnite population and randomization-based inference framework. The potential outcomes and covariates are ﬁxed quantities, and the sole source of randomness is the treatment assignment. Thus, we allow the outcome data generating models to be mis-speciﬁed. Our contributions are three-fold and can be summarized as follows. First, we propose two approaches to combine blocking and high-dimensional regression adjustment, speciﬁcally, two Lasso-adjusted average treatment eﬀect estimators in randomized block (stratiﬁed randomized) experiments. We show that under mild conditions, both estimators are consistent and asymptotically normal. Moreover, the asymptotic variance of the ﬁrst estimator is no greater than that of the unadjusted estimator when the propensity scores are the same across blocks. The second estimator is obtained from a projection perspective and is asymptotically more eﬃcient than, or at least as eﬃcient as, the unadjusted estimator, even when the propensity scores differ across blocks. In addition, we use Neyman-type conservative variance estimators to construct conﬁdence intervals for the average treatment eﬀect. Although Bloniarz et al. (2016) also established an asymptotic theory for a Lasso-adjusted estimator, they did not consider blocking. The technical diﬃculty lies in establishing novel concentration inequalities for the weighted sample mean and sample covariance under stratiﬁed randomization. Second, we propose a Lasso-adjusted estimator to combine rerandomization and regression adjustment, thereby extending the results of Li and Ding (2020) to highdimensional settings. We show that in the case of rerandomization, the proposed Lassoadjusted estimator improves, or at least does not degrade, the precision compared with that obtained using the unadjusted estimator. Third, we propose two Lasso-adjusted estimators in randomized experiments when both blocking and rerandomization are used in the design stage. We investigate the asymptotic properties of the estimators and outline conditions under which they are more eﬃcient than the unadjusted estimator. Moreover, we propose conservative variance estimators to facilitate valid inferences. The remaining paper is organized as follows: Section 2 introduces the framework and notation. Section 3 describes the two Lasso adjustment methods in randomized block or stratiﬁed randomized experiments and the examination of their asymptotic properties. Section 4 describes the method combining rerandomization and Lasso adjustment. Section 5 describes the two novel “blocking + rerandomization + Lasso adjustment” methods and the establishment of their asymptotic theory. Details of the simulation studies and two real data analyses are presented in Sections 6 and 7, respectively. Section 8 presents the concluding remarks. All the proofs are presented in the Supplementary Material. Consider a randomized experiment with n units and a binary treatment. For each unit i, i = 1, . . . , n, Zis an indicator of treatment assignment. Speciﬁcally, Z= 1 if unit i is assigned to the treatment group and Z= 0 otherwise. The treatment assignment is randomized. For example, in a completely randomized experiment, the probability distribution of the treatment assignment vector Z = (Z, . . . , Z)is where n=Zis the number of treated units, n=(1 −Z) is the number of control units, and I(·) is an indicator function. We deﬁne the treatment eﬀects by using the Neyman–Rubin potential outcomes framework (Sp lawa-Neyman et al., 1990; Rubin, 1974). For unit i, Y(1) and Y(0) are the potential outcomes under the treatment and the control, respectively. We deﬁne the unit-level treatment eﬀect as τ= Y(1) − Y(0). As each unit is assigned to either the treatment group or the control group, but not both, we cannot simultaneously observe Y(1) and Y(0). Thus, τcannot be identiﬁed without strong modelling assumptions pertaining to the potential outcomes. Under the stable unit treatment value assumption (SUTVA) (Rubin, 1980), the average treatment eﬀect, deﬁned as follows, is identiﬁable: The observed outcome is Y a p-dimensional baseline/pre-treatment covariate vector x where p domain knowledge, certain covariates are most relevant to the potential outcomes and may thus be preferentially balanced in the design stage. Without loss of generality, we deﬁne these covariates as the ﬁrst k elements of x Although the remaining covariates may also be relevant, the designer does not have prior information regarding their importance. These covariates are candidates for performing regression adjustment in the analysis stage. Throughout the paper, we assume that k is ﬁxed, and p is to make valid and eﬃcient inferences on the average treatment eﬀect τ by using the observed data {Y Notation. For an L-dimensional column vector u = (u kuk, and kuk {1, . . . , L}, S u on S. Let |S| be the cardinality of S. For a matrix Σ, Λ eigenvalue of A. respectively. ˙∼ denotes the asymptotic equivalence. We use c, C, . . . , to denote universal constants that do not change with n but whose precise value may change from line to line. 3.1. Randomized block experiments and unadjusted treatment effect estimator Blocking is a traditional approach to balance discrete covariates in experimental design. Experiments in which blocking is implemented are usually known as stratiﬁed randomized experiments or randomized block experiments. Blocking can increase the estimation eﬃciency of the average treatment eﬀect when the blocking variables are relevant to the outcomes (Fisher, 1926; Imai, 2008; Imbens and Rubin, 2015). Moreover, Liu and Yang (2020) showed that a weighted regression adjustment can further improve the estimation eﬃciency when a ﬁxed number of covariates is available. In this section, we describe two methods that combine blocking and high-dimensional regression adjustment to manage homogeneous and heterogeneous propensity scores across blocks. Speciﬁcally, we study the properties of randomized block experiments by using covariates w design stage and performing regression adjustment using the Lasso in the analysis stage to adjust for the remaining imbalances in covariates x First, we introduce the randomized block experiments. Before the physical implementation of the experiment, we stratify the units into M blocks based on the covariates w by using a function B : support(w is comparable to or even larger than n. According to prior experiments or is the complementary set of S and u= (u, j ∈ S)is the restriction of w. For example, we stratify the units according to their gender, location, and discretized age. Let B= B(w) denote the block indicator for unit i. We remove the covariates that are linearly dependent on Bfrom xand w, and denote the remaining covariatesP as xand wwith dimensions of p and k, respectively. Let n=I(B= m) denote the number of units in block m (m = 1, . . . , M). Hereafter, subscript “[m]” indicates block-speciﬁc quantities. Within block m, nunits are randomly assigned to the treatment group, and the remaining nunits are assigned to the control group. TheP total number of treated units is n=n. We assume that 2 6 n6 n−2. The treatment assignments are independent across blocks, and thus, the probability distribution of Z = (Z, . . . , Z)in randomized block experiments is where i ∈ [m] indexes the unit i in block m. Certain additional notations are deﬁned as follows: π= n/n is the proportion of block size for block m, and e= n/nis the propensity score. For potential outcomes or transformed potential outcomes R(z) (z = 0, 1), the block-speciﬁc average and sample mean are deﬁned as respectively. The overall average and overall (weighted) sample mean are denoted as respectively. For ﬁnite population quantities where Hand Qare the column vectors. The block-speciﬁc covariance and overall covariance are denoted as When H = Q, we occasionally simplify the subscript as S= S. The corresponding sample quantities are denoted as s,ˆΣ, and s. These quantities depend on n; however, they are not indexed with n to ensure simplicity of notation. Thus, the block-speciﬁc average treatment eﬀect is with the overall average treatment eﬀect being The diﬀerence-in-means of the outcomes within block m is an unbiased estimator of τ Thus, a plug-in estimator of τ is the following weighted diﬀerence-in-means: Under mild conditions, ˆτ with a mean of zero and variance of More detailed discussions of this aspect can be found in the work of Liu and Yang (2020) and the references therein. Notably, ˆτ sections, we introduce two Lasso-adjusted average treatment eﬀect estimators and study their asymptotic properties. The ﬁrst and second approaches are applicable for cases involving equal and unequal propensity scores across blocks, respectively. For equal propensity scores, e proposed the following weighted linear regression with low-dimensional covariates: The regression-adjusted average treatment eﬀect estimator ˆτ least squares (OLS) estimator of τ (coeﬃcient of ω /(n−1)}+ (1 −Z){n/(n−1)}, for i ∈ [m]. Liu and Yang (2020) equivalent to performing two weighted regressions in which we derive the weighted least squares-adjusted vectors by using the treated and control units, respectively, where z = 0, 1. In this case, where (¯x−¯x)ˆβand (¯x−¯x)ˆβadjust for the imbalances of the covariate means between the treatment and the control groups in block m. Remark 1. When both the block sizes and propensity scores are the same across blocks, i.e., n= n/M and e= e∈ (0, 1), the weighted least squares-adjusted vectors become The weighted regression (1) is equivalent to the following unweighted regression: which is the regression with covariates I(B= m) and x, as suggested by Lin (2013). The resulting estimator ˆτensures eﬃciency gains when two conditions are satisﬁed, namely, (1) the propensity scores are equal, and (2) the nvalues are identical or n→ ∞ for all m = 1, . . . , M. Otherwise, the eﬃciency may be degraded. In a high-dimensional setting, when p > n, the OLS framework is ill-posed. Variable selection or regularization is necessary for an eﬀective regression adjustment. In this study, we use the Lasso (Tibshirani, 1996) to simultaneously perform variable selection and regression adjustment. We add lpenalties on the regression coeﬃcients θand θ in the weighted regression (1), or equivalently, we derive the Lasso-adjusted vectors as where z = 0, 1, λand λare tuning parameters. In practice, we can choose λby cross-validation. We deﬁne the Lasso-adjusted average treatment eﬀect estimator as Remark 2. When only one block (M = 1) is present, ˆτ adjusted estimator proposed by Bloniarz et al. (2016). Thus, ˆτ tor proposed by Bloniarz et al. from completely randomized experiments to randomized block experiments. To investigate the asymptotic properties of ˆτ comes into a linear combination of the relevant covariates and an error term. Let Let S be the set of relevant covariates and s = |S|. Let X sub-matrix consisting of the covariates in S. We deﬁne the projection coeﬃcient β(z) as We consider a ﬁnite population and randomization-based inference, i.e., all of the quantities in the above equation are ﬁxed and deterministic real numbers, and the randomness is solely a result of the treatment assignment Z. The following conditions must be satisﬁed to ensure the consistency and asymptotic normality of ˆτ Condition 1. There exists a constant c ∈ (0, 0.5) independent of n, such that c 6 e6 1 − c for m = 1, . . . , M. Condition 2. There exists a constant L < ∞ independent of n, such that, for z = 0, 1 and j = 1, . . . , p, n Condition 3. The weighted variances e), and ﬁrst two terms. The limit of Remark 3. To satisfy Condition 1, the propensity scores must be bounded away from zero and one. In Condition 2, the bounded fourth moments are used to manage the high-dimensional covariates. This condition was also used by Bloniarz et al. (2016), Fogarty (2018a,b), Freedman (2008a), and Lin (2013) to study the asymptotic properties of various average treatment eﬀect estimators. When p is ﬁxed, we can weaken it to the following condition: for z = 0, 1 and j = 1, . . . , p, Condition 3 ensures that the asymptotic variance of limit. , . . . , x)denote the observed values of the jth covariate, j = 1, . . . , p. 6 L, and n{ε(z) − ¯ε(z)}6 L. Sis strictly positive. maxmax{ε(z) − ¯ε(z)}→ 0,1nmaxmax(x− ¯x)→ 0. Because we consider high-dimensional settings, additional conditions must be set to ensure that the Lasso can consistently estimate the projection coeﬃcient vector β(z). Condition 4. There exist constants C > 0 and ξ > 1 independent of n, such that ||h||6 Cs||Σh||, ∀h ∈ {h : ||h||6 ξ||h||}. Condition 5. For constants 0 < η < (ξ − 1)/(ξ + 1), the tuning parameters of the Lasso satisfy Remark 4. Bloniarz et al. (2016) proposed similar conditions to determine the l convergence rate of the Lasso estimator in completely randomized experiments, without blocking. We can weaken the strict sparsity condition to a weak sparsity condition.P Speciﬁcally, our theorems hold if we deﬁne s(z) =min{|β(z)|/λ, 1} and s = max{s(1), s(0)}. In this deﬁnition, we allow β(1) and β(0) to have many small but√ non-zero entries. Moreover, Condition 5 implies that s log p/n → 0. Remark 5. To satisfy Condition 6, the propensity scores must be asymptotically equal rather than exactly equal (e= efor all m = 1, . . . , M). Exactly equal propensity scores are unrealistic in certain cases due to practical restrictions. The main results are presented in the following text. Furthermore, if Condition 6 holds, then where ∆= βSβ/{e(1 − e)} with β= (1 − e)β(1) + eβ(0). Remark 6. The proof of Theorem 1 essentially relies on novel concentration inequalities for the weighted sample mean and weighted sample covariance in the case of stratiﬁed randomization. These entities are crucial for deriving the l the Lasso estimator in a ﬁnite population and randomization-based inference framework. We obtain these inequalities in general asymptotic regimes, including the cases of (1) M tending to inﬁnity with ﬁxed n inequalities are of independent interest in other ﬁelds in which stratiﬁed sampling without replacement is performed. This aspect is extensively discussed in the Supplementary Material. Theorem 1 implies that the Lasso-adjusted estimator ˆτ totically normal. Moreover, compared to the unadjusted estimator, ˆτ least does not degrade the precision when the propensity scores are asymptotically equal across blocks. In the case of unequal propensity scores, the eﬃciency may be degraded. A novel estimator to manage unequal propensity scores is described in the next section. Next, we deﬁne a Neyman-type conservative estimator for the asymptotic variance. For z = 0, 1, let ˆs(z) = || estimate the block-speciﬁc variance S variance Remark 7. Condition 7 was also used by Bloniarz et al. (2016) to ensure that max{ˆs(0), ˆs(1)} = O variance estimator without any adjustment for the degrees of freedom. However, our simulation experience shows that the unadjusted estimator may underestimate the variance in ﬁnite samples. Theorem 2. If Conditions 1–7 hold, ˆσ which is no less than σ According to Theorem 2, ˆσ treatment eﬀect τ β(1) = β(0) and S= 0. In this case, ˆσis a consistent estimator. Given 0 < α < 1, let qdenote the upper α/2 quantile of a standard normal distribution. According to Theorems 1 and 2, a 1 − α conﬁdence interval for τ is the asymptotic coverage rate of which is greater than or equal to 1 − α. Moreover, the length of the conﬁdence interval is less than or equal to that based on (ˆτ, ˆσ). Thus, ˆτincreases, or, at least, does not degrade both the estimation and inference eﬃciencies for equal propensity scores. When the propensity scores diﬀer across blocks, ˆτmay deteriorate the eﬃciency compared with that achieved using ˆτ. To address this problem, we propose another Lasso-adjusted estimator based on a projection perspective. The new estimator can ensure eﬃciency gains even when the propensity scores diﬀer across blocks. We consider the covariates as potential outcomes that are not aﬀected by the treatment assignment, i.e., x(1) = x(0) = x. The average treatment eﬀect of the covariatesPP weighted diﬀerence-in-means estimator of the covariates. To decrease the variance of ˆτ, we project it onto ˆτ, which is the weighted diﬀerence-in-means estimator of the relevant covariates. We deﬁne the projection coeﬃcient vector γas (γ)= arg minE(ˆτ− τ − ˆτγ)= cov(ˆτ)cov(ˆτ, ˆτ) with (γ)= 0. The oracle projection estimator ˜τ= ˆτ− ˆτ(γ)= ˆτ− ˆτγis consistent, asymptotically normal, and has the smallest asymptotic variance among the estimators of the form ˆτ− ˆτγ for adjusted vector γ with Remark 8. In the case of equal propensity scores, i.e., e= e, we have Thus, ˆτhas the same asymptotic distribution as ˜τ. Therefore, when the propensity scores are equal, ˆτis the best estimator among the class of estimators {ˆτ−ˆτγ : γ ∈ R, γ= 0}. {γ(z)} Intuitively, if the set S is known, we can estimate {γ(z)} covariances with the corresponding sample covariances: where s mulate ( In this case, In practice, S is usually unknown. Fortunately, we can directly estimate γ using the Lasso, To investigate the asymptotic properties of ˆτ outcomes in the following manner: Furthermore, to examine the convergence of formed potential outcomes into a linear combination of transformed covariates and an error term: +(1−z)(1−e) to simplify the notation. In this case, γ= γ(0)+γ(1), ˆγ)as a weighted least squares problem, we introduce the following weights: Theorem 3. If Conditions 1–2 hold with ε(z) being replaced by both ε(z) and ε(z)√ and xbeing replaced byωx, and Condition 3 holds with ε(z) being replaced by ε(z), and Conditions 4–5 hold with ε(z) and xbeing replaced by ε(z) and√ωx, where Furthermore, Remark 9. Theorem 3 shows that ˆτis not only feasible but also has the same asymptotic distribution as ˜τeven for unequal propensity scores. In other words, ˆτhas the smallest asymptotic variance among the estimators in {ˆτ−ˆτγ : γ ∈ R, γ= 0}. Similar to the estimation of σ, we can conservatively estimate σby replacing the ﬁnite population quantities with the corresponding sample quantities. Precisely, let ˆs = ||ˆγ||. The block-speciﬁc variance Scan be estimated by the corresponding block-speciﬁc sample variance: Then, σcan be estimated as where the factor n/{n − ˆs − 1} adjusts for the degrees of freedom. Theorem 4. Suppose that the conditions associated with Theorem 3 and Condition 7 hold, then ˆσconverges in probability to which is no less than σand no greater than the probability limit of ˆσ. For the additive treatment eﬀect within each block, i.e., τ= τfor all i ∈ [m], we have S= 0. In this case, ˆσis a consistent estimator of σ. Generally, ˆσ we can construct a 1 − α conﬁdence interval for τ: The asymptotic coverage rate of the abovementioned conﬁdence interval is greater than or equal to 1 −α. Moreover, the length of this conﬁdence interval is less than or equal to that based on (ˆτ the estimation and inference eﬃciencies, regardless of equal or unequal propensity scores. 4. Rerandomization and high-dimensional regression adjustment Although blocking is widely used in practice, it can balance only discrete covariates. Rerandomization is a more general approach to balance both discrete and continuous covariates (Morgan and Rubin, 2012, 2015; Li et al., 2020). Rerandomization discards the treatment assignments that lead to covariate imbalances and accepts only those assignments that fulﬁl a prespeciﬁed balance criterion. Morgan and Rubin (2012) proposed the use of the Mahalanobis distance of the covariate means in the treatment and control groups to measure the covariate imbalances. In completely randomized experiments, we deﬁne ˆτ A treatment assignment is acceptable if and only if the corresponding Mahalanobis distance is less than or equal to a prespeciﬁed threshold a > 0, i.e., Ma(Z, W ) 6 a. We denote M Li et al. (2018) suggested choosing a suitable a to ensure that the probability of a treatment assignment satisfying the balance criterion equals a certain value, for example, p= P {Ma(Z, W ) 6 a} = 0.001. A general rerandomization procedure is as indicated in Algorithm 1. Under mild conditions, the average treatment eﬀect estimator ˆτ (with M = 1) subjected to rerandomization is consistent and asymptotically truncated normally distributed, with the asymptotic variance being no greater than that of ˆτ under complete randomization, as reported by Morgan and Rubin (2012) and Li et al. (2018) and the references therein. Algorithm 1 (Stratiﬁed) Rerandomization using the Mahalanobis distance 1. Collect covariates data w 2. (Re-)Randomize units to treatment and control groups by complete randomization (or stratiﬁed randomization) and obtain the treatment assignment vector Z; 3. If Ma(Z, W ) 6 a, proceed to Step 4; otherwise, return to Step 2; 4. Conduct the physical experiment by using the treatment assignment Z. Rerandomization is useful for balancing a ﬁxed number of covariates w relevant to the potential outcomes. However, the additional high-dimensional covariates =¯w−¯wand the Mahalanobis distance as xmay also be related to the potential outcomes and remain imbalanced in the case of rerandomization. This phenomenon has motivated researchers to consider regression adjustment under rerandomization to adjust for the remaining covariate imbalances and further increase the eﬃciency. Li and Ding (2020) showed that rerandomization followed by regression adjustment using the OLS could increase the estimation and inference eﬃciencies when the analyzer uses both the covariates adopted in the design stage and additional covariates available only in the analysis stage. Nevertheless, this conclusion is true only for low-dimensional covariates. To extend this principle to high-dimensional settings, the proposed Lasso-adjusted estimators ˆτand ˆτcan be used. In the next section, we examine their asymptotic properties of these estimators in the case of rerandomization, as a special case of stratiﬁed rerandomization with M = 1. 5. Blocking, rerandomization, and high-dimensional regression adjustment 5.1. Stratiﬁed rerandomization (blocking plus rerandomization) Both blocking and rerandomization are powerful methods to balance a ﬁxed number of covariates. Scholars, such as Fisher and Rubin, have recommended combining these two methods in the design stage. Recently, Schultzberg and Johansson (2019) proposed a stratiﬁed rerandomization strategy in which stratiﬁed randomization is implemented instead of complete randomization in step 2 of Algorithm 1. However, this method is only applicable for the case of involving equal propensity scores, mainly because ˆτmay be asymptotically biased for τwhen the propensity scores diﬀer across blocks. To addressP this issue, Wang et al. (2020) modiﬁed the deﬁnition of ˆτ: ˆτ=π(¯w− ¯w), and showed that the asymptotic distribution of ˆτin the modiﬁed stratiﬁed rerandomization strategy is a truncated normal distribution and its asymptotic variance, denoted as σ, is less than or equal to that of ˆτin the case of stratiﬁed randomization. Moreover, the asymptotic variance can be estimated using a conservative estimator ˆσ, as indicated in the Supplementary Material. These conclusions hold in cases involving equal or unequal propensity scores. The eﬃciency of ˆτin the case of Wang et al.’s stratiﬁed rerandomization (referred to as stratiﬁed rerandomization in the following text) can be further increased by adjusting for the remaining imbalances in x. In the following two sections, we examine the asymptotic properties of the Lasso-adjusted estimators, introduced in Section 3, in the case of stratiﬁed rerandomization. 5.2. Stratiﬁed rerandomization plus Lasso for equal propensity scores To investigate the asymptotic properties of ˆτin the case of stratiﬁed rerandomization, the decomposition speciﬁed in equation (2) must be performed. We assume that W is a subset of X, i.e., {1, ..., k} ⊂ S. Moreover, we regard ε(z) as the transformed potential outcomes and let ˆτbe the weighted diﬀerence-in-means estimator forP τ= (1/n){ε(1) − ε(0)}. Applying Proposition 2 reported by Wang et al. (2020) to ε(z), we obtain the covariance of where The asymptotic distribution of ˆτ on the squared multiple correlation between ˆτ Condition 8. The weighted covariances and the limit of V {ε, W } is strictly positive deﬁnite. Theorem 5 implies that the asymptotic distribution of ˆτ rerandomization is a truncated normal distribution. For (asymptotically) equal propensity scores (Condition 6), the asymptotic distribution of ˆτ rerandomization is normal, with the asymptotic variance σ those of ˆτ ﬁed rerandomization followed by the Lasso adjustment does not deteriorate the precision for equal propensity scores. In particular, when M = 1, Condition 6 holds trivially, and Theorem 5 extends the results of Li and Ding (2020) (Theorem 3 and Proposition 3) from a low-dimensional setting to a high-dimensional setting. In contrast, for (asymptotically) unequal propensity scores, ˆτ using ˆτ the second Lasso-adjusted estimator ˆτ , . . . , Dbe independent standard normal distributed random variables andP πS/e, andπS/(1−e) tend to ﬁnite limits, in the case of stratiﬁed rerandomization. In the next section, we describe Theorem 6. If Conditions 1–8 hold, then in the case of stratiﬁed rerandomization, ˆσconverges in probability to Moreover, the following inequality holds in probability in the case of stratiﬁed rerandomization: ˆσ6 ˆσ6 ˆσ. When the individual treatment eﬀect τis constant within each block, i.e., τ= τ for all i ∈ [m], ˆσis a consistent estimator of σ. In the case involving equal propensity scores, we can construct an asymptotically conservative 1 − α conﬁdence interval for τ , according to Theorems 5 and 6: The length of this conﬁdence interval is less than or equal to those based on (ˆτ, ˆσ) and (ˆτ, ˆσ). Therefore, ˆτdoes not degrade the estimation and inference efﬁciencies in the case of equal propensity scores, relative to that attained using ˆτin both stratiﬁed randomization and stratiﬁed rerandomization scenarios. 5.3. Stratiﬁed rerandomization plus Lasso for unequal propensity scores In the stratiﬁed rerandomization scenario, ˆτmay deteriorate the eﬃciency in cases involving unequal propensity scores. To solve this problem, we consider the projection estimator ˆτintroduced in Section 3.3. Theorem 7. If the conditions associated with Theorem 3 and Condition 8 hold, then Furthermore, σ6 σ6 σ. Remark 10. When the propensity scores are equal across blocks, Theorem 5 indicates that ˆτhas the same asymptotic distribution in the stratiﬁed randomization and stratiﬁed rerandomization scenarios. When the propensity scores diﬀer across blocks, Theorem 7 implies that ˆτhas the same asymptotic distribution in the stratiﬁed randomization and stratiﬁed rerandomization scenarios. Thus, the discussion in the Remarks 8 and 9, regarding the optimality of these two estimators, remains valid. Theorem 7 shows that the asymptotic distribution of ˆτin the stratiﬁed rerandomization case is normal, which can be viewed as a truncated normal with the threshold a → 0. Moreover, the asymptotic variance of ˆτin the case of stratiﬁed rerandomization is no greater than those of ˆτin the stratiﬁed randomization and stratiﬁed rerandomization scenarios, even for the case involving unequal propensity scores. Thus, the eﬃciency attained using ˆτis never lower than that achieved using ˆτ. Compared with that in stratiﬁed randomization, the eﬃciency in the stratiﬁed rerandomization scenario does not increase when ˆτis used in the analysis stage. Similar conclusions were derived by Li and Ding (2020), who examined the combination of rerandomization and low-dimensional regression adjustment. However, as discussed by Li and Ding (2020), stratiﬁed rerandomization is preferred because it can enable a more transparent analysis and avoid the bias associated with searching for a speciﬁc outcome model in the analysis stage (Cox, 2007; Rosenbaum, 2010; Lin, 2013). Theorem 8. If the conditions associated with Theorem 3 and Conditions 7–8 hold, then in the stratiﬁed rerandomization scenario, ˆσ Moreover, ˆσ the stratiﬁed rerandomization scenario. In the stratiﬁed rerandomization case, the variance estimator ˆσ the unit-level treatment eﬀect is constant within each block. Generally, the estimator is conservative. According to Theorems 7 and 8, we can construct a 1 − α conﬁdence interval for τ : The asymptotic coverage rate of this conﬁdence interval is greater than or equal to 1−α, and its length is less than or equal to those based on the estimated asymptotic distributions of ˆτ Therefore, ˆτ unequal propensity scores. This section describes the simulation studies performed to examine the ﬁnite sample performance of the proposed methods. We set the sample size as n = 200 and 500. We consider three scenarios of blocking: many small blocks (MS, with n M = 20 or 50), a few large blocks (FL, with n blocks (MS+FL, with n the subscripts “S” and “L” denote small and large blocks, respectively). The potential outcomes are generated as where x with Σ the remaining elements are zero; and ε a mean of zero and variance of σ p = 400, s = 10, and ρ = 0.6. The potential outcomes and covariates are generated once and then kept ﬁxed. We consider six designs: complete randomization (block = no, rerand = no), rerandomization (block = no, rerand = yes), and stratiﬁed randomization/rerandomization Y(z) = (B/M)+ xβ(z) + ε is generated from a p-dimensional multivariate normal distribution N(0, Σ) = ρ; the ﬁrst s elements of β(z) are generated from the tdistribution, and with equal/unequal propensity scores (block = eq/uneq, rerand = no/yes). We set w as the ﬁrst k = 4 dimensions of xand p= 0.001 for rerandomization. The propensity scores e’s are equal to 0.5 or evenly spaced in value between 0.3 and 0.7. For each design, we consider the diﬀerence-in-means estimator (unadj) and two Lasso-adjusted estimators ˆτand ˆτfor equal/unequal propensity scores, respectively. We use the R package “glmnet” to ﬁt the solution path of the Lasso. We choose the tuning parameter in the Lasso via 10-fold cross-validation (the number of the selected covariates is set to be less than n/3). We replicate the randomization/rerandomization 1000 times to evaluate the repeated sampling properties. Figure 1 shows the distributions (violin plot) of diﬀerent estimators. All of the distributions are symmetric around the true value of the average treatment eﬀect. The distributions of the Lasso-adjusted estimators are more concentrated than those of the unadjusted estimators in both the randomization and rerandomization cases. Tables 1–3 present several summary statistics of diﬀerent estimators. First, for all designs, the absolute value of the bias of each estimator is considerably smaller than its standard deviation (sd). Second, compared with the unadjusted estimator without rerandomization, the Lasso-adjusted estimator reduces the standard deviation by 40%–67%. Third, the empirical coverage probabilities (cp) of all estimators reach the nominal level. Fourth, compared with the unadjusted estimator without rerandomization, the Lasso-adjusted estimator decreases the mean conﬁdence interval lengths (length) by 17%–73%. Finally, the Lasso-adjusted estimators in the stratiﬁed randomization and stratiﬁed rerandomization cases exhibit a comparable performance, as indicated by our theory. However, stratiﬁed rerandomization is preferable when a few important covariates needed to be balanced in the design stage. Thus, our ﬁnal recommendation is to implement stratiﬁed rerandomization in the design stage and use the Lasso-adjusted estimator in the analysis stage. We use two real data sets to illustrate the performance of the proposed methods. The ﬁrst data set pertains to a clinical trial that aimed at assessing the eﬃcacy and safety of panitumumab combined with cisplatin and ﬂuorouracil as ﬁrst-line treatment for patients with recurrent or metastatic squamous-cell carcinoma of the head and neck (SCCHN) (Vermorken et al., 2013). Patients are stratiﬁed into M = 8 blocks based on previous treatment, primary tumour site, and performance status. The patients in each block are randomly assigned to the treatment and control groups with equal probability (e= 1/2). The outcome of interest is the logarithm of the progression-free survival days (time from randomization to disease progression or death). There are 30 baseline covariates for each patient, such as demographic variables and physiological indicators. We consider adjusting for the main eﬀect, quadratic terms of the continuous covariates, and two-way interactions, resulting in a design matrix X with p = 464 columns (covariates) and n = 428 rows (observations). To evaluate the repeated sampling properties of diﬀerent estimators, we must determine all the potential outcomes. For illustration purposes, we generate a synthetic data set. We use the Lasso to ﬁt two sparse linear models for the treatment and control groups, respectively, and impute the potential outcomes by Fig. 1. Distributions of the average treatment effect estimators minus the true value of the average treatment effect in six cases. Table 1. Performance of different estimators in the scenario of many small blocks. Table 2. Performance of different estimators in the scenario of a few large blocks. Block indicates whether stratiﬁcation is performed and whether the propensity scores of the blocks are equal; rerand indicates whether rerandomization is performed; bias indicates the absolute bias; sd is the standard deviation; sd% is the percentage decrease in the standard deviation relative to that for the unadjusted estimator without rerandomization; rmse is the root-mean-squared error; cp is the empirical coverage probability; length is the mean conﬁdence interval length; le% is the percentage decrease in the conﬁdence interval length relative to that associated with the unadjusted estimator without rerandomisation. The numbers in brackets are the corresponding standard errors estimated using the bootstrap with 500 replications. Bias, sd, rmse, cp, length, and their standard errors are multiplied by 100. Table 3. Performance of different estimators in the scenario of hybrid blocks. using the ﬁtted models. We use the same blocking and propensity scores for each block as those in the original experiment and implement either stratiﬁed randomization or stratiﬁed rerandomization in the design stage. For rerandomization, we use the following covariates: age, sex, red blood cells, and white blood cells. The second data set pertains to the “Opportunity Knocks” (OK) randomized experiment aimed at evaluating the eﬀect of academic achievement awards on the academic performance of college students (Angrist et al., 2014). We focus on second-year college students. Based on the sex and discretized high school grades, the students are stratiﬁed into M = 8 blocks with sizes ranging from 42 to 90. In each block, only about 20 students are assigned to the treatment group (receiving incentives), and thus, the propensity scores are signiﬁcantly diﬀerent across blocks. We consider the average grades at the end of the year as the outcome. There are 23 baseline covariates, such as demographic variables and grade point average (GPA) in the previous year. We consider adjusting for the main eﬀect, quadratic terms of the continuous covariates, and two-way interactions. The design matrix X has p = 253 columns (covariates) and n = 506 rows (observations). To evaluate the repeated sampling properties of diﬀerent estimators, which depend on all of the potential outcomes, we match the treated units to the control units by using the 23 baseline covariates (Sekhon et al., 2011) to impute the unobserved potential outcomes. We use the same blocking and propensity scores for each block as those in the original experiment and implement either stratiﬁed randomization or stratiﬁed rerandomization in the design stage. For the rerandomization, we use the following covariates: age, high school grades, and GPA of the previous year. For both data sets, we replicate the stratiﬁed randomization/rerandomization 1000 times to evaluate the repeated sampling properties of diﬀerent estimators. Figure 2 and Table 4 show the results. Rerandomization is the preferable strategy, and the Lasso-adjusted estimator is superior to the unadjusted estimator. These conclusions are similar to those derived in the simulation studies. This study is aimed at enhancing the estimation and inference eﬃciencies of the average treatment eﬀect in randomized experiments when many baseline covariates are available. We propose novel methods to combine blocking, rerandomization, and regression adjustment using the Lasso. Under mild conditions, we obtain the asymptotic distributions of the Lasso-adjusted average treatment eﬀect estimators when blocking or rerandomization or both are implemented in the design stage. We demonstrate that the proposed Lasso-adjusted estimators enhance, or, at least, do not deteriorate the precision compared with that associated with the unadjusted estimator. Our results are randomization-based, allowing the outcome data generating model to be mis-speciﬁed. In addition, we deﬁne Neyman-type conservative variance estimators to construct asymptotically conservative conﬁdence intervals or tests for the average treatment eﬀect. Our ﬁnal recommendation is to use blocking and rerandomization in the design stage to balance a subset of covariates that are most relevant to the potential outcomes and then implement regression adjustment using the Lasso in the analysis stage to adjust for the remaining covariate imbalances. Similar to the ﬁndings reported by Li and Ding (2020), Fig. 2. Distributions of the average treatment effect estimators minus the true value of the average treatment effect for two real data sets. Table 4. Performance of different estimators for two real data sets: SCCHN and OK. yes yes Rerand indicates whether rerandomization is performed; bias indicates the absolute bias; sd is the standard deviation; sd% is the percentage decrease in the standard deviation relative to the unadjusted estimator without rerandomization; rmse is the root-mean-squared error; cp is the empirical coverage probability; length is the mean conﬁdence interval length; le% is the percentage decrease in the length relative to the unadjusted estimator without rerandomization. The numbers in brackets are the corresponding standard errors estimated using the bootstrap with 500 replications. Bias, sd, rmse, cp, length, and their standard errors are multiplied by 100. when rerandomization or the combination of blocking and rerandomization is used in the design stage, the Lasso should consider all of the covariates used in the rerandomization to ensure eﬃciency gains. To render the theory and methods more intuitive, we focus on inferring the average treatment eﬀect for a binary treatment. Our analysis can be generalized to multiple value treatments, including factorial experiments as particular cases (Fisher, 1935; Yates, 1937; Dasgupta et al., 2015; Li et al., 2020). Moreover, it may be interesting to extend our results to other complicated settings, for example, binary outcomes based on penalized logistic regression (Freedman, 2008b; Zhang et al., 2008; Moore and van der Lann, 2009), regression adjustment using the Lasso in the event of noncompliance (Imbens and Angrist, 1994; Angrist and Imbens, 1995; Angrist et al., 1996), and the use of other machine learning methods such as random forest (Wager et al., 2016; Wu and Gagnon-Bartsch, 2018) in the analysis stage. A limitation of our analysis is that the proposed Lasso-adjusted point and variance estimators require each block to have at least two treated and two control units. Thus, our results do not cover the case of randomized block experiments in which certain blocks are “small” in the sense that they consist of only one treated or one control unit (Pashley and Miratrix, 2020). The matched-pair design (Imai, 2008; Fogarty, 2018b) and ﬁnely stratiﬁed randomized experiments (Fogarty, 2018a) are special cases of this setting. It may be worth investigating methods to generalize the regression-adjusted estimators proposed by Fogarty (2018b) and Fogarty (2018a) to high-dimensional settings and use the variance estimator proposed by Pashley and Miratrix (2020) to handle such small blocks. The second author was supported by the National Natural Science Foundation of China (Grant No. 12071242). The third author was supported by the National Natural Science Foundation of China (Grant No. 12001557); the Youth Talent Development Support Program (QYP202104), the Emerging Interdisciplinary Project, the Disciplinary Funding, and the School of Statistics and Mathematics in Central University of Finance and Economics.