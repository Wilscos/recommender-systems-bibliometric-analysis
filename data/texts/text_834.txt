With the development of emerging computing areas such as cloud computing, big data, and Internet of Things, the Web-based services available on the Internet have increased rapidly in both quantity and type [3]. Following [1], software service is speciﬁcally deﬁned as services which contain code under open-source licenses for others to use and modify freely, such as open-source projects or repositories on social coding sites (e.g., GitHub can build their Web services, applications, or even scientiﬁc experiment systems quickly by exploiting functional code modules in massive software services [13]. Please cite the paper as the following: Zhang, M., Liu, J., Zhang, W., Deng, K., Dong, H., Liu, Y.: CSSR: A Context-Aware Sequential Software Service Recommendation Model. The 19th International Conference on Service Oriented Computing (ICSOC 2021), 2021. https://doi.org/10.1007/978-3-030-91431-8_45. https://github.com/ https://bitbucket.org/ https://sourceforge.net/ {zhangmw,liuy}@swc.neu.edu.cn, {2071295,1871164}@stu.neu.edu.cn School of Computing Technologies, RMIT University, Melbourne, Australia Abstract. We propose a novel software service recommendation model to help users ﬁnd their suitable repositories in GitHub. Our model ﬁrst designs a novel context-induced repository graph embedding method to leverage rich contextual information of repositories to alleviate the diﬃculties caused by the data sparsity issue. It then leverages sequence information of user-repository interactions for the ﬁrst time in the software service recommendation ﬁeld. Speciﬁcally, a deep-learning based sequential recommendation technique is adopted to capture the dynamics of user preferences. Comprehensive experiments have been conducted on a large dataset collected from GitHub against a list of existing methods. The results illustrate the superiority of our method in various aspects. Keywords: Recommender System · Service Recommendation · Sequential Recommendation · Software Services · GitHub Repository As a representative software service hosting platform, GitHub is widely known to developers from all over the world, who ﬁnd it easier and quicker to build up their complex applications from particular repositories. As of January 2020, GitHub reports having over 40 million users and more than 100 million repositories [4], making it the largest host of software services in the world. The large number of repositories has undoubtedly increased the diﬃculty of selecting the most suitable ones to fulﬁll users’ application development. Therefore, software service recommendation has become of practical importance [21]. McMillan et al. [9] designed a tool named CLAN to help users detect similar applications. It used latent semantic indexing to measure the similarity of repositories relative to API usage. However, it is limited to Java applications and small-scale data. LRMF[6] is a pairwise regularization framework for GitHub open source repository recommendation based on matrix factorization, focusing mainly on exploiting user language preference. PNCF [1] is the state-of-the-art repository recommender model, which combined deep learning with collaborative ﬁltering to enhance recommendation eﬀectiveness, and also focused on language preference. The above methods proposed eﬀective strategies to make software service recommendation. However, they suﬀer from the following two common issues. First, the well-known data sparsity problem is not addressed. Although the number of users and repositories on GitHub can be very large, the interactions between users and repositories are highly sparse, i.e., most users typically interact with a few repositories. Second, user preferences may exhibit dynamic characteristics. For instance, users’ preferences may drift over time due to the continuous evolution of software technology and the inﬂuence of other users. To address the two aforementioned issues, a novel recommendation model named CSSR (Context-aware Sequential Software Service Recommendation) is proposed in this paper with two unique traits. Firstly, there is a consensus that contextual data can be utilized as complementary information to alleviate the data sparsity issue in general recommender systems [18]. Each original repository on GitHub has rich contexts as depicted in Fig. 1. We leverage more comprehensive contextual information of repositories (i.e., topics, general description, README ) compared with the state-of-the-art recommendation methods [1,6]. It can model the similarity between repositories more precisely to make better recommendation when the interaction data is sparse. Secondly, users on GitHub interact with repositories in a chronological order as depicted in Fig. 1. The temporal information of user interaction behaviors can help to model users’ dynamic interests. For example, it is reasonable to assume that a user is most likely to access the repositories which are relevant to the repositories the user has interacted with recently. Therefore, we adopt sequential user-repository interactions to capture the dynamics of user preferences. More speciﬁcally, CSSR ﬁrst explores contextual information to construct a repository graph upon which the latent vector of each repository can be derived through the graph embedding. Then, the repository sequences of users are fed into a GRU model, where the latent vector of each repository is applied, to identify the appropriate repositories and recommend them to users. We have conducted comprehensive experiments to compare CSSR with the state-of-the-art methods on a large real-world dataset crawled from GitHub least 16.16%, 22.05% and 11.35% improvements over the best baseline in terms of Hit Rate, Mean Reciprocal Rank and Normalized Discounted Cumulative Gain respectively, and the performance boost is more signiﬁcant in the situation of high level of data sparsity. Our contributions are summarized as follows: – This study proposes a context-aware sequential software service recommen- – We design a repository graph construction method. It takes full advantages – This study, to the best of our knowledge, is the ﬁrst work that explores The rest of paper is organized as follows: Sect.2 introduces the related work; Sect.3 formulates the software service recommendation problem; Sect.4 presents the CSSR model; Sect.5 is the experiments and result analysis, and Sect.6 is the conclusion. In this section, we will brieﬂy review several lines of works closely related to ours, including sequential recommendation, service recommendation and software service recommendation. The dataset and source code are released on https://github.com/JiaYuan6/CSSR. dation model (CSSR) to improve software service recommendation by mitigating the diﬃculties caused by data sparsity and the dynamic characteristics of user preferences. of the context characteristics of repositories on GitHub, upon which the recommendation performance can be improved. the sequential interactions in software service recommendation to model the dynamics of user preferences. Sequential Recommendation. The technology of recommender systems continues to develop. This results from their signiﬁcant role in helping users alleviate the problem of information explosion and select interesting contents in many Web application domains. Meanwhile, many recommendation techniques have been designed, including collaborative ﬁltering[12], matrix factorization[10], factorization machine[7], and deep-learning-based methods[18]. Sequential recommendation is a critical research topic of recommender systems, and has been extensively studied over years. It views the interactions as a sequence in a time order and aims to predict the successive items that a user is likely to interact with in the near future. Traditional methods [11] utilized Markov Chains to capture item-item transitions for sequential recommendation. Recently, deepsequential-neural-model-based methods [5,14] have shown much superior performance. They utilized diﬀerent sequential neural networks (e.g., RNNs, Transformers) to address concrete issues from diﬀerent aspects and domains. Aiming at validating the eﬀectiveness of sequential recommendation in software service domain, we adopt the classic sequential neural model GRU [2] fusing with graph embedding techniques to solve next repository recommendation issue. Service Recommendation. Lots of research works have been done on service recommendation in recent years. They can be mainly classiﬁed into two categories, i.e., QoS-based service recommendation[8] and functionality-based service recommendation[20,19,17]. However, QoS-based service recommendation approaches cannot help developers ﬁnd an unknown but interesting service, limited by their objective. Functionality-based service recommendation approaches focus on ﬁnding the services that meet the functional requirements the best. Among them, the semantic-based approaches[20] aim at ﬁnding services with the highest matching degree via semantic similarity computation. The socialnetwork-based approaches[19] tend to apply user interest, social relationship and link prediction. The information-network-based approaches[17] mainly employ diﬀerent kinds of information and multiple semantic meanings of meta paths to recommend services. In this paper, we focus on recommender systems for a special kind of Web-based services, i.e., software services. Software Service Recommendation. Software services are the services with a focus on providing various code resources to facilitate software development. GitHub is the largest software service providers. It opens access to the information of repository, users, and the interactions between them. This attracts much interest of researchers, and currently most studies in software service recommendation are for GitHub repositories. Jiang et al. [6] proposed a repository recommendation model based on matrix factorization. Chen et al. [1] combined deep learning with collaborative ﬁltering to do repository recommendation. The above two methods both concentrated on exploiting user language preference. Sun et al.[15] proposed an approach to recommend repositories considering both user behaviors and repository features. Shao et al.[13] designed a novel crossplatform recommender system, paper2repo. It recommended relevant repositories on GitHub that match a given paper, by integrating text encoding and constrained graph convolutional networks. In summary, the study in software service recommendation is still in its early stage. None of the existing studies pay attention to making performance analysis in diﬀerent sparsity levels and addressing the really severe data sparsity issue, together with the problem of dynamic characteristics of user preferences. This paper aims to ﬁll the research gap. Each user has interacted with a sequence of repositories ordered by time on GitHub. The repositories may be created by a user directly or forked from other users, as illustrated in Fig. 1. Each repository has contextual information. Let U = {u itories, with |U| and |R| being the sizes, respectively. Each user u can be associated with a sequence of repositories R action records in a chronological order, where r user u interacted with at time step t. R from interaction r each user based on the recent repository subsequence of length L the user interacted with, where L is a hyperparameter. For each user u at time step t, we will have a training data record where the features are R r. For all users from t = 1 to t research problem investigated in this study is to (1) represent user preferences and repositories, and (2) develop a prediction model to identify and recommend the preferable repositories to users. The objective is to optimize the performance by addressing the data sparsity issue and the dynamics of user preferences along with time. As illustrated in Fig. 2, the proposed model named CSSR (Context-aware Sequential Software Service Recommendation) consists of three steps: (1) constructing a repository graph by leveraging contextual information of repositories; (2) feeding the constructed graph into a graph autoencoder to derive embedding of each repository, which is fused with other features to form ﬁnal repository latent vectors; (3) predicting the probability that each repository will be preferred by each user using a GRU model. These steps are detailed respectively in the following subsections. First, a repository graph is constructed where the text-based contextual information is exploited. On GitHub, developers usually tag their repositories with − 1 is greater than L), we will obtain a training data set. Based on it, the topics using words or phrases. The topics are suggested by a topic extraction framework, called repo-topix, which was developed by GitHub considering many engineering problems. We utilize the topics tagged by users with the suggestion of repo-topix directly rather than extracting the similar information using topic modeling like in existing studies. However, some repositories may not be tagged with such information explicitly or tagged incompletely. We then, for each repository, exploit its general description and README to derive and complete its topics by techniques such as keyword matching against the explicitly-tagged topics. In addition, the programming language of a repository can also be used as a special kind of topic-like information. This is because users are more likely to ﬁnd source codes with languages they have used before. Let T = {t Each repository r has a repository topic vector RT = {rt tion, README ); otherwise rt Given any two repositories r The similarity ranges from 0 (meaning that two repositories don’t have any same topic) to 1 (meaning two repositories have the exactly same set of topics). We further deﬁne a hyperparameter in our model, i.e., the edge keeping threshold ε ∈ (0, 1), which is used to help generate an eﬀectual and simple graph. With the threshold, the similarity between r = 1 if r has t(either directly tagged by developers or derived from descrip- = {rt, rt, ..., rt} are their corresponding repository topic vectors. as follows: After calculating the similarity of any two repositories, we can get a similarity matrix S = {s represent each repository r as a vertex v and there is a link between two vertices v than 0. By this way, we obtain a homogeneous graph where the contextual similarity between repositories has been captured. The graph is called contextinduced repository graph. For nodes in a graph, graph embedding automates the process of extracting lowdimensional node feature vectors. It has been proved very useful in many downstream tasks, such as classiﬁcation, link prediction and recommendation. Various graph embedding models have been proposed. For embedding the contextinduced repository graph G, we adopt Structural Deep Network Embedding model (SDNE) [16], a representative embedding model for homogeneous graphs. As illustrated in Fig. 3, a multi-layer autoencoder is extended to capture the non-linear structure of G. The ﬁrst-order proximity characterizes the local graph structure (i.e., the direct links between repositories in G). The second-order proximity characterizes the global graph structure (i.e., the co-neighbor relations between repositories in G). They are jointly exploited in the embedding process. Given the similarity matrix S = {s (1 ≤ r ≤ |R|) into an autoencoder. The input s vertex v encoder are shown as follows. where S = {s den representations; W respectively. K denotes the number of encoder layers. (i.e., repository r). The hidden representations for each layer in the Given the input data s and then obtain the reconstructed data of encoder (i.e., decoder). The ﬁrst-order proximity describes the pairwise proximity between vertices. Intuitively, it implies that two vertices in real-world graphs are always similar if they are linked by an observed edge. Recall the construction of the contextinduced repository graph G in Sect. 4.1, two repositories are certainly similar if they are linked by an observed edge in G. The ﬁrst-order proximity cost function for local structure preserving is applied on the output layer of the encoder and deﬁned as follows. where s computed by Eq. (2). The second-order proximity exploits the similarity of the vertices’ neighborhood structures to capture the global graph structure. Intuitively, it assumes that if two vertices share many common neighbors, they tend to be similar. The second-order proximity cost function for global structure preserving is applied on the output layer of the decoder. It is shown as follows. where  means Hadamard product; s input of encoder and the output of decoder for vertex v penalty to the reconstruction error of the non-zero elements than that of zero elements. For s cost function L similar low-dimensional feature vectors. We combine Eq. (4) and Eq. (5) and jointly minimize the following objective function to preserve the ﬁrst-order and second-order proximity simultaneously: We use the stochastic gradient descent algorithm to train the model. Through the trained model, each repository r ∈ R can obtain its initial embedding y The sequential repository recommendation component in the framework of CSSR is illustrated in Fig. 4. Recall, in a training data record, the features are R is the similarity between any pair of vertices vand vin G, which is , where dis the size of graph embeddings. and the label is r · · · , r of L GRU (Gated Recurrent Unit)[2] blocks as shown in Fig. 4. The input of GRU block t − i (1 ≤ i ≤ L) is a nonlinear transformed vector combined feature vector of repository r vector is derived from graph embeddings as discussed in Sect. 4.2. It is coupled with a list of other repository features relevant to repository recommendation. The output of the last GRU block is the inferred repository ˆy compared against the ground truth (i.e., r and the GRU parameters will be learned. Next, we introduce the sequential repository recommendation modeling in more details. Fusing Multimodal Features for Repositories. For each repository r R(1 ≤ i ≤ |R|), we concatenate the features derived from context-induced graph embedding with other important features (i.e., the number of watches, stars and forks) to obtain its ﬁnal representation. Note that these features have diﬀerent numerical ranges. We adopt min-max scaling to normalize them into a real number between 0 and 1, and concatenate them with the graph embedding vectors. By this way, each repository r Fig. 4 can get its ﬁnal representation (denoted as r where d Generating User Representation. Next, we present how to derive the latent vector of user u at time step t via the GRU model based on repositories u interacted with before t. . Correspondingly, the sequential recommendation component consists is the dimensionality of initial repository embeddings. Recall R size L interacted with u just before time step t. The user representation can be computed iteratively as follows. where W dis the dimensionality of user embeddings. σ(·) is a logistic sigmoid function to do non-linear projection.  is the Hadamard product between two vectors. z and r mation ﬂows through the sequence. u the representation of the user u at time step i. It is dynamic and can remember past states. r at time step i. the i-th GRU block. Note that the dimensionalities of u (i.e., d simplicity, we use u Recommending and Model Training. We then illustrate how to recommend repositories for u at t. Given a user u with a sequence of visited repositories Then, the rating score of each candidate repository r u is computed as follows. where ˆy at time step t. Finally, we train the GRU model by minimizing the following objective function. where T set of user u at time step t. We adopt the negative sampling strategy to train the model. T t and the randomly-sampled 10 negative repositories corresponding to r denotes the ground truth. If repository r learnable parameters. ∈ R, W, W, W∈ Rare learnable parameters, and denote update gate and reset gate respectively. They control how infor- ) for the convenience of prediction, and u=~0 when initializing. For , the embedding uof user u at time step t can be computed by Eq. (7). denotes the recommendation probability of repository rto user u denotes the training dataset of user u, and T⊂ R denotes the training is an L2-norm regularizer to prevent overﬁtting, and θ is the set of all In this section, we conduct experiments to validate the eﬀectiveness of the proposed model in capturing dynamics of user preferences and addressing data sparsity issue. We also analyze how the key hyperparameters aﬀect the performance. We evaluate the proposed method on a large dataset crawled from GitHub. We use GitHub REST API to create calls to obtain the data in JSON format and store them in MongoDB. A user is considered to prefer a repository if the user forked it. This means the user produced a personal copy of someone else’s repository so that she can contribute to it or use it as the starting point for her own. All the repositories that a user created or forked are listed in her Web page in a chronological order. We randomly select users who forked more than 5 repositories. For each selected user, we crawl the information of all her forked repositories (e.g. topics, programming languages, README ). Such information is used to construct context-induced repository graph. We eliminate repositories forked by fewer than 5 users. There are 2,616 users, 3,126 repositories, and 21,924 interactions in the dataset after preprocessing. The data sparsity is 0.268%. To capture dynamics of user preferences, we also try to consider temporal information of user-repository interactions (e.g., the absolute time span, the relative time interval, the relative temporal position interval) in our model. However, the experimental results don’t show performance improvement. Thus, CSSR just utilizes the sequential interactions to make repository recommendation as described above. Next, we compare CSSR against the following baseline methods. – Pop simply recommends top ranked repositories based on popularity in – Item-KNN [12] recommends a user the repositories similar to the previously – BPR [10] is a classic method for non-sequential recommendation, which – FFM [7] is the representative recommendation model based on factorization – GRU4Rec [5] is a representative sequential recommendation model, which training data. forked repositories by the user based on cosine similarity. optimizes a Matrix Factorization model using a pairwise ranking loss. machine. It groups features into ﬁelds, and learns the interactions between users and repositories to complete the user-repository implicit rating matrix. also utilizes GRU to model user action sequences. We feed randomly-generated repository embeddings into GRU blocks, and obtain the best performance by using Xavier initializer against other random number generators. – PNCF [1] is the state-of-the-art GitHub repository recommendation method For constructing the context-induced repository graph, we conduct stemming and lemmatization on all topics tagged by users with the help of repo-topix, and extract 4,015 topics. Then, for each repository, we conduct tokenization, stop words removing, stemming, lemmatization, typo corrections, and string matching on its textual contexts to complete its topics as introduced in Sect. 4.1. RE, NLTK and Spacy packages of Python are used for these tasks. Next, we compute the cosine similarity between each pair of repositories by using Numpy package and save the constructed graph into a ﬁle by using Pandas package. The edge keeping threshold ε is set to 0.3, which can generate a reasonable number of edges. The ﬁnal constructed graph contains 3,126 repositories with 168,039 edges between them. For each user, we hold the ﬁrst 80% of interactions as the training set. We then use the next 10% of interactions as the validation set for hyperparameter tuning. The latest 10% constitute the test set for reporting model performance. We conduct experiments with each model for ﬁve times independently, and report the average results. The hyperparameters are learned from the validation dataset and set as follows. The size of initial repository embedding is 140. The size of user embedding is 64. L = 4 means that the recent 4 interacted repositories are considered to infer recommendations. The learning rate is 0.009. The maximum number of epoch is 100 during the model training. All the experimental results of our model are achieved by using the above hyperparameter conﬁguration settings if no speciﬁc situations are provided. The optimal hyperparameters of each baseline method are set based on the experiment reports of the relevant research papers. We implement our CSSR model in Tensorﬂow. We adopt three commonly-used metrics to evaluate the recommendation performance, i.e., Hit Rate (HR@N ), Mean Reciprocal Rank (MRR@N ) and Normalized Discounted Cumulative Gain (NDCG@N ) where N indicates top-N ranked repositories. In general, HR@N doesn’t care about rank position in the recommendation list, MRR@N considers only the position of the ﬁrst matched recommendation, and NDCG@N is a full position-aware metric which assigns greater weights on higher positions. They reﬂect diﬀerent aspects of recommendation quality. The higher values indicate the better repository recommendation quality for all the three metrics. The experimental results of of CSSR and all the baselines are reported in Table 1. We have the following observations. (1) In most cases, the state-of-the-art baseby building a preference-based neural collaborative ﬁltering recommender model. We feed the model not only with the language features in the original paper but also all our utilized topic features to make it fair. Table 1. The performance comparison (The method with the best performance is starred and the method with the second-best performance is boldfaced; columns “KNN” and “GRU” denote the baseline “Item-KNN” and “GRU4Rec” respectively; column “Improv.” denotes the improvement ratio of CSSR relative to the best baseline). Ratio (Sparsity) ALL (0.096%) Half (0.182%) (0.268%) line PNCF achieves the best performance than the other baseline methods. (2) The proposed CSSR consistently achieves better performance on all the metrics at diﬀerent N values compared with all the baselines by at least 10%. Speciﬁcally, it improves the performance slightly more on the metric MRR than on HR and NDCG. It achieves slightly more performance improvement when N = 10 than other N values. (3) All the baselines except GRU4Rec are sequential-information free models. However, GRU4Rec doesn’t outperform the other baselines by just using randomly-initialized repository embeddings. Compared with GRU4Rec, the signiﬁcant improvement of CSSR validates the importance of the contextinduced repository graph embedding component in our model. NDCG (%) 0.886 1.923 2.003 1.746 1.712 2.079 2.497* 20.11% NDCG (%) 1.151 2.599 2.519 2.136 2.099 2.629 3.206* 21.95% NDCG (%) 1.803 3.064 2.915 2.499 2.501 2.935 3.523* 14.98% NDCG (%) 2.032 3.444 3.194 2.712 2.685 3.206 3.835* 11.35% Table 2. The performance comparison at diﬀerent sparsity levels. NDCG (%) 1.103 0.543 1.085 1.116 0.989 1.119 1.881* 68.09% NDCG (%) 1.350 1.538 1.893 1.429 1.853 2.004 2.487* 24.10% NDCG (%) 1.151 2.599 2.519 2.136 2.099 2.629 3.206* 21.95% Fig. 5. The sensitivity of CSSR performance to hyperparameters (a) repository embedding size; (b) user embedding size; (c) sequence length (L). We compare CSSR and all the baselines at diﬀerent levels of data sparsity. The aim is to evaluate the solution applied in CSSR for mitigating the issue of sparse data. Since each user has at least 3 repositories and a repository has at least one user, we delete at most 14,081 interactions in our dataset to simulate diﬀerent settings of sparsity. Table 2 shows the performance of all the methods at three levels of sparsity, i.e., deleting all/half of/none of the 14081 interactions respectively. We set N =10, and adopt all repositories in the training set that a user has interacted with to train the model in the ﬁrst two sparsity levels, i.e., the repository sequence length L is not ﬁxed. From Table 2, we have the following observations. (1) The performance of all the methods gets worse and worse when the data sparsity changes from 0.268% to 0.182% and then to 0.096%. (2) Compared with all the baselines except Pop, the impact of data sparsity on CSSR is much weaker. CSSR can have much more stable performance than the other methods except Pop, and achieve more signiﬁcant improvements against the best baseline in the sparser data set. (3) Although the impact of data sparsity on Pop is weaker than CSSR, the performance of Pop is very poor among baselines. In short, our model achieves the best performance and demonstrates robustness in the situation of data sparsity. The size of initial repository embeddings, the size of user embeddings, and the sequence length L are the three important hyperparameters in our model. In this study, we further investigate the impact of the three hyperparameters on the recommendation performance. We set N =10. Fig. 5 (a) illustrates the eﬀect of the initial repository embedding size (i.e., the size of graph embeddings). We can see that our CSSR would achieve the best performance when the graph embedding size is 140. Fig. 5 (b) illustrates the eﬀect of the user embedding size (i.e., the size of hidden state in the GRU model). We can see that CSSR would achieve the best performance when the user embedding size is 32 or 64. Fig. 5 (c) illustrates the eﬀect of the sequence length L. We can see that CSSR would achieve the best performance when it equals 4. This paper presented a context-aware sequential software service recommendation model—CSSR. It can recommend repositories on GitHub matching users’ interests. CSSR is a joint model that incorporates a graph embedding technique into a GRU formulation to generate latent vectors of users and repositories. Speciﬁcally, graph embedding technique is leveraged to exploit rich repository contextual information to alleviate the data sparsity problem. The context-aware latent vectors of repositories are then fed into a GRU model, which captures the dynamics of user preference and eventually recommend repositories to users. The results of extensive experiments show that our method can signiﬁcantly outperform the existing state-of-the-art repository recommender models in various aspects. Acknowledgements. This work is partially supported by Australian Research Council Linkage Project (No.LP180100750) and Discovery Project (No.DP210100743).