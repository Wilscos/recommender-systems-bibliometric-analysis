Fig. 1. (A) and (B) are comparisons between static probabilistic networks and sampled network realizations from a random graph model deﬁned by probabilistically weighted edges. Both (A) and (B) consist of 21 vertices with corresponding density values of 0.9 and 0.5. Abstract— Probabilistic graphs are challenging to visualize using the traditional node-link diagram. Encoding edge probability using visual variables like width or fuzziness makes it difﬁcult for users of static network visualizations to estimate network statistics like densities, isolates, path lengths, or clustering under uncertainty. We introduce Network Hypothetical Outcome Plots (NetHOPs), a visualization technique that animates a sequence of network realizations sampled from a network distribution deﬁned by probabilistic edges. NetHOPs employ an aggregation and anchoring algorithm used in dynamic and longitudinal graph drawing to parameterize layout stability for uncertainty estimation. We present a community matching algorithm to enable visualizing the uncertainty of cluster membership and community occurrence. We describe the results of a study in which 51 network experts used NetHOPs to complete a set of common visual analysis tasks and reported how they perceived network structures and properties subject to uncertainty. Participants’ estimates fell, on average, within 11% of the ground truth statistics, suggesting NetHOPs can be a reasonable approach for enabling network analysts to reason about multiple properties under uncertainty. Participants appeared to articulate the distribution of network statistics slightly more accurately when they could manipulate the layout anchoring and the animation speed. Based on these ﬁndings, we synthesize design recommendations for developing and using animated visualizations for probabilistic networks. Network data are prone to uncertainty. It is often unclear whether all relevant entities are included in a graph and if observed interactions are representative or occur merely by chance (e.g., [45, 92]). For example, social network data are frequently collected through surveys, but it is well-known in the Social Network Analysis (SNA) community that network surveys are problematic due to selection bias, response bias, and missing responses (e.g., [5, 90]). While technological affordances of online platforms reduce data uncertainty by making user interactions visible and persistent [27, 53, 54], uncertainty remains an issue when analysts binarize or predict social relations through statistical models based on the frequency of communication (e.g., [1]). Uncertainty in the network analysis pipeline is sometimes addressed by imposing probabilities on edges as weights, resulting in a probabilistic graph. Although edge uncertainty can be visualized in a nodelink diagram through visual encodings such as width, fuzziness, or grain [31,58], the rendered graph is typically difﬁcult to visually assess • Dongping Zhang is with Northwestern University. E-mail: dzhang@u.northwestern.edu. • Eytan Adar is with the University of Michigan. E-mail: eadar@umich.edu. • Jessica Hullman is with Northwestern University. E-mail: jhullman@northwestern.edu. Manuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication xx xxx. 201x; date of current version xx xxx. 201x. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org. Digital Object Identiﬁer: xx.xxxx/TVCG.201x.xxxxxxx for practical use. For example, an analyst will likely ﬁnd it challenging to respond to common graph analysis tasks, such as, “What is the most likely shortest path length between node 16 and node 9?”, or “What is the expected density?” using either of the static visualizations shown in Fig. 1. In such cases, analysts must rely on a hard-to-decode visual channel not only to gain probability information about any single edge, which might be difﬁcult to see due to the high density of a probabilistic graph (i.e., showing all edges with non-zero weights), but also to simultaneously integrate and process the joint probability from multiple edges for certain statistics (e.g., path lengths, isolates, and densities). Similarly, although there are algorithms to identify clusters for static weighted networks (e.g., [55]), the uncertainty of community occurrence or cluster membership is difﬁcult to visualize in a static diagram because traditional encodings (e.g., node coloring or convex hulls) are used to show deterministic community membership. These reasons may contribute to the relative lack of techniques available for visualizing probabilistic graphs to support exploratory network analysis. To provide a solution, we introduce Network Hypothetical Outcome Plots (NetHOPs), a frequency-based uncertainty visualization technique that applies animated hypothetical outcomes [39] to probabilistic graphs. NetHOPs dynamically visualize a set of realizations sampled from a network distribution deﬁned by probabilistic edges. By showing independent possible realizations of a network, NetHOPs avoid the challenges of supporting judgments about network properties under uncertainty with static encodings. Instead, structures and properties can be estimated by attending to the temporal frequency of occurrence from a set of independent but equally representative realizations. A challenge arises when presenting network uncertainty as a se- quence of node-link diagrams: graph layout algorithms are intentionallyalternating path) can be summarized by network statistics or distribuoptimized based on a static network. This induces a trade-off betweentions [57], analysts typically begin the analysis by examining structural more optimal visualization of each sampled realization and analysts’dependencies and correlations from a comprehensive overview of the ability to preserve their mental maps [61] of how vertices and edgesgraph, which visualizations can help to provide. relate across realizations. NetHOPs address this trade-off using an ofﬂine graph drawing approach and applying an aggregation and an-outs [17], stress minimization [10, 25], and the stochastic gradient choring algorithm [8] to enable analysts to control layout stability anddescent approach [93] can help to achieve aesthetic goals like minimizreadability [11]. To address the challenges associated with visualizinging edge crossing or overlapping nodes to support low-level visual tasks community membership under uncertainty, NetHOPs employ commu-such as tracing each edge from source to target and seeing clusters [83]. nity detection algorithms designed for static unweighted networks, for which we develop a community matching and coloring algorithm.namic and longitudinal graphs [13], where each frame in the animation To demonstrate the use of NetHOPs in a realistic analysis settingrepresents the graph at different states. It is possible but often impractiand explore how well the technique supports uncertainty perceptioncal to show all graphs in a static visualization (e.g., small multiples [3]) on networks, we contribute a user study in which 51 network expertsdue to large numbers of graphs. When designing network animations, it used NetHOPs to complete a set of common visual analysis tasks,is insufﬁcient to apply a layout algorithm to each state in a time-varying chosen based on network task taxonomies [2,52]. The experts providedgraph because the dynamic layout algorithm can produce inconsistent probability estimates and used distribution builders [82] to sketch theirresults when repeatedly applied to the same network data. Instead, perceptions of uncertainty in network properties (e.g., density, shortestlayouts must be carefully engineered to help analysts preserve their path, clusters). We ﬁnd that NetHOPs allowed experts to visually assessmental maps of how the nodes and edges change over time [61,69, 79]. the distributions of network structures fairly accurately: responses were within 11% of the ground truth distributions (deﬁned on the full set ofcategorized into ofﬂine computation based on the whole sequence visualized realizations) across tasks. When participants were instructedof graphs [9] and an online approach [8] that computes the graph layout to adjust NetHOP parameters like the amount of layout stability, theone transition at a time [24,66]. Layout stability can be addressed by animation speed, and other visual properties, we see some evidenceanchoring vertices to ﬁxed positions while animating edges [62] or by of a small (7%) additional average improvement in performance. Weconnecting vertices from different instances with external edges, which present an exploratory analysis of our results that we use to reﬂectis conceptually similar to parallel-coordinates [15, 16, 18]. on how different visual network estimation tasks under uncertainty can be best supported. Based on our ﬁndings, we synthesize designplied in NetHOPs also requires addressing layout stability. However, recommendations for future development of NetHOPs and similarinstead of helping an analyst detect graph evolution over time, the goal techniques as a solution to address network uncertainty.of layout stability when animating a probabilistic graph is to facilitate 2 BACKGROUNDthese entities of interest recognizable from frame to frame. NetHOPs’ 2.1 Uncertainty Visualizationlayout computation is based on the aggregation and anchoring approach,developed by Brandes et al. [8], which is an instance of the ofﬂine draw- Prior work demonstrates that people can make better decisions whening scenario where stress minimization is used to compute a reference uncertainty is effectively represented [19,43,44,63], which makes uncer-layout based on all graphs in the sequence. tainty communication an important practice for scientiﬁc research [84]. Empirical evidence suggests that framing probabilities as frequencies2.3 Visualizing Probabilistic Graphs (e.g., 3/10 rather than 30%) can make them easier to reason with [28,34].Probabilistic networks have a ﬁxed vertex set with immutable vertex Among other frequency-based uncertainty visualization techniquesattributes. Edges are weighted, and weights are typically the probability (e.g., [20, 26, 48]), hypothetical outcome plots (HOPs) [39,47] displayof edge occurrence. Edge weights can be dependent by conditional a ﬁnite set of samples from a distribution as a series of animated frames.probability or independent based on network context or network modSome studies of simple 2D visualizations ﬁnd that HOPs can lead toels used. From an analytical perspective, probabilistic networks have better estimates than error bars [35, 39, 47] and other static techniquesconstrained usability because some common graph analysis tasks, such like static ensembles and violin plots [47].as cluster detection, are difﬁcult to implement when edges are weighted We note several properties of HOPs that make them potentiallyby probability. Although there are existing algorithms to identify clusinteresting as a technique for displaying probabilistic graphs. First,ters and communities for a static weighted network (e.g., [42,55, 56]), HOPs are a natural choice for visualizing uncertainty when baselinethe uncertainty of community occurrence or cluster membership is visual encodings are already complex and hard to read, such that theimpossible to visualize in a static network representation. addition of another encoding (e.g., width) or glyph (e.g., error bars), may not be effective. By using temporal frequency encoding, whichedge probability, this approach is unsuitable for denser probabilistic perceptual research has found can be processed automatically withoutnetworks [31, 58]. This is because probabilistic graphs tend to have requiring counting [32], HOPs support intuitive estimation of eventmaximal connectivity, that is, all edges with non-zero weights must probabilities, which in a network application might include probabilitiesbe present in the graph. Even if analysts can ﬁnd relevant network associated with structures of interest (e.g., edges, clusters, cliques).conﬁgurations (e.g., path or alternating stars), they must decode and Finally, by depicting multivariate samples, HOPs make it possible for aintegrate the meaning of visual properties from multiple edges, which single visualization to show joint probabilities, which typically requiresare often limited for supporting accurate visual judgments [39, 50, 59]. adding additional views. While our network model does not require joint probability depiction, other probabilistic networks can (e.g., [40]).subset the edges by an analyst-deﬁned threshold [23, 72]. However, 2.2 Graph Visualization and Animationit is difﬁcult to identify an optimal threshold that can maintain thestructure of the networks without information loss. Perhaps because of Many network properties (e.g., centrality, clustering, density) have vi-these challenges, visualizing probabilistic networks using the node-link sual signatures, which make network visualization an important tool fordiagram is a relatively unexplored topic. One exception is Schulz et network analysis. When well laid out, a node-link diagram can provideal. [81], who developed a layout algorithm for probabilistic networks an effective bird’s eye view of the network, making these diagrams athat can blend sampled realizations from a probabilistic graph model ubiquitous representation of graphs. Analysts use node-link diagramsinto a static visualization, shown in Fig. 2. Their approach anchors and to identify overall patterns such as cores and peripheries, communitiesaligns different network realizations [9] such that the same vertex can or neighborhoods, and isolates and components, among others. Whileform a vertex cloud through node splatting [36]. Edges are splatted and many structural conﬁgurations (e.g., reciprocity, triadic closure, orbundled [36] to improve readability. However, improved readability of Graph layout algorithms, like force-directed (spring embedder) lay- Animated node-link diagrams are commonly used to visualize dy- Layout computation for dynamic network visualizations can be Animating random draws from a probabilistic graph model as ap- Although visual variables [6] (e.g., width or fuzziness) can encode One common strategy to simplify weighted graphs is to truncate or Fig. 2. Probabilistic graph layout by Schulz et al. [81]. the graph as a whole comes at the cost of concealing edge uncertainty, such that it is difﬁcult to imagine analysts estimating the distribution of properties like edge occurrence or path lengths. Conceptually, probabilistic graph layout and NetHOPs share many similarities, but the major difference is that probabilistic graph layouts aim to create a static visual representation through 2D graph embedding, such that many of the limitations for decoding distributional information from a static depiction of a probabilistic graph remain. Graph clustering is an important topic in many network domains (e.g., [4, 41, 49, 60]). Network task taxonomies describe clustering and community identiﬁcation as a class of topology-based tasks that is fundamental to network analysis and visualization [2, 52]. Prior work proposes several robust community detection algorithms on static graphs based on modularity optimization (e.g., [29, 64]), Markov simulations [85], random walk [68], and cluster structures [74, 75], to name a few. Many of these techniques are unsupervised or semi-supervised, so cluster boundaries and node memberships can be uncertain. Some interactive visualization tools communicate this uncertainty by showing crisp and overlapping community structures [86, 87] to address fuzzy overlapping communities with different granularity. When graphs are made dynamic through a temporal dimension, topology can change as vertices and edges appear and vanish. Hence, detected communities can emerge, merge, split, and disappear [67, 73]. Most dynamic community detection approaches can be classiﬁed as instant optimal, temporal trade-off, or cross-time [73]. The instant optimal approach searches communities individually using each graph in the sequence, and matches communities detected throughout the sequence (e.g., [37,76,88]). We develop a variant of the instant optimal approach for NetHOPs so our technique can support cluster detection and community membership for probabilistic graphs. 3 NETWORK HYPOTHETICAL OUTCOME PLOTS (NETHOPS) NetHOPs animate a set of hypothetical outcomes sampled from a probabilistic graph model, designed to address the challenges associated with visualizing probabilistic networks. This representation removes the requirement that users visually integrate distributional information across static encodings of probability. With NetHOPs, analysts can perceive deterministic network statistics from each sampled realization (see Fig. 1), and identify edge probabilities, and probabilities of higherlevel network structures, by integrating across the animated samples. At a high level, the NetHOPs creation pipeline starts with formulating a probabilistic random graph model based on a given network dataset. The model provides a network data generating process enabling us to sample a sequence of different network realizations via a Monte Carlo process. We apply our instant-optimal community detection and matching algorithms (see Sect. 3.2) to the network sequence so each individual realization is supplemented with additional measures that capture community structure across the set. We pass the network sequence to the visualization functions, which compute the layouts and use the additional community structure measures to color communities. NetHOPs are agnostic to how the probabilistic graph model is inferred as long as the graph model describes a network distribution and network sampling is enabled through a Monte Carlo process. In Sect. 3.4, we demonstrate the construction of a random graph model by treating edge occurrences as following a Bernoulli distribution parameterized by their corresponding probabilistic weights without dependency assumption. Our example is simple and aimed to convey the idea of probabilistic graphs. More rigorous network modeling approaches are available but are not the focus of our work. For example, efforts have been made to statistically quantify and model uncertainty in network edges by reconstructing the network through Bayesian inference [91, 92]. The exponential-family random graph models (i.e.,pmodels) can also place conditional probabilities on user-speciﬁed structural conﬁgurations [14, 57, 70, 71]. Additionally, probabilistic networks can be easily created based on network context, such as the well-known Cognitive Social Structures (CSS) [51] we use for demonstration. Given a probabilistic graph model (e.g., a posterior distribution in a Bayesian network reconstruction pipeline [91, 92]), we can sample realizations through a Monte Carlo process, which generates a setGof N graphs whereG= {G= (V, E), ··· , G= (V, E)}. We can then supplement the sequence of realizations with additional information, including a stability score and community label for each vertex. 3.2 Community Matching NetHOPs are designed to support probabilistic versions of common visual network analysis tasks, such as estimating distributions of network statistics that are normally deterministic (e.g., shortest path, density, edge occurrence, isolates). Many of these can be supported primarily through layout engineering to preserve stability (see Sect. 4.1). However, other properties, such as assessing the number of communities or the stability of community membership, require further optimizations. Cluster structures and membership can vary for each network realization that comprises NetHOPs due to small differences in conﬁguration across realizations [73]. This problem is similar to the “Ship of Theseus” thought experiment [80] in which it is challenging to identify communities when their corresponding vertex memberships change partially or completely in different network realizations. To demonstrate, the three static network visualizations in the ﬁrst row of Fig. 3 are network realizations sampled from a probabilistic graph derived from Krackardt’s advice-seeking CSS dataset (see Sect. 3.4 where we describe the data) positioned using the reference layout computed by aggregation. We apply a modularity-based community detection algorithm [7] to each of the network realizations, and colored vertices based on community membership without any analysis of relationships across realizations. All three realizations have three distinct communities, with similar vertex memberships. However, because community detection algorithms are typically not capable of leveraging cluster information across a set of related network realizations, communities will appear to change despite the fact that the clustering results are consistent. For example, the blue community in realization 2 has the same vertex membership as the orange community in realization 3, but we cannot identify these two communities as the same. To address this problem, we devise a two-step community matching algorithm. Given a sequence of N graphsGwhere eachG= (V, E) with vertex set V and edge setE= {(i, j) : i 6= j and i, j ∈ V }, a chosen community detection algorithm can assign a community label to each vertex as a vertex attribute Y where Y= {Y, ··· ,Y|i ∈ V }. We then use the community-labeled network realizations as inputs to a matching process based on the degree of vertices’ community cooccurrences. This process starts with constructing a weighted full graph (which we call the “co-community graph”)G= (V, E). The weight matrixWwherew= |{Y= Y|n ∈ N}|forGrepresents the total number of times two vertices belong to the same community summed across all networks in the sequence. In short, the “co-community graph” records the relationships between community status across realizations. To assess vertex community stability in the graph sequence, we set a thresholdTwheret = {1, ··· , n}. Astincrements, we remove edge (i, j)fromGift > w, soGdecomposes from a giant component and isolates emerge. Whenever a vertex becomes an isolate, we assign tas a “stability score” attribute to this vertex. Intuitively, the larger the stability score, the more stable the vertex. When each vertex has a stability score, we can identify the most stable vertices in each community and use these for coloring communities (Sect. 3.3.2). Fig. 3. (A) Probabilistic network realizations with community structuresstructure in node-link diagrams. Thus, we use the stability score (seeSect. 3.2) and community labels to assign colors to communities. We detected by Brandes et al. [7]. Vertices are colored to indicate community membership. (B) Same as (A) but with a community matching algorithmreiterate the thresholding process used to compute the stability scores, applied as described in Sect. 3.2and whenever we see a new component emerge, we assign a unique Our approach is designed speciﬁcally for sampled network realiza-score in the component if it does not yet have a color. When all stable tions from a network distribution with a ﬁxed vertex set. The Bernoullivertices have colors assigned, we match the same colors to other vertices sampling scheme causes network conﬁgurations to follow an approx-belonging to the same community in each network realization. The imately normal distribution by the central limit theorem, such thatresult of our matching algorithm is presented in Fig. 3 (B). Additional sampled realizations tend to have consistent structures and hence com-marks, such as convex hulls, can be added to reinforce boundaries. munity memberships. However, this approach can be generalizable to3.4 Application of NetHOPs other similar network sequences that follow a probability distribution. 3.3 Visualizing the Networkinteractive web-based prototype visualization system for study. 3.3.1 Layout Engineeringdimensional data structure used to measure individual perceptions of When arranging layouts for a graph sequence, too much emphasis onsocial relations within a network [12, 51]. Following the notation usedin [51], if node stability across realizations diminishes readability, while optimiz-lation of interest, CSS can be represented as ing individual layouts compromises analysts’ ability to relate entitiesof a relation, across states. NetHOPs address the trade-off between layout stabil-R ity and readability [11] by drawing on an aggregation and anchoring1 as a friend of person 2. We build our NetHOPs prototypes using technique developed by [8]. This dynamic layout algorithm is basedtwo CSS datasets, which measure the advice-seeking and friendship on the stress minimization approach and leverages the ofﬂine drawingrelations among 21 managers in a high-tech ﬁrm. Therefore, our data property that all realizations in a sequence are known in advance.has a dimension of R × N ×N × N where R = 2 and N = 21. Given a graphG = (V, E)deﬁned by a vertex setVand an edge set E, stress minimization computes a layoutPforGusing Equation 1. Toto build networks called consensus structures through a dimensiondetermine the positionspfori ∈ V,δmeasures the dissimilarity, orreduction technique by Equation 4 because the ground truth relathe shortest path, between(i, j)wherei, j ∈ Vandk · kdenotes the Eu-tions can be predicted from a weighted average of individual percepclidean norm. The weight matrixW = ωdetermines the contributiontions [23, 72]. However, Equation 4 is essentially the thresholding of each (i, j) to the layout arrangement.approach to create networks (see Sect. 2.3) because it adds an edge Given a graph sequenceG, we can compute a single reference layoutPthrough aggregation by Equation 2. The reference layout has the maximum stability as it places each vertex to a ﬁxed position for each realization inG(also called a “ﬂip-book” approach [62]). InG = (V, E) Equation 2,¯δis the mean shortest path for(i, j)wherei, j ∈ V. Thethe aggregated perception of weightsωconsider the variance of¯δ, which places more importancew on dyads having more stable shortest path length.perception accuracy depending on their experiences, observations, or stress(P) =ω(¯δ− kp− pk)the quality of perceptions homogeneously, thus placing an equal weightwhen computing edge probabilities. where¯δ=1Nδand ω=1¯δ·11 + Var(δ)independent Bernoulli random variable. The edge variable The reference layout, P = pfor i ∈ V , can be used as a benchmarkrealization in the sequence is a possible “version of reality” given the stress(P) =(1 − α) ·ω(δ− kp− pk)+ Therefore, the balance between stability and readability is parameterα. Whenα = 1, all network realizations are positioned using obtained by Equation 2. On the other hand, settingα = 0removes Probabilistic Graph ModelKrackhardt’s CSS data [51] is a three- Rdenotes a collection of adjacency matrices measuring a remeasures friendship,R= 1indicates person 3 perceives person Traditionally, perceptionsR= f (R, ··· , R)are used to the network if a certain proportion of perceivers claimR= 1. To avoid the thresholding approach, we create a weighted full graph . A weight matrixW = wwhere i 6= j and i, j ∈ Vholds Since the CSS data is a collection of perceptions provided inde- ) = w, which makes network sampling possible. Each sampled real-world social relations among the 21 managers. We repeatedly sample 150 network realizations for both the advice-seeking and friendship relations, and use these to create two sequences of 150 hypothetical outcomes, where the order in the sequence is not meaningful. Community MembershipFor each sequence, we apply our community matching algorithm and recorded community membership. NetHOPs RenderingWe then compute a total of 11 sets of layouts using Equation 3 by setting theαparameter from zero to one with an increment of 0.1. Because of the ofﬂine drawing approach, users of the prototype can adjust layout stability and readability in the interface by tuning the amount of anchoring through a slider and receive immediate feedback. We then create another slider that enables users to adjust the animation speed in the unit of second per network, which ranges from 0.1 to 2. The interface also has four switches that allow users to control graph-speciﬁc visual elements, such as adjusting edge opacity between 0.2 and 1, or turn on or off visual aids like convex hulls, node color, and node labels designed speciﬁcally for community detection tasks. 4 AN EXPLORATORY STUDY ON NETHOPS We sought to investigate how well social network experts could use NetHOPs to conduct a broad range of common network analysis tasks, including density, path lengths, community detection, edge occurrence, and node attributes. We aimed to understand how well participants could process the uncertainty inherent in probabilistic graphs when estimating network properties or statistics. We used Krackhardt’s CSS data (described in Sect. 3.4), which are relatively easy to describe for a study and include two graphs of varying connectivities. All experimental materials are included in the supplemental material. 4.1 Tasks Our tasks were inspired by the task taxonomies from Lee et al. [52] and Ahn et al. [2]. We extended these tasks to focus on participants’ ability to perceive the uncertainty of network statistics and properties. The available graph-speciﬁc objects in the CSS data imply tasks are centered around nodes, links, paths, and clusters (communities). Table 1 presents the complete list of tasks we used, labeled according to [52]. We omitted the isolate question on the advice-seeking CSS network because no isolates were detected after many sampling runs. Naturally, the extent to which we design custom parameterizations of the visualization to support speciﬁc tasks will affect performance. Table 1 also lists the set of default visualization parameters and graphical elements we chose to provide for each task. We identiﬁed these parameter choices based on the target of the task. For graphical elements, this meant turning on visual features, like colors and convex hulls, helpful for community detection. Our goal was to provide minimal support so as to investigate how well analysts could do with a fairly stable visualization with extra visual features that would be easy to turn on or off (e.g., node or edge highlighting). For anchoring and animation speed, we used self-experimentation to choose parameter values that seemed most beneﬁcial for the tasks. However, some of these choices can be arbitrary (e.g., node label, dark edges), so we designed a portion of our study to explore how analysts tuned the parameters themselves. 4.2 Study Interface The study interface contained two columns, a visualization panel containing NetHOPs on the left, and a task panel showing questions on the right. The default view coupled each NetHOPs with an animation control panel, which allowed participants to pause, resume, forward play, or backward play realizations. When paused, participants could inspect NetHOPs’ realizations one by one. A slider above the buttons indicated the progress of the animation, with a reset button next to the progress bar, which participants could click to reset to the ﬁrst realization. The additional controls for NetHOPs’ parameters mentioned in Sect. 3.4 were available for participants to use for the second part of the study, as we describe below. 4.3 Response Elicitation Using a frequency-based distribution sketching tool called the distribution builder, our interface recorded probability estimates for node- Fig. 4. Modiﬁed distribution builder adapted from [2, 38] with kernel density curve used to elicit uncertainty perception. attribute and edge-attribute tasks and elicited participants’ uncertainty perception for topology, overview, and browsing tasks [82]. Distribution builders allowed participants to place a set number of balls (e.g., 20, 50, 100) in bins to express their beliefs about a parameter distribution. Prior work suggests this method leads to less noisy elicited beliefs than common approaches (e.g., asking for fractiles [30] or sketching continuous density functions [38]). For our distribution elicitation tasks, we requested participants ﬁrst make deterministic estimates of the upper and lower bound of a network statistic. The interface then used the range produced by these estimates as thex-axis scale of the distribution builder. Participants could then drag different yellow markers above all possible discrete values that fall within the range, and allocate a total of 20 balls to each discrete “bucket” to approximate their perception of a distribution. Our study tasks required eliciting both discrete (e.g., path length) and continuous (i.e., network density) distributions. To help participants distinguish the difference, we created a modiﬁed distribution builder adapted from [38] by adding a kernel density curve as shown in Fig. 4. This instant feedback on the overall shape is important for continuous distributions because there are different ways a participant might try to use the interface. For example, if a participant wants to sketch a longtailed distribution, she might forget to place balls in every other bin near the tail, which, unintentionally, results in a multi-modal distribution. 4.4 Study Procedure Participants were directed to our web interface and instructed to complete the study in one session using Google Chrome. Participants were ﬁrst required to pass a qualiﬁcation test consisting of seven questions designed to check that they understood basic network statistics. The test questions were based on a simple static network diagram, and participants had to count or compute vertices, edges, isolates, communities, path length, and density, resembling the actual task questions shown in Table 1. To ensure participants were familiar with the use of distribution builders before tasks, we provided an exercise at the end of the qualiﬁcation test. A bell-shaped normal distribution was given, and participants were asked to drag the yellow markers to mimic the distribution as much as possible. Participants passed the assessment if they made one or fewer errors, excluding the distribution builder exercise. If an error was detected, they were directed to a test results page, in which the system would show which question was wrong with detailed explanations of why and how to get the correct answer. Participants who passed the qualiﬁcation test reviewed some background information, which described the CSS data structures, illustrated the NetHOP’s data generating process, and reviewed community detection. At the end of the background section, participants were given detailed instructions on how to use the NetHOP’s application interface and watched a short video visually demonstrating functionalities with transcribed text shown on the same page. Participants began the tasks ordered by taxonomy shown in Table 1. They ﬁrst completed the task on the advice-seeking NetHOPs and then proceeded to complete the same task using the friendship NetHOPs. Participants completed all tasks two times. In the ﬁrst iteration, they completed the tasks using the default visualization parameters and graphical elements (Table 1). In the second iteration, they completed the same set of tasks but were given the freedom to tune the visualization parameters and control graphical elements. To ensure our participants fully understood how to use the visualization control panels to tune NetHOPs’ displays, we created an instructional page describing the features of visualization parameters Table 1. NetHOPs user study tasks listed by task taxonomy with default visualization parameter value and graphical elements add-ons. and graphical visual elements before proceeding to the second itera-requirement on the expertise of the participants. We removed ﬁve tion. Another short video was created to provide a better visual aidentries due to incomplete data, leaving 51 responses for analysis. The explaining this newly added feature panel. In the second iteration, wemajority of our participants are graduate-level network researchers reminded participants of each response they had previously provided(98%) who have taken at least one course in SNA or graph theory to make it easier for them to tell if they thought the tuning could be(90%) and use network analysis in their daily work (86%). improved. We instructed them to change their responses only if they were reasonably conﬁdent that tuning the visualization parameters andsuperimposed against the ground truth distribution (rows A and B) or changing the graph elements could help them answer the task questions.probability (row C). Empirical cumulative distributions functions (A 4.5 Participantsand B right) are plotted for all distribution elicitation tasks. Barplotsand density curves differentiate the discrete (A left) and continuous We recruited participants familiar with SNA and graph theory by send-(B left) responses. We present results from the ﬁrst block of trials ing a recruitment email to a large SNA listserv and encouraged recip-where visualization parameters were given separately from those for ients to forward the study to relevant personnel. We also recruitedthe second block where tuning was allowed. participants from a private institution in the midwest, mainly from departments related to perception and networks (e.g., psychology, com-the browsing task of the friendship network in Fig. 5. About half of puter science, industrial engineering, and sociology). Participants whoparticipants (22) incorrectly assumed some realizations had a shortest successfully completed the study received a$15 dollar Amazon Giftpath length of zero (Figure 6 A, left, second column) when theoretically Card or an equivalent for their time and effort completing the study.it should be inﬁnity and therefore not counted when sketching the 4.6 Analysis Approach(i.e., higher EMD scores) in response quality for this task. We computed the ground truth probabilities and distributions for all5.2 Performance without Tuning tasks using the 150 network realizations that comprised NetHOPs. For tasks asking for deterministic probability estimates (node-We evaluated individual task performance by computing the bootattribute and edge-attribute tasks), we computed the differences be-strapped mean EMD scores for distribution elicitation tasks and the tween participants’ guesses and the ground truth probability summa-bootstrapped mean estimation error for the probability estimation tasks. rized from all realizations to assess how much they were off and inThe blue and orange 95% CIs in Fig. 6 indicate tasks completed with what direction. For distribution elicitation tasks (overview, browsing,or without tuning correspondingly. topology tasks), we discretized the ground truth distributions using the quantile dot plot (QDP) algorithm with pre-speciﬁed and constant bining the shortest path lengths between selected vertices on both the width [48]. QDP is non-parametric and visualizes the predictive quan-advice-seeking and the friendship networks, despite the smaller varitiles in Wilkinsonian dotplot [89], which allows us to match the groundance for the ground truth distribution in the advice-seeking network truth distribution with the elicited distribution from the participant.than that of the friendship network shown in Fig. 5 (A). Participants To assess the differences between participants’ elicited distributionswere more likely to overestimate the shortest path length for the adviceand the discretized ground truth distributions, we used Earth Mover’sseeking network, and, as described above, underestimate for friendship. Distance (EMD), which computes the minimum amount of work needed to shift the distribution of interest to match the target distribution oftwo blue CIs in Fig. 6 (A) for the two browsing tasks almost completely truth [77, 78]. QDP enables us to one-to-one point match the elicitedoverlap. The mean EMD for advice-seeking has a CI distribution with the ground truth distribution formed by 20 balls; hence,compared to a CI [1.67, 2.5] for the mean EMD of friendship. the input distributions have the integer solution property, and each ball has the same weights of one [33].tion task, with the response distributions closely resembling the ground Given a user input distributionU = {(u, w), ··· , (u, w)}and thetruth (Fig. 5 A, middle columns). The blue CIs for the isolate task in the ground truth distributionT = {(t, w), ··· , (t, w)},|U| = |T | = Nmiddle of Fig. 6 (A), top, come closest to zero EMD. Network density andw= w= 1 ∀i, j ∈ N. LetF(U, T )be a set of all feasible ﬂow toestimation, on the other hand, was the most difﬁcult task for particimatch balls inUtoT, and so the distance or cost to perform such move-pants. Density plots and CDFs in Fig. 5 (B) show lots of dispersion ments is the Manhattan distances,L(u,t), summed across all pairin elicited distributions, with some centered roughly 40% points away of balls, which can be expressed byCost(F, u, t) =∑∑fL(u,t).from the ground truth distribution’s location. The mean EMD scores Therefore, the EMD score can be computed by Equation 5, which is anfor the density estimation tasks are much higher than the rest of the optimization aiming to minimize the cost of ﬂows. EMD score can bedistribution-elicitation tasks in Fig. 6 (B). Participants, on average, perinterpreted as the average distance balls in the user distribution mustceived the density distribution more accurately on the sparse friendship move to match those of the target distribution.network (CI EMD(U, T ) =N(5)that participants left at the end of the study (e.g., “Density seems nearimpossible to intuitively estimate” and “I was able to count for the ﬁrst Below, we report mean estimates with bootstrapped 95% conﬁdencefew questions but that is clearly not practical for the density ones.”). intervals (CIs) of participants’ responses and EMDs for each task.munities suggest participants perceived the distributions more accu- 5 RESULTSrately in the advice-seeking network. The elicited distributions areclearly biased toward underestimation for the sparse friendship network 5.1 Preliminaries(Fig. 5 A, last column) but less clearly biased and closer to the ground Of 173 participants recruited to our study website, 32% (56) passedtruth for advice-seeking. The blue CIs on EMD in Fig. 6 (row A) do the qualiﬁcation test. The high exclusion rate indicates our stringentnot overlap for these tasks (advice-seeking: We provide an overview of performance in Fig. 5, with responses In reviewing overall performance, we discovered a data anomaly for Browsing TaskParticipants performed consistently well when track- Despite these small differences in apparent bias in the results, the Overview Tasks: Most participants excelled at the isolate identiﬁca- [7.3, 13.9]) than that of the advice-seeking (CI[13.9, 22.2]). Topology TaskResults for the topology tasks counting distinct com- Fig. 5. (A). Left: Barplots display participants’ discrete responses for browsing, topology, and overview (isolate) tasks stacked on top of each other against the ground truth distribution in red. Right: Empirical cumulative distribution functions based on participants’ elicited discrete responses shown in the barplots on the left. (B). Left: the density plot shows participants’ continuous responses for the network density task stacked on top of each other against the ground truth distribution in red. Right: Empirical cumulative distribution functions based on participants’ elicited network density estimations are shown in the density plot on the left. (C). Strip plots present participants’ deterministic probability estimates with 95% bootstrapped CIs for each attribute-based task from the study. The ground truth probabilities for each task are shown as red points between the CIs. We elicited four probability estimates for node-attribute tasks and two for edge-attribute tasks from both advice-seeking and friendship networks. CI[2.75, 3.36]). This outcome is unsurprising because the ground truth distribution for the advice-seeking networks shown in Fig. 5 (A) has a smaller variance compared with that of the friendship network. Attribute-based TasksFig. 6 (C) and (D) display how much participants’ probability estimates were off from the ground truth for the attribute-based tasks. Participants tended to underestimate probabilities for node-attribute tasks and overestimate probabilities for edge-attribute tasks. However, on average, participants’ probability estimates were not too far from the ground truth. As suggested by the blue CIs in Fig. 6 (C) and (D), all participants’ deterministic probability guesses were off within 20 percentage points of the ground truth probability. 5.3 Performance with Tuning Several participants commented that the ability to control NetHOP rendering helped them complete the tasks. We summed each participants’ EMD scores for all tasks completed with and without tuning and computed the average amount of improvement. We found that the ability to control NetHOPs rendering could improve participants’ distribution elicitation by 4% on average, though this was not a reliable difference given our sample size (CI[−4.2%, 12%]). We computed a similar statistic by aggregating the total absolute error for probability estimation tasks, and found tuning visualization parameters did not improve probability estimation (CI[−14.2%, 13.3%]). Recall that we instructed participants to update their answers only if they were conﬁdent that tuning could help them achieve better results. Participants performed reasonably well with the default parameters, which makes this result not terribly surprising. Many may not have felt they could improve the prior parameters, or tweaked them only by a small amount. This is reﬂected in that 22% (11) of our participants provided the same answers in the second iteration of tasks. Nonetheless, we provide an exploratory analysis of tuning strategies, since how participants changed parameters can shed light on how visualization parameters may support different tasks in slightly different ways. 5.3.1 Tuning Strategies The distributions of the two performance metrics indicate that tuning did help some participants. To investigate the dynamics between visualization parameters and accuracy, we ranked all participants by their performance with tuning and grouped top-performers from the ﬁrst quartile and bottom-performers from the fourth quartile, with each Fig. 6. (A) and (B) display the bootstrapped mean EMD scores with 95% CI for browsing (shortest path length), overview (isolate and network density), and topology (distinct community) tasks. (C) and (D) display the bootstrapped mean of probability estimation errors for each attributebased task on node community stability and edge occurrence. group consisting of 13 participants. Top-performers had a pooled mean EMD score of 3.1 (Min.: 1.7, Median: 2.8, SD: 1.2, Max.: 5.3), and their probability estimates were, on average, 1.9% off from the truth (Min.: 0.1, Median: 1.3, SD: 1.6, Max.: 5). On the other hand, bottomperformers had a pooled mean EMD score of 7.8 (Min.: 3.1, Median: 6.3, SD: 4.7, Max.: 15.4), and their probability estimates were, on average, 14.3% off from the truth (Min.: 1.3, Median: 12.6, SD: 12.1, Max.: 44.9). We focused on how anchoring and animation speed were used by each group, and present the bootstrapped mean with 95% CIs in Fig. 7 to assess how the parameters related to response quality. Fig. 7. Bootstrapped means with 95% CIs for anchoring (A) and frame rate (B) parameters used by participants.Fig. 8. Participants’ use of graphical visual aids. Tuning on Layout StabilityFig. 7 row (A) shows participants’element by task in Fig. 8 and found some combinations were very anchoring tuning did not deviate too much from the default value wedifferent from the default visualization that we thought would work provided for most tasks, except for density estimation. For this overviewbest on a given task. The majority of top-performers chose to make task, participants preferred layout stability over the general readabilitytargeted or relevant network objects and elements more salient by the layout algorithm optimizes for (e.g., by reducing overlapping edges).deactivating irrelevant visual elements. For example, when detecting This goes against our expectation that the need to estimate densitythe number of communities, they chose to make edges less salient and would trump the need to keep nodes in consistent positions, which hadturn off node labels to better emphasize node color and convex hulls. led us to set a default anchoring value of zero.When browsing shortest paths, 75% of top-performers preferred less Layout stability appears more important for the two attribute-basedsalient edges to further emphasize the red highlighted edges connecting tasks. Participants preferred higher average anchoring for node-attributethe nodes. To estimate network densities, top-performers preferred tasks regardless of performance, and nearly all top-performers chosemore salient edges while minimizing other visual elements by turning the most stable layout for node-attribute tasks.off convex hulls, node color, and node labels. The topology tasks (detecting distinct communities) and the isolatewhen identifying the number of isolates, roughly 70% of top-performers overview task were the only two tasks where top-performers on averageturned on convex hulls, 50% removed node color, and 30% preferred preferred lower anchoring values than the bottom-performers. Anchor-less salient edges, even though convex hulls and node colors were ing preferences were similar between networks for the browsing tasks.seemingly irrelevant visual elements to the task. We note that convex Both groups lowered the anchoring slightly from the default of 0.8, buthulls do not include isolated nodes, and our coloring algorithm would the bottom-performers, on average, lowered anchoring a bit more.consistently assign a distinct color to isolated nodes. With these two We pooled all anchoring parameters used by top-performers andparameters, edge salience becomes less important and could be turned bottom-performers for each task and found that top-performers pre-off to accentuate convex hulls and node color. ferred layout stability more than bottom-performers. Top-performers tended to set a slightly higher average anchoring of 0.81 (CI [0.73, 0.89]) compared with the average 0.71 (CI[0.63, 0.79]) set by the5.4 Precision of Inference & Time-Accuracy Correlation bottom-performers. Between CSS datasets, participants preferred moreTwo forms of error can impact the precision of inferences about netlayout stability when working on the denser advice-seeking network.work statistics made with NetHOPs: perceptual and cognitive errors Top-performers used an anchoring of 0.83 (CI[0.75, 0.90]) on averagerelated to how accurately analysts can estimate probabilities from the for the advice-seeking and 0.78 (CI[0.70, 0.86]) for the friendship. Thisvisualization (which applies to any visualizations of distributions), and penchant is more noticeable from bottom-performers as the averagedapproximation error introduced by sampling from the network model. anchoring used on the advice-seeking network is 0.72 (CI[0.63, 0.81]), and the friendship network is 0.67 (CI[0.59, 0.75]).of random draws from the graph model. While we cannot compute Tuning on Animation SpeedOne consistent pattern observableapproximation error against the ground truth model, we can infer it by from Fig. 6 (B) is that top-performers generally chose to set the ani-re-sampling mation speed slower than the bottom-performers. Top-performers, ondistributions of network statistics from each re-sampled set to compute average, preferred to render each network for 1 second (CI[0.9, 1.13]),EMD scores against those from the set of NetHOPs. We can then compared to the average 0.82 (CI [0.75, 0.9]) of bottom-performers.quantify the sampling error of the distribution for each network statistic When viewing the denser advice-seeking networks, all participantsin the unit of EMD by constructing a conﬁdence interval, as shown in from both groups preferred faster animation speed on average, dis-Fig. 9. Therefore, if a participant perfectly perceived and sketched a playing each network realization on the screen for 0.77 seconds ondistribution and received an EMD score of zero using NetHOPs, her average (CI[0.66, 0.88]), compared to 0.84 seconds (CI[0.75, 0.92])perception could be off by an for the friendship network. For top-performers, the averaged anima-is generalizable and can be easily applied to compute the sampling tion speed when completing tasks on the advice-seeking network waserror of any probability estimation task. 0.97 seconds per network (CI[0.85, 1.1]), and 1.02 seconds per network (CI[0.91, 1.13]) for the friendship network. Similarly, bottom-While we did not log exact realizations viewed, we can use time spent performers chose to display each network realization on the screen foron tasks to infer approximate viewing. For our study, we found par0.77 seconds (CI[0.68, 0.86]) for the advice-seeking network and 0.83ticipants, on average, spent 55 minutes to complete all tasks (Min.: 9, (CI[0.76, 0.90]) seconds for the friendship network.Median: 49, SD: 32, Max.: 176), after removing one outlier of 549 Graphical ElementsEdge opacity, node color, convex hulls, andminutes. This participant paused on one task page for approximately node labels are network-related graphical attributes or elements that8.5 hours, suggesting this participant might have left the browser open can be highly task-speciﬁc. In analysis, we found it hard to generalizeand walked away. Recall that the average of 55 minutes describes much from looking at each individually, but analyzing combinations ofparticipants’ time to complete a total of 70 questions spread across 22 visual parameters was more meaningful.task screens. For the distribution elicitation tasks, 75% of participants We computed the percentage of participants who used each graphicalcompleted the tasks within approximately ﬁve minutes, which includes We also observed some creative use of visual features. For example, First, we quantify the sampling error introduced when taking a set Naturally, participants may not view all NetHOPs’ realizations. Fig. 9. Sampling error for the distribution elicitation tasks in EMD based on 500 samples of 150 network realizations. the time spent on identifying the lower and upper bounds and sketching the distributions. For probability elicitation tasks, 75% of our participants were able to complete all four sub-tasks for node stability within six minutes and two sub-tasks for edge occurrence within three minutes. These estimates suggest that many participants viewed all 150 frames, though we cannot be sure how they divided their attention between questions and watching the animation. To assess whether spending more time on a task correlated with performance, we conducted a correlation analysis between task completion time and response quality by computing Pearson’s correlation coefﬁcient for each task, then by using Fisher’s Z-Transformation [21, 22] to meet the normality assumption and compute CIs shown in Fig. 10. We observed negative correlation coefﬁcients in the range of[−0.3, 0]for the majority of the tasks, implying that longer time spent on tasks can slightly reduce the amount of perception error. However, almost all CIs include zero, which makes this effect unreliable except for the task on the shortest path length of the advice-seeking network with tuning. It is worth mentioning that participants left comments such as, “I had to think a lot about each question and pause to take breaks. There were a lot of questions,” which may bias these correlations. Our user study demonstrates NetHOPs’ potential to support exploratory analysis on probabilistic networks. We summarize our ﬁndings, provide design recommendations, and discuss future work. Overall PerformanceWhen using NetHOPs, we discovered analysts were better at identifying isolates, tracking path lengths, and detecting attribute-based changes on both nodes and edges, while they struggled more with estimating properties like density and distinct communities when realizations had overlapping communities. We speculate the reason our participants excelled at identifying isolates and tracing paths is that people tend to be visually sensitive to a lack of continuity between nodes, perhaps because it can be recognized pre-attentively when layouts are stable. We found that participants’ estimates of network properties fell on average within 11% of the statistics computed on the realizations comprising NetHOPs. Naturally, a question arises of whether this amount of error, in combination with the sampling error discussed in Sect. 5.4, is tolerable. We suspect that the error induced by NetHOPs is acceptable in many cases where visual analysis aims to help analysts to get a rough sense of many network properties to build intuition. We also note that whenever visualization is used for network exploration, a rough sense of the properties is more likely to be the goal, since an analyst might otherwise use more exact methods or modeling. However, future work might better contextualize whether the approximations allowed by NetHOPs seem sufﬁcient to network analysis. Layout StabilityOur participants appeared to tune NetHOPs differently based on network density. Stable layouts seemed generally beneﬁcial for all tasks, even for tasks like density estimation that do not require stability. A highly stable layout may prevent change-blindness and make it easier to detect important differences across realizations. Interestingly, our study participants did not prefer a completely stable layout except for attribute-based tasks on nodes. This suggests that estimating distribution from animated network realizations requires its own balance of stability versus within-realization optimization as analysts appear sensitive to both. We also found that analysts can tolerate more node movements for sparse networks. We speculate the reason behind this may be related Fig. 10. Pearson’s Correlation with 95% CIs between task completion time (mins.) and perception accuracy. to the overall shape of the networks and the amount of visual clutter in the visualizations caused by density. A sparse network is more visually trackable because of fewer graphical elements, so stability can be compromised in favor of readability. For denser networks, we think methods, such as [65], can be incorporated into the layout engineering when certain network properties (e.g., small-worldness) are known to make layout more comprehensible before aggregation and anchoring. Animation SpeedWe found top-performers tended to use slower animation speeds, which is unsurprising as a slower speed allows a more thorough review of each network realization. However, a faster animation speed (and a high degree of anchoring) appears to work well for node-attribute tasks where change detection is straightforward. The chosen animation speeds for the two NetHOPs in our user study are relatively slower compared to the chosen default speeds for simpler 2D HOPs in prior work [39,46, 47]. This is because network realizations convey more information than simpler charts and require more cognitive load for analysts to process. Participants may have needed a longer time to register what relationships were present in a realization. Graphical ElementsThe salience of relevant network objects appears to be the most important driver of participants’ choices. Therefore, graphical aids like edge opacity, node color, convex hulls, and node labels are useful in producing more accurate uncertainty depictions. Highlighting or emphasizing relevant network objects can also help analysts identify targeted graphical elements and capture changes with minimum effort. We think these add-ons can greatly reduce the risks of change-blindness, and suggest any practical implementation of NetHOPs would allow for such visual tuning. Limitations and Future WorkNetHOPs are subject to errors from (1) approximating a distribution with samples to create the animation, and (2) analysts not watching full realizations. As we described in Sect. 5.4, errors can be quantiﬁed by comparing network statistic distributions across sets of realizations of a particular size. However, future work might aim to better understand how many network realizations analysts tend to watch before they feel conﬁdent estimating a particular statistic, providing more insight into how much time is required and for how much accuracy gain, in relation to static graphs. Our study also involved two relatively small networks. Beyond testing larger networks, researchers could explore the utility of NetHOPs for bipartite or multiplex networks, as well as network models with edge dependencies, which NetHOPs are well suited to address. 7 CONCLUSION NetHOPs aim to facilitate uncertainty communication for probabilistic networks. We summarized the design of NetHOPs and illustrated the computation of its controllable dynamic layout. We designed a community matching algorithm so our technique can support uncertainty detection of topology-based tasks such as clustering identiﬁcation. The results of our user study suggested that the technique can support visual exploratory analysis, at least of small networks. Our results point to directions for future work around optimizing visualization parameters and better understanding perception of network properties via animation. ACKNO WLEDGMENTS This work was supported by NSF IIS-1907941, NSF IIS-1815760, and Microsoft.