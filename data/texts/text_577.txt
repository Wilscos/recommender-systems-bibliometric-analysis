<title>Mixed-Integer Optimization with Constraint Learning</title> <title>arXiv:2111.04469v1  [math.OC]  4 Nov 2021</title> <title>1. Introduction</title> complicated, however, when the constraints and/or objectives are not explicitly known. with a limit on toxicity; we may have observational data on treatments and their toxicity outcomes, data to learn these functions? are MIO-representable, meaning that they can be embedded into MIO formulations. This MIO- and objectives directly from data, using ML, and to optimize decisions accordingly, using MIO. directly using oﬀ-the-shelf solvers. this further in Section 2.2. clinical trials. Kleijnen (2015) provides further information on this subject. activation function can be represented using binary variables and big-M formulations (Amos et al. possible, provided the solvers are capable of handling these functions. tree ensembles (Cremer et al. 2019) have also been used in MIO in the same way as decision trees, aggregate constraints. and Krawiec 2019), local search (Sroka and Pawlak 2018), evolutionary strategies (Pawlak 2019), and Litwiniuk 2021). are restricted to limited problem structures and learned model classes. Recently, Bergman et al. framework and cannot be directly applied in our case studies. We take a broader perspective, components of a data-driven decision making problem. Elmachtoub and Grigas (2021) leverage ML model predictions as inputs into an optimization prob- lem. Our approach is distinct from existing work in that we directly embed ML models rather than extracting predictions, allowing us to optimize our decisions over the model. In the broadest sense, our framework relates to work that jointly harnesses ML and MIO, an area that has garnered signif- et al. 2021). follows: 1. We develop an end-to-end framework that takes data and directly implements model train- available at https://github.com/hwiberg/OptiCL. allow for the combined use of diﬀerent algorithms for diﬀerent outcomes. Our framework sup- in cases with both one-class and two-class data. Additionally, we give mathematical represen- tations of the ML functions to enable their use in MIO applications. computational burden of our approach while keeping the beneﬁts of the trust region. methods in these settings. <title>2. Methodology</title> Suppose we have data D = {(¯x , ¯w , ¯y )} , with observed treatment decisions ¯x , contextual infor- pipeline, which is detailed in the sections below. s.t. g(x, w, y) ≤ 0, (1) y = (x, w), models that can be tackled by those ever-improving solvers. with the embedded constraints and variables as EM(w). Model M(w) is quite general and encompasses several important constraint learning classes: by a speciﬁed upper bound τ, i.e., g(y) = y − τ ≤ 0, or lower bound τ, i.e., g(y) = −y + τ ≤ 0. for the constraints. a probability y ∈ [0, 1]. We can enforce a lower bound on the feasibility probability, i.e., y ≥ τ. probability. s.t. g(x, w) ≤ 0, y = h(x, w), y − t ≤ 0, x ∈ X (w). common in practice to use y in the objective and omit the auxiliary variable t. model training approach. Suppose that we have a continuous scalar outcome y to learn and we want to impose an upper bound of τ ∈ R (it may also be a lower bound without loss of generality). directly encode feasibility. vary τ . Our framework is enabled by the ability to embed learned predictive models into an MIO formu- model training procedure, but solely the size of the ﬁnal trained model. Without loss of generality, a scalar, not a multi-output vector. procedure for both cases when h(x, w) is a continuous or a binary predictive model, where relevant. We assume that either regression or classiﬁcation models can be used to learn feasibility constraints, as described in Section 2.1. y = β + β x + β w. predictions, both for classiﬁcation (Cortes and Vapnik 1995) and regression (Drucker et al. 1997). function learning, we ﬁt a linear function to the data. The setting is similar to linear regression, y = β + β x + β w. 1, if β + β x + β w ≥ 0; y = 0, otherwise. be embedded as y ≥ 1. of features (Bertsimas, D. and Dunn, J. 2018). probability threshold). s.t. g(x, w) ≤ 0, gains. This is explored further in Appendix A.2. in Appendix A.1. machines (GBM) consist of many decision trees that are aggregated to obtain a single predic- tion for a given observation. These models can thus be implemented by embedding many “sub- individual trees: probabilities returned by each model (y ∈ [0, 1]), which can likewise be constrained or optimized. outlier predictions: estimate, whereas α = 1 removes the constraint entirely. of the MIO-representable predictive models discussed in this section. space over multiple nodes (and layers) allows MLPs to capture complex functions that other algo- rithms cannot adequately encode, making them a powerful class of models. the input layer, with a set of ReLU constraints for each node in each internal layer, l ∈ {2, . . . , L − 1}. can be chosen according to the minimum necessary probability to predict 1. As for the SVC case, neural networks trained for multi-class classiﬁcation. As the optimal solutions of optimization problems are often at the extremes of the feasible region, a boundary of convex shape, the region inside this boundary is known as an interpolation region. ¯z = (¯x , ¯w ), we deﬁne the trust region as the convex hull of this set and denote it by CH(Z). Recall that CH(Z) is the smallest convex polytope that contains the set of points Z. It is well- known that computing the convex hull is exponential in time and space with respect to the number (a) CH(Z) with single region. (b) CH(Z) with clustered regions. of samples and their dimensionality (Skiena 2008). However, since the convex hull is a polytope, where λ ∈ R , and I = {1, . . . , N} is the index set of samples in Z. are found in the low-density regions. We therefore advocate the use of a two-step approach. First, as the union of the convex hulls of the individual clusters (Figure 3b). one of the convex hulls. More precisely, u = 1 corresponds to the convex hull of the k-th cluster. are required. the schedules created by the machine shop supervisor are feasible, even if they may not be optimal. trust region. than a traditional approach, which makes it an ideal choice when dealing with massive datasets. <title>3. Case study: a palatable food basket for the World Food Programme</title> In this case study, we use a simpliﬁed version of the model proposed by Peters et al. (2021), simultaneously optimizes the food basket to be delivered, the sourcing plan, the delivery plan, and the transfer modality of a month-long food supply. The model proposed by Peters et al. surveys. The structure of this problem, which is an LO and involves only one learned constraint, the eﬀect of clustering on the computation time and the optimal objective value. Additionally, prescriptions. The optimization model is a combination of a capacitated, multi-commodity network ﬂow model, and a diet model with constraints for nutrition levels and food basket palatability. procurement during the food aid operation. constraints. The parameter t is used as a lower bound on the food basket palatability. ration per beneﬁciary for commodity k. The variable y refers to the palatability of the food basket. The full model formulation is as follows: The objective function consists of two components, procurement costs and transportation costs. palatability (y), deﬁned by means of a predictive model (4h), to be greater than a threshold (t). Lastly, non-negativity constraints (4i) are added for all commodity ﬂows and commodity rations. of 0.5 for our learned constraint. approximates the unknown constraint. The predictive models used to learn the palatability con- as base-learners, and MLP with ReLU activation function. 2021) as the optimization solver. Table 5 reports the performances of the predictive models evalu- MLP model signiﬁcantly achieves the lowest error during this validation phase. The column “MSE” gives the MSE of the predictive models once embedded into the optimization problem to evalu- with diﬀerent cost vectors. The MLP model exhibits the best performance (0.055) in this context, showing its ability to model the palatability constraint better than all other methods. trust region. fact reside in low-density areas of the feature space that should not be included in the trust region. In this sense, the loss in optimality might actually coincide with more trustable solutions. the right graph, we have the distributions of optimality gap, i.e., the relative diﬀerence between the optimal solution obtained with clusters compared to the solution obtained with no clustering. K = 50) while still obtaining near-optimal solutions (less then 0.25% average gap with K = 50). solution as the convex combination of points within a single cluster. <title>4. Case study: chemotherapy regimen design</title> cohort and study characteristics, the prescribed chemotherapy regimen, and various outcomes. linear regression models to predict survival and toxicity, and it constrains a single toxicity measure. oﬀers beneﬁts through higher performing predictive models and more clinically-relevant constraints. learn the objective function directly as a predictive model. treatment. The contextual variables (w) consist of various cohort and study summary variables. setting. drugs, each with an administration schedule of potentially varied dosages throughout a chemother- maximum instantaneous dose in the cycle: = I(drug d is administered), = average daily dose of drug d, = maximum instantaneous dose of drug d. This allows us to diﬀerentiate between low-intensity, high-frequency and high-intensity, low- as the objective (y ), and various toxicities, to be included as constraints (y , i ∈ Y ). w, we formulate the following MIO: (x, w), x ∈ X (w). In this case study, we learn the full objective. However, this model could easily incorporate deter- domain-driven constraint, enforcing a maximum regimen combination of three drugs. solution that integrates directly into the model framework. nine contextual variables, including the average patient age and breakdown of primary cancer site. We include several “dose-limiting toxicities” (DLTs) for our constraint set: Grade 3/4 constitu- decision variables. We apply a temporal split, training the predictive models on trial arms through 2008 and generat- ing prescriptions for the trial arms in 2009-2012. The ﬁnal training set consists of 320 observations, data processing details are included in Appendix D.1. the observed (x, w) in our training set. threshold within the optimization model. Based on the model selection procedure, overall DLT, gastrointestinal toxicity, and overall sur- complete comparison of the considered models is included in Appendix D.2. observed cohort-treatment pairs and do not have information on potential unobserved combina- tions. We propose an evaluation scheme that leverages a “ground truth” ensemble (GT ensemble). performances are included in Appendix D.3. We evaluate our model in multiple ways. We ﬁrst consider the performance of our prescrip- tions against observed (given) treatments. We then explore the impact of learning multiple sub- a feasible solution. the given outcome predictions. Constraints”) against the observed actual treatments. For example, under the GT ensemble scheme, 94.1% under the proposed treatment. This yields an improvement of 11.10%. We obtain a signif- blood toxicity and infection than the baseline given regimens. By constraining multiple measures, the overall DLT measure satisfaction, suggesting that the inclusion of these “sub-constraints” the treatment unviable. <title>5. Discussion</title> Our experimental results illustrate the beneﬁts of our constraint learning framework in data- chemotherapy regimens for advanced gastric cancer. The quantitative results show the improve- single aggregate measure. Our framework scales to large problem sizes, enabled by eﬃcient formu- the trust region also has broad applicability in one-class constraint learning. of unobserved confounders. case of model misspeciﬁcation, a known shortcoming of “predict-then-optimize” methods (Elmach- allows us to obtain higher quality predictive models by capturing several possible functional rela- optimization to directly account for prediction uncertainty in the constraints. constraints and objectives with supervised learning, and incorporates them into a larger optimiza- unsupervised learning. The generality of our method allows us to tackle quite complex decision set- optimization modeling software packages. <title>Acknowledgments References Appendix A: Methodology A.1. Embedding a decision tree Consider the leaves in Figure 2. An observation will be assigned to the leftmost leaf (node 3) if x ≤ b and A x ≤ b . An observation would be assigned to node 4 if A x ≤ b and A x > b , or equivalently, −A x < −b . Furthermore, we can remove the strict inequalities using a suﬃciently small  parameter, so that −A x ≤ −b − . We can then encode the leaf assignment of observation x through the following constraints:</title> where l , l , l , l are binary variables associated with the corresponding leaves. For a given x, if x ≤ b , Constraints (5e) and (5h) will force l and l to zero, respectively. If A x ≤ b , constraint (5d) will force l to 0. The assignment constraint (5i) will then force l = 1, assigning the observation to leaf 3 as desired. Finally, constraint (5j) sets y to the prediction of the assigned leaf (p ). We can then constrain the value of y using our desired upper bound of τ (or lower bound, without loss of generality). More generally, consider a decision tree h(x, w) with a set of leaf nodes L each described by a binary variable l and a prediction score p . Splits take the form (A x + (A w ≤ b, where A gives the coeﬃcients for the optimization variables x and A gives the coeﬃcients for the nonoptimization (ﬁxed) variables w. Let S be the set of nodes that deﬁne the splits that observations in leaf i must obey. Without loss of generality, we can write these all as ( x + ( w − M(1 − ) ≤ , where A is A if leaf i follows the left split of j and −A otherwise. Similarly, b equals b if the leaf falls to the left split, and −b −  otherwise, as established above. This decision tree can then be embedded through the following constraints: Note that the non-learned constraints on x, namely constraint (7b), and the trust region constraint (7c) allow us to reduce the search space when determining M. A.2. MIO vs. LO formulation for decision trees In Section 2, we proposed two ways of embedding a decision tree as a constraint. The ﬁrst uses an LO to represent each feasible leaf node in the tree, while the second directly uses the entire MIO representation of the tree as a constraint. To compare the performance of these two approaches, we learn the palatability constraint using a decision tree (CART) grown to various depths (from a maximum depth of 3 to 20) and solve the optimization model with both approaches. Figure 6 shows that as the maximum allowable tree depth is increased, the number of LOs to be solved also increases. This is because there are more feasible leaves which need to be represented using LOs. Once the tree has reached the optimal depth (selected via cross-validation), increasing the maximum allowable depth of the tree does not cause the tree to grow any further. At this point, the number of LOs to be solved remains constant. When comparing the solution times (averaged over 10 runs), the right graph in Figure 6 shows that the MIO approach is relatively consistent in terms of solution time regardless of the tree depth. With the LO approach however, as the depth of the tree grows, the number of LOs to be solved also grows. While the solution time of a single LO is very low, solving multiple LOs sequentially might be heavily time consuming. A way to speed up the process is to solve the LOs in parallel. A tree of depth 3 requires only one LO to be solved, which takes 1.8 seconds in this problem setting. By parallelizing the solution of the LOs, the total solution time can be expected to take only as long as it takes for the slowest LO to be solved. A.3. MIO representation of the ReLU activation function We can represent the ReLU operator, v = max {0, x} the following way: where M < 0 is a lower bound on all possible values of x, and M > 0 is an upper bound. While this embedding relies on a big-M formulation, it can be improved in multiple ways. The model can be tightened by careful selection of M and M . Furthermore, Anderson et al. (2020) recently proposed an additional iterative cut generation procedure to improve the strength of the basic big-M formulation. A.4. Embedding a multi-layer perceptron for multi-class classiﬁcation In multi-class classiﬁcation, the outputs are traditionally obtained by applying a softmax activation function, S(x) = e , to the ﬁnal layer. This function ensures that the outputs sum to one and can thus be interpreted as probabilities. In particular, suppose we have a K-class classiﬁcation problem. Each node in the ﬁnal layer has an associated weight vector β , which maps the nodes of layer L −1 to the output layer by β . The softmax function rescales these values, so that class i will be assigned probability We cannot apply the softmax function directly in an MIO framework with linear constraints. Instead, we use an argmax function to directly return an indicator of the highest probability class, similar to the approach with SVC and binary classiﬁcation MLP. In other words, the output y is the identity vector with y = 1 for the most likely class. Class i has the highest probability if and only if + β ≥ β + β , k = 1, . . . , K. = 1. (9b) Constraint (9a) forces y = 0, if the constraint is not satisﬁed for some k ∈ {1, . . . , K}. Constraint (9b) ensures that y = 1 for the highest likelihood class. We can then constrain the prediction to fall in our desired class i by enforcing y = 1. Appendix B: Trust region As we explain in Section 2.3, the trust region prevents the predictive models from extrapolating. It is deﬁned as the convex hull of the set Z = {(¯x , ¯w )} , with ¯x ∈ R observed treatment decisions, and ¯w ∈ R contextual information. In Section B.1, we explain the importance of using both ¯x and ¯w in the formulation of the convex hull. When the number of samples (N) is too large, the optimization model trust region constraints may become computationally expensive. In this case, we propose a column selection algorithm which is detailed in Section B.2. region. trusted solutions (red line) lies within CH(Z) when we include ¯w. If we leave out ¯w in the deﬁnition of the trust region, then we end up with the undesired situation shown in Figure 7b, where the solution may lie outside of CH(Z). We observe that in some cases we must deﬁne the convex hull with a subset of variables. This is true in cases where the convex hull constraint leads to excessive data thinning, in which case it may be necessary to deﬁne the convex hull on treatment variables only. where the decision variable x is replaced by Z λ. Constraints (10b) include both known and learned constraints, while constraints (10c) and (10d) are used for the trust region. The dual variables associated with with constraints (10b), (10c), and (10d) are µ ∈ R , ρ ∈ R, and υ ∈ R , respectively. Note that for readability, we omit the contextual variables (w) without loss of generality. When we deal with huge datasets, solving P may be computationally expensive. Therefore, we propose an iterative column selection algorithm (Algorithm 1) that can be used to speed up the optimization while still obtaining a global optima. f( ) + ) − eρ . (13) ¯z ¯z If υ is negative it means that we may improve the incumbent solution of P by including the sample ¯z in Z. Lemma 1. After solving the convex and continuously diﬀerentiable problem P , the sample in I \ I with the most negative reduced cost is a vertex of the convex hull CH(Z). Without a loss of generality, we assume that the constraint (16b) is known a priori, and constraints (16c) are the linear embeddings of learned constraints with A ∈ R and b ∈ R . Constraints (16d-16f) deﬁne the trust region based on N datapoints. Figure 8 shows the computation time required to solve P with diﬀerent values of n, k, and N. The “No Column Selection” approach consists of solving P using the entire dataset. The “Column Selection” approach makes use of Algorithm 1 to solve the problem, starting with |I | = 100, and selecting only one sample at each iteration, i.e., the one with the most negative reduced cost. It can be seen that in all cases, the use of column selection results in signiﬁcantly improved computation times. This allows us to more quickly deﬁne the trust region for problems with large amounts of data. Appendix C: WFP case study Table 7 and Table 8 show the nutritional value of each food and our assumed nutrient requirements, respectively. The values adopted are based on the World Health Organization (WHO) guidelines (UNHCR et al. 2002). C.1. Eﬀect of ensemble violation limit Figure 9 reports the eﬀect of the ensemble violation limit (α) on the objective (Total Cost) and constraint (Palatability) in the WFP case study. As expected, we see a tradeoﬀ between the total cost of the recommended WFP food baskets and the achieved palatability. Higher violation limits (larger α) obtain lower costs at the expense of lower palatability. Lower α values result in more conservative solutions with higher cost but better palatability. This parametrization of individual model violation tolerance allows us to directly quantify this tradeoﬀ and can provide a useful tool in assessing solution alternatives. Appendix D: Chemotherapy regimen design D.1. Data Processing The data for this case study includes three components, study cohort characteristics (w), treatment variables (x), and outcomes (y). The raw data was obtained from Bertsimas et al. (2016), in which the authors manually curated data from 495 clinical trial arms for advanced gastric cancer. Our feature space was processed as follows: DLT = 1 − (1 − t ). We deﬁne Grade 4 blood toxicity as the maximum of ﬁve individual blood toxicities (related to neutrophils, leukocytes, lymphocytes, thrombocytes, anemia). Observations missing all of these toxicities were excluded; entries with partial missingness were imputed using multiple imputation based on other blood toxicity columns. Similarly, observations with no reported Grade 3/4 toxicities were excluded; those with partial missingness were imputed using multiple imputation based on the other toxicity columns. This exclusion criteria resulted in a ﬁnal set of 461 (of 495) treatment arms. We split the data into training/testing sets temporally. The training set consists of all clinical trials through 2008, and the testing set consists of all 2009-2012 trials. We exclude trials from the testing set if they use new drugs not seen in the training data (since we cannot evaluate these given treatments). We also identify sparse treatments (deﬁned as being only seen once in the training set) and remove all observations that include these treatments. The ﬁnal training set consists of 320 observations, and the ﬁnal testing set consists of 96 observations. D.2. Predictive Models Table 9 shows the out-of-sample performance of all considered methods in the model selection pipeline. We note that model choice is based on the 5-fold validation performance, so it does not necessarily correspond to the highest test set performance. D.3. Prescription Evaluation Table 10 shows the performance of the models that comprise the ground truth ensemble used in the evaluation framework. These models trained on the full data. We see that the ensemble models, particularly RF and GBM, have the highest performance. These models are trained on more data and include more complex parameter options (e.g., deeper trees, larger forests) since they are not required to be embedded in the MIO and are rather used directly to generate predictions. For this reason, the GT ensemble could also be generalized to consider even broader method classes that are not directly MIO-representable, such as neural networks with alternative activation functions, providing an additional degree of robustness.