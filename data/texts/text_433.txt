Abstract: N-of-1 trials, single participant trials in which multiple treatments are sequentially randomized over the study period, can give direct estimates of individual-speciﬁc treatment eﬀects. Combining nof-1 trials gives extra information for estimating the population average treatment eﬀect compared with randomized controlled trials and increases precision for individual-speciﬁc treatment eﬀect estimates. In this paper, we present a procedure for designing n-of-1 trials. We formally deﬁne the design components for determining the sample size of a series of n-of-1 trials, present models for analyzing these trials and use them to derive the sample size formula for estimating the population average treatment eﬀect and the standard error of the individual-speciﬁc treatment eﬀect estimates. We recommend ﬁrst ﬁnding the possible designs that will satisfy the power requirement for estimating the population average treatment eﬀect and then, if of interest, ﬁnalizing the design to also satisfy the standard error requirements for the individual-speciﬁc treatment eﬀect estimates. The procedure is implemented and illustrated in the paper and through a Shiny app. Keywords: Multilevel model; N-of-1 trial; Sample size; Shiny app; Treatment eﬀect estimation. In the presence of treatment eﬀect heterogeneity, population average treatment eﬀects from parallel-group randomized controlled trials may not accurately represent the risk to individual participants, making individualized treatment recommendations challenging (Kravitz et al., 2004; Greenﬁeld et al., 2007; Olsen et al., 2007). N-of-1 trials, single participant crossover trials in which multiple treatments are given in sequentially randomized treatment periods (Nikles and Mitchell, 2015), where we refer to a certain length of time where the same treatment is given as a treatment period, have been recommended as suitable designs for estimating individual-speciﬁc treatment eﬀects (Duan et al., 2013). Combining data from a series of n-of-1 trials oﬀers several advantages compared to using data from randomized controlled trials or from a single n-of-1 trial. Firstly, repeated measures on each participant provide more information for estimating population average treatment eﬀects compared to measuring each participant only once in most randomized controlled trials. Secondly, because crossover trials reduce the number of participants needed to achieve the pre-speciﬁed power, a series of n-of-1 trials with multiple crossovers is even more eﬃcient at estimating the population average treatment eﬀect. Lastly, the ability to borrow information from other participants increases the eﬃciency for estimating individual-speciﬁc treatment eﬀects compared to using only data from a single n-of-1 trial (Zucker et al., 2010; Senn, 2019). Designing a series of n-of-1 trials that achieve the desired power for estimating the population average treatment eﬀect, and that, if of interest, satisfy the standard error requirements for the individual-speciﬁc treatment eﬀect estimates requires specifying the sequences with diﬀerent orders of treatments assigned to the treatment periods, the number of participants (or trials; we can refer to trials as participants because n-of-1 trials are single participant trials and we will use “participants” in later development) assigned to each sequence, and the number of measurements in each period. Previous work on estimating sample sizes for n-of-1 trials has been limited. Johannessen and Fosstvedt (1991) derived the power for estimating an individual-speciﬁc treatment eﬀect using a single n-of-1 trial. Senn (2019) presented sample size formulae for estimating the population average treatment eﬀect and variances of individual-speciﬁc treatment eﬀect estimates when combining multiple n-of-1 trials. Both approach assumed speciﬁc orders of treatments assigned to treatment periods in the sequences, one measurement in each period, and independent measurements on each participant. In this paper, we present methods for designing a series of n-of-1 trials. Section 2 deﬁnes the design components for determining the sample size of a series of n-of-1 trials. Section 3 presents models for estimating the population average treatment eﬀect and the individual-speciﬁc treatment eﬀects. Section 4 and 5 derive the sample size formula for estimating the population average treatment eﬀect and the standard error of the individual-speciﬁc treatment eﬀect estimates, respectively. Section 6 provides details about ﬁnding the possible combinations of the design components using the derived formulae. We implement and illustrate the procedure in Section 7 and in a Shiny app described in Section 8. Section 9 summarizes our ﬁndings and points to some future extensions. Let Y be the outcome and let A be the treatment assignment. Figure 1 presents a schematic for the design of a series of n-of-1 trials where the outcome Y is measured repeatedly at times to which treatments are assigned. Let i, i = 1, . . . , I, index the sequences with diﬀerent orders of treatments assigned to treatment periods; let j, j = 1, . . . , J index the K kth treatment period for participant j assigned to sequence i. Therefore, Y on the outcome in the kth treatment period for participant j assigned to sequence i with corresponding treatment assignment A where treatments are assigned to a number of treatment periods in which a number of measurements are taken. The design components consist of: 1) the sequences with diﬀerent orders of treatments assigned to periods in the sequences, which in turn determines the number of sequences I and the number of treatment periods in each sequence K of measurements in each period L I and K We make the following assumptions in our derivations. We assume that there are two treatments in the series of n-of-1 trials and refer to the two treatments as intervention and reference treatment; therefore, let treatment assignment A be an indicator for being assigned to the intervention of interest, taking on value of 1 if assigned to the intervention and 0 if assigned to the reference treatment. We assume that the outcome is continuous. The participants are independent and the repeated measurements on each participant, indexed by k and l, can be correlated. There is no underlying trend in the outcome or carryover eﬀects from one treatment to the other throughout the trials. We now describe the models for estimating treatment eﬀects using n-of-1 trials and start by the naive estimates for estimating the individual-speciﬁc treatment eﬀects, which only use the data from a single treatment periods in sequence i; let l, l = 1, . . . , L, index the Lmeasurements in the because a diﬀerent number of treatment periods leads to a diﬀerent sequence. Figure 1: Indices for measurements in a series of n-of-1 trials. A is the treatment assignment; we present the scenario where there are two treatments in the trials and A is an indicator for being assigned to the intervention of interest. i, j, k and l are used to index the sequences in trials, participants assigned to each sequence, treatment periods in each sequence and measurements in each treatment period, respectively. in sequence i and the number of measurements in the kth treatment period of participant j assigned to sequence i, respectively. participant for estimation, where m, the intercept, is the mean of the responses when given the reference treatment, δ, the slope, is the diﬀerence between the mean responses of the intervention and reference treatments, and  error. The estimate for δ gives the naive estimate for the individual-speciﬁc treatment eﬀect. We specify the variance matrix for the residual error vector to account for the correlation among the repeated measurements on a single participant. Using data from a series of n-of-1 trials, we can model the intercepts and the slopes for each participant with some structure to estimate the population average treatment eﬀect, The intercept µ pooling (i.e., ﬁxed for each participant), 2) partial pooling (i.e., random from a common distribution), or 𝑖 = 1:⋯ and Lare the number of participants assigned to sequence i, the number of treatment periods 3) complete pooling (i.e., common across all participants). We usually do not ﬁt the models with complete pooling of the intercepts because they make the strong assumption that the means of the responses on the reference treatment across the participants are the same, which usually do not hold; we also do not use the models with no pooling of the slopes for estimating the population average treatment eﬀect because they do not give the estimate directly, but if we use the model with no pooling of both intercepts and slopes, we will have the models for each participant giving the naive estimates for the individual-speciﬁc treatment eﬀects. Therefore, four diﬀerent models span the realm of possibilities for estimating the population average treatment eﬀect, where the intercepts can either be ﬁxed or random and the slopes can either be random or common. The estimate for the common slope in the common slope models or for the average of the random slopes in the random-slope models estimates the population average treatment eﬀect. Random slopes are more commonly used in order to allow for heterogeneous treatment eﬀects across participants. They also suggest the shrunken estimates for the individual-speciﬁc treatment eﬀects by borrowing information from other participants in the series of trials. Assuming a common slope implies that the individual-speciﬁc treatment eﬀects are the same in all trials (Jackson et al., 2018). When the number of measurements for each trial is small, one may choose to model the population average treatment eﬀect using a common slope for more stable estimation. While it is common to assume random slopes, assuming random intercepts is more controversial. Some recommend ﬁxed intercepts so that estimation of the intercepts does not bias the estimation of the population average treatment eﬀect or of the shrunken estimates for the individual-speciﬁc treatment eﬀects. Others have produced simulations showing that the use of ﬁxed intercepts may bias downward the maximum likelihood estimate of the variance for the random slopes (Jackson et al., 2018). Random intercepts may also be helpful in cases where the information per trial is weak and ﬁxed intercepts are poorly estimated (e.g., cases where there are a small number of measurements per period). We refer readers to previous studies for details on the use of random or common slopes and the use of ﬁxed or random intercepts (Legha et al., 2018; Riley et al., 2020; White et al., 2019) and will focus on the derivations using all four possible models. In Model (2), participants are assumed to be independent, but repeated measurements on each participant may be correlated. We specify the variance matrix of the residual error vector for each participant to account for the correlation. A general model incorporating ﬁxed or random intercepts, random or common slopes, and a ﬂexible residual error structure on each independent participant is the general linear mixed model Here, Y to sequence i, θ and b matrices for ﬁxed and random eﬀects, respectively, where i = 1, . . . , I and j = 1, . . . J matrix for between-individual errors and Σ Speciﬁcations of Σ measurements on each participant. The illustrations in Section 7 and the Shiny app described in Section 8 implemented commonly-used variance matrices with homogeneous residual errors and independent, exchangeable and ﬁrst order autoregressive (AR-1) correlation structures. Table 1 summarizes the elements in Model (3) for the four possible models that combine ﬁxed or random intercepts with random or common slopes. We denote the ﬁxed and random intercepts as m respectively, and the common and random slopes as δ and δ + γ random components for the random intercepts and slopes, respectively. The standard error for the generalized least squares estimator of the population average treatment eﬀect (Laird and Ware, 1982), where C or the variance for the treatment eﬀect estimate from the corresponding variance matrix; Σ matrix for the outcome vector Y and are the outcome and residual error vectors of lengthPLfor participant j assigned is the contrast matrix that pulls oﬀ the coeﬃcient for treatment eﬀect from the ﬁxed eﬀects vector For a given pre-speciﬁed type I error α, a minimal clinically important treatment eﬀect ∆, and variance matrices for the between-individual errors when applicable, D, and for the within-individual errors, Σ we can achieve power of at least 1 − β for estimating the population average treatment eﬀect by ﬁnding the design components for a series of n-of-1 trials (i.e., the sequences, J condition, where Φ(·) and Z normal distribution, respectively. The ﬁrst term on the right hand side is small and is commonly ignored in practice. The model we propose expands upon that of Senn (2019) in deriving sample sizes for n-of-1 trials in several ways. First, Senn (2019) assumed intervention and reference treatments are randomized to each pair of consecutive treatment periods and that limits the sequences to which participants can be assigned. Second, he worked with the diﬀerences between the outcomes in each pair of consecutive treatment periods where the outcome on each treatment was measured once. Third, he assumed no correlation among the repeated measurements on each participant. In our formulation, we allow more ﬂexible sequences with diﬀerent orders of treatments assigned to the treatment periods, work with outcome measurements directly so the number of measurements in each period can also vary, and allow correlation among the repeated measurements on each participant. We derive the standard error of the individual-speciﬁc treatment eﬀect estimates in this section. Section 5.1 and 5.2 present the standard error of naive and shrunken estimates respectively. To specify the heterogeneous residual error variance and correlation among the repeated measurements on the participant of interest, we write Model (1) in vector notation for participant j iof interest, for whom we will derive the standard error of the naive estimate for the individual-speciﬁc treatment eﬀect, Here, Y to the treatment periods and θ variance and correlation among the repeated measurements on the participant of interest. The standard error of the resulting naive estimate for the individual-speciﬁc treatment eﬀect, where C The naive estimates have limitations which show the advantage of the shrunken estimates. At least two treatments are required to estimate the treatment eﬀect and standard error using the data from a single participant. Additionally, estimating Σ uncertainty (Senn, 2019). Model (2) suggests the shrunken estimate for the individual-speciﬁc treatment eﬀect for a given participant jassigned to sequence i and are the outcome and the residual error vectors, respectively, of lengthPL, is the design matrix with one column for intercept and the other for treatment indicators corresponding = (0, 1). accounts for the additional variation in random treatment eﬀects (Laird and Ware, 1982), is Var( where C with random intercepts (i.e., Random-Random in Table 1); the remaining terms are as deﬁned in Table 1. The square root of the variance gives the standard error for the shrunken estimate. We recommend that practitioners take the following two steps when designing n-of-1 trials. Firstly, use the sample size formula for estimating the population average treatment eﬀect to ﬁnd the possible combinations of the design components that achieve the pre-speciﬁed power requirement; secondly, if they are further interested in estimating the individual-speciﬁc treatment eﬀects, they will ﬁnalize the design by picking the combinations of the design components that also satisfy the standard error requirements for the individualspeciﬁc treatment eﬀect estimates. Illustrations in Section 7 and the Shiny app described in Section 8 will follow these two steps. In this section, we discuss the ways to ﬁnd the possible combinations of the design components using the formulae in Section 4 and 5. Among the design components, the sequences with diﬀerent orders of treatments assigned to periods in the sequences, which in turn determines the number of sequences I and the number of treatment periods in each sequence K each treatment period L the sequences in the series of trials. Sequences can be speciﬁed in two general ways, manually or by randomization. Manual determination usually pre-speciﬁes sequences for a speciﬁc purpose. For example, one might wish to start with a placebo, followed by an intervention and then alternate these two treatments a certain number of times. Or one might constrain the number of times the same treatment could be given consecutively when choosing sequences. We can also follow randomization schemes to determine the sequences. Randomization schemes include is 1 for the model with ﬁxed intercepts (i.e., Fixed-Random in Table 1) and is (0, 1) for the model , the number of participants assigned to each sequence J, and the number of measurements in but are not limited to: 1) alternating sequences, where the two treatments alternate with the ﬁrst period assigned at random, 2) pairwise randomization, randomly allocating the order of the two treatments in each consecutive pair of treatment periods, where we refer to the consecutive pairs of treatment periods as blocks, 3) restricted randomization, randomly assigning treatments in the sequence with the restriction that each treatment is assigned to the same number of periods, or 4) unrestricted randomization, completely randomizing treatments to treatment periods in the sequence (Johannessen and Fosstvedt, 1991). If the number of treatment periods in the sequences are the same (i.e., K derive the number of sequences I from the number of treatment periods K in each sequence following the randomization schemes (Table 2). Except under unrestricted randomization, each treatment is generally assigned to the same number of treatment periods in each sequence so all the sequences in a two treatment design will have an even number of treatment periods. Here, we include odd number of treatment periods for completeness. For odd number of treatment periods in each sequence: 1) under pairwise randomization, we randomly allocate the order of the two treatments in each consecutive pair of periods in the ﬁrst K − 1 periods and randomly assign a treatment to the last period; 2) under restricted randomization, we randomly assign treatments with the restriction that there is only one period diﬀerence between the number of periods assigned with the two treatments, regardless of the direction. Table 2: The number of sequences I under diﬀerent randomization schemes given the number of treatment periods K in the sequence. ”Odd K” and ”Even K” refer to scenarios where there are odd and even number of treatment periods in the sequences respectively. When there are odd number of periods in each sequence: 1) under pairwise randomization, we randomly allocate the order of the two treatments in each consecutive pair of crossover periods in the ﬁrst K − 1 periods and randomly assign a treatment to the last period; 2) under restricted randomization, we randomly assign treatments with the restriction that there is only one period diﬀerence between the number of periods assigned with the two treatments, regardless of the direction. We will be able to determine the number of sequences I and the number of treatment periods K quences are speciﬁed manually and the relationship between I and K when following randomization schemes for designs with the same number of periods across sequences. The next step is to determine the number of participants assigned to each sequence J We focus on balanced designs in which the number of participants assigned to each sequence, J of treatment periods in each sequence, K are the same so that J numbers of treatment periods in the sequences, diﬀerent numbers of participants assigned to the sequences, or diﬀerent numbers of measurements in the treatment periods are much more complex and have more moving parts making optimization diﬃcult. Furthermore, if balance is not desired, the nature of the imbalance is often speciﬁed. It will be possible to ﬁx one or more of the design components and solve a constrained optimization problem. Because both the number of participants, IJ and the number of repeated measurements on each participant, KL, aﬀect the cost and practicality of the series of trials (Senn, 2002), determining J and L once I and K are determined trades oﬀ between the number of participants and the number of repeated measurements per participant. We can therefore ﬁx either KL or IJ and then ﬁnd the other. Speciﬁcally, if we choose to ﬁrst ﬁx KL, I and K are determined when investigators specify sequences manually, and L will be ﬁxed because K is determined; when following randomization schemes we ﬁnd the possible combinations of K and L that lead to the ﬁxed product and I will be determined by K following the relationship in Table 2. We will then be able to calculate the possible values for the number of participants assigned to each sequence, J, using Equation (5) in both scenarios. Alternatively, if we choose to ﬁrst ﬁx IJ, following a similar procedure, we will also be able to calculate the possible values for the last element in this case, the number of measurements in each treatment period, L. These calculations ﬁnd the possible combinations of the design components that satisfy the power requirement for estimating the population average treatment eﬀect. One can then ﬁnalize the design using Equations (6) or (7) to calculate the standard errors of the individualspeciﬁc treatment eﬀect estimates if these are of interest and choose the designs that also achieves the required precision. To illustrate the trade-oﬀs between the number of participants and the number of measurements per participant, we consider a balanced design with pairwise randomization, probably the most common type of n-of-1 design. In balanced designs, the dimensions of within-individual error variance matrices, Σ the same across participants. We assume that the variance matrices do not vary by participants and equal to Σ structure with a correlation coeﬃcient of 0.4. We set a minimal clinically important treatment eﬀect of . Additionally, the residual errors are homogeneous with a variance of 4 and have an AR-1 correlation ∆ = 1, Type I error rate of α = 0.05 and Type II error rate of β = 0.2. When applicable in the model, the variance of the random intercepts (σ random intercepts and the random slopes (σ random slopes is 0.5). Figure 2 shows the change in the average required number of measurements across a series of n-of-1 trials (IJKL) as a function of the number of measurements per participant (KL, left) and the number of participants (IJ, right) for optimized designs when ﬁxed-intercept models are used for estimating the population average treatment eﬀect. Optimized designs refer to designs that achieve criteria with the smallest possible value of the last element with all the other elements in I, J, K and L ﬁxed. For example, if given the number of sequences I, the number of participants assigned to each sequence J, and the number of treatment periods in each sequence K, a design with L ≥ 5 measurements in each treatment period will achieve the pre-speciﬁed power, the design with L = 5 measurements in each treatment period will be the optimized design and will be presented. Analogous optimization applies if I, J or K is the last component. The shaded area around the lines represent the range of the required number of measurements across trials from diﬀerent combinations of K and L (left) and of I and J (right) that lead to the same product and the dots on the lines represent the average if there are multiple combinations. As Appendix S.2.1 shows that the form of intercepts has almost no eﬀect on the optimized designs for estimating the population average treatment eﬀect, we show results from models with ﬁxed intercepts and by the form of slopes. Legha et al. (2018) also reported that using restricted maximum likelihood to estimate the population average treatment eﬀect, which gives unbiased estimates of the variances compared with our assumed known variances, the coverage for the eﬀect estimate with ﬁxed or random intercepts are very similar for continuous outcomes. In general, the required number of measurements across a series of n-of-1 trials is larger when we use the average of random slopes to estimate the population average treatment eﬀect compared to when using a common slope for estimation because the random slope model contains an extra source of variability from the between-individual variance. Additionally, the required number of measurements across trials stays stable with increasing number of measurements per participant when a common slope is used for estimation, while that increases when we allow random eﬀects around the slope; the required number of measurements across trials decreases with increasing number of participants for models with either form of slopes and the decreasing rate is faster when the random-slope model is used for estimation, which leads to the decreasing discrepancy between the required number of measurements across trials for the common- and random-slope model with more participants in Figure 2: Average required number of measurements across a series of n-of-1 trials versus number of measurements per participant (KL, left) and number of participants (IJ, right) for optimized designs when ﬁxed-intercept models are used for estimating the population average treatment eﬀect. “Common Slope” and “Random Slopes” refer to “Fixed-Common” and “Fixed-Random” models in Table 1, respectively. Number of measurements per participantNumber of participants trials. These results are consistent with those in Senn (2019). There, in a special case of our model described earlier (trials with independent repeated measurements on each participant, one measurement per treatment period and the same number of periods for the two treatments in the sequence), the required number of measurements across trials varied little with the number of measurements per participant for the common eﬀect approach but increased for the random-eﬀect approach. The discrepancy between the required number of measurements per participant for the two approaches also decreased with more participants in trials. Figure 3 shows the standard errors of the naive and shrunken estimates for individual-speciﬁc treatment eﬀects versus the number of measurements per participant given the number of participants (ﬁxed at 32, left) and versus the number of treatment periods in the sequence further given the number of measurements per participant (ﬁxed at 24, right) for all possible designs that satisfy the power requirement for estimating population average treatment eﬀect. The shaded areas around the lines represent the range of standard errors from diﬀerent combinations of K and L that lead to the same product (left) and from trials with the same number of treatment periods but with diﬀerent orders of treatments assigned to the periods (right) and the dots on the lines represent the average if there are multiple combinations. Note that all possible designs for the series of n-of-1 trials are plotted in the ﬁgure because as described in Section 6 in practice, after using Figure 2 to ﬁnd designs that satisfy the power requirement for estimating the population average treatment eﬀect, we want to further use Figure 3 to ﬁnalize the design by picking from all the possible designs that satisfy both the power requirement for estimating population average treatment eﬀect and the standard error requirement for estimating the individual-speciﬁc treatment eﬀect. For example, if the required total number of measurements is reasonable when we recruit 32 participants in a series of n-of-1 trials in Figure 2 and we require the standard error of the shrunken estimates with ﬁxed intercepts for individual-speciﬁc treatment eﬀects to be lower than 1, all the designs on the “Shrunken Estimates-Fixed Intercepts” curve in Figure 3 will satisfy the requirement. Additionally, if we are able to measure the outcome 24 times on each participant, Figure 3 (right) gives all the possible designs. A speciﬁc design can be a series of trials with I = 4 possible sequences, J = 8 participants assigned to each sequence, K = 4 treatment periods per sequence, and L = 6 measurements per treatment period. Detailed information for all the possible designs is given in the Shiny app (part (e) in Figure 4). As expected, the results in Figure 3 show the advantage of shrunken estimates over naive estimates for estimating individual-speciﬁc treatment eﬀect. Given ﬁxed number of participants, the standard error of naive estimates is larger than that of shrunken estimates. The diﬀerence decreases with increasing number of measurements per participant, but even then the standard errors for naive estimates are larger. Naive Figure 3: Standard error of naive and shrunken estimates for individual-speciﬁc treatment eﬀect versus number of measurements per participant given total number of participants across trials (ﬁxed at 32, left) and versus number of treatment periods per sequence further given number of measurements per participant (ﬁxed at 24, right) for all possible designs that satisfy the power requirement for estimating population average treatment eﬀect. “Naive Estimates”, “Shrunken Estimates-Fixed Intercepts” and “Shrunken EstimatesRandom Intercepts” refer to the standard error of naive estimates, shrunken estimates in the ﬁxed- and random-intercept model, respectively. estimates beneﬁt more from larger number of treatment periods in the sequence when we further ﬁx the number of measurements on each participant, with a larger drop in standard error when we increase the number of treatment periods in the sequence compared to shrunken estimates. We also found in Figure 3 that the standard error of the shrunken estimates in the random-intercept model is slightly smaller than that in the ﬁxed-intercept model. To evaluate the sensitivity of the results to the varying parameters, Appendix S.2 includes the following additional illustrations: • Appendix S.2.2 presents results where we use alternative values for the type I and II errors. The • Appendix S.2.3 presents results with alternative parameterizations for the residual error variance ma- • Appendix S.2.4 presents results with alternative parameterizations for the random-eﬀect variance maaverage required number of measurements across trials increases with smaller type I and II errors; the rate of increase is higher if 1) we want to reduce smaller type I and II errors, 2) the number of measurements per participant is larger, and 3) the number of participants in trials is smaller. trix. We show results assuming 1) independent and exchangeable correlation structure, and diﬀerent values for 2) the homogeneous residual error variance and 3) residual correlation coeﬃcient under ﬁrst order autoregressive correlation structure. Trials with exchangeable correlation structure require the fewest measurements across trials, followed by independent correlation structure. Under ﬁrst order autoregressive correlation structure, the required number of measurements across trials 1) is similar to that under exchangeable correlation structure when the number of measurements per participant is small and the correlation coeﬃcient is large, 2) becomes larger than that under independent correlation structure when the number of measurements per participant is large and the correlation coeﬃcient is small, and 3) increases linearly with homogeneous variance and the rate of increase is higher when the number of measurements per participant is larger and when the number of participants in trials is smaller. trix. Variance of random intercepts and correlation between random intercepts and slopes do not aﬀect the optimized designs that satisfy the power requirement. Holding the number of measurements per participant the same, the average required number of measurements across trials increases linearly with the variance of random slopes; the rate of increase is larger when the number of measurements per participant is larger. Holding the number of participants the same, the average required number of measurements across trials increases more at larger values for the variance of random slopes. • Appendix S.2.5 presents results with alternative minimal clinically important treatment eﬀects. The We implemented our methods in a Shiny app to allow investigators to design n-of-1 trials interactively without requiring programming knowledge or familiarity with a speciﬁc software. The Shiny app is available at http://jiabeiyang.shinyapps.io/SampleSizeNof1/. Figure 4 presents the layout of the Shiny app, where we replicated Figure 2 (right) and 3 in Section 7. In Figure 4, part (a) shows the input panel of the app, where investigators are allowed to specify the parameters for designing the series of n-of-1 trials. Part (b)-(e) present information for the possible designs that will satisfy the power and standard error requirements speciﬁed by the investigators. Part (b) presents the speciﬁed parameters in the input panel and how the average required number of measurements across trials changes as a function of the number of participants for optimized designs (Figure 2, right). Part (c) and (d) show the detailed design information for optimized designs and the standard errors of the individual-speciﬁc treatment eﬀect estimates for all possible designs that satisfy the power requirement (Figure 3), respectively, when one ﬁxes the number of participants across trials by clicking on a speciﬁc point in the ﬁgure in part (b). Part (e) shows the detailed information for all possible designs that satisfy the power and standard error requirements when one further ﬁxes the number of measurements per participant by clicking on a point in the ﬁgure in part (d). If investigators want to know how the average required number of measurements across trials changes as a function of the number of measurements per participant (Figure 2, left), they can choose “Total # of measurements vs. # of measurements per participant” under ”Design option” in the input panel. The output in part (d) of the Shiny app will be replaced accordingly by presenting the standard errors versus the number of participants in the trials given the number of measurements per participant. The Shiny app implements both alternating sequences and pairwise randomization and also allows the user to upload manually speciﬁed sequences through “Possible sequences”-“User-speciﬁed sequences” in the input panel. Because the number of possible sequences under restricted and unrestricted randomization becomes large as the number of treatment periods in the sequences increases (Table 2) and many sequences may be required number of measurements across trials increases with smaller minimal clinically important treatment eﬀect; the rate of increase is higher if 1) we want to reduce a smaller minimal clinically important treatment eﬀect, 2) the number of measurements per participant is larger, and 3) the number of participants in trials is smaller. Figure 4: Screenshot of Shiny app. Part (a) allows investigators to specify parameters for designing the series of n-of-1 trials; part (b)-(e) present the possible designs that satisfy the power and standard error requirements speciﬁed by the investigators. impractical if the same treatment is given in too many consecutive treatment periods, users can complete calculations for these two randomization schemes by picking speciﬁc sequences of interest and uploading them through “User-speciﬁed sequences”. Additionally, we provide an option to only optimize designs over the scale of the y-axis in part (b) of the Shiny app. Because of the current optimization, even if we allow large number of participants in the trials, the maximum number of participants presented in part (b) of the Shiny app will be small because designs with more participants are not optimized using our deﬁnition of optimized designs. Therefore, this option will present all the possible designs within the speciﬁed range for the x-axis, only optimized on the scale of the y-axis. Finally, if investigators are not interested in estimating the individual-speciﬁc treatment eﬀects, they can clear “Calculate standard error for individual-speciﬁc treatment eﬀect estimates” and only part (b) and (c) will be displayed in the output. We present a procedure for calculating the sample size for n-of-1 trials. We formally deﬁne the design components for determining the sample size of a series of n-of-1 trials which include the sequences with diﬀerent orders of treatments assigned to periods in the sequences, the number of participants assigned to each sequence, and the number of measurements in each treatment period. We present models for analyzing n-of-1 trials and use them to derive the required sample size for estimating population average treatment eﬀect and the standard error of individual-speciﬁc treatment eﬀect estimates. We recommend that investigators ﬁrst use the sample size formula to ﬁnd the possible combinations of the design components that will satisfy the power requirement for estimating the population average treatment eﬀect, and, if of interest, use the standard error formulae to pick the combinations of design components that will also satisfy the standard error requirements for the individual-speciﬁc treatment eﬀect estimates. We implement and illustrate the procedure in the paper and through a Shiny app. Several directions of future research are practically useful. First, the current derivations assume that the variance components, either for residual errors or for random eﬀects, are known or estimated with adequate precision. Taking into account the fact that the variance components are estimated will involve using a distribution instead of the standard normal distribution when deriving power in Section 4 and will facilitate more accurate planning of the n-of-1 trials. Second, it will be helpful to extend the results to discrete outcomes, although correlation among the repeated measurements would then need to be handled diﬀerently (Zeger, 1988). Additionally, it will be valuable to extend the results to trials with more than two treatments (Kravitz et al., 2020) and with multiple outcomes of interest (Barr et al., 2015). Lastly, to avoid carryover eﬀects, we can introduce washout periods into the derivations when switching from one treatment to another. These periods will limit the number of switches between diﬀerent treatments in the sequences. The R code for illustrations and the Shiny app and an example input ﬁle for the Shiny app are available on http://github.com/jiabei-yang/SampleSizeNof1. The Shiny app is hosted at http://jiabeiyang. shinyapps.io/SampleSizeNof1/.