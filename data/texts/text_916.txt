Diﬀerences-in-diﬀerences (DiD) is one of the most popular methods in the social sciences for estimating causal eﬀects in non-experimental settings. The last few years have seen a dizzying array of new methodological papers on DiD and related designs, making it challenging for practitioners to keep up with rapidly evolving best practices. Furthermore, the recent literature has addressed a variety of diﬀerent components of diﬀerence-in-diﬀerences analyses, which has made it diﬃcult even for experts in the ﬁeld to understand how all of the new developments ﬁt together. In this paper, we attempt to synthesize some of the recent advances on DiD and related designs and to provide concrete recommendations for practitioners. two time periods are available, there is a treated population of units that receives a treatment of interest beginning in the second period, and a comparison population that does not receive the treatment in either period. The key identifying assumption is that the average outcome among the treated and comparison populations would have followed “parallel trends” in the absence of treatment. We also assume that the treatment has no causal eﬀect before its implementation (no anticipation). Together, these assumptions allow us to identify the average treatment eﬀect on the treated (ATT). If we observe a large number of independent clusters from the treated and comparison populations, the ATT can be consistently estimated using a two-way ﬁxed eﬀects (TWFE) regression speciﬁcation, and clustered standard errors provide asymptotically valid inference. DiD setup. The recent wave of DiD papers have each typically focused on relaxing one or two of the key assumptions in the canonical framework while preserving the others. We taxonomize the recent DiD literature by characterizing which of the key assumptions in the canonical model are relaxed. We focus on recent advances that piq allow for multiple periods and variation in treatment timing (Section 3); piiq consider potential violations of parallel trends (Section 4); or piiiq depart from the assumption of observing a sample of many independent clusters sampled from a super-population (Section 5). Section 6 brieﬂy summarizes some other areas of innovation. In what follows, we brieﬂy describe each of these strands of literature. literature has focused on settings where there are more than two time periods and units are treated at diﬀerent point in times. Multiple authors have noted that the coeﬃcients from standard TWFE models may not represent a straightforward weighted average of unit-level treatment eﬀects when treatment eﬀects are allowed to be heterogeneous across time or units. In short, TWFE regressions make both “clean” comparisons between treated and not-yettreated units as well as “forbidden” comparisons between units who are both already-treated. When treatment eﬀects are heterogeneous, these “forbidden” comparisons potentially lead to severe drawbacks such as TWFE coeﬃcients having the opposite sign of all individual-level treatment eﬀects due to “negative weighting” problems. Even if all of the weights are positive, the weights “chosen” by TWFE regressions may not correspond with the most policy-relevant parameter. Our starting point in Section 2 is the “canonical” diﬀerence-in-diﬀerences model, where In practice, DiD applications typically do not meet all of the requirements of the canonical Multiple periods and variation in treatment timing: One strand of the DiD to bypass the limitations associated with TWFE regressions and identify/estimate causal parameters of interests under rich sources of treatment eﬀect heterogeneity. These procedures rely on generalizations of the parallel trends assumption to the multi-period setting. A common theme is that these new estimators isolate “clean” comparisons between treated and not-yet-treated groups, and then aggregate them using user-speciﬁed weights to estimate a target parameter of economic interest. We discuss diﬀerences between some of the recent proposals — such as the exact comparison group used and the generalization of the parallel trends assumption needed for validity — and provide concrete recommendations for practitioners. We also brieﬂy discuss extensions to more complicated settings such as when treatments turn on-and-oﬀ over time or are non-binary. that the parallel trends assumption may be violated. One set of papers considers the setting where parallel trends holds only conditional on observed covariates, and proposes new estimators that are valid under a conditional parallel trends assumption. However, even if one conditions on covariates, there are often concerns that the necessary parallel trends assumption may be violated due to time-varying confounding factors. It is therefore common practice to test for pre-treatment diﬀerences in trends (“pre-trends”) as a test of the plausibility of the (conditional) parallel trends assumption. While intuitive, researchers have identiﬁed at least three issues with this pre-testing approach. First, the absence of a signiﬁcant pre-trend does not necessarily imply that parallel trends holds; in fact, these tests often have low power. Second, conditioning the analysis on the result of a pre-test can introduce additional statistical distortions from a selection eﬀect known as pre-test bias. Third, if a signiﬁcant diﬀerence in trends is detected, we may still wish to learn something about the treatment eﬀect of interest. there is concern that parallel trends may be violated. One class of solutions involves modiﬁcations to the common practice of pre-trends testing to ensure that the power of pre-tests is high against relevant violations of parallel trends. This can be done either by running power calculations for economically-relevant violations of parallel trends, or using a “noninferiority” approach that reverses the role of the null and alternative hypotheses so that the pre-test only “passes” if there is evidence that the pre-trend is small. A second class of solutions has proposed methods that remain valid under certain types of violations of parallel trends, such as when the post-treatment violation of parallel trends is assumed to be no larger than the maximal pre-treatment violation of parallel trends, or when there are non-treated groups that are known to be more/less aﬀected by the confounds as the treated We discuss a variety of straightforward-to-implement strategies that have been proposed Non-parallel trends: A second strand of the DiD literature focuses on the possibility Several recent papers have therefore suggested alternative methods for settings where group. These approaches allow for a variety of robustness and sensitivity analyses which are useful in a wide range of empirical settings, and we discuss them in detail. alternatives to the classical “sampling-based” approach to inference with a large number of clusters. One topic of interest is inference procedures in settings with a small number of treated clusters. Standard cluster-robust methods assume that there is a large number of both treated and untreated clusters, and thus can perform poorly in this case. A variety of alternatives with better properties have been proposed for this case, including permutation and bootstrap procedures. These methods typically either model the dependence of errors across clusters, or alternatively place restrictions on the treatment assignment mechanism. We brieﬂy highlight these approaches and discuss the diﬀerent assumptions needed for them to perform well. for DiD. Canonical approaches to inference view the randomness in the data as coming from the fact that the observed data is drawn from a super-population of units. However, this super-population view may be unnatural in DiD settings where all units in the population are observed, such as when we have data on all 50 US states or administrative data on a full population. Design-based approaches to uncertainty instead view the population as ﬁxed and the assignment of treatment as stochastic. Although design-based approaches have typically been employed in the case of randomized experiments, recent work has extended this to the case of “quasi-experimental” strategies like DiD. Luckily, the message of this literature is positive, in the sense that methods that are valid from the canonical sampling-based view are typically also valid from the design-based view as well. The design-based approach to inference helps to overcome conceptual issues related to deﬁning the super-population, and can also be useful for determining the appropriate level of clustering of standard errors. A useful rule of thumb implied by this approach is that it is typically appropriate to cluster at the level at which treatment is independently assigned. Other topics: We conclude by brieﬂy touching on some other areas of focus within the DiD literature, as well as highlighting some areas for future research. Example include using DiD to estimate distributional treatment eﬀects; settings with quasi-random treatment timing; spillover eﬀects; estimating heterogeneous treatment eﬀects; and connections between DiD and other panel data methods. and precision in a researcher’s discussion of his or her assumptions, comparison group and time frame selection, causal estimands, estimation methods, and robustness checks. When Alternative sampling assumptions: A third strand of the DiD literature discusses Another direction that has been explored relates to conducting “design-based” inference Overall, the growing DiD econometrics literature emphasizes the importance of clarity used in combination with context-speciﬁc information, these new methods can both improve the validity and interpretability of DiD results and more clearly delineate their limitations. clean presentation of some of the most important directions the literature has gone. Wherever possible, we try to give clear practical guidance for applied researchers, concluding each section with practical recommendations for applied researchers. For reference, we include Table 1, which contains a checklist for a practitioner implementing a DiD analysis, and Table 2, which lists R and Stata packages for implementing many of the methods described in this paper. This section describes a simple two-period setting in which the econometrics of DiD are wellunderstood. Although this “canonical” setting is arguably too simple for most applications, clearly articulating the assumptions in this setup serves as a useful baseline for understanding recent innovations in the DiD literature. Consider a model in which there are two time periods, t “ 1, 2. Units indexed by i are drawn from one of two populations. Units from the treated population pD treatment of interest between period t “ 1 and t “ 2, whereas units from the untreated (a.k.a. comparison or control) population pD The econometrician observes an outcome Y i “ 1, ..., N and t “ 1, 2. Although DiD methods also accommodate the case where only repeated cross-sectional data is available, or where the panel is unbalanced, we focus on the simpler setup with balanced panel data for ease of exposition. We adopt a potential outcomes framework for the observed outcome, as in, e.g., Rubin (1974) and Robins (1986). Let Y untreated in both periods. Likewise, let Y t if i is untreated in the ﬁrst period but exposed to treatment by the second period. To simplify notation we will write Y for our later discussion to make clear that these potential outcomes in fact correspond with a path of treatments. As is usually the case, due to the fundamental problem of causal Given the vast literature on DiD, our goal is not to be comprehensive, but rather to give a inference (Holland, 1986), we only observe one of the two potential outcomes for each unit i. That is, the observed outcome is given by Y outcomes framework implicitly encodes the stable unit treatment value assumption (SUTVA) that unit i’s outcomes do not depend on the treatment status of unit j ‰ i, which rules out spillover eﬀects. ment eﬀect on the treated (ATT) in period t “ 2, It simply measures the average causal eﬀect on treated units in the period that they are treated (t “ 2). The challenge in identifying τ observed for the treated group (D identiﬁcation challenge via assumptions that allow us to impute the mean counterfactual untreated outcomes for the treated group by using (1) the change in outcomes for the untreated group and (2) the baseline outcomes for the treated group. The key assumption for identifying τ come for the treated and untreated populations would have evolved in parallel if treatment had not occurred. Assumption 1 (Parallel Trends). model for the untreated potential outcomes. If Y independent of D assigned non-randomly based on characteristics that aﬀect the level of the outcome pα requires the treatment assignment to be mean-independent of variables that aﬀect the trend in the outcome ( but the bias from selecting into treatment must be the same in period t “ 1 as it is in period t “ 2. no-anticipation assumption, which states that the treatment has no causal eﬀect prior to its The causal estimand of primary interest in the canonical DiD setup is the average treat- The parallel trends assumption can be rationalized by imposing a particular generative Another important and often hidden assumption required for identiﬁcation of τis the implementation. This is important for identiﬁcation of τ outcome for the treated group between period 1 and 2 could reﬂect not just the causal eﬀect in period t “ 2 but also the anticipatory eﬀect in period t “ 1 (Abbring and van den Berg, 2003; Malani and Reif, 2015). Assumption 2 (No anticipatory eﬀects). Y identiﬁed. To see why this is the case, observe that by re-arranging terms in the parallel trends assumption (see equation (1)), we obtain Further, by the no anticipation assumption, E rY lows that where the second equality uses the fact that we observe Y p1q for treated units and Y p0q for untreated units. The previous display shows that we can infer the counterfactual average outcome for the treated group by taking its observed pre-treatment mean and adding the change in mean for the untreated group. Since we observe Y p1q for the treated group directly, it follows that τ i.e. the “diﬀerence-in-diﬀerences” of population means! Equation (2) gives an expression for τ expectations. Therefore, a natural way to estimate τ sample analogs, where Y Under the parallel trends and no-anticipation assumptions, the ATT in period 2 (τ) is puting pτ eﬀects (TWFE) regression speciﬁcation which regresses the outcome Y interaction of a post-treatment indicator with treatment status. setup, it is straightforward to show that the ordinary least squares (OLS) coeﬃcient equivalent to pτ ﬁdence intervals of τ independent sampling. Assumption 3. Let W for unit i. We observe a sample of N i.i.d. draws W parallel trends. in the asymptotic as N Ñ 8 and T is ﬁxed. The variance σ standard clustering methods that allow for arbitrary serial correlation at the unit level (Liang and Zeger, 1986; Arellano, 1987; Wooldridge, 2003; Bertrand, Duﬂo and Mullainathan, 2004). The same logic easily extends to cases where units are clustered within independent clusters (e.g. states), and the standard errors are clustered at the appropriate level, provided that the number of treated and untreated clusters both grow large. Constructing consistent point estimates and asymptotically valid conﬁdence intervals is thus straightforward via OLS. the ways that diﬀerent strands of the recent DiD have relaxed each of these components. Although these sample means could be computed “by hand”, an analogous way of com, which facilitates the computation of standard errors, is to use the two-way ﬁxed OLS estimates ofpβ from (3) provide consistent estimates and asymptotically valid con- Under Assumptions 1-3 and mild regularity conditions, Having introduced all of the components of the “canonical” DiD model, we now discuss Several recent papers have focused primarily on relaxing the baseline assumptions about treatment assignment and timing discussed in Section 2. A topic of considerable attention has been settings where there are more than two periods, and units adopt a treatment of interest at diﬀerent points in time. For instance, diﬀerent states may enact a particular type of legislation at diﬀerent points in time. We provide an overview of some of the key developments in the literature, and refer the reader to the review by de Chaisemartin and D’Haultfœuille (2021a) for additional details. Several recent papers have focused on relaxing the timing assumptions discussed in Section 2, while preserving the remaining structure of the stylized model (i.e., parallel trends, no anticipation, and independent sampling). Since most of the recent literature considers a setup in which treatment is an absorbing state, we start with that framework; in Section 3.4, we discuss extensions to the case where treatment can turn on and oﬀ or is non-binary. We introduce the following assumptions and notation, which captures the primary setting studied in this literature. Treatment timing. There are T periods indexed by t “ 1, ..., T , and units can receive a binary treatment of interest in any of the periods. Treatment is an absorbing state, so that once a unit is treated they remain treated for the remainder of the panel. We denote by D an indicator for whether unit i receives treatment in period t, and G the earliest period at which unit i has received treatment. If i is never treated during the sample, then G deﬁne R treated period for unit i. Potential outcomes. We extend the potential outcomes framework introduced above to the multi-period setting. Let 0 respectively. We denote unit i’s potential outcome in period t if they were ﬁrst treated at time g by Y This notation again makes explicit that potential outcomes can depend on the entire path of treatment assignments. Since we have assumed that treatment “stays on” once it is turned on, the entire path of potential outcomes is summarized by the ﬁrst treatment date pgq, and so to simplify notation we can index potential outcomes by treatment starting time: Ypgq “ Y Parallel trends. There are several ways to extend the canonical parallel trends assumption to the staggered setting. The simplest extension of the parallel trends assumption to the staggered case requires that the two-group, two-period version of parallel trends holds for all combinations of periods and all combinations of “groups” treated at diﬀerent times. Assumption 4 (Parallel trends for staggered setting). For all t ‰ t This assumption imposes that in the counterfactual where treatment had not occurred, the outcomes for all adoption groups would have evolved in parallel. Callaway and Sant’Anna (2021) consider a relaxation of Assumption 4 that imposes (4) only for pairs of groups and time periods such that at least one of the groups has already been treated. Likewise, several papers, including Callaway and Sant’Anna (2021) and Sun and Abraham (2021), consider versions that impose (4) only for groups that are eventually treated, and not for the never-treated group pg “ 8q. There are tradeoﬀs between the diﬀerent forms of Assumption 4: imposing parallel trends for all groups and all periods is a stronger assumption and thus may be less plausible; on the other hand, it may allow one to obtain more precise estimates. estimators for the staggered case below. No anticipation. The no-anticipation assumption from the canonical model also extends in a straightforward way to the staggered setting. Intuitively, it imposes that if a unit is untreated in period t, their outcome does not depend on what time period they will be treated in the future. Several variants of Assumption 4 have been considered in the literature. For example, Recall that in the simple two-period model, the estimand (population coeﬃcient) of the two-way ﬁxed eﬀects speciﬁcation (3) corresponds with the ATT under the parallel trends assumption. A substantial focus of the recent literature has been whether the estimand of commonly-used generalizations of this TWFE model to the multi-period, staggered timing case have a similar, intuitive causal interpretation. In short, the literature has shown that the estimand of TWFE speciﬁcations in the staggered setting often does not correspond with an intuitive causal parameter even under the natural extensions of the parallel trends and no-anticipation assumptions described above. Static TWFE. We begin with a discussion of the “static” TWFE speciﬁcation, which regresses the outcome on individual and period ﬁxed eﬀects and an indicator for whether the unit i is treated in period t, treatment eﬀects across either time or units. Formally, let τ that for all units i, τ same treatment eﬀect, and (2) the treatment has the same eﬀect regardless of how long it has been since treatment started. Then, under a suitable generalization of the parallel trends assumption (e.g. Assumption 4) and no anticipation assumption (Assumption 5), the population regression coeﬃcient β ment eﬀects across either time since treatment or across units, as shown in Borusyak and Jaravel (2018), de Chaisemartin and D’Haultfœuille (2020b), and Goodman-Bacon (2021), among others. Suppose ﬁrst that there is heterogeneity in time since treatment only. That is, τ after they receive treatment. In this case, β weighted average of the parameters τ but may be negative. The possibility of negative weights is concerning because, for instance, all of the τ longer-run treatment eﬀects will often receive negative weights. Likewise, if treatment eﬀects diﬀer across units but are constant across time, i.e. τ be a non-convex weighted average of the individual level eﬀects τ The static speciﬁcation yields a sensible estimand when there is no heterogeneity in Issues arise with the static speciﬁcation, however, when there is heterogeneity of treatpgq “τ1rt ´ g “ ss, so all units have treatment eﬀect τin the s-th period there is heterogeneity both across units and time since treatment. He shows that comparisons between pairs of units and time periods in which one unit changed its treatment status and the other did not. Counterintuitively, however, this decomposition includes diﬀerence-in-diﬀerences that use as a “control” group units who were treated in earlier periods. Hence, an early-treated unit can get negative weights if it appears as a “control” for many later-treated units. This decomposition further highlights that β sensible estimand when treatment eﬀects diﬀer across either units or time, because of its inclusion of “forbidden comparisons”. speciﬁcation with heterogeneity. From the Frisch-Waugh-Lovell theorem, the coeﬃcient β from (5) is equivalent to the coeﬃcient from a univariate regression of Y (5), D its predictions may fall outside the unit interval. If the predicted value 1, then D will get negative weight in univariate OLS coeﬃcients to obtain that The denominator is positive, and so the weight that because Y sample. To see why this is the case, we note that some algebra shows that where D sectional average of D for period t, and D “ pNT q periods and units. It follows that if we have a unit that has been treated for almost all periods (D non-treated units in some period pD ă 1q. We thus see that Goodman-Bacon (2021) provides some helpful intuition to understand this phenomenon. We now give some more mathematical intuition for why weighting issues arise in the static is the predicted value from a regression of Don the other right-hand side variables in “ ˜α`˜φ`u. However, a well-known issue with OLS with binary outcomes is that ´pD. Thus, if Dą 0 and D´pDă 0, thenpβwill be decreasing in Y. But These negative weights will tend to arise for early-treated units in periods late in the “ TDis the time average of D for unit i, D“ NDis the cross- « 2 ´D, which will be strictly greater than 1 if there is a non-substantial fraction of weight on τ clear that the static OLS coeﬃcient and thus will not produce a sensible estimand when there is arbitrary heterogeneity. When treatment eﬀects are homogeneous – i.e. τ units cancel out the positive weights on other units, and thus β under a suitable generalization of parallel trends. Dynamic TWFE. Next, we turn our attention to the “dynamic speciﬁcation” that regresses the outcome on individual and period ﬁxed eﬀects, as well as dummies for time relative to treatment mand when there is heterogeneity only in time since treatment. In particular, the results in Borusyak and Jaravel (2018) and Sun and Abraham (2021) imply that if τ then β sumption 4. treatment eﬀects across adoption cohorts, the coeﬃcients from speciﬁcation (7) become difﬁcult to interpret. There are two issues. First, as with the “static” regression speciﬁcation above, the coeﬃcient β treatment for some units. Second, the coeﬃcient β eﬀects at lags r dynamic speciﬁcation thus fails to yield sensible estimates of dynamic causal eﬀects under heterogeneity across cohorts. The derivation of this result is mathematically more complex, and so we do not pursue it here. The intuition is that, as in the static case, the dynamic OLS speciﬁcation does not aggregate natural comparisons of units and includes “forbidden comparisons.” An important implication of the results derived by Sun and Abraham (2021) is that if treatment eﬀects are heterogeneous, the “treatment lead” coeﬃcients from (7) are not guaranteed to be zero even if parallel trends is satisﬁed in all periods, and thus evaluation of pre-trends based on these coeﬃcients can be very misleading. Unlike the static speciﬁcation, the dynamic speciﬁcation yields a sensible causal estiτ1rt ´ g “ ss, so all units have treatment eﬀect τin the s-th period after treatment, “ τunder a suitable generalization of the parallel trends assumption such as As- Several recent papers introduce diagnostic approaches for understanding the extent of the aggregation issues under staggered treatment timing, with a focus on the static speciﬁcation (5). de Chaisemartin and D’Haultfœuille (2020b) propose reporting the degree of heterogeneity in treatment eﬀects that would be necessary for the estimated treatment eﬀect to have the “wrong sign.” Goodman-Bacon (2021) proposes reporting the weights that on the diﬀerent 2-group, 2-period diﬀerence-in-diﬀerences, which allows one to evaluate how much weight is being placed on “forbidden” comparisons of already-treated units and how removing the comparisons would change the estimate. Jakiela (2021) proposes evaluating both whether TWFE places negative weights on some treated units and whether the data rejects the constant treatment eﬀects assumption. Several recent papers have proposed alternative estimators that more sensibly aggregate heterogeneous treatment eﬀects in settings with staggered treatment timing. The derivation of each of these estimators follows a similar logic to the derivation of the DiD estimator in the motivating example in Section 2. We begin by specifying a causal parameter of interest (analogous to the ATT τ anticipation assumptions, we can infer the counterfactual outcomes for treated units using trends in outcomes for an appropriately chosen “clean” control group of untreated units. This allows us to express the target parameter in terms of identiﬁed expectations, analogous to equation (2). Finally, we replace population expectations with sample averages to form an estimator of the target parameter. discuss the connections to other approaches. They consider as a building block the grouptime average treatment eﬀect on the treated, AT T pg, tq “ E rY gives the average treatment eﬀect at time t for the cohort ﬁrst treated in time g. They then consider identiﬁcation and estimation under generalizations of the parallel trends assumption such as Assumption 4 and variants thereof. trends) and 5 (no anticipation), we can identify AT T pg, tq by comparing the expected change in outcome for cohort g between periods g´1 and t to that for a control group not-yet treated We describe in detail the approach taken by Callaway and Sant’Anna (2021), and then at period t. Formally, which can be viewed as the multi-period analog of the identiﬁcation result in equation (2). Since this holds for any comparison group g comparisons G such that g Speciﬁcally, Callaway and Sant’Anna (2021) consider two options for G. The ﬁrst uses only never-treated units (G “ t8u) and the second uses all not-yet-treated units (G “ tg tu). When there are a relatively small number of periods and treatment cohorts, reporting zAT T pg, tq for all relevant pg, tq may be reasonable. may be cumbersome, and each one may be imprecisely estimated. Thankfully, the method described above extends easily to estimating any weighted average of the AT T pg, tq. For instance, we may be interested in an “event-study” parameter that gives the (weighted) average of the treatment eﬀect l periods after adoption across diﬀerent adoption cohorts, The weights w frequencies in the treated population. It is straightforward to form estimates for AT T by averaging the estimates and Sant’Anna (2021) for a discussion of a variety of other weighted averages that may be economically relevant. Inference is straightforward using either the delta method or a bootstrap, as described in Callaway and Sant’Anna (2021). or dynamic TWFE regressions. The ﬁrst is that it provides sensible estimands even un- We can then estimate AT T pg, tq by replacing expectations with their sample analogs, When there are many treated periods and/or cohorts, however, reporting all thezAT T pg, tq This alternative approach to estimation has two primary advantages over standard static der arbitrary heterogeneity of treatment eﬀects. The second is that it makes transparent exactly which units are being used as a control group to infer the unobserved potential outcomes. This contrasts with standard TWFE models, which we have seen make unintuitive comparisons under staggered timing. D’Haultfœuille (2020b) propose an estimator that can be applied when treatment turns on and oﬀ (see Section 3.4 below), but in the context of the staggered setting here corresponds with the Callaway and Sant’Anna estimator for AT T Sun and Abraham (2021) propose an estimator that uses the last-to-be-treated units as the comparison (G “ tmax propose a recursive estimator that more eﬃciently exploits the identifying assumptions in Callaway and Sant’Anna (2021). See, also, Imai and Kim (2021) and Strezhnev (2018) for closely related ideas. to ‘clean’ (i.e. not-yet-treated) controls and there are separate ﬁxed eﬀects for each set of treated units and its control, as in Cengiz, Dube, Lindner and Zipperer (2019) among others. Gardner (2021) shows that this approach estimates a convex weighted average of the AT T pg, tq under parallel trends and no anticipation, although the weights are determined by the number of treated units and variance of treatment within each stacked event, rather than by economic considerations. imputation estimator (see, also, Gardner (2021), Liu, Wang and Xu (2021) and Wooldridge (2021) for similar proposals). Speciﬁcally, they ﬁt a TWFE regression, Y using observations only for units and time periods that are not-yet-treated. They then infer the never-treated potential outcome for each unit using the predicted value from this regression, and these individual-level estimates can be aggregated to form summary parameters like the AT T pg, tq described above. Although the Borusyak et al. (2021) estimator is diﬃcult to characterize in closed form in general, in the special case where units are either ﬁrst-treated at some g where Y imputation estimator thus diﬀers from outcome over all periods before period g Several other recent papers propose similar estimation strategies. de Chaisemartin and Another related approach is to run a stacked regression where each treated unit is matched Another related estimator is what Borusyak, Jaravel and Spiess (2021) refer to as an can potentially improve eﬃciency since it averages over more periods, and indeed Borusyak et al. (2021) show that this is necessarily the case in a model for Y errors. On the other hand, the validity of the estimator depends on a stronger parallel trends assumption, which in this example requires parallel trends for all periods rather than beginning only in period g would hold exactly for all post-treatment periods and not for all pre-treatment periods in some applications, relying on this stronger assumption may lead to larger biases if the parallel trends assumption holds only approximately. As discussed in Roth (2018) and de Chaisemartin and D’Haultfœuille (2021a), for example, the imputation estimator may be more susceptible to bias if there is a monotonic violation of parallel trends, since it puts more weight on earlier periods where the treatment and comparison groups are less similar. See Marcus and Sant’Anna (2021) for additional discussion of the tradeoﬀs between the strength of the identifying assumptions and the precision of one’s estimates in staggered treatment settings. Our discussion so far has focused on the case where there is a binary treatment that is adopted at a particular date and remains on afterwards. Several recent papers have studied settings with more complicated forms of treatment assignment. We brieﬂy highlight a few of the recent contributions, and refer the reader to the review in de Chaisemartin and D’Haultfœuille (2021a) for more details. assumptions about treatment timing, but do not necessarily require that treatment is an absorbing state. Their estimators intuitively compare changes in outcomes for units whose treatment status changed to other units whose treatment status remained constant over the same periods. This approach yields an interpretable causal eﬀect under generalizations of the parallel trends assumption and a “no carryover” assumption that imposes that potential outcomes only depend on current treatment status and not on the full treatment histories. de Chaisemartin and D’Haultfœuille (2020a) relax the no-carryover assumption, allowing potential outcomes to depend on the full path of treatments, at the expense of imposing a parallel trends assumption that requires parallel trends in untreated potential outcomes regardless of a unit’s path of treatment. de Chaisemartin and D’Haultfœuille (2018) study “fuzzy” DiD settings in which all groups are treated in both time periods, but the proportion of units exposed to treatment increases in one group but not in the other. Finally, de Chaisemartin and D’Haultfœuille (2021b) and Callaway, Goodman-Bacon and Sant’Anna (2021) de Chaisemartin and D’Haultfœuille (2020b) and Imai and Kim (2021) adopt similar study settings with multi-valued or continuous treatments. The results discussed above show that while conventional TWFE speciﬁcations make sensible comparisons of treated and untreated units in the canonical two-period DiD model, in the staggered case they typically make “forbidden comparisons” between already-treated units. As a result, treatment eﬀects for some units and time periods receive negative weights in the TWFE estimand. In extreme cases, this can lead the TWFE estimand to have the “wrong sign” — e.g., the estimand may be negative even if all the treatment eﬀects are positive. Even if the weights are not so extreme as to create sign reversals, it may nevertheless be diﬃcult to interpret which comparisons the TWFE estimator is making, as the “control group” is not transparent, and the weights it chooses are unlikely to be those most relevant for economic policy. in Section 3.3 that explicitly specify the comparisons to be made between treatment and control groups, as well as the desired weights in the target parameter. These methods allow one to estimate a well-deﬁned causal parameter (under parallel trends), with transparent weights and transparent comparison groups (e.g. not-yet-treated or never-treated units). This approach, in our view, provides a more complete solution to the problem than the diagnostic approaches discussed in Section 3.2.1. Although it is certainly valuable to have a sense of the extent to which conventional TWFE speciﬁcations are making bad comparisons, eliminating these undesirable comparisons seems to us a better approach than diagnosing the extent of the issue. Using a TWFE speciﬁcation may be justiﬁed for eﬃciency reasons if one is conﬁdent that treatment eﬀects are homogeneous, but we suspect that this will be rare in practice. 3.3 to use is trickier. As described above, there are some tradeoﬀs between the eﬃciency of the estimator and the strength of the parallel trends assumption needed for identiﬁcation. The best estimator to use may therefore depend on the context. Nevertheless, it is our practical experience that the various heterogeneity-robust DiD estimators typically (although not always) produce similar answers. The ﬁrst-order consideration is therefore to use an approach that makes clear what the target parameter is and which groups are being compared for identiﬁcation. Thankfully, there are now statistical packages that make implementing (and comparing) the results from these estimators straightforward in practice (see Table 2). In our view, the most direct remedy for this problem is to use the methods discussed The question of which of the many heterogeneity-robust DiD methods discussed in Section We acknowledge that these new methods may initially appear complicated to researchers accustomed to analyzing seemingly simple regression speciﬁcations such as (5) or (7). However, while traditional TWFE regressions are easy to specify, as discussed above they are actually quite diﬃcult to interpret, since they make complicated and unintuitive comparisons across groups. By contrast, the methods that we recommend have a simple interpretation using a coherent control group. And while more complex to express in regression format, they can be viewed as simple aggregations of comparisons of group means. We suspect that once researchers gain experience using the newer heterogeneity-robust DiD methods, they will not seem so scary after all! A second strand of the literature has focused on the possibility that the canonical parallel trends assumption may not hold exactly. Approaches to this problem include relaxing the parallel trends assumption to hold only conditional on covariates, testing for pre-treatment violations of the parallel trends assumption, and various tools for robust inference and sensitivity analysis that explore the possibility that parallel trends may be violated in certain ways. The canonical parallel trends assumption requires that the mean outcome for the treated group would have evolved in parallel with the mean outcome for the untreated group if the treatment had not occurred. As discussed in Section 2, this allows for confounding factors that aﬀect treatment status, but these must have a constant additive eﬀect on the mean outcome. tion for several reasons. First, there will often be concern about time-varying confounding factors. For example, Democratic-leaning states may be more likely to adopt a particular policy (e.g., the minimum wage) and be exposed to diﬀerent macro-economic shocks. If the state of the macro-economy is time-varying, then we would expect this confound to have a time-varying eﬀect on the outcome. A second concern relates to the potential sensitivity of the parallel trends assumption to the chosen function form of the outcome. If the mean of Yp0q evolves in parallel for both groups, then it will generally not be the case that the mean of logpY trends can hold for all monotonic transformations of the outcome gpY In practice, however, we will often be unsure of the validity of the parallel trends assumpp0qq evolves in parallel. Indeed, Roth and Sant’Anna (2021b) show that parallel the population can be partitioned into two groups, the ﬁrst of which is eﬀectively randomly assigned between treatment and control and the second for which the outcome distribution is stable over time. Although there are some cases where these conditions may be (approximately) met — the most prominent of which is random assignment of treatment — they are likely not to hold in most settings where DiD is used, and thus parallel trends will be sensitive to functional form. It will often not be obvious that parallel trends should hold for the particular functional form chosen for our analysis, and thus we may be skeptical of its validity. One way to increase the credibility of the parallel trends assumption is to require that it holds only conditional on covariates. Indeed, if we condition on a rich enough set of covariates X, we may be willing to believe that treatment is nearly randomly assigned conditional on X. Imposing only parallel trends conditional on X since conditional random assignment can fail so long as the remaining unobservables have a time-invariant additive eﬀect on the outcome. naturally extended to incorporate covariates as follows. For simplicity, we will focus ﬁrst on the conditional parallel trends assumption in the canonical two-period model, although several papers have also extended this idea to the case of staggered treatment timing, as we will discuss towards the end of this subsection. We furthermore limit our discussion to covariates measured prior to treatment and which are time-invariant (although they may have a time-varying impact on the outcome); relevant extensions to this are also discussed below. condition (a.k.a. positivity condition), which guarantees that for each treated unit with covariates X value of X procedures (Khan and Tamer, 2010). In the canonical model discussed in Section 2, the parallel trends assumption can be ErYp0q ´ Yp0q|D“ 1, Xs “ E rYp0q ´ Yp0q|D“ 0, X a pre-treatment vector of observable covariates. In addition to the conditional parallel trends assumption, we will also impose an overlap Assumption 7 (Strong overlap). The conditional probability of belonging to the treatment group, given observed characteristics, is uniformly bounded away from one, and the proportion of treated units is bounded away from zero. That is, for some  ą 0, P pD 1 ´ , almost surely, and E rDs ą 0. condition, the ATT conditional on X is identiﬁed for all x with P pD Note that equation (11) is analogous to (2) in the canonical model, except it conditions on X and so we can take the same steps as in Section 2 to infer the conditional ATT for that sub-population. The unconditional ATT can then be identiﬁed by averaging τ distribution of X indicator for whether someone has a college degree – then estimation is straightforward. We can just run an unconditional DiD for each value of X form an estimate for the overall ATT, using the delta method or bootstrap for the standard errors. points), estimation becomes more complicated, because we will typically not have a large enough sample to do an unconditional DiD within each possible value of X there are several available econometric approaches to semi-/non-parametrically estimate the ATT even with continuous covariates. We ﬁrst discuss the limitations of using TWFE regressions in this setting, and then discuss several alternative approaches. Standard linear regression. Given that the TWFE speciﬁcation (3) yielded consistent estimates of the ATT under Assumptions 1-3 in the canonical DiD model, it may be tempting Given the conditional parallel trends assumption, no anticipation assumption, and overlap “ x. Intuitively, among the sub-population with X“ x, we have parallel trends, τ“ ErYp1q ´ Yp0q|D“ 1s “ E—–ErYp1q ´ Yp0q|D“ 1, Xsloooooooooooooooooomoooooooooooooooooon|D“ 1ﬃﬂ. When Xis discrete and takes a small number of values — for example, if Xis an When Xis continuously distributed (or discrete with a very large number of support to augment this speciﬁcation with controls for a time-by-covariate interaction, for estimation under conditional parallel trends. Unfortunately, this augmented speciﬁcation need not yield consistent estimates of the ATT under conditional parallel trends without additional homogeneity assumptions. The intuition is that equation (12) implicitly models the conditional expectation function (CEF) of Y slope of γ, regardless of i’s treatment status. If there are heterogeneous treatment eﬀects that depend on X with respect to X setups, estimates of β can be biased for the ATT; see Meyer (1995) and Abadie (2005) for additional discussion. Fortunately, there are several semi-/non-parametric methods available that allow for consistent estimation of the ATT under conditional parallel trends under weaker homogeneity assumptions. Regression adjustment. An alternative approach to allow for covariate-speciﬁc trends in DiD settings is the regression adjustment procedure proposed by Heckman, Ichimura and Todd (1997) and Heckman, Ichimura, Smith and Todd (1998). Their main idea exploits the fact that under conditional parallel trends, strong overlap, and no anticipation we can write the ATT as where the second equality follows from the law of iterated expectations. Thus, to estimate the ATT under conditional parallel trends, one simply needs to estimate the conditional expectation among untreated units given covariate values, and then average these “predictions” using the empirical distribution of X where control units (but evaluated at X model for interacts X τ“ E rE rY´ Y|D“ 1, Xs ´ E rY´ Y|D“ 0, Xs|D“ 1s, pErY´Y|D“ 0, Xs is the estimated conditional expectation function ﬁtted on the pErY´ Y|D“ 0, Xs, then this would be similar to a modiﬁcation of (12) that identical because the outcome regression approach re-weights using the distribution of X among units with D for the CEF, however, and can use more ﬂexible semi-/non-parametric methods instead. One popular approach in empirical practice is to match each treated unit to a “nearest neighbor” untreated unit with similar (or identical) covariate values, and then estimate pτreduces to the simple DiD estimator between treated units and the matched comparison group. come model used to estimate be done using the delta-method for parametric models, and there are also several methods available for semi-/non-parametric models (under some additional regularity conditions), including the bootstrap, as described in Heckman et al. (1998). Inference is more complicated, however, when one models the outcome evolution of untreated units using a nearest-neighbor approach with a ﬁxed number of matches: the resulting estimator is no longer asymptotically linear and thus standard bootstrap procedures are not asymptotically valid (e.g., Abadie and Imbens, 2006, 2008, 2011, 2012). Ignoring the matching step can also cause problems, and one therefore needs to use inference procedures that accommodate matching as described in the aforementioned papers. Inverse probability weighting An alternative to modeling the conditional expectation function is to instead model the propensity score, i.e. the conditional probability of belonging to the treated group given covariates, ppX (2005), under Assumptions 2, 6 and 7, the ATT is identiﬁed using the following inverse probability weighting (IPW) formula: estimate the ATT by pluging in an estimate of the propensity score to the equation above, ´Y|D“ 0, Xs using Y´Y, where lpiq is the unit matched to i, in which case The outcome regression approach will generally be consistent for the ATT when the out- As in the regression adjustment approach, researchers can use the “plug-in principle” to mated using parametric models or semi-/non-parametric models (under suitable regularity conditions). The IPW approach will generally be consistent if the model for the propensity scores is correctly speciﬁed. Inference can be conducted using standard tools; see, e.g., Abadie (2005). Doubly-robust estimators The outcome regression and IPW approaches described above can also be combined to form “doubly-robust” (DR) methods that are valid if either the outcome model or the propensity score model is correctly speciﬁed. Speciﬁcally, Sant’Anna and Zhao (2020) show that under Assumptions 2, 6 and 7, the ATT is identiﬁed as: score and the CEF, The outcome equation and the propensity score can be modeled with either parametric or semi-/non-parametric methods, and DR methods will generally be consistent if either of these models is correctly speciﬁed. In addition, Chang (2020) shows that data-adaptive/machine- Similar to the regression adjustment approach, the propensity score model can be esti- As before, one can then estimate the ATT by plugging in estimates of both the propensity learning methods can also be used with DR methods. Standard inference tools can be used as well; see, e.g., Sant’Anna and Zhao (2020). Finally, under some regularity conditions, the DR estimator achieves the semi-parametric eﬃciency bound when both outcome evolution and propensity score models are correctly speciﬁed (Sant’Anna and Zhao, 2020). Extensions to staggered treatment timing: Although the discussion above focused on DiD setups with two groups and two periods, these diﬀerent procedures have been extended to staggered DiD setups when treatments are binary and non-reversible. More precisely, Callaway and Sant’Anna (2021) extend the regression adjustment, IPW and DR procedures above to estimate the family of AT T pg, tq’s discussed in Section 3.3. They then aggregate these estimators to form diﬀerent treatment eﬀect summary measures. Wooldridge (2021) proposes an alternative regression adjustment procedure that is suitable for staggered setups. His proposed estimator diﬀers from the Callaway and Sant’Anna (2021) regression adjustment estimator as he exploits additional information from pre-treatment periods, which, in turn, can lead to improvements in precision. On the other hand, if these additional assumptions are violated, Wooldridge (2021)’s estimator may be more biased than Callaway and Sant’Anna (2021)’s. de Chaisemartin and D’Haultfœuille (2020b,a) consider an estimator which includes covariates in a linear manner. Caveats. Throughout, we assume that the covariates X duction of the intervention and are, therefore, unaﬀected by it. If X by treatment, then conditioning on it induces a “bad control” problem that can induce bias; see Zeldow and Hatﬁeld (2021) for additional discussion. treatment outcomes. Proponents of including pre-treatment outcomes argue that controlling for lagged outcomes can reduce bias from unobserved confounders (Ryan, 2018). conditioning on lagged outcomes need not necessarily reduce bias. For example, Daw and Hatﬁeld (2018) show that when the treated and comparison groups have diﬀerent outcome distributions, matching the treated and control groups on lagged outcomes selects control units with a particularly large “shock” in the pre-treatment period. This can then induce bias owing to a mean-reversion eﬀect, when in fact not conditioning on lagged outcomes would have produced parallel trends. See, also Chabé-Ferret (2015) and Ding and Li (2019) for related discussion. Another important question relates to whether researchers should condition on pre- Although conditioning on pre-existing covariates can help increase the plausibility of the parallel trends assumption, researchers typically still worry that there remain unobserved time-varying confounders. An appealing feature of the DiD design is that it allows for a natural plausibility check on the identifying assumptions: did outcomes for the treated and comparison groups (possibly conditional on covariates) move in parallel prior to the time of treatment? It has therefore become common practice to check, both visually and using statistical tests, whether there exist pre-existing diﬀerences in trends (“pre-trends”) as a test of the plausibility of the parallel trends assumption. Section 2 in which we observe outcomes for an additional period t “ 0 during which no units were treated. (These ideas will extend to the case of staggered treatment or conditional parallel trends). By the no-anticipation assumption, Y t “ 0 and t “ 1. We can thus check whether the analog to the parallel trends assumption held between periods 0 and 1 — that is, is In the non-staggered setting, this hypothesis can be conveniently tested using a TWFE speciﬁcation that includes leads and lags of treatment, where the coeﬃcient on the lead of treatment Testing for pre-treatment trends thus is equivalent to testing the null hypothesis that β This approach is convenient to implement and extends easily to the case with additional pre-treatment periods and non-staggered treatment adoption. When there are multiple pretreatment periods, it is common to plot the If all of the pre-treatment coeﬃcients (i.e., interpreted as a sign in favor of the validity of the design, since we cannot reject the null that parallel trends was satisﬁed in the pre-treatment period. To ﬁx ideas, consider a simple extension of the canonical non-staggered DiD model in This pre-testing approach extends easily to settings with staggered adoption and/or conditional parallel trends assumptions. For example, the Callaway and Sant’Anna (2021) estimator can be used to construct “placebo” estimates of AT T l periods before treatment. The estimates (corresponding to diﬀerent lengths of time before/after treatment) to form an event-study plot analogous to that for the non-staggered case. This illustrates that the idea of testing for pre-trends extends easily to the settings with staggered treatment adoption or conditional parallel trends, since the Callaway and Sant’Anna (2021) can be applied for both of these settings. These results are by no means speciﬁc to the Callaway and Sant’Anna (2021) estimator, though, and event-study plots can be created in a similar fashion using other estimators for either staggered or conditional DiD settings. We caution, however, against using dynamic TWFE speciﬁcations like (17) in settings with staggered adoption, since as noted by Sun and Abraham (2021), the coeﬃcients β eﬀects at relative time r may reject even if parallel trends holds in the pre-treatment period. Although tests of pre-existing trends are a natural and intuitive plausibility check of the parallel trends assumption, recent research has highlighted that they also have several limitations. First, even if pre-trends are exactly parallel, this need not guarantee that the post-treatment parallel trends assumption is satisﬁed. Kahn-Lang and Lang (2020) give an intuitive example: the average height of boys and girls evolves in parallel until about age 13 and then diverges, but we should not conclude from this that there is a causal eﬀect of bar mitzvahs (which occur for boys at age 13) on children’s height! scribed above may fail to reject owing to low power (Bilinski and Hatﬁeld, 2018; Freyaldenhoven, Hansen and Shapiro, 2019; Kahn-Lang and Lang, 2020; Roth, Forthcoming). That is, even if there is a pre-existing trend, it may not be signiﬁcant in the data if our pre-treatment estimates are imprecise. treatment eﬀect but there is a pre-existing linear diﬀerence in trends between the treatment and comparison groups. Then in the simple example from above, the pre-treatment and posttreatment event-study coeﬃcients will have the same magnitude, |β estimated coeﬃcients the chance that we ﬁnd a signiﬁcant pre-trend will be the same as the probability we ﬁnd a signiﬁcant post-treatment eﬀect. But this means that a pre-trend that we detect only half the A second issue is that even if there are pre-existing diﬀerences in trends, the tests de- To develop some intuition for why power may be low, suppose that there is no true time will also lead us to ﬁnd a signiﬁcant treatment eﬀect half the time — that is, 10 times more often than we expect to ﬁnd a spurious eﬀect using a nominal 95% conﬁdence interval! Another intuition for this phenomenon, given by Bilinski and Hatﬁeld (2018), is that pretrends tests reverse the traditional roles of type I and type II error: they set the assumption of parallel trends (or no placebo pre-intervention eﬀect) as the null hypothesis and only “reject” the assumption if there is strong evidence against it. This controls the probability of ﬁnding a violation when parallel trends holds tightly at 5% (or another chosen α-level), but the probability of failing to identify a violation can be much higher, corresponding to type II error of the test. power appears to be relevant in practice: in simulations calibrated to papers published in three leading economics journals, Roth (Forthcoming) found that linear violations of parallel trends that conventional tests would detect only 50% of the time often produce biases as large as (or larger than) the estimated treatment eﬀect. trends test induces a selection bias known as pre-test bias (Roth, Forthcoming). Intuitively, if there is a pre-existing diﬀerence in trends in population, the draws from the DGP in which we fail to detect a signiﬁcant pre-trend are a selected sample from the true DGP. Roth (Forthcoming) shows that in many cases, this additional selection bias can exacerbate the bias from a violation of parallel trends. we do detect a signiﬁcant pre-trend. In this case, the pre-trends test suggests that parallel trends is likely not to hold exactly, but researchers may still wish to learn something about the treatment eﬀect of interest. Indeed, it seems likely that with enough precision, we will nearly always reject that the parallel trends assumption holds exactly in the pre-treatment period. Nevertheless, we may still wish to learn something about the treatment eﬀect, especially if the violation of parallel trends is “small” in magnitude. However, the conventional approach does not make clear how to proceed in this case. A few papers have proposed alternative tools for detecting pre-treatment violations of parallel trends that take into account some of the limitations discussed above. Roth (Forthcoming) developed tools to conduct power analyses and calculate the likely distortions from pre-testing under researcher-hypothesized violations of parallel trends. These tools allow the researcher to assess whether the limitations described above are likely to be severe for potential violations of parallel trends deemed economically relevant. In addition to being concerning from a theoretical point of view, the possibility of low A third issue with pre-trends testing is that conditioning the analysis on “passing” a pre- A ﬁnal issue with the current practice of pre-trends testing relates to what happens if approaches to pre-testing that help address the issue of low power by reversing the roles of the null and alternative hypotheses. That is, rather than test the null that pre-treatment trends are zero, they test the null that the pre-treatment trend is large, and reject only if the data provides strong evidence that the pre-treatment trend is small. For example, Dette and Schumann (2020) consider null hypotheses of the form H are the (population) pre-treatment coeﬃcients from regression (17). This ensures that the test “detects” a pre-trend with probability at least 1 ´ α when in fact the pre-trend is large (i.e. has magnitude at least c). since they guarantee by design that the pre-test is powered against large pre-treatment violations of parallel trends. However, using these approaches does not provide any formal guarantees that ensure the validity of conﬁdence intervals for the treatment eﬀect, the main object of interest. They also do not avoid statistical issues related to pre-testing (Roth, Forthcoming), and do not provide clear guidance on what to do when the test fails to reject the null of a large pre-trend. This has motivated more formal robust inference and sensitivity analysis approaches that consider inference on the ATT when parallel trends may be violated. Bounds using pre-trends. Rambachan and Roth (2021) propose an approach for robust inference and sensitivity analysis when parallel trends may be violated, building on earlier work by Manski and Pepper (2018). Their approach attempts to formalize the intuition motivating pre-trends testing: that the counterfactual post-treatment trends cannot be “too diﬀerent” from the pre-trends. To ﬁx ideas, consider the non-staggered treatment adoption setting described in Section 4.4. Denote by δ post-treatment period: The bias δ tential outcomes, Y we can identify the pre-treatment analog to δ which looks at pre-treatment diﬀerences in trends between the groups, with δ Bilinski and Hatﬁeld (2018) and Dette and Schumann (2020) propose “non-inferiority” These non-inferiority approaches are an improvement over standard pre-testing methods, from the event study regression (17). strict the possible values of δ if there are K pre-treatment coeﬃcients. For example, one type of restriction they consider states that the magnitude of the post-treatment violation of parallel trends can be no larger than a constant M times the maximal pre-treatment violation, i.e. |δ They also consider restrictions that bound the extent that δ trapolation of the pre-treatment diﬀerences in trends. Rambachan and Roth (2021) use tools from the partial identiﬁcation and sensitivity analysis literature (Armstrong and Kolesár, 2018; Andrews, Pakes and Roth, 2019) to construct conﬁdence sets for the ATT that are uniformly valid under the imposed restrictions. These conﬁdence sets take into account the fact that we do not observe the true pre-treatment diﬀerence in trends δ dence sets thus tend to be larger when there is more uncertainty about the pre-treatment diﬀerence in trends (i.e. when the standard error on might report that the conclusion of a positive treatment eﬀect is robust up to the value M “ 2. This indicates that to invalidate the conclusion of a positive eﬀect, we would need to allow for a post-treatment violation of parallel trends two times larger than the maximal pre-treatment violation. staggered treatment timing and an unconditional parallel trends assumption, they extend easily to the case of staggered treatment timing and conditional parallel trends as well. Indeed, under mild regularity conditions, these tools can be used anytime the researcher has a treatment eﬀect estimate to bound the possible bias of staggered setting, described in Section 3.3, and https://github.com/pedrohcgs/CS_RR for examples on how these sensitivity analyses can be combined with the Callaway and Sant’Anna (2021) estimator in R. Bounds using bracketing. Ye, Keele, Hasegawa and Small (2021) consider an alternative partial identiﬁcation approach where there are two control groups whose trends are assumed to “bracket” that of the treatment group. Consider the canonical model from Section 2, and suppose the untreated units can be divided into two control groups, denoted C C“ b. For ease of notation, let C Rambachan and Roth (2021) then consider robust inference under assumptions that re- . In contrast to conventional pre-trends tests, the Rambachan and Roth (2021) conﬁ- This approach enables a natural form of sensitivity analysis. For example, a researcher It is worth highlighting that although we’ve described these tools in the context of non- Let ∆pcq “ E rY (2021) impose that so that the trend in Y p0q for the treated group is bounded above and below (“bracketed”) by the minimum and maximum in groups a and b. An intuitive example where we may have such bracketing is if each of the groups corresponds with a set of industries, and one of the control groups (say group a) is more cyclical than the treated group while the other (say group b) is less cyclical. If the economy was improving between periods t “ 1 and t “ 2, then we would expect group a to have the largest change in the outcome and group b to have the smallest change; whereas if the economy was getting worse, we would expect the opposite. Under equation (18) and the no anticipation assumption, the ATT is bounded, This reﬂects that if we knew the true counterfactual trend for the treated group we could learn the ATT exactly, and therefore that bounding this trend means we can obtain bounds on the ATT. Ye et al. (2021) further show how one can construct conﬁdence intervals for the ATT, and extend this logic to settings with multiple periods (but non-staggered treatment timing). See, also, Hasegawa, Webster and Small (2019) for a related, earlier approach. Keele, Small, Hsu and Fogarty (2019) propose a sensitivity analysis in the canonical twoperiod DiD model that summarizes the strength of confounding factors that would be needed to induce a particular bias. Freyaldenhoven, Hansen, Pérez Pérez and Shapiro (2021) propose a visual sensitivity analysis in which one plots the “smoothest” trend though an event-study plot that could rationalize the data under the null of no eﬀect. Finally, Freyaldenhoven et al. (2019) propose a GMM-based estimation strategy that allows for parallel trends to be violated when there exists a covariate assumed to be aﬀected by the same confounds as the outcome but not by the treatment itself. We suspect that in most practical applications of DiD, researchers will not be conﬁdent ex ante that the parallel trends assumption holds exactly, owing to concerns about timevarying confounds and sensitivity to functional form. The methods discussed in this setting ErY|D“ 1s `mint∆paq, ∆pbqu ď τď E rY|D“ 1s `mint∆paq, ∆pbqu. for relaxing the parallel trends assumption and/or assessing sensitivity to violations of the parallel trends assumption will therefore be highly relevant in most contexts where DiD is applied. change meaningfully when imposing parallel trends only conditional on covariates. Among the diﬀerent estimation procedures we discussed, we view doubly-robust procedures as a natural default, since they are valid if either the outcome model or propensity score is well-speciﬁed and have desirable eﬃciency properties. A potential exception to this recommendation arises in settings with limited overlap, i.e., when the estimated propensity score is close to 0 or 1, in which case regression adjustment estimators may be preferred. continue to plot “event-study plots” that allow for a visual evaluation of pre-existing trends. These plots convey useful information for the reader to assess whether there appears to have been a break in the outcome for the treatment group around the time of treatment. In contexts with a common treatment date, such plots can be created using TWFE speciﬁcations like (17); in contexts with staggered timing, we recommend plotting estimates of AT T diﬀerent values of l using one of the estimators for the staggered setting described in Section 3.3 to avoid negative weighting issues with TWFE. See Section 4.3 for additional discussion. We also refer the reader to Freyaldenhoven et al. (2021) regarding best-practices for creating such plots, such as displaying simultaneous (rather than pointwise) conﬁdence bands for the path of the event-study coeﬃcients (Olea and Plagborg-Møller, 2019; Callaway and Sant’Anna, 2021). trends assumption, we think it is important to appreciate that tests of pre-trends may be underpowered to detect relevant violations of parallel trends, as discussed in Section 4.4. At minimum, we recommend that researchers assess the power of pre-trends tests against economically relevant violations of parallel trends, or conduct non-inferiority tests against pre-trends that are determined to be “economically large”, as described in Section 4.4.1. We also think it should become standard practice for researchers to report sensitivity analyses that formalize the extent to which their conclusions are sensitive to violations of parallel trends, using the tools described in Section 4.5. possible violations of parallel trends. The parallel trends assumption is much more plausible in settings where we expect the trends for the two groups to be similar ex-ante (before seeing the pre-trends). Whenever possible, researchers should therefore provide a justiﬁcation for why we might expect the two groups to have similar trends. It is also useful to pro- A natural starting point for these robustness checks is to consider whether the results Whether one includes covariates into the DiD analysis or not, we encourage researchers to While event-study plots play an important role in evaluating the plausibility of the parallel We encourage researchers to incorporate context-speciﬁc knowledge in the discussion of vide context-speciﬁc knowledge about the types of confounds that might potentially lead to violations of the parallel trends assumption — what time-varying factors may have diﬀerentially aﬀected the outcome for the treated group? Such discussion can often be very useful for interpreting the results of the formal sensitivity analyses described in Section 4.5. For example, suppose that a particular conclusion is robust to allowing for violations of parallel trends twice as large the maximum in the pre-treatment period. In contexts where other factors were quite stable around the time of the treatment, this might be interpreted as a very robust ﬁnding; on the other hand, if the treatment occurred at the beginning of a recession much larger than anything seen in the pre-treatment period, then a pre-trend of that magnitude may indeed be plausible, so that the results are less robust than we might like. Thus, economic knowledge will be very important in understanding the robustness of a particular result. In our view, the most scientiﬁc approach to dealing with possible violations of parallel trends therefore involves a combination of state-of-the-art econometric tools and context-speciﬁc knowledge about the types of plausible confounding factors. We now discuss a third strand of the DiD literature, which considers inference under deviations from the canonical assumption that we have sampled a large number of independent clusters from a super-population. As described in Section 2, standard DiD inference procedures rely on researchers having access to data on a large number of treated and untreated clusters. Conﬁdence intervals are then based on the central limit theorem, which states that with independently-sampled clusters, the DiD estimator has an asymptotically normal distribution as the number of treated and untreated clusters grows large. In many practical DiD settings, however, the number of independent clusters (and, in particular, treated clusters) may be small, so that the central limit theorem based on a growing number of clusters may provide a poor approximation. For example, many DiD applications using state-level policy changes may only have a handful of treated states. We note that the central limit theorem may provide a poor approximation with few clusters, even if the number of units within each cluster is large. This is because the standard sampling-based view of clustering allows for arbitrary correlations of the outcome within each cluster, and thus there may be common components at the cluster level (a.k.a. cluster-level “shocks”) that do not wash out when averaging over many units within the same cluster. Since we only observe a few observations of the cluster-speciﬁc shocks, the average of these shocks will generally not be approximately normally distributed. Model-based approaches. Several papers have made progress on the diﬃcult problem of conducting inference with a small number of clusters by modeling the dependence within clusters. These papers typically place some restrictions on the common cluster-level shocks, although the exact restrictions diﬀer across papers. The starting point for these papers is typically a structural equation of the form where Y and time ﬁxed eﬀects, D common cluster-by-time error term, and  the “cluster-level” error term, ν It is often assumed that  Donald and Lang (2007), Conley and Taber (2011), and Ferman and Pinto (2019). Letting number of units in cluster j, we can take averages to obtain where η clusters are treated in period t “ 1 and some clusters are treated in period t “ 2, the canonical DiD estimator at the cluster level is equivalent to the OLS estimated coeﬃcient from (20), and is given by where now N the challenge in this setup: with few clusters, the averages of the ∆ν untreated clusters will tend not to be approximately normally distributed, and their variance may be diﬃcult to estimate. “ nYbe the average outcome among units in cluster j, where nis the “ ν` n. Assuming the canonical set-up with two periods where no (and likewise for the other variables). The equation in the previous display highlights tion (19) rather than a model where the primitives are potential outcomes as in Section 2. We think that connecting the assumptions on the errors in the structural model (19) to restrictions on the potential outcomes is an interesting open topic for future work. Although a general treatment is beyond the scope of this paper, in Appendix A we derive how the errors in the structural model (19) map to primitives based on potential outcomes in the canonical model from Section 2. Speciﬁcally, we show that under the set-up of Section 2, Assumptions 1 and 2 imply that the canonical DiD estimator takes the form given in (21), where β “ τ where Thus, in the canonical set-up, restrictions on ν primitives that are functions of the potential outcomes. For the remainder of the sub-section, however, we focus primarily on the restrictions placed on ν the implications of these assumptions for the potential outcomes — since this simpliﬁes exposition and matches how these assumptions are stated in the literature. assume that the “cluster-speciﬁc” shocks ν respect to cluster and treatment status, and independent of other unit-and-time speciﬁc shocks. When each cluster is suﬃciently large (n that η This allows one to conduct inference using critical values from a t-distribution with J ´ 2 degrees of freedom, where J is the total number of clusters. The key restriction in this approach is the assumption that the cluster-speciﬁc shocks ν to imposing a potentially strong distributional assumption on the shape of the errors, the homoskedasticity assumption also rules out many forms of treatment eﬀect heterogeneity. For example, suppose the cluster-level means of Y treated and control clusters. Then if the average treatment eﬀect at the cluster level is heterogeneous, this will tend to lead ν It is worth highlighting that the model described above starts from the structural equa- When the number of treated and untreated clusters is ﬁxed, Donald and Lang (2007) in (20) are (asymptotically) normal, with mean zero and a homoskedastic variance. violating the homoskedasticity assumption. (2007) that does not rely on the cluster-speciﬁc shocks ν consider a setup where the number of treated clusters, J one, but there are a large number of untreated clusters, J Conley and Taber (2011) is that, if the cluster-speciﬁc error terms η group are informative about the cluster-speciﬁc error terms for the treated group, one can conduct inference about β using the estimated distribution of the untreated errors. In order to satisfy the “informativeness” condition, Conley and Taber (2011) impose the following restrictions: the idiosyncratic errors  treatment status, the cluster-speciﬁc shocks ν status, and have mean zero for all t, and that all clusters grow at the same rate as J Based on these conditions, one can construct conﬁdence intervals for β using the estimated distribution of the clustered error-terms. Although the conditions imposed by Conley and Taber (2011) are arguably weaker than those in Donald and Lang (2007), they still rule out important types of treatment eﬀect heterogeneity. For instance, if average treatment eﬀects diﬀer across clusters, then this will tend to violate the assumption that ν Another limitation of the Conley and Taber (2011) procedure is that it does not accommodate settings with heterogeneous cluster sizes, a situation that often arises in practice. bootstrap-based inference procedures to allow for some types of heteroskedasticity, paying particular attention to the case where heteroskedasticity arises due to variation in cluster sizes. The key insight of Ferman and Pinto (2019) is that, under a range of structures for the within-cluster correlation, it is possible to estimate the heteroskedasticity generated by variation in cluster sizes, and re-scale the residuals in a bootstrap procedure. The main assumption, however, is that the heteroskedasticity is only based on variation in cluster sizes (or on other observed variables). See also Ferman (2021) for an extension allowing for spatial correlation. ble to DiD setups with a single large treated cluster and a ﬁxed number of large untreated clusters, provided the average evolution of the untreated outcomes is the same across all untreated clusters. Hagemann (2020)’s proposal allows for heteroskedastic error terms and, in contrast to Ferman and Pinto (2019), it does not require one to directly estimate (or model) the heteroskedasticity. The key insight of Hagemann (2020) is that if we place a bound on the maximal relative heterogeneity across clusters, then we can bound the probability of type I error from a permutation approach. He also shows how one can use this measure of relative Conley and Taber (2011) consider an alternative inference procedure to Donald and Lang Ferman and Pinto (2019) build on Conley and Taber (2011) and show how one can use Hagemann (2020) considers a rearrangement/permutation-based method that is applicaheterogeneity to do sensitivity analysis. Like the other proposals above, though, Hagemann (2020)’s approach must also place some strong restrictions on certain types of heterogeneity. In particular, his approach essentially requires that, as cluster size grows large, any single untreated cluster could be used to infer the counterfactual trend for the treated group, and thus his approach rules out cluster-speciﬁc heterogeneity in trends in untreated potential outcomes. paper, Cameron, Gelbach and Miller (2008) presented simulation evidence that the cluster wild bootstrap procedure can work well in settings with as few as ﬁve clusters. More recently, however, Canay, Santos and Shaikh (2021) provided a formal analysis about the conditions under which the cluster wild bootstrap procedure would be asymptotically valid in settings with a few large clusters. Importantly, Canay et al. (2021) show that the reliability of these bootstrap procedures depends on imposing certain homogeneity conditions on treatment eﬀects, as well as the type of bootstrap weights one uses and the estimation method adopted (e.g., restricted vs. unrestricted OLS). In particular, these restrictions are commonly violated when one uses TWFE regressions with cluster-speciﬁc and time ﬁxed eﬀects like (20) or when treatment eﬀects are allowed to be heterogeneous across clusters – see Examples 2 and 3 in Canay et al. (2021). Simulations have likewise shown that the cluster wild bootstrap may perform poorly in DiD settings with a small number of treated clusters (MacKinnon and Webb, 2018). Thus, while the wild bootstrap may perform well in certain scenarios with a small number of clusters, it too requires strong homogeneity assumptions. liable inference with less stringent homogeneity assumptions about treatment eﬀects. For instance, Canay, Romano and Shaikh (2017), Ibragimov and Müller (2016), Hagemann (2021), and Chernozhukov, Wüthrich and Zhu (2021) respectively propose permutation-based, t-test based, adjusted permutation-based, and conformal inference-based procedures that allow one to relax distributional assumptions about common shocks and accommodate richer forms of heterogeneity. The key restriction is that one is comfortable limiting the time-series dependence of the cluster-speciﬁc-shocks, and strengthening the parallel trends assumption to hold in many pre- and post-treatment time periods. These methods have been shown to be valid under asymptotics where the number of periods grows large. When in fact the number of time periods is small, as frequently occurs in DiD applications, one can still use some of these methods, but the underlying assumptions are stronger — see, e.g., Remark 4.5 and Section 4.2 of Canay et al. (2017). Another popular solution with few clusters is the cluster wild bootstrap. In an inﬂuential Finally, in settings with a large number of time periods, it may be feasible to conduct re- Alternative approaches. We now brieﬂy discuss two alternative approaches in settings with a small number of clusters. First, while all of the “model-based” papers above treat ν as random, an alternative perspective would be to condition on the values of ν remaining uncertainty as coming from the sampling of the individual units within clusters, constructing standard errors by clustering only at the unit level. This will generally produce a violation of parallel trends, but the violation may be relatively small if the cluster-speciﬁc shocks are small relative to the idiosyncratic variation. The violation of parallel trends could then be accounted for using the methods described in Section 4. To make this concrete, consider the setting of Card and Krueger (1994) that compares employment in NJ and PA after NJ raised its minimum wage. The aforementioned papers would consider NJ and PA as drawn from a super-population of treated and untreated states, where the state-level shocks are mean-zero, whereas the alternative approach would treat the two states as ﬁxed and view any state-level shocks between NJ and PA as a violation of the parallel trends assumption. One could then explore the sensitivity of one’s conclusions to the magnitude of this violation, potentially benchmarking it relative to the magnitude of the pre-treatment violations. sidered Fisher Randomization Tests (FRTs), otherwise known as permutation tests. The basic idea is to calculate some statistic of the data (e.g. the t-statistic of the DiD estimator), and then recompute this statistic under many permutations of the treatment assignment (at the cluster level). We then reject the null hypothesis of no eﬀect if the test statistic using the original data is larger than 95% of the draws of the test statistics under the permuted treatment assignment. Such tests have a long history in statistics, dating to Fisher (1935). If treatment is randomly assigned, then FRTs have exact ﬁnite-sample validity under the sharp null of no treatment eﬀects for all units. The advantage of these tests is that they place no restrictions on the values of Y p0q, and thus allow arbitrary heterogeneity in Y p0q across clusters. On the other hand, the assumption of random treatment assignment may often be questionable in DiD settings, as it is substantially stronger than parallel trends. Moreover, the “sharp” null of no eﬀects for all units may not be as economically interesting as the “weak” null of no average eﬀects. Roth and Sant’Anna (2021a) extend the idea of FRTs to settings where there is staggered adoption and (quasi-)random timing of treatment, and show that an FRT with a studentized statistic is both ﬁnite-sample valid for the sharp null and asymptotically valid (as the number of clusters grows) for the weak null. Recommendations. In sum, recent research has made progress on the problem of conducting inference with relatively few clusters, but all of the available approaches require the researcher to impose some potentially strong additional assumptions. Most of the litera- Second, a large literature in statistics and a growing literature in econometrics has conture has focused on model-based approaches, which require the researcher to impose some homogeneity assumptions across clusters. Diﬀerent homogeneity assumptions may be more reasonable in diﬀerent contexts, and so we encourage researchers using these approaches to choose a method relying on a dimension of homogeneity that is most likely to hold (approximately) in their context. We also note that allowing for more heterogeneity may often come at the expense of obtaining tests with lower power. When none of these homogeneity assumptions is palatable, conditioning the inference on the cluster-level shocks and treating them as violations of parallel trends, accompanied by appropriate sensitivity analyses, may be an attractive alternative. Permutation-based methods also oﬀer an intriguing alternative which requires fewer assumptions about homogeneity in Y p0q, but requires stronger assumptions on the assignment of treatment and tests a potentially less interesting null hypothesis when the number of clusters is small. The canonical approach to inference in DiD views each unit (or cluster) as having been sampled from an inﬁnite larger super-population. This view is natural when, for example, our sample is a labor market survey of workers drawn from a much larger population. The super-population view can be somewhat harder to conceptualize in other applications, for instance when all 50 US states are observed or we have administrative data on an entire population (Manski and Pepper, 2018). In such settings, it is often conceptually easier to view the N units in the sample as the ﬁxed population of interest, and to think of the uncertainty in the data as arising only from the randomness in the treatment assignment vector D “ pD dating to Neyman (1923), but has focused on experiments where treatment is assigned with known probabilities. settings like DiD. Rambachan and Roth (2020) consider a setting similar to the canonical two-period model in Section 2. However, rather than viewing the units as drawn from a super-population, they treat them as ﬁxed (or conditioned on) – that is, the potential outcomes Y Only the treatment assignment vector D is considered to be random. In this set-up, they show that the usual DiD estimator is unbiased for a ﬁnite-population analog to the ATT under a ﬁnite-population analog to the parallel trends assumption. In particular, let π Recent work by Rambachan and Roth (2020) has extended this design-based view to denote the probability that D so that treatment probabilities are uncorrelated with trends in Y p0q (a ﬁnite-population version of parallel trends). Then E is a ﬁnite-population analog to the ATT, i.e. the expected average treatment eﬀect on the treated, and the expectation is taken over the distribution of the treatment assignment vector. dently at the unit level, potentially conservative) inference from the design-based perspective in large populations. Similarly, their results imply that if units i are nested in clusters j, and treatment is assigned independently at the cluster level, then standard errors clustered at the j level are valid from the design-based perspective. These results suggest that it may not actually be a problem if it is diﬃcult to conceptualize a super-population. Rather, the “usual” approach remains valid if we can conceptualize the treatment assignment as being stochastic. priate level of clustering. When the need to cluster arises from correlation in treatment assignment, then these results imply it is appropriate to cluster at the level at which treatment is independently assigned. Clustering at the level of treatment assignment thus seems like a good rule of thumb in many cases. Abadie, Athey, Imbens and Wooldridge (2017) study a model in which both treatment is random and units are sampled from a larger population, and suggest that one should cluster among units if either their treatment assignments are correlated or the event that they are included in the sample is correlated. Although the Abadie et al. (2017) results are for cross-sectional settings and do not directly apply to DiD, we suspect that a similar heuristic would apply in DiD as well in light of the results in Rambachan and Roth (2020) for the case where treatment is viewed as random. Formalizing this intuition strikes us as an interesting area for future research. Recommendations. If it is diﬃcult to conceptualize a super-population, fear not! Your DiD analysis can likely still be sensible from a ﬁnite-population perspective where we think of the treatment assignment as stochastic. Furthermore, if you are unsure about the appropriate level of clustering, a good rule of thumb (at least from the design-based perspective) is to cluster at the level at which treatment assignment is independently assigned (or at which Rambachan and Roth (2020) also show that when treatment assignment occurs indepen- These results in the design-based view can also be useful when determining the approunits are independently sampled). In this section, we brieﬂy touch on some other areas of interest in the DiD literature, and highlight some open areas for future research. Distributional treatment eﬀects. The DiD literature typically focuses on estimation of the ATT, but researchers may often be interested in the eﬀect of a treatment on the entire distribution of an outcome. Athey and Imbens (2006) propose the Changes-in-Changes model, which allows one to infer the full counterfactual distribution of Y p0q for the treated group in DiD setups. The key assumption is that the mapping between quantiles of Y p0q for the treated and comparison groups remains stable over time – e.g., if the 30th percentile of the outcome for the treated group was the 70th percentile for the comparison group prior to treatment, this relationship would have been preserved in the second period if treatment had not occurred. Bonhomme and Sauder (2011) propose an alternative distributional DiD model based on a parallel trends assumption for the (log of the) characteristic function, which is motivated by a model of test scores. Callaway and Li (2019) propose a distributional DiD model based on a copula stability assumption. Finally, Roth and Sant’Anna (2021b) show that parallel trends holds for all functional forms under a “parallel trends”-type assumption for the cumulative distribution of Y p0q, and this assumption also allows one to infer the full counterfactual distribution for the treated group. Quasi-random treatment timing. In settings with staggered treatment timing, the generalized parallel trends assumption is often justiﬁed by arguing that the timing of treatment is random or quasi-random. Roth and Sant’Anna (2021a) show that if one is willing to assume treatment timing is as good as random, one can obtain more eﬃcient estimates than using the staggered DiD methods discussed in Section 3.3. This builds on earlier work by McKenzie (2012), who highlighted that DiD is typically ineﬃcient in an RCT where lagged outcomes are observed, as well as a large literature in statistics on eﬃcient covariate adjustment in randomized experiments (e.g., Lin, 2013). Shaikh and Toulis (2021) propose a method for observational settings where treatment timing is random conditional on ﬁxed observable characteristics. We think that developing methods for observational settings where treatment timing is approximately random, possibly conditional on covariates and lagged outcomes, is an interesting area for further study in the years ahead. Sequential random assignment. As discussed in Section 3.4, an exciting new literature in DiD has begun to focus on settings where treatment can turn on and oﬀ and potential outcomes depend on the full path of treatments. A similar setting has been studied extensively in biostatistics, beginning with the pioneering work of Robins (1986). The key diﬀerence is that the biostatistics literature has focused on sequential random assignment (a.k.a. sequential ignorability) assumptions that impose that treatment in each period is random conditional on the path of covariates and realized outcomes, rather than parallel trends. We think that integrating these two literatures — e.g., understanding when parallel trends is preferable to sequential ignorability and vice versa, and whether there are any fruitful combinations of the two assumptions — is an interesting area for future research. Spillover eﬀects. The vast majority of the DiD literature imposes the SUTVA assumption, which rules out spillover eﬀects. However, spillover eﬀects may be important in many economic applications, such as when policy in one area aﬀects neighboring areas, or when individuals are connected in a network. Butts (2021) provides some initial work in this direction by extending the framework of Callaway and Sant’Anna (2021) to allow for local spatial spillovers. Huber and Steinmayr (2021) also consider extensions to allow for spillover eﬀects. We suspect that in the coming years, we will see more work on DiD with spillovers. Conditional treatment eﬀects. The DiD literature has placed a lot of emphasis on learning about the ATT’s of diﬀerent groups. However, in many situations, it may also be desirable to better understand how these ATT’s vary between subpopulations deﬁned by covariate values. For instance, how does the average treatment eﬀect of a training program on earnings vary according to the age of its participants? Abadie (2005) provides re-weighting methods to tackle these types of questions using linear approximations. However, recent research has shown that data-adaptive/machine-learning procedures can be used to more ﬂexibly estimate treatment eﬀect heterogeneity in the context of RCTs or cross-sectional observational studies with unconfoundedness (e.g., Lee, Okui and Whang, 2017; Wager and Athey, 2018; Chernozhukov, Demirer, Duﬂo and Fernández-Val, 2020). Whether such tools can be adapted to estimate treatment eﬀect heterogeneity in DiD setups is a promising area for future research. Triple diﬀerences. A common variant on DiD is triple-diﬀerences (DDD), which compares the DiD estimate for a demographic group expected to be aﬀected by the treatment to a DiD for a second demographic group expected not to be aﬀected (or eﬀected less). For example, Gruber (1994) studies the impacts of mandated maternity leave policies using a DDD design that compares the evolution of wages between treated/untreated states, before/after the law passed, and between married women age 20-40 (who are expected to be aﬀected) and other workers. DDD has received much less attention in the recent literature than standard DiD. We note, however, that DDD can often be cast as a DiD with a transformed outcome. For example, if we deﬁned the state-level outcome age 20-40 and other workers, then Gruber (1994)’s DDD analysis would be equivalent to a DiD analysis using a more formal analysis of DDD along with practical recommendations for applied researchers would be a useful direction for future research. Connections to other panel data methods. DiD is of course one of many possible panel data methods. One of the most prominent alternatives is the synthetic control (SC) method, pioneered by Abadie, Diamond and Hainmueller (2010). Much of the DiD and SC literatures have evolved separately, using diﬀerent data-generating processes as the baseline (Abadie, 2021). Recent work has begun to try to combine insights from the two literatures (e.g., Arkhangelsky, Athey, Hirshberg, Imbens and Wager, 2021; Ben-Michael, Feller and Rothstein, 2021a,b; Doudchenko and Imbens, 2016). We think that exploring further connections between the literatures — and in particular, providing clear guidance for practitioners on when one we should expect one method to perform better than the other, or whether one should consider a hybrid of the two — is an interesting direction for future research. This paper synthesizes the recent literature on DiD. Some key themes are that researchers should be clear about the comparison group used for identiﬁcation, match the estimation and inference methods to the identifying assumptions, and explore robustness to possible violations of those assumptions. We emphasize that context-speciﬁc knowledge will often be needed to choose the right identifying assumptions and accompanying methods. We are hopeful that these recent developments will help to make DiD analyses more transparent and credible in the years to come. – Is everyone treated at the same time? If yes, and panel is balanced, estimation with TWFE speciﬁcations such as (5) or (7) yield easily interpretable estimates. If no, consider using a “heterogeneity-robust” estimator for staggered treatment timing as described in Section 3. The appropriate estimator will depend on whether treatment turns on/oﬀ and which parallel trends assumption you’re willing to impose. Use TWFE only if you’re conﬁdent in treatment eﬀect homogeneity. – Are you sure about the validity of the parallel trends assumption? If yes, explain why, including a justiﬁcation for your choice of functional form. If the justiﬁcation is (quasi-)random treatment timing, consider using a more eﬃcient estimator as discussed in Section 6. If no, consider the following steps: 1. If parallel trends would be more plausible conditional on covariates, consider a 2. Assess the plausibility of the parallel trends assumption by constructing an event- 3. Accompany the event-study plot with diagnostics of the power of the pre-test 4. Report formal sensitivity analyses that describe the robustness of the conclusions – Do you have a large number of treated and untreated clusters sampled from a super-population? If yes, then use cluster-robust methods at the cluster level. A good rule of thumb is to cluster units whose treatment assignment is correlated (e.g. residents of the same state, when policy is at the state level); see Section 5.2. If you have a small number of treated clusters, consider using one of the alternative inference methods described in Section 5.1. If you can’t imagine the super-population, consider a design-based justiﬁcation for inference instead, as discussed in Section 5.2.