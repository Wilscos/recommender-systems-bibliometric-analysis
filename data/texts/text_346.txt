Inferring the substitutable and complementary products for a given product is an essential and fundamental concern for the recommender system. To achieve this, existing approaches take advantage of the knowledge graphs to learn more evidences for inference, whereas they often suﬀer from invalid reasoning for lack of elegant decision making strategies. Therefore, we propose a novel Knowledge-Aware Path Reasoning (KAPR) model which leverages the dynamic policy network to make explicit reasoning over knowledge graphs, for inferring the substitutable and complementary relationships. Our contributions can be highlighted as three aspects. Firstly, we model this inference scenario as a Markov Decision Process in order to accomplish a knowledge-aware path reasoning over knowledge graphs. Secondly, we integrate both structured and unstructured knowledge to provide adequate evidences for making accurate decision-making. Thirdly, we evaluate our model on a series of real-world datasets, achieving competitive performance compared with state-of-the-art approaches. Our code is released on https://gitee.com/yangzijing ﬂower/kapr/tree/master . Keywords: Recommender system, Knowledge graph 1. Introduction products boosts the development of recommender system [1, 2, 3, 4, 5]. Substitutable relationship links two products with similar functions and can be substituted with each other. Complementary relationship links two products with same usage scenarios but playing complementary roles. These two product relationships are of great signiﬁcance when recommended to users with diﬀerent purchase intentions [6]. For instance, it is reasonable to recommend a Samsung Galaxy S10 Plus as a substitutable product for a user who is browsing the page of iPhone11 Pro. Meanwhile, after the purchase, the recommender system should recommend phone’s complements, for instance, USB charging cable, to the user. The contribution of this article to the community can be viewed from both the user and the e-commerce platforms. From the user’s point of view, the signiﬁcance of the research is to make recommendations based on the user’s behavior, make recommendations that are more in line with the user’s preference, improve the user’s shopping eﬃciency. From the perspective of e-commerce platforms, the signiﬁcance of this task is to reduce redundant recommendations and increase the success rate of transactions. tation, which can be categorized into text-based methods and relation-based methods. The text-based approaches use diﬀerent methods to learn product representation, such as Latent Dirichlet Allocation (LDA) [7] and variational autoencoders (VAE) [8]. The relation-based methods learn product representation through the relationship constraints between products, such as PMSC [9] and SPEM [10]. They incorporate product embedding with constraints to further promote the distinction between two relationships. DecGCN encodes the semantic representation of products through GCN on an product graph and model product substitutability and complementarity in two spaces [11]. topological information of knowledge graph is still under-exploited. Most of the existing methods suﬀer from two shortcomings. (1) None of these models Understanding substitutable and complementary relationships between The mainstream of existing researches focus on modeling product represen- Although the previous methods have made progress, the exploration of Navigation Gaming Sensor.  [Computers & Accessories, considers the issue of ﬁne-grained inference, which takes into account product characteristics. Judgments solely rely on product representation fails to derive the ﬁne-grained characteristics of their relevance. For example, they can’t ﬁnd a substitute featuring ‘Bluetooth’ to a given keyboard. (2) Inferences lack interpretability. Existing models can only estimate the probabilities of the substitutable and complementary relationships, but the reason cannot be further explained. The inferring result may not be convincing if the algorithm can not be interpreted. Reasoning (KAPR) method to infer substitutable and complementary relationships over knowledge graph. Speciﬁcally, we ﬁrst construct a knowledge graph by extracting structured information from e-commerce datasets to better tackle the problems in ﬁne-grained inference and interpretability [12]. Then we design diﬀerent meta-paths comprising of ﬁne-grained characteristics (e.g., brand, word, category) for modeling substitutable and complementary relationships, which enables the agent to navigate over potential products with speciﬁed characteristics through these meta-paths. Based on these, the proposed model can cast the product relationship inference task into a path reasoning problem over product-level MFI score for complementary relationreward To overcome these two shortcomings, we propose a Knowledge-Aware Path knowledge graph and make accurate decisions with dynamic policy networks. structured and unstructured knowledge to explicitly guide the reasoning path and increase the interpretability of the model. On one hand, we leverage structured knowledge to construct a graph with constraints to provide the model with necessary adjacent information and eliminate many irrelevant products, eﬀectively narrowing the search space with a pruning strategy to ensure reasoning accuracy. On the other, we propose a Multi-Feature Inference (MFI) component based on relevant unstructured knowledge (e.g. title, description, category, and relevance) to construct a novel reward function in order to guide the learning process. the proposed model to ﬁnd a candidate product which has a substitutable relationship with ‘mouse A’. To perform this inference, the KAPR ﬁrst constructs a knowledge graph shown in the lower right part of the ﬁgure, and then utilizes a dynamic policy network to reason over this graph. More precisely, starting from ‘mouse A’, the agent ﬁrst obtains adequate features from adjacent entities to search for possible paths with two-hop traversal over knowledge graph, and then adopt the pruning strategy to narrow search space into a valid subspace, including two paths ‘mouse A — noiseless — mouse B’ and ‘mouse A — keyboard — memory’. Next, this agent relies on MFI component to exploit unstructured knowledge from both product and category-level (e.g. ‘Computers & Accessories’) to obtain relevance scores of substitutable products, constituting reward function to guide path reasoning toward the right direction. Finally, the KAPR reaches the target entity ‘mouse B’ with a highest rank. 1. To accurately infer the substitutable and complementary relationships, The superior advantage of KAPR is that we elaborately incorporate both An example is illustrated in Figure1. Given an entity ‘mouse A’, we expect Signiﬁcant contributions of this work can be summarized as follows: we propose a Knowledge-Aware Path Reasoning (KAPR) model, which leverages dynamic policy networks, to perform in-depth reasoning over knowledge graphs, opening up the avenue of utilizing knowledge-aware reasoning into ﬁne-grained product relationship inference. 2. We integrate both structured features from knowledge graph and un- 3. The extensive experimental evaluation on real-world datasets shows that 2.1. Product Relationship Inference ships between products in recommender systems. Previous studies formulate the task of substitutable and complementary relationship inference as a supervised link prediction problem. Sceptre is the ﬁrst proposed model to tackle the inference which constructs product representation from textual information through LDA [13]. However, Sceptre neglects the relationships information and does not always work well since LDA is not eﬀective for short texts. Further, PMSC adopts a novel loss function with relation constraints to distinguish between the substitutes and complements[9], and LVAE links two variational auto-encoders to learn latent features over product reviews[8]. SPEM considers both textual information and relational constraints [10], and DecGCN exploits the graph structure to learn product representations in diﬀerent relationship spaces [11]. Nevertheless, all these methods suﬀer from two drawbacks. Firstly, these models can not perform a ﬁne-grained inference since the embedding modules donot take word-level characteristics into consideration. Secondly, these models are lack of explainability due to the fact that probability values cannot reveal the original relationships. Therefore, we aim to propose a novel framework to provide accurate recommendations with explicit inferences. structured textual information to provide adequate evidences for exact decision-making. Meanwhile, the reward function newly constituted from unstructured knowledge also enables the path reasoning toward a right direction over knowledge graph. the our model can successfully tackle substitutable and complementary relationship inference with interpretable path reasoning, surpassing all previous state-of-the-art approaches. In this paper, we mainly focus on substitutable and complementary relation- 2.2. Reinforcement Learning in Recommendation ommender systems [14, 15], such as multi-agent RL-based model [16], the hierarchical RL-based model [17]. Reinforcement learning has received a series of attention, it can understand the environment, and has a certain reasoning ability. Reinforcement learning has been widely used in recommender systems, such as product recommendation [18], advertisement recommendation [19] and explainable recommendation [20]. Among them, Xian regards users, commodities and their related attributes as nodes, and trains the agent to ﬁnd the potential purchase relationship between user and products[1]. Based on the Q-Learning method, Zheng et al. simulate the rewards given by users to complete the news recommendation task[2]. Wang et al. designed an interpretability framework based on reinforcement learning, which can be ﬂexibly explained according to usage scenarios[3]. PGPR [18] is an RL-based path reasoning model for personalized recommendation. Compared with previous RL-based models, PGPR achieves higher accuracy and can give explicit evidences for inference. However, its policy network is static, unable to encode large-scale action spaces. PGPR only uses structured knowledge for reward function, ignoring the information in unstructured knowledge, resulting in poorly guided and unwell reward signals. In this paper, our method addresses the issues by proposing a knowledge-aware path reasoning method and integrating structured and unstructured knowledge to guide the reasoning. 3. Problem Formulation a given product v E, r ∈ R}, where E is the entity set and R is the relation set which consists of six type of relationships. e and e r represents the relationship between entities. category’, ‘product-produced by-brand’, ‘product-purchase-user’, ‘product- Recently, many reinforcement learning (RL) based models applied in rec- This task aims to ﬁnd the substitutable and complementary products for The relationship tuples are ‘product-described by-word’, ‘product-belongalso bought-product’, ‘product-also viewed-product’. The tuple (e, r, e ﬂects the facts that e and e entity and r is a type of relationship. ‘Also bought’ indicates that two products are often purchased together. ‘Also viewed’ indicates that two products are often viewed together. We follow the deﬁnition of previous work, and call two products with also bought relationship as complementary products, and two products with also viewed relationship as substitutable products. In this setting, substitutable product inference requires the model to ﬁnd a product set ship of ‘also viewed’ with the starting product v the model to ﬁnd certain products which have a relationship of ‘also bought’. (KAPR) to infer substitutable and complementary relationships over knowledge graph. The overall structure of the proposed model is illustrated in Figure2. In this method, we formulate this relationship inference task as an MDP environment and adopt an agent to navigate the products with a potential relationship (substitutable or complementary) of the given product. At the inference stage, the trained agent samples a series of paths for each product, and all products on the path constitute the candidate product sets. The ﬁnal ranking of substitutable and complementary products are obtained by sorting the candidate product sets based on corresponding scores. lation of MDP in Section 4.1, and then introduce detailed working principles of knowledge-aware path reasoning in Section 4.2. In Section 4.3, we will describe the ﬁnal step which conducts the relationship inference with knowledge-aware reasoning via dynamic policy network on the graph. ‘Also bought’ and ‘also viewed’ are abstracts from user behavior. consists of the tuples, whereas complementary product inference requires In this section, we propose the Knowledge-Aware Path Reasoning method The rest of this section is organized as follows: we will start with the formu- 4.1. Formulation as Markov Decision Process consists of a product set V , a word set W , a brand set B, a category set C and a user set U. The deﬁnition of entities and relationships is in Table1. Therefore, the graph can be represented as G = {(e, r, e tuple stands for the fact that e and e above six types. We regard each (e, r, e relationship in the knowledge graph G. There are 6 kinds of tuples in the knowledge graph, representing 6 kinds of relations between entities in the emarket scene The tuples have the same meaning as previous work [18]. v, b, c, u, w represent products, brands, categories, users, and words respectively, where v ∈ V , b ∈ B, c ∈ C, u ∈ U, w ∈ W , v of tuples include (v (v, produced by, b), (v, purchase, u), (v, described, w). describe the MDP environment [21]. The environment informs the agent search state s product, it gets the reward R. Formally, the MDP environment can be deﬁned by a tuple (S, A, δ, ρ), where S denotes the state space, δ : S × A → S refers to the state transition function, and ρ : S × A → R is the reward function. We start the path reasoning process at product v The knowledge graph G has a relation set R and an entity set E which We follow the terminologies commonly used in reinforcement learning to and the complete action apace Aat time t. When the agent ﬁnds a • State: The initial state sis represented as s= v. When we consider k-step history, the state sat step t is deﬁned as Equation 1. • Action: For state s, the action is deﬁned as a= (r, e), where e is the next entity and ris the relationship that connects eand e. The complete action space Ais deﬁned as all edges connected to entity e excluding history entities and relationships. Because some nodes have a very large outgoing degree, we propose a pruning strategy with structured 4.2. Knowledge-Aware Path Reasoning policy network and the reward function with unstructured knowledge . 4.2.1. Pruning Strategy with Structured Knowledge egy using structured knowledge. This strategy needs to retain actions that help inference keeping nodes that are closely associated with v egy consists of two stpdf. First, we exclude impossible edges based on the meta path patterns, then the scoring function f((r, e)|v a value conditioned on the starting product v as the pruned action space of the state s initialize all entity and relationship representations [22]. All types of entities have a 1-hop pattern with the product entity, such as user knowledge for action pruning. The pruned action space is represented as ˜A. The detail of the pruning strategy is further explained in the next section. • Transition: Given state sand action a, the transition to the next state • Reward: In the path ﬁnding process, for the model to learn the fundamental reasoning process, we design diﬀerent meta paths for the two relationships. Only when the agent generates a path that ﬁts in the meta paths and ends with a product, a reward is calculated. In other cases, the reward is 0. For the relationship sparseness problem, using binary rewards can lead to inadequate supervision. Instead, we use a reward function with unstructured Knowledge to guide the reasoning. The detail of the reward function is further explained in the next section. Now we present the pruning strategy with structured knowledge, dynamic Since some nodes have much larger out-degrees, we propose a pruning stratproduct complementary) between product entities, we choose the maximum of the two scores. The scoring function is deﬁned as Equation 3. Here, r types of nodes. 4.2.2. Dynamic Policy Network maximizes the expected cumulative reward for the path reasoning. We design a dynamic policy network that can select actions in a dynamically changing space. The policy network π(·|s, embeddings a aﬃnity between s and each action and we apply a softmax function to normalize the aﬃnity into a probability distribution. The structure of the dynamic policy network is deﬁned in Equation 4. Here, s and s is an action-to-vector lookup table, and a action and D is the maximum size of the space action. s is represented as the concatenation of the embedding (v f((r, e)|v) =max(< v+ r, e > +b,(3) is the relationship that directly connects product nodes and other Based on the MDP formulation, our goal is to learn a policy network π that We map s and ainto a shared learnable feature space and compute their are the embedding and hidden features of all actions in˜A. s ∈ R, , a∈ R. a∈ R, M ≤ D, M is the size of the space action a entity and relationship embeddings learned by TransE. The model parameters for both networks are denoted as θ = {W gradient is deﬁned as Equation 5. Here, G is the discounted cumulative reward from the initial state to the terminal state. 4.2.3. Reward Function with Unstructured Knowledge vance between two products. A general method uses TransE to calculate the distance between the entities as reward [18], but this method is not applicable in the sparse graph. Substitutable and complementary relationship is very sparse. The sparse reward leads to convergence problems in the path reasoning process. To solve this problem, we propose a model for extracting unstructured knowledge to generate more robust rewards. Unstructured knowledge contains more information, such as textual knowledge (product’s reviews and descriptions), which can accurately reﬂect the relevance of two products. We propose a Multi-Feature Inference component (MFI) as a prediction model that infers relationship based on category-level and product-level features. Introducing category-level features can provide shared semantic information among products that belong to the same category. Although labelled product pairs are sparse compared with the overall product set, MFI can learn the shared knowledge on category-level with product-level supervision signal. Figure3 shows an overview of the reward function model which consists of two MFI models. We consider the title of all products under the category as the document due to they usually give the main topic. First, we extract the most important F words in each document through TF-IDF [23]. For category c , we regard its textual knowledge as T = [w is represented as the concatenation of the embedding (r, e). is the concatenation of the embedding (a, ..., a). v, e, rare product, The training of the policy network needs rewards that measure the releinto embedding through Glove vector [24] and form an embedding sequence as T = [w Then a doc2vec model is used to infer a vector v product i. Product-level features are extracted from the well-trained model, and it is feasible to directly use them as product representation. However, through our experiment, it can achieve better results by applying a module consists of an MLP with mask-attention and BatchNormal [26]. The maskattention reads a feature vector and generates a soft mask vector with the same shape, and the mask-attention F The multi-layer perception consists of one mask-attention F layers F , w, ..., w] , w∈ R, where dis the dimension of word embedding. For product-level features, we ﬁrstly collect the descriptions of all products. . We can formulate the entire muti-layer perception as Equation 7. Here, the ﬁnal result y relationship r. We use a nonlinear classiﬁer to project all evidences to the probability. The loss function is deﬁned as Equation 8. are named as MFI s and MFI c, respectively. In our experiments, we ﬁnd that regardless of target relationship, substitutable and complementary relationship play an essential role in the reasoning process. For instance, two chargers substitute to each other and both of them are complements to a phone. No matter what kind of relationship the agent ﬁnds, both substitutes and complements are beneﬁcial to the reasoning. So we use the maximum value of MFI s and MFI c as a reward. The reward function is deﬁned as Equation 9. Here, MFI s(v have a substitutable or complementary relationship. 4.3. Inference Techniques knowledge-aware path reasoning via policy network on the graph. Our goal is to ﬁnd product set {v the explicit reasoning path P of paths, the agent should not repeatedly search for paths with big rewards. Therefore, we employ beam search to select actions guided by the dynamic policy network. Given a product v For link prediction, MFI emits the probability that vand vbelong to The models to predict the substitutable and complementary relationships The ﬁnal step is to solve the product relationship inference problem with T and sampling size at each step t, represented by K path at step t is SP retrieved node in SP structured knowledge the meta-path patterns. The meta-path patterns allow the agent to learn basic reasoning modes and its search direction is determined by structured knowledge. Secondly, employing beam search based on the action probability emitted by the dynamic policy network, the agent selects K actions with the highest probability to search. The dynamic policy network can handle dynamically changing action spaces and be rewarded by unstructured knowledge which means it can choose appropriate actions according to the current state. Thirdly, Save the retrieved path to SP the network are closely related to product v them can be used as explicit evidence of the association. We save paths with length greater than 1 and end with a product. These nodes may be substitutes or complements of v aiming to distinguish substitutes and complements. Finally, the products that appear in the training set are removed and we select top-N as the ﬁnal inference result. We ﬁrstly introduce the statistics of datasets, evaluation metrics, and experimental settings. And then, we present the statistics of all model’s performances and provide an ablation study to investigate the eﬀects of each component of the model. Next, we conduct a series of detailed analyses to illustrate the eﬀectiveness and interpretability of our model. Finally, we make an error analysis of the experimental results. The reasoning process at step t is as follows. First, the agent from the last After T stpdf of search, we get a network composed of paths. All nodes in We evaluate our model on four datasets to demonstrate the improvements. Phones and Accessories) and Electronics. Each dataset contains reviews and product metadata. The deﬁnition and statistics of entities and relations in each dataset can be found in Table1. We follow the method in previous work to keep the critical words in the reviews as features [18]. We randomly choose 85% of the data for training and the remain for testing. When training the MFI model, we randomly sample N non-links from the dataset. When training the KAPR model, we treat all products as candidate products instead of negative sampling. SPEM, Hits@k to evaluate rank-based methods. We vary the value of k by {10, 30, 50}. For each product pair (A, B) in the test set, we take the evaluation stpdf for Hits@k as follow [10]. (1) We randomly sample n products with We evaluate our model with 4 datasets [12]: Baby, Beauty, Cell Phone (Cell To measure the inference accuracy, we adopt the evaluation method in which product A is irrelevant, n is set to 500. (2) Among the n products, the number of products ranking before product B is m. (3) If m < k, we get a hit. Otherwise, we get a miss. malized Discounted Cumulation Gain (NDCG), Hit Ratio (HR), Recall and Precision as the evaluation metrics. We evaluate the metrics based on the top 10 recommended products for each product in the test set. For product A, we regard all products in the dataset as candidate products, except for products in the training set. we take stpdf as follow: (1) We get the candidate products list L based on MFI score. (2) We evaluate the metrics based on the top-k recommended products. k is set to 10. TF-IDF, that is, for each review, the 15 most critical words are selected as representatives. The dimension of each feature are d The hyper-parameter values for doc2vec: vector size=300. window size=20. For the MDP environment, we mainly refer to PGPR. The history length K = 1 for the state s sampling size is [25, 5, 1]. We set the maximum size of the action space D = 250 and the embedding size of entities and relationships is d learning rate for our model is 0.001, and the batch size is 16. 5.3. Results and Analysis ment product inference. Sceptre uses LDA to extract features from product textual information to predict the relationships [13]. LVA links two VAE to learn the content feature of products [8]. SPEM applies a semi-supervised deep Autoencoder to preserve the second-order proximity between products [10]. SPEM can only predict the substitute. PGPR is an RL-based path reasoning model for personalized recommendation [18]. It adopts a policy-based To further compare with the path reasoning model PGPR, we use Nor- The parameter setting for the MFI model is as follow: F is set to 15 for We compare KAPR with the following models in substitute and complemethod to reason in the knowledge graph. We adjust the model so that PGPR can infer the product relationship. DecGCN models the substitutability and complementarity of products in separated embedding spaces [27]. To test the performance of the MFI model, we treat MFI as a supervised prediction model to infer relationship. MFI), the graph-based model (PGPR, KAPR) has achieved better results in almost all of the datasets. The main reason is that link constraints between entities ensure they have some share attributes (e.g., same brand, same feature), thus reducing candidate products’ search space and improving the accuracy rate. erage relative improvements of 18.0%, 24.7% in hits@10 on substitutable and complementary relationship inference. The main reason is that KAPR integrates structured and unstructured knowledge to enhance the discriminability of the model. The dynamic policy network can select actions in a dynamically changing space. This method solves the problem of model training diﬃculty due to the extensive action space in reinforcement learning. the proposed MFI model achieves better eﬀects. MFI has an average relative improvement of 4.11%, 4.49% in hits@50 on substitute and complement product inference. The result shows that it is necessary to consider the features of categories, which can solve the data sparsity problem. 5.3.1. The Ablation Study ablation experiments on knowledge fusion mechanism and dynamic policy network on four datasets. We are using hit@10, ndcg@10, recall@10, hr@10, and precision@10 as metrics. We design two variants of KAPR as follows. The results are shown in Figure4, Figure5, Figure6, Figure7. From the results in Table2, we can draw the following conclusions. (1) Compared with the embedding-based model (Sceptre, LVA, SPEM, (2) Compared with the most competitive model PGPR, KAPR has an av- (3) Compared with the models based only on the product-level feature, To further investigate each model component’s signiﬁcance, we conduct The results shows that the eﬀect of two variant models obtains lower performance on almost all metrics than KAPR. We can observe: (1)Both KAPR-M and KAPR-P are superior to PGPR for almost all metrics in four datasets. The results show that both the knowledge fusion algorithm and dynamic policy network play an essential role in the inference model. For example, the relative improvements of KAPR-M and KAPR-P over PGPR are at least 22.2% and 14.1% on substitutes inference and 6.0% and 9.0% on complements inference For all metrics. (2) Knowledge fusion algorithm and dynamic policy network apply to most datasets. We conduct 8 ablation experiments on 2 relationships of 4 datasets, and each experiment contained 5 evaluation metrics. The investigation ﬁnds that the knowledge fusion algorithm and dynamic policy network improve the metrics by 100% and 87.5%, respectively, proving that the two components have certain universality. (3) The reason that KAPR has better eﬀect than KAPR-M and KAPR-P can be summarized as follows. The result of KAPR-M shows that unstructured knowledge can better judge the relationship than structure knowledge. The reason for the poor eﬀect from KAPR-P is that the dynamic policy network can consider both the state vector and the action vector and selects the best action for the current state through the attention mechanism. 5.3.2. Visualization of Reasoning pattern output of the model in the reasoning process and then give a case study based on the correct results generated by the model. than one as valid paths. As shown in Table3, we observe that the total sampling paths are 250, and the success rate of eﬀective paths is 0.62 and 0.74. • KAPR-M: KAPR-M replaces MFI with reward function in the PGPR (TransE). • KAPR-P: KAPR-P replaces the dynamic policy network with that mentioned in PGPR. We analyze the interpretability of the model. We ﬁrstly analyze the path We analyze the validity of the path. We regard paths with length greater The result shows KAPR has good reasoning ability. The average number of related products per product for a relationship is 60. There are about three reasoning paths between each pair of products. The results indicates that the explanations are diverse. Figure8 shows examples of reasoning paths generated by our model. Our model can use rich relationships between entities for reasoning. The relationship between products can be explained by the reasoning path with the attribute node, brand node, or product node. In case 1, we infer that white sleeping bag and pink sleeping bag are complementary products because they had the same attribute (drafty). The potty chair is the white sleeping bag’s complement because they have the same complement (toy). In case 2, diﬀerent mascara cream styles are substitutable products because they belong to the same brand Yves Saint Laurent (YSL). The reasoning path in case 3 links several products (charger, data cable, battery) that are often purchased together to ﬁnd complementary ’charger suit’ of ’charger.’ In case 4, the inference path connects several ’Kodak’ products as explicit evidence for inference. 5.3.3. The Eﬀects of Relationships in the reasoning stage. We remove various relationships separately and observe the impact on reasoning. The results are shown in Figure9, and we have the following conclusions: (1) In the inference of the two relationships, the model mainly relies on ‘also viewed’ and ‘also bought’ for reasoning. Other relationships play a smaller role in the experimental results, and removing some edges can improve the experimental results. In future work, the research should focus on optimizing the graph structure. (2) The lack of a target relationship has the most signiﬁcant impact on the results. The reason is that the target relationship is the primary edge of the inference meta-paths, and the lack of target In this section, we further investigate the signiﬁcance of each relationship relation in the graph leads to the disconnection of part of the meta-paths. 5.3.4. Sampling Size in Path Reasoning diﬀerent sampling combinations, and each tuple (N1, N2, N3) represents the number of expansion nodes in each step. The total number of samples for each combination is N1*N2*N3=120 (except for the ﬁrst case). We test on the Cell phone and Electronics datasets, and the experimental results are as follows. Table4 reports the results in terms of NDCG@10, Recall@10, HR@10, We study the inﬂuence of sampling size for path reasoning. We design 9 and Prec@10. We observe that the ﬁrst two levels of sampling sizes play a signiﬁcant role in reasoning. For example, the result of combination (20,6,1), (20,3,2) is better than combination (10,12,1), (10,6,2). The main reason is that the agent can largely determine the direction of exploration in the ﬁrst two stpdf, and a larger search space can retrieve more good paths. 5.3.5. Inﬂuence of Fine-grained Features features on the experimental results. Experiments on Electronics dataset, random replace 10%-90% relationship, to observe the impact on the experimental results. Table6 is the average number of relationships for the head entity after random replacing a certain proportion of the relationships. Figure10 show the inﬂuence of diﬀerent proportions of ﬁne-grained attributes on the inference of substitutable and complementary relationships. The experimental results show that with the decrease of ﬁne-grained features, the accuracy of the prediction of the two relationships decreases, indicating the important role of ﬁne-grained attributes. 5.3.6. Inﬂuence of Action Pruning Strategy ferent sizes of pruned action spaces. For a given state, we prune actions with the scoring function deﬁned in Equation3. The action with a larger score has a greater correlation with the source product and is more likely to be preserved. The purpose of the experiment is to verify whether a larger action space is conducive to ﬁnding more accurate reasoning paths. We experiment on Electronics We design an experiment to verify the inﬂuence of the density of ﬁne-grained In this experiment, we evaluate the performance of KAPR varies with difrandom replacement radio dataset. The pruning space size is set from 100 to 500 with a step size of 100. The results are shown in Table7. The conclusions are as follows. Our model performance is slightly inﬂuenced by the size of the action space. The results ﬁrstly increased and then decreased with the size of the pruned action space. The results indicate that when the action space is small, the model can not fully explore. When the action space is too large, many unrelated action nodes are introduced, and the model may learn sub-optimal solutions in a larger space. 5.3.7. Error analysis mainly including two points. (1) Lack of relationships that facilitate reasoning. In Table8, we count the percentages of the correctly and error judged product pairs that have the same node in various relationships. The percentages of error We observe some error cases of our model and summarize the error reasons, cases in the ‘sub’ and ‘comp’ are much lower than those of correct issues. The conclusion is the same as in Figure9, which further illustrates that ‘sub’ and ‘comp’ play an essential role in reasoning. (2) In some categories, the distinction between the two relationships is not apparent. The concept of substitute and complement is derived from user behaviour. Products viewed by the same user are called substitutes, and bought together are called complement. However, some products may have both of the relationships. For example, two clothes with similar styles may be bought after comparison or purchased together. Therefore, the boundary between the two relations is relatively fuzzy, bringing speciﬁc diﬃculties to the model’s judgment. 6. Conclusion to infer the substitutable and complementary relationship, which integrates structured and unstructured knowledge to make the reasoning more robust. Based on dynamic policy network with an elegant reward function, our model achieves outstanding performance with explicit inferences. Experiments on four datasets demonstrate the remarkable performance of our model against previous state-of-the-art approaches. Since there exist more ﬁne-grained product relationships among real-world data, we expect this model to be of broad applicability in numerous diﬀerent tasks of recommender systems. In this paper, we propose a Knowledge-Aware Path Reasoning (KAPR)