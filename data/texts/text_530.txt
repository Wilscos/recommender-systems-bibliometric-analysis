Contracts are a common type of legal document that frequent in several day-to-day business workﬂows. However, there has been very limited NLP research in processing such documents, and even lesser in generating them. These contracts are made up of clauses, and the unique nature of these clauses calls for speciﬁc methods to understand and generate such documents. In this paper, we introduce the task of clause recommendation, as a ﬁrst step to aid and accelerate the authoring of contract documents. We propose a twostaged pipeline to ﬁrst predict if a speciﬁc clause type is relevant to be added in a contract, and then recommend the top clauses for the given type based on the contract context. We pretrain BERT on an existing library of clauses with two additional tasks and use it for our prediction and recommendation. We experiment with classiﬁcation methods and similarity-based heuristics for clause relevance prediction, and generation-based methods for clause recommendation, and evaluate the results from various methods on several clause types. We provide analyses on the results, and further outline the advantages and limitations of the various methods for this line of research. A contract is a legal document between at least two parties that outlines the terms and conditions of the parties to an agreement. Contracts are typically in textual format, thus providing a huge potential for NLP applications in the space of legal documents. However, unlike most natural language corpora that are typically used in NLP research, contract language is repetitive with high inter-sentence similarities and sentence matches (Simonson et al., 2019), calling for new methods speciﬁc to legal language to understand and generate contract documents. A contract is essentially made up of clauses, which are provisions to address speciﬁc terms of the agreement, and which form the legal essence of the contract. Drafting a contract involves selecting an appropriate template (with skeletal set of clauses), and customizing it for the speciﬁc purpose, typically via adding, removing, or modifying the various clauses in it. Both these stages involve manual effort and domain knowledge, and hence can beneﬁt from assistance from NLP methods that are trained on large collections of contract documents. In this paper, we attempt to take the ﬁrst step towards AI-assisted contract authoring, and introduce the task of clause recommendation, and propose a two-staged approach to solve it. There have been some recent works on itembased and content-based recommendations. Wang and Fu (2020) reformulated the next sentence prediction task in BERT (Devlin et al., 2019) as next purchase prediction task to make a collaborative ﬁltering based recommendation system for ecommerce setting. Malkiel et al. (2020) introduced RecoBERT leveraging textual description of items such as titles to build an item-to-item recommendation system for wine and fashion domains. In the space of text-based content recommendations, Bhagavatula et al. (2018) proposed a method to recommend citations in academic paper drafts without using metadata. However, legal documents remain unexplored, and it is not straightforward to extend these methods to recommend clauses in contracts, as these documents are heavily domain-speciﬁc and recommending content in them requires speciﬁc understanding of their language. In this paper, clause recommendation is deﬁned as the process of automatically providing recommendations of clauses that may be added to a given contract while authoring it. We propose a twostaged approach: ﬁrst, we predict if a given clause type is relevant to be added to the given input contract; examples of clause types include governing laws, conﬁdentiality, etc. Next, if a given clause type is predicted as relevant, we provide contextaware recommendations of clauses belonging to Figure 1: CLAUSEREC pipeline: Binary classiﬁcation + generation for clause recommendation. the given type for the input contract. We develop CONTRACTBERT, by further pre-training BERT using two additional tasks, and use it as the underlying language model in both the stages to adapt it to contracts. To the best of our knowledge, this is the ﬁrst effort towards developing AI assistants for authoring and generating long domain-speciﬁc legal contracts. A contract can be viewed as a collection of clauses with each clause comprising of: (a) the clause label that represents the type of the clause and (b) the clause content. Our approach consists of two stages:(1)clause type relevance prediction: predicting if a given clause type that is not present in the given contract may be relevant to it, and(2) clause recommendation: recommending clauses corresponding to the given type that may be relevant to the contract. Figure 1 shows an overview of our proposed pipeline. First, we build a model to effectively represent a contract by further pre-training BERT, a pre-trained Transformer-based encoder (Devlin et al., 2019), on contracts to bias it towards legal language. We refer to the resulting model asCONTRACTBERT. In addition to masked language modelling and next sentence prediction, CONTRACTBERT is trained to predict (i) if the words in a clause label belong to a speciﬁc clause, and (ii) if two sentences belong to the same clause, enabling the embeddings of similar clauses to cluster together. Figure 2 and 3 show the difference in the performance of BERT and CONTRACTBERT to get a meaningful clause embedding. BERT is unable to differentiate between the clauses of different types as it is unfamiliar with legal language. On the other Figure 3: Clustering of clauses using ContractBERT hand, CONTRACTBERT is able to cluster similar clause types closely while ensuring the separation between clauses of two different types. Given a contract and a speciﬁc target clause type, the ﬁrst stage involves predicting if the given type may be relevant to be added to the contract. We train binary classiﬁers for relevance prediction for each of the target clause types. Given an input contract, we obtain its CONTRACTBERT representation as shown in Figure 1. Since the number of tokens in the contracts are usually very large ( 512), we obtain the contextual representations of each of the clauses present and average their [CLS] embeddings to obtain the contract representation ct_rep. This representation is fed as input to a binary classiﬁer which is a small fully-connected neural network that is trained using binary cross entropy loss. We use a probability score of over 0.5as a positive prediction, i.e., the target clause type is relevant to the input contract. Once a target clause type is predicted as relevant, the next stage is to recommend clause content corresponding to the given type for the contract. We model this as a sequence-to-sequence generation task, where the the input includes the given contract and clause label, and the output contains relevant clause content that may be added to the contract. We start with a transformer-based encoder-decoder architecture (Vaswani et al., 2017), follow (Liu and Lapata, 2019) and initialize our encoder with CONTRACTBERT. We then train the transformer decoder for generating clause content. As mentioned above, the inputs for the encoder comprise of a contract and a target clause type. We calculate the representations of all possible clauses belonging to the given type in the dataset using CONTRACTBERT, and their [CLS] token’s embeddings are averaged, to obtain a target clause type representation trgt_cls_rep.This trgt_cls_rep and the contract representation ct_rep are averaged to obtain the encoding of the given contract and target clause type, which is used as input to the decoder. Note that since CONTRACTBERT is already pre-trained on the contracts, we do not need to train the encoder again for clause generation. Given the average of the contract and target clause type representation as input, the decoder is trained to generate the appropriate clause belonging to the target type which might be relevant to the contract. Note that our generation method provides a single clause as recommendation. On the other hand, with retrievalbased methods, we can obtain multiple suggestions for a given clause type using similarity measures. We evaluate three methods for clause type relevance prediction + clause recommendation:(1) Binary classiﬁcation + clause generation, which is our proposed approach;(2)Collaborating ﬁltering + similarity-based retrieval; and(3)Document similarity + similarity-based retrieval. Collaborating ﬁltering (CF) + similarity-based retrieval.Clause type relevance prediction can be seen as an item-item based CF task (Linden et al., 2003) with contracts as users and clause types as items. We construct a contract-clause type matrix, equivalent to the user-item matrix. If contractu contains clause typei, the cell(u, i)gets the value 1, otherwise0. We then compute the similarity between all the clause type pairs (i, j), using an adjusted cosine similarity, given by, sim(i, j) =qPqP(1) We obtain the item similarity matrix using this cosine score, and use it to predict if a target clause typetis relevant to a given contract. We compute the score fortusing the weighted sum of the score of the other similar clause types, given by, score(u, t) =P+ ¯r Iftgets a high score and is not already present in the contract, it is recommended. We experiment with multiple thresholds above which a clause type may be recommended. Given a clause library containing all possible clause types and their corresponding clauses, clause content recommendation can be seen as a similarity-based retrieval task. For a given contract and a target clause typet, we use ct_rep and trgt_cls_rep, and ﬁnd cosine similarities with each of the clauses belonging totto ﬁnd the most similar clauses that may be relevant to the given contract. We do so by computing the similarity of either (i) ct_rep or (ii) (ct_rep + trgt_cls_rep)/2, with individual clause representations. Document similarity + similarity-based retrieval.This is based on using similar documents to determine if a target clause typetcan be recommended for a given contract. The hypothesis is that similar contracts tend to have similar clause types. To ﬁnd similar documents, we compute cosine similarities between the given contract’s representations ct_rep with those of all the contracts in the (training) dataset to identify the topksimilar contracts. Iftis present in any of theksimilar contracts and is not present in the given contract, it is recommended as a relevant clause type to be added Table 1: Clause type relevance prediction results. to the contract. We experiment withk ∈ {1, 5}. Similarity-based retrieval for clause content recommendation is same as above. Metrics.We evaluate the performance of clause type relevance prediction using precision, recall, accuracy and F1-score metrics, and that of the clause content recommendation using ROUGE (Lin, 2004) score. Data.We use the LEDGAR dataset introduced by Tuggener et al. (2020). It contains contracts from the U.S. Securities and Exchange Commission (SEC) ﬁlings website, and includes material contracts (Exhibit-10), such as shareholder agreements, employment agreements, etc. The dataset contains 12,608 clause types and 846,274 clauses from around 60,000 contracts. Further details on the dataset are provided in the appendix. Since this dataset can not be used for our work readily, we preprocess it to create proxy datasets for clause type relevance prediction and clause recommendation tasks. For the former, for a target clause typet, we consider the labels relevant and not relevant for binary classiﬁcation. For relevant class, we obtain contracts that contain a clause corresponding tot, and remove this clause; given such a contract as input in whichtis not present, the classiﬁer is trained to predicttas relevant to be added to the contract. For the not relevant class, we randomly sample an equal number of contracts that do not containtin them. For recommendation, we use the contracts that containt(i.e., the relevant class contracts); the inputs consist of the contract with the speciﬁc clause removed andt, and the output is the clause that is removed. For both the tasks, we partition these proxy datasets into train (60%), validation (20%) and test (20%) sets. These ground truth labels ({relevant, not rel- Table 2: Clause content recommendation results. evant} for the ﬁrst task and the clause content for the second task) that we removed are used for evaluation. The implementation details are provided in appendix. Table 1 summarizes the results of the three methods (CF-based, document similarity-based and binary classiﬁcation) for the clause type relevance prediction task. For the tasks, we report results on the thresholds,kand learning rate which gave best results on the validation set (the ablation results are reported in the appendix). The CF-based method gives the best recall values for all the clause types, while the precision, accuracy and F1 scores are worse compared to the other two methods. This method does not incorporate any contextual information of the contract clause content and relies only on the presence or absence of clause types to predict if a target type is relevant, thus resulting in high recall and low precision and F1 scores. While the results of document similarity-based and classiﬁcation methods are comparable, both have merits and demerits. While the document similarity-based method is simpler and more extensible than classiﬁcation which requires training a new classiﬁer for each new clause type, the former requires a large collection of possible contracts to obtain decent results (particularly the recall values), which may not be available always. Further, the performance of document similarity method is dependent onk. This can be seen in the lower recall values for the document similarity method compared to those of classiﬁcation. The storage costs associated with the contract collection can also become a bottleneck for the document similarity method. Also, currently there is no way to rank the clauses in the similar contracts, and hence its recommendations cannot be scoped, while in classiﬁcation, the probability scores can be used to rank the clause types for relevance. On an average, the F1 scores for binary classiﬁcation are highest compared to the other methods, while the accuracies are comparable with the document similarity method. Table 2 shows the results for clause content recommendation using similarity and generationbased methods. For the sim-based method, we use the clause with the highest similarity to compute ROUGE. The scores using only ct_rep are lower than those with trgt_cls_rep. This is expected as trgt_cls_rep adds further information on the clause type for which the appropriate clauses are to be retrieved. Finally, the generation-based method results in the best scores for clause recommendation, thus indicating the usefulness of our proposed approach for this task. Some qualitative examples using both the methods are provided in appendix. For clause content recommendation, we focused primarily on relevance (in terms of ROUGE). In general, retrieval-based frameworks, like the one we proposed, are mostly extractive in nature, and hence might be perceived as “safer” (or factual) to avoid any noise and vocabulary change in clauses that may be incorporated by generation methods, particularly in domains like legal. However, they can also end up retrieving clauses irrelevant to the contract context at times, as we note from their lower ROUGE scores, as retrieval is based on similarity heuristics which may not always capture relevance, while generation is trained to generate the speciﬁc missing clause in each contract. We also notice that generated clauses have lower linguistic variations in them, i.e., generated clauses belonging to one type often look alike. However, this is expected as most clauses look very similar with only a few linguistic and content variations. We believe because clauses have this repetitive nature, there is a large untapped opportunity to leverage NLP methods for legal text generation while accounting for the nuances and factuality in them, to build more accurate clause recommendation frameworks. We believe our work can provide a starting point for future works to build powerful models to capture the essence of legal text and aid in authoring them. In the future, we aim to focus on balancing the relevance and factuality of clauses recommended by our system. We addressed AI-assisted authoring of contracts via clause recommendation. We proposed CLAUSEREC pipeline to predict clause types relevant to a contract and generate appropriate content for them based on the contract content. The results we get on comparing our approach with similaritybased heuristics and traditional ﬁltering-based techniques are promising, indicating the viability of AI solutions to automate tasks for legal domain. Efforts in generating long contracts are still in their infancy and we hope our work can pave way for more research in this area.