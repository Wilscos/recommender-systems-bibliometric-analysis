Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189 CRIStAL, F-59000 Lille, France Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189 CRIStAL, F-59000 Lille, France The multi-armed bandit (MAB) is a popular framework to model sequential decision making problems. At each round and it receives a random reward Among the many problem settings studied in this context, we focus on pure exploration, where the learner aims at maximizing the information gain for answering a given query about the arms [ particular, we are interested in ﬁnding a subset of known as the TopTop-1) identiﬁcation problem [ recommendation and drug repurposing [ hand, in the ﬁxed-budget setting [ a subset of hand, in the ﬁxed-conﬁdence setting [ returning a subset of of samples collected before the algorithm stops. This paper focuses on the latter. 35th Conference on Neural Information Processing Systems (NeurIPS 2021). Université de Paris, NeuroDiderot, Inserm, F-75019 Paris, France We study the problem of the identiﬁcation ofmarms with largest means under a ﬁxed error rateδ(ﬁxed-conﬁdence Top-midentiﬁcation), for misspeciﬁed linear bandit models. This problem is motivated by practical applications, especially in medicine and recommendation systems, where linear models are popular due to their simplicity and the existence of efﬁcient algorithms, but in which data inevitably deviates from linearity. In this work, we ﬁrst derive a tractable lower bound on the sample complexity of anyδ-correct algorithm for the general Top-m identiﬁcation problem. We show that knowing the scale of the deviation from linearity is necessary to exploit the structure of the problem. We then describe the ﬁrst algorithm for this setting, which is both practical and adapts to the amount of misspeciﬁcation. We derive an upper bound to its sample complexity which conﬁrms this adaptivity and that matches the lower bound whenδ → 0. Finally, we evaluate our algorithm on both synthetic and real-world data, showing competitive performance with respect to existing baselines. t > 0, a learner chooses an armkamong a ﬁnite set ofK ∈ Npossible options, mbest arms while minimizing the probability of error in identiﬁcation. On the other In practice, information about the arms is typically available (e.g., the characteristics of an item in a recommendation system, or the inﬂuence of a drug on protein production in a clinical application). This side information inﬂuence the expected rewards of the arms, thus adding structure (i.e., prior knowledge) to the problem. This is in contrast to the classic unstructured MAB setting, where the learner has no prior knowledge about the arms. Due to their simplicity and ﬂexibility, linear models have become the most popular to represent this structure. Formally, in the linear bandit setting [3 product between known This model has led to many provably-efﬁcient algorithms for both best-arm [ Top-midentiﬁcation [ hold only when the expected rewards are perfectly linear in the given features, a property that is often violated in real-world applications. In fact, when using linear models with real data, one inevitably faces the problem of misspeciﬁcation, i.e., the situation in which the data deviates from linearity. A misspeciﬁed linear bandit model is often described as a linear bandit model with an additive term to encode deviation from linearity. Formally, the expected reward can be decomposed into its linear part of this model: for highly structured, as the mean rewards of different arms are related through the common parameter θ; whereas when the misspeciﬁcation vector an unstructured one, since knowing the linear part alone provides almost no information about the expected rewards. Learning in this setting thus requires adapting to the scale of misspeciﬁcation, typically under the assumption that some information about the latter is known (e.g., an upper bound εtokηk). Due to its importance, this problem has recently gained increasing attention in the bandit community for regret minimization [ context of pure exploration. In this paper, we take a step towards bridging this gap by studying ﬁxed-conﬁdence Topcontributions are as follows. Contributions. algorithm for the general Topthat knowing an upper bound in the sense that any complexity than that obtainable when no structure is available. (3) We design the ﬁrst algorithm for Top-m complexity that holds for any our analysis reveals a nice adaptation to the value of the linear case ( in the unstructured case ( algorithm on synthetic problems and real datasets from drug repurposing and recommendation system applications, while showing competitive performance with state-of-the-art methods. Related work. several attempts to tackle this problem in the context of regret minimization exist. In [ show that, if on linear models, there exists a misspeciﬁed instance where the regret is necessarily linear. As a workaround, the authors design a statistical test based on sampling a subset of arms prior to learning to decide whether a linear or an unstructured bandit algorithm should be run on the data. Similar ideas are presented in [ and unstructured models. More recently, elimination-based algorithms [ methods [ misspeciﬁcation ε. Moreover, while best-arm identiﬁcation has been the focus of many prior works in the realizable linear setting, some suggesting asymptotically-optimal algorithms [ been seldom studied in terms of problem-dependent lower bounds. Lower bounds for the unstructured Top-mproblem have been derived previously, focusing on explicit bounds [ dependence in the problem parameters for any conﬁdence δ [9, 37], or on asymptotic optimality (as δ → 0) [ tractable, tight, problem-dependent lower bound is not straightforward. ], the mean rewardµof each armk ∈ [K] := {1, 2, . . . , K}is assumed to be an inner (1) We derive a tractable lower bound on the sample complexity of anyδ-correct identiﬁcation in misspeciﬁed linear bandits. We derive an upper bound to its sample ε = 0), where the sample complexity scales polynomially indand not inK, and While model misspeciﬁcation has not been addressed in the pure exploration literature, Tis the learning horizon, for any bandit algorithm which enjoysO(dT )regret scaling 33,18] have attracted increasing attention. Notably, these algorithms adapt to the amount of εwithout knowing it beforehand, at the cost of an additive linear term that scales with 19]. Because of the combinatorial nature of the Top-midentiﬁcation problem, obtaining a At successive stages and internal randomization (a random variable σ({U, k rewards until time In a misspeciﬁed linear bandit, each arm corresponding feature matrix is denoted by `-norm of these vectors is (otherwise we could rewrite those vectors in a subspace of smaller dimension). We assume that the learner is provided with a set of realizable models M := whereM, ε ∈ R respectively. Intuitively, features A only up to some misspeciﬁcation η. We consider Topδ ∈ (0, 1) with highest means with probability at least Top-midentiﬁcation can be decomposed into three rules: a sampling rule, which selects the arm sample at a given learning round the end of the learning phase, and is a stopping time with respect to the ﬁltration τ; ﬁnally, a decision rule, which returns a An answer is a set might not be well deﬁned since the set thanmelements if some arms have the same mean. Thus, let the set containing all subsets of m elements of S Deﬁnition 1 µ ∈ M, τ LetNdenote the number of times arm modelµ Consider the following set of alternatives to µ, that is, the set of all bandit models arms ofλ the case for atτis correct for divergence in [19, Theorem 1], for any λ ∈ Λ The restriction to kµk The expression max We abuse notation by denoting distributions in the same one-dimensional exponential family by their means. , X, . . . , U, k, X, U})be theσ-algebra associated with past sampled arms and and is independent of all past observations, conditionally onk. We suppose that the noise is µ ∈ R| ∃θ ∈ R∃η ∈ R, µ = Aθ + η ∧ kµk≤ M ∧ kηk≤ ε are known upper bounds on the`-norm of the meanand misspeciﬁcation vectors, , the learner is required to output them ∈ [K]arms of the unknown bandit modelµ ∈ M (δ-correctness).Forδ ∈ (0, 1), we say that an algorithmAisδ-correct onMif, for all < +∞ almost surely and PˆS/∈ S(µ)≤ δ . has exactlymarms that are among the top-m, i.e., that|S(µ)| = mandS(µ) = {S(µ)}. . Note that, while we assumed that the set of top-marms inµis unique, this might not be λ. Deﬁne the eventE:= {ˆS∈ S(µ)}that the answer returned by the algorithm andklthe binary relative entropy. Then, using the change-of-measure argument proposed E[N] KLµ, λ≥ klP(E), P(E)≥ kl(1 − δ, δ) ≥ log12.4δ, where the second-last inequality follows from the of the function kl. This holds for any λ ∈ Λ H:= sup cult: while the Kullback-Leibler is convex for Gaussians, the set non-convex. Its description using sets, one for each subset of toppractical. In order to rewrite this lower bound, we prove the following lemma in Appendix C. Lemma 1. ∀µ, λ ∈ R Lemma 1 allows us to go from an exponentially costly optimization problem, which implied minimizing over of alternative models as derived in Lemma 1, the lower bound in Equation 2 can be rewritten in the following more convenient form : Theorem 1. such that Computing the lower bound now requires performing one maximization over the simplex (which can be still hard), and (i, j) ∈ (S efﬁciently. Our algorithm inspired from that bound will need to perform only those minimizations. Note that a lower bound for Topbeen obtained in [ best arms is switched with the best one). These models are a strict subset of Theorem 1, which is why the algorithm we detail in the next sections will rely on the latter instead. Note that with perfectly linear models [ the set of alternative models becomes the same as the unstructured model. We show that in fact the lower bound becomes exactly equal to the unstructured lower bound as soon as ε > ε Lemma 2. bound of Theorem 1 is equal to the unstructured top-m lower bound. The proof is in Appendix C. It considers ﬁnitely supported distributions over the equilibrium in the max-min game of the lower bound. As soon as one of these equilibrium distributions for the unstructured problem has its whole support in the misspeciﬁed model, the two complexities are equal. We now make an important observation: knowing that a problem is misspeciﬁed without knowing an upper bound ε on kηk The lower bound of Equation be the right-hand side of that equation, such that δ-correct on have lower sample complexity (possibly at the cost of a higher sample complexity on := {p ∈ [0, 1]|Pp= 1}the simplex on[K]. We deﬁne the inverse complexityP infωKLµ, λ. Computing that lower bound might be difﬁsets, to optimizing acrossm(K − m)halfspaces. Therefore, by replacing the set For anyδ ≤ 1/2, for anyδ-correct algorithmAonM, for any bandit instanceµ ∈ R |S(µ)| = m, the following lower bound holds on the stopping timeτofAon instanceµ: (µ))× S(µ). The minimizations are convex optimization problems and can be solved ε = 0andm = 1, this lower bound is exactly the one for best arm identiﬁcation in There existsε∈ Rwithε≤ maxµ− minµsuch that ifε > ε, then the lower M. Suppose that we haveM⊆ M, a subset of the model, for which we would like to Algorithm 1 MISLID Require: Set of models M, online learner L, stopping thresholds {β Stop and return S end if Obtain ω Compute closest alternative: λ Mis the misspeciﬁed linear model with deviation deviation lower than is not achievable. The lower bound states that it is not possible for an algorithm to have lower sample complexity on M An algorithm cannot adapt to the deviation to linearity: it has to use a parameter and its sample complexity will depend on that that this observation does not contradict recent results for regret minimization [e.g., show that adapting to an unknown scale of misspeciﬁcation is possible. In fact, such results involve a “weak” form of adaptivity, where the algorithms provably leverage the linear structure at the price of suffering an additive linear regret term of order the counterpart of inTfor all instances of the given family”, this implies that algorithms with such “weak” adaptivity loose this important property of consistency. We introduce MISLID (Misspeciﬁed Linear Identiﬁcation), an algorithm to tackle misspeciﬁcation in linear bandit models for ﬁxed-conﬁdence Top4.1, while in Section 4.2 we report its sample complexity analysis. The pseudocode of MISLID is outlined in Algorithm 1. On the one hand, the design of MISLID builds on top of recent approaches for constructing pure exploration algorithms from lower bounds novelties to deal with misspeciﬁed Topother settings. We describe these components below. Let us deﬁne any vector v ∈ R Initialization phase. minimum eigenvalue of the resulting design matrix R, such sequence can be easily found by taking any subset of (e.g., by computing a barycentric spanner [ desired condition is met. This is required to make the design matrix invertible. While the literature typically avoid this step by regularizing (e.g., [ ∼ ωand receive reward X// ACTION SAMPLING and compute projection ˜µ← arg minkλ − bµk// ESTIMATION ,21]. On the other hand, its main components and their analysis introduce several technical so to obtain tight concentration results for the estimator of Appendix D.1 for a discussion of the length t Estimation. This is obtained by ﬁrst computing the empirical mean and then projecting it onto the family of realizable models i.e.,˜µ:= arg min inK + d constraint is only required for the analysis, while it often has a negligible impact in practice. Thus, we shall drop it in our implementation, which yields two independent optimization problems for the projection least-squares estimator program with K variables (see Appendix D). A crucial component in the concentration of these estimators, and a key novelty of our work, is the adoption of an orthogonal parametrization of mean vectors. In particular, we leverage the following observation: any mean vector µ = Aθ matrixV same bound we have in linear bandits with no misspeciﬁcation (refer to Appendix B). This is an important advantage over prior works [ the concentration rate by a factor misspeciﬁed models with which are present in related works and which would prevent us from deriving good problem-dependent guarantees. Stopping rule. exploration [ requires a careful combination of concentration inequalities for (1) linear bandits, to make the algorithm adapt well to linear models with low optimality. The precise deﬁnition of β Lemma 3 W (x) = −W This result is a simple consequence of two (linear and unstructured) concentration inequalities. See Appendix F. Sampling strategy and online learners. optimal sample complexity from the lower bound in Theorem 1. As popularized by recent works [ 13,43], instead of relying on inefﬁcient max-min oracles to repeatedly solve the optimization problem of Theorem 1 [ stept, the learner whose precise deﬁnition will be speciﬁed shortly. Then, MISLID directly samples the next arm to pull from the distribution Similarly to what was recently shown by [ be crucial in our analysis to reduce dependencies on dependencies in the realizable linear case. Regarding the choice of only a single learner, while existing asymptotically optimal algorithms for pure exploration [ At each time stept ≥ t, MISLID maintains an estimator˜µof the true bandit modelµ.P andη∈ R, this can be solved efﬁciently as the minimization of a quadratic objective variables subject to the linear constraintskηk≤ εandkAθ+ ηk≤ M. The second ˜µ= A˜θ+ ˜η: one for˜θ, whose solution is available in closed form as the standardP + η, whereθ= Vµφis the orthogonal projection (according to the design ) ofµonto the feature space andη= µ − Aθis the residual. Then, it is possible to show kis exactly the self-normalized martingale considered in [1] and, thus, it enjoys the MISLID uses the standard stopping rule adopted in most existing algorithms for pure 19,12,36]. What makes it peculiar is the deﬁnition of the thresholdsβ. MISLID (MISLID isδ-correct).LetWbe the negative branch of the Lambert W function and let (−e) ≈ x + log x. For δ ∈ (0, 1), deﬁne := 2KW12Klog2eδ+12log(8eK log t) 17,21], we compute it incrementally by employing no-regret online learners. At each Lplays a distribution over armsω∈ ∆and it is updated with a gain functiong need to allocate one learner for each possible answer. Since the number of answers is extension of these algorithms to the Top-m setting would yield an impractical method with exponential (inK) number of learners, hence space complexity, and possibly sample complexity. choice of L is highly ﬂexible since any learner that satisﬁes the following property sufﬁces. Deﬁnition 2 any sequence of gains constant C Examples of algorithms in this class are Exponential Weights [ be our choice for the implementation since it does not use does not suffer from a possibly loose bound on B. Optimistic gains. µwere known, one would directly use known and must be estimated, we set particular, we choose a sequence of bonuses arg min ful combination of structured and unstructured concentration bounds: whereα this choice of c Theorem 2. solution to the equation in t where ` bO(a; b; c) represent a sum of terms, each of which is O of one of the expressions shown. See Appendix F for the proof. Since Co(log(1/δ)) lim inf MISLID is asymptotically optimal. The only polynomial factors in that depends on dependence on the number of arms, which is on par with the state of the art [ the bound exhibits an adaptation to the value of inequality upper bound transitions to terms matching the optimal unstructured bound. Decoupling the stopping and sampling analyses. result on the stopping rule, then, a discussion of the sampling rule. The algorithm is shown to verify that, under a favorable event, if it does not stop at time t, The sample complexity result is a consequence of that bound on solely to the stopping rule, and the second one only to the sampling mechanism. The expression The fact that the optimization problem of the lower bound decomposes into not reduce the number of possible answers, which is still combinatorial in K. (No-regret learner).A learnerLover∆is said to be no-regret if, for anyt ≥ 1and (K, B) such that maxg(w) − g(w)≤ C(K, B)t . ) :=Pω|˜µ− λ| +c≥ infkµ − λk, forλ:= := βandα:= log(5t) + d log(1 + t/(2d)). We show in Appendix F that sufﬁces to guarantee optimism with high probability. MISLID has expected sample complexityE[τ] ≤ T(δ) + 2, whereT(δ)is the +bOmin{tKε+dt`,Kt`}; log Kt;min{tKε+d`, K`}log(1/δ), := log t, His the inverse complexity appearing in the lower bound (see Equation 2), and , whereCis a problem-dependent constant. Thenlim infE[τ]/ log(1/δ) = T(δ)/ log(1/δ) = Hand thus the upper bound matches the lower bound in that limit: ε. In the linear setting, whenε = 0, we have only logarithmic (and no polynomial) (5)are equal to the “linear” values which involveKεanddinstead ofK. Asεgrows, the inf stopping rule and any sampling rule, as long as they each verify the corresponding inequality. A more aggressive optimism. in the leading term). If we instead accept to be asymptotically optimal up to a factor 2, we can use the gainsg(ω) = which are much closer to those it would take if using the empirical gains the theoretical bound, while worse in the leading factor, has better lower order terms. The aggressive optimism sometimes has signiﬁcantly better practical performance (see Experiment (C) in Figure 1). Since our algorithm is the ﬁrst to apply to Topcompare it against an efﬁcient linear algorithm, LinGapE [ described in [ In all experiments, we consider the average sample complexity on the repetitions for simulated (resp. real-life) instances rounding up to the outcomes are shown as gray dots. It has frequently been noted in the ﬁxed-conﬁdence literature that stopping thresholds which guarantee error frequencies that are actually much lower than from linear to unstructured models. In order to ensure a good trade-off between performance and computing speed, and fairness between tested algorithms, we use a heuristic value for the stopping number of arms ( (ε) and the gap between the The computational resources used, data licenses and further experimental details can be found in Appendix G. (A) Simulated misspeciﬁed instances. ﬁx a linear instance zero-mean Gaussian distribution, and renormalizing them by their respective ε ∈ {0, 5} fourth best arm, third and fourth arms in the set of best arms of εis, the more different the answers from the linear and misspeciﬁed models are. This experiment was inspired by [ minimization. See the leftmost two plots on Figure 1. As expected, LUCB is always suffers from a signiﬁcantly larger sample complexity than its structured counterparts. Moreover, LinGapE does not preserve the ˆδ = 0.96 stopping threshold, as running it with the theoretically-supported threshold derived in [ an empirical error rate ε = 0is a perfectly linear instance. See Table 2 in Appendix for numerical results for algorithms LinGapE and MISLID. (B) Discrepancy between user-selected ε and true kηk. ∆ ≈ 0.4 linearity. We test its robustness against perturbations to the input value ε:= kηk the associated vectors are normalized by their the true deviation to linearity. The results, shown in the third plot of Figure 1, display the behavior predicted by Lemma 2. Indeed, as the user-provided value complexity increases as well. The plateau in sample complexity when Cases ε ∈ {1, 2} display a sample complexity close to that of unstructured bandits. All the code and scripts are available at https://github.com/clreda/misspecified-top-m. kµ − λkdoes not feature any variable speciﬁc to the algorithm: we can combine any ω(|˜µ− λ| +c), are tuned to ensure asymptotic optimality (with a factor 1 Pω(˜µ− λ)+ c. When using those, the learner takes decisions 35], which coincides with LinGapE form = 1), and an unstructured one, LUCB [23]. := ln((1 + ln(t + 1))/δ)unless otherwise speciﬁed. For each experiment, we report the K), the dimension of features (d), the size of the answer (m), the misspeciﬁcation , we build a misspeciﬁed linear instanceµ= Aθ + η, such that, if(4)is the index of the ∀k 6= (4), η= 0, andη= ε. Note that any value ofε < ∆does not switch the 20], where a similar model is used to prove a lower bound in the setting of regret ), which illustrates the effect ofεon the answer set. Note that it is not due to the choice of ) MISLID crucially relies on a user-provided upper bound on the scale of deviation from in the misspeciﬁed modelµ := Aθ + η. Values are sampled randomly forθ, A, η, and Figure 1: Experiment (A) for Experiment (C) to compare different optimistic gains (right). Figure 2: Experiment (D) for drug repurposing in epilepsy (left). Experiment (E) for online recommendation. (C) Comparing different optimisms. bandit model as in Experiment (B), and use described in Section 4.2, no optimism (that is, gains given in Section 4.1. See the rightmost plot in Figure 1. The algorithm with no optimism is denoted “empirical”, and is signiﬁcantly faster than the optimistic variants. (D) Application to drug repurposing. the drug repurposing problem for epilepsy proposed by [ method. In order to speed up LUCB, we consider the PAC version of Topas stopping threshold ofmbest arms. Following [ neural network and taking the features learned in the last layer. We compute difference between the predictions of this linear model and the average rewards from the data, which yieldsˆε = 0.02 accurately ﬁts the data, the results (leftmost plot in Figure 2) show that MisLid and LinGapE perform comparably on this instance. Moreover, both are an order of magnitude better than an unstructured bandit algorithm sample complexity-wise. Please refer to Table 3 in Appendix for numerical results for LinGapE and MISLID. (E) Application to a larger instance of online recommendation. ˆ ≈ 0.206 of online recommendation of music artists to users (Last.fm dataset [ forεand feed the value from Experiment (D), this yields a misspeciﬁcation that is much larger than the minimum gap. To improve performance on these instances, we modiﬁed MISLID. To reduce the sample complexity, we use empirical gains instead of optimism. To reduce the computational complexity, we check the stopping rule infrequently (on a geometric grid) and use only a random subset of arms in each round to compute the sampling rule (see Appendix G for details and an empirical comparison to the theoretically supported MISLID). See the rightmost plot in Figure 2. This plot particularly illustrates our introductory claim: an unstructured bandit algorithm is practice for misspeciﬁed instances, whereas the guarantee on correctness for a linear bandit does not hold anymore on these models with large misspeciﬁcation. Numerical results for LinGapE and MISLID are listed in Table 3 in Appendix. . Since the misspeciﬁcation is way below the minimum gap, and the linear model thus ,∆ ≈ 0.022) As in Experiment (D), a linear representation is extracted for an instance We have designed the ﬁrst algorithm to tackle misspeciﬁcation in ﬁxed-conﬁdence Toption, which has applications in online recommendation. However, the algorithm relies exclusively on the features provided in the input data, and as such might be subjected to bias and lack of fairness in its recommendation, depending on the dataset. The proposed algorithm can be applied to misspeciﬁed models which deviate from linearity (i.e., values of ε) and linear models (i.e., ε = 0). Our tests on variants of our algorithm suggest that the optimistic estimates have a big inﬂuence on the sample complexity. Removing the optimism completely and using the empirical gains leads to the best performance. We conjecture that other components of the algorithm like the learner are conservative enough for the optimism to be superﬂuous. The main limitation of our method is its computational complexity: at each round, for both the sampling and stopping rules, which can be expensive if the number of arms is large. However, the “interesting” arms are much less numerous and we observed empirically that the sample complexity is not increased signiﬁcantly if we consider only a few arms. In general, theoretically supported methods to replace the alternative set by computationally simpler approximations would greatly help in reducing the computational cost of our algorithm. Since the sampling of our algorithm is designed to minimize a lower bound, we can expect it to suffer from the same shortcomings as that bound. It is known that the bound in question does not capture some lower order (in test we perform, which can be very large for small times. Work to take these effects into account to design algorithms has started recently [ further improvements in misspeciﬁed linear identiﬁcation. Clémence Réda was supported by the “Digital health challenge” Inserm-CNRS joint program, the French Ministry of Higher Education and Research [ENS.X19RDTME-SACLAY19-22], and the French National Research Agency [ANR-19-CE23-0026-04] (BOLD project).