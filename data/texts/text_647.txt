Abstract—Sequential recommendation has been a widely popular topic of recommender systems. Existing works have contributed to enhancing the prediction ability of sequential recommendation systems based on various methods, such as recurrent networks and self-attention mechanisms. However, they fail to discover and distinguish various relationships between items, which could be underlying factors which motivate user behaviors. In this paper, we propose an Edge-Enhanced Global Disentangled Graph Neural Network (EGD-GNN) model to capture the relation information between items for global item representation and local user intention learning. At the global level, we build a global-link graph over all sequences to model item relationships. Then a channel-aware disentangled learning layer is designed to decompose edge information into different channels, which can be aggregated to represent the target item from its neighbors. At the local level, we apply a variational auto-encoder framework to learn user intention over the current sequence. We evaluate our proposed method on three real-world datasets. Experimental results show that our model can get a crucial improvement over state-of-the-art baselines and is able to distinguish item features. Index Terms—disentangled learning, graph, sequential recommendation. Recommender systems play a critical role in the fastdeveloping Internet age, aiming to predict the most likely items which users may be interested in. Collaborative ﬁltering is an efﬁcient and widely used approach in recommendation, which commits to capturing latent user and item features from historical interactions. Early works like Matrix Factorization (MF) [1] decompose a rating matrix into user and item embeddings to capture implicit semantics. As the scale of users and items increases rapidly in recent years, more deep learning models are proposed based on collaborative ﬁltering to characterize plentiful user tastes over a large amount of items. For example, [2] and [3] build user-item graphs to integrate the multi-hop relationship of interactions. [4] and [5] introduce a variational auto-encoder framework into the model and infer the representation as a Gaussian distribution. Sequential recommendation is an important part among recommender systems. It models user behaviors as a sequence of items instead of a set of items. Markov Chain (MC) [6] is a classic method, which models short-term item transitions and predicts the next item a user may like. Factorized personalized Rutgers University, New Jersey, USA victor.sheng@ttu.eduzxf@cse.ust.hk Markov chain (FPMC) [7] combines the markov chain and the traditional matrix factorization together to model user preferences. With the development of deep learning networks, Recurrent Neural Networks (RNNs) have achieved successes in sequential recommendation. For example, Long Short-Term Memory (LSTM) [8] is a common variation of RNN to enhance model’s ability of maintaining sequential information by memory cells. GRU4Rec [9] applies Gated Recurrent Units (GRU) to session-based recommendation by introducing session-parallel mini-batches. RNN-based methods face the challenge of maintaining long-range information. Then selfattention network is applied to sequential recommendations recently to capture both long-term and short-term dependencies. SASRec and BERT4Rec both get good prediction results with attention mechanisms. SASRec [10] is able to capture long-term dependencies because it takes into account the inﬂuential weights of a whole historical sequence. BERT4Rec [11] employs a deep bidirectional self-attention network with Cloze tasks to increase the efﬁciency of a transformer model. These previous works model user intentions with historical sequential interactions, ignoring dynamic underlying relationships behind items. The edges that link pairwise items contain abundant semantic information of factors why and how users choose one item after another. These underlying factors are related to real-world concepts, and one certain factor often plays a leading role in a single situation. For example, suppose there are two users interacting with six items, as shown in Figure 1. The link graph shows that item 2 is adjacent to all the other ﬁve items. But these edges are intuitively motivated by different factors. Item 2 is linked to items 1 and 4 because they are in the same color, while it is linked to 5 and 6 because they have short sleeves. Item 3 is connected to item 2 because it can be used as a T-shirt jacket. These different factors show the intention transformation of user behaviors, and also reveal the shared features of pairwise items. Therefore, recognizing and distinguishing the underlying item-link factors is able to enhance the expression ability of models, and disentangled representation learning [12] is a common method proposed to achieve this goal. Disentangled representation learning has been of great popularity in many ﬁelds such as Computer Vision [13], [14], and it has been applied to recommender systems recently. The general purpose of disentangled representation learning is to separate the distinct and informative factors from the variations of data, where each unit is related to a single concept in the real world. A single change of one factor will lead to a change of the relevant unit. Many models have been proved to have the ability to learn disentangled representation and have been applied to fulﬁll realistic tasks. For example, by learning disentangled representation of a face image, we can obtain independent representations of different features of the face. Then we are able to identify whether a person in a picture has bangs, is wearing glasses, is smiling, and so on. Further, we can change these features directionally by modifying the values of the corresponding dimensions of these features. Therefore, learning disentangled representation can enhance the interpretability and controllability of model. The most prominent networks to learn disentangled representation are β-VAE and InfoGAN. β-VAE [15] adds a coefﬁcient hyperparameter β to the KL-divergence term in the objective of variational auto-encoder to encourage more factorized latent representations. This extra hyperparameter puts a heavy pressure on the posterior distribution to match the factorized prior distribution [16]. InfoGAN [17] maximizes the mutual information between a ﬁxed small subset of the GAN’s noise variables and observations. With regard to recommender systems, Macrid-VAE [18] infers high-level concepts of user intentions at the macro level and applies VAE to enhance disentanglement at the micro level. The authors also propose a self-supervised seq2seq training strategy for sequential recommendation [19], which compares user intentions between sub-sequences generated by an intention disentangled encoder. DGCF [20] devises intent-aware interaction graphs to distinguish user intentions over different items, focusing on user-item relationships. However, these studies do not consider item-link relationship patterns, and fail to distinguish different user intentions behind sequences. As a result, the sequential model will be sensitive to noisy data and hardly interpretable. In this paper, we propose an Edge-Enhanced Global Disentangled Graph Neural Network (EGD-GNN) model to capture the item-link information. We model item representations and user intentions from both the global and the local levels. At the global level, we build a global item-link graph over all sequences, and each item-pair in the sequences is denoted as an edge in the graph. Figure 1 shows an example of the construction of a global graph over two sequences. We apply the channel-aware mechanism to decompose edges into several channels, where each channel is correspond to an inﬂuential factor. The channels extract features speciﬁcally to one of the disentangled factors from the neighbors and aggregate different factors jointly to the target item. At the local level, we model disentangled user-intention representation over the current sequence. We ﬁrst infer the latent variation as a Gaussian distribution in order to enforce disentanglement from the statistical perspective of variational auto-encoder. Then we use the channel-aware mechanism and aggregate item information through the edge channels from former items in the sequence. The aggregated item representation is used to express current user intention. We conduct experiments based on our proposed method on three real-world datasets and compare the predicting results with the state-of-art baselines. Results show that the EGD-GNN model not only outperforms the previous works in prediction tasks, but also forces the system to ﬁnd good disentangled representations. The major contributions of this paper are summarized as follows: explore disentangled representation over the global and the local levels to learn factorized underlying factors of item relationships. the factors behind pairwise items which motivate user intentions. We apply the GNN model to the global graph and the local sequences to learn item link patterns, and employ variational auto-encoder taking advantage of its statistical property. and experimental results show our proposed model is able to achieve a good disentangled representation over sequences to indicate user intentions. The rest of this paper is organized as follows. Firstly, we review related works corresponding to our work in Section II. Then we propose the problem formulation and deﬁnitions of our model and introduce preliminaries in Section III. Next, we present the details of our proposed model in Section IV. Section V records and visualizes experimental results, proving the effectiveness of our model. Finally, we conclude the paper and put forward a vision for future work in Section VI. In this section, we present the recent works related to our model, including Sequential Recommendation, Disentangled Representation Learning, and Graph Neural Network. Recommendation systems have been extensively popular over the last two decades. They aim to predict users’ preferences over historical behaviors. Matrix Factorization (MF) [1] is the most common framework for prediction, which learns user/item embeddings respectively to model latent relationships between users and items. Further study like SVD++ [21] combines domain model and hidden factor model, and proposes a new globally optimized neighborhood model. Sequential recommendation is an important branch of recommendation systems. Given a chronological item sequence of user’s historical behaviors, sequential recommendation can predict the next item with which a user is likely to interact. Markov Chain (MC) [6] is a classical model to capture short-term item transitions. FPMC [7] further combines Matrix Factorization and Markov Chain together to model both longtern preferences and short-tern transitions. Fossil [22] combines similarity-based models with high-order Markov Chains. TransRec [23] turns a user embedding into a translation vector and considers the three-order relationships between users, candidate items, and previous behaviors. With the proposal of Recurrent Neural Network (RNN), researchers have proposed redundant works based on this sequential framework and its variants. For example, Time-LSTM [8] uses Long Short-Term Memory (LSTM) to model time intervals with time gates, and GRU4Rec [9] uses Gated Recurrent Units (GRU) to model click sequences for session-based recommendation. Recently, more deep neural networks have been applied to model sequence patterns. Caser [24] employs a Convolutional Neural Network (CNN) to capture sequential patterns as local features of images by embedding recent sequential items into the images. SASRec [10] ﬁnds the relevance between items adaptively using the self-attention mechanism. BERT4Rec [11] employs a deep bidirectional selfattention network with Cloze task to increase the efﬁciency of transformer model. SVAE [25] leverages Variational Autoencoder (VAE) to handle temporal information of sequences. However, these previous works do not distinguish the various contributions of neighbors over different aspects. The purpose of learning disentangled representation is to ﬁnd independent factors in the latent space. Each dimension of the representation has a speciﬁc and irrelevant meaning and is human-understandable. For example, learning disentangled representation over face pictures can get representations regarding eyes, hair, smiles, etc., while learning disentangled representation over landscape pictures can get representations regarding trees, sky, buildings, etc. Distinguishing such features from the representations can bring enhanced robustness, interpretability, and controllability. Therefore, it has been a popular task in many ﬁelds such as computer vision [13] and topic modeling [26]. During recent years, many methods have been proposed to improve the disentanglement learning ability. InfoGAN [17] realizes unsupervised learning of disentangled representation by introducing mutual information to constrain the latent variables. β-VAE [15] turns the perspective to information bottleneck and focuses on the KL-divergence in the VAE objective. Further studies like β-TCVAE [27] and FactorVAE [28] decompose the KL-divergence and directly encourage factorized distribution by putting penalty on the total correlation. Recently, some studies turn attention to disentangled learning in recommendation. For instance, Macrid-VAE [18] is the ﬁrst work to learn disentangled representation from user-item interactions in recommender systems. At the macro level, it divides user intentions into several high-level concepts and categorizes each item into a concept. At the micro-level, it applies VAE framework to the encoder layer to encourage dimension independence. DGCF [20] devises a disentangled graph model to learn user intents based on neural graph collaborative ﬁltering. DICE [29] disentangles the interest and conformity representation with causal embedding. Ma et.al. [19] performs self-supervision in the latent space to classify user intentions. It reconstructs future sequences as a whole using the sequenceto-sequence training strategy, instead of individual items in the future sequences. However, these works fail to maintain the item-link relationships and disentangle their inﬂuential factors. In this paper, we will solve this problem by introducing graph neural network into sequential recommendation. Graph Neural Network (GNN) is a classical learning network used to capture information of graph structure data. It has achieved great success in various tasks, such as node classiﬁcation [30] and link prediction [31]. Early work like ChebNet [32] realizes fast localized convolutional ﬁlters on graphs by CNN and avoids the Fourier basis. Graph Attention Network (GAT) [33] aggregates neighbor nodes through multihead self-attention mechanism, realizing the adaptive matching of the weights of different neighbors and enhancing the ability of Graph Convolutional Network (GCN). DisenGCN [34] proposes a disentangled graph convolutional network with neighborhood routing mechanism to learn disentangled node representations from its neighbors. CGAT [26] enhances the GAT framework by introducing a channel-aware attention mechanism. It disentangles topic representations structurally and semantically over user-user interaction graphs. Graph neural network is also widely used in recommender systems. LightGCN [35] learns the user and item embeddings by linearly propagating them on the user-item interaction graph. FGNN [36] investigates the inherent order of item transition patterns in session recommendation using a modiﬁed weighted GAT model. These existing studies have proved the effectiveness of graph neural network in obtaining item-link transition patterns, so we apply it to our work to model the user intention transition through sequences. We will present the preliminary statements of this paper before the details of our model. We ﬁrst describe the notations and the sequential recommendation problem of our paper. Then we put forward the channel-aware mechanism used in the representation space. Finally, we introduce the variational auto-encoder and its contribution to learning disentanglement. Given M users and N items, we denote a user set as U = {u, u, ..., u} and an item set as V = {v, v, ..., v}. For each user, S= {h, h, ..., h} represents the sequential behaviors interacted by user u. Given a historical sequence at time t, a sequential recommender model aims to predict the next item at time t + 1. In this paper, we propose a global-level graph to capture item-link transition information. We deﬁne the global graph as G =< V, E >, where V is a set of all items in the training data and E is a set of edges. Each edge < v, v>∈ E means a user interacts with vafter vin a sequence. Ndenotes the neighborhood of item v, i.e., the items adjacent to vin the sequences. We use an undirected graph in this paper, because for the item-link pairs, the similarities and inﬂuencing factors between them are order-independent. The temporal order of sequences will be considered at the local level. Table I lists detailed explanations of the notations used in this paper. Given a historical sequence S= {h, h, ..., h}, let z∈ Rbe the latent intention of user u while interacting with item h. Assuming that there are K factors related to user intentions, we divide the latent representation zinto K channels, i.e., z= [z, z, ..., z]. The kchannel corresponds to the kfactor independently. For each pair of adjacent items, the correlation between zand zindicates the similarity between item vand item vregarding factor k, and also reveals why the two items are connected and how they inﬂuence each other. The Variational Auto-encoder (VAE) is a generative model which models variables as random distributions based on the Bayesian Theorem. Assume a d-dimensional variable z being the sampled latent representation from sequence S= {h, h, ..., h}, we aim to maximize the probability of the next item, that is, to maximize the probability of the whole sequence S: Since the probability p(S) is not iterable, the variational inference method takes advantages of Bayesian Theorem p(x, z) = p(x|z)p(z) and proposes a posterior distribution q(z|x) to approximate the true distribution p(z|x). Migrating to sequential recommendation, the log likelihood of p(S) can be derived as follows: log p(S) =q(z|S) log p(S)dz Algorithm 2 is the training objective of variational autoencoder, it is called Evidence Lower BOund (ELBO). By maximizing ELBO, the model can get an approximate posterior distribution q(z|S) for the encoder to generate the latent representation z. In practice, the generative model suggests that the variables follow Gaussian distribution and applies a ’Reparameterization Trick’ to calculate the gradient. Then the variables can be written as a polynomial generated from the mean µ and the variance σ of Gaussian distribution: β-VAE is a common modiﬁcation of VAE. It introduces an adjustable hyperparameter β to the original objective of VAE: ELBO = E[log p(S|z)] −βKL(q(z|S)||p(z)). (4) Burgess et.al. [16] discussed why β-VAE is able to learn an axis-aligned disentangled representation from the perspective of information bottleneck. β acts as a constriction limiting the capacity of the bottleneck, and encourages β-VAE to improve data log-likelihood. Furthermore, the KL-divergence term can be composed to three parts, following the contribution of β-TCVAE [27]: = I(z, S) + KL(q(z)||p(z)) +KL(q(z)||p(z)) The three terms above are referred to as the Mutual Information (MI), the Total Correlation (TC), and the dimension-wise KL respectively. A heavier penalty on the TC term forces the model to learn a factorized representation, each dimension of which is independent. Therefore, if we put a strong penalty on the KL-divergence by adjusting β, VAE can ﬁnd statistically independent factors from the observed data. In this section, we will present our proposed model. Figure 3 illustrates its overall architecture, which consists of three parts: Global-level Disentanglement Layer, Local-level Disentanglement Layer, and Prediction Layer. We claim that sequential disentangled representation learning model should have three main characteristics: 1) items that have similar features should be close in the corresponding embedding space; 2) the changing of factors between linked items should reveal the intention transition of user behaviors; 3) separated representations should be independent of each other. We will discuss how the model realizes these purposes in detail in the following sections. We will ﬁrst introduce the global-level disentangled representation learning layer based on the channel-aware mechanism, which is the key framework of our work. We build a global item-link graph G =< V, E > based on training sequences, where all the item pairs appear adjacently in the sequences are connected with undirected edges. We aim to extract the independent factors motivating user intentions and ﬁnd out the degree of mutual inﬂuence between the two items on these factors. Before introducing the mechanism, we ﬁrst propose two hypotheses. Hypothesis 1. There are K high-level concepts associated with user intentions, which means there are K latent factors to be disentangled. Based on this hypothesis, given a global graph G, we divide the nodes (i.e., the items) into K components in the latent space, and the edges are divided into K channels correspondingly. The kcomponent is related to the k factor of the user intention, and the kchannel indicates how factor k attributes to the linkage of pairwise items. Hypothesis 2. Factor k indicates the degree of similarity between item vand vin terms of factor k, that is, the representations of item vand vshould be close in the klatent subspace if vand vhave similar characteristics regarding the kfactor. Intuitively, for a pair of linked items, their similarity is equivalent, which means on the same factor k, the degree of inﬂuence of item von vis the same as that of von v. Therefore, we can use undirected graphs to model the information transition instead of directed graphs. Then we will introduce the channel-aware mechanism based on the above hypotheses. The illustration is shown in Figure 2. The item representations are divided into K components by sending the initial embeddings into K learning layers respectively. The edges are composed into K channels and each channel transmits information of the corresponding item embedding. For a single node vin the graph, we aim to aggregate information from its neighbourhood N. We ﬁrst compute the probability that factor k inﬂuences item vfrom its neighbors v∈ N: where W∈ Ris the parameter of the klearning layer regarding factor k, and his the initial embedding of node v. σ(·) is a nonlinear activation function. αreveals why the item pair vand vis linked adjacently, and how item vattributes to item vover factor k. The larger αis, the higher item vand vare similar on factor k, the greater the transition information from vto vis, and the larger the width of the edge is in the graph. Moreover, αsatisﬁesP α= 1 to ensure that the total width of each factor is the same. Then we can accumulate information according to the probabilities of channels from the neighbors of item vand update the item representation: In order to ensure the numerical stability, we use lnormalization as: By projecting item representations into different channels, we can aggregate item information from the perspective of different concepts. The global-level item representation zcan then be denoted as the combination of K channels: The design of channel-aware mechanism based on neighborhood fulﬁlls our ﬁrst claim of disentanglement learning. Similar characteristics are passed through corresponding channels to model item features and different neighbors inﬂuence the target item differently. Taking Figure 2 as an example, item vand vare linked because they are black, then information will be passed through the channel which corresponds to factor ’color’. The representation of item vand vshould be close in the component related to ’color’, but far in the component related to ’category’ since item vis a pair of trousers and item vis a shirt. Similarly, the representation of item vand vshould be close in the component of ’category’, but far in the component of ’color’. Considering that items appearing in one sequence are rarely repeated, we model local-level user intentions based on sequential models instead of graphs. Given a sequence of user’s historical behavior S= {h, h, ..., h}, we transform it into S= {h, h, ..., h} as training data. For users whose sequential length is greater than T , we select the nearest T interacted items, and for those whose sequential length is less than T , we add zero vectors repeatedly to the left side of sequences. In order to distinguish the item representations at different positions in the sequence, we add a learnable position embedding p ∈ Rinto the initial item embedding, and take H as the input of the learning layer: 1) SA-VAE Layer: We ﬁrst apply self-attention network [10] into our local learning model taking advantage of its ability to capture both long and short-range dependencies of items in sequence. The scaled dot-product attention is deﬁned following [37]: D = Attention(Q, K, V ) = softmaxQK√dV, (11) where dis the dimension of input embedding, the scale√ factordis to avoid the inner product values being overly large. Q, K, and V denote the queries, keys and values respectively. The three parameters are generated by input H: where W, W, W∈ Rare the projection matrices of attention layers. By utilizing residual connection and layer normalization, we can propagate low-level features to the high-level ones and get the ﬁnal output of the self-attention layer: We then take has the input of the variational auto-encoder framework. Let zbe the latent variable sampled from the sequence S, which obeys a Gaussian distribution. Following SVAE [25], we inference the posterior distribution q(z|S) as a multinomial layer. The mean and variance vectors are computed based on the self-attention vectors as follows: where l(·) represents linear transformations. By using the ’Reparameterization Trick’ mentioned in the Preliminary section, the output of our SA-VAE layer is written as: where  ∼ N(0, I). By sampling a random variable  with standard Gaussian distribution, the latent representation of sequence is reparameterized, and we can handle the uncertainty of user behaviors. 2) Disentangled Learning Layer: After the self-attention variational auto-encoder model, we get item representations with normal distribution of the overall sequence. Then, we will apply the channel-aware aggregation mechanism for locallevel disentanglement learning. In the global-level learning layer, we assume that adjacent items have similar characteristics, so we apply the channelaware mechanism to aggregate feature information for representation updating. When it comes to local level, we focus on the transition of user preference by modeling the variation of item factors. In order to obtain the transition features, we use the sliding window strategy based on graph neural network. Sliding window strategy is a popular dividing algorithm. By applying sliding window strategy to some search tasks, it can convert the nested loop problem into a single loop problem, reducing time complexity. Speciﬁcally, the algorithm sets a ﬁxed window, which moves from time 1 to time T in the sequence axis, and executes the channel-aware algorithm in each step among the window. Taking Figure 3 as an example, the user sequence is arranged by time order as v−v−v− v−v−v. Suppose the window length is 4, the window ﬁrst covers the 4 items of the earliest interactions. We add edges between v−v, v−vand v−vrespectively, and apply the channel-aware mechanism to calculate the similarities and degrees of inﬂuence between the three items and vover the K channels. Then we accumulate the feature information to v, achieving a step of information transmission. Next, the window slides to v−v−v−v, and we repeat the above steps in this window. Finally, the item feature information will be transformed to the last item through K channels. We set the sliding window length as L. That means for each target item v, information will be aggregated from its former L items. The probability between item vand vis calculated by Algorithm 6 based on the channel-aware mechanism and channel information is aggregated as follows: where Wrepresents the learning parameter of channel k, which is shared with the global-level layer. Also, we use lnormalization for z. Having obtained the information aggregation through sliding window from previous to back, we can form the user intention at time t with the titem embedding in the sequence. Then the local sequential representation is the combination of K factors: z= [z, z, ..., z]. In summary, we learn disentangled representation of the current sequence from both channel and statistical perspectives. Variational auto-encoder helps the model learn independent latent representation over the whole sequence statistically, which would be discussed in the next part. The channelaware sliding window strategy is able to distinguish the various factors of users. Different factors pass through channels that are related to different user intentions. The inﬂuenced factor is changed through sequences with the transition of user intentions, realizing characteristic (2) of our claim. Based on the obtained representations z, zlearned from global and local level layers, the ﬁnal sequential representation is written as: where W, Ware combination parameters of predicting layer. We can estimate the ﬁnal recommendation probability of candidate items based on the current sequential embedding and the initial item embedding. Let ˆydenote the prediction probability of item vappearing as the next interaction in the current sequence: Since we use VAE framework in our model, the training objective is deﬁned following the evidence lower bound: ELBO = E[log p(S|z)]−βKL(q(z|S)||p(z)). (19) The ﬁrst term E[log p(S|z)] is regarded as the reconstruction error, measuring the accuracy between the prediction ˆyand ground truth y. Here we compute the reconstruction loss using cross entropy: E[log p(S|z)] = −ylog(ˆy) + (1 −y) log(1 − ˆy). Input: initial item embeddings h, channel number K Output: disentangled item embeddings z Parameters: W, k = 1, 2, ..., K = [z, z, ..., z] The second term, KL(q(z|S)||p(z)), is used to measure the distance between posterior distribution and prior distribution. Practically, it is computed with the intermediate variables of VAE layer [38]: KL(q(z|S)||p(z)) =12(µ+ σ− log σ− 1). (21) We then discuss how our model can learn independent disentangled representation. According to Section III-C, the KL-divergence KL(q(z|S)||p(z)) can be separated into three parts: the index-code mutual information, the total correlation, and the dimension-wise KL. The total correlationQ KL(q(z)kq(z)) is a measure of redundancy, acting as the degree of interdependence between variables in the latent variable space. Therefore, applying the β-VAE framework into our model contributes to learning statistically independent factors of the data distribution, and realizing our last claim of learning disentangled representation. 1) Time Complexity: The time consumption of our model mainly consists of three parts. The ﬁrst part is the globalgraph building. In order to construct the global, we need to traverse every edge, which costs O(E). The second part is the channel-aware mechanism, the algorithm of the mechanism is shown in Algorithm 1. For each channel, the cost of updating item embedding is O(Ndd). The third part is sliding window strategy. The window slides from the start of sequences to the end, which costs time of sequence length T , and the local-level channel-aware mechanism costs O(LTdd). Therefore, the total space complexity of our model is O(E + K(N+ LT )dd). 2) Space Complexity: The space consumption of our model is mainly in the undirected graph and channel-aware mechanism. In order to store the neighborhood of each node, an adjacency matrix of O(N). For the channel-aware mechanism, there are K parameters of dimension ddfor all channels, and the ﬁnal item embedding generated from K channels is of dimension NT d. Therefore, the total space complexity of our model is O(N+ Kdd+ KN T d). In this section, we will present our experimental setup and results. Firstly, we introduce the datasets and the evaluation metrics used in our experiments, then we will introduce the eight baseline methods which are related to VAE models or disentangled learning models. Next, we compare the experimental results of these baseline methods with our method under the same experimental setting to verify the effectiveness of our proposed model. Moreover, we evaluate the inﬂuence of each part in our model and the inﬂuence of the key parameters. Finally, we perform visualization experiments on the sequential embeddings generated in the experiment, which proves that our disentanglement model is able to distinguish intention factors in the latent space. In speciﬁc, our experiments aim to answer the following questions: art works over various kinds of datasets? global and local layers in our model? resentation learning in the latent space? on different datasets? We adopt three real-world datasets to evaluate the effectiveness of our method. MovieLens is a time-series dataset containing rating data for multiple movies by users. We use the version MovieLens-1M that includes 1 million user ratings. Amazon is an e-commerce dataset which contains users’ purchasing behaviors on rich products. We choose two categories, ’Beauty’ and ’Video Games’, and use the 5-core version for our experiment. We use timestamps to arrange the sequence order, that is, the items that are interacted by the same users are arranged in sequence according to their interacting time. Following the previous work [10], we split data into three parts: the last interacted item for testing, the second-to-last interacted item for validation and the rest items for training. We regard the training sequence of length n as n −1 sub-sequences, and the last element of each sub-sequence is regarded as the training ground truth. While in validation and testing tasks, we choose the last item of sequence as ground truth with 100 randomly sampled negative items. The detailed statistics are shown in Table II. The average sequence length of each dataset is 163.5, 5.63 and 7.26 respectively. We adopt two ranking based metrics to evaluate the recommendation performance: Normalized Discounted Cumulative Gain (NDCG) and Recall. The larger the values of metrics are, the better the performance is. We refer to the two metrics as N@K and R@K for short. position of correctly recommended items. It is deﬁned as follows:DCG@K where DCG is the Discounted Cumulative Gain. We hope that the most relevant items are at the top of the list, so before adding scores, we divide each item by an increasing number. IDCG is the ideal DCG, which sorts the results to the best state and calculates DCG of the query under this arrangement. They are deﬁned as: where rrepresents the relevance of the iitem, which is either 1 or 0, and N is the set of relevant items. actually preferred by users included in the recommendation list. It deﬁnes a recommendation list of top K predicted items for a user as R, and uses T to represent the corresponding test set. The percentage of rated items is then computed as: We compare our method with the following competitive baselines, with particular emphasis on VAE-based and disentangled learning methods. All the baselines put emphasis on sequential recommendation tasks. their popularity. model based on Matrix Factorization. It designs a pairwise optimization method to learn pairwise item rankings from implicit feedback. method combining Matrix Factorization and ﬁrst-order Markov Chain together. It introduces a personalized transfer matrix based on Markov chain to capture time information and introduces matrix factorization to solve the sparse problem of the transition matrix. embeds items into a transition space and models each user as a transition vector to obtain the ’three-order’ relationships, i.e., the interactions between a user, the previous visited items and the next item. mendation [24]. The main idea is to form an ’image’ with the most recent items of a sequence in time and latent spaces, and apply Convolutional Neural Network (CNN) to learn the high-order sequential patterns as the local feature of the image. dation [10]. By applying the self-attention mechanism into sequential problems, the model can not only capture the long term information like RNNs but also handle the short term patterns in terms of small number of behaviors like MCs. model that focuses on disentangled representation learning on sequential recommendation. It designs a Disentangled Sequence Encoder to disentangle user intention in the latent space over sub-sequences and propose a seq2seq self-supervised strategy for training. combines the self-Attention mechanism with variational inference for sequential recommendation to model the long-range and short dependencies of sequences. We conduct experiments with PyTorch. In the experiments, the dimension of item embedding of all the methods is set 100. The channel embedding dimension of our model is set 20. We set the batch size as 128 and the learning rate as 0.002. We limit the maximum sequence length to 200 for the MovieLens dataset and 50 for Amazon. The dropout rate of turning off neurons is set as 0.5 for both the global and local layers. Single-head self-attention network is used as the sequential encoder. We use random seeds for the generation of Gaussian distribution and report the average performance result under ﬁve times. To evaluate the effectiveness of our proposed model, we perform next-item recommendation based on our model and the baselines under the same experimental setting. Speciﬁcally, we predict the item user may be interested in at time t based on the former t−1 items and choose the th item in each sequence as ground truth for metric. Table III records the performance results. We will compare and analyze the results in detail in this section. Firstly, We can observe from the table that our method outperforms the baselines over all the datasets. There is no doubt that our model gets better predicting results over the classical baselines, POP, BPR, and FPMC, since we take complex sequential interaction information into account. In terms of models based on neural networks, we can see that SASRec performs better than the transformer models, indicating that the self-attention network captures more sequential semantics with both long and short term patterns. The VSAN method proposes a new self-attention network with variational auto-encoder and achieves second-best results in our experiments. It proves that capturing the long and short range dependencies together with the attention-based network and the statistical method does help the model get better prediction results. The effectiveness of random method, variational inference, is also conﬁrmed in eliminating the random noise in user behaviors. Although the disentangled self-supervised method performs well in the Beauty dataset, it does not have good results in the other two datasets. However, its good performance on Beauty dataset is sufﬁcient to prove the effectiveness of learning disentangled user intention over sequences. In DSS, one sequence behavior is encoded into one kind of user intention, ignoring the various different factors hidden behind item transitions. Compared with disentangling user intention over whole sequences, we focus on the intention transition of pairwise items, therefore, our model gets better predicting results than the previous work. Then we turn focus back to our proposed model, we get the best experimental results in most circumstances. In particular, its relative improvements over the strongest baselines w.r.t. NDCG@5 are 8.21%, 4.16%, and 8.17% for the three datasets respectively. Compared with VSAN, our model builds a global item-link graph and disentangles the inﬂuential factors into channels for representation updating. Compared with DSS, our model pays more attention to the item-item relationship. We form the user intention taking advantage of the transformer ability of self-attention instead of modeling the whole sequence with an encoder. According to these improvements, it is no doubt that our model can obtain user intention in an adaptive way and ﬁnd more suitable items that users may be interested in. Secondly, we achieve the best improvements for all the metrics on MovieLens dataset. It indicates that by introducing the channel-aware mechanism, the model is able to capture more item-link relationship information that is hard to be captured by previous works. Moreover, by composing several high-level concepts, the movie items, which have few explicit features, is classiﬁed into some implicit categories, and the model can obtain the user intention from various high-level perspectives to predict users’ true preference. Thirdly, we ﬁnd that our model reaches high values very early compared with the baselines, as shown in Figure 4. The trends of experimental results of 10 epochs indicate that our model can get good prediction results early in the ﬁrst ﬁve epochs. Even though the time complexity of our model is larger than the state-of-art baselines, we can still get high prediction results within a short time. That means by distinguishing the latent factors hidden behind sequences, the model can learn item representations over various factors and ﬁnd dynamic user intentions that are not shown explicitly. 1) Inﬂuence of each layer of model: We ﬁrst implement ablation studies to evaluate the effectiveness of each part of our model. Speciﬁcally, we perform four ablation experiments as follows: the SA-VAE layer and sliding window layer, only perform with the global-level graph. ing learning layer, only perform with the local-level layer. only reserve the self-attention and variational autoencoder layers. auto-encoder layers, only reserve the sliding window mechanism for local-level learning. Table IV lists the results of ablation studies, showing how each part inﬂuences the ﬁnal performance of our model. It is clear that the global and local-level layers both contribute to the improvement of our model. For Amazon datasets, the global-level layer performs better than the local-level layer, indicating that the relationship between product items is close and worth exploring. Besides, the sliding window strategy gets better prediction results compared with the SA-VAE layer. It proves that the channel-aware mechanism plays quite a crucial role in disentangling user intentions over different factors. Moreover, we can observe that the improvement of channel-aware mechanism is extremely large on the MovieLens dataset, since our model can capture much relevant information between items and explore high-level factors even on a small scale dataset. 2) Inﬂuence of penalty on KL-divergence: Then we implement ablation experiments on the variational auto-encoder framework. As introduced in the previous sections, the parameter β acts as a penalty on KL-divergence term which contributes to forcing the model to ﬁnd independent latent variables. Therefore, we will evaluate the role of β in disentangled representation learning. We set β from 0 to 2 to examine its effectiveness, and list the results in Table V. We can see that when β is 0, the experimental results are obviously the worst, since the variational auto-encoder model degenerates to original auto-encoder. And when β is too large, the results will also decrease, since the posterior distribution is close to the standard normal distribution. Therefore, we need to ﬁnd a suitable value to strike a balance between reconstruction accuracy and disentangled learning. In order to analyze the performance of learning disentangled representation, we visualize the item representations using the t-SNE [41] algorithm on the two Amazon datasets. In detail, we learn the global-level item embeddings based on the channel-aware mechanism and project the embeddings into a 2-dimension space. We choose the channel with the largest embedding value, i.e., maxz, as the item category and color the nodes based on their categories in Figure 5. We can observe that on both datasets, the items with the same categories are close in the latent space, indicating they share similar features. Meanwhile, the factors which have close relationships are close in the latent space as well. Taking the Beauty dataset as an example, the items colored in pink are close to the items colored in orange and cyan. This indicates that the items which have these three features share similar characteristics. When a user interacts with an item colored pink, he/she is likely to choose an item colored in orange or cyan. The Games dataset also shows the same characteristics. This visual experiment again proves the effectiveness of learning disentangled representation from an intuitive perspective, and also shows its ability in enhancing the interpretability of model. In summary, learning disentangled representations based on item edges can not only observe the underlying features between items, but also help the model predict what users may like. The most important hyper-parameters in our model are the number of channels K and the length of sliding window L. Speciﬁcally, we ﬁx other parameters and adjust the number of one hyperparameter by ﬁxed length. We record the predicting results on the three datasets and draw line charts to show their impacts. We will analyze the ﬁgures in this section. 1) Impact of the number of channels: We adjust the number of channels from 5 to 35 in steps of 5 and show the results in Figure 6. We can see that the recommendation performance improves as the channel number increases, and tends to remain unchanged after reaching the peak. The MovieLens dataset reaches the peak later than the Amazon dataset. The reason may be that product items do not have as many attributes as the movie items have, and the model does not require too many classiﬁcations to achieve the best results. 2) Impact of the length of sliding window: We adjust the length of sliding window from 5 to 25 in steps of 5 and show the results in Figure 7. We can observe that the inﬂuences of the length are quite different from that of channel numbers. On the MovieLens dataset, the performance results become slightly larger as the window length grows, but there is no such trend on the Amazon datasets. Therefore, we can speculate that the choice of window length does not mainly affect the recommended results. In this paper, we proposed an edge-enhanced model based on graph neural network to learn sequential representation at both global and local levels. We designed a disentangled learning layer, i.e., the channel-aware mechanism, to distinguish various factors which motivate user intentions. The mechanism divided the information transition model into several channels and aggregated item information through different channels. At the global level, we built a global item-link graph based on training data and update item feature information through neighborhood. At the local level, we apply variational autoencoder framework to infer user behaviors as distributions, taking advantage of its statistical ability in learning disentangled representation. Then we adopt a sliding window strategy along with the channel-aware mechanism to capture the transition of user intentions through sequences. Experimental results showed that our proposed method achieves better performance than previous works. It is notable that user information is also important for learning disentangled representation. Therefore, we will consider adding user nodes in further studies. This research was partially supported by NSFC (No. 61876117, 61876217, 61872258, 61728205), ESP of the State Key Laboratory of Software Development Environment, and PAPD of Jiangsu Higher Education Institutions.