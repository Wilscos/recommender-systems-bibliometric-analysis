Sciences,Beijing,China & School of Cyber Security, Institute of Information Engineering, Chinese Academy ofInstitute of Information Engineering, Chinese Academy of Sciences,Beijing,China & School of Cyber Security, The core objective of modelling recommender systems from implicit feedback is to maximize the positive sample score𝑠and minimize the negative sample score𝑠, which can usually be summarized into two paradigms: the pointwise and the pairwise. The pointwise approaches t each sample with its label individually, which is exible in weighting and sampling on instance-level but ignores the inherent ranking property. By qualitatively minimizing the relative score𝑠−𝑠, the pairwise approaches capture the ranking of samples naturally but suer from training eciency. Additionally, both approaches are hard to explicitly provide a personalized decision boundary to determine if users are interested in items unseen. To address those issues, we innovatively introduce an auxiliary score 𝑏for each user to represent the User Interest Boundary(UIB) and individually penalize samples that cross the boundary with pairwise paradigms, i.e., the positive samples whose score is lower than𝑏 and the negative samples whose score is higher than𝑏. In this way, our approach successfully achieves a hybrid loss of the pointwise and the pairwise to combine the advantages of both. Analytically, we show that our approach can provide a personalized decision boundary and signicantly improve the training eciency without any special sampling strategy. Extensive results show that our approach achieves signicant improvements on not only the classical pointwise or pairwise models but also state-of-the-art models with complex loss function and complicated feature encoding. • Computing methodologies → Ranking;• Information systems → Learning to rank. Gaoling School of Articial Intelligence, Renmin University of China, Beijing Key Laboratory of Big Data ACM Reference Format: Jianhuan Zhuo, Qiannan Zhu, Yinliang Yue, and Yuhong Zhao. 2018. Learning Explicit User Interest Boundary for Recommendation. In Woodstock ’18: ACM Symposium on Neural Gaze Detection, June 03–05, 2018, Woodstock, NY . ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/1122445.1122456 scorescorescore With the problem of information overload, recommendation system plays an important role to provide useful information for users eciently. As the widely used technique of the recommendation system, collaborative ltering (CF) based methods usually leverage the user interaction behaviours to model users’ potential preferences and recommend items to users based on their preferences [14]. Generally, given the user-item interaction data, a typical CF approach generally consists of two steps: (i) dening a scoring function to calculate the relevance scores between the user and candidate items, (ii) dening a loss function to optimize the total relevance scores of all observed user-item interaction. From the view of the loss denition, the CF methods are usually optimized by a loss function that assigns higher scores𝑠to observed interactions (i.e., positive instances) and lower scores𝑠to unobserved interactions (i.e., negative instances). In the previous work, there are two types of loss functions designed for recommendation systems, namely, pointwise and pairwise. As shown in gure 1(a), pointwise based approaches typically formulate the ranking task as a regression or classication task, where the loss function𝜓 (𝑥,𝑙)directly optimizes the normalized relevance score𝑠of the sample𝑥into its label𝑙 ∈ {0, 1}. The sample𝑥 = (𝑢, 𝑖)is the observed or unobserved pair of the user𝑢 and the item𝑖. Usually, the pointwise-based loss function uses a xed hardline like 0.5 as the indictor to distinguish the sample as positive or negative, i.e., for all users in the ranking stage, samples whose scores more than 0.5 are regarded as positive, where the user 𝑢would be interested in the item𝑖. Correspondingly, the pairwise based approaches shown in gure 1(b), take the pairs(𝑥, 𝑥)of the positive and negative samples as input, and try to minimize the relative score𝑠−𝑠by the loss function𝜙 (𝑥, 𝑥). The pairwise loss focuses on making the score𝑠of positive samples greater than that𝑠of negative samples, which can get the plausibility of the sample 𝑥 = (𝑢, 𝑖) for being used in the ranking stage. Recently, such two paradigms of loss function are widely used in various recommendation methods, and helpful to achieve a promising recommendation performance. However, they still have disadvantages. They are hard to learn theexplicit user’s personalized interest boundary, which can directly infer whether the user likes a given unseen item [5,16]. Factually, the users have their own interest boundary learned from their interactions for determining whether the sample is the positive sample in ranking stage. As mentioned above, the pointwise loss function is non-personalized and prone to determine the global interest boundary as a xed hardline for all users, which may make the incorrect classication for the users whose real interest boundary is lower than the xed hardline. For example, in gure 1(a), although the score𝑆of the sample𝑥is more than the users’ real interest boundary, the positive sample 𝑥 is still classied into the negative group as its score𝑆is lower than the x hardline. While the pairwise approach is unable to provide an explicit personalized boundary for unseen candidate sample𝑥 in gure 1(b), because its score𝑆learned by the relative scores can only reect the plausibility of the sample𝑥, not the explicit user-specic indicator of whether the sample is a positive sample in ranking stage. In addition, we are also interested in another issue, thelower training eciencyproblem that prevents the pairwise models from obtaining optimal performance. For the pairwise, with the convergence of the model in the later stage of training, most of negative samples have been classied correctly. In this case, the loss of most randomly generated training samples is zero, i.e., those samples are too “easy” to be classied correctly and are unable to produce an eective gradient to update models, which is also called the gradient vanishing problem. To alleviate this problem, previous work adopt the hard negative sample mining strategy to improve the probability of sampled eective instances [6,7,24,32,35]. Although these methods are successful, they ignore the basic mechanism leading to the vanishing problem. Intuitively, hard samples are typically those near the boundary, and it is hard for the model to distinguish these samples well. Instead of improving the sampling strategy to mine a hard sample, why don’t we directly use the boundary to represent the hard sample score? To address the issue mentioned above, we innovatively introduce an auxiliary score𝑏for each user and individually penalize samples that cross the boundary with the pairwise paradigm, i.e., the positive samples whose score is lower than𝑏and the negative samples whose score is higher than𝑏. The boundary𝑏is meaningfully used to indicate user interest boundary(UIB), which can be used to explicitly determine whether an unseen item is worth recommending to users. As we can see from the gure 1(c), the candidate sample𝑠can be easily predicted as positive by the UIB 𝑏of user𝑢. In this way, our approach successfully achieves a hybrid loss of the pointwise and the pairwise to combine the advantages of both. Specically, it follows the pointwise in the whole loss expression while the pairwise inside each example. In the ideal state, the positive and negative samples should be separated by the boundary𝑏, i.e., scores of positive samples are higher than𝑏and those of negative are lower as gure 1. The learned boundary can provide a personalized interest boundary for each user to predict unseen items. Additionally, dierent from previous works trying to mine hard samples, the boundary𝑏can be directly interpreted as score of the hard samples, which signicantly improves the training eciency without any special sampling strategy. Extensive results show that our approach achieves signicant improvements on not only classical models of the pointwise or pairwise approaches, but also state-of-the-art models with complex loss function and complicated feature encoding. The main contributions of this paper can be summarized as: •We propose a novel hybrid loss to combine and complement the pointwise and pairwise approaches. As far as we know, it is the rst attempt to introduce an auxiliary score for fusing pointwise and pairwise. •We provide a ecient and eective boundary to match users’ interest scope. As the result, a personalized interest boundary of each user is learned, which can be used in the pre-ranking stage to lter out abundant obviously worthless items. •We analyze qualitatively the reason why the pairwise trains ineciently, and further alleviate the gradient vanishing problem from the source by introducing an auxiliary score to represent as the hard sample. •We conduct extensive experiments on four publicly available datasets to demonstrate the eectiveness of UIB, where multiple baseline models achieve signicant performance improvements with UIB. For the implicit CF methods, the user-item interactions are the important resource in boosting the development of recommender systems. For convenience, we use the following consistent notations throughout this paper: the user set isUand the item set isX. Their possible interaction set is donoted asT = U × X, in which the observed part is regarded as users’ real interaction historiesI ⊂ T. Formally, the labeling function𝑙 : T → {0, 1}is used to indicate if a sample is observed, where a value of 1 denotes the interaction is positive (i.e. (𝑢, 𝑝) ∈ I) and a value of 0 denotes the interaction is negative (i.e. (𝑢, 𝑛) ∉ I). In implicit collaborative ltering, the goal of models is to learn a score function𝑠 : T → Rto reect the relevance between items exible sampling√×√√√ exible weighting×√ Table 1: Features comparison among loss paradigms. and users. The loss function is used to indicate how well the score function ts, which can usually be summarized into two paradigms: the pointwise and the pairwise. The pointwise approach formulates the task as a classication task of single sample, whose loss function𝜓directly optimizes the normalized relevance score𝑠 (𝑢, 𝑥)between user𝑢and item𝑥into its label 𝑙 (𝑢, 𝑥): where𝜓can be CrossEntropy [14] or Mean-Sum-Error [4] and so on. Since the pointwise approach optimizes each sample individually, it is exible on sampling and weighting on instance-level. However, as these scores depend on the observation context, tting the sample into the xed score is hard to reect the inherent ranking property [22]. Instead of tting samples with xed scores, the pairwise approach tries to assign the positive samples with higher scores than that of the negative [2]. The loss function of the pairwise approach can be rewritten as: where𝜙can be MarginLoss [15,18] or LnSigmoid [12,14] and so on. Although the pairwise approach can improve generalization performance by learning the qualitative scores between the positive and negative samples, it is hard to provide eective ranking information in the inference stage and suers from the gradient vanishing problem. The pointwise and the pairwise approaches have their two sides as shown in table 1. Intuitively, a better loss function can be obtained by fully combining the advantages of the two to further improve the recommendation performance. Hence, we seek a hybrid loss to combine and complement each other. We propose a new loss paradigm to combine the advantages of two mainstream methods and match the user’s interest adaptively. Our approach is eective and ecient. As shown in equation 4, we innovatively introduce an auxiliary score𝑏∈ Rfor each user𝑢 to represent the User Interest Boundary(UIB): whereP∈ Ris the embedding vector of user𝑢,𝑊 ∈ Ris a learnable vector. Our loss comes from the weighted sum of two parts: the positive sample loss part𝐿and the negative sample loss part𝐿. Within the𝐿and𝐿, the pairwise loss is used to penalize samples that cross the decision boundary𝑏, i.e. the positive samples whose𝑠 (𝑢, 𝑝)is lower than𝑏and the negative samples whose𝑠 (𝑢, 𝑛)is higher than𝑏. Formally, the loss function of our approach can be rewritten as: L =𝜙 (𝑏−𝑠(𝑢, 𝑝))+𝛼𝜙 (𝑠(𝑢, 𝑛) −𝑏)(4) where𝛼is a hyperparameter to balance the contribution weights of positive and negative samples. Our approach can be regarded asthe hybrid loss of the pointwise and the pairwise, which is signicantly dierent from previous works. On one hand, the pointwise loss usually optimizes each sample to match its label, which is exible but not suitable for rank-related tasks. On another hand, the pairwise loss takes a pair of the positive and negative samples, then optimizes the model to make their scores orderly, which is a great success but suers from the gradient vanishing problem. Our approach successfully combines and complements each other by introducing an auxiliary score𝑏. Specically, in the whole loss expression, it follows the pointwise loss because the positive samples and negative samples are calculated separately in𝐿and𝐿. Inside the𝐿and𝐿, each sample is applied the pairwise loss, e.g. the margin loss, with the auxiliary score𝑏. In other words, the pairwise loss is applied on (𝑏−𝑠 (𝑢, 𝑝))and(𝑠 (𝑢, 𝑛) −𝑏)respectively rather than traditional (𝑠 (𝑢, 𝑛) −𝑠 (𝑢, 𝑝)). In this way, our approach can provide a exible and ecient loss function. The learned𝑏can provide a personalized decision boundary to determine whether the user likes the item in the inference stage. The explicit boundary is useful for many applications, e.g. lter out abundant obviously worthless items in the pre-ranking stage. Why it is personalized? From the view of gradient direction, the ideal boundary of user𝑢is adaptively matched under the balance between positive and negative samples, which provides a personalized decision boundary for dierent users. Concretely, to optimize the loss function equation 4 we proposed, the optimizer has to penalize two-part simultaneously: the positive part𝐿and the negative part𝐿. During the process, the𝐿upward forces the scores of positive samples and downward forces the boundary𝑏like the green arrow in gure 2, while the𝐿upward forces the boundary 𝑏and downward forces the negative like the blue arrow. If the boundary is straying from its reasonable range, the unbalance gradient will push it back until it well-matched between positive and negative. Take the boundary𝑏in gure 2 for example. The boundary is mistakenly initialized to a very low score so that all negative samples are incorrectly classied as positive. Consequently, the boundary is pushed upward to balance the low𝐿and large𝐿. As the result of the balance between positive and negative samples, the boundary can adaptively match the user’s interest scope. Additionally, we also conduct experiments to verify this statement, detailed in section 4.6. As our approach explicitly learns the user interest boundary in the training stage, the boundary learned can be directly used to determine whether the user likes the item in the inference stage. It is easily used, such as regarding candidates with a higher score than boundary as the positive, otherwise the negative as shown in gure 1(c). Our approach can signicantly improve the training eciency without any special sampling strategy. The traditional pairwise loss function suers from the gradient vanishing problem, especially in the later stage of training. Since the pairwise loss is to minimize the relative scoreΔ = (𝑠−𝑠), it is reasonable to useΔas an indicator to explain the training eciency. For example, as shown in gure 3, 9 pair training instances are generated by combining the scores of positive examples {𝑠,𝑠,𝑠} and the scores of negative examples {𝑠,𝑠,𝑠}, but only the pair (𝑠,𝑠) can provide eective gradient information to update the model, i.e. is not classied correctly or “corrupted” [13] asΔ = (𝑠− 𝑠)greater than zero. That is1/9 probability. By introducing the boundary setting, our approach signicantly improves the training eciency only with the simple uniform sampling strategy. From the view of negative sampling, the boundary𝑏can be naturally interpreted as the hard negative sample for positive samples and the hard positive for negative ones. Concretely, both positive and negative samples are paired with the boundary𝑏and result in 6 pair training instances, two of which are eective, i.e.,(𝑠−𝑏)and(𝑏−𝑠). That is1/3probability. Formally, let a dataset contains𝑁positive samples,𝑁negative samples, and𝑀eective pairs of all possible combination results. Each time a training instance(𝑠, 𝑠)is generated by randomly sampling, only𝑀/𝑁probability of the pairwise loss can provides eective gradient information. While in our approach,𝑀/𝑁probability can be achieved. Hence, compared with the traditional pairwise loss, our approach is more ecient and signicantly alleviate the gradient vanishing problem. Furthermore, the advantage of our approach is proved experimentally in section 4.8. Our approach can provide a exible way to balance the negative and positive samples. In general, the positive samples are observed instances collected from users’ interaction history, while negative samples are instances that are not in the interaction history. As the method is dierent to obtain the positive and negative samples, it is unreasonable to treat both with the same weight and sampling strategy. As our approach optimizes𝐿and𝐿individually on the whole expression, we can assign a proper𝛼and develop dierent sampling strategy to balance classes. For sampling strategy, since the negative sample space is much larger than the positive, we use negative samples of𝑀times the positive to balance the class for each batch sampling. Signicantly, here we still use the simplest uniform sampling strategy instead of other advanced methods [6, 7,24,32,35]. For weighting, the introduction of the auxiliary score mechanism makes another way possible: adjusting𝛼to enlarge or reduce the scoring space of positive and negative samples. Here, we denote the positive scoring spaceSas the range between boundary and the maximum score of positive samples, while the negative scoring spaceSas the range between boundary and the minimum score of negative samples as shown in gure 4. Intuitively, the scoring space corresponds to the score range of a candidate sample determined as the positive sample or negative. Amplifying Lby increasing𝛼will push the boundary upward and compress the positive scoring spaceSas shown on the right side of gure 4. With the boundary𝑏driven up, all positive samples obtain a larger upward gradient by largerLand gather into a more compact space. In this way, the expected score of positive and negative samples are limited in a proper range. our approach can adjust𝛼to balance the negative and positive samples. Conversely, the same is true for reducing𝛼. This phenomenon is also observed in the experiments with dierent 𝛼 settings in section 4.7. In this section, we rst introduce the baselines (including the boosted version via our approach), datasets, evaluation protocols, Figure 4: Boundary rebalance with larger 𝛼 setting. and detailed experimental settings. Further, we show the experimental results and some analysis of them. In particular, our experiments mainly answer the following research questions: • RQ1How well can the proposed UIB boost the existing models? • RQ2How well does the boundary match the users’ interest scope? • RQ3How does the𝛼aect the behaviour of the boundary? • RQ4How does the proposed UIB improve the training eciency? To verify the generality and eectiveness of our approach, targeted experiments are conducted. Concretely, we reproduce the following four types of S.O.T.A. models as the baselines and implement the boosted version by our UIB loss. To compare the dierence among those architectures, table 2 list all score function and loss function used in the baselines and our boosted models. • Pairwise model, i.e. the BPR [28], which applies an inner product on the latent features of users and items and uses a pairwise loss, the LnSigmoid(also known as the soft hinge loss) to optimize the model as follows: In boosted version, the loss function is reformed into UIB style as: • Pointwise model, i.e. the NCF [14], which is a classical neural collaborative ltering model. The NCF uses the crossentropy loss (pointwise approach) to optimize the model as equation 7. Here, we only use the MLP version of NCF as our baseline and replace the cross-entropy loss with UIB loss to build our boosted model. Specically, we directly replace the loss function with equation 6 in the boosted version of NCF. L = −𝑙 (𝑢, 𝑥)ln(𝑠 (𝑢, 𝑝)) + (1 −𝑙 (𝑢, 𝑥))ln(1 −𝑠 (𝑢, 𝑛)) (7) • Model with complicated loss function, i.e. the SML [18], which is a S.O.T.A. metric learning model. The loss function of SML not only makes sure the score of positive items is higher than that of negative, i.e.L, but also keeps positive items away from negative items, i.e.L. Furthermore, it extends the traditional margin loss with the dynamically adaptive margins to mitigate the impact of bias. The loss of SML can be characterized as: where𝑚and𝑛are learnable margin parameters,𝜆and𝛾 are hyperparameters and theLis the regularization on dynamical margins. Since the loss of SML contains multiple pairwise terms, various adaptations on SML with UIB can be selected, which also shows the exibility of our approach to boost models with a complex loss function. Here, we boost the SML only by replacing the main part Lto: L= |𝑠 (𝑢, 𝑛) −𝑏+𝑚|+𝛼 |𝑏−𝑠(𝑢, 𝑝) +𝑚|(11) • Model with complicated feature encoding, i.e. the Light- GCN [12], is used to make sure our approach can work on advanced models. The LightGCN [12] is a state-of-the-art graph convolution network for the recommendation task. Here, we only focus on the loss part and employ the simpliedG(·)to represent the complicated feature encoding process with the graph convolution network. LightGCN uses the same loss function as BPR [28] in equation 5. To boost the LightGCN, we remain the score function𝑠 (𝑢 , 𝑥 ) = G(𝑢)G(𝑥)and only replace the loss function with equation 6. In order to evaluate the performance of each model comprehensively, we select four publicly available datasets including dierent types and sizes. The detailed statistics of the datasets are shown in table 3. •Amazon Instant Video (AIV) is a video subset of Amazon Dataset benchmark, which contains product reviews and metadata from Amazon [11]. We follow the 5-core, which promises that each user and item have 5 reviews at least. •LastFM dataset [3] contains music artist listening information from Last.fm online music system. •Movielens-1M (ML1M)dataset [10] contains 1M anonymous movie ratings to describe users’ preferences on movies. •Movielens-10M (ML10M) dataset is the large version of ML1M, which contains 10 million ratings of 10,677 movies by 72,000 ln𝜎(𝑠 (𝑢, 𝑝) −𝑏Í ln𝜎(𝑠 (𝑢, 𝑝) −𝑏Í ln𝜎(𝑠 (𝑢, 𝑝) −𝑏 users. We use this dataset to check whether our approach works well on the large dataset. We use Hit Ratio(Hit@K), Normalized Discounted Cumulative Gain(NDCG@K) and Mean Reciprocal Rank(MRR@K) to evaluate the models, where K is selected from classical settings {1, 10}. The higher value of all measures means the better performance. As Hit@1, NDCG@1 and MRR@1 are equivalent mathematically, we only report the Hit@1, Hit@10, NDCG@10 and MRR@10. All datasets are split by the popular One-Leave-Out strategy [14, 28] as table 3. In the testing phase, models learned are asked to rank a given item list for each user. As the space of negative sampling is extremely huge or unknown in the real world, for each positive sample in the test set, we x the number of its relevant negative items as 100 negative samples [18]. Each experiment is independently repeated 5 times on the same candidates and the average performance is reported. We use the PyTorch [25] to implement all models and use Adagrad [8] optimizer to learn all models. To make the comparison fair, the dimension𝑑and batch size of all experiments are assigned as 32and1024, respectively. For all boosted version,𝑀 = 32is used to balance classes as discussed in section 3.4. Grid search with early stop strategy on NDCG@10 of the validation dataset is adopted to determine the best hyperparameter conguration. Each experiment runs 500 epochs for all datasets except ML10M, which is limited to 100 epochs due to its big size. The detailed hyperparameter conguration table is reported in the appendix. Íln𝜎(𝑠 (𝑢 , 𝑝) −𝑠 (𝑢, 𝑛)) From the results shown in gure 4, we make three observations: (1) Comparing our boosted versions and the baselines on all datasets, our approach works well for all data sets to improves the model, even if in the large ML10M dataset. It conrms that our model successfully uses the UIB to improve the prediction performance on the recommendation task. Specically, compared with the baselines, our models achieve a consistent average improvement of 6.669% on HIT@1, 1.579% on HIT@10, 3.193% on NDCG@10, 4.078% on MRR@10 for the AIV dataset, 4.153%, 1.013%, 2.345%, 2.909% for the LastFM dataset, 5.075%, 0.782%, 2.001%, 2.608% for the ML1M dataset and 4.987%, 0.2946%, 2.341%, 3.277% for the ML10M dataset. Among them, the improvement on HIT@1 is the most impressive, reaching 5.22% average on all datasets. (2) Comparing the pointwise and pairwise models, our approach achieves a higher performance, concretely, 9.18%, 0.68%, 3.83%, 5.34% average improvements for pointwise approach and 5.81%, 1.36%, 3.10%, 3.94% for pairwise approach. It conrms that the UIB loss can be used to boost pointwise or pairwise based models dominated in the recommendation system. It is because our approach can help for learning inherent ranking property to boost the pointwise and improves training eciency to boost the pairwise. (3) Compared to the state-of-theart model LightGCN [12] with complicated feature encoding, our boosted model LightGCN+UIB makes an average gain of 4.73% on HIT@1, 0.93% on HIT@10, 2.30% on NDCG@10 and 2.97% on MRR@10, which suggests our approach also works on the deep learning models. To determine how well the boundary matches the user’s interest scope, we essentially need to answer two sub-questions: (1) Does the model match dierent boundaries for dierent users? (2) Does the matched boundary is the best value? To answer the rst question, learned boundary distributions of NCF+UIB on four datasets are visualized in gure 5. It conrms that our model matches dierent boundaries for dierent users in the form of dierent normal distributions. To answer the second question, we add extra osets {-5,-4. . .4,5} on the𝑏and make predictions on all items for users. Then the precision, recall, and F1 measures are reported to determine if the boundary learned is the best. As the results shows in Figure 5: Boundary distribution on dierent datasets. gure 6, (1) The boundary learned makes a competitive performance. Specically, the F1 measure of 54% in AIV, 48% in LastFM, 58% in ML1M, and 51% in ML10M are achieved, which suggests the boundary is competent to match the user’s interest scope. (2) From all datasets, reducing oset consistently increases recall and reduces accuracy, and vice versa. When the oset is zero, F1 that considers both precision and recall performs best which shows that our method can learn the best boundary matching the user’s interest scope. As discussed in section 3.2, the boundary is the best result of game between positive and negative samples, which can save computing by ltering out abundant obviously worthless items Figure 6: Measures with dierent oset on boundary. in the pre-ranking stage, like 1674 of 1685 items (99.37%) for AIV, 17562 of 17617(99.69%) fro LastFM, 3529 of 3706(95.24%) for ML1M, 10576 of 10677 (99.06%) for ML10M. In our approach, only one hyperparameter𝛼is introduced to balance the contributions of positive and negative samples. To investigate how does the𝛼aect the behaviour of our approach, experiments with various𝛼 ∈{0.1,0.2,1,2,4,8,16} settings are conducted based on the optimal experiment of NCF+UIB in LastFM datasets. We also provides the results on other datasets in the appendix. Besides the performance and boundary distribution comparison, we also analyze the score distribution changes of positive and negative samples. The experimental results in gure 7 show that: (1) From the rst cell of gure 7, it is conrmed that the𝛼does aect the performance and here exists an optimal𝛼to achieve the best performance. (2) Along with the growth of𝛼, boundary𝑏consistently increases, which suggests that the𝛼is strongly relative with boundary distribution. This phenomenon conrms that increasing 𝛼to emphasize the negative loss part actually forces upward the boundary and aects both positive and negative sides at the same time. (3) From the change of positive sample score distribution at the bottom-left, it is conrmed that the positive sample score space is compressed caused by the growth of𝛼. (4) We also observe that the negative sample score distribution becomes compact at the bottom-right cell. It is because the larger𝛼also enlarges the loss of “margin”, such as𝛾in the MarginLossmax(0, Δ +𝛾), which pushes negative samples farther from the boundary and becomes compact. Figure 7: Mo del comparison with dierent 𝛼 settings. To show the ability of our approach to improve training eciency and alleviate the gradient vanishing problem that plague the traditional pairwise approach, experiments on BPR(the pairwise approach) and BPR+UIB(ours) are conducted to compare the rate of corrupted samples through epochs, i.e. the proportion of training samples that model classify incorrectly. Usually, a high corrupted rate means that a higher proportion of training samples can provide gradient information to optmize model. As shown in gure 8, the x-axis is the epoch through training, while the y-axis is the corrupted rate. The red is computed by our approach, while the blue is by the traditional pairwise approach. From gure 8, we can observe that the corrupted rate in our model is higher than that in BPR loss on all datasets. Consistent with previous literature, the training eciency of the traditional pairwise model decreases obviously with the convergence, that is, the gradient vanishing. This leads to low training eciency. Especially in ML10M and ML1M datasets, the proportion of training samples that can provide eective gradient is low after 10 epochs. Our approach maintains a certain eective gradient in training for all datasets, especially in the AIV dataset. As discussed in section 3.3, this is because the boundary itself is a good hard sample to guide the training. This paper tries to combine and complement the two mainstream loss paradigms for the recommendation task. As the pointwise and the pairwise approaches have their advantages and limitations [22], several methods have been proposed to improve the loss function [9,33]. Bellogin et al. [1]improved the recommendations based on the formation of user neighbourhoods. Liu et al. [19]proposed Wasserstein automatic coding framework to improve data sparsity and optimize uncertainty. The pairwise approach is good at modeling the inferent ranking property but suers the inexible optimization [31]. Lo and Ishigaki[20]proposed a personalized pairwise weighting framework for BPR loss function, which makes the model overcome the limitations of BPR on cold start of items. Sidana et al. [29]proposed a model that can jointly learn the new representation of users and items in the embedded space, as well as the user’s preference for item pairs. Mao et al. [21]considers loss function and negative sampling ratio equivalently and propose a unied CF model to incorporate both. Zhou et al. [36]introduces a limitations to ensure the fact that the scoring of correct instances must be low enough to fulll the translation. Inspired by metric learning [31], several researchers try to employ the metric learning to optimize the recommendation model [15,17,18,23,30]. In addition, the problem of low training eciency of paired method has also attracted much attention. Uniform Sampling approaches are widely used in training collaborative ltering because of their simplicity and extensibility [14]. Advanced methods try to mine the hard negative samples to improve the training eciency, including attribute-based [26,27], GAN-based [6,24,32], Cache-based [7,35] and Random-walk-based methods [34]. Chen et al. [4]provides another way by directly using all samples in the negative sample space. In this work, we innovatively introduce an auxiliary score𝑏for each user to represent the User Interest Boundary(UIB) and individually penalize samples that cross the boundary with pairwise paradigms. In this way, our approach successfully achieves a hybrid loss of the pointwise and the pairwise to combine the advantages of both. Specically, it follows the pointwise in the whole loss expression while the pairwise inside each example. Analytically, we show that our approach can provide a personalized decision boundary and signicantly improve the training eciency without any special sampling strategy. Extensive results show that our approach achieves signicant improvements on not only classical models of the pointwise or pairwise approaches, but also state-ofthe-art models with complex loss function and complicated feature encoding.