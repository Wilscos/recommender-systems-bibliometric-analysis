<title>R4: A Framework for Route Representation and Route Recommendation</title> Route recommendation is signiﬁcant in navigation service. Two major challenges for route recommendation are route representation and user representation. Different from items that can be identiﬁed by unique IDs in traditional recommendation, routes are combinations of links (i.e., a road segment and its following action like turning left) and the number of combinations could be close to inﬁnite. Besides, the representation of a route changes under different scenarios. These facts result in severe sparsity of routes, which increases the difﬁculty of route representation. Moreover, link attribute deﬁciencies and errors affect preciseness of route representation. Because of the sparsity of routes, the interaction data between users and routes are also sparse. This makes it not easy to acquire user representation from historical user-item interactions as traditional recommendations do. To address these issues, we propose a novel learning framework R4. In R4, we design a sparse & dense network to obtain representations of routes. The sparse unit learns link ID embeddings and aggregates them to represent a route, which captures implicit route characteristics and subsequently alleviates problems caused by link attribute deﬁciencies and errors. The dense unit extracts implicit local features of routes from link attributes. For user representation, we utilize a series of historical navigation to extract user preference. R4 achieves remarkable performance in both ofﬂine and online experiments. Route recommendation plays an important role in navigation service, since it affects travel experience of users. When a user requests a route planning from an origin to a destination, navigation service will gather hundreds of available routes and then select several of them to recommend to the user. The user chooses one route and enjoys his travel accompanying with the navigation service. If the user deviates from the chosen route as shown in Figure 1, it implies user dissatisfaction with the route to a certain extent. Since user satisfaction is determined by route characteristics and user preference, the representations of route and user are two vital parts of route recommendation. The sparsity of routes makes route representation a challenging task. It is not practical to assign a unique ID to each route as other recommendation systems do to an item, such as YouTube recommen- <title>arXiv:2110.10474v2  [cs.AI]  25 Oct 2021</title> dations (Covington et al., 2016), Wide & Deep framework (Cheng et al., 2016) and DIN (Zhou et al., 2018). The reason is that routes are combinations of links and the number of combinations could be close to inﬁnite, where link is deﬁned as the concatenation of a road segment and its following action (e.g., going forward and turning left). Besides, the representations of a route under different scenarios, such as different trafﬁc conditions, could be different. These facts make routes severely sparse, enlarging difﬁculty of learning route representation. Moreover, sufﬁcient and accurate link attributes are signiﬁcant for route representation. However, some route characteristics cannot be depicted by existing statistical features. For example, if there are a lot of cars parked on both sides of a road, it is not very easy to drive through it. Finding a feature to describe such characteristic is a complicated task. Besides, data errors occasionally appear in link Figure 1: Deviation. As long as the user trajectory deviates from the chosen route, it will be regarded as a deviation, whether the user deviates to an alternative route (left) or a route which is not displayed (right). attributes. For instance, a blocked road is mistakenly identiﬁed as a passable road. These problems also make it challenging to acquire precise route representation. In addition to route representation, user representation is also pivotal in route recommendation. Traditional recommendations utilize historical user-item interactions to extract user preference for items. For example, if a user frequently clicks on a set of items recently, there is a high probability that he will buy one of them. However, as aforementioned, routes are severely sparse. It implies that the interactions between users and routes are sparse as well. Hence, it is not feasible to learn user representation from historical user-route interactions. To address above issues, we propose a novel framework R4. In addition to route-level features, R4 introduces link-level features to obtain route representation. A sparse & dense network is designed to generate two types of route representations. The sparse unit learns link ID embeddings and aggregates them to represent a route. It is capable of discovering implicit characteristics of the route, which subsequently alleviates problems caused by link attribute deﬁciencies and errors. For the dense part, we refer to the ideas of residual network (He et al., 2016) and sentence CNN (Rakhlin, 2016). A deep residual network is applied to capturing different levels of route local features (i.e., detours) and then aggregating them to represent a route. With regard to user representation, a series of user historical navigation are utilized to extract user preference. After that, DCN-V2 (Wang et al., 2020) is adopted to generate combination features from two types of route representations and user representation. R4 achieves superior performance on both ofﬂine and online experiments. We carry out an analysis on link embeddings and ﬁnd out that they contain information of link static attributes, which validates the effectiveness of route representation in R4. Furthermore, a similarity unit is designed to expose hidden characteristics of links. It learns similarity scores between link ID embeddings and vectors of link static attributes. A smaller similarity value implies more hidden information contained in the ID embedding of a link. By conducting analysis on links with small similarity values, we discover some hidden features, which proves that R4 has the ability to capture implicit characteristics in addition to static attributes of links. Meanwhile, these hidden features could be helpful in discovering new attributes or correcting data errors in link attributes. This procedure can provide more sufﬁcient and accurate link static features, which in return beneﬁts route representation learning. Thus, the contribution of this paper is four-fold: • A learning framework R4 is proposed for route representation and route recommendation, and it achieves remarkable performance on both ofﬂine and online experiments. • To the best of our knowledge, we are the ﬁrst to introduce link IDs in route representation. • The sparse & dense network proposed in this paper represents a route from both link IDs and link attributes, which can be applied to route representation in any scenario. • The similarity unit is designed to expose implicit characteristics of links, which is helpful in ﬁnding new attributes and correcting attribute errors, and in return, provides sufﬁcient and accurate link data for route representation learning. In route recommendation, most of classical works focus on improving route searching by optimizing link costs. Various features of links, such as distance, travel time, gas consumption and personalized information, have been introduced to optimize link costs (Tian et al., 2009; Andersen et al., 2013; Kanoulas et al., 2006; Dai et al., 2015; Funke and Storandt, 2015). However, in these works, the cost of the route generally is a simple linear accumulation of its link costs, which leads to poor route representation because the interaction information between links that compose the route cannot be captured. Some people implement more complicated route cost functions like using neural networks to learn cost functions of the A* algorithm (Wang et al., 2019). However, this method could not directly leverage the global information of a route since it is only based on the links that have been predicted and guesses the rest of the route by reinforcement learning. Besides, costs of links cannot be calculated in parallel in this work because the costs of candidate links at each step rely on the result of the previous step, which makes the method unable to be applied to a large road network. In order to learn better route representation while considering the feasibility for application in large road network, we propose a two-step approach for route recommendation: 1. searching routes as many as possible between two points in a road network; 2. ranking these routes. Existing multi-route algorithms (Abraham et al., 2013; Bader et al., 2011; Delling et al., 2017) have already been capable of searching hundreds of routes between an origin and a destination. Therefore, our work focuses on route ranking. In this strategy, route representation could be learned more effectively and efﬁciently than the previous works. If a route is regarded as an item, then route ranking task is actually an item recommendation task. Unlike traditional items, routes are sequences composed of different number of links, which makes routes much sparser than items. Therefore, it is impractical to represent routes by IDs which are widely used in item recommendation. As a result, ID-based algorithms, such as xDeepFM (Lian et al., 2018), AutoInt (Song et al., 2019), Sampling-Bias-Corrected neural modeling (Yi et al., 2019) and YouTube recommendation model (Covington et al., 2016), cannot handle route representation. Besides, it also leads to the infeasibility of constructing the ID-based user-item interactions which have been proved to be effective in obtaining user representation, e.g. DIN (Zhou et al., 2018) and DIEN (Zhou et al., 2019). Compared with item representation in traditional recommendation, route representation is closer to sentence representation in natural language processing (NLP), and a link is to a route what a word is to a sentence. Word embedding and sentence embedding are basic and mature researches in NLP. Many works have achieved outstanding results, such as Skip-Gram (Mikolov et al., 2013), Transformer (Vaswani et al., 2017), BERT (Devlin et al., 2019), etc. Nevertheless, these models cannot be directly transferred to the route representation task because of the following two aspects: 1. there are hundreds of millions of links in a large road network, which are much more and sparser than words; 2. the states of links change more frequently than grammatical and semantic meanings of words which are stable in different time. Therefore, to tackle these problems, we propose a framework R4 to gain more suitable representations of routes and users. Item recommendation systems in E-commerce normally collect thousands of candidate items ﬁrst, and then rank them with a more sophisticated model in order to obtain a better performance of recommenda- tion. Similar with that, we adopt a two-step approach to tackle with route recommendation task. First, we generates up to hundreds of candidate routes using CRP algorithm (Delling et al., 2017) which is able to be applied to realtime navigation system. After that, we rank candidate routes and recommend the top one. Route ranking is what we concentrate on in this paper. Since trafﬁc condition changes frequently, especially in densely populated cities like Beijing, simply ranking shortest path ahead does not work. Besides, user preference differs from person to person. For example, some prefer major roads despite of congested trafﬁc, while others prefer minor roads with free trafﬁc. These facts make it difﬁcult to ﬁnd a route-related indicator to measure quality of a route. Therefore, we propose to measure route quality by user deviation behaviors. On the one hand, user deviation on the chosen route generally means that the user is not satisﬁed with it. In some cases, deviations indeed cannot represent user preferences, such as user changing the destination. Such cases account for a very low proportion, and can be easily identiﬁed and ﬁltered out. On the other hand, in addition to the route chosen by the user, the navigation service also provides multiple alternative routes. Therefore, if the user does not deviate from the chosen route, it means that the user prefers to it or thinks there is no problem with it, otherwise the user will deviate to other routes. In traditional recommendations, the conversion rate (CVR) is the probability that a user buys an item after clicking on it. Similarly, deviation rate (DR) is proposed to measure the probability that a user deviates from a route after choosing it. The difference is that traditional recommendation aims to maximize CVR, while route recommendation aims to minimize DR. Therefore, the target of R4 is to predict DR of candidate routes, and then recommend the route with the lowest DR to users. Features for predicting DR in R4 are listed in Table 1, categorized into 7 domains. Since route condition and user preference vary in different environment, context features f (e.g., the time when the route recommendation was initiated, spherical distance between an origin and a destination, route feature difference between the sample and other candidate routes) are involved. User features f refer to user proﬁle, such as age, number of historical deviations. These features are helpful in DR prediction because personality traits inﬂuence user behaviors and different users may end up with different outcomes in similar circumstances. Besides, the number of historical deviations alleviates the bias of user on following recommended route. Route features are denoted as f , including route distance, route ETA (i.e., estimated time of arrival), distance of road segments with congested trafﬁc, etc. They are high correlated to user behavior during navigation. Other than route-level features, link-level features are also included to provide more detailed information. Link static features l represent relatively stable information of link like link length, while link dynamic features l refer to high-frequency changing information like link conditions. Link position features l reﬂect the offset of a link in a route, such as the cumulative distance from the origin to the link. For convenience, link ID is also regarded as a domain which is denoted as p It should be noted that some domains contain discrete features. In embedding layer of R4, these discrete features are projected to dense vectors using embedding technique and concatenated with the normalized continuous features. Embedding technique is a normal operation in NLP to transform highdimensional sparse vector into low-dimensional dense vector. Discrete features will ﬁrst be encoded as one-hot vectors. After that, embedding layer maps them into dense vectors. For example, with one-hot encoding, link ID becomes a one-hot vector with dimension of over 5 million. After that, the embedding layer maps it into a 32-dimension vector. Besides, the predicted DR is denoted by ˆy and the label y is set to 1 if the user deviates from the route, and 0 otherwise. The overall architecture of R4 is presented in Figure 2. R4 has two main modules, route representation module and user representation module. Their outputs are combined with the basic features to predict DR. Each module will be explained in the following sections. Figure 2: Overall architecture of R4. Route representation module utilizes link-level information to obtain route representation. User representation module learns user preference from information of a series of user historical navigation. The output of each module and basic features are concatenated and sent into DCN-V2 (Wang et al., 2020). Finally, the predicted DR is output after sigmoid function. In embedding layer, discrete features are projected to dense vectors and concatenated with the normalized continuous features. With basic features as input, the base model adopts DCN-V2 (Wang et al., 2020) for DR predicting. As shown in Figure 2, basic features are composed of context features f , route features f , and user features f . DCN-V2 is a state-of-the-art model for feature crossing. The loss function of the base model is the cross-entropy loss deﬁned as below: L = − (y log ˆy + (1 − y) log(1 − ˆy)), (1) |D| where |D| is the size of the training set D. This module aims to obtain route representation from link-level features. Three feature vectors of link are utilized: dense vector l of link ID p , vector l of link dynamic features, and vector l of link position features. Since a route is composed of multiple links, the sparse network learns link embeddings and aggregates them to represent a route. Referring to the solution in NLP, we replace low-frequency links with the unknown token. Besides, a link could have different representations in different scenarios and positions. For example, the characteristics of the same link under free and congested trafﬁc conditions are different. For another example, if a link includes a private road, the representation when it appears at the very beginning of a route is different from the representation when it appears in the middle of a route. Because the former is passable since that is the place where user starts navigation, the latter is probably not. Therefore, we introduce link dynamic features and link position features for link embedding learning. The route representation module in Figure 2 demonstrates the approach to represent a route. If a route is composed of M links, then we get a sequence of inputs [f , f , ..., f ], where f = l ⊕ l ⊕ l denotes the feature vector of the i-th link and ⊕ represents concatenation operation. To obtain route representation, a multi-layer perceptron (MLP) is applied to each f to acquire link embeddings. After that, a sum pooling layer adds up all link embeddings into route embedding. Due to the introduction of link ID, the sparse network is capable of extracting implicit characteristics of routes, which cannot be easily depicted by existing statistical features. The sparse network acquires global characteristics of routes. In contrast, the dense network aims at learning local characteristics of routes (e.g., detours). It employs link static features l , link dynamic features l and link position attributes l to generate route representation. The dense network adopts ResNet (He et al., 2016) to extract local characteristics of routes. If a route is composed of M links, then we get a sequence of inputs S = [f , f , ..., f ], where f = l ⊕ l ⊕ l is the feature vector of the i-th link. Before input into ResNet, S is reshaped into a matrix with size M ×1×dim(f ), where dim(f ) is the feature dimension of f . Figure 3(a) illustrates the convolutional operation on the matrix, where the number of links is regarded as the height and the number of features as the channel. After multiple ResNet blocks, route representation is acquired by summing up each feature map. This module extracts user preference from a sequence of user historical navigation. Figure 4 gives an example of navigation record. Route r is the ﬁrst recommended route. The user chooses anther route Figure 4: Navigation record example. to start navigation, which is labeled as r . However, the user deviates from the chosen route during navigation. Route r represents user trajectory. There is a candidate route which is the most similar with user trajectory, labeled as r . If a user has T navigation records recently, the input can be represented by a list E = [f , f , ..., f ], where f = f ⊕ f ⊕ f ⊕ f is the feature vector of i-th navigation. f is the context information of navigation. f is the feature vector of the recommended route ranked ﬁrst. f is the feature vector of user chosen route. f is the feature vector of the planned route most close to user trajectory. f is the feature vector of user trajectory. Features involved are listed in Table 1. As shown in Figure 2, an MLP generates feature combinations of E for each f , and a sum pooling layer adds them up to obtain user representation. The dataset used in experiments is provided by Amap, a leading navigation service provider in China. Each data sample is a navigation record of an anonymous user. Origins and destinations in the data are both at Beijing. It includes information of navigation context, candidate routes (i.e., routes that participate in recommendation), user proﬁle, interactions between the user and recommended routes (e.g., choosing a route and deviation from a route), and user historical navigation records within last 90 days. Data samples that the user deviates from his chosen route for personal intention (e.g., changing destination and going for refuel) are ﬁltered. Statistics of the dataset are summarized in Table 2. There are 29,684 k navigation records, belonging to 5,234 k users. The average number of candidate routes is 19, and the maximum number of candidate routes is 150. The average number of user historical navigation records is 59, the latest 30 records are utilized for model training. Among 5,667 k links in Beijing, 2,479 links are covered by user chosen routes in the dataset. The average frequency of links is 1,200. We use data of the last day for testing, and other 30 days for training. Link IDs with frequency under 5 are replaced by the unknown token. The mini-batch size is set to be 512 and we use Adam (Kingma and Ba, 2014) as the optimizer. Besides, we adopt exponential decay technique, where the initial learning rate is 0.001 and the decay rate is 0.9. Methods compared in experiments are listed as follows: • Base Model. We use DCN-V2 (Wang et al., 2020) as the baseline model, as demonstrated in Section 3.4. The DCN-V2 is a stacked combination of 2-layer cross network and 128-64 deep network (i.e., two hidden layers with outputs of size 128 and 64). • R4. It is the framework proposed in this paper. In sparse network, the dimension of embedded link ID l is 32 and the dimension of route embedding is 64. Dense network uses ResNet50, as shown in Figure 3(b). User representation module uses MLP with one hidden layer of size 64. • R4-WoS. It differs from R4 by removing the sparse network. • R4-WoU. It differs from R4 by removing the user representation module. • R4-WoD. It differs from R4 by removing the dense network. • R4-WoB. It differs from R4 by removing route features f from basic features. • R4-WoDP. It differs from R4 by removing link dynamic features l and link position features l from the route representation module. • R4-WoD. It differs from R4 by removing link dynamic features l from the route representation module. • R4-WoP. It differs from R4 by removing link position features l from the route representation module. • R4-C (clipped). To speed up model inference, the dense network uses ResNet20 instead of ResNet50 in online experiment, as displayed in Figure 3(b). Table 3: Performance. l is the number of layers of cross network in DCN-V2 (Wang et al., 2020) and [128, 64] is the hidden layer sizes of dense network in DCN-V2. e and h are the dimension of link ID embedding and route embedding respectively. where D is the dataset of positive samples, D is the dataset of negative samples, ˆy is model output of a positive sample, ˆy is model output of a negative sample, and I is indicator function. Based on our historical experience, every 1% increases in ofﬂine AUC brings about 1% decreases in online DR. Results of experiments are shown in Figure 3. R4 improves AUC by 2.8% compared with the base model, which is a remarkable improvement. It indicates the effectiveness of R4 on route and user representation learnings. The comparison between R4 and R4-WoS shows that the sparse network improves AUC by 1.6%. In order to depict link ID embeddings learned by the sparse network, we adopt k-means to cluster them and t-SNE (Van der Maaten and Hinton, 2008) to project them into two-dimensional vectors. As displayed in Figure 5(a), each cluster has one characteristic quite different from other clusters, such as slip road, highway, etc. It implies that link ID embeddings capture useful information. Compared with R4-WoD, R4 improves AUC by 0.4%, which manifests the effectiveness of the dense network. To prove that the dense network indeed has the ability to capture local properties of routes, we remove route features f , including local features, from basic features to obtain R4-WoB. The similar performance between R4-WoB and R4 proves that the dense network is capable of covering all the information provided by f . Furthermore, R4-WoB has better performance than R4-WoD. These two facts indicate that not only the dense network has learned route local features explicitly in basic features, but also stores other route characteristics implicitly. R4 improves AUC by 0.08%, compared with R4-WoU. Moreover, as shown in Figure 5(b), user embeddings after clustering reveal different user preferences, such as hating toll roads, hating congestion, etc. It demonstrates that user embeddings obtained from the historical navigation sequence can well represent user preferences. Furthermore, we propose a similarity unit to reveal hidden features learned by the sparse network, as shown in Figure 6. First, we freeze all parameters in R4, and then calculate similarity between link ID embeddings and link static attributes and maximize it. Speciﬁcally, a linear transformation changes link static attributes l into a vector l which has the same size with the dense vector l of link ID. Next, we calculate cosine similarity between l and l . One thing should be noticed is that cosine distance can only measure similarity between non-zero vectors. Hence, we add non-zero bias to avoid zero vectors as proposed in (Luo et al., 2018). In this regard, a smaller similarity value implies more extra information contained in the ID embedding of a link. We select links with small similarity values and conduct analysis on them to expose implicit link properties, including new attributes and attribute errors. The similarity loss is deﬁned as: where D denotes links in the training set D. Unknown tokens and zero-paddings do not participate in similarity loss computation. Since the similarity unit tries to force a link ID embedding to imitate its corresponding vector of static attributes, if the similarity still keeps small, it probably means that the embedding has some hidden characteristics which have not been covered by static attributes, such as new features and data errors. We conduct analysis on links with small similarity values and ﬁnd out cases given in Figure 7. Figure 7(a) is a link whose width is 3 meters, but 6 meters in data; Figure 7(b) is a blocked link under construction, but stored as a passable link in data mistakenly. Figure 7(c) shows a private link of a village where most people cannot enter, but existing attributes cannot depict this situation explicitly. On the one hand, these Figure 5: Embedding Clustering. We use k-means to cluster embedding vectors and present them after dimensionality reduction by t-SNE (Van der Maaten and Hinton, 2008). Low-frequency links and users are removed. Each cluster has at least one characteristic very different from others. For example, most links in the red cluster of link ID embeddings are highways, so we assign it a highway label. (a) shows several clusters of link ID embeddings with labels such as slip road, highway, etc. and (b) shows several clusters of user embeddings with labels such as hating toll roads, preferring highways, etc. Figure 6: Similarity unit. cases are helpful to prove that link ID embeddings contain implicit characteristics of links. Figure 7: Cases of hidden feature detection. Table 3 presents experiment results of ablating different link features. Compared with R4-WoD, R4 brings a big improvement of 0.3% AUC. Compared with R4-WoP, R4 increases AUC by 0.06%. These two observations conﬁrm that the representations of a link should be different in different scenarios and positions. Figure 8: Cases of different route ranking models. To speed up model inference, we employ ResNet20 instead of ResNet50 in online experiment, and the response time (RT) reduces from 100 ms to 60 ms. ResNet20 is able to capture information of 13 links, which means it can characterize route with length of about 2km since the average length of link is about 160m. It is sufﬁcient for learning local features of route. Besides, as shown in Table 3, ResNet20 has similar performance with ResNet50. We conduct online experiments of several baseline models and R4, to manifest the performance of R4 in route recommendation: • SD. Recommend routes with the shortest distance. • ST. Recommend routes with the shortest ETA. The ETA calculation leverages a regression model with real travel time as labels, which implies that ETA is a weighted combination of multiple indicators such as distance, realtime trafﬁc condition, realtime road condition, etc. • ST-H. Recommend routes with the shortest historical time-cost in statistics. Each link has an average statistical time-cost. The time-cost of route is a cumulation of link time-costs. • Base Model. Predict DR of each route with the base model (Section 3.4), and recommend routes with the lowest predicted DR. • R4-C. Predict DR of each route with R4-C (Section 4.2), and recommend routes with the lowest predicted DR. Experiments are conducted in Beijing. Table 4 provides experimental results of DR. Compared with the base model, R4-C decreases DR by 2.4%, which indicates higher satisfaction of users. It manifests R4-C has better performance in DR prediction and route recommendation. Besides, in contrast with the base model and R4-C, SD, ST, and ST-H all have higher DR, implying lower satisfaction of users. The statistical features of routes recommended by different models are listed in Table 4. Comparing R4-C with the base model, the number of trafﬁc lights and the number of turns have very small changes, which proves that routes recommended by R4-C provide sufﬁcient intersections for users to turn. That is to say, the decrease of DR is not achieved by recommending routes with less intersections for users to turn. Moreover, the highway distance is reduced, which also eliminates the probability that R4-C decreases DR by inducing users to drive highways and consequently restricting users from turning into other routes. Route distance of SD is the shortest as expected, but it has much more trafﬁc lights and much longer ETA than others. ST has shortest ETA but longest route distance and highest toll. ST-H has no obvious advantages. Figure 8 provides an example of recommended routes from same origin to same destination of different ranking models. Figure 8(a) is the route recommended by SD. It has shortest distance but 7 km of congestion. In this case, ST-H recommend the same route with SD. Both ST and the base model recommend a route with barely no congestion as shown in Figure 8(b). In contrast with the route recommended by SD, it reduces time by 24 min, which seems to be a good choice. However, as shown in the picture, it has over 1 km of minor road with many cars parked on both sides of it, which is very hard to drive through and may give user a pretty bad experience. R4-C solves the problem as given in Figure 8(c). It avoids the bad minor road above and chooses a major road instead at the beginning of the route. It further proves that R4-C indeed captures implicit properties of routes and ranking routes by predicted DR of R4-C is able to avoid bad roads. In online service, user embeddings are pre-calculated and updated daily. Online DR prediction retrieves them directly from database. Since the framework supports parallel computing, it is possible to apply it to a large road network with hundreds of millions of links. In this paper, a novel framework R4 is proposed to learn route representation and user representation in route recommendation task. For the accuracy of route representation, we denote route as a sequence of links, which includes both road segment information and turn information. The sparse & dense network we proposed obtains two types of route embeddings. One contains implicit characteristics of routes, the other contains local features of routes. For user representation, a sequence of user historical navigation is utilized to extract user preference. Moreover, a similarity unit is designed to reveal hidden features captured by link ID embeddings. It is helpful for discovering new attributes and correcting attributes errors, which in return beneﬁts the learning of route representation. Ablation study proves the effectiveness of each unit in R4. Furthermore, the online experiment on Amap, the top-tier LBS-service provider in China, manifests the remarkable performance improvement of R4 for route recommendation.