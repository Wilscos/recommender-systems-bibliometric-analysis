thanhdatn@student.unimelb.edu.authanh.ld164834@sis.hust.edu.vn Graph Neural Networks (GNNs) have recently emerged as a robust framework for graph-structured data. They have been applied to many problems such as knowledge graph analysis, social networks recommendation, and even Covid19 detection and vaccine developments. However, unlike other deep neural networks such as Feed Forward Neural Networks (FFNNs), few analyses such as verication and property inferences exist, potentially due to dynamic behaviors of GNNs, which can take arbitrary graphs as input, whereas FFNNs which only take xed size numerical vectors as inputs. This paper proposes an approach to analyze GNNs by converting them into FFNNs and reusing existing FFNNs analyses. We discuss various designs to ensure the scalability and accuracy of the conversions. We illustrate our method on a study case of node classication. We believe that our approach opens new research directions for understanding and analyzing GNNs. Property Inference, Formal Explanations, Graph Neural Networks ACM Reference Format: Thanh-Dat Nguyen, Thanh Le-Cong, ThanhVu H. Nguyen, Xuan-Bach D. Le, and Quyet-Thang Huynh. 2022. Toward the Analysis of Graph Neural Networks. In Proceedings of The 44th International Conference on Software Engineering (ICSE 2022). ACM, New York, NY, USA, 5 pages. https://doi.org/ 10.1145/nnnnnnn.nnnnnnn Deep Neural Networks (DNNs) have emerged as one of the most eective and modern approaches in solving problems, from common ones such as movies recommendations, image recognition thanghq@soict.hust.edu.vn Hanoi University of Science and to important ones such as collision control and "fake" news and information detection. Just like software, these DNN models can be misused and attacked (e.g., small perturbations to the inputs can result in misclassifying results). Thus, over the last decade, researchers have developed many powerful techniques to analyze DNNs, e.g., verifying that for certain inputs, a DNN will result in a certain output or have a desirable property, and more recently, inferring properties or facts to help explain behaviors of a DNN, which is typically treated as blackbox. Despite the proliferation of DNNs analyses, most eective ones focus only on certain types of DNNS, such as Feedforward Neural Network (FFNNs), in which the inputs are presented as xed-size vectors of numbers and a xed structure network. One of the more complicated DNNs that has recently been used in practice is Graph Neural Networks (GNNS), which take inputs as graphs of various sizes (even each of the nodes in the graph is attached with information encoded as a vector of numbers) and have a dynamic network that depends on the structure and information from the input graphs. GNNs have been applied to solve many practical problems, e.g., knowledge graphs analysis [12], recommendation system for social networks [16], chemical and protein classication [4,10], reasoning the structure of graphics and images [13], and even advanced COVID19 detection [11,19] and vaccine development [2, 6, 17]. Just as with standard DNNs, complex GNNs are often used as blackbox and can be vulnerable to adversary attacks, all of which lead to concerns about safety, fairness, and privacy of GNNs [3,14, 18], e.g., a new Covid vaccine developed by unknown and attackedprone ML technique can only further increase doubts and hesitancy from the public. However, unlike popular FFNNs, in which there are many eective formal analyses, to the best of our knowledge, few exist for GNNs, potentially due to the vast dierences between the two types of networks. In this paper, we propose an approach to analyze GNNs, both in verication and property inference, by converting GNNs to FFNNs and reusing developed techniques for FFNNs. While analyses explicitly designed for GNNs can be more ecient, they can be dicult and time-consuming to develop due to the dierences between two types of networks. Thus, we believe our approach of leveraging existing ecient techniques and tools can be achieved quicker and also as eectively, as we can rely on existing powerful FFNN tools. This kind of approach is similar to many techniques in software engineering that encode the analysis task as a logical formula that can be eciently analyzed by existing constraint solving techniques and tools (e.g., SAT and SMT solvers). Fig. 1 gives an overview of our idea. The main challenge in analyzing GNNs and converting them to FFNNs is that the input graphs of a GNN can have various topological structures and the GNN has a dynamic structure depending on its input graphs. To solve this challenge, we mine inuential sub-structures of input graphs to summarize the structural input space of a GNN. Then for each sub-structure, which represents a class of input graphs, we "unroll" the structure to create an equivalent FFNN for each node update operation of GNN, and then combine these FFNNs into a nal FFNN representing the original GNN computation of the substructure. While inuential substructure should contribute signicantly toward GNN prediction, additional nodes that are noninuential can still aect the nal computation result of the GNN. To deal with this, we nd conditions on which the rolled out FFNN on the substructure and the original GNN is equivalent to ensure our results. Finally, given the equivalent condition, we can now extend the existing DNN analyses to the rolled out FFNN of each substructure and obtain results for the original GNN. Existing verication techniques for DNNs attempt to check that the DNN satises a user-supplied property (e.g., a certain range over Figure 2: GNN message passing and unrolling inputs results in a certain output). In contrast, property inference attempts to automatically infer such properties from the DNN. In both cases, the property to be veried or inferred has the form pre =⇒ post, wherepreis a condition over the inputs andpost is certain requirement on the outputs. Typically, we are interested in verifying or inferring theprefor some specicpost, e.g., we want to nd input conditions that make the DNN classies an image as a "dog". For this work, we will consider GNN models for the standard problem of graph node classication, which takes as input a graph 𝐺and gives a classication𝑐for each node𝑣 ∈ 𝐺. For such GNNs, thepreare input properties, which are logical predicates capturing common structure and featuresof the input graphs that lead to a certain classication of the target node. Below we use a concrete example given in Fig. 2 to describe the steps of our approach, whose overview is given in Fig. 1. Unlike an FFNN, a GNN does not have a xed structure: it can take arbitrary graphs and the behaviors of GNN itself also change depending on the structure of the inputs (e.g., the inuence of a node depends on its neighbors). Thus, a direct, naïve way of converting a GNN to an FFNN does not scale as it would result in a dierent FFNN for each dierent input graph and the FFNN can also be very large if the input graph is large. To solve this challenge, we will create FFNNs that support classes of input graphs. We leverage existing works in network graphs and GNNs to mine common and inuential substructures from sample input graphs. These substructures are compact and summarize important behaviors of a GNN[9,15], and existing works such as GNNExplainer and PGExplainer [9,15] can extract substructures that are important to each GNN prediction (e.g., sets of edges, nodes, and features that are important to the output of target node’s prediction). These substructures are crucial for the generation and analysis of FFNNs in subsequent tasks. For example, comparing to individual graphs these inuential substructures are compact, which are crucial to achieving FFNNs with manageable sizes. Fig. 1 illustrates how we mine inuential substructures (substructure miner). For a trained GNN model, we take in a set of input graphs that have the desired classication and use an existing tool such as GNN explainer to extract subgraphs that are common from the input graphs and inuential to the classication result of the target node. In Figure 1, from the two input graphs𝐺and𝐺, GNNExplainer would extract three substructures𝐺, 𝐺, 𝐺that have been determined to contribute signicantly (inuential) towards the target red-color node prediction while also being present in both graphs from the training dataset (frequented). Our approach thus focuses on analyzing GNNs over input graphs that we have knowledge about (through the extracted inuential substructures). The better the sample of graph inputs we have, the larger and more accurate set of inuential substructures we learn—this leads to larger classes of supported graphs. Just as with most DNNs, sources of obtaining training samples vary, e.g., public benchmarks. If available, we can also reuse input graphs that were used to train the GNN models we are analyzing. Many existing DNNs and program analyses encode problems into logical formulae that can be reasoned about using constraint solving. Here, we encode the obtained graph substructures as logical predicates𝜎, so that we can leverage existing automating reasoning tools such as SAT and SMT solvers. An important use for these structure predicates is to check if an input graph contains the considered substructures. If it does, we are condent that our approach and result will hold; and if it does not, we can support it by adding it to our training data to learn about its inuential substructures. These predicates are also a crucial part of the inferred properties that help explain the behaviors of the GNN to the user. To determine if an input graph satises a substructure, we check if the graph and the substructure, which is also a graph, is isomorphic. By adapting existing work such as CFL-match [1], we can apply logical reasoning over the obtained structure predicates to check if there exist a mapping from the querying substructure graph to some subgraph of input graph that would make both graphs isomorphic. Fig. 1 shows these steps. For each obtained substructure, we create a predicate capturing that structure by using standard graph isomorphic checking. As an example structure predicate ensuring present of𝐺which has three nodes𝑥(green),𝑥(blue) and𝑦 (red) to be matched to input graph𝐺 = (𝑉, 𝐸)where𝑉is the set of nodes and𝐸is the set of edges, can has the following form (note that we have omitted node-label checking for readability): Concerning the implementation side, this can be done with existing analysis tools by transforming from a graph problem to âa satisability problem (e.g., nodes represented as boolean variables and edges as logical connections among variables). Notice if we perform graph isomorphism checking on some input graph such as 𝐺in the Figure 1, we will see that it is isomorphic to the predicate of substructure 𝐺because they share the same substructure. Obviously, all trained input sets would be isomorphic to at least one of the structure predicates. After obtaining inuential substructures and their corresponding substructural predicates, we are now ready to create an FFNN to represent the GNN model. As it turns out, it is actually straightforward to convert a GNN with a xed substructure directly to an FFNN. We assume our GNN uses the the popular message passing process[4] adopted in most types of GNNs. This process works by updating the value of a node in the graph based on the information of its neighboring nodes. Then, to create an FFNN from a GNN with a set of substructures, we essentially create a FFNN to simulate how message passing is done on a substructure using the “unroll” technique similar to one introduced in [7] for RNN unrolling. Finally, we combine all FFNNs to obtain a nal FFNN representing the original GNN (that supports graph inputs isomorphic to the considered substructures). Figure 2 shows how message passing works on the substructure 𝐺obtained in Fig. 1. Again,𝐺consists of 3 nodes𝑥, 𝑥 and𝑦, for illustration purposes, we use a GNN with 2-layer and the weight𝑊to represent the values of features of each node. For layer 1, the GNN contains three message passing processes labelled (1), (2), (3) that correspond to the three nodes𝑦,𝑥, and𝑥. The results of these message passing processes are updated as newly computed node features of𝑦, 𝑥and𝑥, which are used for next layer. For nal layer 2, we only need to consider target node𝑦’s message passing from the result of (1), (2) (3), followed by a simple linear transformation and we have a message processing process labeled (4) in Figure 2. Now, we unroll each message passing process in layer𝑖of the GNN into a corresponding𝑖-layer FFNN. For the three messagepassing processes in Layer 1 in Figure 2a, we obtain the three 1-layer FFNNs shown in Figure 2b and for the message passing process in layer 2 in Figure 2a, we have the 2-layer FFNN shown in Figure 2b (4). Finally, we connect these individual FFNNs to construct a nal (large) FFNN as shown in Figure 2b to represent the original GNN. Using Existing FFNN analyses. We can apply existing analyses for FFNNs to our rolled out FFNN. For instance, we can apply the Prophecy tool [5] to infer properties for FFNNs. This work derives predicates over the inputs of an FFNN, which convex regions over inputs values, that map to a desired output classication. We can also apply FFNN verication tools such as Marabou (the successor of the popular Reluplex work [8]) to check if an inferred or usersupplied property is correct. For the running example in Figure 2, given some specic weights in Figure 2a, running Prophecy on the resulting FFNN can gives the following predicates representing a convex region over the inputs space that result in the desired classication of the target node in the GNN. Here the input𝑥of the FFNN represents the feature𝑗 of node 𝑥of the GNN. 𝜎= (𝑥+ 𝑥− 𝑥− 𝑥> 0) Ideally, the mined inuential substructures truly represent the behaviors of the considered GNN and the obtained FFNN is thus equivalent to the GNN. In practice, this does not happen as many nodes, especially those that are not part of the inuential substructures but are neighbors with those in the substructure, can inuence the nal GNN classication result. Thus, we want to analyze how these neighboring nodes can directly aect those in the inuential substructures and thus the nal result. Our experiences with GNNs show that a node in a inuential substructure is aected by their "outside" neighbors (those that are not in the substructures) in two ways: the number of outside neighbors it has comparing to its total number of neighbors (connectivity ratio) and the mean contribution of the outside neighbors. Given this knowledge, we compute additional conditions over substructures to make them represent the GNN more accurately. To do this, we use decision trees to compute predicates over the two features representing connectivity and mean contribution. We split the input graphs (e.g., used in the beginning to obtain substructures) into those that are and are not isomorphic to the substructures. With respect to each inuential substructure, we collect the supporting input graph set from the training dataset. Following this, for each input in the supporting graph set, we perform two predictions of target node𝑦’s output: 1) using only the inuential substructure and 2) using the full input graph. We collect statistics onconnectivity ratioandmean contributionto predict whether the output on target node 𝑦 remains the same throughout two scenario. Using this set of training data, we can leverage decision tree to determine conditions over the two features representing connectivity ratio and mean contribution that lead to equivalent or non-equivalent classication. Each paths in the tree represents an additional predicate that can help strengthen the substructures, allowing them to represent the GNN more accurately. For example, the decision tree in Fig. 3 produces several predicates such as which says that node 0 with connectivity ratio>0.2 , node 1 with connectivity ratio<=0.5, and the mean contribution of feature 0 in node 0≥0.2 are likely needed as conjunction for the feature predicate on the substructure holds for all graphs. Thus, this approach allows us to obtain a set𝜎of predicates to strengthen the substructure predicates, ensuring they represent the GNN more accurately. Figure 3: Example of using decision tree to predict whether substructure computation will be equivalent to the input graphs At the end, our approach produces a property𝜎of a given GNN in form of where𝜎is predicate capturing graph isomorphism (Section 2.2), 𝜎are input properties of the converted FFNN (Section 2.3), 𝜎is the additional constraints helping the FFNN more accurate to the original GNN (Section 2.4), and Q is the output property of some target node𝑦(e.g.𝑜< 𝑜). This means for an an input graph with target node𝑦that is isomorphic to some of the mined substructure (satises𝜎), has certain requirements about neighboring substructure nodes (satises 𝜎), with node features lie within certain regions (satises𝜎), then this graph will have the property 𝑄 on its target node. Currently, we only have worked out our idea on several small examples by hand. We are now moving to implementing these ideas to automate the process. After that, we will evaluate the approach with existing GNN benchmarks. We anticipate several challenges that would arise in this direction. First, for complex GNNs, the converted FFNNs might be too complex and contain non-trivial, e.g., nonlinear-arithmetic. These would give diculties to standard FFNN verication tools such as Reluplex. Second, we use sample inputs to mine substructures and feature predicates, and thus can obtain inaccurate results. While we might be able to obtain "groundtruths" or manually check results of small GNNs, we will not have an eective way to formally verify our results on complex and real-world GNNs. Third, obtaining realistic benchmarks for GNNs might be more dicult as they are not as abundent and well-studied as benchmarks of FFNNs. However, we can start with existing dataset from the literature such as those from [13] for autnomous driving and [4, 20] for drug interactions. Finally, there is always a chance that this entire approach does not work well in practice, e.g., it does not scale or becomes too inaccurate for converting complex GNNs. It might be that designing algorithms directly to solve GNN would give more benets in the long run. However, as with any research problem, especially those with few existing attempts, we have to start somewhere, and converting it to something we do know how to do well seems to be a good place to start.