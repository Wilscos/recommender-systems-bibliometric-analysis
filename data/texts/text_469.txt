Recommender systems are central to modern online platforms, but a popular concern is that they may be pulling society in dangerous directions (e.g., towards ﬁlter bubbles). However, a challenge with measuring the effects of recommender systems is how to compare user outcomes under these systems to outcomes under a credible counterfactual world without such systems. We take a model-based approach to this challenge, introducing a dichotomy of process models that we can compare: (1) a “recommender” model describing a generic item-matching process under a personalized recommender system and (2) an “organic” model describing a baseline counterfactual where users search for items without the mediation of any system. Our key ﬁnding is that the recommender and organic models result in dramatically different outcomes at both the individual and societal level, as supported by theorems and simulation experiments with real data. The two process models also induce different trade-offs during inference, where standard performanceimproving techniques such as regularization/shrinkage have divergent effects. Shrinkage improves the mean squared error of matches in both settings, as expected, but at the cost of less diverse (less radical) items chosen in the recommender model but more diverse (more radical) items chosen in the organic model. These ﬁndings provide a formal language for how recommender systems may be fundamentally altering how we search for and interact with content, in a world increasingly mediated by such systems. Personalized recommender systems guide the modern online experience. These systems recommend movies and music on content platforms (Nguyen et al., 2014; Anderson et al., 2020; Holtz et al., 2020), suggest friendships and groups on social networking sites (Gupta et al., 2013; Kloumann and Kleinberg, 2014), select advertisements for target audiences (Lambrecht and Tucker, 2019), and ﬁlter news to consumers (Das et al., 2007). As recommender systems increasingly shape the content we consume, we have become more critical of their potential for unintended societal consequences. For example, one concern that has received considerable attention by academics (e.g., (Nguyen et al., 2014; Flaxman, Goel, and Rao, 2016; Rastegarpanah, Gummadi, and Crovella, 2019)) and the public (e.g., (Singer, 2011)) alike is that these systems may be pulling society towards “ﬁlter bubble” dynamics, where individuals become isolated from viewpoints besides their own (Pariser, 2011). However, jugander@stanford.edu a key challenge with measuring the true effects of recommender systems is that we only observe user outcomes under recommender systems, but we are missing a credible assessment of user outcomes in the absence of these systems. To understand deﬁnitively whether recommender systems have a signiﬁcant impact on ﬁlter bubbles, or any other societal phenomena, we need a systematic way to compare these two scenarios and their outcomes against each other. To address this need, we introduce a dichotomy of process models that describes a world with and a world without recommender systems. Consider the example of a user who is new to a movie distribution platform, and seeking to watch one movie for the night. Under our organic model, the user searches for movies “organically” without the mediation of any recommender system. She wants to watch the movie that best ﬁts her interests, but she does not know the contents of any of the candidate movies. During this search process she has access only to noisy signals of each movie (e.g., by watching trailers or reading reviews), and based on these noisy signals, she must estimate each movie’s content. To complete the matching process, she chooses to watch the movie that she estimates best matches her own interests. Compare this ﬁrst model against the case where the platform has a personalized recommender system. Under our recommender model, the situation is now ﬂipped: whereas the user knew her own interests well but previously had to estimate the contents of the movies, now the system knows the movies on the platform well, but must estimate the user’s interests. In a similar manner, the system gathers a noisy sample from the user (e.g., by asking her to name one movie she recently enjoyed). Based on this noisy sample, the system then estimates her interests and recommends her the movie it believes is the best match. In this dichotomy, the organic model functions as a baseline against which the matching behavior of a recommender system can be compared. What connects these two settings is the act of trying to match users to items with only noisy information about one side; what differs, however, is which information is known and who is doing the matching (the user themselves vs. the recommender system). We ﬁnd that this difference in perspective between the two models results in signiﬁcant differences in outcomes. We characterize these differences through the lenses of both (1) individual metrics (what is the expected loss for a given user? Does this differ across users?) and (2) population metrics (what is the average user loss? Which items tend to be selected overall?). Furthermore, we document the notably varying effects of regularization in each of the models, where the users or system apply shrinkage to their estimates. We will see that shrinkage can reduce average user loss in both models, but it also introduces new effects that cause the models to diverge further. Thus, even in these distilled settings, the intersection of our models, metrics, and algorithm design decisions (such as shrinkage) creates a rich environment in which we can investigate the effects of recommender systems. We summarize our contributions as: 1. A framework of two contrasting models that capture organic search and recommended item-matching as symmetric, comparable processes; 2. Theorems proving key differences between the models from both the individual and population perspectives; 3. Simulations demonstrating that our ﬁndings translate from the theorem settings to realistic data (MovieLens). Collectively, our work lays out a formal model-based language for how the effect of recommender systems can be meaningfully analyzed relative a counterfactual world without such systems. The widespread adoption of personalized recommender systems has led to diverse investigations of the potential societal consequences of these systems. One body of literature tackles bias in recommender systems (Chen et al., 2020; Bozdag, 2013), examining how they may systematically underrepresent minority views (Stoica and Chaintreau, 2019), serve predictions of uneven quality across user groups (Yao and Huang, 2017), or fail to recommend valuable items to certain users, e.g., showing job opportunities in STEM ﬁelds to fewer women than men (Lambrecht and Tucker, 2019). Empirical observations, however, have often been mixed in nature, e.g., documenting how systems sometimes favor longtail items (Fleder and Hosanagar, 2009; Brynjolfsson, Hu, and Simester, 2011) or (over-)favor popular items (Abdollahpouri, Burke, and Mobasher, 2017). Another topic of societal concern is the possibility that personalized recommendations are pushing individuals into “ﬁlter bubbles” (Pariser, 2011). Social media users are known to selectively share content and connect to friends who agree with their existing opinions (An et al., 2014; Garimella et al., 2018), and there is some evidence that recommender systems exacerbate this dynamic of ideological segregation (Bakshy, Messing, and Adamic, 2015; Flaxman, Goel, and Rao, 2016). Recommender systems seem to have a narrowing effect in other contexts as well: e.g., the sets of movies (Nguyen et al., 2014) and songs (Anderson et al., 2020) recommended to users tend to be less diverse than the content that users ﬁnd on their own. However, some studies have pointed out that the role of recommender systems is modest compared to the impact of user choice (e.g., whether to click on a recommended story) on narrowing consumption diversity (Bakshy, Messing, and Adamic, 2015). Other works have made the case that recommender systems actually increase diversity in exposure (Flaxman, Goel, and Rao, 2016) and widen users’ interests (Hosanagar et al., 2013). Part of the reason why it is so challenging to measure the true effects of recommender systems—and perhaps why empirical studies have not been able to reach a consensus— is that we typically only observe user outcomes under the recommender system, but we cannot assess user outcomes in the absence of these systems. Claims, e.g., that users are entering ﬁlter bubbles, must be understood relative to some counterfactual baseline. Thus, it is often helpful to design models that enable us to “observe“ and compare these hypothetical realities. For example, Dandekar, Goel, and Lee (2013) show with a model of opinion formation that if users are biased in how they process evidence (drawing undue support for their initial opinion), recommender systems can cause a polarizing effect on users’ opinions. Stoica and Chaintreau (2019) show under their model that recommender systems accelerate hegemonic dynamics on social media (i.e., when a single viewpoint receives undue attention). Perra and Rocha (2019) model the impact of algorithmic personalization on user opinions, although the effect also depends on the structure of the users’ social network, As a ﬁnal example, Chaney, Stewart, and Engelhardt (2018) use models to analyze the consequences of feedback loops, when the recommender system is trained on data that was inﬂuenced by the system. Using models to study the impact of recommender systems can be powerful when it is difﬁcult to observe “whatifs” in real life, e.g., what if we removed the feedback loop, what if recommendations were not personalized. In the present work, we take a model-based approach to ask arguably the most fundamental “what-if” question about recommender systems: what if there were no recommender system at all? We analyze our models using ﬁrst-principles measures such as the expected item match for each user, their expected loss, and the variance over the population of matched items (Section 2.2). These measures form the building blocks for many of the downstream phenomena of interest related to recommender systems, including polarization, ﬁlter bubbles, user satisfaction, user retention, and bias and fairness. Implicitly embedded in these more complex processes are the metrics we study, and thus, our work forms a foundation upon which future researchers can build. Our models describe two contrasting processes through which users could be matched with items of choice, e.g., movies, news articles, or consumer products. In Section 2.1, we introduce the notation and formal dynamics of our models. In Section 2.2, we deﬁne the individual and populationlevel metrics we will use to compare the models’ outcomes. 2.1 Model deﬁnition In both models, we will have m users and n items. Each user and each item has a latent position; for example, this could represent movie attributes in the movie context or ideology in the context of news articles. We denote user positions as x∈ Rand item positions as y∈ R, where d represents the dimensionality of the latent space. Overall, the set X = {x}represents all user positions and the set Y = {y}represents all item positions. Our analysis will make very weak distance-based assumptions about the interest/utilities of users for items: we simply assume that user i’s enjoyment of item j is monotonically decreasing to the distance between xand y. Thus, under both models, the decision-making agent (either the user or the recommender system) wants to match the user to the item whose position is closest to hers. Organic model. In this model, the user will “organically” search through the collection of items and choose one for herself (Figure 1a). When surveying each item j, she only has access to a noisy sample of its true position, y. She draws her sample zfrom N (y, Σ), where Σrepresents the covariance in her noise. Then, the user makes an estimate ˆyof item j’s true position. In the simplest case, the user takes the maximum likelihood estimate (MLE) based on her single sample of y: We compare this MLE to an alternate case where the user applies some form of shrinkage (James and Stein, 1961) to her estimates. For example, if the user assumes a Gaussian prior on the item positions, she could take a maximum a posteriori (MAP) estimate of each, shrinking the estimate towards the item mean: where µand Σare the mean and covariance of the item distribution, respectively. This style of shrinkage can also be thought of as regularization towards the item mean. In an empirical setting without a clear prior, Empirical Bayes shrinkage (Efron and Morris, 1976) would be preferred. After surveying all n items, the user will have constructed estimates for every item’s position. Since we assume utility is monotonically decreasing in distance, the user will then choose the item whose estimate is closest to her own position, x. Let krepresent the item chosen by user i under the organic setting. Then, We let ydenote the position of the chosen item k, and will later study properties of yas a random variable that inherits its randomness from the user’s estimates, ˆy. Recommender model. In this model, a recommender system takes on the burden of search instead of the user (Figure 1b). When user i comes onto the platform, the system gathers a noisy sample of i’s true position x. This sample zis drawn from N (x, Σ), where Σrepresents the covariance in the recommender’s noise. Then, just as the user estimated item positions based on her noisy samples, the system makes an estimate ˆxof user i’s true position based on its sample of the user. Again, we ﬁrst consider the case where the recommender system takes the MLE: We will again compare the MLE to the case where the recommender system applies shrinkage to its estimates of user positions. With a Gaussian prior, the MAP estimate of user i’s position is where µand Σare the mean and covariance of the user distribution, respectively. In the absence of a prior, Empirical Bayes shrinkage would again be preferred. As a reversal of the organic model, we assume that the recommender system has perfect knowledge of Y, the set of true item positions, but can only estimate the user’s true position. Let krepresent the chosen item for user i under the recommender model. Similar to the organic model, the system will choose the item whose position is closest to ˆx: Here we again let ydenote the position of the matched item k, where yis a random variable that inherits its randomness from the system’s estimates, ˆx. We deliberately set up the recommendation process to be as similar as possible to the organic process—the structure of the noise and logic in the choice function are identical— so that we can compare the models on the basis of who/what controls the matching and what information they have access to. We do not, for example, model the process of users reacting to recommendations. Instead, we assume that k will be the user’s match, comparing it directly to the match kunder the organic model. Furthermore, we note that both models are made up of distinct modules (sampling, estimation, choice), each of which could be swapped out for more complex processes. For example, in the organic model, one might be interested in other decision-making rules for the user, such as those that make explore/exploit trade-offs or capture risk aversion (in the case of non-uniform sample noise), or in the recommender model, the user estimation process could be derived from a speciﬁc algorithm. Thus, our models describe ﬂexible item-matching processes that can be extended to encompass many real-world systems. 2.2 Metrics We are interested in comparing the outcomes of these models through two lenses, at the individual and at the population levels. At the individual level, we will treat the squared distance between the user and their matched item as a userlevel loss, since we model utility as monotonically decreasing in distance. Let Y= {y, y, · · · , y} represent the multiset of matched item positions over all users; note that |Y| = |X | = m, and that each item position ymight appear 0 times, once, or multiple times in Y. Then, the loss for user i is deﬁned as Figure 1: Model schematics. (a) In the organic model, the user samples and estimates item positions, and chooses the estimate closest to her own position. When shrinkage is applied, the user’s estimates of the items shifts inward, and the user’s choice switches from the inner to outer item. (b) In the recommender model, the system samples and estimates the user’s position, and chooses the item closest to its estimate. When shrinkage is applied, the system’s estimate of the user shifts inward, and the system’s choice switches from the outer to inner item. As we analyze l(X , Y) in Section 3, we will also derive E[y] and Var[y] along the way; that is, the expected position and variance of the matched item for user i. We choose these metrics to study because they form the building blocks of many downstream phenomena of interest. For example, if the expected match for a user is not the user’s own position, the matching process might eventually shift user preferences or opinions, and if different users systematically experience different losses (as we will see happens under certain settings of our models), this implies inequities in the model as it provides matches of differential quality to users on the basis of their preferences. The population-level analysis, meanwhile, is concerned with average user loss and the overall collection of matched items. Observe that the average loss over users simply becomes the mean squared error (MSE) of the matches: These matches are based on estimates, where shrinkage is known to reduce the MSE of an estimator. As such, there are opportunities in both models to reduce mean user loss by having the user / system apply shrinkage during estimation. However, while shrinkage might reduce MSE, that is not its only effect. In Figure 1, we illustrate a basic intuition for a key result: due to the reversal in who is doing the estimating and what is being estimated, shrinkage acts as a “diversifying” force in the organic model, but it serves as a “homogenizing” force in the recommender model. We see that shrinkage in the organic model shifts the user’s estimates of the items inward (i.e., towards 0), so items that are further out now have a better chance of being chosen. Meanwhile, shrinkage in the recommender model shifts the system’s estimate of the user inward, so now items closer to the center are likelier to be chosen. To quantify this intuition, we also study Var[Y] as another population-level metric, the variance of the matched item positions Y. This variance has numerous interpretations in the real world: for example, seeing what kinds of items are being selected may guide content creators as they decide what to generate next. Furthermore, there is evidence that users adjust their preferences to better align with content that they are matched with, whether because they were persuaded by the content (Diehl, Weeks, and Z´u˜niga, 2015), or by the very fact that it was recommended to them (Summers, Smith, and Reczek, 2016). Such dynamics suggest that users may become more heterogeneous if they are matched with a more diverse set of items, and more homogeneous if they are all matched to similar content. With repeated rounds of matching and opinion formation, a great level of heterogeneity in users could lead to polarization or radicalization; conversely, increasing homogeneity could result in ﬁlter bubbles and a lack of diverse perspectives for those on the platform. To develop a theoretical understanding of how these two models behave, we begin with simpliﬁed instances, where we assume that the user and item positions come from Gaussian distributions in a one-dimensional space. For now, we will assume that user and item positions are drawn independently from N(0, σ) and N (0, σ), respectively (since d = 1, we replace covariance matrices Σ with scalar variances, σ). We also focus here on the asymptotic setting where the number of items n approaches ∞ (in Section 4.1 we examine simulations with different ﬁnite values of n). Interestingly, we will see that even this simpliﬁed setting is sufﬁcient to induce the phenomena we seek to understand, and that the results remain qualitatively similar when we explore non-Gaussian multidimensional user and item positions learned from data (Section 4.2). In this section, we organize our results into a series of theorems. In Theorems 1–2, we will analyze how the models differ in terms of individual metrics, by deriving 3 quantities for each model: (1) E[y], the expected item match; (2) Var[y], the variance in the match; (3) E[l], the expected loss; all for any user i at position x. In Theorems 3–4, we will then study how the models differ at the population level, showing that even though shrinkage can reduce MSE for both processes, a key difference is that shrinkage increases the variance of matched items under the organic model but1. E[y decreases this variance under the recommender model.2. Var[y 2. Var[y] →+ Proof. In the organic MLE model, the user makes an estimate of each item position, ˆy= z, where zis a sample drawn from N(y, σ). Since there are an inﬁnite number of items and the support of the item and noise distributions is R, then there must be at least one item estimate located at any given point in R. Thus, when the user chooses the estimate that is closest to her own position, x, we can expect that the chosen estimate lies at x. Given the knowledge that the user’s chosen item produced a sample at x, and that the chosen item’s position ywas drawn from N(0, σ), we can derive a closed form solution for the1. E[y posterior mean and variance of y(since both distribu-2. Var[y tions are Gaussian, forming a conjugate pair), forming the expressions above for E[y] and Var[y].3. E[l Finally, recall that in estimation, mean squared error can be decomposed into the sum of the squared bias and the variance of the estimator. If we view the position of the matched item, y, as an estimate for user i’s true position, x, then the expected squared distance between the two is simply (E[y] − x)+ Var[y], thus yielding E[l]. Theorem 1.2. In the organic MAP model as n → ∞, 2. Var[y] →+ Proof. When the user uses MAP, her estimate of item j’s position becomes ˆy= (σ/(σ+ σ))z. Since there are an inﬁnite number of items, she will still choose an estimate that is equal to x; however, this means that the chosen item must have produced a sample at ((σ+ σ)/σ)x. Again, we can derive a closed form solution for the posterior distribution of the chosen item’s position y, knowing that it was also drawn from N(0, σ). We ﬁnd that the terms cancel out, giving us E[y] = x, and the variance does not change compared to the MLE version of the model. Since E[y] is now unbiased, the user’s expected loss becomes only the variance. Theorem 2.1. In the recommender MLE model as n → ] → σ. Proof. In the recommender MLE model, the recommender system makes an estimate of the user’s true position, ˆx= z, where zis a sample drawn from N(x, σ). Then, the system ﬁnds the item whose position is closest to ˆx. Echoing the proof in Theorem 1, if there are an inﬁnite number of items, then there must be at least one item located at any given point in R. Thus, the chosen item position, y, must be equal to ˆx, and so the distribution of yreduces to the distribution of ˆx, which has an expected value xand variance σ. Since y forms an unbiased estimate for x, the expected loss for the user is again just the variance. Theorem 2.2. In the recommender MAP model as n → Proof. In the MAP setting, the recommender model’s estimate of the user’s position becomes ˆx= (σ/(σ+ σ))z. Since there are an inﬁnite number of items, it is still true that the chosen item’s position, y, will match ˆxperfectly, and so the distribution of yreduces to the distribution of ˆx. Since ˆxis simply a sample drawn from N (x, σ) scaled by σ/(σ+ σ), then ˆxmust be normally distributed with mean (σ/(σ+ σ))xand variance (σ/(σ+ σ))σ. This provides the expressions above for E[y] and Var[y], and the expected squared loss is the sum of the squared bias, (E[y] − x), and the variance Var[y]. Theorems 1 and 2 imply that if we treat the matched item position yas an estimate of the user position x, then the organic MLE model forms biased matches for users, while the recommender MLE model does not. In particular, the organic MLE model is biased in that, relative to x, the expected match for user i is contracted towards the center of Figure 2: Expected user loss as a function of user position (Theorems 1–2); σ= 1 and σ= σ= 0.5. the item distribution (Theorem 1.1). Furthermore, since the bias term grows with x, this means that users closer to the center will be less impacted by the bias than users who are farther out. This is a fundamental difference between the MLE versions of the processes: the organic model favors users who are closer to the center of the item distribution, while the recommender model is agnostic to user position, as we show in Figure 2. Interestingly, the trend reverses when we switch from MLE to MAP: the organic model becomes unbiased, and the recommender model becomes favorable to central users. Some of this effect is particular to our form of shrinkage here (namely, that the user perfectly erases the bias in the organic model by taking the MAP based on the true prior distribution of items), but in general, shrinkage will always increase bias for the recommender model, and,1. Var[Y if the item distribution is heaviest around its mean, shrinkage will also reduce bias for the organic model.2. Var[Y From Theorems 1 and 2, we can also establish that switching from MLE to MAP will always reduce mean user loss (i.e., MSE) in the organic model, and that it can sometimes reduce MSE in the recommender model. First, Theorem 1 shows that in the organic model, expected loss strictly decreases for every user (with non-zero x) from MLE to MAP; thus, the mean loss must fall as well. From Theorem 2.2, we can imagine the conditions under which MAP will achieve a lower MSE in the recommender model: if the user variance σis small, then the bias terms will be smaller because all of the x’s will be closer to 0, and the relative reduction that MAP achieves on the variance, scaling by a factor of (), will be larger. More generally, we can conclude that there are certainly reasons to switch from MLE to MAP for both models, which makes the consequences of the switch all the more interesting – the individual-level consequences which we have analyzed, in terms of biased matches and favored users, and now population-level consequences, which we analyze below. Theorem 3. In the organic model as n → ∞, Proof. In general, we can think of each chosen item position y∈ Yas the sum of its expected value conditioned on x, E[y], and some independent random noise  with variance Var[y] (which does not depend on xin any of our models). Using this approach, the process of generating terms in Yin the organic MLE model can be seen as ﬁrst drawing a random user position x from N(0, σ), scaling it by σ/(σ+ σ), then adding this noise term . We scale x because E[y] = σ/(σ+ σ)x(Theorem 1.1). This output becomes the sum of two random variables, where the ﬁrst term is the scaled x and the second is . The variances of these terms are (σ/(σ+ σ))σand Var[y] = (+), respectively, so the expected variance of Yis the sum of these expressions multiplied by (m − 1)/m, because there are m elements in Y. In the organic MAP case, the process of generating terms in Ycan also be seen as ﬁrst drawing a random user position x from N(0, σ), then adding a noise term . We do not scale x in this case, since E[y] = x (Theorem 1.2). The output is again the sum of two random variables, where the ﬁrst term is x and the second is . Their variances are σand (+), respectively, so the expected variance of Yis their sum scaled by (m − 1)/m. Theorem 4. In the recommender model as n → ∞, Proof. We can use the same approach from Theorem 3 to derive Var[Y] here. In the recommender MLE model, the process of generating terms in Ycan be seen as drawing a random user position x from N(0, σ) then adding a noise term  that has variance Var[y] = σ(Theorem 2.1). We do not scale x here either because E[y] = x. The sum of these terms’ variances is σ+ σ, and again we scale this by (m − 1)/m. In the recommender MAP model, to generate terms in Y, we draw a random user position x from N(0, σ), scale it by σ/(σ+ σ), then add a noise term  (Theorem 2.2). The variance of the scaled x is (σ/(σ+ σ))σand the variance of  is Var[y] = (σ/(σ+ σ))σ. Adding these terms together, simplifying, and multiplying by (m − 1)/m yields expression for Var[Y]. Figure 3: Variance of matched items Var[Y] (Theorems 3– 4); σ= σ= 0.5 and m = 300. On the left, we ﬁx σ= 1 and vary σ; on the right, we ﬁx σ= 1 and vary σ. From Theorems 3 and 4, we can see that the variance of matched items will always increase in the organic model when switching from MLE to MAP, but it will always decrease in the recommender model when making the same switch. We demonstrate these two effects in Figure 3: across different values for the user variance σand item variance σ, the matched item variance for the recommender MLE model remains well above that of the recommender MAP, and the matched item variance for the organic MLE model is always below that of the organic MAP. This quantiﬁes our earlier intuition from Figure 1 that shrinkage acts as a diversifying force in the organic model (increasing variance), but a homogenizing force in the recommender model (decreasing variance), and we have proven that this is always true in this setting. Theorems 1–4 demonstrated that even the simplest versions of the organic and recommender processes result in vastly different matching behavior. However, one may wonder how sensitive these results are to our assumptions (studying the asymptotic case, with single-dimensional, normally distributed user and item positions). In this section, we remove each of these assumptions, and show via simulation experiments that the key qualitative results we established in this section hold for much more realistic settings as well. In Section 4.1, we implement the single-dimensional Gaussian model described in Section 3, and test how the individual-level and population-level metrics converge to their limits as we increase the number of available items. In Section 4.2, we augment our process models to integrate multidimensional user and item embeddings learned from real ratings data. First, in the single-dimensional Gaussian setting we analyze the behavior of our proposed metrics as the number of items n grows, complementing our analytical results in Section 3, where we focused on the asymptotic setting where n → ∞. We consider both the MLE and MAP versions of the organic and recommender models and n ∈ {4, 6, · · · , 200}. For the individual metrics, we simulate 5000 stochastic trials for each model and value of n, re-sampling per trial the positions of items and noisy samples, but ﬁxing the location of the single hypothetical user to x= 0.75. For the population metric, we simulate 500 stochastic trials, since there is far less variance in this metric, and re-sample positions of users, items, and noisy samples per trial. As shown in Figure 4, these simulations are consistent with and extend our earlier analyses. In the organic model, when the user employs the MLE, a biased match is formed and the average yconverges inward of x= 0.75; as expected, converging at 0.5, since σ= 1 and σ= 0.5, and E[y] = (σ/(σ+ σ))x(Theorem 1). Meanwhile, the recommender MLE model forms an unbiased match, and the average yconverges to 0.75 when the number of items n reaches around 100. When MAP is used, the roles are reversed, as the organic model becomes unbiased and the recommender model becomes biased. Furthermore, every model converges to a different matched item variance: the recommender MLE model has the highest variance, followed by organic MAP, then organic MLE, then ﬁnally recommender MAP (following the order we would expect from Figure 3, at σ= σ= 1), and this ordering is observed when there are as few as 10 items. We also observe that as we increase the number of items n, the average yand Var[Y] converge to their limit from the “inside” (the side closer to 0). To provide some intuition for this behavior, at the core of our asymptotic analyses for E[y] is the understanding that when there are inﬁnite items, the user will choose an estimate that lies exactly at x, regardless of the shape of the item distribution. However, with fewer (ﬁnite) items available, the more the item density inﬂuences E[y] and contracts it towards the item mean, which is 0. In the most extreme case, if there is only one item, then E[y] = 0 for all users and Var[Y] = 0, because every user will be matched to the same item. Thus, as the number of items n grows, E[y] and Var[Y] converge from the side closer to 0. 4.2 Empirical analysis with MovieLens data In this section, we further extend our simulations by incorporating multidimensional user and item positions ﬁtted on real ratings data. We use the MovieLens 1M dataset, which contains 1,000,209 ratings from approximately 6,000 MovieLens users on 3,900 movies (Harper and Konstan, 2015). First, we ﬁlter the ratings matrix to only keep users that have rated at least 50 movies, then ﬁlter to keep movies with at least 50 ratings. After ﬁltering, we are left with a rating matrix R ∈ R, where we have m= 4, 297 users and n = 2, 514 movies remaining. Learning user and item distributions from data. We apply a collaborative ﬁltering algorithm to R in order to infer latent embeddings U = [u], u∈ R, for each user i, and V = [v], v∈ R, for each movie j. Collaborative ﬁltering uses the history of interactions between all users https://grouplens.org/datasets/movielens/1m/. Figure 4: Simulation results over different values of n. As before, we set σ For the individual metrics, we run 5000 trials for each model and n, and evaluate the mean (left) and variance (middle) of the matched item position yfor a user positioned at x= 0.75. For the population metric, we run 500 trials for each setting and evaluate the mean variance over the matched item positions Y(right). and items to infer latent representations, where users and items are encoded into low-dimensional spaces such that if a user has given an item a high rating, their representations should be “similar”, and if a user has given an item a low rating, their representations should be further apart. Similarity can be measured in different ways (e.g., inner products, Euclidean distance); since our models take a distance-based perspective to utility, we implement a collaborative ﬁltering procedure (Khoshneshin and Street, 2010) that embeds users and items into a uniﬁed Euclidean space where items that are closer to users are more attractive to them. In this framework, given a user embedding uand movie embedding v, their predicted rating ˆris where µ is the global average rating in R, bis the user bias term capturing users that tend to rate higher or lower, and ||u− v||is the squared distance between the two embeddings. This framework naturally integrates our deﬁnition of user loss—the squared distance between a user and her matched item—since a user’s predicted rating is exactly the negative squared distance, translated by µ + b(which remains constant per user). Furthermore, this formulation ﬁts with the choice function in our models: just as we assume that the recommender system will choose the item that minimizes distance to its estimate of the user, that very same item here would be the one that maximizes predicted rating. To learn these embeddings, we deﬁne the following objective function, where we aim to minimize the regularized loss over all observed ratings in R: minw[(r− ˆr)] + λ(||u− v||+ b). (10) Here B represents the set of all user biases b, and w∈ {0, 1} indicates whether the rating ris observed in R. We then use gradient descent to update the latent parameters U, V, and B with respect to the regularized loss. After learning U, i.e., the embeddings of the users in the MovieLens Figure 5: Distribution of learned user (top) and movie (bottom) embeddings from the MovieLens 1M dataset. dataset, we sample from this empirical distribution to generate m “test” users. This creates a new matrix of user positions, X ∈ R, which we use in our simulations to represent unseen users. Our simulations do not rely on unseen movies, however, so we can directly set Y, the item positions in our simulations, to V, the movie positions directly inferred from the MovieLens dataset. Simulations with MovieLens embeddings. Using this approach, we learn user and movie embeddings of dimension d = 5 from the MovieLens dataset. In Figure 5, we display the learned user and movie distributions. We see that the user distribution is less dispersed than the movie distribution in each dimension, and the movie distribution is sometimes asymmetric (clearly non-Gaussian). For both embeddings, the covariance between dimensions is low. We then simulate the organic and recommender models with m = 300 users and n = 2, 514 movies (the number of movies in the ﬁltered MovieLens dataset). For the organic model, we ﬁx each user’s noise covariance Σto 0.5 · Σ, where Σwas the empirical covariance ﬁtted on Y, the movie embeddings. Similarly, for the recommender model, we ﬁxed the system’s noise covariance Σto 0.5 · Σ, where Σwas the empirical covariance ﬁtted on X , the Figure 6: Individual-level results from MovieLens experiments. We plot each user’s average squared distance to their 10 nearest movies (as a measure of centrality) vs. the user’s loss, averaged over 500 trials. In order to see data points more clearly, we truncated outliers beyond the 95th percentile of the x-axis (showing 285 out of 300 users). user embeddings. We scaled the user / movie covariance in this way, as opposed to using spherical noise, so that the size of the noise per dimension would scale with the variance of the estimated population in that dimension, which we believed was more realistic. When shrinkage is applied within each model, we no longer have the user or system construct MAP estimates with Gaussian priors: the prior distribution is neither Gaussian nor known. Instead, we implemented shrinkage parameterized by a scalar α ∈ [0, 1], which interpolates between the MLE estimate and the mean over all MLE estimates. That is, user i’s shrunken estimate ˆyfor movie j becomes ˆy= (1 − α)ˆy+ α(1nˆy and the recommender system’s shrunken estimate of user i is the equivalent interpolation between ˆxand the mean MLE estimate over all users. This family of estimators generalizes James–Stein shrinkage and Empirical Bayes estimators, which correspond to speciﬁc recipes for choosing α (or α, different for each user). Despite the lopsided movie distribution and expanded number of dimensions, we ﬁnd that the key qualitative results from our theoretical analyses hold. In Figure 6, we see that the organic MLE model continues to strongly favor more central users, compared to the recommender MLE model, which is much more even-handed across user positions. In our earlier setting with items drawn from N(0, σ), the centrality of a user could be summarized by the absolute value of x, but here we need a more empirical measure; for example, we use the user’s average squared distance to their 10 nearest movies (where higher average distance corresponds to lower centrality). Secondly, we simulate different amounts of shrinkage (α ∈ {0.05, 0.1, · · · , 0.95}) and evaluate the impacts on our population-level metrics, the mean user loss (MSE) and the variance of matched item positions Var[Y]. In multiple dimensions, we compute the generalized variance as the product of the eigenvalues of the covariance matrix of Y; we Figure 7: Population-level results from MovieLens experiments. We assess the effect of varying the shrinkage parameter α on the MSE and variance of matched item positions Var[Y], running 500 trials for each model and value of α. log-transform this quantity to make it more interpretable. As we increase the amount of shrinkage, at ﬁrst this improves MSE for both models, but eventually MSE begins to increase; the optimal level of shrinkage seems to fall around α ≈ 0.4 for both models. However, even though the MSE curves look similar, the Var[Y] curves completely diverge: the more we increase α, the more Var[Y] grows in the organic model, and the more it shrinks in the recommender model. This matches our earlier ﬁndings that shrinkage has a “diversifying” effect on the organic model but a “homogenizing” effect on the recommenders. We have introduced two contrasting models of itemmatching processes: one describing a generic personalized recommender system, and the other describing a setting where users search for items organically without the mediation of any system. In both cases, we have a decision-making agent trying to match users to items with limited information, but the difference lies in who/what is doing the matching, and what information they have access to vs. what is being estimated. Comparing the two, we have seen that this simple switch in perspective results in dramatic differences at both the individual and population levels. For example, in the MLE versions of the models, the recommender model forms unbiased item matches for the users, while the organic model does not, and the organic model favors central users, while the recommender model does not. Applying shrinkage has notably diverging effects on the two models: while it can reduce MSE in both cases, shrinkage leads the recommender model to choose increasingly similar sets of items, while leading the organic model to diversify its selections. These ﬁndings, which are robust to changes in user and item distribution, single and multiple dimensions, and asymptotic and ﬁnite settings, indicate pervasive differences between recommended and organic processes of item-matching. We have worked to study one of the core counterfactual questions about recommender systems: if there were no recommender system, how would the world be different? Our analyses provide evidence that the use of recommender systems fundamentally alters how humans interact with content. Recommender systems are usually touted as reducing search frictions in markets, but through our work we ﬁnd that such reductions in search friction comes with myriad subtle trade-offs. We hope that future studies can build upon the framework established in this paper, using our models as building blocks to analyze diverse potential effects of recommender systems, such as polarization, ﬁlter bubbles, user retention rates, or fairness across users or products. As a speciﬁc direction, by modeling repeated choices and incorporating learning dynamics where users learn from the items they consume (Diehl, Weeks, and Z´u˜niga, 2015), it should be possible to analyze how the phenomena we document here, pertaining to single choices, compound over time and affect the evolution of users’ opinions and behaviors. Finally, we also hope in future work to tie the theory of our model to real-world experiments; for example, through randomized trials where participants are assigned to unmediated organic search versus system-mediated search processes, to understand the differences most broadly. This work was supported in part by funding from the Stanford Program on Democracy and the Internet and ARO MURI award #W911NF-20-1-0252. We thank Jan Overgoor, Amel Awadelkarim, Arjun Seshadri, and Kaitlyn Zhou for helpful feedback and discussions.