Information Technologies Institute Centre for Research and Technology—Hellas 57001 Thermi, Thessaloniki, Greece Department of Electrical and Computer Engineering Aristotle University of Thessaloniki 54124, Thessaloniki, Greece Relational data can be organized into graphs, where entities are represented as nodes and linked through edges corresponding to real-world relations between them. Due to the pervasiveness of complex graphs across disciplines such as social networking, epidemiology, genomic analysis and software engineering, various schemes have been proposed to mine relational information. These range from the unsupervised paradigms of node clustering (Schaeﬀer, 2007; Kulis et al., 2009) and exposing underlying structures through edge sparsiﬁcation (Spielman and Teng, 2004) to semi-supervised inference of posterior attribute scores based on known node prior values (Kipf and Welling, 2016; Chen et al., 2020). A mechanism favored by many approaches is propagating latent or predictive attribute information through graphs via recursive aggregation among node neighbors. For example, information Graph ﬁlters are an emerging paradigm that systematizes information propagation in graphs as transformation of prior node values, called graph signals, to posterior scores. In this work, we study the problem of mitigating disparate impact, i.e. posterior score diﬀerences between a protected set of sensitive nodes and the rest, while minimally editing scores to preserve recommendation quality. To this end, we develop a scheme that respects propagation mechanisms by editing graph signal priors according to their posteriors and node sensitivity, where a small number of editing parameters can be tuned to constrain or eliminate disparate impact. We also theoretically explain that coarse prior editing can locally optimize posteriors objectives thanks to graph ﬁlter robustness. We experiment on a diverse collection of 12 graphs with varying number of nodes, where our approach performs equally well or better than previous ones in minimizing disparate impact and preserving posterior AUC under fairness constraints. Keywords: graph signal processing, node ranking, algorithmic fairness, disparate impact, optimization propagation has been used in unsupervised extraction of tightly knit node clusters with few outgoing edges (Andersen et al., 2006; Wu et al., 2012), node ranking algorithms that recommend nodes based on their structurally proximity to a set of query ones (Tong et al., 2006; Kloster and Gleich, 2014) and recent graph neural network advances that decouple latent attribute extraction with their propagation to neighbors (Klicpera et al., 2018; Dong et al., 2020; Huang et al., 2020). (Gavili and Zhang, 2017; Ortega et al., 2018; Sandryhaila and Moura, 2013). This domain extends discrete signal processing to higher dimensions, where signals comprise prior values spread not across points in time but across graph nodes. ﬁlters produce posterior node scores through a weighted aggregation of propagating priors diﬀerent hops away, where propagation follows either spectral or stochastic rules. ters, are correlated to sensitive attributes, such as gender or ethnicity (Chouldechova, 2017; Kleinberg et al., 2018). Previous research has studied bias mitigation in the sense that sensitive and non-sensitive groups of data samples behave similarly under evaluation measures of choice (Chouldechova, 2017; Krasanakis et al., 2018; Zafar et al., 2019; Ntoutsi et al., 2020). In this work, we tackle the fairness objective of achieving (approximate) statistical parity between sensitive and non-sensitive positive predictions—a concept known as disparate impact elimination (Biddle, 2006; Calders and Verwer, 2010; Kamiran and Calders, 2012; Feldman et al., 2015) and often assessed through a measure called pRule. In particular, we explore the problem of imposing fairness objectives on graph ﬁlter posteriors, such as maximimizing pRule or making it reach a predetermined level, while maintaining the ability to form accurate predictions over diﬀerent thresholding criteria, as measured by recommender system measures (Shani and Gunawardana, 2011; Wang et al., 2013; Isinkaye et al., 2015), such as AUC. For instance, this can help ensure that a protected set of nodes (the ones considered sensitive) are also frequently but not erroneously recommended. et al., 2020a). There, we proposed that satisfying fairness-aware objectives with minimal impact to posterior score quality can be achieved by appropriately editing graph signal priors. This way, new posteriors can be guided to be fairer while respecting information propagation through the graph’s structure, which is responsible for predictive quality. In our previous paper, we ﬁrst tackled this objective by editing priors with schemes of few parameters, which depend on whether nodes are sensitive and the diﬀerences between priors and posteriors. Our base assumption was that parameters can be tuned to yield priors proportionate to their estimated contribution to fair yet similar to original posteriors. novel mathematical framework to express how tightly prior editing mechanisms should approximate the gradients of posterior objectives and use it to explain why coarse prior editing models can locally optimize fairness-aware objectives. Second, we propose an alternative to our approach that uses an error-based instead of perturbation-based surrogate model, a more robust training objective that is not impacted by high posterior score outliers and an explicit prior retention term. These changes induce higher average AUC when mitigating A systematic way to study information propagation is through graph signal processing Fairness concerns arise when the outputs of data mining systems, such as graph ﬁl- This work extends our previous paper on making graph ﬁlter posteriors fair (Krasanakis In this work we improve various aspects of our previous research. First, we provide a disparate impact, though the two alternatives outperform each other on diﬀerent experiments. Finally, we assess the eﬃcacy of our work by experimenting on a signiﬁcantly larger corpus of 12 instead of 4 multidisciplinary real-world graphs combined with 8 instead of 2 base graph ﬁlters. To facilitate an informed discussion of our results, we also perform a rigorous instead of empirical post-hoc analysis of summary statistics. In this section we provide the theoretical background necessary to understand our work. We start with a common community-based interpretation of node scores and their practical usefulness in Subsection 2.1. Then, in Subsection 2.2, we present graph signal processing concepts used to study a wide range of methods for obtaining node scores given prior information of node attributes. We ﬁnally discuss algorithmic fairness under the prism of graph mining and overview the limited research done to merge these disciplines in Subsection 2.3. The operations and symbols used in this work are summarized in Table 2. Table 1: Mathematical notation. Graph-related quantities refer to a common studied graph. Nodes of real-world graphs can often be organized into communities of either ground truth structural characteristics (Fortunato and Hric, 2016; Leskovec et al., 2010; Xie et al., 2013; Papadopoulos et al., 2012) or shared node attributes (Hric et al., 2014, 2016; Peel et al., 2017). A common task in graph analysis is to score or rank all nodes based on their relevance to such communities. This is particularly important for large graphs, where community boundaries can be vague (Leskovec et al., 2009; Lancichinetti et al., 2009). Furthermore, node scores can be combined with other characteristics, such as their past values when discovering nodes of emerging importance in time-evolving graphs, in which case they should be of high quality across the whole graph. Many algorithms that discover communities with only a few known members also rely on transforming and thresholding node scores (Andersen et al., 2006; Whang et al., 2016). as node scores, is AUC (Hanley and McNeil, 1982), which compares operating characteristic trade-oﬀs at diﬀerent decision thresholds. If we consider ground truth node scores signal deﬁned in the next subsection), and posterior scores r[v], the True Positive Rate (TPR) and False Positive Rate (FPR) operating characteristics for decision thresholds θ can be respectively deﬁned as: where P (a|b) denotes the probability of a conditioned on b. Then, AUC is deﬁned as the cumulative eﬀect induced to the TPR when new decision thresholds are used to change the FPR and quantiﬁed per the following formula: AUC values closer to 100% indicate that community members achieve higher scores compared to non-community members, whereas 50% AUC corresponds to randomly assigned node scores. Graph signal processing (Ortega et al., 2018) is a domain that extends traditional signal processing to graph-structured data. To do this, it starts by deﬁning graph signals q : V → R as maps that assign real values q[v] to graph nodes v ∈ V. as column vectors q elements and V[i] is the i-th node of the graph after assuming an arbitrary ﬁxed order. For ease of notation, in this work we use graph signals and their vector representations interchangeably by replacing nodes with their ordinality index—in other words, we assume the isomorphism V[i] = i. of interest, in which case their elements are assigned binary values depending on whether respective nodes are queries q[v] = {1 if v has the attribute, 0 otherwise}. For example, the A measure frequently used to quantify the quality of attribute recommendations, such [v] = {1 if node v is a community member, 0 otherwise} (these form a type of graph Graph signals are often constructed from sets of query nodes that share an attribute attribute of interest could capture whether nodes belong to the same structural community as query ones. In general, we consider graph signals that are constrained to non-negative values q ∈ [0, ∞) the attribute of interest. In this case, graph signal elements can be understood as node rank scores. A pivotal operation in graph signal processing is the one-hop propagation of node values to their graph neighbors, where incoming values are aggregated on each node. Expressing this operation for unweighted graphs with edges E ⊆ V × V requires the deﬁnition of adjacency matrices A, whose elements correspond to the binary existence of respective edges, i.e. A[i, j] = {1 if (V[i], V[j]) ∈ E, 0 otherwise}. A normalization operation is typically employed to transform adjacency matrices into new ones W with the same dimensions, but which model some additional assumptions about the propagation mechanism (see below for details). Then, single-hop propagation of node values stored in graph signals q to neighbors yields new graph signals q brevity, this operation is usually expressed using linear algebra as q The ﬁrst sets up one-hop propagation as a stochastic process (Tong et al., 2006) that is equivalent to randomly walking the graph and selecting the next node to move to from a uniformly random selection between neighbors. Formally, this is expressed as W of the column-normalized adjacency matrix sum to 1. This way, if graph signals priors model probability distributions over nodes, i.e. their values sum to 1 and are non-negative, posteriors also model probability distributions. tive, where the eigenvalues of the normalized adjacency matrix are treated as the graph’s spectrum (Chung and Graham, 1997; Spielman, 2012). In this case—and if the graph is undirected in that the existence of edges (u, v) also implies the existence of edges (v, u)— a symmetric normalization is needed to guarantee that eigenvalues are real numbers. To achieves this, the normalization W merit that it has bounded eigenvalues and D that implements the equivalent of discrete derivation over graph edges. ization, since these enable computational tractability and closed form convergence bounds of resulting tools. equivalent of signal ﬁltering we later adopt to maintain spectral characteristics needed by our analysis. The key property we take advantage of is that, as long as the graph is connected, the normalized adjacency matrix W is invertible and has the same number of real-valued eigenvalues as the number of graph nodes |V| residing in the range [−1, 1]. If we annotate these eigenvalues as {λ Two popular types of adjacency matrix normalization are column-wise and symmetric. , where D = diagA[u, v]is the diagonal matrix of node degrees. Columns On the other hand, symmetric normalization arises from a signal processing perspec- Graph signal processing research often targets undirected graphs and symmetric normaladjacency matrix’s Jordan decomposition takes the form: where U is an orthonormal matrix with columns the corresponding eigenvectors. Therefore, scalar multiplication, power and addition operations on the adjacency matrices also transform eigenvalues the same way. For example, it holds that W The one-hop propagation of graph signals is a type of shift operator in the multidimentional space modeled by the graph, in that it propagates values based on a notion of relational proximity. Based on this observation, graph signal processing uses it analogously to the time shift z multi-hop propagations. In particular, since W hops away of graph signals q, a weighted aggregation of these hops means that the outcome of graph ﬁlters can be expressed as: where H(W ) is graph ﬁlter characterized by real-valued weights {h indicating the importance placed on propagation of graph signals n hops away. In this work, we understand the resulting graph signal r to capture posterior node scores that are the result of passing prior node values of the original signal q through the ﬁlter. eigenvalues are all positive. For symmetric normalized graph adjacency matrices with eigenvalues {λ tion 2 are positive deﬁnite, as they assume eigenvalues and hence we can check whether the graph ﬁlter’s corresponding polynomial assumes only positive values: For example, ﬁlters arising from decreasing importance of propagating more hops away deﬁnite for symmetric adjacency matrix nomralizations are personalized pagerank (Andersen et al., 2007a; Bahmani et al., 2010) and heat kernels (Kloster and Gleich, 2014). These respectively arise from power degradation of hop weights h kernel h The sweep procedure (Andersen et al., 2006, 2007b) is a well-known mechanism that takes advantage of graph ﬁlters to identify tightly-knit congregations of nodes that are also wellseparated from the rest of the graph—a concept known as low subgraph conductance (Chalupa, 2017). When attributes modeled by graph signal priors are closely correlated In this work, we consider graph ﬁlters that are positive deﬁnite matrices, that is whose ∈ [−1, 1]|i = 1, . . . , |V|}, it is easy to check whether graph ﬁlters deﬁned per Equa-P > h∀n = 0, 1, . . . are positive deﬁnite. Two well-known graph ﬁlters that are positive = et/n! for empirically chosen parameters a ∈ [0, 1] and t ∈ {1, 2, 3, . . . }. to the formation of structural communities, it enhances the recommendation quality of posteriors. algorithm R with strong locality (Wu et al., 2012), such as personalized pagerank and heat kernels, outputs graph signal posteriors R(q) for graph signal priors q that comprise structurally close query nodes. The posteriors are said to be personalized on the query nodes and are compared to their non-personalized counterparts R(1), where 1 is a vector of ones, through the following division: In this work, we follow the terminology of our previous research (Krasanakis et al., 2020a) and refer to the post-processing of Equation 4 as the sweep ratio. The sweep procedure orders all nodes based on this ratio and splits the order in two partitions so that conductance is minimized for the respective graph cut. This practice statistically yields well-separated partitions for a variety of node ranking algorithms (Andersen et al., 2006, 2007b; Chalupa, 2017). Hence, when nodes are scored based on their relevance to structural communities, the sweep ratio can be deployed to improve their quality. In this subsection we introduce the well-known concept of disparate impact in the domain of algorithmic fairness, which we aim to either fully or partially mitigate. We also overview previous works that can be used to bring fairness to graph mining and graph ﬁlter posteriors. Algorithmic fairness is broadly understood as parity between sensitive and non-sensitive samples over a chosen statistical property. Three popular fairness-aware objectives (Chouldechova, 2017; Krasanakis et al., 2018; Zafar et al., 2019; Ntoutsi et al., 2020) are disparate treatment elimination, disparate impact elimination and disparate mistreatment elimination. These correspond to not using the sensitive attribute in predictions, preserving statistical parity between the fraction of sensitive and non-sensitive positive labels and achieving identical predictive performance on the two groups under a measure of choice. Biddle, 2006; Calders and Verwer, 2010; Kamiran and Calders, 2012; Feldman et al., 2015). An established measure that quantiﬁes this objective is the pRule (Biddle, 2006); denoting as R[v] ∈ {0, 1} the binary outputs of a system R for samples v, S the set of sensitive samples and S In detail, the sweep procedure assumes that a base personalized graph node scoring In this work, we focus on mitigating disparate impact unfairness (Chouldechova, 2017; The higher the pRule, the fairer a system is. There is precedence (Biddle, 2006) for considering 80% pRule or higher fair, and we also adopt this constraint in our experiments later. parate impact assessment measure. However, although it is optimized at the same point as the pRule, it biases fairness assessment against high fractions of positive predictions. For example, it considers the fractions of positive labels (p tation of posterior nodes scores could be scaled by a constant yet unknown factor. On the other hand, the pRule would quantify both numerical examples as In domains related to the outcome of graph mining algorithms, fairness has been deﬁned for the order of recommended items (Beutel et al., 2019; Biega et al., 2018; Yang and Stoyanovich, 2017; Zehlike et al., 2017) as equity in the ranking positions between sensitive and non-sensitive items. However, these notions of fairness are not applicable to the more granular understanding provided by node scores. (Bose and Hamilton, 2019; Rahman et al., 2019) under the guise of fair random walks— the stochastic process modeled by personalized pagerank when the adjacency matrix is normalized by columns. Yet the fairness of these walks is only implicitly asserted through embedding fairness. Furthermore, they require a certain number of sensitive nodes to make sure that at least one is available to walk to at every step. and Wang, 2020), which can be trained to produce fair recommendations, even under partial knowledge of sensitive attributes. Still, advances on graph neural network theory (Dong et al., 2020) suggest that they can be perceived as decoupled multiplayer perceptron and graph ﬁlter components, in which case the question persists on how to make the outcome of graph ﬁlters fair, given potentially unfair priors. For graph neural networks that follow a predict-then-propagate paradigm (Klicpera et al., 2018), this could be achieved by the aforementioned practice of adding fairness objectives to loss functions responsible for the construction of graph signal priors from data. However, the model deriving graph signal priors could be too costly to retrain or not available. In such cases, the problem of inducing fairness reverts to the graph signal processing viewpoint of this work. fairness. Although focused on algorithms scoring the structural importance of nodes without any kind of personalization pertaining to speciﬁc graph signal priors, it ﬁrst recognized the need for optimizing a trade-oﬀ between fairness and preserving posterior score quality. Furthermore, it provided a ﬁrst deﬁnition of node score fairness, called φ-fairness. Under a stochastic interpretation of node scores, where they are proportional to the probability of nodes assuming positive labels, φ-fairness is equivalent to full disparate impact elimination when φ = to posterior scores, which we also adopt in this work. In particular, we start from the Calders-Verwer disparity |p− q| (Calders and Verwer, 2010) is also a well-known dis- , q) = (0.4, 0.3). We shy away from this understanding because a stochastic interpre- Another deﬁnition of graph mining fairness has been introduced for node embeddings Fairness has also been recently explored for the outcome of graph neural networks (Dai A recent work by Tsioutsiouliklis et al. (2020) has initiated a discourse on posterior score In our previous work (Krasanakis et al., 2020a), we introduced a generalization of pRule above-mentioned stochastic interpretation of posteriors and calculate the expected positive number of sensitive and non-sensitive node labels obtained by sampling mechanism that uniformly assigns positive labels with probabilities proportional to posterior scores. This deﬁnes the quantities: where the maximum value of posteriors krk is a stochastic process with probability P(R[v] = 1) = cancels out the normalization of dividing both the nominator and denominator with the same value and yields the following formula for calculating a stochastic interpretation of the pRule given posterior node scores r: By convention, we consider pRule = 0 when all node scores are zero. Optimizing graph ﬁlter posteriors to better satisfy objectives by adjusting their values deteriorates the quality gained by passing priors through graph ﬁlters. Ultimately, this leads to losing the robustness of propagating information through node relations by introducing one additional degree of freedom for each node. To prevent loss of quality, we propose that, instead of posteriors, graph signal priors can be edited based on their initial posteriors so as to ﬁnd new posteriors better satisfying set objectives. This scheme is demonstrated in Figure 1, where initial priors q and their respective posteriors r are used to construct new edited priors q be tuned to let posteriors r pact mitigation and discourage large posterior changes. Then, in Subsection 3.2 we explore mechanisms of editing priors to be proportional to the probability of respective posterior scores approaching ideal ones optimizing the objective. This probability is estimated with a surrogate model of diﬀerences between original priors and posteriors. Given that biases against sensitive nodes could also aﬀect the ability to estimate ideal posteriors, diﬀerent model parameters are reserved for nodes with sensitive attributes. We also propose an alternative to our previous approach, that uses absolute errors instead of diﬀerences between priors and posteriors and introduces an additional parameter to explicitly control original prior retention. The involvement of sensitive attributes in both prior editing and objective calculation is demonstrated in the updated scheme of Figure 2. approaches are able to (locally) optimize posterior objectives using few parameters. To do this, we take advantage of graph ﬁlter robustness against prior perturbations to show in In Subsection 3.1 we demonstrate fairness-aware objectives that encourage disparate im- Finally, in Subsection 3.3 we present a new theoretical justiﬁcation of why prior editing Figure 1: Starting from graph priors q and estimating edited priors q Figure 2: Starting from graph priors q and estimating edited priors q ﬁlter posteriors rlocally optimizing an objective L(r). graph ﬁlter posteriors rlocally optimizing an fairness-aware objective L(r). A graph signal s holding sensitive attribute values is used for prior editing and calculating the objective. Theorem 2 that non-tight (that is, bound by the eigenvalue ratio of minimum over maximum eigenvalues multiplied by scalar depending on the post-processing) approximations of prior optimization slopes suﬃce to lead posteriors to local optimality. Under the assumption that prior editing gradients exhibits enough degrees of freedom to express objective gradients with the same loose tightness as before, we then show in Theorem 3 that there exist (not necessarily observed) parameter optimization trajectories that arive at edited priors with locally optimal posteriors. Tuning prior editing mechanisms requires fairness-aware objectives that trade-oﬀ disparate impact mitigation and original posterior score preservation. The ﬁrst of these two components is quantiﬁed by the pRule, which can also be constrained so that values over a threshold sup distance measure between the original posteriors r and the estimated ones r vious work, we penalized the mean absolute diﬀerence between the max-normalized version of original and new posteriors: scores used for normalization. Furthermore, if a few high posteriors were disproportionately large (for example, orders of magnitude larger) compared to the rest, their comparisons would dominate the assessment. As an extreme example, if a clique of nodes with prior values 1 were disconnected from the rest of the graph, personalized pagerank would yield posteriors 1 for these and hence would not normalize other node scores at all. Similar arguments hold if priors favor the discovery of well-separated communities from the rest of the graph, as graph ﬁlter algorithms often do. For instance, the sweep ratio explicitly aims to amplify this phenomenon. posterior scores from assuming disproportionately larger values and dominate comparisons. To address this persisting issue, in this work we move away from the mean absolute diﬀerence comparison and instead use the KL-divergence of estimated posteriors distributions given the distribution of original high quality posteriors. A clear advantage of this measure is that it compares distributions as a whole (it has thus been used to estimate diﬀerences between diﬀerent Gaussian distributions for metric learning (Wang et al., 2017)) and is hence less inﬂuenced by outliers or few disproportionately large posteriors. We convert posteriors to distributions by normalizing them by division with their L1 norm, in which case the KL divergence measures the entropy lost by moving from the original posterior distribution to the new one: . On the other hand, retaining original posterior scores can be assessed through a minimize L(r) A shortcoming of this objective is that it is heavily inﬂuenced by the maximum posterior Dividing posteriors with summary statistics, such as their L1 norm, can not prevent high where the vector division is performed element-by-element and by convention 0 ln x = 0 ∀x ∈ [0, ∞) ∪ {∞}. Replacing the mean absolute error in the previous objective with KL-divergence, we end up with the following more robust variation of the objective: We now explore in more detail the advances of our previous work (Krasanakis et al., 2020a), where we ported to graphs a pre-processing scheme that weights training samples to make well-calibrated black box classiﬁers fair (Krasanakis et al., 2018). This scheme proposes that unfairness is correlated to misclassiﬁcation error (the diﬀerence between binary classiﬁcation labels and calibration probabilities) and is inﬂuenced by whether samples are members of a sensitive group. Since strongly misclassiﬁed samples could exhibit diﬀerent degrees of bias from correctly classiﬁed ones, it skews calibrated probabilities to make them fair by a transformation of misclassiﬁcation error. Diﬀerent skewing parameters are determined for sensitive and non-sensitive samples. and sources of unfairness, depending on the parameters of misclassiﬁcation error transformation and the ones controlling whether calibration probabilities should increase and decrease. Unfortunately, the same principles can not be ported as-are to graph signal processing, because weighting zero node priors through multiplication does not aﬀect posteriors and there is no posterior validation set on which to tune permutation parameters. We address these issues by respectively performing non-linear edits of graph signal priors instead of scaling them and using priors as a rough one-class validation set of known positive examples. Under the above assumptions, we refer to a stochastic interpretation of graph signal posteriors similar to the one used to set up the stochastic generalization of pRule; posteriors are snapped to 1 with probability proportional to their value and to 0 otherwise. We also consider edited graph signal priors q similar fairness to some unobserved ideal ones r suggest a ground truth categorization of nodes based on predictive attributes, we condition the probability of fairness-inducing node posteriors achieving their ideal values on whether they match their priors, that is on whether high posterior values correspond to high prior values. This is formally expressed for graph nodes v as: least some portion of their priors (a fraction of their value equal to or greater than comes from their priors if non-negative parameters are used to deﬁne ﬁlters per Equation 2), we further argue that fairness of posteriors pertains to fairness of respective priors. Hence, probabilities of estimated node posteriors approaching fair ones given tight approximations These considerations introduce a type of balancing between original predictive abilities P (r[v] = r[v]) = P (r[v] = r[v] | q[v] = r[v])P (q[v] = r[v]) Since graph ﬁlters tend to be strongly local in the sense that their posteriors preserve at original priors are correlated with the probabilities of priors being fair P(q The same reasoning applies for estimated posteriors not approximating well the original priors. discovering fairness-aware posteriors increases (compared to the rest of nodes), the others should decrease and conversely, as they are conditioned on complementary events. Therefore, they should not simultaneously overestimate or underestimate original ones. Formally, this property can be expressed as: for some scaling parameters K a surrogate model satisfying this property. This model depends on diﬀerences between posteriors and priors and whether nodes are sensitive: where b is a vector of real values such that b[v] = {b The selection of sensitive or non-sensitive nodes to contribute to original priors can be viewed as Bernoulli trials with probabilities α may diﬀer depending on bias involved in prior selection. For example, there is often a lower probability of reporting sensitive nodes to construct priors (Cassel and Bindman, 2019). We organize prior selection probabilities into a graph signal α with values α[v] = P (q[v] = mation q fairness-inducing personalization, estimated fair ranks should also approach the ideal fair ones: for graph signal a[v] = {a probabilities and permutation scaling factors per a[v] ∝ requires only two independent parameters a In the above process we started with a surrogate model of conditional fair posterior probability estimation that uses the diﬀerences between original priors and their normalized An additional observation is that, when one of the conditional probabilities of correctly [v]) = {αif v ∈ S, αotherwise} ∈ [0, 1]. Therefore, given the surrogate model of conditional errors, we make a fair prior estiq[v] = P (r[v] = r[v] | q[v] = q[v]) ≈P (r[v] = r[v])P (q[v] = q[v]) posteriors as inputs. Although this approach was met with success in our previous work, we also point out that it implicitly involves information on whether nodes assume positive values in the original binary priors instead of only the deviation between posteriors and priors. In detail, the diﬀerences r[v]/krk negative for positive priors p[v] = 1. For example, when b[v] > 0 high posteriors are penalized for the conditional probability of priors approaching estimated posteriors when in reality high posteriors need to be encouraged for positive priors. Similarly, when b[v] > 0 it encourages small posteriors for the conditional probability of priors not approaching estimated posteriors when in reality small posteriors need to be encouraged for zero priors. ternative of adopting the absolute value of diﬀerences by using errors |r[v]/krk inputs to the surrogate model. Following the same analytical process as above, this leads us to the following error-based prior editing mechanism as a potential competitor: The ability of error-based perturbations to mitigate disparate impact while enjoying high predictive quality has also been justiﬁed and experimentally corroborated in previous research (Krasanakis et al., 2018). As a ﬁnal step, and to provide more granular control of the retention of original posteriors required by objective functions, we introduce an explicit trade-oﬀ between original and edited fairness-aware priors by adding a term of the latter weighted by a new parameter a In this subsection we investigate theoretical properties of positive deﬁnite graph ﬁlters that allow coarse approximations of optimal prior editing schemes to also reach local optimality with regards to posterior objectives. Real-world graph ﬁlters often end up with a post-processed version of posteriors. For example, when personalized pagerank is implemented as an iterative application of the power method scheme r = aW r + (1 − a)q, potential feedback loops that continuously increase posteriors for some asymmetric adjacency matrix normalizations are often avoided by performing L1 normalization, which divides node posteriors with their sum. This ends up not aﬀecting the ratio of importance scores placed on propagating prior graph signals diﬀerent number of hops away, but produces a scaled version of the ﬁlter for which node score posteriors sum to 1. transformations per node that can not be modeled by graph ﬁlters. Taking these concerns into account, we hereby introduce a notation with which to formalize post-processing; we consider a post-processing vector with which posteriors are multiplied element-by-element. Formally, this lets us write post-processed posteriors r of passing graph signal priors q To introduce an explainable interpretation of parameters b[v], we thus propose the al- More complex post-processing mechanisms, such as the sweep ratio, may induce diﬀerent through a graph ﬁlter H(W ) as: We stress that the exact post-processing transformation could change depending on both the graph ﬁlter and graph signal priors. However, we can decouple this dependency by thinking of the ﬁnally selected post-processing as one particular selection out of many possible ones. In this work we consider two types of postprocessing: a) L1 output normalization and b) the sweep ratio. These are respectively modeled as multiplication with the inverse of the original posterior’s L1 norm q To formalize the concept of approximately tracking the optimization slope of posterior objectives with small enough error, in Deﬁnition 1 we introduce λ-optimizers of objectives as multivariate multivalue functions that approximate the (negative) gradients of objectives with relative error bound λ. Smaller values of this strictness parameter indicate tighter approximation of optimization slopes, whereas smaller values indicate looser tracking. To disambiguate the possible directions of slopes, our analysis considers loss functions of nonnegative values to be minimized. Deﬁnition 1 A continuous function f : R → R function L(r) over graph signal domain R ⊆ R We now analyse the robustness of positive deﬁnite graph ﬁlters with post-processing in terms of how tight optimizers of posterior losses should be for the graph ﬁlter’s propagation mechanism to “absorb” the error. To this end, in Theorem 2 we ﬁnd a maximum tightness parameter suﬃcient to lead to local optimality of posteriors with respect to the loss. The required tightness depends on the graph ﬁlter’s maximum and minimum eigenvalues and the post-processing vector’s maximum and minimum values and requires the graph ﬁlter to be symmetric positive deﬁnite. Theorem 2 Let H(W ) be a positive deﬁnite graph ﬁlter and p a postprocessing vector. If f(r) is a R ⊆ R respectively, updating graph signals per the rule: asymptotically leads to the loss to local optimality if posterior updates are closed in the domain, i.e. r ∈ R ⇒ diag(p)H(W ) [v] =. , where λ, λ> 0 are the smallest positive and largest eigenvalues of H(W ) Proof For non-negative posteriors r = diag(p)H(W)q, and non-zero loss gradients, the Cauchy-Shwartz inequality in the bilinear space hx, yi = x positive deﬁnite graph ﬁlter H(W ) yields: Therefore, the loss asymptotically converges to a locally optimal point. Following a similar approach as to check whether graph ﬁlters are positive deﬁnite in Equation 3, we can also bound the eigenvalue ratio by knowing only the type of ﬁlter but not the graph or priors. In particular, for graph ﬁlters H(W ) where W are symmetric adjacency matrices of undirected graphs: aW ) eigenvalue ratios for λ ∈ [−1, 1] are at most which penalize less the spread of graph signal priors farther away, stricter optimizers are required to keep track of the gradient’s negative slope. When normalization is the only postprocessing employed, all elements of the personalization vector are the same and bounds for suﬃcient optimizer strictness coincide with the aforementioned eigenvalue ratios. In practice, these bounds are often lax compared to the small average node score posteriors nodes. For example, for personalized pagerank with a = 0.85 it suﬃces to select 0.081optimizers to edit priors. Even for wider prior diﬀusion with a = 0.99 it suﬃces to select 0.005-optimizers. Based on the above analysis, we ﬁnally explain why, if the surrogate model of bias estimation matches real-world behavior, the proposed personalization error-based editing mechanism dL(r) = (∇L(r))diag(p)H(W )f(r) = (∇L(r))diag(p)H(W )− ∇L(r) + (f(r) + ∇L(r)) ≤ − minp[v](∇L(r))H(W )∇L(r) + (∇L(r))diag(p)H(W )(f(r) + ∇L(r) Since personalized pagerank can be expressed in closed form as the ﬁlter (1 − a)(I − and heat kernels as e, where a and t are their parameters, their respective arising from L1 normalization in graphs with many (such as thousands or millions of) of Equation 11 can tweak posteriors to locally optimize the set fairness-aware objectives. To do this, in Theorem 3 we translate the required tightness of optimizers to a corresponding tightness of projecting loss gradients to vector spaces of prior editing model parameter gradients. When this requirement is met, there exist prior editing model parameters that lead posteriors to locally optimize the objective. Since the same quantity as in Theorem 2 is used to decide adequate tightness, the analysis of the previous subsection indicates that even coarse surrogate models can be met with success. and multiplying the matrix of parameter gradients D these diﬀerences are further constrained to matter only for nodes with high gradient values. This means that, as long as the objective’s gradient has a clear direction to move towards to and this can be captured by the surrogate prior editing model F (θ), a parameter trajectory path exists to arrive at locally optimal prior edits. For example, if prior editing had the same number of parameters as the number of nodes and its parameter gradients were linearly independent, D would always hold. Whereas as the number of parameters decreases, it becomes more important for F (θ) to be able to induce degrees of freedom in the same directions as its induced loss’s gradients, which our theoretical analysis aims to approximate with the self-consistency criterion that prior edits should induce fairness-aware posteriors. models with few parameters could yield locally optimal priors, since it suﬃces to form only loose approximations of desired properties. On the other hand, due to the mathematical intractability of plugging in true prior editing gradients in the computation of the pseudoinverse, the real-world eﬃcacy of proposed prior editing schemes needs to be experimentally corroborated, as we do in the next section. As a ﬁnal remark, we stress that being able to explicitly retain priors for some parameters, as the new proposed model of Equation 11 (but not the previous model of Equation 10) does, is a necessary condition for our analysis to hold true. Theorem 3 Let us consider graph signal priors q largest and smallest eigenvalues λ tion L(r) in domain R and a diﬀerentiable graph signal editing function F (θ) with parameters θ ∈ R Let us consider the |V| × K table function D where ∇ then there exist parameters θ be locally optimal. Intuitively, in Theorem 3 the matrix E computes the diﬀerence between the unit matrix (θ)(D(θ)D(θ))D(θ) = I ⇔ E = 0 and the theorem’s precondition inequality At this point we stress that this section’s theoretical analysis indicates that prior editing indicates parameter gradient vectors. If for any parameters θ it holds that: Proof Let us consider a diﬀerentiable trajectory for parameters θ(t) for times t ∈ [0, ∞) that starts from θ(0) = θ trajectory, it holds that diag(p)H(W )F (θ(t)) arising from the graph signal function F (θ(t)) at times t, as well the least square problem of minimizing the projection of the loss’s gradient to the row space of The closed form solution to this problem can be found by: Thus, as long as q(t) = F (θ(t)) (Proposition I), the theorem’s precondition for posteriors r(t) = diag(p)H(W )q(t) and ∇L(r(r)) 6= 0 can be written as: Hence, if we set x(t) as parameter derivatives: which means that, on the selected parameter trajectory, of the loss function. As, such, from Theorem 2 it discovers locally optimal posteriors. can see that the update rule leads to the selection of priors q(t) at times t for which: tion path of prior editing parameters (not necessarily the same as the one followed by the optimization algorithm used in practice) that arrives at the edited priors F (θ(t parameters θ(t In this section we describe the experiment settings (graphs and base graph ﬁlters), competing approaches and evaluation methodology used to assess whether prior editing can make graph ﬁlter posteriors fair. Our experiments are conducted on 12 real-world graphs from the domains of social networking, scientiﬁc collaboration and software engineering. The graphs are retrieved from (θ(t)): As a ﬁnal step, we now investigate the priors signal editing converges at. To do this, we We can similarly show that (Proposition I) holds true. Hence, there exists an optimizapublicly available sources, namely the SNAP repository of large networks (Leskovec and Krevl, 2014), the network repository (Rossi and Ahmed, 2015), the LINQS repository (lin), the AMiner repository of citation data sets (Tang et al., 2008) and the software dependency graph data set (Musco, 2016). They are selected on merit of seeing widespread use in their respective domain research and comprising multiple node attributes, which we use as predictive and sensitive information. their attributes. Motivated by the frequent use of graph ﬁlters for recommendation, we consider membership to each community as a diﬀerent binary attribute. When not stated otherwise, and to facilitate experiments with a small portion of seed nodes, we select the ﬁrst community with more than 100 nodes to experiment on. If there are no explicit sensitive node attributes, we designate members of the second community found during the previous search as sensitive. behavior against persons, such as recommending other attributes with disproportionately lower scores. Disparate impact mitigation safeguards against this kind of disparity. This is also useful in other types of graphs, where biases are less impactful from a humanitarian perspective, but can still impact the inclusiveness of recommendation to end-users. For example, in scientiﬁc collaboration graphs, it could be important for older publishing venues to compete fairly with newer ones by not biasing recommendation scores against them, for example due to fewer handled publications. Or it could be important to make searches of scientiﬁc publications respect a lesser-known area of research, such as less known types of diabetes in the PubMed graph below. Finally, in software engineering graphs it is often useful to discover entities (such as libraries, source code artifacts) related to query ones while protecting those of a subsystem from being avoided, for example because it plays a pivotal role in a software project’s architecture and potential risks of impacting it should be well-understood. such as the number of graph nodes, edges, positive labels, sensitive labels and pRule of positive labels given sensitive ones are summarized in Table 2. For most graphs, the pRule of positive labels 0, which indicates that either all positive labels are sensitive or all of them are not sensitive (ﬂipping which nodes are considered sensitive retains data set pRule and experiment results). ACM (Tang et al., 2008) A co-authorship graph whose nodes are authors forming edges based on whether they have co-authored a publication. We consider communities corresponding to diﬀerent publication venues (such as journals or conferences) the authors have published in. To construct this data set, we processed the authorship and publication data of the 2017 version of the ACM citation data set extracted by AMiner. Amazon (Leskovec et al., 2007) A graph comprising frequent Amazon product copurchases, as well as their category. The graph was parsed from frequent co-purchase metadata hosted in the SNAP repository. In all graphs, nodes are organized into potentially overlapping communities based on The sensitive attributes of social networking graphs could give rise to discriminative Below we detail the type of data captured by each graph. Quantiﬁable characteristics, Ant (Musco, 2016) A method call graph for the Apache Ant dependency builder tool, where nodes are source code methods and edges indicate that one of the methods called the other. We retrieve this graph from the feature ﬁle corresponding to the project’s release 1.9.2 in the software dependency graph data set and remove dangling nodes with only one edge. We consider methods of the same class, as identiﬁed through their signatures, to belong to the same community. Hence, predicting communities corresponds to predicting the organization of methods into classes. Citeseer (Getoor, 2005) A citation graph where scientiﬁc publications are nodes and edges correspond to citations between them. Nodes are categorized into communities based. We use the version of the data set provided by the LINQS repository. Since our aim is to experiment on attribute propagation mechanisms, we do not experiment with available publication text tokens that could be used by more complex schemes (such as predict-thenpropagate graph neural networks (Klicpera et al., 2018) that estimate graph signals through multilayer perceptrons before propagating them). DBLP (Tang et al., 2008) A co-authorship graph whose nodes are authors forming edges based on whether they have co-authored a publication. We consider communities corresponding to diﬀerent publication venues the authors have published in. To construct this data set, we processed the authorship and publication data of the 2011 version of the DBLP citation data set extracted by AMiner Facebook0 (Leskovec and Mcauley, 2012) A Facebook graph of user friendships starting from given user and record social relations between them and their friends, including relations between friends. Ten such graphs are available in the source material, out of which we experiment on the ﬁrst one. We use the version of the data set hosted by SNAP and select the anonymized binary ‘gender’ attribute as sensitive and the ﬁrst anonymized binary ‘education’ attribute as the prediction label. Facebook686 (Leskovec and Mcauley, 2012) A graph obtained through the same process as Facebook0 and choosing a diﬀerent graph out of those available in the source material (the ego network of user with identiﬁer 686). Log4J (Musco, 2016) A method call graph for the Java logging project Log4J, where nodes are source code methods and edges indicate that one of the methods called the other. We retrieve this graph from the feature ﬁle corresponding to the project’s release 2.0b9 in the software dependency graph data set and apply the same preprocessing and community extraction steps as we did for Ant. Maven (Benelallam et al., 2019) A dependency graph of Java libraries hosted in Maven central. that one of the edge’s nodes depends on the other. We organize libraries into communities based on their parent projects (for example, the libraries org.seleniumhq.selenium:seleniumserver:3.0.1 and org.seleniumhq.selenium:selenium-support:3.0.1 are both consider part of the org.seleniumhq.selenium project) and remove dangling nodes with only one edge. Pubmed (Namata et al., 2012) A citation data set of PubMed publications pertaining to diabetes research, where nodes correspond to papers and edges to citations between them. Nodes form communities based on the type of diabetes they research. We use the version of the data set provided by the LINQS repository. Squirrel (Musco, 2016) A method call graph for the Squirrel email server written in Java, where nodes are source code methods and edges indicate that one of the methods called the other. We retrieve this graph from the feature ﬁle corresponding to the project’s release 0.34 in the software dependency graph data set and apply the same preprocessing and community extraction steps as we did for Ant and Log4J. Twitter (Rossi and Ahmed, 2015) A Twitter graph of political retweets, where nodes are social media users and edges indicate which users have retweeted posts of others. This data set comprises only one anonymized attribute of binary political opinions (left or right). We consider this attribute as sensitive and its complement as prediction labels. For our experiments we consider the two popular types of graph ﬁlters we outline in Subsection 2.2: personalized pagerank and heat kernels. Commonly used parameters for those ﬁlters that encourage few-hop propagation are a = 0.85 and t = 3. However, previous ﬁndings suggest that propagating graph signal priors more hops away leads to higher posterior AUC for communities with many nodes (Krasanakis et al., 2020b). We thus experiment with propagation parameters a = 0.99 and t = 5 that induce this behavior too. Since the sweep procedure is also a well-known method in improving posterior score quality (for example, it often increases AUC) we also experiment both with and without it. In total, depending on the choice of ﬁlter type, propagation parameter and post-processing, we experiment across 2 · 2 · 2 = 8 base graph ﬁlters, which we outline in Table 3. This way, graph ﬁlters become positive deﬁnite and hence support our theoretical results. Posterior scores are computed to numerical precision of 10 chosen graph ﬁlters provided by the pygrank In all cases, we treat graphs as undirected ones and employ symmetric normalization. In this subsection we outline promising existing and new approaches that improve the fairness of base graph ﬁlters. These span multiple fairness-aware objectives, such as maximizing fairness, meeting fairness constraints and trying to preserve the posterior quality measured by AUC, which we detail in Table 4. Their implementation has been integrated in the pygrank library. None The base graph ﬁlter. Mult A simple post-processing baseline that multiplies posterior scores across the sensitive and non-sensitive groups with a diﬀerent constant each, so that disparate impact is fully mitigated. If r are the base graph ﬁlter’s posteriors and s a graph signal holding the sensitive attribute, this method post-processes posteriors per the rules: where φ = S, 0 otherwise}. It holds that FairWalk A random walk strategy previously used for fair node embeddings. We implement this as an asymmetric preprocessing applied to the graph’s adjacency matrix that retains nodes degree but makes signals spread equally between sensitive and non-sensitive neighbors. This approach aims to predominantly maintain the propagation mechanism and attempts to make posteriors fair only if this is convenient by encountering nodes with both sensitive and non-sensitive neighbors. LFPRO Near-optimal redistribution of ranks causing disparate impact. Contrary to our assumption that aims to inﬂuence posteriors by editing priors, this approach directly oﬀsets the disparate impact of posteriors by moving excess node scores between the sensitive and the non-sensitive nodes to improve the pRule as much as possible while maintaining nonnegative scores. To avoid numerical underﬂows that erroneously prevent this approach from exact convergence in the graphs with many nodes, we repeat the gradual movement of scores up to numerical tolerance 10 FairPers Our previously proposed fair personalization model described by Equation 10. Its tradeoﬀ parameters assume values a large enough range b editing mechanism for large exponents of vanish for small exponents. This variation aims to maximize fairness while partially retaining posterior quality and is hence trained towards optimizing Equation 7 for w algorithm we developed as part of the pygrank library for non-derivative optimization, which is detailed in Appendix A. FairPers-C A variation of FairPers that aims to impose strong fairness constraints with FairEdit The personalization editing mechanism of Equation 11 proposed in this work. Its parameters assume values {θ trains them to maximize fairness while partially retaining posterior quality by optimizing Equation 9 for w optimization algorithm as FairPers. FairEdit-C A variation of FairEdit that aims to impose strong fairness constraints with This subsection details the methodology we follow to assess fairness-aware approaches on combinations of graphs and base graph ﬁlters, as well as the summary statistics used to perform a high level comparison between approaches. To rigorously evaluate fairness-aware approaches, we separate graph nodes into training and test sets, by uniformly sampling the former without repetition to comprise one of the fractions {10%, 20%, 30%} of all graph nodes. Positive labels are on average also split alongside the same fraction to construct graph signal priors (i.e. by assigning 1 to their respective elements). For example, for the Maven data set a 20% train-test split uses only 20% · 185 = 37 of positive labels to construct graph signal priors. For each graph, we experiment with all three split ratios and average evaluation measures between them. To make sure that comparisons between diﬀerent approaches are not aﬀected by sampling variance, we use seeded sampling to select training nodes. = 10 of optimizing the pRule up to value sup= 80%. = 10 of optimizing the pRule up to value sup= 80%. Our experiments are focused on two types of fairness-aware objectives: maximizing the pRule of posterior scores and achieving high pRule values while preserving high posterior score quality. Both consider a recommender system setting, where we start from graph signal priors and graph ﬁlters are used to obtain node score posteriors. These posteriors then provide a granular understanding on how much nodes pertain to an attribute shared by nodes with non-zero priors. To assess how well approaches achieve high posterior quality and fairness we respectively calculate the AUC and pRule of their posteriors over the evaluation subset of nodes. noting that, although only test nodes are used to calculate measures, the sensitive-aware approaches explored in this work require knowledge of sensitive attributes for all nodes, which include the test ones. Nonetheless, evaluation remains robust in the sense that training data are not overﬁtted as long as fairness-aware approaches are not provided with information about which nodes are used for testing. induce perfect fairness when considering all nodes, but this fairness needs to generalize to subsets of graph nodes, such as test ones. Our experiments output one value for each measure per combination of graph, data set, fairness-aware approach and graph ﬁlter, for a total of 12 · 8 · 8 = 768 combinations. To Figure 3: The process of assessing the AUC and pRule of a fairness-aware approach on a An overview of information ﬂow during evaluation is presented in Figure 3. It is worth graph ﬁlter for a given graph and train-test split ratio. Figure 4: Averaging the outcome of Mult AUC and pRule values across experiment settings. help gather insights from these results, we opt to delegate them to Appendix B and instead extract high-level summary statistics that make it easy to compare diﬀerent approaches. depending on the type of post-processing (no post-processing or the sweep ratio). These statistics are: a) the average AUC of approaches and their statistical signiﬁcant diﬀerences, b) the average pRule of approaches and their statistical signiﬁcant diﬀerences and c) the percentage of experiments in which pRule achieves the constraint of 80% or more. As an example, in Figure 4 we demonstrate the process of obtaining the average AUC and pRule values for the Mult approach, where the same procedure is followed for all others too. procedure for multi-approach comparison (Demˇsar, 2006; Garcia and Herrera, 2008; Derrac et al., 2011). In detail, we ﬁrst employ a Friedman test with p-value <0.001 to assert that at least one approach diﬀers from the others with statistical signiﬁcance. Provided that the Friedman test rejects the null hypothesis that all approaches produce similar outcomes, we then use a Nemenyi post-hoc test to compare individual approaches. The latter ranks approaches for each measure (assigning rank 1 to the best approach, 2 to the second best and so on), reports the average rank across data sets and base ranking algorithms and outputs a critical diﬀerence with p-value at most 0.05, where average rank diﬀerences greater than it imply statistical signiﬁcance at that p-value level. Following the evaluation methodology detailed in the previous section, we compare the fairness-aware approaches proposed in this work (FairEdit, FairEdic-C) to the ones of our previous paper (FairPers, FairPers-C), an intuitive baseline (Mult) and two similar methods employed in the literature (FairWalk, LFPRO). This comparison involves running experi- To this end, we extract three summary statistics across all graphs and graph ﬁlters, We assert which approaches diﬀer signiﬁcantly from the rest by following a well-known Table 5: Average AUC, pRule and fraction of experiments achieving 80% pRule for fairnessments for all combinations of graph ﬁlters and data sets and exploring the resulting AUC and pRule values presented in Appendix B. average of evaluation measures across all experiments for both types of post-processing. It also presents the Nemenyi ranks for multiway comparison between approaches. We remind that lower ranks indicate approaches performing better for the particular measure, where rank diﬀerences exceeding a critical diﬀerence indicate statistically signiﬁcant improvements. For our both sets of comparisons, the critical diﬀerence indicating statistical signiﬁcance is calculated as approximately 1.6. For example, base graph ﬁlters (the approach dubbed None) with no post-processing are assigned 3.0 AUC rank, which indicates that they outperform LFPRO in this regard with statistical signiﬁcance, as the latter’s corresponding rank is 5.4 > 3.0 + 1.6. All numbers rounded to their two most important digits. Compared to base graph ﬁlters, the approaches LFPRO, FairPers and FairEdit reduce the average AUC by at least 7% with statistical signiﬁcance, where LFPRO suﬀers from the greatest posterior quality reduction. Posterior quality loss for all three methods arises from their attempt to maximize fairness while only partially preserving posteriors. to the second-best FairPers at the cost of 1% pRule. Although these diﬀerences are not statistically signiﬁcant, they nonetheless identify FairEdit as the preferred method to eliminate disparate impact in real-world applications. Looking at detailed experiment results, FairPers and FairEdit outperform each other in diﬀerent experiments, which suggests that there is added value in better controlling prior retention in future research, which we ﬁnd in Appendix C to contribute the most in this improvement. 9% compared to the two prior editing approaches, which corroborates our assumption that aware approaches (higher are better). Average Nemenyi ranks for measures in parenthesis (smaller are better), where rank diﬀerences greater than 1.6 are statistically signiﬁcant. Diﬀerent results are presented depending on the postprocesseing of the base graph ﬁlter. Table 5 forms a high-level summary of experiment results. In particular, it reports the Among these approaches, FairEdit exhibits at least 3% greater average AUC compared In terms of disparate impact elimination, LFPRO yields signiﬁcantly smaller pRule by respecting the graph’s structure by editing priors can better satisfy posterior objectives than directly editing those through uniformly skewing mechanisms. The Mult, FairPers-C and FairEdit-C approaches in large part preserve posterior score quality, with their AUC seeing a reduction by at most by 5% compared to base graph ﬁlters, while improving their pRule by large margins. This achievement can be attributed to prior editing approaches placing signiﬁcance to pRule improvements only up to the target level, whereas Mult aﬀects posterior node score comparisons only between sensitive nodes and the rest of the graph, which in most graphs at introduces only a small fraction of erroneously high node posterior scores compared to the number of nodes with non-positive labels. ably large portion of experiments, which hints at their robust generalization capabilities. By contrast, Mult yields signiﬁcantly lower pRule on average with statistical signiﬁcance regardless of the and does not meet the fairness criterion in most experiments. In fact, the constrained approaches exhibit similar -and on average higher- pRule than even LFPRO, while at the same time enjoying sigiﬁcantly higher AUC values. We previously mentioned that the sweep ratio is often employed to improve posterior quality for graph ﬁlters. In line with this consensus, the average AUC of approaches when this kind of post-processing is used is at least equal to or greater than the one with no postprocessing. Although this improvement is often marginal (∼1%), in the case of FairEdit-C the sweep ratio improves AUC by 4%. More importantly, this mechanism induces 2% pRule improvement for all personalization editing approaches, which suggests that there is likely merit in employing it in new settings. Intuitively, improvements thanks to the sweep ratio can be attributed to increasing the posteriors of low-scored nodes so that it becomes easier to move a portion of those to sensitive ones without aﬀecting pairwise node score comparisons. Of the fairness-aware approaches, FairWalk performs similarly or worse than base graph ﬁlters. However, result details reveal that, in some experiments, it manages to improve the pRule. Hence, we argue that this method’s failure lies more in sensitive nodes not being randomly mixed in all graphs we experiment on but forming structurally close communities; this prevents the fair random walk formulation from visiting sensitive and non-sensitive neighbors with equal probabilities, as for most nodes only one of those kinds of neighbors is available. LFPRO sometimes outperform our approaches in preserving AUC (such as the near-100% AUC of the Maven data set). Our understanding of these phenomena lies in these two approaches potentially aﬀecting only the sensitive nodes without respecting propagation mechanisms, which lets them ﬁnd success in speciﬁc cases. Another case that warrants at- Overall, prior editing approaches achieve over 80% pRule both on average and a remark- Lastly, we overview some noticeable outliers in experiment outcomes. First, Mult and tention is the inability of our approach to meet 80% pRule for the DBLP graph when base graph ﬁlters involve personalized pagerank. We attribute this ﬁnding to further approximation terms being needed given that graph’s eigenvalue ratio, but further investigation is needed. In this work we explored the concept of editing graph signal priors to locally optimize fairness-aware graph ﬁlter posterior objectives. To this end, we proposed an editing mechanisms with few parameters and showed that, given its parameter gradients’ lose approximation of fairness-aware objective optimization slopes, it reaches local optima without overﬁtting posterior node scores. We then experimented on a large number of real-world graphs with various graph ﬁlters and signal priors, where we used our approach to produce high-quality posterior scores in terms of AUC that are fair (enough). Our ﬁndings suggest that, compared to other fairness-aware methods, prior editing is able to better reduce disparate impact or meet reduction constraints while in large part preserving the predictive quality of posteriors. neural network architectures, where feature extraction and propagation with graph ﬁlters are performed separately. Our theoretical framework on optimizing posteriors is also general enough to warrant application on other types of objectives, such as maximizing smooth relaxations of AUC. Finally, we are interested in further exploring the assumption that prior editing in its current form exhibits enough degrees of freedom and aim to provide a bound on its necessary number of terms in future work. This work was partially funded by the European Commission under contract numbers H2020-860630 NoBIAS and H2020-825585 HELIOS. Promising applications of this work could involve bringing fairness to decoupled graph In this appendix we detail the algorithm we developed as part of the pygrank library to optimize the parameters of graph signal prior editing mechanisms (FairPers, FairEdit and their constrained variations) in a given hypercube without derivating posterior objectives. tion `(θ) by ﬁnding the best permutation around each one. For the prior editing approach of this work, the parameters are θ = {a `(θ) = L(H(W )q ﬁlter; for the graphs with millions of nodes, this requires approximately 1 − 2 sec on the 2.2 Ghz 4-core CPU with hyperthreading used in experiments, after a preprocessing operation obtains a common sparse version of the adjacency matrix (sparse matrices require O(|E|) amortized time in big-o notation to perform one-hop propagations by multiplying graph signals). Though this time is not prohibitively large, to run the large number of experiments in this work we design the optimization algorithm with the goal of performing only a small number of parameter loss function evaluations. Intuitively, it is equivalent to moving the center of the selected rectangle chosen for each parameter based on subsequent selections of other parameters. So, at the time where the parameter’s permutation breadth shrinks to the size of its intended rectangle, potential combinations with permutations of other parameters have been considered too. Kelley, 2006) that, instead of keeping many candidate rectangles to divide, keeps only one, though of larger width than the partition. This practice corresponds to the shrinking radius technique proposed for non-convex block coordinate optimization (Lyu, 2020), although the two are not mathematically equivalent due to the ﬁnite sum of rectangle widths that limits the optimization within the hypercube of searched parameters, rameters i. For each of those parameters, we consider the maximal range ∆θ[i] in which Our algorithm involves cycling through a list of parameters θ and optimizing a loss func- The implemented algorithm is a variation of divided rectangles (DIRECT) (Finkel and In detail, we start from the center of parameter square bounds and cycle through pa- Input: parameter loss `(θ), parameter square bound vectors θ, θ∈ R, Output: near-optimal vector of K parameters θ ← (θ+ θ)/2 ∆θ ← θ− θ err ← [∞] × K i ← 0 while maxerr[i] >  do u←unit vector with 1 at element i, 0 elsewhere Θ ← {θ + u· ∆θ[i] · (p/part − 1) | p = 0, 1, . . . , 2 part} θ ← arg min`(θ) err[i] ← max`(θ) − min`(θ) ∆θ[i] ← ∆θ[i]/T i ← (i + 1) mod K return θ to search for new solutions and partition it uniformly to 2 part + 1 points. These form a set Θ of parameter perturbations, out of which we select the ones minimizing the loss. Finally, we contract the range in which to search parameters by dividing it with the value K and move on to the next parameter. We stop cycling through parameters when the max loss diﬀerence between perturbations are smaller than the given tolerance. This process is outlined in Algorithm 1. is easy to see that the division of the parameter permutation radius by T every K iterations lets the algorithm run in amortized time O For experiments in this work, and to reduce running time as much as possible, we empirically selected the parameters part = 2, T = 2,  = 0.01, which yielded near-identical results to employing the more granular parameters part = 4, T = 1.3,  = 0.001 in a randomly selected subset of 15 experiment settings. If the objective `(θ) is Lipshitz continuous with Lipshitz constant sup k∇`(θ)k < ∞, it Table 7: Experiments for base graph ﬁlters with sweep ratio post-processing. In this appendix we investigate the eﬀect of adding granular retention of original posteriors in Equation 11. To this end, we perform additional experiments on the FairEdit and FairEdit-C approaches, in which we ﬁx the parameter value a tion of original priors—and hence original posteriors. In Table C we present the outcome of the two new variations under the names FairEdit0 and FairEdit0-C respectively. We remind that FairPers0 variants diﬀer from FairEdit in that they use error-based instead of diﬀerence-based skewing of posteriors and KL-divergence from original posteriors as a training objective instead of mean absolute error. And FairPers variants further diﬀer from FairPers0 in that they explicitly introduce a degree of freedom towards maintain original posteriors. all three types of prior editing yield similar average AUC and pRule values and Nemenyi ranks when used to satisfy the 80% pRule constraint. On the other hand FairEdit0 manages to improve AUC by only a small margin (∼1%) compared to FairPers when maximizing fairness. This indicates that concerns over posterior outliers and the interpretability of stochastic surrogate models are valid yet not too prevalent in the graphs we experiment on. At the same time, small improvements do not retract from the added value of accounting for these phenomena, as posterior outliers could arise in diﬀerent graphs and the more intuitive interpretation of prior editing parameters can prove useful in terms of explainability. Finally, FairEdit’s 3-4% AUC improvement compared to FairPers can be in large part be attributed to partially retaining priors, as recommended by Theorem 3. Table 8: Average AUC, pRule and fraction of experiments achieving 80% pRule for prior Table C summarizes a multiway comparison between prior editing approaches. Overall, editing approaches (higher are better). Average Nemenyi ranks for measures in parenthesis (smaller are better), where rank diﬀerences greater than 1.3 are statistically signiﬁcant. Diﬀerent results are presented depending on the postprocesseing of the base graph ﬁlter. Table 9: Experiments of FairEdit with a= 0 for both types of post-processing