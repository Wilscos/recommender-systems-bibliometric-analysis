Changwon Seo, Kyeong-Joong Jeong, Sungsu Lim, Member, IEEE, and Won-Yong Shin, Sen ior Member, IEEE Abstract—In recent years, many recommender systems using network embedding (NE) such as graph neural networks (GNNs) have been extensively studied in the sense of improving recommendation accuracy. However, such attempts have focused mostly on utilizing only the information of positive user–item interactions with high ratings. T hus, there is a challenge on how to make use of low rating scores for representing users’ preferences since low ratings can be still informative in designing NE-based recommender systems. In this study, we present SiReN, a new Sign-aware Recommender system based on GNN models. Speciﬁcally, SiReN has three key components: 1) constructing a signed bipartite graph for more precisely representing users’ preferences, which is split into two edge-disjoint graphs wit h positive and negative edges each, 2) generating two embeddings for the partitioned graphs with p ositive and negative edges via a GNN model and a multi-layer perceptron (MLP), respectively, and then using an attention model to obtain the ﬁnal embeddings, and 3) establishin g a sign-aware Bayesian personalized ranking (BPR) loss function in the process of optimization. Through comprehensive experiments, we emp irically demonstrate that SiReN consistently outperforms state-of-the-art NE-aided recommendation methods. Index Terms—Bayesian personalized ranking (BPR) loss, graph neural network, network embedding, recommender system, signed bip artite graph. COMMENDER systems have been widely advocated as a way of providing suitable recommendation solutions to customers in various ﬁelds such as e-commerce , advertising, and social media sites. One of the most important and popular tec hniques in recommender systems is collaborative ﬁltering (CF), w hich computes similarities between users and items from historical interactions (e .g., clicks and purchases) to su ggest relevant item s to users by assuming tha t users who have behaved similarly with each other exhibit similar preferences for items [1]–[3]. Moreover, following up the gre at success of network embedding (NE), also known as network representation learning, considerable research attention has been paid to NE-based recommender systems that attemp t to model high-order connectivity inform ation from user–item interactions viewed as a bipartite graph [4]–[7].In recent ye a rs, graph neural networks (GNNs) [8]–[12] have emerged as a powerful neural architecture to learn vector representations of nodes and graphs. By virtue of great prowess in solv ing various downstream machine learning problems, GNN-based recommender systems [13]–[19] have also been d eveloped for improving the reco mmendatio n accuracy. GNN models ar e basically traine d by aggregating the information of direct neighbor nodes via message passing under the homophily ( or assortativity) assumption that a target node and its neighbors are similar to eac h other [12]. Due to the neighborhood aggregation mechanism, existing literature posits that high homophily of the underly ing graph is a necessity for GNNs to achieve good perform ance especially on node classiﬁcation [20]–[ 22]. On the other hand, in recommender systems, while users’ feedback on many online websites (e.g., likes/dislikes on YouTube and high/low ratings on Ama zon) can be positive and negative, existing GNNbased recommender systems overlook the existence o f negative feedb a ck (i.e., user–item interactions with low ratings) due to their ease of modeling. Precisely, most GNN-based approa c hes utilize only positive feedback by removing the negative interactions in order to exhibit strong hom ophily in neighbors (see Fig. 1).It is worthwhile to note that, de spite the remarkable performance boost by existing GNN-based recommender systems, the low ratings can be still informative. This is because such information expresses signs of what users dislike. In other words, full exploitation of two types of feedback in GNNs may have the poten tial to further improve the recommen dation performance, which remains a new design challenge. Even with the wide applications of GNNs to recomm ender systems [13]–[19], a question that arises na turally is: “How can we make use of negative feedb a ck (i.e., low rating scores) for representing users’ pre ferences via GNNs?”. In this paper, to a nswer this qu estion, we introduce SiReN, a Sign-aware Recommender system based on GNN models. To this end, we design and optimize o ur new GNN-aided learning model while distinguishing users’ positive and negative feedback. Our proposed SiReN method includ es three key componen ts: 1) signe d graph construction and partitioning, 2) model arch itec ture design, and 3) model optimization. First, Fig. 1: New challenges in GNN-based recommender systems. to overcome the primar y problem of existing GNN-based recommender systems [15], [18], [19] that fail to learn both positive and negative relations between users and items, w e start by constructing a signed bipartite graph, which is split into two edge-disjoint graphs with positive and negative edges each. This signed gra ph construction and partitioning process enables us to more distinctly identify users’ preferences for observed items. Second, we show how to design our model architecture for discovering embeddin gs of all users and items in the signed bipartite gra ph. Although several GNN models were introduced in [23], [24] for signed unipartite graphs, simply applying them to recomme nder systems, corresponding to u ser–item bipartite graphs, may not be desirable. This is because such GNN models were built upon the assumption of balance theory [25], which implies that “the friend of my friend is my friend” and “the enemy of my enemy is my friend”. However, the balance theory no longer holds in recommender systems since users’ pr e ferences canno t be dichotomous. In other words, users are likely to have dissimilar preference s even if they dislike the same item(s). This motivates us to design our own model architecture for each partitioned graph, rather than employing existing GNN approaches based on the balance theory. Concretely, SiReN contains three learning models. For th e graph with positive edges, we employ a GNN model suit for recommender systems. For the graph with negative edges, we adop t a multi-layer perceptro n (MLP) due to the fact that negative edges can weaken the hom ophily and thus message passing to such d issimilar nodes would not be feasible. To obtain the ﬁnal embed dings, we then use an attention model that learns the impor tance of two embedd ings gener ated from GNN and ML P models. Third, as our objective function in the process of optimization, we present a sign-aware Bayesian persona lize d ranking (BPR) loss function, which is built u pon the original BPR loss [26] widely used in r ecommender systems. More speciﬁcally, unlike the original BPR loss, our ob je c tive functio n takes into account two types of observed items, including bo th positive and negative relations between users and items, as well as unobser ved ones. To validate th e superiority of our SiReN method, we comprehensively perform em pirical evaluations using various real-world datasets. Experimental results show that our method consistently outperforms state-of-the-art GNN methods for top-N recommendation in terms of several recommendation accuracy metrics. Such a gain is possible owing to the use of low rating information along with ju dicious model design and optimization. We also empirically validate the effectiveness of MLP in comp arison with other model architectures used f or the graph with negative edges. Additionally, our experimental results demonstrate the robustness of our SiReN method to more challenging interaction sparsity levels. It is worth noting that our method is GNN-model-agnostic and thus any competitive GNN architec tures can be appropriately chosen for poten tially better p e rformance. The main technical contributions of this paper ar e four-fold and summarized as follows: system that makes full use of the user–item inte raction informa tion after signed graph construction and partitioning; models in the sense of utilizing sign awareness so as to generate embeddings of users and items; function; three re al-world datasets while showing the superiority of our method over state-of-the-art NE-aided methods under diverse conditions. The remainder of this paper is organized as follows. In Section II, we present prior studies related to our work. In Section III, we explain the me thodology of our study, including basic settings and an overview of our SiReN method. Section IV describes technical details of the proposed method. Comprehe nsive experimental resu lts are shown in Section V. Finally, w e provide a summary and concluding remarks in Section VI. Table I summar iz e s the notatio n that is used in this paper. This notation will be formally deﬁned in the following sections when we introduce our methodology a nd the technical details. The m ethod that we propo sed in this study is related to two broade r research lines, name ly standard CF approaches and NE-based recommen dation approaches. As one of the most popular techniques, CF in recommender systems aims to capture the relationships between users and items from historical interactions (e.g., ratings and purchases) by discovering learnable vector representations for users and items based on a rating matrix [2], [27]. Matrix factorization (MF) [2 8] decomposes the user–item interaction matrix into a product of two low-dimensional matrices and mo dels their similarities with the dot product of two matrices. ANLF [29] was designed based on a non-negative MF (NMF) model [30] using the altern a ting direction method. In DMF [31] and NCF [32], MF models with neural network architectures were proposed to project users and items into a latent structured space. Moreover, SLIM [3 3] proposed a sparse linear model by directly reconstru cting the low-density user–item interaction matrix. To capture complex relationships be tween items in sparse datasets, FISM [ 34] and NPE [35] showed how to learn item–item similarities as the prod uct of two latent factor matrices. While MF-based models such as [31], [32] rely on the dot product of user and item latent vectors as a similarity measure, CML [1] showed how to learn a joint metric space to encode not only users’ pre ferences but also user–user and item–item similarities in the Euclidean distance. In NAIS [36], the attention mechanism was incorporated to obtain the importance of each item from user–item interactions for preference prediction. DLMF [37] designed a trust-aware recommender system tha t leverages deep learning to determine the initialization in MF by synth esizing th e users’ interests and their trusted friends’ interests in addition to the user–item interactions. Recently, it has been com prehensively studied how to develop recommender systems using NE. While standard CF approa c hes are capable of only modeling the ﬁr st-order connectivity between users and items, NE-based approa c hes aim to exploit high-order p roximity among users and items th rough the user–item bipa rtite gr aph structure [15], [19]. BiNE [6] and CSE [7] were developed based on random walks in order to infer similar users (or items) in the underly ing bipartite graph (i.e., user–item intera c tions). Moreover, encou raged by the success of GNNs in so lving many graph mining tasks [12], GNN-based recommender systems have more recently emerged as promising techniques [13]–[19], [38], [39]. Existing GNN models for top-N reco mmendation were generally developed using implicit feedba ck, which treats observed user–item interactions as positive relations. GC-MC [38] presented a graph autoencoder including graph convolutions f or rating matrix comp letion. PinSage [13] showed a scalable GNN framework developed in production at Pinterest by improving upon Graph SAGE [ 9] along with several aggregation functions. Spectral CF [14] presented a spectral convolution operation to learn the rich information of connectivity between users and items in the spe ctral domain. As state-of-the-art NE-based recommen der systems using only user–item inte ractions as input, NGCF [15], LRGCCF [18], and LightGCN [19] were developed based on GCN [8], the ﬁrst attempt to apply co nvolutions to graph domains, while performing layer aggregation to solve the oversmoothing problem. IGMC [39] proposed an inductive GNNbased matrix completion m odel that learns local subgr aphs in the unde rlying user–item interaction matrix. To explore users’ latent purchasing motivations (e.g., cost effectiveness and appeara nce), MCCF [16] presented a CF approach based on GNNs for generating multiple user/item embeddings and then combining them via attention mechanisms. AGCN [17] proposed a GCN approach for joint item recommendation and attribute inference in an attributed user–item bipartite gr aph with incomplete attribute values. To alleviate the sp arsity of user–item interactions, each user’s local neighbors’ preferences in social networks were also utilized in [40]–[42] for better user embedding modeling, thus enabling us to improve the recommendation accuracy. Despite the aforementioned contributions, leveraging explicit feedback data (i.e., user–item intera ctions with ratings) in NE-based approaches has been largely underexplored in the literature. To le a rn vector representations for users and items based on the NE, it is comm on to utilize only positive user– item interaction s as observed data when explicit feedback data are given (see [7], [40], [42] and references therein). However, negative interactions with low ratings can be still informative since such informa tion shows signs of what users dislike. It remains open how to make use of low ratings in d esigning NE-aided recomme nder systems. On the other hand, several GNN models wer e developed in [23], [24] to learn vector representations of nodes in signed (unipartite) graphs with both positive and n egative edges based on the structural balance theory [25]. However, it is worth noting that the balance theory does not hold in recommen der systems due to the fact that u sers’ preferences cannot be dichotomous, i.e., a behavior of users disliking similar items does not always imply the sam e degree of user preference s about items. Therefor e , adopting such GNN methods designed for signe d graphs would not be de sira ble to c apture different levels of user preferences. In this section, we describe ou r network mod el with basic settings. Next, we explain an overview of the proposed SiReN method as a solution to the problem of making full use of low ratings in GNN models. In reco mmender systems, the basic input is the historical user–item interactions with rating s, which is repr e sented as a weighted bipartite gr aph. Let us denote the underlying bipar tite graph as G = (U, V, E), where U and V are th e set of M users and the set of N items, respectively, and E is the set of weighted e dges between U a nd V. A w e ighted edge (u, v, w) ∈ E can be interpreted as th e ratin g wwith which the user u ∈ U ha s given to the item v ∈ V. We assume G to b e a static network w ithout repeated edges, where ratings (i.e., user prefere nces) do not change over time. In our study, we aim at de signing a new GNN-aided recommender system for improving the a c curacy of top-N recommendation by making full use of the user–item rating informa tion in G, including low ratings that have not be en explored by conventional GNN-based recommender systems [18], [19], without any sid e information. In this subsection, we explain our methodology along with the overview of the proposed SiReN m ethod. We recall that our study is motivate d by the fact that recent recomme nder systems built u pon GNN models such as [18], [19] take advantage of only high rating scores as observed data by deleting some edg e s, corresponding to low ratings (e.g., the rating scores of 1 and 2 in the 1–5 rating scale), in the set E over the weighted bipartite g raph G [7], [40], [42]. This is because such a re moval of low ratings from G enables us to aggregate the positively connected ne ighbors via message passing in GNNs. However, the set of negative interactions indicates what users dislike and thus is still quite informative. In o ther words, it remains open how to fully exploit the rating informa tion in building GNN-based rec ommend er systems as recently developed models fail to capture the effect of low rating scores. To tackle this challenge, we present SiReN, a new signaware rec ommend er system using GNNs, wh ic h is basically composed of the following three core components ( refer to Fig. 2): First, we de scribe how to construct a sign e d bipartite graph Gthat enables us to more distinctly ide ntify users’ preferences based on all the user–item interactions. More speciﬁcally, we construct G= (U, V, E) with a param e te r w> 0, representing a criterion for dividing high and low ratings, where E=(u, v, w)w= w− w, (u, v, w) ∈ E. (1) Here, wcan be determined according to characteristics (e.g., the r a ting scale and the popularity distribution of items) of a given d ataset; from an algorithm design perspective, we assume that a user u likes an item v if w> 0 and he/she dislikes v otherwise, where w= w− wcorrespo nds to the edge weight in the signed bipartite gr a ph G. Note that, although representation learning, including GNNs, on signed graphs has been studied in [23], [24], [43], d e signing GNNbased recommender systems on signed bipartite graphs has never been co nducted in th e literature. Basically, GNN models are trained by aggregating the information of neighbor nodes under the homophily assumption [12]. However, due to the fact th at the signed gra ph Gincludes negative edges (i.e., interactions with low ratings), aggregating the information of such negatively conne cted neighbors may not be desirable. As illustrated in Fig. 2, to more delicately capture each relation of positively a nd negatively connected neighbors, w e then partition the signed bipartite g raph Ginto two edge-disjoint graphs G= (U, V, E) an d G= (U, V, E), consisting of the set of positive edges and negative edges, respectively. Here, it follows that E= E∪ E, where E=(u, v, w)w> 0, (u, v, w) ∈ E(2a) The purpose of this graph partitioning is to make th e graphs Gand G, respectively, assortative and disassortative so that each partitioned gr aph is used as input to the most appropriate learning model. Second, we describe how to generate embe ddings of M users and N item s a long with three learn ing models in our SiReN method. Using the graph Ghaving positive e dges, we adopt a GNN model suit for recommender systems (e.g., [18], [19]) to calculate embedding vectors Z∈ R for the nodes in U ∪ V: where d is the dim ension o f the emb e dding space an d θis the learned mode l p a rameters of GNN. On the other hand, we adopt an M LP for the graph Gto calculate embed ding vectors Z∈ Rfor the same nod e s as those in (3): where θis the learned model parameter s of MLP. We would like to state the following two rem a rks to explain the model selection according to types of graphs. Remark 1. It is worth no ting that existing GNN models, built upon message passing architectures, work on the basic assumption o f homophily [22]. We re call that users wh o dislike similar items may not have similar preferences (i.e., the tendency in rating items) with each other. Negative edges in Gcan undermine the effect of homophily and thus message passing to such dissimilar nodes would not be feasible. For these reasons, adopting GNNs in the graph with negative edges may not be desirable, based on the fact that many GNNs fail to generalize to disassortative graph s, i.e., graphs with low levels of homophily [20], [21], [44]. Remark 2. Additionally, note that the MLP architecture itself does not exploit the topological information. However, it does not imply that the connectivity information in the graph G is not used at all. In the optimization step, we update the embedding vectors in (3) and (4) b y fully taking advantage of the set Ein Gas well as the set Ein G, which will be speciﬁed later. Next, let us mention another training model in SiReN, the so-called attention model. To get the importance of two embedd ings Zand Z, we use the attention mechanism [45] that learns the corresponding importance (α, α) as follows: which results in the ﬁnal embeddings: where α, α∈ R; 1∈ Ris th e all-ones vector; ⊙ denotes the Had a mard ( e le ment-wise) product; θis the learned model parameters of ATTENTIO N ; and each row of Z ∈ Rindicates the embedding vector of each node in U ∪ V. Third, we turn to the optimization of model parameters {θ, θ, θ}, which updates the embedd ings Z accordingly. In our study, we adopt the BPR loss [26], which has been widely used in recommender systems to comprehensively learn what users prefer from the histo rical user–item interactions. Nevertheless, simply apply ing the existing BPR loss to our setting does not precisely capture the relations of negatively connected neighbors; thus, we establish a sign -aware BPR loss, which is a new BPR-based loss that takes into acc ount both positive and negative relations in the signed bipartite graph G, while ac commod ating the sign of edges in Gas an indicator of what users like and dislike. In the next section, we shall describe implementation details of the proposed SiReN method. In this section, we elaborate on ou r SiReN method, designed for top-N recommendation. SiReN has the following three key comp onents: 1) constructing a signed bipartite graph Gfor more precisely representing users’ preferences, which is split into two graphs Gand Gwith positive and negative edges each, 2) generating two embeddings Zand Zfor the partitioned graphs with positive and negative edges via a GNN model and an MLP, respectively, and then using the attention model to learn the importance of Zand Z, and 3) Input: G, w, Θ , {θ, θ, θ}, K (number of negative samples), λ(regularization co efﬁcient) Output: Z establishing a sig n-aware BPR loss function in the process of optimization. T he overall procedure of the proposed SiReN method is summarized in Algorithm 1. As one of main contributions to the design o f our method, we start by constructing the signed bipartite graph Gand then partitioning Ginto two edge-disjoint graphs Gand Gfor exploiting the relation of positively a nd negatively connected neighbors. In the f ollowing subsection s, we explain how we discover embedd ings of all nodes (i.e., users and items) and optimize our model via the sign-aware BPR loss during the training phase. In this subsection , we describe how to gener ate the embeddings of M users and N items in o ur SiReN method. As stated in Section III-B, SiReN basically contains thr e e learning models, i.e., GNN, M LP, and ATTENTION. To gene rally indicate either users or items interchangeably, we de note a node in the graphs Gand G, whic h can b e in either U or V, by x. First, we describe the GNN model, which is designed to be model-agnostic. To this end, we show a general form of the message passing mecha nism [9], [10], [46] in which we iteratively update the representation of each node by aggregating representations of its neighbors using two functions, namely AG GREGATEand UPDATE, along with model parameters of GNNin (3). Formally, at the ℓ-th laye r of a GNN, AGGREGATEaggregates (latent) feature information from the local neighborhood of node x in Gat the (ℓ − 1)-th GNN layer as follows: m← AGGREGATEhy ∈ N∪ {x} Fig. 3: The GNN architecture in our SiReN method, co mposed of three functions in (7)–(9). where h∈ Rdenotes the d-dimensional latent representation vector of node x at the (ℓ−1)-th GNN layer, N is the set of neighbor nodes of x in G, and m∈ Ris the aggregated information for node x at the ℓ-th GNN layer. Since x belongs to a node in either U or V, AGGREGATE aggregates feature infor mation of connected items if x is a user node, and vice versa. In the upd ate step, we use UPDATE to ob tain the ℓ-th embedding vector hfrom the aggregated informa tion mas follows: We note that, for each node x, we randomly initialize the learnable 0- th embeddings ( i.e., h) due to the fact that we have no side info rmation for users and items in our setting as in [18], [19]. Additionally, we present a nother function in o ur GNN model, namely LAYER-AGG, which performs lay er aggregation similarly a s in [47]. This operation is motivated by the argument that oversmoothing tend s to o ccur in GNN-based recommender systems if the last GNN layer’s embedding vectors are u sed as the ﬁnal embedding Z[48]. To alleviate the oversmoothing problem, we calculate the embedding vector z∈ Rof node x via layer aggregation as follows: which results in the embeddings Zfor the gra ph Gwhere Lis the number of GNN layers. The GNN architecture of our SiReN method including the above three functions AGGREGATE, UPDATE, and LAYER-AGGis illustrated in Fig. 3. Remark 3. No w, let us state how the above three functions in (7)–(9) can be spec iﬁed by several types of GNN-based recommender systems. As one state-of-the-art method, LRGCCF [18] can be impleme nted by using where W∈ Ris a learnable weight transforma- tion matrix,is the conca te nation operator, and Lis the number of GNN layers. I n addition, as anothe r state-of-the-art method for recommendation, LightGCN [19] can be speciﬁed according to the following function setting: Second, we pay our attentio n to the MLP architecture designed for the graph Ghaving negative edges. We calculate the embeddings Zusing the MLP as follows: where ℓ = 1, 2, · · · , L; Lis the number of MLP layers; ReLU(x) = max (0, x); W∈ Ris a learnable weight transf ormation matrix; b∈ Ris a bias vector; dis the dimension of the latent representation vector Zat the ℓ-th MLP layer; 1∈ Ris the all-ones vector; and Z∈ Ris the learnable 0-th layer’s embedd ing matrix for all no des in the set U ∪ V, which is randomly initialized. That is,W,b, and Zcorrespo nd to the model parameters of MLPin (4). Third, we turn to describing the attention model. The importance (α, α) in (5) represents the attention values of two embeddings Zand Zfor all nodes in U ∪V. Let us focus on node x ∈ U ∪V whose embedding vectors calcula te d for the graphs Gand Gare given by z, z∈ R, resp e ctively. Let wand wdenote attention values of the two embeddings zand z, respectively, for node x. Then, our attention model learns a weig ht transformation matrix W∈ R, an attention vector q ∈ R, and a bias vector b ∈ R with a dimension d, c orresponding to the model parame ters of ATTENTI ONin (5), as follows: where tanh(x) =is the hyperbolic tangent activation f unction. By normalizing the attention values in (13a) and (13b) according to the softmax function, we have where αand αare the resulting importance of two embeddings zand z, respectively, which thus yields the ﬁnal embedd ing z= αz+ αzfor each node x in (6). In this subsection , we explain the optimization of SiReN method in the training phase via our proposed loss function. We start by randomly initializing the learnable model parameters Θ = {θ, θ, θ} in (3)– (5) (refer to lin e 1 in Algorithm 1). To train our learning mod els (i.e., th e GNN, MLP, and attention models), we use a batch Dconsisting of multiple samples of a triplet (u, i, j), where (u, i, w) ∈ Eand j ∈ V is a negative sample (i.e., an unobserved item ), which is no t in the set of direct neighbors of user u in the signed bipartite graph G(refer to line 6).More speciﬁcally, we ﬁrst acquire the set of edges, E, in Gand then sample K negative samples {j}for each (u, i, w) ∈ Ein order to crea te new samples of a node triplet (u, i, j) for a ll n ∈ {1, · · · , K}, which yields the batch Das follows: D=(u, i, j)(u, i, w) ∈ E, j/∈ N, n ∈ {1, · · · , K}, where Nis the set of neighbor nodes of user u in G. We further subsample mini- batches D⊂ Dto efﬁciently train our learning models (refer to line 7). The sampled triplets are fed into the loss function in the training loop along with the calculated embeddings Z for all node s in U ∪ V (refer to lines 9–12). Now, we present ou r sign-aware BPR loss function, which is built upon the original BPR loss [26] widely used in recommender systems (see [14], [15], [17]–[19], [40], [42] and referenc e s therein). To this end, we deﬁne a user u’s predicted preference for an item i as the inner product of user a nd item ﬁnal embeddings: which is used for establishing our loss function. However, simply employing the original BPR loss is not desirable in our setting since it is a pairwise loss b ased on the relative order between observed and unobserved items by basically assuming that high ratings are more reﬂec tive of a user’s preferences with higher pre diction values of ˆrthan the case of unobserved ones. On the other hand, our objective function should account for two ty pes of observed items, which include both positive and negative relatio ns between users and items, as well as unobserved ones. The pr oposed sign-aware BPR loss function is desig ned in such a way that the predicted preferenc e for an observed item (or its negative value when the observed item is negatively connected) is higher than its unobserved counterpar ts. More formally, we deﬁne a ternary relation >(i, j, w) , {(i, j, w)|ˆr> ˆrif w > 0 and − ˆr> ˆrotherwise} ⊂ V × V × (R \ {0}). Based on the relation >, we aim at minimizing the following loss function L for a given minibatch Dwith the Lregularization: where λis a hyperparame te r that controls the Lregularization strength; Θ represents the model parameters; and L is the sign-aware BPR loss term realized by Here, to capture the above relation >(i, j, w) for each (u, i, j) ∈ D, we mod el the likelihood in (18) as p(>(i, j, w)Θ) , σsgn(w)ˆr− ˆr where sgn(·) is the sign f unction and σ(x) =is the sigmoid function. By training our models through the loss in (17), it is possible to mo re elaborately learn representations of nodes depending on both positive and negative relations. In this section, we ﬁrst describe r e al-world datasets used in the evaluation. We also present ﬁve competing methods including two baseline MF methods and three state-of-theart GNN-based methods for comparison. After describing performance metrics and our experimental settings, we comprehen sively eva luate the performance of our SiReN method and ﬁve benchmark methods. The so urce code for SiReN can be accessed via https://github.com/woni-seo/SiReN-reco. We conduct experiments on three real-world datasets, which are widely a dopted for evaluating recommender systems. For all experiments, we use user–item inte ractions with ratings in each dataset as the input. The main statistics of each dataset, including the number of users, the number of items, the num ber of ratings, th e density, and the rating scale, are summarized in Table II. In the following, we explain impor ta nt characteristics of the datasets br ie ﬂy. MovieLens-1M (ML-1M). This is the most popular dataset in m ovie recommender systems, which consists of 5star ratin gs (i.e., integer values from 1 to 5) of movies given by users [51]. Amazon-Book. Among th e Amazon-Review dataset containing product reviews and metadata, we select the AmazonBook dataset, which consists of 5-star ratings [52]. We r emove users/items tha t have less than 20 interactions similarly as in [53]. TABLE II: Statistics of th ree re a l-world datasets. Yelp. This dataset is a local business review data consisting of 5-star ratings. As in the Amazon-Book dataset, we remove users/items that have less than 20 interactions. In this subsection, we present two b aseline MF methods and three state-of-the -art GNN methods for compariso n. BPRMF [26]. T his baseline method is a MF model optimized by the BPR loss, which assumes th at each user prefers the items with which he/she has interacted to items with no interaction. NeuMF [32]. As another popular baseline, NeuMF is a neural CF model, which generalizes standard MF and uses multiple hidden layers to ge nerate user and item embeddings. NGCF [15]. This state-of-the-art GNN-based approach follows basic oper ations inherited from the standard GCN [8] to explore the high-order connectivity information. More speciﬁcally, NGCF stacks embedding layers and concatenates embedd ings obtained in all laye rs to constitute the ﬁnal embedd ings. LR-GCCF [18]. LR-GCCF is a state-of-the-art GCN-based CF model. As two main characteristics, this mo del uses only linea r transformation without nonlinear activation and concatenate s all layers’ embed dings to alleviate oversmoothing at deeper layers [48]. LightGCN [19]. LightGCN simpliﬁes the design of GCN [8] to make the model more appropriate for recomme ndation by including only the most essential componen t suc h as neighborhood aggregation without nonlinear activation and weight transformation operations. Similarly as in LR-GCCF, this approach uses the weighted sum of embeddings learned at all layers as the ﬁnal em bedding. To validate the performa nce of the pro posed SiReN method and the ﬁve benchmark methods, we adopt three metrics, which are widely used to evaluate the a c curacy o f top-N recommendation. Let T eand R(N) denote the ground truth set (i.e., the set of items rated b y user u in the test set) a nd the top-N recommendatio n list for user u, respectively. In the following, we describe each of metrics for recommenda tion accuracy. The precision P @N is deﬁned as the ratio of releva nt item s to th e set of re commended items and is expressed as Fig. 4: Performance comparison according to different GNN models for eac h dataset in o ur SiReN method. The recall R@N is deﬁned as the ratio of relevant items to the ground truth set and is expressed as The normalized discou nted cumulative gain nDCG@N [ 54] measures a ranking quality of the recommendation list b y assigning higher scores to relevant items at top-N ranking positions in the list: Let ybe the binary relevance of the k-th item iin R(N) for each user u: y= 1 if i∈ T eand 0 otherwise. Then, nDCG@N c an be computed as where DCG@N is and IDCG@N indicates the ideal case of DCG@N (i.e., all relevant items are at the top rank in R(N)). Note that all metrics are in a range of [0, 1], and higher values representRQ1. H ow do underlying GNN models affect the performan c e better performance. D. Experimental SetupRQ3. H ow much does the SiReN meth od improve the top- In this subsection, we describe the expe rimental settings of neural networks in our SiReN meth od. We imple ment SiReN via PyTorch Geometric [55], which is a geometricRQ4. H ow r obust is our SiReN method with respe c t to interdeep lear ning extension library in PyTorch. In our experiments, we adopt GNN models for the graph Gwith positive edges and the 2-layer MLP architecture for the graph Gwith negative edges. We use the Xavier initializer [56] to initialize the model parameters Θ = {θ, θ, θ}. We use dropout regularization [57] with the probability of 0.5 for the MLP and attention models in (4) and (5). We set the dimension of the embedding sp ace and all hidden latent spaces to 64; the number of negative samples, K, to 40; and the strength of L regularization, λ, to 0.1 for the ML-1M dataset and 0.05 for the A mazon-Book and Yelp datasets. We train our model using the A dam optimizer [58] with a learning rate of 0.005. For each dataset, we co nduct 5-fold cross-validation by splitting it into two subsets: 80% of the ratings (i.e., user–item interactions) as the training set and 2 0% of the ratings as the test set. In the train ing set, when we implemen t ﬁve benchmark methods, we regard only the items with the rating scores of 4 and 5 as observed interactions by removing the ratings wh ose scores are lower than 4 as in [7], [40], [ 42]; however, when we implement our SiReN method, we utilize all user–item interactions in cluding low ratings in the training set while the parameter w, indicating the design criterion for signed bipartite graph construction, is set to 3.5.It is worthwhile to note that, for fair comparison, the test set consists of only the ratings of 4 and 5 as the ground truth set for all the methods including SiReN. In this subsection, our empirical study is designed to answer the following four key research questions. of the SiReN method? with n egative edges? N recommendation over baseline and state-of-the-art methods? action sparsity levels? To answer these research questions, we comprehensively carry out experiments in the f ollowing. Fig. 5: Performance comparison according to several mode l architectures used for the graph G method. a) Compa rative Study Among GNN Models Used for G (RQ1): In Fig. 4, f or all datasets, we evaluate the accuracy of top-N recommendation in te rms of P @N , R@N, and nDCG@N when N is set to 10 w hile using various GNN models used for the graph Gin our SiReN method. Since our m e thod is GNN-mo del-agnostic, any existing GN N mod e ls can be adopted; however, in o ur experiments, we adopt three state-of-the-art GNN models that exhibit superior performance in re c ommend er sy stems from the literature, na mely NGCF [15] (SiReN-NGCF), LR-GCCF [18] (SiReN-LRGCCF), and LightGCN [19] (SiReN-LightGCN). Fr om Fig. 4, we observe that SiReN-LightGCN consistently outperforms other models for all per formance m etrics. As discussed in [19], this is because nonlin ear activation and w eight transforma tion operations in GN N s rather tend to degrade the recommendation accuracy; LightGCN thus attempted to simplify the design of GCN by removing such operations. It turns out that such a gain achieved by LightGCN is also possible in our SiReN mod el that contains three learning models including the GNN, MLP, and attention models. From the se ﬁndings, we use SiReN-LightGCN in ou r subsequen t experiments u nless otherwise stated. b) Compa rative Study Among Model Architectures Used for G(RQ2): We perform another co mparative study among model architectures u sed for the graph Gwith negative edges. We adopte d the MLP for Gsince n egative edges in Gcan undermine the assortativity and thus message passing to such dissimilar no des would not be feasible. In this experiment, we empirically validate this claim by taking into account two other design scenarios. We evaluate the accuracy of top-N recommendation when N is set to 10 for all datasets. First, we recall the original SiReN method employing MLP for G, dubbe d SiReN. Second, instead of employing MLP, we introduce SiReNthat uses an additional GNN model for the graph Gto calculate the embedding vectors Z: where θis the learned model parameters of GNN for the graph G. In this exp eriment, we adopt LightGCN [1 9] among GNN models. Third, as an ablation study, we introduce SiReNthat does not calculate the embedding vectors Z. In other words, we only use the embe dding vectors Zin (3) as the ﬁnal embedd ings Z in (6) (i.e., Z = Z). Note that SiReN is identical to the model architecture of LightGCN [19], which g enerates embedding vectors by aggregating only the informa tion of positively connected neighbors. However, unlike LightGCN, SiReNutilizes the sign-aware BPR loss in (17)–(19) as our objective fu nction in the process of optimization. From Fig. 5, our ﬁndings are as follows: gardless of performance metrics, which indeed validates our claim addressed in Remark 1. plies that, although the model in SiReNis trained via our sign-aware BPR loss, both positive and n egative relations in the signed bipartite graph Gare not precisely captured during training unless an appropriate model architecture is designed for the gra ph G. From these ﬁndings, we use SiReNin o ur subsequent experiments unless otherwise stated. c) Comparison With Benchmark Methods (RQ3): The performance compar ison between our SiReN method an d three state-of-the-art GNN methods, including NGCF [15], LR-GCCF [18], and LightGCN [19], as well as two baseline MF methods, includin g BPRMF [26] and NeuMF [32], for top-N recommenda tion is comprehensively presented in Table III with respect to three performance metrics using three realworld datasets, where N ∈ {10, 15, 20}. We note that the hyperparameters in all the aforementioned benchmark methods are tuned differently according to each da ta set so as to pr ovide the best performan c e. In Table III, th e value with an underline indicates the best performer for each case. We would like to make the following insig htful observations: TABLE III: Performance comparison a mong SiReN and ﬁve benchmark methods in terms of three performance metrics (average ± standard deviation) when N ∈ {10, 15, 20}. Here, the best method for each case is highlighted using u nderlines. TABLE IV: Performan ce comparison among SiReN and ﬁve benchmark methods in terms of three p erformance me trics (average ± standard deviation) for the ML-1M dataset accordin g to three different user groups. For each u ser group, the number in the parentheses indicates the average number of users in the belonging group. Here, the best method for each case is highlighted using underlines. mark me thods for all datasets regardless of the performance metrics a nd the values of N. The superiority of our method comes from the fact that we ar e ca pable of more precisely representing users’ preferences without any information loss. This im plies that low ratings are indeed informative as long as the low rating information is well exploited through judicious model design a nd optimization. The performance gap betwee n our SiReN me thod (X) and the second best performer (Y ) is the largest when the Amazo n-Book dataset is used; the maximum improvement rates of 12.19%, 13.28%, and 13.48% are ach ieved in terms of P @10, R@10, and nDCG@10, respectively, where the improvement rate (%) is given by×100. We recall that the Amazon-Book dataset has the lowest density (i.e., the highest sparsity ) out of three datasets (refer to Table II). Thus, from the above empirical ﬁnding, it is seen that exploiting negative user–item interactions in sparser datasets would be more beneﬁcial and effective in improving the recommend a tion accuracy. that of three state-of-the- art GNN methods. This indicates that exploring the high -order connectivity inf ormation via GNNs indeed sig niﬁcantly improves the recommendation TABLE V: Perf ormance comparison among SiReN and ﬁve benchmark methods in terms of three performance metrics (average ± standard deviation) for the Amazon-Book da ta set accordin g to three different user groups. For each user gr oup, the number in the parentheses indicates the average number of users in the belonging group. Here, the best method for each case is highlighted using underline s. TABLE VI: Performan ce comparison among SiReN and ﬁve benchmark methods in terms of three p erformance me trics (average ± standard deviation) for the Yelp dataset according to three different user groups. For each user group, the number in the parentheses indicates the average number of users in the belonging group. Here, the best method for each case is highlighted using underline s. accuracy. consistently observed. We note that, in contrast to LRGCCF a nd NGCF, LightGCN aggr egates the information of neighbors without both nonlinear activation and weight transformation operations. Our experime ntal r esults coincide with the argument in [19] that a simple aggregator of the information of neighbo rs using a weighted sum is the most effective as long as GNN-based recommender systems are associated. d) Robustness to Interaction Sparsity Levels (R Q 4): Needless to say, the sparsity issue is one of crucial challenges on designing rec ommend er sy stems since few user–item interactions are insu fﬁcient to gene rate high-quality embe ddings [15], [35]. In this experiment, we demonstrate th a t making use of low rating scores for better representing users’ preferences enables us to a lleviate this sparsity issue. To this end, we partition the set of users in the test set into three group s accordin g to the number of interactions in the trainin g set as in [15], [3 5]. More precisely, for each dataset, w e split the users into three groups, each of which is composed of the u sers whose number of interactions in the tr aining set ranges between [0, 20), [20, 50), and [50, ∞), respectively. In Tables IV–VI, we comprehensively car ry out the performance compariso n between our SiReN method and ﬁve benc hmark methods with resp ect to three perf ormance metrics of top-N recommendation using the ML-1M, Amazon-Book, and Yelp datasets, respectively, wher e experimental re sults are shown accordin g to three inter a ction sparsity levels for ea ch d ataset. Our ﬁndings can be summarized as follows: benchm ark methods except for only one case of u ser groups in the ML-1M data set. This comes from the fact that th e ML-1M dataset is relatively less sparse; thus, in this case, exploiting the set of negative interactions in designing GNN-based recommender systems may not be often u seful in improving the recommendation accura cy. the secon d best performe r is the largest for the user group having [0, 20) interactions in the Amazon- Book da ta set (refer to Table V); the maximum improvement rates of 17.83%, 1 5.73%, and 18.33% ar e achieved in terms of P @10, R@ 10, and nDCG@10, respectively. As stated above, the performance im provement of SiReN over competing methods is signiﬁcant when sparse datasets are used. performance is likely to be enhanced for all the methods regardless of types of d a ta sets. It is obvious that more user–item interactions yield higher recommendation accuracy. In this paper, we explored a funda mentally important p roblem of how to take advantage of both high and low ra ting scores in developing GNN-based recommender systems. To tackle this challenge, we introduced a n ovel method, termed SiReN, that is designed based on sign-aware learning and optimization models along with a GNN architecture. Speciﬁcally, we presented an approach to 1) constructing a signed bipartite graph Gto distingu ish user s’ positive and negative feedback and then partitioning Ginto two edge-disjoint graphs G and Gwith positive and negative edges each, respectively, 2) generating two embeddings for Gand Gvia a GNN model and an ML P, respectively, and then using an attention model to discover the ﬁnal embeddings, and 3) training our learning models by establishing a sign-aware BPR loss function that captures each relation of positively and negatively connected neighbors. Using three real-world datasets, we demonstrated that our SiReN me thod r emarkably outperforms three stateof-the- a rt GNN methods as well as two baseline MF method s while showing ga ins over the second best performer (i.e ., LightGCN) by up to 1 3.48% in terms of the recommendation accuracy. We also demonstrated tha t o ur proposed method is robust to more challenging situations acco rding to interaction sparsity levels by investigating that the perform ance improvement of SiReN over state-of-the-art methods is signiﬁcant when sparse datasets are used. Additionally, we em pirically showed the effectivene ss of MLP used for the graph Gwith negative edges. Potential avenues of future research include the design of a more sophisticated GNN model that ﬁts well into Gin signed bipartite graphs. Here, the cha llenges lie in developing a new informa tion aggregation and propagation mechanism. This research was supported by the National Research Foundation of Korea (NRF) gr a nt funded by the Korea government (MSIT) (No. 2021R1A2C30043 45), by the Institute of Information & Communications Technology Planning & Evaluation (IIT P) grant funded by the Korea G overnment (MSIT) (N o. 2020-0-0 1441, Artiﬁcal Intelligence Convergence Research Center (Chungnam National University)), and by the Yonsei Un iversity, Republic of Korea Research Fund o f 2021 (2021-22-0 083). The authors would like to thank Dr. Hajoon Ko from Harvard University for his helpful com ments.