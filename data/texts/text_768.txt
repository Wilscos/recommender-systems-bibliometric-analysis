In this paper we are primarily interested in the problem: where is the probability simplex and f is convex and twice continuously diﬀerentiable (henceforth: smooth). We also consider several other related geometric constraints and the more general case where f is nonconvex (See Section 7). Optimization over ∆ processing, control and game theory. Typical applications include, but are not limited to, estimation of mixture proportions (Keshava, 2003), probability density estimation (Bunea et al., 2010), convex aggregation learning (Nemirovski, 2000), training of support vector machines (Clarkson, 2010), portfolio optimization (Bomze, 2002), population dynamics (Zeeman, 1980), graph theory (De Klerk, 2008), Bayesian neural architecture (Limmer and Sta´nczak, 2018), and archetypal analysis (Bauckhage et al., 2015). A natural approach to this problem is Projected Gradient Descent (PGD): where η We show how to convert the problem of minimizing a convex function over the standard probability simplex to that of minimizing a nonconvex function over the unit sphere. We prove the landscape of this nonconvex problem is b enign, i.e. every stationary point is either a strict saddle or a global minimizer. We exploit the Riemannian manifold structure of the sphere to propose several new algorithms for this problem. When used in conjunction with line search, our methods achieve a linear rate of convergence for non-degenerate interior points, both in theory and in practice. Extensive numerical experiments compare the performance of our proposed methods to existing methods, highlighting the strengths and weaknesses. We conclude with recommendations for practitioners. is an appropriately chosen step size and P(y) is the projection onto ∆, Standard theory (e.g. (Bertsekas, 1997, Chpt. 3)) shows that when f is convex (resp. strong convex) PGD ﬁnds an iterate satisfying f (x iterations. In many cases (e.g. simplex-constrained least-squares, see Section 8) computing P tial part of the per-iteration computational cost. Theoretically, P complexity O(n). However, this involves either (i) using a linear time median selection algorithm Blum et al. (1973) known to be slow in practice; or (ii) using the recently proposed algorithm of Perez et al. (2020), which requires a priori knowledge (i.e. a bound on the size of the entries of x) as well as some non-standard ﬂoating point operations. Hence, randomized algorithms (Duchi et al., 2008; Condat, 2016) with worst case complexity O(n summarize, the total computational complexity of ﬁnding an ε-optimal solution to (C and O(n used in practice yield a worst-case complexity of O(n We note there are are many algorithms for (C computational complexities. In this work we propose a new approach to (C weaker than strong convexity, our approach has worst-case complexity O(n log(1/ε)) and is fast in practice. Our approach also avoids the sorting or median selection sub-routines required by many algorithms for P As these are tricky to parallelize, our approach may prove to be more GPU-friendly. Hadamard parametrization Our proposed approach is conceptually simple. We use the Hadamard parametrization: x = z  z, where  represents the elementwise product (u  v) As a consequence, the probability simplex constraint x ∈ ∆ sphere constraint z ∈ S the unit sphere. (See Fig. 1). Figure 1: x ∈ ∆ Importantly S et al., 2009) may be applied to (NC (Riemannian) gradient based methods applied to (NC build on recent research on nonconvex optimization to show: Theorem (Theorem 1, informally stated). Every stationary point of g(z) is either a strict saddle or a global minimizer. /ε) (O(n log(1/ε)) and O(nlog(1/ε)) if f is strongly convex) but most implementations of P It is easily checked that if z f(x). Thus, any method applied to Problem (NC provably solves Problem (C Descent (PRGD) (Criscitiello and Boumal, 2019) and two variations of RGD with line search. Deﬁning U := {u ∈ R Theorem (Theorems 4 and 6, informally stated). Suppose x positive deﬁnite (henceforth: PD) when restricted to U. Then: 2. RGD with a backtracking, Armijo-Wolfe linesearch ﬁnds an ε-optimal solution in O(log(1/ε)) iterations Our experimental results show that, when the step-size is well tuned, PRGD is signiﬁcantly faster than PGD. Finally, we show experimentally that RGD with a non-monotone line search incorporating the BarzilaiBorwein step-size rule is the overall fastest algorithm for Problem (C and other algorithms by an order of magnitude in some cases. Notation We use x to denote a variable constrained to ∆ space. Our original objective function will always be f and by g we always mean the Hadamard parametrized version of f: g(z) = f(z  z). The notations ∇ and grad will be reserved for (Euclidean) gradient operator and Riemannian gradient operator, respectively. We will use ∇ and Riemannian Hessian operator, respectively. Finally, by int(∆ Hadamard Calculus For the reader’s convenience, we recall a few properties of the Hadamard product. We defer all proofs to the appendix. (H1) 1 (H2) If d  z  z = 0 then d  z = 0 (H5) ∇g(z) = 2∇f(x)  z and ∇ Hadamard parametrization There has been a ﬂurry of recent papers examining the Hadamard parametrization. In particular, we highlight the papers (Vaskevicius et al., 2019; Zhao et al., 2019) which study the constrained convex problem: frequently used to ﬁnd the sparsest solution to an underdetermined system Ax = b. Informally, their approach is to set x = z  z and then apply carefully initialized gradient descent to the unconstrained nonconvex problem: Using results on the implicit bias of gradient descent (Ali et al., 2019; Bauer et al., 2007; B¨uhlmann and Yu, 2003), they argue gradient descent applied to (5) will ﬁnd a z kzk= kz  zk line of research can be summarized as using the Hadamard parametrization to exploit implicit regularization. :Pu= 0} we show and O(n log(1/ε) total operations. Although inspired by these works, our approach is distinct from this line of research. Instead of using the Hadamard parametrization to take advantage of implicit regularization, we use it to convert a non-smooth constraint set into a smooth one. Simplex Minimization Alternative approaches to solving (C et al., 1956; Jaggi, 2013), also known as the conditional gradient algorithm, and mirror descent (Ben-Tal et al., 2001; Beck and Teboulle, 2003), known in this context as the entropic mirror descent algorithm or the exponentiated gradient algorithm. When f is strongly convex certain variants of Frank-Wolfe achieve a linear convergence rate (Lacoste-Julien and Jaggi, 2015; Pedregosa et al., 2020) although for merely convex f the convergence rate is sublinear. Interior point methods (e.g. (Koh et al., 2007)) enjoy a fast convergence rate but, as the cost of each iteration is typically quadratic in n, are intractible for high-dimensional problems. We recall a few notions required for discussing optimization on Riemannian manifolds, specialized to the case of the sphere, S Proj f : S grad Hess f(z) = Proj Given z ∈ S direction of v, which is a curve on S in Euclidean geometry. On S exponential map at z ∈ S (RGD) mimics regular (i.e. Euclidean) gradient descent, except instead of using ∇f (x and instead of stepping along the straight line in the direction −∇f (x direction −grad f (x By construction x describes how to apply RGD to (C is actually minimizing, g, will in general be nonconvex (even if f is convex). However g does inherit the smoothness of f : Lemma 3.1. Suppose f is L-Lipschitz diﬀerentiable. Then g is where M = max As ∇f(x) is continuous and ∆ Recall in this paper, we transform the simplex constrained convex optimization problem (C constrained nonconvex optimization problem (NC can be used to characterize the (global) optimality conditions of (C one correspondence between the global minimizers of (C parameterized nonconvex optimization problem (NC denote the projection onto TS. One can verify that Proj(w) = w − (wz)z. For any smooth → R the Riemannian gradient at z ∈ Sis the projection of the regular gradient onto TS: f = Proj∇f(z). Similarly, we may deﬁne the Riemannian Hessian at z ∈ Sas the operator Second-order KKT conditions of (NC are given by the second-order KKT conditions: there exists λ (10b) and for all d⊥z where ∇ conditions is a second-order KKT/stationary point. Remark 1. Note that z and d Boumal, 2020). This justiﬁes using these terms interchangeably. Strict saddle points of (NC conditions, i.e. there exists d⊥z ) is convex, the global optimality conditions are given by the (ﬁrst-order) KKT conditions: there ∈ R and β∈ Rsuch that satisfying the ﬁrst-order optimality conditions is called a KKT/stationary point. (·) denotes the partial Hessian with respect to z. A point zsatisfying the second-order optimality Hess f(z)d ≥ 0 for all d ∈ TS, if and only if zis a second order KKT point (Luenberger, 1972; We call such a stationary point z strict saddle or a second-order stationary point. Remarkably, many existing iterative algorithms are able to avoid strict saddle points and converge to second-order stationary points, e.g. Trust-region method (Sun et al., 2015), cubic-regularization method (Zhang and Zhang, 2018; Nesterov and Polyak, 2006), Riemannian gradient descent (Criscitiello and Boumal, 2019), and projected gradient descent (Ge et al., 2015). We now provide our main landscape analysis results. Theorem 1. Suppose f is convex and z stationary point of (NC Proof. Deﬁne the Hadamard decomposition set as Z of (C only if z ). Then Theorem 1 is equivalent to saying that zis a second order stationary point of (NC) if and ﬁrst show zsatisﬁes the ﬁrst-order optimality conditions (10a) and (10b). Multiplying both sides of the optimality condition (8a) by z: By complementary slackness (8d): zzβ= 0, hence zβ= 0 by (H2). Thus (14) reduces to (10a) by choosing λ= λ. Note (8e) is equivalent to (10b) as It remains to show the second-order optimality conditions (11) of (NC) with λ= λ. Since x satisﬁes (8a) and (8c), we have Plugging this into (11), we get for any d ∈ R which follows from the convexity assumption of f. show its contrapositive: If z/∈ Z, then zis a strict saddle point of (NC). Because zis a stationary point of (NC), it satisﬁes (10b): Non-degenerate stationary points It will also be useful to consider the following reﬁned version of a second-order stationary point. Deﬁnition 1 (Deﬁnition 3.1 (Yang, 2007)). z order optimality conditions (10a) and (10b) are satisﬁed, and the second-order optimality condition (11) holds with strict inequality. Roughly speaking, a nondegenerate stationary point is an isolated local minimizer. We now characterize nondegenerate stationary points of g(z) := f(z  z). Theorem 2. Suppose x to U := {u ∈ R nondegenerate stationary points of (NC As we are using RGD to minimize a nonconvex function, care must be taken when analyzing its convergence. First recall: That is, zzsatisﬁes the optimality conditions (8b) and (8e) of (C). Since zsatisﬁes (10a), there exists λ∈ R such that On the other hand, (8a),(8c) and (8d) are equivalent to that there exists some λsuch that For the sake of contradiction, further suppose then z zsatisﬁes the optimality conditions (8a),(8c) and (8d) by choosing λ= λand β= [∇f(z z)]− λ≥ 0. Consequently, z zsatisﬁes the entire KKT conditions (8a)–(8e), and so z∈ Z, which is a contradiction to the assumption z/∈ Z. Therefore, By constructing d = e, where {e} denotes the canonical basis in R, we have hd, zi = 0 and dz= 0. By direct computation and (11) we obtain Therefore, zis a strict saddle point of (NC). Deﬁnition 2 ((Criscitiello and Boumal, 2019)). A point z ∈ S twice-diﬀerentiable function g : S where λ constant of the Hessian of the pullback of g from the manifold to tangent space. There is no guarantee RGD applied to a nonconvex function will converge to a second order stationary point (it may ﬁnd a saddle point). Fortunately, (Criscitiello and Boumal, 2019) shows a Perturbed version of RGD (PRGD, c.f. Algorithm 1 in (Criscitiello and Boumal, 2019)) will, with high probability (w.h.p), ﬁnd an -second-order stationary point. We reproduce their result, adapted to the sphere, here. Theorem 3. PRGD applied to g : S O(log n) We call the combination of the Hadamard parametrization and PRGD HadPRGD (see Algorithm 2). As a consequence of our landscape analysis (Theorems 1 and 2): Theorem 4. Suppose x every global minimizer of (C iterations, for ε small enough. Each iteration of HadPRGD (excluding the perturbed steps, which are hardly ever triggered) requires O(n) operations, hence the total ﬂop count of HadPRGD is O improvement on the complexity of PGD for (C larger step-sizes, leading to faster convergence in practice. To substantiate this we consider the simplexconstrained least squares problem where A ∈ R function of n, the number of iterations and wall-clock time required by HadPRGD and PGD to reach to ﬁnd an ε-optimal solution with ε = 10 to be as large as possible while still converging. Clearly, HadRGD is eﬀective when using an appropriately large step-size, but it is unclear from theoretical grounds how large this step-size can be. Thus, we implement HadRGD in conjunction with a line search algorithm. We consider two approaches. ∈ ∆: initial point, α: step size, K: number of iterations, f: original objective func- =√x{(Deﬁned componentwise)} = exp(−α grad g(z)) (H) denotes the smallest eigenvalue of the symmetric operator H and ρ denotes the Lipschitz /iterations. Figure 2: Left: Number of iterations vs. n. Right: Wall-clock time vs. n. When the step-size is properly tuned, PRGD requires fewer iterations than PGD on the simplex. Moreover, the per-iteration cost of PRGD is lower, leading to a lower overall run-time. Armijo-Wolfe Suppose v ∈ T Armijo-Wolfe conditions along the geodesic traced out by exp where g cient descent while (19b) guarantees approximate stationarity (recalling hgrad g(z), vi < 0). We implement HadRGD, with α line search, as HadRGD-AW (Alg. 4 in Appendix E). Barzilai-Borwein (BB) The BB step-size where s be monotone, thus we follow (Wen and Yin, 2013; Zhang and Hager, 2004) and determine α monotone line search starting at α where h is the smallest integer satisfying where C We implement this as HadRGD-BB (Alg. 5 in Appendix E). All parameters (ρ for further implementation details. (exp(αv)) is shorthand for the derivative of α 7→ g (exp(αv)). Informally, (19a) guarantees suﬃ- = z− zand y= grad g(z) − grad g(z). HadRGD with the BB step-size need not is a running average: We show HadRGD-AW converges at a linear rate. Theorem 5 (Theorem 4.1 (Yang, 2007), adapted). Suppose z of g. Let {z constant E Combining Theorems 5 and 2: Theorem 6. Suppose all global minimizers x (PD). Then HadRGD-AW ﬁnds an ε-optimal solution in O(log(1/ε)) iterations. Each iteration of HadRGD-AW requires O(n) operations yielding a total ﬂop count of O(n log(1/ε). We know of no corresponding proof for HadRGD-BB, but empirically HadRGD-BB is signiﬁcantly faster. We extend our framework from ∆ Using x = z  z we transform (C kxk≤ 1}: Similar to the ∆ Theorem 7. Suppose f is convex and z stationary point of (NC The weighted probability simplex For any a ∈ R probability simplex: Let us consider the following optimization problem: Using once more x = z  z, we obtain: } be a sequence of points converging to zconstructed by HadRGD-AW. Then, there exists a such that, for some integer K≥ 0 and θ ∈ (0, 1), we have kz− zk≤ Eθ. Theorem 8. Suppose f is convex and z stationary point of (NC The ` where the unit ` Since x may have negative entries, we use the double Hadamard parametrization x = z transform (C Similar landscape results hold here. Theorem 9. Suppose f is convex and (z order stationary point of (NC We can extend our framework to nonconvex objective functions f in Problems (C convexity of f in showing: (P) The Hessian ∇ Thus we can relax the convexity assumption of f and obtain more general results by assuming (P and possibly (P h(z) = z  z for (C Theorem 10. Under Assumption (P stationary point if and only if h(z Note that this general result applies to a broader family of objective functions, which are not necessarily convex, such as quasi-convex functions and ` 10 will be stronger: any stationary point z Problems (NC norm ball Consider the minimization: ) to a nonconvex problem: Figure 3: Solving underdetermined least squares with x Left: Time required. Center: Number of iterations required. Right: Time required, for the three fastest algorithms, not in log scale. All results are averaged over ten trials and the shading denotes the min-max range. Figure 4: Solving underdetermined least squares with x accuracy of 10 accuracy; PFW struggles to reach the target accuracy. All results are averaged over ten trials and the shading denotes the min-max range. We consider simplex-constrained least squares where A ∈ R as diverse as portfolio optimization (Bomze, 2002), archetypal analysis (Bauckhage et al., 2015) and hyperspectral unmixing (Condat, 2016). We take m = 0.1n so that f is convex but not strongly convex. We take b = Ax uniformly at random from the interior of ∆ ∆(and hence lies on the boundary of ∆ We considered the following benchmark algorithms: Entropic Mirror Descent Algorithm (EMDA) (BenTal et al., 2001; Beck and Teboulle, 2003); Pairwise Frank-Wolfe (PFW) (Pedregosa et al., 2020), both with and without linesearch; and Projected Gradient Descent (PGD) on ∆ Appendix G for more details and supplementary for codes. We found EMDA and PFW (without line search) to be non-competitive in both cases (see Appendix H), hence here we only present results for PGD (with line search), HadGrad-AW, HadGrad-BB and PFW (with line search). The results for case (i) are presented in Figure 3 while the results for case (ii) are presented in Figure 4. We record, as a function of n, the wall-clock time required to ﬁnd an ε-solution (ε = 10 where x∈ ∆is randomly selected in two qualitatively diﬀerent ways: (i) xis sampled case (i) and ε = 10 HadGrad-AW, HadGrad-BB and 1000 Our experiments conﬁrm HadGrad-AW enjoys a linear convergence rate when x dicted by Theorem 6, see Figure 8. A signiﬁcant amount of the run-time of HadGrad-AW is spent on computing points along the geodesic exp search, instead of a geodesic Boumal (2020). We leave this for future work. From Figure 3 it is clear that HadGrad-BB is the fastest algorithm for problem (23), converging an order of magnitude than the others, both in terms of number of iterations and wall-clock time. In this paper we presented a new framework for transforming a non-smooth constraint set to the unit sphere or ball. We showed that this transformed problem may sometimes be solved much faster using techniques from Riemannian optimization. The superiority of our algorithms is particularly pronounced when: (i) the objective function f is convex but not strongly convex, and (ii) the cost of evaluating ∇f(x) is equal to or higher than the cost of projection on to ∆ consider using either HadRGD-AW (if a guaranteed convergence rate is required) or HadRGD-BB. Finally, we note that our approach is generic in the sense that it does not specify a particular optimization algorithm to use. Thus, future work could combine our Hadamard reparametrization trick with proximal or sub-gradient methods for non-smooth f, or SGD-style methods for ﬁnite sum objectives: f(x) =