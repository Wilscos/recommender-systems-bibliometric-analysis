is a popular knowledge representation form. It focuses on nominal entities and their relations, thus represents static knowledge. However, there is a great deal of event information in the world, which conveys dynamic and procedural knowledge. Thus, event-centric knowledge representation form like Event KG (EKG) is also essential, bringing entities and events together. It has facilitated many downstream applications, such as intelligent search, question-answering, recommendation, and text generation [1], [2], [3], [4], [5]. This paper goes deep into what EKG is and how it develops. What do you want to know about EKG? You may be interested in how it comes into being, what is called an EKG, how to construct it, and further where it can be applied. Thus, to comprehensively introduce EKG, we see it from history, ontology, instance, and application views. From the history view, we introduce the brief history of EKG and our derived deﬁnition of EKG. From the ontology view, we present the basic concepts related to EKG, and the tasks and methods therein, including event schema induction, script induction, and EKG schema induction. From the instance view, we elaborate on event acquisition and EKG-related representative graphs/systems. Speciﬁcally, event acquisition focuses on how to construct a basic EKG and get a better one. The former includes event extraction and event relation extraction, these fundamental tasks. The latter includes event coreference resolution and event argument completion. From the application view, we introduce some basic applications, including script event prediction and temporal KG prediction, and some deep applications, such as search, question-answering, recommendation, and text generation. Moreover, the development processes and trends of the related tasks are studied and analyzed thoroughly. Future directions are then pointed out. There are also some surveys related to part of EKG, focusing on event extraction [6], [7], [8], [9], event modeling and mining [10], event extraction and event relation extraction [11], and event coreference resolution [12]. However, there is a lack of a comprehensive survey on EKG. Actually, events are an essential and non-negligible element in the world. Many events happen every day, reﬂecting the state of the world. Thus, it is necessary to go deep into events. In this way, a comprehensive survey on EKG is of great importance. The remainder of this paper is organized as follows. We ﬁrst present what is EKG from different views in Sections 25, and then introduce future directions in Section 6, followed by conclusions in Section 7. In this section, from the history view, we present the brief history of EKG. We then derive our deﬁnition of EKG based on EKG-related concepts from history. 2.1 The Brief History of EKG EKG does not suddenly burst forth. Instead, it is the outcome of the development of Natural Language Processing (NLP) and artiﬁcial intelligence. As presented in Fig. 1, it can be divided into four stages, and date from event, event extraction, event relation extraction, etc. Stage 1: Early stage of event constitution study. From 1950s, events and their constituents, the essential elements of EKG, were extensively studied [13], [14], [15], [16]. For example, Davidson [14] tried to get the logical form of sentences about actions. He gave an account of the logical or grammatical role of the parts or words in such sentences that is consistent with the entailment relations between such sentences and with what is known of the role of those same parts or words in other (non-action) sentences. Mourelatos [15] and Pustejovsky [16] explored event and proposed its basic deﬁnition. In 1978, Mourelatos [15] deﬁned events as those occurrences that are inherently countable. Whereas in 1991, Pustejovsky [16] regarded that an event can provide a distinct and useful representation for linguistic analysis involving the aspectual properties of verbs, adverbial scope, the role of argument, and the mapping from the lexicon to syntax. Stage 2: Standard formed for event element extraction and ordered event structures appeared. Then, in 1989, the MUC (Message Understanding Conference) evaluations proposed the task of event template ﬁlling, initiated by Naval Ocean System Center to assess and foster researches on the automatic analysis of military textual messages [17]. Given the description of a class of events to be identiﬁed in texts, the participants were required to ﬁll a template for each event on the page. More practically, with the unbounded information-bearing potential of the Web, the ACE (Automatic Content Extraction) program aims to develop the capability to extract meaning therein. Starting in 2004, it added in event extraction, and this task was deﬁned to extract event triggers and arguments, more in line with reality [18]. An event trigger is a word or span that most clearly expresses the event, i.e., mainly indicates the type of the event, and an argument is an entity or span that plays a speciﬁc role in the event. With the awareness of the importance of identifying the events described in a text and locating them in time, in 2007, SemEval (Semantic Evaluation) proposed the temporal relation extraction task TempEval [19]. It aims to extract temporal relations between events within a text. After that, researches of event extraction and event relation extraction usually follow the task deﬁnitions of ACE and TempEval, respectively. Since understanding the temporal ﬂow of discourse is a signiﬁcant aspect of text comprehension, from 2006, there have been some attempts to construct ordered event structures from texts, such as temporal graph [20] and event timeline [21], [22]. Stage 3: KG and event graph appeared. Notably, in 2012, to signiﬁcantly enhance the results returned by Google searches, Google proposed the concept of KG with all the gathered knowledge of entities and relations in a semantic network. KG has thus caught much attention in various ﬁelds since then. However, it is about entities and their relations, i.e., static knowledge, and cannot deal with events elegantly. It somehow triggers the emergence of knowledge representation form on events and their relations. In 2014, Glavaˇs andˇSnajder [23] proposed event graph as a novel event-based document representation model that ﬁlters and structures the information about events described in texts to address the need for efﬁcient retrieval and concise presentation of event-related information. In this event graph, nodes denote events consisting of triggers and arguments (only subject, object, time, and location are considered), and edges indicate temporal relations between events. In 2015, Glavaˇs andˇSnajder [24] further added in coreference relations between events. Speciﬁcally, to describe changes in the world through the events the news articles report, in 2016, Rospocher et al. [25] proposed event-centric KGs, where nodes are events identiﬁed by URIs and entities, while edges are event-entity relations, event-event relations, and general facts about entities. Action, participant, time, and location are considered for the event-entity relations, capturing the dynamic information of events (what, who, when, and where). The event-event relations include temporal and causal relations. Stage 4: Event logic graph came into being. Recently, with the development of many real-world applications, such as event prediction, decision making, and scenario design of dialog systems, there is a great need to understand the evolution and development of events. Thus, in 2017, Li et al. [26] proposed event evolutionary graph. It is similar to the event graph deﬁned in [23], but event nodes therein are represented by abstract, generalized, and semantic complete verb phrases. It further considers causal relations between events and reveals evolutionary patterns and development logics of real-world events. Then, in 2018, Gottschalk and Demidova [27] proposed event-centric temporal KG, where events, entities, and relations are represented as nodes, to facilitate semantic analyses of information regarding contemporary and historical events on the Web, in the news, and in social media. Events therein have topical, temporal, and geographical information, and are linked to the entities participating in the events. They also considered entityentity relation, and subevent, previous, and next event relations between events. In 2019, event evolutionary graph was derived to event logic graph [28], where nodes are abstract, generalized, and semantic complete event tuples (s, p, o), here p is the action/predicate (i.e., event trigger), s is the actor/subject, and o is the object on which the action is performed. Besides, two more relations between events, conditional and hypernym-hyponym (“is-a”), were considered. Generally speaking, there are many EKG-related concepts. As presented in Table 1, event evolutionary graph [26] and event logic graph [28] only focus on schema-level event knowledge. Nodes in event graph [23], [24] and event logic graph are composite structures, which are difﬁcult to handle. Moreover, these EKG-related concepts all consider speciﬁc and limited argument roles, as well as speciﬁc and limited relations between events. Actually, an event has its components, each of which consists of an argument and an argument role that the argument plays in the event [29]. Besides, there are many different relations between events. 2.2 Deﬁnitions As introduced in Section 2.1, there are some EKG-related concepts with deﬁciencies. We follow this line but introduce richer contents, as presented in the following. We think that EKG, centering on events, has two types of nodes, events and entities, and three types of directed edges, indicating event-event relations, event-entity relations, and entity-entity relations. The ﬁrst type of relations includes many kinds of relations between events, such as temporal, causal, conditional, thematic, etc. The second type of relations represents the arguments of events, i.e., the edges are the argument roles of the entities to the linked events. Different event types have different argument roles. The third one describes the relations between entities, such as place of birth, located in, has part, etc. Formally, Deﬁnition 1. EKG G = {(s, p, o)|{s, p} ∈ N, p ∈ E, N = N∪ N, E = E∪ E∪ E} is a graph of events N, entities N, and their relations E, where E, E, and Eare the relations between events, between events and entities, and between entities, respectively. In this way, events can easily be connected by common argument entities and vice versa. KG is thus a special case of EKG, with only entity nodes and entity-entity relations. From the ontology view, we look into the schema and the related tasks. The schema of an EKG describes the basic concepts that form it, such as the event types, the roles of the event arguments, and the relations between events. The event types and the roles of the event arguments form the frames of events, i.e., event schema. As for the relations between events, the typical script [30] organizes a set of events according to some event relations, which together describe the common scenario. In this section, before introducing EKG schema induction, let us begin with event schema induction and script induction. 3.1 Event Schema Induction An event schema can be either manually designed or automatically extracted. For example, ACE event schema [18], [29] and FrameNet frame [31] are typical manually designed event schemas. Since manually designed event schemas show low coverage and difﬁculty in domain adaptation, researchers have paid much attention to automatic event schema extraction, i.e., event schema induction. It automatically extracts event types and their corresponding argument roles from texts. Existing methods on this task can be divided into supervised, semi-supervised, and unsupervised methods. Among them, the last one is more popular. Supervised methods are applied in early studies. They learn from annotated data and then induce event schema from new documents [32], [33], [34], [35]. For example, methods in the third MUC evaluations used pattern matching (e.g., regular expressions), syntax-driven techniques which combine syntactic analyses with semantics and subsequent processing, or integrate syntax-driven techniques into pattern matching for event schema induction [33]. Chieu et al. [35] adopted semantic and discourse features, and built one classiﬁer, e.g., maximum entropy, Support Vector Machine (SVM), naive Bayes, or decision tree, for each argument role. Semi-supervised methods start with a few annotated seeds to induce event schema [36], [37], [38], [39]. For example, Patwardhan and Riloff [38] created a self-trained SVM classiﬁer to identify relevant sentences for the domain of interest and then used a semantic afﬁnity measure to extract domain-relevant event schema automatically. The self-training process begins with a few seed patterns and a set of relevant and irrelevant documents. The following event schema extraction is based on heuristic rules upon syntactic analyses. The extracted results were then ranked by semantic afﬁnity based on frequency counts to keep top results. Huang and Ji [39] automatically discovered a set of unseen event types from a given corpus by leveraging annotations available for a few seen types. They designed a vector quantized variational autoencoder framework to learn a type embedding for each seen or unseen event type automatically and optimized the framework using seen event type annotations. A variational autoencoder was further introduced to enforce the reconstruction of each event trigger conditioned on its event type distribution. Unsupervised methods remove the requirements of annotated data and are widely applied [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50]. For example, Chambers and Jurafsky [42] viewed event schema induction as a task aiming to discover unrestricted relations from unlabeled corpora. They used Pointwise Mutual Information (PMI) to measure the distances between events and clustered events according to the distances. Then, they induced the argument roles of events via the syntactic relations. Balasubramanian et al. [43] used co-occurrence statistics of (subject, predicate, object) pairs to build a graph with these triples as nodes and edges were weighted by the symmetric conditional probabilities of the involved triple pairs. Triples therein were normalized using stemmed headwords and semantic types. They started with high-connectivity nodes in the graph as seeds. Then, they used graph analysis to ﬁnd closely related triples to the seeds and merged their argument roles to create event schema. Chambers [44] proposed the ﬁrst generative model for schema induction similar to LDA [51]. Nguyen et al. [45] further introduced entity disambiguation. More recent studies introduced representation learning to induce event schema unsupervisedly [46], [47], [48], [49], [50]. For example, Yuan et al. [47] proposed a two-step framework. They ﬁrst detected event types from the news corpus by clustering news articles. Then, they proposed a graph-based model that exploits entity co-occurrence information to learn entity embeddings and then clustered these embeddings into argument roles. Methods in the 2019 International Workshop on Semantic Evaluation usually applied pretrained language models, such as BERT [52], to get contextualized word embeddings [48]. They then clustered these embeddings with hand-crafted features and aligned them to the event types and argument roles of the existing event schema (e.g., FrameNet). Yamada et al. [49] thought previous studies focused too much on the superﬁcial information of verbal event triggers and proposed to use masked word embeddings from BERT to get deep contextualized word embeddings. They then applied a two-step clustering method, which ﬁrst clusters instances of the same verb according to the embeddings and further clusters across verbs. Finally, each generated cluster was regarded as an induced schema. In a word, for supervised methods, they are hard to apply to new event types, which limits their usage. For semi-supervised and unsupervised methods, automatically derived event schema is noisy and difﬁcult to be aligned. So far, these techniques are still not so applicable to building the event schema for an EKG. 3.2 Script Induction A script can be seen as a stereotypical structure of event schema that expresses a speciﬁc scenario. Speciﬁcally, it organizes a set of events into a certain structure (usually according to their temporal relations). Fig. 2 shows a typical example of script, the restaurant script, which models the scenario of a customer eating food in a restaurant. Script has a primary feature, i.e., the “events” in scripts, usually called script events, are event schema rather than event instances. In early studies, scripts were manually designed [30], [53]. In more recent studies, researchers tried to extract script automatically from texts, i.e., script induction. One challenge therein is to learn the scenario-speciﬁc argument roles automatically. Thus, Chambers and Jurafsky [54] proposed a heuristic method, which uses the most frequent headword in an entity coreferential chain as the argument role of this entity. Regneri et al. [55] collected natural-language descriptions of script-speciﬁc event sequences from volunteers over the Internet. They then computed a graph representation of the script’s temporal structure using a multiple sequence alignment algorithm. This graph makes statements about what phrases can describe events of a scenario and in what order these events can occur. Cheung et al. [56] proposed a probabilistic method, which deﬁnes a joint distribution over the words in a document and their script assignments. Speciﬁcally, they combined a script Hidden Markov Model (HMM) [57] with an event HMM, where the ﬁrst HMM models script transition and emits events, and the second one models event transition within a script and emits argument roles. Orr et al. [58] also learned scripts from documents based on HMM. Differently, the states of the HMM correspond to event types in scripts, and observations correspond to sentences that describe the event instances occurring in the story. A clustering algorithm was applied to get the states and observations. Then, they started with a fully enumerated HMM representation of the event sequences and incrementally merged states and deleted edges (state transitions) to improve the posterior probability of the structure and parameters given the data. Weber et al. [59] argued that a purely correlation-based approach is insufﬁcient and proposed an approach to script induction based on the causal effect between events, formally deﬁned via interventions using a Bayesian network-based method. Weber et al. [60] and Ciosici et al. [61] further induced script via human-machine collaboration manner. In general, among these script induction methods, the simple one proposed by Chambers and Jurafsky [54] is usually used in the studies of script application [62], [63], [64]. However, it is still far from satisfactory. For example, suppose a coreferential chain contains “Jobs”, “Steve Jobs”, and “CEO Jobs”. In that case, the above method will use “Jobs” instead of “CEO” as the argument role, which is too speciﬁc and lacks generalization. It is still an open problem how to learn high-quality scenario-speciﬁc argument roles effectively and efﬁciently. Scripts can be seen as rules about events, which form the evolution patterns of events in certain scenarios. One basic application of script is to predict what will happen in the future via script event prediction. Speciﬁcally, the known real-world events are ﬁrstly generalized into script events. Then, these script events are used to derive the subsequent script events, which is called script event prediction. Finally, the predicted subsequent script events can be instantiated to real-world events. We will describe more details of script event prediction in section 5.1.1. 3.3 EKG Schema Induction There are researches for EKG schema induction directly. Since EKG-related studies have not been put forward for a long time, researches on EKG schema induction are much scarcer and newer. In 2020, Li et al. [65] ﬁrst studied event graph schema induction, focusing on rich event components and event-event connections. A path language model was proposed to construct an event graph schema repository where two event types are connected through multiple event-event paths involving entities that ﬁll important argument roles. These entities were replaced by their types in the event graph schema. However, this work only pays attention to the connections between a pair of events. In 2021, Li et al. [66] further focused on all three types of relations, i.e., event-event, event-entity, and entity-entity relations. They regarded schema as hidden knowledge to guide the generation of event graphs and learned via maximizing the probability of these instance graphs. However, for eventevent relations, only temporal relations were considered. Generally speaking, existing few studies on EKG schema induction consider limited relation types. Thus, there is a long way to go for EKG schema induction to induce overall schema for EKG. From the instance view, this section introduces how to construct an EKG, i.e., event acquisition and EKG-related representative graphs/systems. 4.1 Event Acquisition Event acquisition is essential for EKG construction. It mainly includes event extraction, event relation extraction, event coreference resolution, and event argument completion. The former two tasks are basic, and the latter two are important for constructing a better EKG. In this section, we review the process of their development and future trends. 4.1.1 Event Extraction As the primary step in constructing EKG, event extraction aims to extract structured event information from texts, including event triggers with types and arguments with roles. Thus, there are two main subtasks, trigger detection and argument extraction. Each of them consists of two stages, identiﬁcation and classiﬁcation. Trigger detection identiﬁes the event trigger words and assigns them with proper predeﬁned types or clustered classes, while arguments extraction identiﬁes the arguments and assigns them with appropriate argument roles of the triggered events. Event extraction can be divided into schema-based and schema-free event extractions according to whether there is a predeﬁned schema. As illustrated in the upper part of Fig. 3, existing schema-based methods take texts as input and pass them to feature learners to obtain local (and global) features. Based on them, classiﬁers of triggers and arguments output the overall probability distributions on the predeﬁned schema and get the answers based on the peaks. As for schema-free event extraction formalization (bottom part of Fig. 3), texts are passed to the discriminators to get raw triggers and arguments, which are then clustered into event groups to induce the event schema. Simple unsupervised event schema induction methods (see Section 3.1) are usually used therein. Finally, it obtains triggers with type and arguments with roles. Speciﬁcally, considering the scale of input data, schema-based event extraction can be further grouped into sentence-level and document-level event extractions, and schema-free event extraction is also named open-domain event extraction. Compared to document-level and open-domain event extractions, sentence-level event extraction is more extensively studied. Sentence-level event extraction aims to extract event triggers and arguments in a single sentence. Early approaches designed elaborate features, such as lexical features and syntactic features, to solve this task through statistical learning methods [67], [68], [69]. For example, Liao and Grishman [69] used document-level event and role features to improve sentence-level event extraction. Speciﬁcally, they applied maximum entropy-based classiﬁers under many constructed patterns to extract events at the sentence level. Then, they adopted cross-event information, e.g., event co-occurrence and relations among the arguments of different events, to train additional maximum entropy-based classiﬁers. These classiﬁers were used to infer new events and event arguments. Recently, with the construction of large-scale datasets (e.g., ACE [29], TACKBP [70], and RAMS [71]) and the development of deep learning, researchers have begun to employ neural networks to extract features automatically. According to the type of features, these methods can be divided into three main categories. The ﬁrst category only uses the intrasubtasks features, including lexical and syntactic features. These methods usually follow a pipeline framework performing each event extraction subtask in separate stages sequentially. The second one explores the inter-subtasks features like the co-occurrence of various trigger types and argument roles. These methods can beneﬁt from the interdependencies among event triggers and the corresponding argument roles. The last one uses a multi-task learning framework to explore the inter-IE features among several related Information Extraction (IE) tasks, such as entity extraction, entity relation extraction, and event extraction. Explore intra-subtasks features. The majority of this kind of methods adopt a Convolutional Neural Network (CNN) or Recurrent Neural Network (RNN) to extract the intrasubtasks features. Chen et al. [72] proposed dynamic multipooling CNN to solve the two subtasks of event extraction in a pipeline way. They used CNN to extract the word features and adopted a dynamic pooling method to extract various sentence-level features for different candidate words in trigger detection and argument extraction. However, as a CNN-based method, this work cannot properly handle the sequential relations and the long-range dependencies among the words in a sentence. Thus, Chen et al. [73] adopted two bidirectional dynamic multi-pooling Long Short-Term Memory Networks (LSTMs) to solve trigger detection and argument extraction sequentially. Besides, they designed a tensor layer to explore interactions between candidate arguments and predicted all candidate arguments simultaneously. With the development of the pretrained language models like BERT and ELMo [74], recent researchers have introduced these models into event extraction. For example, Yang et al. [75] added a multi-classiﬁer on the BERT for trigger detection and then added multiple sets of binary classiﬁers on the BERT for argument extraction. They separated argument predictions in terms of argument roles to solve the role overlapping problem that an argument may have different argument roles in the same event. The importance of argument roles was also considered via reweighting the loss function to solve their long-tail frequency distribution problem. Deng et al. [76] enriched event schema with event-event relations, such as temporal, causal, and hierarchical relations, to improve trigger detection based on BERT embeddings. Recently, Du and Cardie [77] and Liu et al. [78] proposed machine reading comprehension frameworks upon BERT, which adopt a question answering process to extract event elements from sentences. Explore inter-subtasks features. Methods in this category explore the inter-subtasks features of trigger detection and argument extraction, and usually follow the joint architecture, which eases the error propagation problem of the pipeline framework in the ﬁrst category. Nguyen et al. [79] proposed a joint model based on Bidirectional LSTM (BiLSTM). They introduced memory vectors to store the joint features during event extraction, which was performed as sequence labeling. The joint features include the dependencies among trigger subtypes, among argument roles, and between trigger subtypes and argument roles. To further make use of syntactic features, Sha et al. [80] proposed dependency bridge RNN for event extraction. They added dependency bridges to connect syntactically related words in RNN and built a tensor layer on each pair of candidate arguments to capture intensive argument-level information interaction. To capture the long-range dependencies more efﬁciently, Liu et al. [81] proposed joint multiple events extraction. They introduced an attention-based Graph Convolution Network (GCN) to aggregate the word information through paths of the syntactic tree of the sentence. By introducing these syntactic structures and the self-attention mechanism, this method can capture more interaction features among the candidate triggers and arguments. Explore inter-IE features. To better model the semantic information of event elements for event extraction, recent researchers have explored more global features among the words in a sentence via introducing other related IE tasks, including entity extraction, entity relation extraction, and coreference resolution. With a multi-task learning framework, these IE tasks can beneﬁt from each other. Nguyen and Nguyen [82] employed a Bidirectional RNN (BiRNN) to learn embeddings for the words in a sentence, over which entity extraction and event extraction were conducted via classiﬁers based on Fully Connected Network (FCN) and softmax. Wadden et al. [83] further handled entity extraction, entity relation extraction, event extraction, and coreference resolution. After encoding sentences via BERT, they enumerated candidate text spans and constructed a span graph based on the current best guess at the relations among spans, where event triggers are linked to their arguments, and entities are linked by their relations. Each span embedding was then updated by integrating embeddings from its neighbors. These updated embeddings were passed to the FCN-based classiﬁers of all the tasks. However, these studies handle the tasks separately without deep interactions among them. To better explore the interIE features, Lin et al. [84] extracted entities, entity relations, and events simultaneously. They used BERT to learn contextualized word embeddings, and computed local scores for all candidate triggers, entities, and their pairwise links via local FCN-based classiﬁers. Then, they designed a series of global features to describe the inter-dependencies among the candidate triggers and entities. After that, they searched for the globally optimal results with a beam search-based decoder by incorporating these global features to capture the inter-tasks and inter-instances interactions. Document-level event extraction. Sentence-level event extraction assumes that the event trigger and its arguments are in the same sentence. However, in real-world scenarios, they usually scatter across multiple sentences in a document. Thus, document-level event extraction is practical. There are several new problems in document-level event extraction. For example, arguments may exist in different sentences, and a document usually contains multiple events. Early approaches used a series of well-deﬁned features to model events and involved entities. Then, they extracted events in the whole document via statistical learning method [85], [86], [87]. For example, Ji and Grishman [85] obtained document-wide and document cluster-wide statistics about the frequency with which triggers and arguments are associated with particular types of events. They then used this information to correct the event extraction results of maximum entropy-based classiﬁers under many constructed event patterns. These handcrafted features and annotated data are usually expensive to obtain. To address this problem, Yang et al. [88] used a distant supervision method to label event triggers and arguments in the whole document automatically. With the annotated data, they trained a sentence-level event extraction model with a BiLSTM layer and a Conditional Random Field (CRF) layer. Then, they used an argument completion strategy to automatically pad the missing arguments from the surrounding sentences based on the sentence-level event extraction results. This framework can handle the argument scattering problem with the argument completion strategy in a pipeline way. To handle document-level event extraction with an end-toend method, Zheng et al. [89] transformed events into an entity-based directed acyclic graph. Then, they transformed the traditional event extraction task into several easier sequential path-expanding subtasks and handled them with a memory mechanism. Xu et al. [90] also did this transformation, but further explored more interactions among different sentences in a document and the inter-dependencies among different events. Speciﬁcally, they designed four edge types on sentences and entities to build a graph. Then, they used a Graph Neural Network (GNN) to model the interactions and obtained document-aware embeddings of entities and sentences. For incorporating the inter-dependencies among different events, they tracked the extracted events and stored the information into a global memory to facilitate the current extraction. Differently, Lou et al. [91] proposed a multi-layer bidirectional network to capture documentlevel semantic and event inter-dependency simultaneously for trigger detection. Speciﬁcally, BiLSTM, BiRNN, and FCN were applied to model event inter-dependency within a sentence when decoding the event label vector sequence. These sentence-level semantic and event label information were aggregated via LSTM. Then, Lou et al. [91] stacked multiple bidirectional labeling layers based on BiRNN and FCN to propagate information across sentences iteratively. The ﬁnal event label vector is the weighted sum from different layers. Open-domain event extraction. Unlike the sentencelevel and document-level event extraction tasks, opendomain event extraction usually has not any predeﬁned event types or speciﬁc argument roles. It aims to extract events mainly from long texts like newswires and short texts like social media streams. For long texts, Rusu et al. [92] proposed a dependency parser-based method. They considered verbs as event triggers, and then analyzed the dependency paths between verbs and other syntactic elements (entities, time expressions, subjects, and objects) to identify arguments. However, compared with the predeﬁned event schema, syntactic relations are too simple to describe complex events. To extract events and induce schema simultaneously, Huang et al. [46] ﬁrst identiﬁed all noun and verb concepts that can be matched to the existing schema like FrameNet as candidate event triggers and further identiﬁed their candidate arguments via manually-selected semantic relations. Then, they clustered candidate triggers and arguments based on their embeddings from a tensor-based model, and named them to obtain the schema and the extracted results via the mappings to the existing schema. Differently, Liu et al. [93] learned the joint probability distribution of a news cluster with headwords, contextual features, and latent event type through sampling them from different distributions. Besides, they additionally used a pretrained language model to improve the embeddings. Then, they adopted the learned joint distributions to cluster news and applied a series of rules to assemble them to get the ﬁnal results. With the development of social networks, social media streams can produce a large amount of information every day. These short texts are also valuable for exploring events. Unlike the open-domain event extraction from long texts that need inducing a complex schema, the main components of events in social media streams are entities, time, location, and keywords. Abdelhaq et al. [94] detected events that are important within a small geographic area from a stream of tweets. For each frame in a timeline, they extracted all candidate event keywords based on the frequency. Then, they calculated the spatial density distribution over the usage ratio of the candidate keywords at a particular location. The ones with small entropy (occur only at a few locations) were selected, which were further clustered by their spatial density distribution to get the events. To extract more information, Wang et al. [95] fused information from Twitter and related Web pages to identify events and extract their times, locations, and titles through tweet-based CRF and page-based CRF, respectively. However, multiple mentions may refer to the same entity, and they would be wrongly assigned to different events by the methods above. Thus, Zhou et al. [96] proposed a non-parametric Bayesian mixture model for event extraction from Twitter, which incorporates word embeddings to deal with this issue. Xu et al. [97] further applied a BiLSTM layer, a control gate layer, and a CRF layer to extract events from Twitter. In a word, although event extraction has been studied for a long time, current methods still cannot meet the need for high-quality EKG construction. The performance now is insufﬁcient, especially that of difﬁcult argument extraction. Thus, it may introduce noisy information into EKG construction. Moreover, partly because of the low performance on argument extraction, some researches on EKG applications like script event prediction and temporal KG prediction (see Sections 5.1.1 and 5.1.2) only consider the simpler ﬁxed argument roles, subject, object, and indirect object or time, instead of well-deﬁned complex schema. Therefore, improving the performance of this primary event extraction task is of great importance. 4.1.2 Event Relation Extraction Besides event extraction, event relation extraction is a fundamental step of EKG construction. It extracts relations between events from texts and thus connects events to get an EKG. The main types of event relations are temporal relation and causal relation. Event temporal relation describes the temporal order between events. Event causal relation describes the causality between events and is a subset of event temporal relation. For short, we use the terms temporal relation and causal relation, respectively. These two types of relation extractions share similar research lines. They are usually formalized as a simple text classiﬁcation task given the event pairs and the contexts. As presented in Fig. 4, extracted event pairs and their contexts are passed to the feature learner to capture helpful information for event relation extraction. Based on these features, the relation classiﬁer outputs the relation labels. Some methods additionally introduce external knowledge. For temporal relation extraction, there are also methods considering the important global consistency problem. For example, if the classiﬁer gets the results: A bef ore B, B bef ore C, and C before A, then there is a conﬂict. Actually, the former two imply A bef ore C. Early methods heavily relied on the manually designed syntactic and semantic features [98], [99], [100], [101], [102], [102], [103]. They then used machine learning models, such as naive Bayes, maximum entropy, or SVM as the classiﬁer, to recognize relations. For example, Chambers et al. [100] proposed a two-stage method for temporal relation extraction. The ﬁrst stage learns the temporal attributes of single events, such as tense, event type, modality, and polarity. Combined with other linguistic features, they were then used to classify the temporal relation between events via SVM in the second stage. Rink et al. [102] used graph patterns as features to train an SVM classiﬁer. Speciﬁcally, they ﬁrst built a graph representation for a sentence that encodes lexical, syntactic, and semantic information. They then automatically extracted multiple graph patterns from such graph representations via a frequent subgraph mining algorithm, which were sorted according to their relevance in determining the causality between events from the same sentence. These graph pattern features were passed to the SVM classiﬁer. Zhao et al. [103] proposed a restricted hidden naive Bayes model to cope with the interactions among features for causal relation extraction. Besides contextual features, syntactic features, and position features, they utilized a new category feature of causal connectives, obtained from the similarities of the syntactic dependency structures of sentences expressing causality. The above methods for temporal relation extraction typically focus on pairwise decisions, ignoring global consistency. Thus, many methods further considered global consistency [20], [22], [104], [105], [106], [107], [108]. Bramsen et al. [20], Chambers and Jurafsky [104], and Do et al. [22] applied Integer Linear Programming (ILP) on top of the above local classiﬁers. Chambers et al. [106] proposed a cascade architecture with a sequence of classiﬁers ordered by their precision. The classiﬁers were run in order starting with the most precise one. Global consistency was enforced by inferring all the transitive relations from the results of earlier classiﬁers before passing the results to the next classiﬁer. Mirza and Tonelli [107] further applied similar methods as temporal relation extractor and causal relation extractor. In particular, labels from the temporal relation extractor were used as features for the causal relation extractor, and labels from the causal relation extractor were adopted to correct the wrong labeled event pairs by the temporal relation extractor. Different from these pipeline methods for global consistency, Yoshikawa et al. [105] and Ning et al. [108] considered global consistency in the learning stage. Yoshikawa et al. [105] proposed a Markov logic model and captured global consistency through the addition of weighted ﬁrstorder logic formulae. Whereas Ning et al. [108] proposed a structured learning approach, which trains the local classiﬁer with feedback that accounts for other relations, by performing global inference in each round of the learning process. Besides the above intra-sentence causal relation extraction, Gao et al. [109] designed lexical features, potential causal features (co-occurrences of two events in one sentence), and syntactic features for intra-sentence and crosssentence causal relation extraction at the document level. These global and ﬁne-grained aspects of causal structures were learned via ILP. More recent methods utilized neural networks, such as CNN and LSTM, to learn useful features for extraction automatically [110], [111], [112], [113], [114], [115]. They applied CNN or LSTM to encode event sentences, followed by a relation classiﬁer based on FCN and softmax. To make better globally consistent decisions for temporal relation extraction, Han et al. [113] further adopted an SVM-based algorithm incorporating transitivity constraints, and Ning et al. [114] further employed ILP. Differently, Cheng and Miyao [116] adopted BiLSTM along dependency paths of event sentences for temporal relation extraction. To further make use of external knowledge, Ning et al. [114] applied a Siamese network to a temporal common sense knowledge base, whose output was concatenated with the LSTM output of event sentences, for temporal relation extraction. Whereas Li and Mao [115] proposed a knowledge-oriented CNN for causal relation extraction, where the convolutional ﬁlters were automatically generated from lexical knowledge bases to represent keywords and cue phrases of causal relations. They also combined a conventional CNN to learn other features of causal relation from training data. To further introduce other related tasks, Han et al. [117] extracted event and temporal relation jointly to avoid error propagation in the conventional pipeline manners, which extract them subsequently. Speciﬁcally, after encoding sentences via BiLSTM, they used the outputs to compute the probability of being an event and the softmax distribution over all possible temporal relation labels. Global consistency was considered via the last SVM-based layer incorporating transitivity constraint, symmetry constraint, etc. Wang et al. [118] proposed a similar method for temporal and subevent relation extraction, but replaced the above SVMbased layer with a differentiable constrained learning layer. The logical constraints were converted into differentiable functions and incorporated into the learning objective of relation extraction. Different from these hard constraints, Han et al. [119] improved similar networks of event extraction and temporal relation extraction by incorporating corpus statistics as soft constraints and by solving the constrained inference problem using Lagrangian relaxation to guarantee global consistency. Notably, since pretrained language models perform well on a wide variety of NLP tasks, researchers have introduced them, such as BERT, into event relation extraction. Many neural network-based researches simply used BERT as pretrained model [113], [114], [117], [118], [119]. Different from them, Liu et al. [120] and Zhou et al. [121] adopted BERT to encode event sentences directly. For example, Liu et al. [120] proposed knowledge enhanced event causal relation extraction with mention masking generalizations. Speciﬁcally, the model consists of the knowledgeaware reasoner, the mention masking reasoner, and the attentive sentinel trading off between the two modules. The ﬁrst module uses BERT to model the sentences where events are replaced by their deﬁnitions from external knowledge, learning more expressive embeddings for events. The second one adopts another BERT to model the sentences where event mentions are replaced by a placeholder symbol [MASK], which mines event-agnostic and context-speciﬁc patterns for reasoning. Recently, some BERT-based studies focused on the data lacking problem in causal relation extraction via introducing external knowledge [122], [123], [124], [125]. Zuo et al. [122] proposed a knowledge enhanced distant data augmentation framework. They extracted event pairs with a high probability of causality based on lexical knowledge and employed the extracted ones to label sentences via distant supervision automatically. Then, they reﬁned distantly labeled sentences with the assistance of causal commonsense knowledge. After that, they employed relabeling and annealing strategies to make use of distantly labeled sentences for training. The causal relation extraction model therein was based on the BERT encoder of event sentences and the FCN-based classiﬁer. Zuo et al. [123] further proposed a knowledgeguided and learnable data augmentation framework. They regarded the target task, causal relation extraction and the augmentation task, sentence generation as dual tasks, and modeled their mutual relations via dual learning. Speciﬁcally, they introduced diverse causal event pairs from external knowledge to initialize the dual generation, ensuring the causality of generated causal sentences. Both causal relation extraction and sentence generation therein were implemented based on BERT. Differently, Zuo et al. [124] designed a self-supervised framework to learn context-speciﬁc causal patterns from external causal statements. Then, they adopted a contrastive transfer strategy to incorporate the learned context-speciﬁc causal patterns into the target causal relation extraction model based on BERT. Whereas Cao et al. [125] concatenated contextualized embeddings from the BERT of event sentences, GCN embeddings of one-hop neighbors of events from external knowledge, and densely connected GCN embedding of the shortest multi-hop path between the event pair from external knowledge. They then passed the concatenated embeddings to an FCN and softmax-based classiﬁer. The above BERT-based causal relation extraction methods are limited to the intra-sentence setting. For documentlevel setting, Phu and Nguyen [126] proposed a graphbased model. They applied BERT to encode words in the document, which were used to generate an interaction graph for the document considering the discourse-based, syntax-based, and semantic-based information. This graph was then consumed by GCN to learn document contextaugmented embeddings for causality extraction between events based on FCN and softmax. In general, existing event relation extraction methods cannot fully satisfy the requirements of EKG construction. For example, event relation extraction currently usually only focuses on verbs as events and does not consider nouns as events. Actually, besides verbs, event triggers can also be nouns. Another limitation is that existing studies ignore arguments. Future researches on event relation extraction should pay attention to these fundamental problems. 4.1.3 Event Coreference Resolution There are usually many texts describing the same events. Thus, it is necessary to group the events referring to the same real-world event into the same cluster after event extraction for better EKG construction. This task is called event coreference resolution. Researchers usually divide it into within-document and cross-document settings according to whether events are from the same document or different documents. The latter is more intricate, since it is difﬁcult to deal with event contexts from different documents. For example, semantically similar event contexts from different documents may describe different events. As illustrated in Fig. 5, existing methods for event coreference resolution take the results from event extraction and their contexts as input, which are passed to the feature learner and coreference scorer to get the coreference results between events. Then, a similar cluster decoder is usually applied to merge the local results to get the global results, where some rules or clustering algorithms are adopted. Some methods additionally introduce external knowledge to improve feature learning. Speciﬁcally, existing methods for event coreference resolution can be divided into unsupervised, semi-supervised, and supervised methods. Unsupervised methods construct feature templatebased event representations and then perform pattern matching or adopt unsupervised probabilistic models to identify the coreferential relations between events [127], [128], [129], [130], [131], [132], [133], [134]. Early researches adopted simple rule-based approaches to deal with event coreference resolution [127], [128]. They applied the consistency of event triggers and arguments between events to determine whether events are coreferential. Subsequently, some studies [129], [130], [134] used lexical-related features of event triggers (e.g., edit distances), argument-related features (e.g., coreferential arguments), semantic-related features (e.g., word embedding similarities), and other handcrafted features to construct event representations. Then, maximum entropy, non-parametric Bayesian estimation, cosine similarity, and other methods were adopted to determine the coreferential score of event pair under within- or cross-document setting. Moreover, Chen and Ng [132] proposed an unsupervised probabilistic model for within-document event coreference resolution and further introduced anaphoricity determination. The lexical and semantic features of triggers and arguments were also used, and the expectation-maximization algorithm was adopted to estimate the model parameters. These unsupervised coreference resolution methods are intuitive and efﬁcient. They can usually handle both withinand cross-document settings. However, they require carefully designed rules or matching strategies, and their scalability is limited by the strictly restricted feature templates. Semi-supervised methods pay attention to the scarcity of existing annotated corpus [135], [136], [137], [138]. They use a small amount of labeled data and a large amount of unlabeled data to conduct event coreference resolution. For example, Sachan et al. [136] proposed an active learning-based within- and cross-document event coreference resolution framework. Some heuristic sample selection strategies, such as the maximum uncertainty strategy, the maximum expected judgment error strategy, and the explore and exploit strategy, were adopted to choose event pairs for manual annotating. Therefore, comparable coreference resolution performance was achieved on smaller labor costs. Moreover, Peng et al. [137] conducted trigger detection and event coreference resolution in a uniﬁed framework with minimal supervision. They transformed event coreference resolution into a similarity calculation problem between event embeddings. Event embeddings were obtained via concatenating the embeddings of its elements trained from external texts. For trigger detection, the similarity between candidate trigger and event type was used, where event type embedding is the average of the embeddings of its event examples. The similarity thresholds of trigger detection and event coreference resolution were tuned by the given few labeled samples, respectively. Focusing on the scarcity of corpus resources, these methods make full use of the existing data and even external resources. They usually can be applied to both withinand cross-document settings. They effectively broaden the application of event coreference resolution, especially in low-resource scenarios. However, their effect is limited, and external resources may introduce noises. Supervised methods. With the construction of datasets such as MUC [17], ACE [29], and ECB/ECB+ [131], [139], and the development of the TAC KBP Event Nugget Detection evaluation task [70], researchers have developed many supervised methods for event coreference resolution. Depending on the form of event coreference resolution samples that the coreference scorer processes, there are two types of models: event-pair and event-ranking models. Event-pair models are the most common but inﬂuential supervised approaches. They process event pairs and adopt binary classiﬁer as coreference scorer to assign each event pair a probability of being coreferential [140], [141], [142], [143], [144], [145], [146]. For example, Krause et al. [142] adopted CNN as the feature learner and took the whole sentence of an event as input, whose output was concatenated with the embeddings of event trigger and its left and right neighbors, to get event embedding. The embeddings of two events were concatenated and augmented with their pairwise features, such as argument overlapping. Then, the concatenated vector was passed to an FCN, followed by a logistic regression classiﬁer as the coreference scorer. This method only focuses on within-document event pairs. To handle both within- and cross-document settings, Choubey and Huang [143] separately trained two neural network-based feature learners and FCN-based coreference scorers for event pairs within and cross documents, respectively. After that, they alternatively performed the within-document cluster merging and the cross-document cluster merging to model the secondorder inter-dependencies across events. These methods all obtain the embedding of each event at ﬁrst and then fuse the embeddings of two events to get the embedding of the event pair. To further capture the semantic interactions between the contexts of two events, Zeng et al. [146] proposed an interaction-based within- and cross-document coreference model. Speciﬁcally, two sentences of the event pair were concatenated and fed to the feature learner based on BERT. Meanwhile, the internal structural information of the events was injected in the form of semantic role label embeddings. FCN and softmax were adopted as the coreference scorer. Lee et al. [140] and Barhom et al. [145] further introduced entity coreference resolution to enhance the performance by the interactions of the two tasks. Lexical resource or pretrained word embeddings were used therein. Event-ranking models process all the events mentioned before the given event, i.e., the antecedents, simultaneously. They are trained to assign the ﬁrst coreferential antecedent of each given event with the highest rank [147], [148], [149], [150], [151], [152], [153]. For example, Lu and Ng [148] trained a probabilistic model to select the coreferential antecedent for each event in a document collectively. They ﬁrst deﬁned the antecedent vector, where the i-th element is the coreferential antecedent index of the i-th event in the given document. And they assumed that given the event features, the probability of the antecedent vector conforms to an exponential distribution. Then, a log-linear model was employed to assign the highest score to the antecedent vector. However, since coreference relations may be long-distance, document-level information may be helpful for event coreference resolution. Thus, Tran et al. [152] constructed a structure graph for each document and employed GCN for representation learning. The nodes in the structure graph are the events, entities, and words in the document. These nodes were connected via different information, such as connecting coreferring entities, linking events and their arguments, connecting similar words/events, etc. Event embeddings from GCN were fed to the FCN-based coreference scorer. Moreover, the intra- and inter-cluster consistencies between the golden and prediction event clusters were ﬁrst exploited to regularize event embeddings. To make use of the cross-task interactions or consistency constraints for better coreference performance, many methods further incorporated trigger detection, entity coreference resolution, anaphoricity determination, realis detection, or argument extraction into a joint learning framework [147], [149], [150], [151], [153]. Notably, since the mention-ranking approaches usually need to use more context information, it is more suitable for within-document event coreference resolution, and it may introduce noises for cross-document setting. Generally speaking, existing researches on event coreference resolution still have some deﬁciencies in practice and cannot meet the need of real-world scenarios. For example, most methods specify that all events have ﬁxed arguments. However, in actual applications, arguments usually differ event by event. In addition, some methods only consider the within-document event coreference resolution and cannot handle cross-document setting simultaneously, while both are important for better EKG construction. Moreover, existing methods pay little attention to computational efﬁciency. A high-complexity event coreference resolution model will become a bottleneck. Thus, future researches should focus on developing practical, effective, and efﬁcient event coreference resolution methods. 4.1.4 Event Argument Completion Since the information in the original texts is incomplete, and there are some missing in event extraction inevitably, the extracted events usually miss some elements. Event argument completion thus aims to complete existing events, which is generally formalized as inferring and ﬁlling in a missing argument or argument role in an event. Existing methods further formalize this task as a prediction or classiﬁcation task. As illustrated in Fig. 6, the prediction formalization takes known argument roles and arguments, as well as target argument role or argument, as input, and passes them to the feature learner and ﬁller predictor to get the predicted argument or argument role for the target argument role or argument. Then, it is compared with all the arguments or argument roles to get the overall distribution. The argument or argument role corresponding to the peak is selected as the answer to ﬁll in. The classiﬁcation formalization additionally takes candidate ﬁller as input and learns the score of the formed candidate event. Candidate ﬁller corresponding to the maximum score is then selected as the answer. Existing methods differ in the feature learner and ﬁller predictor or score learner. Some relatively early researches learned from the thematic ﬁt task for sentence comprehension, which determines the goodness of ﬁt between the entities and the agent and patient roles of the verb [154]. For example, Tilk et al. [155] proposed a neural network model, which combines the embeddings of argument roles and arguments to get the embeddings of argument role-argument pairs. They added these embeddings together to further combine with the target argument role and then predicted the missing argument. Hong et al. [156] replaced the sum of the embeddings of argument role-argument pairs with their weighted sum and additionally predicted the missing argument role for the target argument. EKG with time can be reorganized as a sequence of graphs according to time. Event argument completion is then conducted based on the time-aware score learner upon the time-speciﬁc embeddings of event elements in the graph sequence. Garc´ıa-Dur´an et al. [157] and Leblay and Chekol [158] integrated the time when the events occurred into the embeddings of event types by concatenating their embeddings. Then, the score learner was designed on these time-aware embeddings of event types and the embeddings of other arguments as their combination operation like TransE [159]. Dasgupta et al. [160] associated each timestamp with a hyperplane. Events valid at a certain time were projected onto the corresponding hyperplane, where the translational scores of arguments via event type [159] were calculated for completion. Xu et al. [161] further attempted to maintain the temporal smoothness between hyperplanes of adjacent time steps by minimizing their Euclidean distances. Differently, Lacroix et al. [162] represented an EKG as a tensor where the orders correspond to event types, time, and other arguments. They then performed tensor decomposition and used the reconstructed tensor to conduct event argument completion. Besides events with exact occur time, TeRo [163] additionally handled events involving time intervals, i.e., having begin time and end time, and accordingly represented each event type as a pair of dual complex embeddings. They then mapped other arguments to these two event type embeddings, respectively, and combined the translation-based scores [159]. Events are typical n-ary relational facts. Thus, completion methods for n-ary relational facts can also be applied to event argument completion. Early studies applied translation-based methods. Wen et al. [164] deﬁned the score learner for each candidate event of candidate ﬁller as the weighted sum of the projection results from its arguments to the hyperplane of its event type, where the weights are the real numbers projected from its argument roles. Then, Zhang et al. [165] additionally introduced the likelihood that two arguments co-participate in a common event via FCN. Liu et al. [166] further considered the relatedness among argument roles, and the compatibility between each argument role and all the involved arguments. Subsequently, tensor-based methods were applied. Liu et al. [167] represented events as a high-order tensor and reconstructed the tensor to make completion. Di et al. [168] further solved the data sparsity problem via partially sharing embeddings and over-parameterization problem by sparsifying the tensor. Recently, neural network-based methods have sprung up. They used CNN [169], [170], [171], [172], FCN [169], [172], [173], GNN [174], [175], and Transformer [174], [176] to learn features, and obtain scores of candidate events or predict ﬁllers. For example, Guan et al. [169] adopted CNN to get the embeddings of argument role-argument pairs. Then, the relatedness of argument role-argument pairs computed by FCN was used to estimate the scores of the candidate events. Differently, Galkin et al. [174] organized events into a graph and applied GCN as the feature learner to get the embeddings of event elements. Then, the embeddings of the known event elements from the feature learner were passed to a Transformer-based score learner to get answer distribution. On the whole, existing studies for event argument completion usually focus on the event itself, while ignoring the relations among events. Introducing event relations may enhance the performance of event argument completion. It is an interesting research direction in the future. Moreover, researchers simplify event argument completion as inferring a missing argument or argument role in an event. However, it is usually not the case in real-world scenarios. More commonly, the argument role and the corresponding argument are both missing. Thus, future studies should pay more attention to more realistic formalizations and methods. 4.2 EKG-related Representative Graphs/Systems With the development of event acquisition, there are some EKG-related representative graphs/systems, targeting a speciﬁc or general domain. Domain-speciﬁc graphs/systems. In 2016, Rospocher et al. [25] constructed four event-centric KGs, i.e., WikiNews in English, FIFA WorldCup in English, Cars in English, and Airbus Corpus in English, Dutch, and Spanish, generated from different kinds of news. These event-centric KGs have more than 624 thousand, 9.3 million, 25 million, and 2.5 thousand events, respectively. Some speciﬁc event-entity relations (i.e., argument roles) and event-event relations are considered as introduced in Section 2.1. In 2017, Li et al. [26] constructed a Chinese travel domain event evolutionary graph from a large-scale unstructured Web corpus. It is a directed sequential relation graph, whose nodes are events (simpliﬁed as verb phrases) and edges are sequential relations between events labeled with transition probability. In 2019, Ding et al. [28] constructed a Chinese ﬁnancial domain event logic graph from plenty of news. It focuses on the causal relations between events, and consists of more than 1.5 million event nodes (i.e., (subject, predicate, object) tuples) and 1.8 million directed edges between event nodes. In 2020, Wu et al. [4] constructed an event-centric tourism KG based on touristic data in Hainan to model the temporal and spatial dynamics of tourists’ trips. Its nodes consist of over 7 thousand journeys, about 87 thousand events, and about 141 thousand entities, while its near 228 thousand edges indicate arguments of events and about 80 thousand temporal relations between events. Each event contains three components, activity, time, and place, and is connected to the its journey via the relation contain. In 2021, Ma et al. [177] presented the ﬁrst event pipeline system, EventPlus, with comprehensive event understanding capabilities to extract event triggers, arguments, duration, and temporal relations among events. It was designed with multi-domain support by multi-domain training. However, in the temporal relation graph therein, nodes represent event triggers and edges represent their temporal relations. The argument information of events is separate. General-domain graphs/systems. In 2018, Gottschalk and Demidova [27] constructed a multilingual event-centric temporal KG EventKG from structured and semi-structured data, and some event-entity, entity-entity, and event-event relations were considered (see Section 2.1). It has over 690 thousand events. It was further extended to EventKG+Click [178] by introducing user interactions with events, entities, and their relations, derived from the Wikipedia clickstream. Besides, based on EventKG, Gottschalk et al. [179] built OEKG (Open EKG) with over 436 million triples by further integrating event-related data sets from multiple application domains, such as question-answering, entity recommendation, and named entity recognition. Also in 2018, Ning et al. [180] proposed a temporal understanding system to extract time expression, event triggers, and temporal relations between event triggers. Argument information was not considered therein. In 2020, Zhang et al. [181] developed ASER (Activities, States, Events, and their Relations), a large-scale English eventuality KG extracted from reviews, news, forums, social media, movie subtitles, and e-books. In ASER, each node is an eventuality, which is a dependency graph, while each edge is a relation between eventualities. In the dependency graph, nodes are the words in the corresponding sentence and edges are the dependency relations between these words. Five categories of relations between eventualities were considered, i.e., temporal, contingency, comparison, expansion, and co-occurrence. The full version of ASER has over 194 million eventualities and 64 million relations. Thus, there are some EKG-related representative graphs/systems developed these years. However, they all consider speciﬁc and limited argument roles or event-event relations. Actually, different events usually do not share argument roles. Moreover, there are various event-event relations in real-world scenarios. There is a need to develop practical EKGs to facilitate downstream applications in the future. With the introduction of events, event-event relations, and event-entity relations, EKG grasps the overall development of events and thus has substantial application value. This section introduces its basic and deep applications. 5.1 Basic Applications Basic applications of EKG are predictions on EKG, which predict future events according to the current EKG. There are two ways to deal with predictions on EKG. The ﬁrst one generalizes the event instances to script events and then predicts the subsequent script events at the script level based on the given historical script events, called script event prediction [182]. The predicted script events can be instantiated to real-world events ﬁnally. The second one predicts future events at the instance level directly. Speciﬁcally, existing methods simplify EKG to temporal KG, formalized as a sequence of KGs of (s, p, o) with timestamps. Then, future prediction is to predict future events for future timestamps given historical temporal KG, called temporal KG prediction [183], [184], [185], [186]. 5.1.1 Script Event Prediction Script event prediction, proposed by Chambers and Jurafsky [182], is formalized as script coherence evaluation, and the script event corresponding to max coherence score is chosen as the answer. Speciﬁcally, Chambers and Jurafsky [182] represented each script event as (subject, predicate) or (predicate, object) pair. Given a script event, they calculated its coherence score with the script by aggregating its coherence scores with all the script events from the script. They used the counting-based function Point-wise Mutual Information (PMI) to measure the coherence score in this process. Finally, the narrative cloze test was adopted to evaluate the method. In this test, one script event in the script is masked, and the others are given. The model is asked to predict the masked script event (in the following, script event is denoted as event for convenience). Following studies improve this model mainly in three aspects: Event representation. The event representation in [182] may lose the co-occurrence information between a subject and its object. Thus, Balasubramanian et al. [43] represented an event as a (subject, predicate, object) triple. Pichotta and Mooney [187] and Granroth-Wilding and Clark [62] further introduced the indirect object into event representation, i.e., (subject, predicate, object, indirect object), which was widely applied in following studies. Then, distributed event representation was applied in recent studies, i.e., represent events as embeddings, to solve the sparsity problem in the above symbolic representations. Event embeddings are typically learned by composing their components. Relatively early studies applied additive composition methods [63], [188], [189]. Speciﬁcally, they summed linearly transformed predicate and argument embeddings. Bai et al. [189] further added the embeddings of the original sentences the events extracted from. Then, Weber et al. [190] and Ding et al. [191] proposed tensor-based event embedding models, which apply the neural tensor network to capture the multiplicative interactions between event elements. To make the tensor-based composition model scalable, Weber et al. [190] learned to generate interaction tensors based on a shared base tensor, whose elements are scaled by the values that depend on a linear transformation of the predicate embedding. To introduce external knowledge, Ding et al. [191] introduced the learning of the intent and the sentiment of the event, and combined their losses with the loss of the tensor-based composition model. More recently, other methods were adopted as composition methods. Lee and Goldwasser [192] applied probability models to learn event embeddings. They represented each event as a sequence of basic event tokens, predicate, arguments, and event properties, such as event sentiment and event animacy. They then learned the probability of others in this sequence given the basic event tokens. They also captured the dependencies between subsequent events via a similar probability model. Granroth-Wilding and Clark [62] and Lee and Goldwasser [193] adopted FCN as the composition method to encode events together with their arguments. Lee and Goldwasser [193] further introduced discourse relations between events via composition operations among them to learn relation-aware event embeddings. Besides obtaining event embeddings via composition methods, Li et al. [64] additionally organized the events into a narrative event evolution graph and applied gated GNN to update event embeddings. Script modeling. Early approaches focused on modeling event pairs in the script, which ignore event order or only consider limited event order between event pair. Different from PMI used in [182], some studies modeled the coherence score of event pairs via Bigram [187], [194], FCN [62], cosine similarity [190], [192], or translation-based composition operation [193]. Other approaches modeled the whole event chain in the script. These approaches applied language model [195], [196], neural network-based probabilistic model [188], or LSTM [63], [197], [198] to model order information of the entire event chain, thus obtained strong temporal order information. In addition, after integrating temporal order information, Wang et al. [63] and Li et al. [64] also took advantage of event pair-based models. Different from these single-chain models, Chambers and Jurafsky [54] and Bai et al. [189] further aggregated the results from multiple event chains. Other than a chain, Li et al. [64] and Ding et al. [191] organized the events in the script into a narrative event evolution graph and adopted GNN to model this graph. Then, they predicted the subsequent event by aggregating the coherence scores of event pairs, computed by the similarity of their embeddings from GNN. Evaluation. One drawback of the narrative cloze test proposed by [182] is that it cannot recognize multiple plausible events, since only the original subsequent event is viewed as the correct answer. Thus, Modi [188] introduced the adversarial narrative cloze test. This test requires models to distinguish a correct chain from a negative chain, where the negative chain is a copy of the correct chain with the subsequent event replaced by a random event. Granroth-Wilding and Clark [62] further proposed the Multiple Choice Narrative Cloze (MCNC) test. As shown in Fig. 7, this test restricts the answer event to a few choices, and the models are required to select the correct subsequent event from these candidates. Based on MCNC, subsequent research proposed two variants, Multiple Choice Narrative Sequences (MCNS) and Multiple-Choice Narrative Explanation (MCNE), to evaluate models’ ability to infer longer events sequences [192]. MCNS creates multiple candidates for each step, except the start event. Whereas MCNE additionally requires the end event provided and infers what happened in between. Among all these evaluation tasks, the MCNC is widely used to evaluate the performance of script event prediction. In a word, as presented above, there are two ways to represent script. The ﬁrst way is the entity-centric representation method, which organizes the script events into event chains according to different participants. The studies that model event pairs or event chain usually follow this way. The other way is the event-centric representation method, which organizes all script events in a document into a graph and is an emerging representation method. Generally speaking, the entity-centric method is better at modeling the relations between the participant and its script events, while the event-centric method is better at modeling the interactions of script events where different entities participate. It remains to be studied how to combine the advantages of both methods. There are also some other challenges in script event prediction. For example, how to really predict the subsequent script event rather than choosing the answer from several given candidates? How to combine the information from event instances and that from script events? 5.1.2 Temporal KG Prediction Predicting future events at the instance level requires models to understand historical events. Thus, as shown in Fig. 8, existing methods for temporal KG prediction formalize this task into two steps, history modeling and future prediction. At the ﬁrst step, existing approaches focus on understanding historical events and modeling their evolution. Based on this, existing approaches predict future events and output a distribution over all the events at the second step. The event of the highest score is chosen as the answer. According to the organization and corresponding modeling approaches of historical events, methods for temporal KG prediction can be split into two categories, methods based on graph sequence model and methods based on temporal point process. As a temporal KG is a sequence of KGs, the former organizes historical events as a sequence of graphs where each graph contains the events that occurred at the corresponding timestamp. The latter considers historical events as event points and usually ignores the concurrent events at the same timestamp. Graph sequence-based methods. In history modeling, existing methods of this type usually extract related history ﬁrstly, which is a subgraph sequence. After that, they represent the graph sequence as a hidden vector or directly learn the evolutional embeddings of subjects, predicates, and objects. In the process of future prediction, they perform argument prediction, i.e., subject/object prediction (and predicate prediction) via calculating the distribution of all the candidate arguments (or predicates) based on the hidden historical vector of graph sequence or the evolutional embeddings of event elements. Existing methods mainly differ in the process of related history extraction. Some methods extract partial historical events related to the focused subject and predicate via heuristic manners. Jin et al. [185] extracted repetitive historical events of the given subject and predicate to predict the object, while Jin et al. [186] extracted historical events of the given subject. Although many heuristic methods can be designed to extract related history, these methods depend on human knowledge and may ignore important historical events. Different from the above heuristic extraction methods, Han et al. [199] started from the given subject, iteratively sampled relevant edges of arguments included in the subgraph, and propagated attention scores with the given subject and predicate along the sampled edges. For each argument in the subgraph, they only allowed message passing from the prior neighbors, i.e., the neighbors before the occurring time of the argument, to preserve the causal nature of the temporal data. Based on attention scores, they computed the scores of entities to be the object. Li et al. [200] and Sun et al. [201] considered history extraction as a sequential decision problem and searched from history via a reinforcement learning-based method. Unlike the above subgraph sequence-based methods, Li et al. [202] directly used the entire graph sequence at the last several timestamps. By stacking a relation-aware GCN, they obtained the evolutional embeddings of subjects, predicates, and objects at the ﬁnal timestamp. They additionally introduced an external KG to regularize these embeddings. These studies model the temporal KG in a discrete-time domain. They take snapshots of the temporal KG sampled at regularly-spaced timestamps and cannot model irregular time intervals. To encode the continuous dynamics of temporal KG, Ding et al. [203] proposed a continuum model by extending the idea of neural Ordinary Differential Equations (ODE) [204] to GCN. Before the ODE solver, they applied a GCN that captures the graph’s structural information according to the observation at the current time. They further adopted a graph transition layer to catch the edge formation and deletion information explicitly. Temporal point process-based methods. Here, a temporal point is an event point. Temporal point process-based methods introduce conditional intensity function, which is powerful for modeling the evolutionary characters of these temporal points, to do history modeling and future prediction in a uniﬁed framework. Traditional temporal point process-based methods are always parametric models where the conditional intensity function is manually prespeciﬁed [205], [206]. Besides, they can only model events without considering the semantics of the subjects, predicates, and objects. Some recent works [183], [184], [207] extended traditionally temporal point process-based methods to neural ones, which use deep neural networks to ﬁt the conditional intensity function. Neural temporal point process-based models are powerful in considering the semantics of the event elements. For example, Trivedi et al. [183] applied deep RNN to learn the evolutional embeddings of arguments and conducted event argument prediction by estimating the conditional probability of an event based on the evolutional embeddings of the involved arguments and the embedding of the predicate. That is, the occurrence of an event was modeled as a multivariate point process, whose conditional intensity function was modulated by its score based on the involved embeddings. This method is more capable of modeling events occurring continuously, where no events may occur at the same timestamp. To further model concurrent events, Han et al. [207] aggregated the embeddings of the objects in the concurrent events related to the given subject into a hidden vector via element-wise mean operation. Then, they modeled time as a random variable and deployed the Hawkes process [208] on temporal KG to capture the underlying dynamics, where a continuous-time LSTM was used to estimate the intensity function. In general, all the existing temporal KG prediction methods focus on the events with only three arguments (i.e., subject, object, and time) and usually perform argument prediction or predicate prediction with other elements of future events given. Thus, there are still several challenges for temporal KG prediction. For example, how to model historical events with various arguments? How to practically predict future events on the whole, rather than require that only one element of each future event is unknown? 5.1.3 Other Basic Applications There are also some direct analyses on EKG, such as timeline generation and abductive reasoning. For example, Gottschalk and Demidova [209] generated cross-lingual event timelines using the multilingual event-centric temporal KG EventKG [27]. Speciﬁcally, for a query entity or event, they relied on EventKG to provide information concerning the event popularity and the relation strength between events and the query. Gottschalk and Demidova [210] and Gottschalk and Demidova [211] addressed the task of biographical timeline generation. For a query person, they extracted the most relevant biographical data from EventKG, concisely describing a person’s life. Features, such as event popularity, relation strength, and predicate labels, were used therein. Du et al. [212] proposed an event graph enhanced pretrained language model based on variational autoencoder for abductive reasoning, which ﬁnds the most reasonable explainable events for the observed events. Speciﬁcally, they adopted an additional hidden variable to capture necessary knowledge from the event graph. 5.2 Deep Applications EKG can further facilitate many downstream applications, such as search, question-answering, recommendation, and text generation. For example, Rudnik et al. [1] developed an event-based search engine capable of querying both the structured data of KGs and the unstructured textual contents of news articles to promote the search ability. Speciﬁcally, they mapped events described in news articles to events in Wikidata [213], and attributes from Wikidata instances were used to annotate the news articles when possible. They then automatically created a coarser-grained schema. Finally, they implemented an event-oriented KG and an event-based search engine. Yang et al. [2] implemented a temporal semantic search system for clinical diagnosis and treatment of traditional Chinese medicine. This search system consists of the online part and the ofﬂine part. The ofﬂine part is mainly about the construction, storage, and indexing of the temporal KG, and the online part is mainly about the understanding, conversion, and execution of the search sentences. Souza Costa et al. [3] addressed answering event-centric questions and adopted EventKG [27] to create queries. They constructed the ﬁrst questionanswering dataset focusing on event-centric questions and the only question-answering dataset that targets EventKG. Wu et al. [4] proposed an event-centric tourism KG CNN for Point-of-Interest (POI) recommendations, which incorporates tourists’ behavior patterns obtained from eventcentric tourism KG, to capture the relations between users and POIs more effectively. They thus improved the accuracy of recommendations. Colas et al. [5] focused on graph-totext generation to better serve the structured information in the graph in a user-friendly manner. For each event from the event-centric temporal KG EventKG, they augmented the data with additional information from Wikidata and linked the event to a Wikipedia page for text generation. There are many researches and achievements on EKG. However, there are still several directions to be focused on and investigated further. In this section, we look deep into these future directions. 6.1 High-performance Event Acquisition Recent event acquisition researches are far from meeting the application requirements in effectiveness and efﬁciency. Especially, the precision of event extraction and event relation extraction is low. Thus, it hinders the construction of highquality basic EKGs. Besides, existing models usually do not pay attention to the complexity problem. However, models of high parameter complexity and high time complexity go against the fast construction of EKGs from massive data. Thus, event acquisition of both high effectiveness and high efﬁciency is an essential direction in the future. 6.2 Multi-modal Knowledge Processing Events may be presented in texts, images, audios, and videos in the real world. However, existing studies on EKG usually only focus on text processing, ignoring the huge amount of information in images, audios, and videos. Only very few researches look into multi-modal event representation learning [214] and event extraction [215]. Actually, events from different modalities can disambiguate and complement mutually. Thus, jointly using multi-modal information is an important future direction. Speciﬁcally, events from all modalities should be represented in a uniﬁed framework, event acquisition researches should pay attention to multi-modal extraction, and reasoning on EKG should also consider the multi-modal information. 6.3 Interpretable EKG Research In EKG research, studies mainly focus on deep learning methods to ﬁt the training data. However, they usually lack interpretability, i.e., there are no deﬁnite ideas about why and how they work. Actually, knowing the reasons for the ﬁnal results is useful for adopting them in real applications. It is friendly and convincing to provide explanations for why the ﬁnal results are the given ones. In the future, interpretable EKG research is an important direction. 6.4 Practical EKG Research In the related tasks of EKG, some task formalizations are so idealized, far from real-world scenarios. For example, complete only a missing argument or argument role in an existing event, predict future script event via choosing it from several candidates, and predict only an element for a future event. Researches under more practical formalizations are more challenging but more interesting, and of great importance for applications. EKG is important for many applications, including intelligent search, question-answering, recommendation, and text generation. This paper presents a survey on EKG from different views comprehensively. Specially, we looked deep into the history, ontology, instance, and application views of EKG. Its history, deﬁnitions, schema induction, acquisition, related representative graphs/systems, and applications are thoroughly studied. Based on the development trends therein, perspective directions are further summarized for future research on EKG. The work was supported in part by the Lenovo-CAS Joint Lab Youth Scientist Project, in part by the Foundation and Frontier Research Key Program of Chongqing Science and Technology Commission (No. cstc2017jcyjBX0059), in part by the Youth Innovation Promotion Association CAS under Grant 20144310, in part by the National Natural Science Foundation of China under Grants 62002341, U1911401, 61772501, U1836206, and 91646120, and in part by the GFKJ Innovation Program.