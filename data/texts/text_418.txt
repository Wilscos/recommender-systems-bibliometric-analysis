<title>Advances in Scaling Community Discovery Methods for Large Signed Graph Networks</title> <title>Maria Tomasso Lucas Rusnak Jelena Teˇsi´c Oct 15 2021</title> <title>1 Introduction</title> The rise of social media interactions has illuminated an increasing necessity for a robust understanding of social network analysis, and social network theory has provided explanations for a variety of social phenomena ranging from individual creativity to corporate proﬁtability. <title>arXiv:2110.07514v1  [cs.SI]  14 Oct 2021</title> Community discovery has proven valuable in many areas of application, including detection of bot activity and fraud in criminology, identiﬁcation of customer segmentation in marketing, characterization of astroturﬁng in political science, detection of cancers via diagnostic imaging, and quantiﬁcation of environmental hazards in public health [24]. In an era dominated by social media communication, the community detection tools developed speciﬁcally from social network theory can help researchers understand trends and propagation patterns within online communities [37]. Users are generally represented as vertices (nodes) in a graph, while edges are deﬁned based on users’ friendships and interactions with posts or re-posts; they are generally based on any social interaction on a media platform between users. A plethora of methods has been proposed to transform social media interactions in a simple graph network where edges exist along user interactions, but do not exist if the connection is unknown. With the increased richness of social media interactions and additional information in the types of interactions that can exist in the social networks today (e.g., reviews, comments, shares, friends, blocked users), researchers have turned to richer interpretations of the edges in graph networks (signs, weights), recently turning their attention to the use of signed graph networks [12]. A community within a network is deﬁned as a partitioning of nodes such that nodes within the same cluster are strongly connected, while nodes in diﬀerent clusters are weakly connected; in essence, similar nodes should be grouped together. In real data sets, community structure is almost always present to some degree [15]. Community detection in unsigned networks traditionally relies on the absence of connections between vertices (e.g., users) to determine if they belong in diﬀerent communities. The presence of negative links provides aﬃrmative evidence of their dissimilarity, allowing the use of richer signed network analysis for community detection. When negative edges are included in a network, we can study social dynamics and stability in respect to friendship and enmity in more depth [2, 29], or expand to new application domains such as the behavior of the brain [40]. In this paper, we present an overview of the work that has been done on community detection in signed networks to date. The methods are divided into two top level categories: methods adapted from unsigned methods and methods that work only for signed graphs, with additional subcategories. We then compare state-of-the-art methodologies on small signed networks with known ground-truth communities and compare their ability to recover the ground-truth labels based on edge signs alone. Finally, we evaluate the scalability in terms of eﬀectiveness and eﬃciency of leading clustering methodologies on real signed networks [30]. Signed graph deﬁnitions are outlined in Section 2, while Section 3 describes unsigned clustering methods adapted for signed graphs, and Section 4 reviews novel methods that utilize signed graph characteristics such as balance or the random walk gap. Prior Surveys: A comprehensive survey on mining techniques for signed graphs [45] includes several community detection methods. The survey had a much broader scope on signed graph analysis, from node ranking, classiﬁcation, and embedding, over link and sign prediction, to information diﬀusion and recommendations in signed graphs [45]. In the same year, a survey of spectral clustering methods for unsigned and signed graphs was published [14]. This survey provides a thorough overview of spectral methods and Laplacian variants for both unsigned and signed graphs. In this paper, we focus on community detection in signed graphs and provide a comprehensive examination of spectral methods and nonspectral methods for community detection with respect to incremental development and suitability based on data characteristics. Reference Searching: In the ﬁrst stage of the literature review, both forward and backward reference searching were used to ﬁnd signiﬁcant contributions to the ﬁeld. After forward and backward reference searching, a systemic literature review was conducted to ﬁnd any publications on signed graph clustering that were previously missed. The following search terms were used: “signed” AND “graph” AND “clustering” and “signed” AND “graph” AND “community” AND “detection”. All results were saved and manually reviewed for relevance. <title>2 Signed Graph Deﬁnitions and Methods</title> A graph G consists of two disjoint sets: a set of vertices v , v ∈ V and a set of edges e, e ∈ E. In this paper, graph and network can be assumed to be synonymous. Graphs can be directed or undirected. In a directed graph, an edge may connect node i to node j without node j necessarily being connected to node i. In an undirected graph, if node i is connected to node j, then node j must be connected to node i. A graph can be weighted, which means that each edge has a ’weight’ attribute that can represent the strength of the connection. In a signed graph, edges are assigned +1 or -1 weights. In graph theory, a signed graph is balanced if the product of edge signs around every cycle is positive. In a complete graph, every pair of vertices is connected by an edge. A complete graph is weakly balanced if and only if it can be divided into multiple sets of mutual friends, with complete mutual antagonism between each pair of sets. The graph density d of undirected graphs is the ratio of the number of edges e with respect to the maximum possible edges in a fully connected graph with v vertices; see Eq. 1. A dense graph is a graph with a number of edges close to the maximum number of edges. With density scores of 0.483, 0.782, and 0.225 respectively, Highland Tribes [38], Sampson [41], and Correlates of War [42] are three examples of real-world signed and dense graphs. A sparse graph has very few edges relative to the number of nodes. A planar graph is a graph that can be embedded in the plane; it can be drawn in such a way that no edges cross each other. Planar graphs are sparse graphs, in that they have only O(v) edges. Note that not all sparse graphs are planar graphs even if the inequality holds. Planar graphs are a subset of sparse graphs, and none of the clustering methods for community discovery analyzed in this paper are conditioned by the planarity of the graph. Most social media networks have a high number of vertices (users) v and relatively small number of edges e as they are only connected to a small fraction of the overall community. The Wikipedia Election [30], Epinions [30], and Slashdot Zoo [30] data sets are large-scale, sparse signed networks that are not planar. <title>2.1 Signed Graph Community Discovery in the Past Century</title> A community in graph theory is deﬁned as a cluster of nodes such that nodes within the cluster are densely connected to other nodes within the cluster and sparsely connected to those outside of the cluster. A community in signed graph theory is a community (cluster) of vertices (nodes) that are connected with dominantly positive edges within the cluster and connected to vertices outside of the cluster with dominantly negative edges. As a signed network graph innately represents expressed opinions between entities (vertices) through edge signs between them, the signed graph balancing model proved successful in social science in the 20th century, e.g., modeling diplomatic relations in the Middle East [35], South Asia [36], and Allied and Axis powers during World War II [4]. Social balance theory, described in Section 4.2, is a branch of signed graph theory proposed by [20] and developed by [18] in the 1940s and 1950s. It allows certain well-behaved graphs to be ’perfectly’ partitioned so that negative edges exist only between clusters, and positive edges exist only within clusters. In the real world, however, such well-behaved data sets are rare. In this paper, we survey the signed graph community discovery methods of the 21st century. These techniques generally fall into two categories, and we explore them in the following sections: (1) in Section 3, we review the signed graph adaptations from algorithms developed for unsigned graphs using discrete optimization techniques; (2) in Section 4, we review novel methods that utilize signed graph characteristics such as balance or the random walk gap. <title>3 Adaptations of Unsigned Spectral Clustering Methods to Signed Graph Clustering</title> <title>3.1 Clustering for Unsigned Graphs</title> Before examining methods for signed graphs, the algorithms developed for unsigned graphs must be understood. The simplest non-trivial case in undirected graph clustering is 2-way partitioning. This involves separating the nodes of the graph into two groups such that nodes in the same group are strongly connected and nodes in opposite groups are weakly connected. To accomplish a 2-way partitioning, two items are needed: (1) a criterion that deﬁnes a ’good’ partition, and (2) a method to eﬃciently optimize the criterion. Criteria for 2-way Partitioning Many criteria have been proposed for 2-way graph partitioning. The ﬁrst measure we will introduce for assessing 2-way clustering of a graph is the graph cut. For an unsigned graph G with disjoint clusters X and Y, the 2-way graph cut is deﬁned as cut(X, Y ) = . The cut is essentially the number of edges or, for a weighted graph, the sum of weights between clusters. Since the typical goal of clustering is to group densely connected nodes together, choosing X and Y to minimize the cut is a good ﬁrst step. Unfortunately, the cut does not account for the size of clusters, and the optimal solution can separate few or single vertices if applied as is. To remedy this, the ratio cut is introduced. For an unsigned graph G with disjoint clusters X and Y, the 2-way ratio cut is deﬁned as rcut(X, Y ) = cut(X, Y )( ). The ratio cut takes the size of the clusters into consideration by minimizing the graph cut relative to the sizes of each cluster. Shi and Malik reﬁne the ratio cut to consider the strength of the connection of the nodes in X and Y to the rest of the graph with the normalized cut [43]. For an unsigned graph G with disjoint clusters X and Y, the 2-way normalized cut is deﬁned as ncut(X, Y ) = cut(X, Y )( ), where vol(P ) represents all of the weights of all edges adjacent to nodes in the cluster P . By including volume in the normalized cut objective, the cut is minimized relative to both the size of the clusters and the connectivity of the graph. Extending the Criteria to k-way Partitions Real networks have more than two communities and a need for eﬃcient k-way partitioning algorithms. The 2-way partitioning algorithms provide a simple recursive technique to perform k-way partitioning [43]. First, partition the graph into two clusters, then recursively run the 2-way partitioning algorithm separately on the subgraph for each cluster. While this technique can be eﬃciently computed, it ignores the higher-order spectral information of the graph. As an alternative, k-way generalizations of the ratio cut and normalized cut have been introduced and are deﬁned as follows: for an unsigned graph G with disjoint clusters X ,...,X , the k-way ratio cut is deﬁned as rcut(X , ..., X ) = and the k-way normalized cut is deﬁned as ncut(X , ..., X ) = . From [43], we know that 2-way partitions can be solved eﬃciently for unsigned graphs. Unfortunately, the same is not true for k-way partitions, and ﬁnding a global optimum is NP-complete for most graphs. Thus, approximation methods are used to estimate solutions to the k-way criteria. Researchers initially tried to use greedy algorithms and gradient descent to ﬁnd solutions to k-way clustering problems, but these approaches often failed to ﬁnd a global optimum due to the high dimensionality of graph data and nonlinearity of the criteria. As an alternative, Shi and Malik developed a technique for approximating k-way normalized cut solutions by formulating them as generalized eigenvalue problems [43]. This approach became known as spectral clustering; twenty years later, it is still considered to be a foundational algorithm in graph clustering. Spectral clustering begins by ﬁnding the Laplacian of the matrix representation of the network. Since several variants of the Laplacian exist, there are multiple versions of the spectral clustering technique. After ﬁnding the Laplacian, the eigenvalues are computed. Note that the algorithm assumes that all eigenvalues of the Laplacian are non-negative (i.e., the Laplacian is positive semideﬁnite), and that the eigenvalues of the Laplacian can be eﬃciently computed. After the eigenvalues are found, they are plotted in increasing order, and the eigengap, the largest ’early’ increase in sequential eigenvalues, is identiﬁed. The location of the eigengap provides options for the value of k, the number of communities in the graph. After identifying the number of clusters, k-means can be applied to cluster the communities [43]. The Laplacian matrix of an unsigned graph G is deﬁned as L = D − A. D, the degree matrix, is a diagonal matrix such that the (i, i) entry represents the degree of vertex v A, the adjacency matrix, contains edge weight information such that entry (i, j) represents the weight of the edge between vertices v and v . If no such edge exists, the entry is 0. The spectral clustering algorithm is described in Alg. 1 and consists of four steps: (1) calculate the Laplacian L (or the normalized Laplacian); (2) calculate the ﬁrst k eigenvectors (the eigenvectors corresponding to the k smallest eigenvalues of L); (3) consider the matrix U formed by the ﬁrst k eigenvectors; the i row deﬁnes the features of graph node i; (4) cluster the graph nodes based on u features using k-means clustering as outlined in Section 3.1.2 and in Alg. 2. Since minimizing the normalized cut is NP-complete, the goal of the original and all subsequent spectral clustering algorithms is to ﬁnd an approximate discrete solution eﬃciently. The two central problems of spectral clustering are the criterion that determines if a partition is ’good’ and how partitions ﬁtting the above criterion can be eﬃciently computed. Laplacian Variants The standard graph Laplacian matrix as deﬁned in Section 3.1.1 is symmetric and positive semideﬁnite, meaning the eigenvalues are real and non-negative [46]. Additionally, two normalized variants of the Laplacian are commonly used in clustering, and they are deﬁned as follows: the symmetric normalized Laplacian is L = D LD and the random walk Laplacian is L = D L. For undirected graphs, both L and are positive semideﬁnite and have real, non-negative eigenvalues [46]. Eigenvalue computation is often expensive and prone to error for very large matrices, so if reasonable bounds on the problem are known (i.e., the maximum number of clusters), the problem can be reduced to ﬁnding the k smallest eigenvalues. The eigengap heuristic in spectral clustering indicates the number of clusters to use, but for noisy data sets the eigengap may be relatively small and diﬃcult to detect. If the eigengap is large, however, the ﬁrst k eigenvalues can be computed relatively eﬃciently through the use of Krylov subspaces or the power method [46]. The k-means algorithm is used to partition a given set of observations into a predeﬁned amount of k clusters. The algorithm starts with a set of k center-points and goes through multiple iterations to ﬁnd optimal cluster centroids C , ..., C . Here, we present the kmeans++ algorithms used in experimental comparisons in Section 5. The k-means++ algorithm distributes the initial centroids over the given data to minimize the probability of bad outcomes[3] by a very simple randomized seeding technique, as illustrated in Algorithm 2. During each update step t in Alg. 2, all observations x are assigned to their nearest centerpoint S . Afterwards, the center-points C are repositioned by calculating the mean of the assigned observations to the respective center-points. The update process reoccurs until the center-point update distance d(C , C ) is smaller than the speciﬁed limit, as show in Alg. 2. As there is only a ﬁnite number of possible assignments for the amount of centroids and observations available, and each iteration has to result in a better solution, the algorithm always ends in a local minimum. k-means++ approximately can be computed in O(log n) time [3]. Algorithm 2 k-means++ [3] Step 1: Select centroids C , C , ...C by taking uniformly a random data point from the data X and mark it as centroid C for s doelect centroid C , i ∈ [2, k] Choose C = x, max ), D(x) = min (d(x, C )) end for Step 2: Iteratively compute new centroids for all data X Iteration 0: t = 0, t = limit while dot ≥ limit t = 0 for doi, i ∈ [1, k] The weighted kernel k-means clustering family of algorithms improves k-means clustering by introducing the weighted kernel approach, which maps the data to a higher-dimensional space and allows the separation of nonlinear components [10]. Kernel function can be polynomial, Gaussian, or Sigmoid, and the correct choice depends on target data characteristics. For weighted kernel k-means clustering, we need to choose the kernel matrix K ﬁrst. If an input matrix is given, it is the weighted kernel matrix. If a standard graph partitioning objective is being used, we obtain the initial clusters using one of the following initialization methods: random, spectral, negative σ shift, or METIS [25], a fast, multi-level graph partitioning algorithm that produces equally sized clusters. After we obtain initial clusters, we make kernel matrix K positive deﬁnite by adding to the diagonal. Finally, we oscillate between running batch weighted kernel k-means and incremental weighted kernel k-means (local search) until convergence. The sensitivity of the approach lies in the selection of the kernel matrix. Algorithm 3 Batch Weighted Kernel K Means Clustering [10] The described spectral approach of ﬁnding eigenvectors, then performing clustering on features derived from eigenvectors, and its extensions and improvements proved to be highly eﬀective on unsigned graphs. In the next section, we present the adaptations of unsigned graph clustering by applying spectral methods to signed graphs. <title>3.2 Spectral Methods for Signed Graphs</title> Spectral clustering cannot be immediately applied to signed graphs without prior modiﬁcations. The standard Laplacian matrix of a signed graph is indeﬁnite [28] and will not yield real, non-negative eigenvalues. Spectral clustering assumes that all the eigenvalues of the Laplacian are nonnegative and real. Moreover, accurate and eﬃcient eigenvalue computation for large and sparse matrices is an open problem without signed graph extension. Thus, any method seeking to adapt spectral clustering to signed graphs must ensure that (1) eigenvalues are real and non-negative, and (2) the new procedure is scalable to large networks. How do we compute a Laplacian for a signed graph and ensure that it is positive semidefinite? The Laplacian matrix introduced in [28] is indeﬁnite, and modiﬁcations were made using the signed degree matrix, with the signed Laplacian matrix of a graph G as L = D−A, where D is the signed degree matrix given by A . Kunegis et al. [28] demonstrated that this signed Laplacian is positive semideﬁnite and, in some cases, positive deﬁnite, thus guaranteeing this Laplacian is a suitable basis for spectral clustering. Moreover, spectral clustering using the signed Laplacian is shown to be equivalent to the k-way signed ratio cut problem, which counts positive edges between clusters and negative edges within clusters [28]. A more natural signed graph Laplacian that possesses the expected relationship to its underlying incidence matrix as well as the signed-path property on the adjacencies was ﬁrst presented in [50] Symmetric normalized Laplacians tend to yield better results than unnormalized Laplacians for graphs with skewed degree distributions [28]. Kunegis et al. propose two ways of normalizing signed Laplacians. First, they deﬁne the random walk normalized Laplacian for signed graphs as = I − A and show that the matrix is positive semideﬁnite [28]. Second, they deﬁne the symmetric normalized Laplacian for signed graphs as = I − , where I is the identity matrix. The signed Laplacian matrix of a graph is positive-deﬁnite if and only if the graph is unbalanced [28]. For a signed graph G, the signed graph cut is given by scut(G) = 2 ⋅ cut (X, Y ) + cut (X, X) + cut (Y, Y ). The signed ratio cut is given by SignedRatioCut(X, Y ) = scut(X, Y )( ). The signed normalized cut is given by SignedNormalizedCut(X, Y ) = scut(X, Y )( ), where vol(X) and vol(Y ) represent the sum of the degrees of the nodes in X and Y, respectively. The balanced normalized signed Laplacian is proposed by Zheng et al. [51] as an extension of the normalized signed Laplacian deﬁned in [28], with an embedding map rather than an index of partitions. This yields additional information on the similarity between nodes rather than simply assigning cluster labels. Additionally, the authors argue that an embedding map is more likely to yield an approximate global solution rather than local optima. Zheng et al. take a two-step approach: (1) the Rayleigh quotient of the random walk normalized Laplacian is used as an objective function to achieve the embedding, and (2) an objective function derived from the normalized signed cuts in [28] is used to complete clustering. Geometric Laplacian means are proposed as a way to address shortcomings in [51] and its inability to recover ground-truth labels in real data sets. The arithmetic mean of the positive-edge and negative-edge Laplacians introduces noise to the embedding of the data points, and with the arithmetic mean the smallest eigenvectors of the Laplacian do not necessarily correspond to the smallest eigenvalues. The authors propose the use of the geometric mean of the positive-edge and negative-edge Laplacians to remedy these issues, although they concede that the geometric mean is more computationally expensive than the arithmetic mean and not well-suited to large, sparse networks [31]. The latest work modiﬁes the Laplacian by combining the positive and negative Laplacians using the matrix power means [33]. This approach further improved the results, as we will demonstrate in Experiment 1. <title>3.3 Non-Spectral Optimization For Signed Graphs</title> given by max . The balance ratio cut combines the positive ratio cut with the negative ratio association and simultaneously minimizes the number of positive edges between clusters while minimizing the number of negative edges within clusters. It is given by min . The balance ratio association combines the negative ratio cut with the positive ratio association and simultaneously maximizes the number of positive edges within clusters while maximizing the number of negative edges between clusters: The balance normalized cut is very similar to the balance ratio cut, except it normalizes the clusters by volume instead of number of nodes. It is given by min Similarly, the balance normalized association can be derived from the balance ratio association and is given by max . Minimizing the balance normalized cut is equivalent to maximizing the balance normalized association. Thus, the choice between balance normalized cut and association is inconsequential [5]. Chiang et al. proposed a multilevel framework that reﬁnes results by ﬁrst dividing vertices into levels, and then applying their modiﬁed version of spectral clustering to each level. Here, the hierarchical approach to graph clustering increases algorithm scalability, and an 100 million edge graph is partitioned in under 4000 seconds [6]. as possible. The algorithm relies on a generalized eigenproblem formulation to ﬁnd the k smallest eigenvectors before k-means clustering. The approach was inspired by constrained clustering [47], and the authors provide theoretical guarantees for our approach in the setting of a signed stochastic blockmodel [8]. For a given signed graph G, the objective function for SPONGE is derived from the normalized cut of the positive-edges subgraph ncut(G ) and the inverse normalized cut of the negative-edges subgraph (ncut(G )) . The trade-oﬀ and regularization parameters τ and τ are introduced, and the previous metrics are merged into the new objective function in Eq 3. C , . . . , C represents a partitioning of G. The authors demonstrate that the prior objective function is equivalent to the discrete optimization problem in Eq 4. The discrete optimization problem in Eq 4 is NP-hard, so the authors relax the discreteness constraint on the x ’s and allow solutions that are in R . New vectors z , . . . , z ∈ R are introduced such that z (L + τ )z = 1) and z (L + τ )z = 0f ori ≠ j, i.e., they are orthonormal with respect to L + τ + D . Finally, the objective function can be rewritten as in Eq. 5. Objective function in Eq. 5 can be formulated as the generalized eigenproblem whose solution is given by the eigenvectors of (L + τ (L + τ )(L + τ [8]. The authors use LOBPCC [26] to solve for the eigenvectors corresponding to the k smallest eigenvectors and cluster the resulting node embedding using k means++ 2. The output of the k-means++ step is the ﬁnal cluster labeling for the graph from the SP ON GE procedure. Alternately, SP ONGE ym uses the symmetric signed Laplacian, deﬁned as = (D (D in the prior equations. SP ONGE and SP ONGE compared favorably against other leading signed spectral clustering algorithms in experiments performed by the authors, and we evaluate it further in Section 5. <title>4 Novel Clustering Methods for Signed Graphs</title> In this section, we review all clustering algorithms developed speciﬁcally for signed graphs. Early work in this ﬁeld was heavily constrained by computational technology and focused on smaller, denser networks. While eﬀective at the time, we note that some of these methodologies do not necessarily translate well to the large, sparse networks that are the focus of most modern research. <title>4.1 Blockmodels for Small Dense Networks</title> Let S be a set and let {R be a set of binary relations on S. Individuals a, b ∈ S are said to be structurally equivalent if and only if for any c ∈ S and any R ∈ {R aR c ⇐⇒ bR c and cR a ⇐⇒ cR b. In graph theory terms, the structural equivalence of two nodes means that both nodes are adjacent to exactly the same set of nodes with the same edge weights. Since this occurrence is very rare in real data sets, the authors used the concept of a blockmodel to relax the deﬁnition of structural equivalence. In a blockmodel, if the same permutation is applied to both the rows and the columns of the adjacency matrix, the underlying network structure is not changed. Blockmodels seek to permute the data in such a way that submatrices of all 0s exist within the adjacency matrix, as illustrated in Figure 3. The adjacency matrix is then divided into blocks, with a block being assigned a value of 0 if all entries within it are 0 and 1 otherwise. Nodes in the same block are assumed to be structurally equivalent if the value of the block is equivalent, thus relaxing the prior deﬁnition of structural equivalence to ﬁt real-world data sets. Lean Fit Breiger et al. build on the concept of blockmodels to develop their system for clustering signed data [48]. A blockmodel is said to be a lean ﬁt to a matrix M if and only if there exists a permutation of M, yielding a permuted matrix M that can be blocked in such a way that (1) zeroblocks in M correspond to 0s in the blockmodel, and (2) blocks in containing at least one nonzero value have a corresponding value of 1 in the blockmodel. While a lean ﬁt falls short of the algebraic deﬁnition of structural equivalence, the authors rationalize this decision by arguing that maintaining a social tie requires eﬀort, while no work is required in the absence of a tie [48]. Thus, it is appropriate to assign any block with nonzero values an overall value of 1 in the blockmodel. The authors further emphasize that nonzero blocks do not need to be true cliques or fully connected subgraphs. Limitations For a graph with n vertices, there are n! possible permutations (and thus blockmodels) of the vertices. The ﬁrst limitation is that exhaustively checking all possible blockmodels quickly becomes impractical, even on relatively small graphs. The second limitation is that once a blockmodel is chosen, the blockings must still be enumerated and checked for a lean ﬁt. The third limitation is the upper limit on number of blockings and the resulting clustering interpretation. The CONCOR (CONvergence of iterated CORrelations) algorithm repeatedly applies bipartitions to the raw data until a hierarchical clustering at the appropriate level of granularity is established [48]. Ordinary product moment correlation coeﬃcients between the columns of the input matrix are computed at each iteration and stored in a correlation matrix. The process is repeated on the correlation matrix until convergence is reached, i.e., there is no change in the matrix between iterations. Once convergence is reached, a clear bipartition emerges. The process is then repeated on each partition to identify sub-clusters. CONCOR does no optimize a speciﬁc metric; it exhaustively checking all possible blockmodels and checking blockings for a lean ﬁt. This makes the algorithm prohibitively slow when applied to large and sparse signed graphs [48]. <title>4.2 Heider Balance Theory Based Methods</title> Clustering for Balanced Signed Graphs Social balance theory was introduced by Fritz Heider in 1946 [20] and mathematically formalized by Cartwright and Harary in 1956 [18]. A signed graph is balanced if and only if (1) all of its edges are positive, or (2) the nodes can be partitioned into two distinct clusters so that all edges within a cluster are positive and all edges between clusters are negative. Such a partition is known as a Harary cut, as illustrated in Figure 4 for a balanced signed graph with 4 nodes and 5 edges. The clustering approach for the balanced signed graphs reduces to a 2-step process as illustrated in Algorithm 4. While clustering adaptation for balanced signed graphs is simple, balanced graphs are rare in real-world data. A Harary cut provides a natural cut to examine clusters with similar sentiments. A new robust signed graphic generalization of normalized cuts using nearest Harary cuts recently appeared in [39]. Algorithm 5 Clustering a weakly balanced signed graph [1] weakly balanced, it is said that an underlying community structure exists in the graph. The signed clustering extension for weakly balanced graphs is outlined in Algorithm 5. Note that weakly balanced partitioning reduces to Alg. 4 for k = 2. Weakly balanced graphs are rare within social networks, and identifying the network beyond a special case is computationally prohibitive. We require clustering techniques that can be applied to signed graphs in any state of balance. Augmentation Based Balancing Hseih et al. impute edges between unconnected nodes to achieve balance. After creating a fully connected, maximally balanced graph based on the initial data, the eigenvectors corresponding to the k greatest eigenvalues of the completed adjacency matrix are computed. Finally, k-means clustering is run on the eigenvectors to assign nodes to clusters [21]. Graph clustering in balance feature space was recently explored as an alternative to spectral clustering [39]. The concept of the frustration cloud builds on the graph balance theory, relaxes the notion of a single frustration index to a family of minimally balanced graphs of a given signed graph, and derives the numeric features of vertex, status, and inﬂuence in a signed graph based on the balance theory [39]. Authors have demonstrated that status and inﬂuence attributes capture the spectrum of signed spectral clustering (Fig. 6) and indicate a possible direction for moving away from eigenvector computation. A study on more degenerate, adversarial networks is necessary to determine if consensus-based attributes [39] can provide insight into networks where spectral clustering fails. Algorithm 6 Clustering via matrix completion [21] Input: A signed matrix G and number of clusters k Σ Step 1: Impute the sign of missing edges in a way that minimizes frustration of the complete graph G. Step 2: Find the eigenvectors l , ..., l corresponding to the k greatest eigenvalues of the adjacency matrix of G. Step 3: Construct U ∈ R as the matrix containing the vectors l , ..., l as columns. Step 4: Cluster the graph nodes i = 1, ..., n based on u features using k-means clustering described in Alg. 2. Output: Cluster labels for all n nodes. <title>4.3 Modularity-Based Methods</title> Modularity-based metrics seek densely connected clusters using optimization techniques. Yang et al. introduced FEC, an algorithm for signed graphs that was designed for densely connected networks [49]. FEC treats the sign and density of edges as clustering attributes. In 2009, Gomez et al. reﬁned modularity metrics and extended existing methods to signed graphs that were directed, weighted, or contained loops [16]. Unfortunately, both FEC and the Gomez method were designed for smaller signed graphs with dense connections. Since many modern clustering applications involve large and sparse networks, we have excluded these methods from the experiments in Section 5. <title>4.4 Random Walk Models</title> A random walk on a graph is a process that begins at a node and moves to one of the nodes to which it is connected. When the graph is unweighted, the node to which the walk moves is chosen uniformly at random among the neighbors of the present node. Harel et al. introduced the random walk clustering algorithm for positively weighted edges in the graph [19]. The method requires only O(nlogn) time, and one of its variants needs only constant space [19]. The Fast Clustering for Signed Graphs (FCSG) algorithm employs a random walk gap approach to extract cluster structure information within the graph for positive edges only and for the entire graph [22]. A random walk gap is deﬁned as the diﬀerence in cumulative transition probabilities between nodes in the positive-only subgraph versus the unsigned graph. The FCSG Algorithm 8 calls the RWG Algorithm 7 as a subroutine and uses the RWG matrix to reweight the edges. Then, an iterative procedure is used to merge nodes connected by a positive edge until no positive edges remain. Nodes that have been merged together are assigned to the same cluster. The FCSG algorithm gives better results than existing algorithms based on the performance criteria of imbalance and modularity [22]. Algorithm 7 RWG algorithm [23] Algorithm 8 FCSG algorithm [23] α ∈ [0, 1] and d > 0, if node i and node j belong to the same cluster and dist(i, j) ≤ d, then the probability that a random walk originating at i will reach j before leaving the cluster is at least α. While this principle is sound for unsigned graphs, it cannot be easily generalized to signed graphs, as its underlying assumption is that the spanning tree can be constructed using only positive edges only in the signed graph. To satisfy this requirement, we have to take the greatest connected component of the all-positive subgraph of the input signed graph. Figure 17(left) illustrates two all-positive subgraphs for Highland Tribes, and it is clear there is no all-positive spanning tree, and as a result four vertices in a community are left out of the analysis. Figure 17(right) illustrates Sampson’s Monastery all-positive subgraph and an all-positive spanning tree, so each vertex receives a label at the end of the procedure. In summary, the ﬁrst limitation leads to some vertices being unlabeled in the ﬁnal analysis, as shown in Section 5.3. The second signiﬁcant limitation is the assumption of the small world hypothesis, a theory that most users are linked by no more than 5 degrees of separation in a social network. The second assumption becomes critical in step 4 of Algorithm 7, where transition probabilities for the all-positive subgraph are normalized using the unsigned version of the input graph. If nodes i and j are not connected by a path with a length less than or equal to k, the k-step transition probability is zero. The matrix is D is deﬁned as D = ((H −H )H where and H represent the k-step transition probabilities between i and j on the all-positive subgraph and unsigned version of the input graph respectively. If H = 0, the normalized transition probability is undeﬁned. The authors assume that H > 0 for k ≥ 5 due to the small-world hypothesis, but for graphs with a diameter exceeding 5, this does not hold. For this reason, the parameter used in the random walk gap matrix calculation L must be greater than or equal to the diameter of the all-positive subgraph of the input graph. The authors recommend that L be set to 5 and warn that the algorithm begins to degrade in quality if L is greater than or equal to 10. <title>5 Experimental Comparison</title> In this section, we compare state-of-the-art signed graph clustering algorithms and implementations in terms of eﬀectiveness when ground-truth is available and eﬃciency for large real-life data sets; we then discuss some of the algorithm implementations. <title>5.1 Modiﬁed Spectral Clustering Techniques: A Comparison</title> This experiment evaluates the strengths and weaknesses of nine modiﬁed spectral clustering approaches for signed graphs using four real-world graphs with known ground-truth community labels. Each of the nine approaches is evaluated on how well it aligns with true communities. Graphs are described in Section 5.1.1, and their characteristics are listed in Table 1. In this experiment, we use four data sets: (1) Highland Tribes, which models agreeable and antagonistic relationships between tribes in the Eastern Central Highlands of New Guinea [38]; (2) Sampson’s Monastery, which models sentiment over time between novice monks in a New England monastery [41]; (3) Football, which tracks Twitter interactions between 248 players belonging to 20 distinct clubs of the English Premier League [17]; and (4) Olympics, which models Twitter interactions between 464 athletes belonging to 28 distinct sports involved in the 2012 London Olympics [17]. Their characteristics are listed in Table 1. Highland The Highland Tribes data set describes agreeable and antagonistic relations between 16 tribes of the Eastern Central Highlands of New Guinea. Each tribe is a node, with agreeable tribes connected by a positive edge and antagonistic tribes connected by a negative edge. The Highland Tribes data set [38] captures the alliances between sixteen tribes of the Eastern Central Highlands of New Guinea as depicted in Fig. 7 (left). There are three communities in the Highland Tribes data, shown in Fig. 7 (left). The golden node in Fig. 7 (left) has no adjacent negative edges and belongs to two communities. The Highland Tribes data set has a high number of balanced triangles (86.8%) and exhibits high clusterability due to the density of the positive edges within clusters and negative edges between clusters in comparison to Sampson network, as illustrated in Fig. 7. ties to a group or ideology, but by their ambivalence or their rejection from the mainstream opinions. The Sampson data set is also complex in combining multiple sentiments into a single edge weight. In the original Sampson data set, surveys were administered in which the monks were asked to rank their top three and bottom three peer choices on four qualities. We assign weighted scores to each relation based on the survey data and sum across qualities for a total. If the total is greater than 1, the relationship was modeled with a positive edge. If less than 1, the relationship was assigned a negative edge. The complexity of the edges, as well as the importance of ambivalence, make Sampson a diﬃcult graph to cluster. See Figure 7(right). Football The Football data set represents football players and clubs from the English Premier League. The data contains 248 Twitter users grouped into 20 clubs in the league. Each user belongs to only one club [17]; see Figure 8 (left) for the network structure. Olympics The Olympics data set features athletes and organisations that were part of the London 2012 Summer Olympics. The data contains 464 Twitter users grouped into 28 diﬀerent sports. Each user belongs to only one sport [17]; see Figure 8 (right) for the network structure. against previously generated negative edges and existing positive edges to avoid duplication. The number of negative edges to add was determined as a percent relative to the number of positive edges. In this case, the number of negative edges was set to be 20 percent of the number of positive edges. Negative edges are only added between communities. Nine diﬀerent clustering methods for signed graphs are applied to each data set and listed below with the indexes used to compare the results in Table 2, Figure 9, and Figure 10: 1. lap none: spectral clustering using the signed graph Laplacian [27] 2. lap sym: spectral clustering using the symmetric Laplacian [27] 3. lap sym sep: spectral clustering using the symmetric separated Laplacian [27] 4. BNC none: balanced normalized cuts [6] 5. BNC sym: symmetric balanced normalized cuts [6] 6. SPONGE none: baseline SPONGE implementation [8] 7. SPONGE sym: symmetric SPONGE [8] 8. GM : geometric means [31] 9. SPM : matrix power means [33] The Python package signet [7] was used to run the 1.-7. methods, while code provided by the authors of [33] and [31] was used for the ﬁnal two algorithms [32] [34] For each community, labels were generated for each of the nine clustering methods for k as given in the ground-truth data set. After clustering, the Adjusted Rand Index (ARI) [44] was computed for each labeling and used to compare the accuracy of the methods. The ARI is a popular choice of metric for assessing similarity of partitions and ranges from -1 to 1, with a value near 0 representing a random pairing and 1 representing perfect recovery. For each data set, we compare each method against all others to detect the most (dis)similar methods. The results of this analysis are presented in Table 2, Figure 9, Figure 10 and Appendix 1. Six algorithms were able to recover all Highland Tribe’s ground-truth community labels, as seen on Table 2 in the second row. The Highland Tribes data set has a high balance score and small size, and this was expected. All nine approaches failed to discover community labels in the Sampson data. The complex nature of the Sampson data set and the low balance score show that the signed network does not capture the complexity in the labels suﬃciently for the clustering approaches to decipher. The bolded scores in Table 2 show the top performer per data set. The symmetric Laplacian and symmetric SPONGE consistently produce top results, as illustrated in Figure 9. We analyze the clustering success with respect to the size, sparseness, balance, and percent of the positive edges of the data sets, and the results are summarized in Figure 10. This experiment does not show clear trends in the eﬀectiveness of a clustering algorithm with respect to the size of the data set within the scope of this experiment, as visualized in Figure 10 (top row) with ARI analysis with respect to the number of vertices (top row, left), number of edges (top row, center), percentage of positive edges (top row, right), ARI by number of sparseness (bottom row, left), and percent of balanced triangles (bottom row, right) for four data sets (Football, Highland, Olympics, and Sampson). The top performing algorithms did not seem to be aﬀected by the percent of positive edges; see Figure 10 (top row). Any eﬀect that was present was likely due to a confounding eﬀect with balance. While a clear pattern does not emerge for sparseness, we can see that the more balanced data sets tend to give better results across most methods, especially for the three that we have previously identiﬁed as top performers (symmetric Laplacian, SPONGE, and symmetric SPONGE); see Figure 10 (bottom row). The SPM (matrix power means) [33] approach was an update to the originally proposed geometric means (GM) [31], and SPM has shown in our experiments to do a better job on weakly balanced graphs than the GM. <title>5.2 Scaling The Signed Graph Clustering Methods: Benchmarking The Performance</title> approaches to evaluate: 1. lap sym - adapted spectral clustering using a symmetric Laplacian matrix [28], 2. BNC none - weighted kernel k-means using the balance normalized cut [6], and 3. SPONGE sym - SPONGE using a symmetric Laplacian [28]. Correlates of War The Correlates of War signed graph was built from records of alliances, wars, and militarized interstate disputes between 50 countries from 1816 to 2014 [42]. In this study, we chose to focus on the year 1944. Countries are represented by vertices, v = 50, and edges represent relationships between countries, e = 276. If two countries were allies, there is a positive edge between them. If two countries were at war or experienced a militarized interstate dispute, there is a negative edge between them. The Correlates of War data set has 3 community labels: Allied Powers, Axis Powers, or remaining neutral [42]. the candidate nodes. In this case, we will also compare the proportion of winners, losers, and voters in each cluster [30]. Slashdot Slashdot is a technology website that allows users to tag each other as “friends” or “foes.” The data set was curated by SNAP [30] and contains 81,867 nodes and 545,671 edges. Duplicate and self-referencing edges were removed from the data set, and all nodes and edges not in the GCC were dropped to ensure modularity and to eliminate the trivial clusters. After pre-processing, the graph had 82,140 nodes and 500,481 edges [30]. Epinions Epinions.com is a website that hosts consumer reviews and employs a ”trust/distrust” metric among users. Users may rate each other as trusted or not, and the resulting ”Web of Trust” is used to weigh product reviews based on the reputations of the authors. Duplicate and self-referencing edges were removed from the data set, and all nodes and edges not in the GCC were dropped to ensure modularity and to eliminate the trivial clusters. After pre-processing, Epinions had 131, 828 users and 841, 373 edges [30]. consumption over time was measured using the Memory Proﬁler library in Python. Figure 11 shows that all three methods ( lap sym, BNC none, SPONGE sym) had roughly the same peak memory usage on the two smaller data sets, Correlates of War[42] and Wikipedia Elections [30]. The discrepancies in peak usage are evident for the larger networks, Slashdot and Epinions, in Figure 12; the SP ON GE sym approach has the highest memory consumption by a large margin. Additionally, we observed that although the symmetric Laplacian clustering was the slowest to ﬁnish on Epinions, it also maintained low and consistent memory consumption throughout its runtime. The area under the curve for the ﬁgures in 12 represents total memory usage by the algorithm. We plotted the total memory usage on the linear Figure 13 (left) and logarithmic Figure 13 (right) scales to compare overall resource usage for each algorithm. The total resource usage is very similar on the smaller Correlates of War and Wikipedia Elections data sets. The symmetric Laplacian lap sym used the most resources to cluster Epinions, the largest network. The balance normalized cut (BN C none) remained the least resourceintensive algorithm of the three methods compared. <title>lap sym [27] BNC none [6] SPONGE sym [8] dataset pos in neg out pos in neg out pos in neg out cow 0.987 0.875 0.996 0.550 1.000 0.300 wiki 0.625 0.667 0.901 0.165 0.591 0.713 slashdot 0.999 0.000 0.963 0.189 1.000 0.000 Epinions 1.000 0.000 0.964 0.190 1.000 0.000</title> edges placed between clusters. The ratio of positive edges within clusters and negative edges between clusters that each algorithm produces is outlined in Table 4. In a ground-truth clustering of a perfectly modular graph, both metrics would be 1 (100%). Correlates of War The Correlates of War clustering products of all three algorithms are shown as the adjacency matrices sorted by cluster label in ascending order by cluster size in Figure 14. All three methods successfully identiﬁed the Allied Powers label, and it is consistently the second largest cluster out of three. The diﬀerences in edge classiﬁcation are shown in Table 4. The symmetric Laplacian took the most balanced approach with 98.7% of the positive edges being placed within clusters and 78.5% of the negative edges being placed between clusters. The balance normalized cut (BNC none) and symmetric SPONGE ( SPONGE sym) both optimized positive edge placement more heavily than negative edge placement, with symmetric SPONGE placing 100% of the positive edges within a cluster but only 30% of the negative edges between clusters. Wikipedia Elections The Wikipedia Elections data set clustering using the three methods is hard to visualize using blockmodeling due to the sparseness of the network, as illustrated in Figure 16. The log scale of discovered community size for all three methods is illustrated in Figure 15. All three methods struggled with small cluster sizes in Figure 15, even though we are using a small cluster size in the normalization. Figure 16(center) contains 29 tiny communities and 1 large community so the community lines are not visible as for Figure 16(left) and Figure 16(right). The introduction of the signed normalized cut, as an alternative to the signed ratio cut, was intended to prevent clustering algorithms from producing trivial or near-trivial optimization solutions with either single nodes or pairs of nodes isolated into a cluster, but we can see that this fails on highly sparse networks such as the Wikipedia Elections data set. Cucuringu et al. [8] note the diﬃculty in recovering community structure in sparse networks with spectral methods, even when normalization is introduced. Dall’Amico et al. further expand on the causes of failure for spectral methods on real sparse graphs, which include an average degree that is small relative to and not proportional with the size of the graph and a power-law distribution of vertex degrees [9]. Slashdot and Epinions The Slashdot and Epinions clustering results in Table 4 produce similar results. The low success metrics for negative edges between Epinions and Slashdot, combined with the low community size, suggest a breakdown in eﬀectiveness across the three methods. The lap sym, BNC none, and SP ONGE sym methods rely on the eigenvalue approximation. Eigenvalue approximation is notoriously unstable for large matrices [26], and the results we have obtained suggest the calculations in these three methods were so prone to error on the large data sets that meaningful community labels were not found. <title>5.3 Fast Clustering for Signed Graph (FCSG) using random walk gap: Implementation Considerations</title> connected component, and all nodes outside of the greatest connected component will not be placed into a cluster. Table 5 shows how many vertices are left to cluster after this condition is met. The parameter used in the random walk gap matrix calculation L must be greater than or equal to the diameter of the positive edge-only subgraph G of Σ. The authors warn that the algorithm begins to degrade in quality for L > 5 and is theoretically unsound for L greater than or equal to 10. For large and sparse real-life data sets, the diameter exceeds 5, as shown in Table 5 for the Wikipedia data. Additionally, Slashdot and Epinions have diameters of 11 and 14 respectively [30]. The recommended value of L cannot be used for large, sparse graphs as their diameters exceed the recommended value. The FCSG results in Table 6 show that the method discovers a subset of the communities in Highland Tribes and Sampson’s Monastery, and the ARI score for each data set is 1.00 and 0.09 respectively. We are interpreting results in this section with caution due to the reproducibility issue, as discussed in Section 4.4. experiments are run on the Texas State University LEAP system [11]. The Dell PowerEdge C6320 cluster node consists of two (14-core) 2.4 GHz E5-2680v4 processors with 128 GB of memory each, and two 1.5TB memory vertices with four (18-core) 2.4 GHz E7-8867v4 Intel Xeon processors [11]. Figure 18 shows runtimes on a workstation with a 2.2GHz QuadCore Intel Core i7 and 16 GB of memory for small graphs and Wikipedia Elections run on LEAP. The Wikipedia Elections data set ran for over 2 weeks on our most powerful cluster. Unfortunately, this algorithm could not easily be sped up. The algorithm is irregular, making it diﬃcult to parallelize, so we used a serial implementation. Additionally, there was no NetworkX merge function that met the needs of this algorithm; we had to write a custom node merging function that did not scale. Since Epinions and Slashdot are substantially larger than Wikipedia Elections, we did not run FCSG on these data sets due to scalability issues. The RWG clustering algorithm assumptions oppose the real-world graph characteristics, positive edge spanning tree, and small world assumptions, as discussed in Section 4.4. Note that the authors did not publish the code, so the reproducibility of the reported results diﬀers from the original paper. Additionally, we had to raise the parameter L above the recommended value of 5 to 8 (Table 5) to prevent division by zero on the Wikipedia Elections data set, and we had to pre-process the graphs to drop any nodes that were not part of the all-positive greatest connected component. We use the ARI measure to demonstrate the inferior performance of the FCSG algorithm on real graphs in comparison to previously published methods. <title>6 Conclusion and Future Work</title> and symmetric SPONGE methods did not scale well with the large size of the data, as all three algorithms rely on eigenvalue approximation. State-of-the-art methods of approximate eigenvector calculation do not scale, and cumulative errors in the algorithm prevented the meaningful interpretation of output results, as shown in Section 5.2. Here, we have found the ﬁrst central ﬂaws in existing clustering techniques for signed graphs: an inability to scale to large graphs, especially for sparse networks. This study also highlights the importance of ongoing reproducibility discussions within the computer science and computation community. We used author-provided code when available, but many of the techniques discussed in this paper did not have the original code used to perform the published experiments. This was especially notable for the large signed data sets Epinions and Slashdot, which performed poorly across the board in our experiments, but have more promising results published in the literature. The computationally expensive family of techniques that does not rely on local minima or maxima showed potential, but the provided implementation details were too sparse to reproduce the results, as shown in Section 5.3. Another central ﬂaw is that algorithms make assumptions that limit the applicability of some techniques to real-world data, such as the small world assumption in Section 5.3 Our next step is to compare the state-of-the-art methods with a frustration-cloud based approach [39] and evaluate how consensus-based feature extraction can mitigate the limitations of current approaches to improve eﬃciency and eﬀectiveness. We are also looking into signed graph clustering where a vertex can belong to multiple communities and/or have a continuous score for community belonging. <title>References</title> [1] Altaﬁni, C. (2013) Consensus Problems on Networks With Antagonistic Interactions. IEEE Transactions on Automatic Control, 58(4), 935–946. [2] Antal, T., Krapivsky, P. L. & Redner, S. (2006) Social Balance on Networks: The Dynamics of Friendship and Enmity. Physica D: Nonlinear Phenomena, 224(1), 130– 136. [3] Arthur, D. & Vassilvitskii, S. (2007) K-Means++: The Advantages of Careful Seeding. In Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA ’07, page 1027–1035, USA. Society for Industrial and Applied Mathematics. [4] Axelrod, R. & Bennett, D. S. (1993) A Landscape Theory of Aggregation. British Journal of Political Science, 23(2), 211–233. [5] Chiang, K.-Y., Hsieh, C.-J., Natarajan, N., Tewari, A. & Dhillon, I. S. (2013) Prediction and Clustering in Signed Networks: A Local to Global Perspective. arXiv:1302.5145 [cs]. arXiv: 1302.5145. conference on Information and knowledge management - CIKM ’12, page 615, Maui, Hawaii, USA. ACM Press. [7] Cucuringu, M., Davies, P., Glielmo, A. & Tyagi, H. (2019a) SigNet. https://github. com/alan-turing-institute/SigNet. [8] Cucuringu, M., Davies, P., Glielmo, A. & Tyagi, H. (2019b) SPONGE: A generalized eigenproblem for clustering signed networks. In The 22nd International Conference on Artiﬁcial Intelligence and Statistics, pages 1088–1098. PMLR. [9] Dall’Amico, L., Couillet, R. & Tremblay, N. (2020) A uniﬁed framework for spectral clustering in sparse graphs. . [10] Dhillon, I. S., Guan, Y. & Kulis, B. (2004) Kernel k-means: spectral clustering and normalized cuts. In Proceedings of the 2004 ACM SIGKDD international conference on Knowledge discovery and data mining - KDD ’04, page 551. ACM Press. [11] Division of Information Technology, T. S. U. (2020) LEAP - High Performance Computing Cluster. https://doit.txstate.edu/rc/leap.html. [12] Esmailian, P. & Jalili, M. (2015) Community Detection in Signed Networks: the Role of Negative ties in Diﬀerent Scales. Scientiﬁc Reports, 5(1), 14339. [13] Foundation, P. S. (2020) Python Time Library, Python 3 documentation. https:// docs.python.org/3/library/time.html. [14] Gallier, J. (2016) Spectral Theory of Unsigned and Signed Graphs. Applications to Graph Clustering: a Survey. . [15] Girvan, M. & Newman, M. E. J. (2002) Community structure in social and biological networks. Proceedings of the National Academy of Sciences, 99(12), 7821–7826. [16] G´omez, S., Jensen, P. & Arenas, A. (2009) Analysis of community structure in networks of correlated data. Phys. Rev. E, 80, 016114. [17] Greene, D. & Cunningham, P. (2013) Producing a uniﬁed graph representation from multiple social network views. In Proceedings of the 5th annual ACM web science conference, pages 118–121. [18] Harary, F. (1953) On the notion of balance of a signed graph. Michigan Math. J., 2(2), 143–146. [19] Harel, D. & Koren, Y. (2001) Clustering spatial data using random walks. In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, pages 281–286. [20] Heider, F. (1946) Attitudes and cognitive organization. J. Psychology, 21, 107–112. [21] Hsieh, C.-J., Chiang, K.-Y. & Dhillon, I. S. (2012) Low Rank Modeling of Signed Networks. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining, page 507–515, New York, NY, USA. Association for Computing Machinery. [22] Hua, J., Yu, J. & Yang, M.-S. (2020a) Fast clustering for signed graphs based on random walk gap. Social Networks, 60, 113–128. Social Network Research on Negative Ties and Signed Graphs. [23] Hua, J., Yu, J. & Yang, M.-S. (2020b) Fast clustering for signed graphs based on random walk gap. Social Networks, 60, 113–128. [24] Karatas, A. & Sahin, S. (2018) Application Areas of Community Detection: A Review. In 2018 International Congress on Big Data, Deep Learning and Fighting Cyber Terrorism (IBIGDELFT), pages 65–70. IEEE. [25] Karypis, G. & Kumar, V. (1999) Kumar, V.: A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs. SIAM Journal on Scientiﬁc Computing 20(1), 359392. Siam Journal on Scientiﬁc Computing, 20. [26] Knyazev, A. V. (2001) Toward the Optimal Preconditioned Eigensolver: Locally Optimal Block Preconditioned Conjugate Gradient Method. SIAM J. Sci. Comput., 23, 517–541. [27] Kunegis, J., Lommatzsch, A. & Bauckhage, C. (2009) The Slashdot Zoo: Mining a Social Network with Negative Edges. In Proceedings of the 18th International Conference on World Wide Web, WWW ’09. ACM. [28] Kunegis, J., Schmidt, S., Lommatzsch, A., Lerner, J., De Luca, E. W. & Albayrak, S. (2010) Spectral Analysis of Signed Graphs for Clustering, Prediction and Visualization. In Proceedings of the 2010 SIAM International Conference on Data Mining, pages 559– 570. Society for Industrial and Applied Mathematics. [29] Leskovec, J., Huttenlocher, D. & Kleinberg, J. (2010) Predicting Positive and Negative Links in Online Social Networks. In Proceedings of the 19th International Conference on World Wide Web, WWW ’10, pages 641–650. ACM. [30] Leskovec, J. & Krevl, A. (2014) SNAP Datasets: Stanford Large Network Dataset Collection. http://snap.stanford.edu/data. [31] Mercado, P., Tudisco, F. & Hein, M. (2016a) Clustering Signed Networks with the Geometric Mean of Laplacians. In Lee, D. D., Sugiyama, M., Luxburg, U. V., Guyon, I. & Garnett, R., editors, Advances in Neural Information Processing Systems 29, pages 4421–4429. Curran Associates, Inc. [32] Mercado, P., Tudisco, F. & Hein, M. (2016b) Clustering Signed Networks with the Geometric Mean of Laplacians. [33] Mercado, P., Tudisco, F. & Hein, M. (2019a) Spectral Clustering of Signed Graphs via Matrix Power Means. In Chaudhuri, K. & Salakhutdinov, R., editors, Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 4526–4536, Long Beach, California, USA. PMLR. [34] Mercado, P., Tudisco, F. & Hein, M. (2019b) Spectral Clustering of Signed Graphs via Matrix Power Means. [35] Moore, M. (1978) An international application of Heider’s balance theory. European Journal of Social Psychology, 8(3), 401–405. [36] Moore, M. (1979) Structural balance and international relations. European Journal of Social Psychology, 9(3), 323–326. [37] Nogueira de Moura, L. (2020) Social network analysis at scale: Graph-based analysis of Twitter trends and communities. Master’s thesis, Texas State University. [38] Read, K. (1954) Cultures of the Central Highlands, New Guinea. Southwestern Journal of Anthropology, 10(1), 1–43. [39] Rusnak, L. & Teˇsi´c, J. (2021) Characterizing Attitudinal Network Graphs through Frustration Cloud. Data Mining and Knowledge Discovery, 6(35). [40] Saberi, M., Khosrowabadi, R., Khatibi, A., Misic, B. & Jafari, G. (2021) Topological impact of negative links on the stability of resting-state brain network. Scientiﬁc Reports, 11(1), 2176. [41] Sampson, S. (1968) A novitiate in a period of change: An experimental and case study of relationships. Ph.D. thesis, Cornell University. [42] Sarkees, M. R. & Wayman, F. (2010) Resort to War: 1816 - 2007. https:// correlatesofwar.org/data-sets/COW-war/cow-wars. [43] Shi, J. & Malik, J. (2000) Normalized Cuts and Image Segmentation. IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, 22(8), 18. [44] Steinley, D. (2004) Properties of the Hubert-Arabie Adjusted Rand Index. Psychological methods, 9, 386–96. [45] Tang, J., Chang, Y., Aggarwal, C. & Liu, H. (2016) A Survey of Signed Network Mining in Social Media. arXiv:1511.07569 [physics]. arXiv: 1511.07569. [46] von Luxburg, U. (2007) A Tutorial on Spectral Clustering. arXiv:0711.0189 [cs]. arXiv: 0711.0189. [47] Wagstaﬀ, K., Cardie, C., Rogers, S., Schr¨odl, S. et al. (2001) Constrained k-means clustering with background knowledge. In Icml, volume 1, pages 577–584. [48] White, H. C., Boorman, S. A. & Breiger, R. L. (1976) Social Structure from Multiple Networks. I. Blockmodels of Roles and Positions. American Journal of Sociology, 81(4), 730–780. [49] Yang, B., Cheung, W. & Liu, J. (2007) Community Mining from Signed Social Networks. IEEE Transactions on Knowledge and Data Engineering, 19(10), 1333–1348. [50] Zaslavsky, T. (2010) Matrices in the theory of signed simple graphs. In Advances in Discrete Mathematics and Its Applications (Mysore, 2008), pages 207–229. Ramanujan Math. Soc. Lect. Notes Ser., Mysore. [51] Zheng, Q. & Skillicorn, D. (2015) Spectral Embedding of Signed Networks. In Proceedings of the 2015 SIAM International Conference on Data Mining, pages 55–63. Society for Industrial and Applied Mathematics.