Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Cold-start problem is still a very challenging problem in recommender systems. Fortunately, the interactions of the cold-start users in the auxiliary source domain can help cold-start recommendations in the target domain. How to transfer user’s preferences from the source domain to the target domain, is the key issue in Crossdomain Recommendation (CDR) which is a promising solution to deal with the cold-start problem. Most existing methods model a common preference bridge to transfer preferences for all users. Intuitively, since preferences vary from user to user, the preference bridges of dierent users should be dierent. Along this line, we propose a novel framework named Personalized Transfer of User Preferences for Cross-domain Recommendation (PTUPCDR). Specically, a meta network fed with users’ characteristic embeddings is learned to generate personalized bridge functions to achieve personalized transfer of preferences for each user. To learn the meta network stably, we employ a task-oriented optimization procedure. With the meta-generated personalized bridge function, the user’s preference embedding in the source domain can be transformed into the target domain, and the transformed user preference embedding can be utilized as the initial embedding for the cold-start user in the target domain. Using large real-world datasets, we conduct extensive experiments to evaluate the eectiveness of PTUPCDR on both cold-start and warm-start stages. The code has been available at https://github.com/easezyc/WSDM2022-PTUPCDR. • Information systems → Recommender systems. Cross-domain Recommendation; Cold-start Problem; Meta Network; Personalized Transfer ACM Reference Format: Yongchun Zhu, Zhenwei Tang, Yudan Liu, Fuzhen Zhuang, Ruobing Xie, Xu Zhang, Leyu Linand Qing He. 2022. Personalized Transfer of User Preferences for Cross-domain Recommendation. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining (WSDM ’22), February 21–25, 2022, Tempe, AZ, USA. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3488560.3498392 Recommender systems are playing more and more important roles in web and mobile applications. In recent years, recommender systems have attracted a vast amount of interest from industries and academia, and researchers have conducted a great deal of research to improve the recommendation performance [1,11]. However, most of these recommender systems are hard to provide satisfying recommendations for new users, i.e., cold-start users, who have no historical interactions. Cross-domain Recommendation (CDR) [25] which aims to transfer knowledge from an informative source domain to the target domain is a promising solution to alleviate the cold-start problem. The core task of CDR is to bridge user’s preferences in the source domain and the target domain, also called preference transfer [37]. To achieve preference transfer, many existing CDR methods [4,9,16,39] assume that all users share the same relationships between user preferences in the source domain and the target domain, and learn a common preference bridge shared by all users, as shown in Figure 1 (a). In practice, due to individual dierences, the complex relationships between the user preferences of the source and target domains vary from user to user. Hence, it is hard for a single bridge to capture such complicated and various relationships, which may degrade these CDR methods’ performance. To alleviate the drawback, it is necessary to use personalized bridges to model various relationships between user preferences in dierent domains. In other words, the process of preference transfer should be personalized. Along this line, we propose a novel framework named Personalized Transfer of User Preferences for Cross-domain Recommendation (PTUPCDR). PTUPCDR learns a meta network that takes users’ Figure 1: (a) In existing CDR methods: all users share the common bridge function. (b) The proposed PTUPCDR utilizes a meta network to generate personalized bridge functions for each user. characteristic embeddings in the source domain as input and generates personalized bridges for each user, as shown in Figure 1(b). The generated bridge functions can be viewed as a model parameterized by the learned meta network. Note that the personalized bridge functions which depend on the users’ characteristics vary from user to user, so the process of the preference transfer is personalized, which can capture preference relationships between dierent domains better than existing methods. After training, we feed user embeddings in the source domain into the meta-generated personalized bridge functions and obtain the transformed user embeddings. The transformed user embeddings are utilized as the initial embeddings in the target domain. With the initial embeddings, our method is eective for cold-start users who have no interactions in the target domain. In practice, a high-level meta network is hard to optimize [18,24], and how to optimize the meta network is another challenge. To learn the bridge function, existing bridge-based methods [4,9,16,39] adopt a mapping-oriented optimization procedure to directly minimize the distance between the transformed users’ embeddings from the informative source domain and the user’s embedding in the target domain. In other words, with such an optimization procedure, the bridge function is sensitive to the quality of the users’ embeddings. In practical recommender systems, it is pretty hard to learn reasonable embeddings [21,42] for all users, which limits the performance of the bridge function learned with the mappingoriented optimization. In addition, we nd it is hard to learn the meta network with the mapping-oriented optimization. Thus, to train the meta network, we take a task-oriented optimization procedure, which skips the users’ embeddings in the target domain and directly utilizes the rating task as the optimization goal. Most existing works in the literature [4,9,16,37,39] only testify their eectiveness by applying their methods upon simple base models (Matrix Factorization) in the extreme cold-start stage (users have no interactions in the target domain). Since such settings are far from real-world scenarios, we further explore how to use PTUPCDR in more practical scenarios to validate the compatibility and utility of PTUPCDR in real-world recommendations, e.g., warmstart scenarios, more complicated base models. Experimental results demonstrate that our proposed PTUPCDR is of good compatibility and utility in real-world recommendations. The main contributions of our work are summarized into three folds: •To solve the cold-start problem in CDR, we propose a novel method named PTUPCDR, utilizing a meta network to generate personalized bridge functions for each user, given the encoded users’ characteristics in the source domain. •To learn the meta network stably, we employ a task-oriented optimization procedure to alleviate the side eects of unreasonable users’ embeddings. •We conduct extensive experiments on three cross-domain tasks using Amazon review dataset to demonstrate the eectiveness and robustness of PTUPCDR for not only cold-start scenarios but also warm-start scenarios, while existing methods only testify their eectiveness in the cold-start scenarios. Transfer learning aims to leverage knowledge from a source domain to improve the learning performance or minimize the number of labeled examples required in a target domain [30,45], which led to an interest in many area, e.g., computer vision [29,43,44], natural language processing [19,32]. Inspired by transfer learning, CDR is a promising solution to alleviate data sparsity and the cold-start problem in the target domain with the help of the auxiliary (source) domain. At the very beginning, CMF [25] assumes a shared global user embedding matrix for all domains, and it factorizes matrices from multiple domains simultaneously. CST [22] utilizes the user embedding in the source domain to initialize the embedding in the target domain and restricts them from being closed. In recent years, researchers proposed many deep learning-based models to enhance knowledge transfer [5,6,8,31,34,42]. CoNet [8] transfers and combines the knowledge by using cross-connections between feed-forward neural networks. MINDTL [6] combines the CF information of the target-domain with the rating patterns extracted from a cluster-level rating matrix in the source-domain. DDTCDR [15] develops a novel latent orthogonal mapping to extract user preferences over multiple domains while preserving relations between users across dierent latent spaces. Another group of CDR methods focus on bridging user preferences in dierent domains [9,16,22,36,37,39,40], which is the most related work. CST [22] utilizes the user embedding learned in the source domain to initialize the user embedding in the target domain and restricts them to being closed. Some methods [9,16,37,40] explicitly model the preference bridge. Our study falls into the this bridge-based category. However, to the best of our knowledge, all of the bridge-based CDR works in the literature learn a shared bridge function for all users, while our PTUPCDR is the rst to learn personalized bridges for each user. Providing recommendations for new users or items is challenging in recommender systems, also named the cold-start problem. There are two kinds of methods to solve the cold-start problems. The rst type actively solves cold-start by designing a decision making strategy, such as using contextual-bandits [14, 20]. This paper belongs to the second type, which utilizes auxiliary information to help the cold-start stage. There are various kinds of auxiliary information could be exploited to improve cold-start recommendation performance, e.g., user attributes [13,23], item attributes [17,35,42], knowledge graphs [28], samples in an auxiliary domain [16], etc. Usually, with samples in an auxiliary domain, the CDR methods can achieve much better results than other cold-start methods. Thus, in this paper, following most CDR work [9,16], we only compare our method with CDR approaches. It is also named learning to learn, aiming to improve novel tasks’ performance by training on similar tasks. There are various meta learning methods, e.g., metric-based methods [26,27], gradientbased methods [3], and parameter-generating based methods [18]. The proposed PTUPCDR falls into the third group, which utilizes a meta learner to predict networks’ parameters. Recently, researchers proposed many meta-based methods [12,21,41,42] to improve recommender systems’ performance. However, most of them fall into gradient-based methods and focus on single-domain recommendations, while we focus on cross-domain recommendations. The most related work is TMCDR [40] which utilizes meta-learning in CDR. However, TMCDR also trains a common bridge as existing bridge-based methods do. In CDR, we have a source domain and a target domain. Each domain has a user setU = {𝑢, 𝑢, ...}, an item setV = {𝑣, 𝑣, ...}, and a rating matrixR.𝑟∈ Rdenotes the interaction between user𝑢 and item𝑣. To distinguish these two domains, we denote the user, item sets, and the rating matrix of the source domain asU, V, R, whileU, V, Rfor the target domain. We dene the overlapping users between the two domains asU= U∩ U. In contrast,V andVare disjoint, which means there is no shared item between the two domains. In latent factor models, the users and items are transformed into dense vectors, also called factors or embeddings. In this paper, 𝒖∈ Rand𝒗∈ Rdenote the embeddings of the user𝑢 and item𝑣, respectively, where𝑘denotes the dimensionality of embeddings and𝑑 ∈ {𝑠, 𝑡}represents the domain label. For each user𝑢, we denote the list of her sequential interaction items in Algorithm 1Personalized Transfer of User Preferences for CDR (PTUPCDR) Input: U, U, V, V, U, R, R Input: Meta network 𝑔. Input: Characteristic encoder ℎ. Pre-training Stage: 1. Learning a source model which contains 𝒖, 𝒗. 2. Learning a target model which contains 𝒖, 𝒗. Meta Stage: 3. Learning a characteristic encoderℎand a meta network𝑔by minimizing Equation (7). Initialization Stage: 4. For a cold-start user 𝑢in the target domain, we use the transformed embedding 𝑓(𝒖;𝒘) as the user’s initialized embedding in the target domain. source domain byS= {𝑣, 𝑣, · · · , 𝑣}, where𝑛denotes the number of interacted items and𝑣denotes the interacted item in the source domain at timestamp 𝑡. The rst step to generate the personalized bridge function is to capture users’ personalized transferable characteristics from interacted items. However, cold-start users have no interacted item in the target domain. Thus, it is essential to exploit the interacted items Sin the source domain. Note that we need to nd the transferable characteristics which are helpful for knowledge transfer. Intuitively, various items have dierent contributions to knowledge transfer. The attention mechanism [33,38] allows dierent parts to contribute dierently when compressing them to a single representation. Therefore, we propose to employ the attention mechanism on item embeddings by performing a weighted sum: where𝒑∈ Rdenotes the transferable characteristic embedding of user𝑢, and𝑎is the attention score for item𝑣, which can be interpreted as the importance of𝑣in predicting the personalized bridge function. For the target domain, an irrelevant item would has little help for personalized bridge functions of all users. Thus, we learn the attention score from the items’ embeddings by an attention network. Formally, the attention network is dened as: whereℎ(·)denotes the attention network, and𝜃denotes the parameters ofℎ(·). In this paper,ℎ(·)is a two-layer feed-forward network. Note that the normalized attention score𝑎is benecial to nd the useful interacted items for a specic user. After that, we could utilize each user’s characteristics as input to guide the generation of personalized bridge function. Figure 2: Personalized Transfer of User Preferences for Cross-domain Recommendation (PTUPCDR) utilizes a meta network with users’ characteristic embeddings in the source domain as input to generate personalized bridge functions for each user. Then, with the personalized bridge function, we can obtain the transformed user’s embeddings as the initial embeddings. We have mentioned that the users’ relationships between preferences of dierent domains vary from user to user. In other words, the process of preference transfer needs to be personalized. Intuitively, there exists a certain connection between the preference relationship and the user’s characteristics. Based on this intuition, we propose a meta network which takes the user’s transferable characteristics as input, and then generates a personalized bridge function between the user’s embeddings in the source and target domains. The proposed meta network is formulated as: where𝑔(·)is the meta network, which is parameterized by𝜙. In this paper, the meta network is a two-layer feed-forward network. The 𝒘is a vector whose size depends on the structure of the bridge function. The personalized bridge function is formulated as: which utilizes𝒘as the parameters of bridge function𝑓 (·). The bridge function can be dened as any structure. In this paper, for simplicity, we use a linear layer as𝑓 (·)following EMCDR [9,16]. Thus, to t the size of bridge’s parameters, we reshape the vector 𝒘∈ Rinto a matrix𝒘∈ R. Note that the𝒘is used as the parameters of the bridge functions rather than input. The generated bridge function depends on user’s characteristics and varies from user to user, and we call it the personalized bridge function. With the personalized bridge function, we can obtain the personalized transformed user’s embeddings: where𝒖denotes the embedding of user𝑢in the source domain, andˆ𝒖represents the transformed embedding. Finally, we can utilize the transformed embeddingˆ𝒖for prediction. To train the meta network and characteristic encoder, we can minimize the distance using themapping-oriented optimization Meta Network… Personalized … Bridge procedure following existing bridge-based methods [4, 9, 16, 39]: whereˆ𝒖denotes the transformed user embedding from𝒖in the source domain, and𝒖denotes the user embedding in target domain. The mapping-oriented optimization procedure would bring the transformed embeddingˆ𝒖close to the target embedding 𝒖. However, since some users only have limited interactions, the user’s embedding𝒖may be not reasonable and accurate enough. Learning towards the relatively unreasonable embeddings would lead to negative impact on the model. Thus, we propose a taskoriented optimization to train the meta network and characteristic encoder. The task-oriented training procedure directly utilizes the performance of the ultimate recommendation task as the optimization goal. In this paper, we focus on rating task, so the task-oriented loss can be formulated as: whereR= {𝑟|𝑢∈ U, 𝑣∈ V}denotes the interactions of overlapping users in the target domain. Compared with the mapping-oriented procedure, task-oriented optimization has two advantages: (1) The task-oriented optimization can alleviate the eects of unreasonable embeddings. It directly uses the rating data, which is ground truth rather than approximate intermediate results. (2) The task-oriented learning procedure has more training samples, which can avoid overtting. For example, with𝑁overlapping users, each user has𝑀ratings. The mappingoriented process learns the mapping function with|U= 𝑁 |samples as Equation (6), while the task-oriented learning procedure utilizes the |R| = 𝑀 × 𝑁 user-item rating as Equation (7). The overall structure of PTUPCDR is shown in Figure 2. The training procedure can be divided into three steps: pre-training, meta and initialization stages, as see Algorithm 1. After training, the method can work for both cold-start and warm-start stages. Pre-training stage: This step is to learn latent spaces for each domain, respectively. The loss function is formulated as: where|R |denotes the number of ratings. After the pre-training step, we can obtain the pre-trained embeddings 𝒖, 𝒖, 𝒗, 𝒗. Meta stage: The existing methods directly train a common bridge function, while PTUPCDR trains the characteristic encoder and the meta network. The characteristic encoder and the meta network are optimized with Equation (7). Initialization stage: When a new user comes (CDR assumes the new user has some interactions in the source domain), we use the transformed embeddingˆ𝒖= 𝑓(𝒖;𝒘)to initialize the new user’s embedding in the target domain. Test stage: For the extreme cold-start users who have no interactions in the target domain, directly utilize the initial embedding ˆ𝒖= 𝑓(𝒖;𝒘)for prediction. For the warm-start users who have some interaction in the target domain, it is convenient to ne-tune the initial embeddings with new interactions, and utilize the ne-tuned embeddings for prediction. We conduct experiments to answer the following research questions:RQ1Why we need an auxiliary domain and why we need to introduce CDR? How does PTUPCDR perform in extremely coldstart scenarios comparing to state-of-the-art models with a CDR perspective?RQ2How does PTUPCDR perform in more practical scenarios of real-world recommendations?RQ3Why could PTUPCDR perform better? Datasets.Following most existing methods [9,37,40], A real-world public dataset is adopted for experiments, namely the Amazon review dataset. Specically, we use the Amazon-5cores dataset in which each user or item has at least ve ratings. Following [9,37], we choose 3 popular categories out of 24 in total: movies_and_tv (Movie), cds_and_vinyl (Music), and books (Book). We dene 3 CDR tasks as Task 1: Movie→Music, Task 2: Book→Movie, and Task 3: Book→Music. As the details listed in Table 1, the number of ratings of the source domain is signicantly large than the one in the target domain. While many existing works only select a part of the dataset for evaluation, we directly use all data to simulate the real-world application. Evaluation Metrics.Amazon review dataset contains rating data (0 - 5 score). Following [16,37] we adopt Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) as the metrics. Baselines.Since PTUPCDR falls into the bridge-based methods for CDR, we mainly compare PTUPCDR with the bridge-based methods. Therefore, we choose the following methods as baselines for comparison. 1) TGT denotes the target MF model, which is trained only using target domain data. 2) CMF [25] is an extension of MF. In CMF, the embeddings of users are shared across the source and target domains. 3) EMCDR [16] is a popular CDR method for cold-start. It adopts Matrix Factorization (MF) to learn embeddings rst and then utilize a network to bridge the user embeddings from the auxiliary domain to the target domain. 4) DCDCSR [39] falls into the bridge-based methods, which considers the rating sparsity degrees of individual users in dierent domains. 5) SSCDR [9] is a semi-supervised bridge-based method. Implementation Details.We implement our framework and the baselines using PyTorch. For each task and method, the initial learning rate for the Adam [10] optimizer are tuned by grid searches within {0.001, 0.005, 0.01, 0.02, 0.1}. In addition, we set the dimension of embeddings as 10. For all methods, we set mini-batch size of 512. We employ the same fully connected layer to facilitate comparison for the cross-domain bridge functions of EMCDR, DCDCSR, SSCDR, and PTUPCDR. Note that the personalized bridge function of PTUPCDR is generated by the meta network. The meta network is a two-layer network with hidden units 2× 𝑘, where𝑘denotes the embedding dimension, and the output’s dimension of the meta network is𝑘 × 𝑘. The attention network is a two-layer network with 𝑘 hidden units. Following [16], to evaluate the eectiveness of the proposed PTUPCDR on cross-domain recommendation, we randomly remove all the ratings of a fraction of overlapping users in the target domain and regard them as test users, and the samples of other overlapping users are used for training the bridge function. In our experiments, we set the proportions of test (cold-start) users𝛽as 80%, 50%, and 20% of the total overlapping users, respectively. For the cold-start experiments in Table 2 and Figure 3, all ratings of test users are used as the test set. For the warm-start experiments in Figure 4, we divide the ratings of each test user into two parts with a ratio of 1:1. Note that we take the sequential timestamps into account to avoid information leakage. We use the rst part as the cold-start set, and the other as the warm-start set. The process of model evaluation can be divided into three step: 1) Train the model on the training set. 2) Test extremely cold-start performance on the cold-start set. 3) Fine-tune the target model with the cold-start set, and evaluate the warm-start performance on the warm-start set. For each task, we report the mean results over ve random runs. Table 2: Cold-start results (MAE and RMSE) of 3 cross-domain tasks. We report the mean results over ve runs. Best results are in boldface. ∗ indicates0.05level, paired t-test of PTUPCDR vs. the best baselines. 𝐼𝑚𝑝𝑟𝑜𝑣𝑒 denotes relative improvement over the best baseline. Task150% Task250% Task350% This section presents experimental results and in-depth discussions of PTUPCDR on cold-start scenarios. Following the existing bridgebased methods [4,9,16,37,39,40], we evaluate the performance of PTUPCDR on cold-start scenarios. We demonstrate the eectiveness of PTUPCDR on 3 CDR tasks under dierent values of𝛽. As the experimental results are shown in Table 2, the best performance is shown in boldface,∗indicates 0.05 level paired t-test of PTUPCDR vs. the best baseline,𝐼𝑚𝑝𝑟𝑜𝑣𝑒denotes relative improvement over the best baseline. From the experimental results, we have several ndings: (1) TGT is a single-domain model that only uses data from the target domain, and its performance is unsatisfying. Compared with TGT, all other cross-domain methods could exploit data from the source domain, thus achieving better results. Therefore, utilizing data from an auxiliary domain is an eective way to alleviate data sparsity and improve the recommendation performance in the target domain. (2) CMF uses the auxiliary data by combining the data from dierent domains into a single domain, while CDR methods are specially designed to bridge the domains. We nd that CDR methods can outperform CMF in most tasks. It is because CMF ignores the potential domain shift by regarding the data from both domains as the same. On the contrary, the bridge functions can transform the source embeddings into the target feature space, which eectively alleviates the inuence of domain shift. Thus, it is essential to study CDR by using the auxiliary domain more eectively. (3) We nd that PTUPCDR could outperform the best baseline signicantly in most scenarios, which demonstrates that PTUPCDR is eective for cold-start recommendation. In this section, we perform experiments and analysis on the compatibility of PTUPCDR with more complicated base models and its utility in the warm-start stage. 4.3.1 Generalization Experiments: Note that the bridge-based CDR methods [16,39] focus on the bridge function itself, and works in the literature mainly apply their methods upon MF to conduct experimental evaluations. However, MF is a non-neural model, and it is probably too simple to achieve satisfying performance in large-scale real-world recommendations. Thus, to testify the compatibility of PTUPCDR as well as other bridge-based methods, we apply EMCDR and our PTUPCDR upon two more complicated neural models. In other words, we use other models to replace the MF: GMF [7] and YouTube DNN [1]. GMF assigns various weights for dierent dimensions in the dot-product prediction function, which can be regarded as a generalization of vanilla MF. YouTube DNN is a two-tower model. For GMF, the bridge function directly transforms the user embeddings. For YouTube DNN, the bridge function transforms the output of the user tower. For both GMF and YouTube DNN, we train the model with data from both domains. With𝛽 =0.2, we conduct the generalization experiments on both non-neural (MF) and neural models (GMF, YouTube DNN). Other experimental settings are consistent with Section 4.1. From the results shown in Figure 3(a)(b)(c), we have several insightful observations: (1) The bridge-based CDR methods can be applied upon various base models. With dierent base models, both EMCDR and PTUPCDR eectively improve the recommendation performance Figure 3: Generalization experiments: applying EMCDR and PTUPCDR upon three base models (a) MF, (b) GMF, and (c) YouTube DNN, and show the averaged results over ve runs. Figure 4: Warm-start experiments on TGT, CMF, EMCDR, and PTUPCDR for dierent proportions of test (cold-start) users 𝛽: (a) 𝛽 =20%, (b) 𝛽 =50%, and (c) 𝛽 =80%. The light-colored histograms represent the performance of extreme cold-start scenario, while the dark-colored histograms represent the warm-start scenario. for cold-start users in the target domain. Since GMF and YouTube DNN are two popular and well-designed models in large-scale realworld recommendations, they achieve better performance than the vanilla MF. (2) The generalized PTUPCDR could achieve satisfying performance. On the one hand, with various base models, the generalized PTUPCDR can constantly achieve the best results. On the other hand, as the cold-start problem is highly challenging, the achieved𝑀𝐴𝐸is good enough to testify the eectiveness of generalized PTUPCDR in real-world scenarios. 4.3.2 Warm-start Experiments. The existing bridge-based CDR works in the literature [4,9,16,37,39] only conduct experiments on the extreme cold-start stage. Actually, bridge-based CDR methods are also highly helpful for the warm-start stage by using the mapped embeddings to initialize cold-start users’ embeddings of TGT for further training. In real-world recommendations, such warming-up scenarios [21, 42] have great application value. We conduct experiments on TGT, CMF, EMCDR, and our proposed PTUPCDR. In the warm-start training stage, i.e., warm-up process, CMF, EMCDR, and PTUPCDR can be viewed as pre-trained models for initialization. For CMF, we use the collectively trained embeddings to initialize both user and item embeddings of TGT. For EMCDR and PTUPCDR, we initialize the cold-start users’ embeddings with mapped users’ embeddings. From the results shown in Figure 4, we have the following observations: Cold-start vs. Warm-start.More interactions can improve the performance of recommender systems. We nd that all models in the warm-start stage can achieve better performance than the cold-start stage, demonstrating that more interactions can help recommendation models understand the users better. Utility.In the warm-start stage, with pre-trained embeddings as the initial embeddings, CMF, EMCDR, PTUPCDR can achieve better performance than TGT, which uses randomly initialized embeddings. PTUPCDR and EMCDR outperform CMF, demonstrating that embeddings pre-trained by bridge-based CDR methods could better exploit the source domain. Such utility of CDR methods on real-world warm-start scenarios is of great practical value. Performance.In the warm-start stage, our PTUPCDR can still achieve the best results with various test ratio of𝛽. Therefore, our PTUPCDR is useful and eective in both the cold-start stage and the warm-start stage. In this section, we conduct extensive experiments and present insightful discussions concerning three modules of PTUPCDR to explain the improvement brought by PTUPCDR and answer 𝑅𝑄3. Latent Factor Visualization.We analyze embeddings on the target-domain feature space to further investigate the reason why PTUPCDR outperforms EMCDR and to show the capacity of the Meta Network to generate personalized bridge functions. We employ the default setting of the t-SNE [2] in Scikit-learn to visualize the user embeddings learned by EMCDR and PTUPCDR on Task3 with𝛽 =0.2. Figure 5 (a) and (b) denote the embeddings of Figure 5: t-SNE visualization of randomly sampled user embeddings in target-domain feature space and transformed user embeddings. (a) and (b), (c) and (d) denotes the visualization results of EMCDR and PTUPCDR, respectively. training and test users by EMCDR, while the visualized embeddings in Figure 5 (c) and (d) are learned by PTUPCDR. The blue points denote the target embeddings taken from the target model learned with both training and test users and are regarded as ground truths, while the orange points represent the transformed embeddings. For clarity, we randomly sample 100 training and test users respectively to plot. Note that PTUPCDR and EMCDR share the source and target models, and the only dierence is whether the bridge function is personalized by our PTUPCDR or learned by EMCDR. Ideally, the distributions of the transformed embeddings are the same as the target embeddings. From Figure 5 (a) and (b), we observe that the target embeddings (ground truths) are scattered, while the embeddings transformed by EMCDR are very concentrated. The main reason would be that the single bridge function is hard to capture the complex relationships between users’ preferences in the source and target domains. As shown in Figure 5(c) and (d), PTUPCDR achieves better results. For one thing, the transformed embeddings by PTUPCDR are scattered across the targetdomain feature space instead of being clustered as EMCDR, demonstrating the personalization capacity of the Meta Network and the PTUPCDR. More importantly, the distribution of embeddings transformed by PTUPCDR could better t the target embeddings distributions, which could be the fundamental reason why PTUPCDR could achieve better overall performance. Case Study.We present a case study to discuss the necessity and eectiveness of the attention-based Characteristic Encoder. As shown in Figure 6, our goal is to recommend CDs to a user who has not purchased any CD before, with the help of interacted movies of that user. Note that the darker color block below a movie represents a higher degree of predicted attention over that movie, and the shown 3 CDs are successfully recommended to this user. Figure 6: The color block below each movie represents the attention score. High attention items dominate the recommendation while others have little inuence on results. Those successfully recommended hard rock records are somewhat related to interacted science ction lms because they are both exciting. However, hard rock records are almost irrelevant to dramas and comedies. Thus, it is evident that the importance of dierent interacted items in the source domain should be modeled appropriately. Thus, it is necessary to adopt the attention mechanism to evaluate the items’ dierent contributions to knowledge transfer automatically. At the same time, although the consumed CDs are related to only part of historical interacted movies, the proposed model still could provide relatively accurate recommendations regardless of the inuence of noise from dramas and comedies, which demonstrates the eectiveness of the attention-based Characteristic Encoder. To summarize, the attention-based Characteristic Encoder could capture transferable individual characteristics, while existing bridge-based CDR methods ignore this point. In this paper, we studied cross-domain recommendation (CDR) which aims to transfer user preferences from an auxiliary domain to the target domain. Many existing CDR methods learn a common preference bridge to transfer preferences. However, a single bridge function shared by all users is hard to capture various relationships between user preferences in source and target domains. Thus, we proposed a novel framework named Personalized Transfer of User Preferences for CDR (PTUPCDR). Specically, a meta network fed with users’ characteristic embeddings is learned to generate personalized bridge functions to achieve personalized transfer of user preferences. We conducted extensive experiments on real-world datasets to evaluate the proposed PTUPCDR, and the results validate the eectiveness of PTUPCDR on both cold-start and warm-start stages. The research work is supported by the National Key Research and Development Program of China under Grant No. 2021ZD0113602, the National Natural Science Foundation of China under Grant No. U183620661773361, 62176014, U1836206, U1811461.