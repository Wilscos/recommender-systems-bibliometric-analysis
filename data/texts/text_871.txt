The advent of open-source software development, and moreover the creation of repositories where multiple open source projects are hosted, has been a boon to empirical software engineering research. Large volumes of highquality code and related a rtifacts have become accessible for analysis [28], [59]. The next step was to use the record of changes to the code to also study the software developm e nt process. A third step was to not only observe the code and the process, but to also interact with them. For example, numerous research projects aimed at building tools for code improvement report on applying t heir tools on open source projects, and then submit ting the improvement suggestions to the projects’ developers. The fraction of suggestions that is accepted is then used as an indication regarding the efﬁcacy of the tool (e.g. [54], [38], [40]). While this practice exploits the time of the developers to assess the tool, it is considered a cceptable as it conforms with the underlying principles of being “open source”, which speciﬁcally include openness to contributions from anyone. But in April 2021 the ma int ainer of the Linux kernel, Greg Kroah-Hartman, banned the Univ e rsity of Minnesota (UMN) from making contributions to the Linux kernel (for a detailed description of the whole affair, see e.g. [14]). He also reverted previous contributions from the university, pending a check that they are valid contributions. The reason was a research project from the Lu la b in the university, dubbed the “hypocrite commits” (HC) study. In this study patches that included bugs were intentionally submitted to kernel developers to see whether they would be a ccepted, under the pretext of demonstrating that open source developm e nt is vulnerable to malicious contributors [64]. In the email announcing the ban, Kroah-Hartman wrote “Our community does not appreciate being experimented on”. While many ﬁnd this study clearly unethical, there are many other situations that are not so clear cut. So when exactly do such studies constitute an unacceptable experiment? This is not an easy question to answer, and there are myriad considerations including how exactly you deﬁne “hum an subjects research” and in fact whether the discussion should be limit e d to only “research” (e.g. [61]). Rather than theorizing on the deﬁnitions and the ethics considerations involved, we decided to elicit opinions s traight from the horse’s mouth. We therefore conducted a survey among open source develope rs and asked about their reaction to various experimental scenarios. For comparison, we also sent t he survey to researchers involved in emp irical software engineering research, and speciﬁcally those who use open source projects and experimentation. As far as we know such a survey was never conducted among practitioners, and the last time a survey concerning ethics in computer science was conducted among researchers (or rather, university department heads) was 20 years ago [26]. The goal of the survey was to answer two main research questions: 1) Wha t do develope rs care about in terms of ethics in research? 2) To what degree do researchers appreciate what developers care about? The survey started out by asking whether respondents knew of the Linux-UMN incident. Subsequent questions asked about 16 possible concerns, ranging from looking at code without asking for permission to voicing an opinion about the quality of the work of identiﬁed developers. The next section outlined 16 development and research scenarios, and asked respondents to judge the degree to which they were acceptable. We collected responses from 168 developers and 56 researchers. The response rate was reasonable for this type of survey: ab ou t 9% for the developers and 30% for the researchers. This attests to an a wareness of and interest in ethics issues in such research, but also raises the danger of a selection bias, where the respondents are predominantly those with higher awareness and s tronger opinions. The results indicate tha t developers are quite open to various types of activity, be it novices who want to build a reputation, students who want to learn about open source, or researchers who want to study open source projects. However, they also tend to expect that freedoms as sociated with the software and project be respected — both their freedom to choose whether to participate in experiments, and maintaining the freedom of the code in line with its license. Researchers largely see things eye to eye with developers, but sometim e s do not fully appreciate the nua nces of developers’ opinions. The rest of the paper is structured as follows. The next section provides background on ethics in research, sta rting with general ethics considerations and continuing with how they are applied to on-line research and to software engineering research. Section3 then describes the survey and how participants were recruited. Section4 presents the results of the survey, followed by a discussion and recommendations in S e ct ion5. Finally, Section 6 lists threats to validity, and S e ction7 presents the conclusions. Experimental research on open source projects exposes some ethics considerations that have not been explored in the experiments ethics literature. 2.1 Background on Ethics in Research Experiments involving software developers fall under the regulations for ethical research involving human subjects. The regulations covering such research were developed primarily in the context of biomedical research [51]. While each country naturally has its own precise regulations, the most commonly cited are those of the U.S. Department of Health and Human Services known as “45 CFR 46” (Code of Federal Regulations, Title 45, Part 46) [55], which apply to research conducted or supported by U.S. government agencies. These regulations deﬁne research on human subjects as “systematic investigation, including research development, testing, and evaluation, designed t o develop or contribute to generalizable knowledge”, where “an investigator (whether professional or student) conducting research: (i) Obtains information or biospecimens through inte rve ntion or interaction with the individual, and uses, studies, or analyzes the information or biospecimens; or (ii) Obtains, uses, studies, analyzes, or generates identiﬁab le private information or identiﬁable biospecimens.” Using the HC study as an example, Wu and Lu wrote in their paper that “The IRBof University of Minnesota reviewed the procedures of the experiment and determined that this is not human research. We obtained a formal IRBexempt letter” [64]. More speciﬁcally, in a FAQ related to the paper they wrote “This is not considered human research. [...] We send the emails to the Linux community and seek community feedback” [63]. However, a community is comp osed of individuals, and in the end t hey did indeed interact with individua ls and obtained information about their behavior. Moreover, they t hemselves note the need to protect the identity of the Linux maintainers who handled their patches, as being identiﬁed as having approved faulty code may cause embarrassment or other inconvenience [64]. In addition, they acknowledge the problem of wasting maintainers’ time, which was the more important issue for at least some of the Linux maintainers. It seems that the ethics of a scena rio of observing people perform their work, and adding to that work as part of an experiment, has not been speciﬁcally discus sed in the literature. The basic document on the ethica l use of human subjects in research is the Belmont Report from 1979 [51]. The Report ﬁrst makes a distinction between research and normal practice, and states that if an activity contains any element of research, it should undergo an ethics review. It t hen identiﬁes three basic ethics principles: 1) Respect for Persons, so experimental subjects should be informed about the experiment and are entitled to decide for themselves whether to participate in it; 2) B eneﬁcence, comprised of the obligations to do no harm and to maximize possible beneﬁts; and 3) J ustice, meaning that the beneﬁts of the research as well as its costs should be shared equally by all. The HC study clearly fails the ﬁrst, in that informed consent was not sought. Moreover, a central tenet of open source development is trust, based on reputation and a hacker ethic of sha ring [17], [18]. The report on the incident by the Linux Foundation Technical Advisory Board speciﬁcally cites the breach of trust that contributions to the kernel are wellintended as a major offense, and in fact classiﬁes the whole affair as a “breach-of-trust incident” in its title [37]. One can also argue tha t the HC stu dy fails the second principle, as it wasted maintainers time. This was aggravated by the trust problem, a s considerable work was needed to re-assess all previous UMN contributions that had been reverted [37]. The study does seem t o comply with the third principle, in that the maintainers who’s time was wasted were not singled out for any particula r reason. Professional societies publish ethics codes for their members which often mention the Belmont Report. One example is The American Psychology Association Ethical P rinciples of Psychologists and Code of Conduct. While the bulk of this code concerns the professional conduct of psychologists, it also includes a section about research, with a detailed description of what should be included in informed consent, and how to deal wit h cases where deception is necessary to elicit spontaneous be havior [1]. the IEEE Code of Ethics, in contradistinction, focuses exclusively on professional conduct and does not mention research at all [29]. The ACM Code of Ethics and Professional Conduct also does not address the issue of ethics in research, except in saying that “The public good should always be an explicit consideration when evaluating tasks associated with research” and many other activities [3]. Informed consent is mentioned only in relation to respecting privacy: as a computing p rofessional, if you build a system that collects data, you should ensure “individuals understand wha t data is being collected and how it is being u sed”. 2.2 Ethics in Online Settings Mining repositories of open source s oftware, and in particular collecting data on software developers, is just a special case of collecting social-science data about the behavior of individuals in some context. In some cases this has clear ethical implications, for example when studying the consumption of porn [53], postings in support groups for trauma victims [31], or an LBGT forum including discussions of coming out [8]. But even if there are no clear repercussions to divulging data about participants, there is still the question of the exp e ctation for privacy and the boundary be tween “public” and “private” in an online setting [52], [8]. Such expectations exis t despite Google’s search capa bilities, which often allow the identiﬁcation of even short quotations from text (or code) which is openly accessible [41], [23]. As the above examples imply, online ethics often apply to the users of software syst e m s, especially web-bas e d systems. Facebook in particular provides several relevant ca se studies with increasing severity. The ﬁrst level is using A/B testing to improve the product [21]. This means that new features are added only after being teste d with real users in live action, unbeknownst to those users, to se e that they lead to a favorable response. This practice is widely us e d in many if not all web-bas e d companies [33], [32], [20]. However, it introduces two ethical difﬁculties. First, there is no informed consent by the users to participate in the experiment. This may be excused on the grounds that users don’t know what version of the system they are using anyway, and this changes daily. But this leaves the second issue, which is what the exp e riment is really trying to optimiz e . It may be that the beneﬁts are for the company and not for the users, e.g. when the desired effect is to improve the monetization from using the product, even if this comes as the expense of the users in terms of expenses (on ecommerce sites) or detrimental effects like addiction. The second lev e l is facilitating other research, which is not directly related to improving the service to use rs [30]. For example, a much-cited research done using Facebook data concerned the transmission of em otions among social network users [34]. To do so, “the experiment ma nipulated the extent to which people (N = 689,003) were exposed t o emotional expressions in their News Feed”. This manipulation was just iﬁ e d by Facebook being a private company, hence not bound by regulations on research supported by the government, and by the fact that the analysis performed “was consistent with Facebook’s Data Use Policy, to which all users agree p rior to creating an a ccount on Facebook, constituting informed consent for this research”. However, this lenient interpretation of informed consent elicited an expression of concern from the Editor-in-Chief of the journal where the research was published [56]. The third level is facilitating direct manipulation of the public, as in the infamous Cam bridge Analytica a ffair (for a detailed description of this affair, see e .g. [39]). On a superﬁcial level the ethical problem was that around 270,000 Facebook users gave informed consent to use their Facebook data for psychological proﬁling, but using Facebook’s Open Graph plat form the proﬁling app actually collected data also from their Facebook friends’ accounts, tota ling 87 million users. The more insidious problem was that Cambridge Analytica claimed to have used t his data to manipulate voters in the 2016 USA elections, which may have contributed to the campaigns of Senator Ted Cruz and President Donald Trump. 2.3 Application to Software engineering Research Vinson and Singer att e m pt to adap t the Belmont principles for the special case of experiments in software engineering [58], [47]. They retain the ﬁrst two principles, of informed consent and beneﬁcence, and add two more: maintaining the conﬁdentiality of all information shared by the experimental subjects , and ensuring scientiﬁc value, in particular by using established methodology. The Menlo Report on Ethical Principles Guiding Information and Communication Technology Research is also based on the Belmont Report. It adopts the three original principles, and adds Respect f or Law and Public Interest [5]. However, in doing so the Menlo Report actually conﬂates ethics with legal issues and with safety. This is a result of two fa ctors. First, their focus is on security research, including whiteha t hacking and the st udy of malware. Studying malware can be dangerous, but this is not an ethical issue but a safety issue, just like s tudying explosives in a chemistry lab is not an ethical issue but a safety issue. Second, t he law may indeed step in when ethics standard fail. For example, the European GDPR and the California CPA were a response t o lack of respect for privacy and information secu rity on the side of hi-tech companies. But while this may affect research, the motivation was unrelated to research. And et hics is more than just abiding by the law. In fact et hics guidelines are speciﬁcally an attempt to codify what is right or wrong beyond what t he law demands. So the Menlo Report is not so much about the ethics of human subjects research, as about all aspects of research with the potential to harm humans, mainly by exposing data about humans. Experimenting with software engineers can lead to various ethical issues, including inconvenience due to frustration or boredom during the experiment, worrying about it, and disapproval or stigmatization by co-workers due to disclosed information [46]. There is also a growing body of software engineering research that interacts with the subjects directly, e.g. using fMRI or psychological tests [22], [42], [24]. Thes e are adequately covered by procedures used in other ﬁelds which use such devices, e.g. cognitive science. Additional vexing ethical questions may come u p in the context of collab orations betwe e n researchers and industry [35]. For example, consider a company-based study where developers are ranked based on a quality analysis of their code. Should the researchers be loyal to the company, which invited them to collaborate and may be ﬁnancing them, and would be harmed by keeping lousy employees — or to e m ployee-subjects, who trust them with their data, and might be ﬁred? [57]. As it is hard to anticipate and regulate all such potential conﬂict situations, they imply a need for open discussions among the collaborators to map out the issues and decide on how to deal with them. A recurring subject in previous investigations on ethics in software engineering research is the use of student subjects in exp e riments. The risk here is that the researchers are also the professors, and the situation might be perceived by the students as coercive [36], [47], [46]. Thu s at a minimum one needs to uphold anonymity, and allow the option to opt out, thereby negating the fear of inﬂuence on grades. There has also been concern regarding harm to the students’ academic progress. Therefore, especially when experiments are carried out as part of compulsory classes, they should have educational goals [47], [12], [10], [13]. Examples include the opportunity t o learn or exercise some technique or methodology, being exposed to cutting-edge ideas and p rocedures, and more [50]. At the same time , one should consider whether the students could have learned the same things more efﬁciently in some other way, and whether it is fair to grade them on their performance in an experiment, especially if they we re divided into groups that used different treatments? 2.4 Considerations for Open Source Most of the research using open source projects is based on repository mining, which is usually not thought to cause ethical problems. But even su ch a seemingly benign approach can have implications (Table1) [23]. For example, developers and eve n companies can be harmed as a result of research ﬁndings, like if developers are ranked based on a quality analysis of their code or if intellectual property is revealed [57]. In this open source is no different than research on any other software. Things become different when researchers interact with the open source developers, as in the HC s tudy. The goal of the HC study (which led to the ban on UMN contributions to the Linux kernel) was to raise awareness of how vulnerabilities can be introduced to open-source software on purpose by malicious agents [64]. The idea was t o analyze the code and create “hypocrite” pa tches that added a missing condition for a vulnerability, thus turning “immature vulnerabilities” into real vulnerabilities. As a proof-of-concept, they prepared 3 patches that created “ use after free” bugs in Linux. They claimed that this was done safely, and that the buggy code was only exchanged in emails, and indeed the 3 buggy patches were rejected by Linux maintainers. But the main fault developers found with the study was the lack of obtaining consent. Other unique ethics issues with open source concern whether and how the research interacts with the open source philosophy. At the most basic level the issue is one of openness and freedom. On the face of it there should not be any problem. A well-known adage regarding free software likens it to free speech a s opposed to free beer. The implication is that anyone can do whatever they want with the code [16], [62], and the problem is not in exposing it but only when it is conﬁned and restricted. Indeed, the hacker ethic of free information justiﬁes using sys tems in uninte nded ways to uncover their inner working [16]. However, one may question whether it is ethical to use public data for purposes other than intended by its authors [19]. Opening source code is not done to facilitate research — it is done to improve the code and beneﬁt it s users. So using it for other purposes may require the consent of the aut hors. But who do you ask for consent for using code from a long lived project where developers come and go with time? [23] The ﬂip side of openness is the danger of compromising privacy [66]. Vinson and Singer comment that developers who identify themselves as authors of open-source code cannot expect p rivacy, a nd therefore using their code — and even identifying them — does not fall under the usual limitations of human su bjects research [58], [47]. But according to Berry, the question is “Is the Internet a space in which e m bodied human beings interact? Or is it a text ual repository where authors deposit work?” [11]. The difference brings up considerations like copyright and fair u se of artifacts, not necessarily from the legal perspective, but from t he social perspective. For example , software published under the GNU public license requires any derivative work to be published under the same open license. Legally s peaking, quoting from such software in research probably falls under fair use. But ethically, is it acceptable to republish even jus t short pieces of code in copyrighted papers, given the speciﬁc license provisions? [11]. Moving beyond privacy, removing restrictions on using open source data may lead to risks that developers may not be aware of. One example of the need to keep information conﬁdential is when studying the development process, and some employees do not follow prescribed practices [9]; exposing this is part of the research goal, but if the employees are identiﬁed they might be punished or e ven ﬁred. As this examp le shows the risk also depends on the style of the research. There is a difference between actual reading and analysis by human researchers and the publication of speciﬁc identiﬁed quotes, and m assive-scale automated analysis using machine learning, where the end result is just statistical observations. And indeed, developers are sometimes sensitive to their priva cy, and even may disassociate themselves from code t hey had written, as evidenced by the existence of services like Gitmask. This casts a shadow on research practices such as ana lyzing developers’ e m ails [4]. A more philosophical level concerns the issue of contribution. At the core of open source software development lies the notion tha t anyone is invited to contribute to the project. So the basic expectation is that people will give to the project, especially if they also beneﬁt from it. For exam ple, Grodzinsky et al. write about the ethical responsibilities of open source developers, including the obligation of organizations who use open source software to also contribute to the community, and the obligation to produce high-quality code [25]. Yu writes about the reciprocity in ﬁrms’ open source policies, and how it contributes to their b usiness performance [65]. Finally, it is not clear that a legally or even ethically centered discussion is t he right approach. As Bakardjieva and Feenberg write, “alienation, not p rivacy, is the a ct ual core of the ethical problems of virtual community research” [6]. Our survey is speciﬁcally designed to obtain input from the community its e lf about what really concerns them. To the best of our knowledge the closest work to ours is a superﬁcial survey of department heads regarding awareness and procedures for ethics approval of software engineering experiments with human subjects, published b y Hall and Flynn twenty yea rs ago [26]. We conducted a deeper survey of the considerations involved, a s seen by the researchers themselves, and, more importantly, by the potential experimental subjects. 3.1 Survey Structure The survey contained four sections: 1) Questions about the Linux-UMN incident; 2) General ethical considerations regarding performing research on open-source projects; 3) A list of short scenarios describing contributions to open-source projects or research on such projects, asking for judgment on whether they constitute acceptable behavior; 4) Demographic questions used to characterize and classify the respondents. The questions are detailed below together with the results. Each section ended with an option to provide general comments. In writing the questions about e thics considerations, we used concrete questions rather than asking about abstract principles. For example, instead of asking about t he principle of not pu tting experimental su bjects at risk, we a sked about voicing an opinion about the quality of developers’ work. Likewise, instead of asking about the principle of maintaining privacy we as ke d about reading and analyzing the text of communications between developers t o better understand their social interactions. The respondents were asked to rank how much these actions are an ethical concern on a 7-point scale. The questions on acceptab le behavior also used concrete scenarios that may happen in the work on a n open-source project. Some of the scenarios focused on develope rs, for example a developer who contributes code that was not adequately tested. Other scenarios were a bout researchers, for example identifying a project whose development they had analyz e d. The respondents were again asked to judge whether they are acceptable behavior on a 7-point sca le. The survey was implem e nted on the Google forms platform. N one of the questions were m andatory, and no identifying information was collected. 3.2 Recruiting Subjects The recruiting procedure and its out come are summarized in Table2. Given the nature of the topic we aimed to collect the opinions of more experienced developers and researchers, rather than novices and students. To ensure we had subjects of both types we employed separate procedures to recruit developers and researchers. However, the distinction is not really binary, as researchers may also make code contributions to open source projects, and developers may participate in research. We therefore also asked the subjects about how they identify themselves, and t his was used to adj ust the ﬁnal classiﬁcation as described below. For developers we wanted t hose who were involved with the project and not j ust making a casual contribution. We ﬁrst selected active recent GitHu b projects, identiﬁed by a threshold of having at least 50 commits since 2020. To ensure tha t they are software projects we used the CCP (corrective commit probability) metric, and used only projects where this was between 0 and 1 [2]. This excludes projects which do not have commits that are identiﬁed as bug ﬁxes. From these projects we extracted developers who had public emails and at least 20 commits s ince 2020. There were 16,559 such developers. From them we randomly selected 2000 and invited them to participate in the survey. The invitations were made by personal emails. In most cases these were addressed using the ﬁrst name, after manual Inclusion criteriaInvitedBouncedRespondedResp. rate in project with ≥ 50 commits open source; H-index ≥ 10 checking. When the ﬁrst name could not be identiﬁed the email was addressed to “developer”. 17 emails bounced, and 180 responded, leading to a response rate of just over 9%. This is signiﬁcantly higher than the 2– 4% reported by Wagner et al. [60]. To identify relevant researchers we performed a Google Scholar search with the query “"software devel opment" experimen t "open source" github”. The query was restricted to papers published in the last 5 yea rs (since 2016). We then veriﬁed that the paper is indeed on topic based on its title (there were a few irrelevant ones, e.g. reporting on opensource software developed to analyze a physics expe riment) and published in a leading software engineering venue. From t hese p apers we selected authors who have an Hindex of 10 or above. The ﬁrst 150 papers returned b y the query yielded 48 usable papers and 102 authors. Some of the p apers were not used because all their above-threshold authors had already been identiﬁed from previous papers. The authors were again invited to participate using personal emails, addressed to their ﬁrst names. To increase the number of research participants, we conducted a second wave of invitations, based on the “empirical software engineering” labe l which researchers can attach to t heir Google scholar proﬁle. The top 100 researchers with this label were scanned, and those with papers with titles indicating work on experiments and open source in either the ﬁrst page or the last 5 years were identiﬁed. There were 57 such researchers, but 8 of them had already been identiﬁed in the previous round, so only 49 additional invitations were sent. In total then 151 invitations were sent, of which 3 bounced. 4 4 authors responded, leading to a response rat e of nearly 30 %. Participants in the survey were not paid or give n any other reward. The instructions indicated t hat advancing to the questions constitutes consent to participate. The survey and recruitment procedure were submitte d to the ethics committee for non-medical research on human subjects of the faculty of science, and received approval. Due to ra te limitations on sending emails, the invitations were sent over several weeks from the end of October to the e nd of November 2021, about 6 months after the Linux-UM N incident. We are aware of the problems with sending unsolicited emails to invite potential pa rticipants to a survey [7], [15]. The above procedure was meant to reduce the danger of sending such emails to irrelevant people, and the relatively high response rates indicate that indeed ma ny recipients found the survey relevant and important. Some even said so explicitly and expressed interest in the results. This issue is discussed further below, in the context of a survey question that addressed it and in the recommendations. A total of 180 active GitHub users responded to the developers survey, and 44 Google Scholar authors t o the researchers survey. However, some of the developers identiﬁed themselves as also be ing researchers and reported having authored multiple papers on empirical software engineering. And some of the researchers reported signiﬁcant activity in open-source development. We eventually reclassiﬁed 1 2 respondents to the developers survey as researchers, as they had self identiﬁed as researchers a nd not as paid developers. Subjects who reported being both researchers and developers were left in their original cla ssiﬁcation. All the results presented below a re after this reclassiﬁcation. Q43: Status (check all t hat apply): Professional developer (paid employee) Interestingly, the distribution of years of development experience was s im ilar for developers and researchers, with developers having only a slight edge. However there was a large difference in the distribution of number of papers published: 78% of developers had published none, and the maximum was 10. Only 14% of researchers had not published papers (or did not reply), and the median was 20. The distribu tions are shown as CDFs (cumulative distribution functions). This enables an eas y compa rison of the distribution of responses of developers and researchers. A CDF that is below and to the right of another implies a distribution biased towards higher value s. Regarding experience with open source projects, more than 30% of researchers reported having none. And the distributions of years of experience and number of projects worked on by developers dominated the respective distributions of researchers. The results for the survey questions are shown as histograms of the selected options. I n most questions the options form a scale. In these cas e s a CDF is shown too. The ﬁrst p art of the survey concerned the Linux-UMN incident. The ﬁrst question was whether the surve y participants had heard about this incident. As shown below, a substantive majority had heard about it, a nd most — and even slightly more so among developers — had followed it when it happened. In other words, this incident was an important news story for our participants. Q1: Did you hear of the Linux-UMN incident? Delving into the details, the majority of respondents thought it was justiﬁed to ban UMN from contributing to the Linux kernel. Ne arly all the rest thought this response was somewha t exaggerated, and only a handful thought it was wrong. In added comments, quite a few respondents referred to the gap between the open source community and academic researchers, some even using quite strong language concerning researchers in their ivory towers. Particular ire was reserved for the perception that researchers were using developers but then were not interested in hearing their opinions and did not solicit feedback. Q2: What do you think of the decision to ban UMN from contributing to the Linux kernel? Responses were more evenly distributed concerning the question whether the UMN IRB had erred in determining that this is not hum an research. Around 13% of developers and researchers thought they got it right. The rest of the developers were evenly split between claiming they were wrong and saying it is hard to tell; among researchers a signiﬁcant majority said they were wrong. Q3: The UMN IRB (Institutional Review Board) had given an exemption to this research based on the perception that studying the kernel patch process is not human research. Do you a gree with this judgement? When asked to identify the worst offense in the UMN study, the top spots were wasting the time of m aintainers (preferred by researchers) and the risk of distributing buggy code (preferred by developers). Some explicitly cited the lack of informed consent and violating trust; in the graph these are included under treating the Linux developers as guinea pigs. Others said all 3 offenses were equally bad; they were counted as contribut ingto each. Q4: What was the worst offense in the UMN study? It is inte resting to note that hardly anyone thought the s tudy was OK. This seems to contradict the previous question, where around 13% said it was not human research at all — but how can it be unethical if it is not human research? T his contradiction testiﬁed to the difﬁculty in deriving precise deﬁnitions, and justiﬁes the approach of asking subjects directly what bothers them. Finally, there was a wide range of opinions on whether this study could be executed in an ethical manner. Speciﬁc interesting results are that many researchers and not few developers thought it would be OK only if informed consent was given, even though such consent may harm the validity of the experiment. On the other hand many developers were also content with having the experiment cleared with project leaders without explicit informed consent from the affected maintainers. Q5: With regard to Kroah-Hartman’s comment that "Our community does not ap preciate being expe rimented on", is it at all possible to conduct an ethical experiment on whether open-source maintainers detect buggy code contributions? OK with informed consen t; risks harming validity OK with dev’s who identify as willing to participate In comments one developer cited the practices of whitehat hackers to contact the security-focused maintainers to coordinate the scope of the research up front. Others claimed the results could be obtained by other me ans. In addition, several developers s uggested t hat if maintainers’ time was wasted by a n experiment they should be compensated, either directly or by a donation to the project. 4.2 Ethics Concerns The second part of the survey was about possible ethics concerns in isolation. The respondents were asked to rate these concerns on a 7-point scale, ranging from 1 = no concern to 7 = extreme concern. We present them here in groups of related concerns. The order in which they appeared in the survey is given by t he question numbers . The ﬁrst two questions were about the openness of the code. The ﬁrst asked about using code examples without asking permission. A large majority of both developers and researchers thought this was of little or no concern. The second question was about quoting code in copyrighted articles. In this case developers were consist e nt ly more concerned than researchers. Quite a few added comments about open source licenses prohibiting this, as they require all derivatives of the code to remain free. Others commented that in general one should learn about a project’s rules and culture before us ing it in research, and respect these rules. Q6: Using code examples from the project without asking permission Q7: Publishing open-source code examp les from the project in a copyrighted article two sets of questions concerned the expectation for privacy and conﬁdentiality. A set of three questions were about using the texts written by developers to communicate among themselves. Developers were very open to having such text s read when the goal was to bette r understand technical issues; researchers were slightly more reserved. Both developers and researchers were somewhat more reserved when the goal was to understand social interactions . Q8: Reading a nd analyzing the text of commu nications between developers of the project to better understand technical issues Q9: Reading a nd analyzing the text of commu nications between developers of the project to better understand the social intera ctions between them Interestingly, developers were even more reserved about the us e of machine learning to analyze a ll the communications and derive a statistical characteriza tion. One explained in a comment that machine learning may not catch all nuances of human commu nication and especially cases of non-native-English spe akers or jokes. Q10: Using machine learning to analyze the text of all communications between developers of the project and derive statistical characterizations (e.g. "73% of comments were negative") The second s e t of questions concerned t he identiﬁcation of developers in research reports. These questions elicited a wide range of responses, from those who saw no problem even with the version asking about researchers voicing an opinion about the quality of work of identiﬁed developers, to those who we re grav e ly concerned with the version that just asked about identifying developers who had contributed to a project. In all these four questions, researchers were signiﬁcantly more concerned than developers, perhaps due to recent increased awareness of ethics issues in research. It could also be a matter of culture: one developer commented tha t in the open source culture criticism is welcome, but it s hould be a constructive discussion on how to improve and not a judgment after the fact. Another wrote “being a part of e xperiment or being judged by some noneven-a-contributor will probably lead to [...] ending any contributions”. Q18: Identifying developers who contributed to t he project in a paper about the research Q19: Identifying developers who wrote speciﬁc code or comments that were quoted in a paper about the research Q20: Voicing an opinion about the quality of the work on the project Q21: Voicing an opinion about the quality of the work of speciﬁc identiﬁed developers We also asked about interacting with developers. There was wide agreement that asking developers about their work is of little or no concern. However, the majority were opposed to engaging developers without e xplaining that this is part of an experiment and obtaining informed consent. In both questions, researchers were marginally more concerned than developers . A third question about deceiving developers so as not to affect their behavior elicited nearly uniform responses, with slightly higher concern by developers. Q11: Approaching developers to ask them about their code or the considerations which guided its writing Q12: Engaging develope rs without explaining that this is part of an experiment and obtaining informed consent to participate Q13: Telling developers that this is an e xperiment, bu t deceiving them about the details so as not to affect their behavior Two additional ques tions about the merits of experiments also led to a wide range of responses. The majority were concerned about the p ossibility of experiments with not scientiﬁc value, but there was also a sizable minority who thought this was of no concern. And there was a nearly uniform response to the possibility of using a new experimental me thodology, a lbeit with m ore respondents expressing no concern than any other single option. Q15: Using the project to test a new experimental methodology Finally, developers and researchers alike were very concerned about conduct that may cause harm to a project. There were two questions about this, one asking ab ou t contributing buggy code and the other about wasting the time of maintainers to review and reject code. Q17: Wasting the time of maintainers to review and reject code 4.3 Acceptance of Scenarios The next part of the survey presented se veral scenarios and asked whether they were acceptable. A 7-point s cale was used, as follows: -3 criminal -2 unacceptable -1 preferably not done 0 I’m not sure 1 not great but tolerable 2 reasonable and a cceptable 3 best pra ctice Respondents were asked to try and be categorical, using 2 and -2. As in the previous part, we present the scena rios here in groups that do not necessarily correspond to the order in which they were presented in the survey. Three of the ques tions were about contribut ing to an open-source project for self beneﬁt. The results show that this is an acceptable or at least tolerable pra ct ice, with only a small minority of respondents indicating that preferably it would not be done. Q23: A novice programmer contributes beginner-quality code in an attempt to build up his or her reputation Q29: A student contributes code to learn how open source deve lopment works Q25: A developer contribut e s code that caters to a speciﬁc personal need Another pair of questions were about various conditions that may occur with regular contributions. As expected testing plays an important role: contributing code that was tested is acceptable even if it still contains a bug (which the tests failed to uncover), while contributing code that was not adequately tested usually thought to be unacceptable or at least that should not be done, although some also thought it was tolerable. Q24: A developer contribut e s reasonably te sted code that unknowingly still contains a bug Q26: A developer contribut e s code that was not adequately tested Continuing this sequence, three questions concerned the contribution of code generated by an a utomatic tool. Contributing such code after checking it manually was generally considered acceptable. But contributing code from an experimental tool to check whether it would b e accepted, thereby obtaining an evaluation of the tools quality, elicited a wide range of less favorable responses. Interestingly, the responses were somewhat more accommodating for experimental tools by researchers than for novel tools by developers. In comments, several respondents suggested that automatically generated patches should be identiﬁed as such. This would run the risk that develope rs are prejudiced against tools [40]. And another comment wa s that only the code is really important, and not who or what produced it. Q27: A developer contribut e s code based on an au tomatic tool after verifying it manually Q28: A developer contribut e s code generated by a novel tool he or she is developing to see if the tool’s output is good enough already Q32: A researcher contributes code sugges ted by an experimental tool he or she is developing to a ssess the tool’s possible contribution The next four questions turn to research scena rios. There was wide acceptance of the u se of open source projects to perform research about code and its development , with many e ven calling it a best practice. At the same time there was strong opposition to the idea of submitting buggy code to see if it would be caught, a nd in the case of security bugs many called such behavior criminal. Q30: A researcher analyzes open source code in research on the use of certain programming language constructs Q31: A researcher contributes valid bug ﬁx e s to see how long it takes to incorporate them into the codebase Q33: A researcher contributes code with a minor bug to see if it would be caught Q34: A researcher contributes code with a security bug to see if it would be caught Additional questions concerned the identiﬁcation of the project and developers that were used in the research. Identifying the project was generally viewed as acceptable, but when the interactions among developers were studied, there were more developers who thought that it should not be done. Identifying deve lopers who wrote s peciﬁc commit messages met with signiﬁcantly stronger opposition, especially from researchers. This correlated with researchers being more sensitive to privacy as we saw above. Q36: A researcher analyzes the development t ra jectory of the code in an open-source project, and identiﬁes the project in t he research report Q37: A researcher analyzes the interactions among developers in a project, and identiﬁes the project in the research report Q38: A researcher analyzes commit message s, and includes examples with the identity of the developers in the research report The last remaining question speciﬁcally addressed the issue of sending surveys to the emails of developers of open-source projects (like this survey was conducted). This was generally considered acceptable or at least tolerable, although a non-negligible minority said that preferably it would not be done. This result contradicts Baltes and Diehl, who quote a developer who said that such unsolicited surveys are “worse than spam” [7]. And the present survey also received one response equating academic surveys to spam. But based on our results it may b e that only a small minority indeed view such practice as unacceptable. However, if developers who are opposed to such invitations refrained from answering the survey (as the one we received said he does), this result is biased. We have no way to know how many potential respondents actually think that sending unsolicited questionnaires is unacceptable, but then didn’t register this opinion for this very reason. Q35: A researcher sends a questionnaire about open source deve lopment to emails of developers listed as contributors to an open source project Wagner et al. report on a similar situation, where an addressee of a survey approached GitHub to check on them [60]. The result was a determination that they had not violated GitHub’s terms of service, bu t a suggestion to check beforehand in the future. GitHub documentation indicates that current p ractice is to set new users’ emails to “private” by default. From a perspective of over 40 years, and a vantage point of software engineering research, it seems that the Belmont report is perhaps not the best basis for discussing ethics. The terminology of “respect for persons” and “be neﬁcence” obscures some of the real concerns of practit ioners. Likewise, using US government deﬁnitions as a basis for discussions about what exactly constitutes “human research” is distracting and unproductive. Open source developers in particular seem to want to promote good, which is what beneﬁcence is all about. This starts, of course, with the drive to create good and useful software, and making it free for anyone to use. But it also includes giving others a chance to interact with the community and to develop professionally, as witnessed by the positive responses to our questions about a novice programmer contributing beginner-quality code, or a student wanting to learn how open-source works. A relevant example is the response to one of the buggy patches submitt e d to the Linux kernel as part of the HC study, where the maintainer who handled it gave suggestions on what might be done to improve it, in an apparent attempt to mentor what appeared to be a not-very-proﬁcient junior contributor. This openness and willingness to help naturally extends to researchers. It is OK to use code ex amples without asking permission. It is a cceptable and ev e n a best practice to analyze the code and the project’s history. It is p e rfectly ﬁne to read commu nications between developers, and ev e n to approach them directly, in order to better understand the project. There is also no problem with contributing valid code to the project to follow how it is treated. At the same time, what developers care ab out is obtain informed consent, and take responsibility for your work. In general decep tion and masquerading are frowned upon; however, when justiﬁ e d by the nature of the research it can be acceptable to coordinate the level of disclosure with project leaders. code or put it at risk. The whole ethos of open source development is to improve the code; doing the opposite puts you on a collision course with the communit y. Many of a project’s developers and maintainers are volunteers, and their time and good will are the scarcest and most valuable resources at the disposal of the project. Negative interactions may lead to frustration and reduced willingness to contribute. toms. Open source development is a communit y. If you want to participate, you need to accept the community standards. For example, the fair us e argument for publishing code excerpts may be irrelevant, because the developers do not see this as a legal iss ue but rather as a core values issue. Upon reﬂection, these considerations can be generalized and summarized as requirements for maintaining and justifying trust in the good intentions of the researchers. One issue which suffers from a certain divergence of opinions is privacy. This was especially apparent in the questions about identifying developers. Interestingly, there was no appreciable difference between general identiﬁcation of developers who contributed to a project, and speciﬁc identiﬁcation of developers whose work had been analyzed. The divergent opinions are probably a result of the clash between two ideals: that of openness and attribution, which favors the identiﬁcation of developers, and that of avoiding harm, which may favor protecting their identity. Further support for this conjecture is given by the fact that researchers, who are probably less motivated by the ideal of openness, tended to oppose the identiﬁcation of developers more than the developers themselves. A workable solution is to ask those you want to identify for their explicit preference and consent. While our results indicate that researchers generally s e e things e ye to eye with developers, the HC study incident shows that this is not a lways the case. It is therefore advisable for open source projects and repositories to draft and publish explicit rules of conduct for researchers who wish to perform research on t hem . However, one must remember that regulations only work if there is good will. For example, Sieber wrote about informed consent that “a signed consent form is a bureaucratic and legal maneuver that better protects the researcher’s institution than it protects the subject” [45]. So t he real goal is to facilitate a culture of cooperation, not just to draft regulations. Some concrete recommendations are given in Table3. These can be used in three contexts. The ﬁrst is research guidelines in open source repositories. The second is ethics codes by professional societies such as the A CM and IEEE. Such societies cater not only to pra ctitioners but also to researchers. They should therefore include research ethics can be used for research. is based on the tacit assumption that the research does not harm t he project. authors should be asked whether they prefer to be identiﬁed (for attribution) or not (for privacy). the research setting must be disclosed. and must obtain informed consent. be done in good faith. experimental one, should be noted as su ch. pose a problem, consult with project leaders. should be reduced by – Targeting only potentially interested develop e rs; – Stopping if the response ra te is low (indicating – Stopping when results stabilize (rather than tryin their guidelines, and they should reach out to affected communities for input about what to include in these guidelines. Finally, a third context is ethics committees and IRBs charged with approving experiments. S uch committees should consider not only the legal framework, but also the emergent etiquette of the communities from which subjects are recruited. Communities have opinions and want to be heard. Our survey is a n example of how such relevant guidelines were obt ained for the case of the open source community. A recurring problem is recruiting projects and developers to participate in research [15], [7]. Ideally this should be ba sed on an opt-in mechanism to av oid spamming, but such a mechanism does not exist. The suggestion by Wagner et al. that over 30,000 invitations should be sent to obtain 400 respondents for a survey seems excessive; with such a low response rate they probably have a strong selection bias which inva lidates the statistical assumptions. And such a large number of invitations imp lies that they are sent over some period of time. This can be used to reduce the spamming in two ways. First, if the response ra te is found to be very low, t his imp lies t hat a wide gap exists between what the researchers are interested in and think is important and what invitees care a bout. Asking t hem about things they don’t care about makes it spam. So if the response rate is too low the s urvey should be stopped. Second, researchers should analyze the results as they are collected, and discontinue data collection as soon as they appear to stabilize enough for their needs. Our survey, like any opinion survey, suffers from a potential threat to construct validity. Res pondents spend only a few seconds forming opinions on hypothetical scenarios that they have not experienced. For exa m ple, developers may not fully realize t he risks they take when research is performed on their code, e.g. if they are identiﬁed and presented in a negative light. This should be kept in mind especially with regard to privacy and conﬁdentiality. In addition, as some respondents noted in their comments, survey questions cannot really fully describe a situation, and therefore in many cases the actual ans wer is “it depends”. We note, however, that the vast majority of respondents did make selections from the given options and did not skip questions or select “other”. A bigger problem is the threat to external validity, namely whether our results are representative of developers and researchers in general. This has two facets: whet her the sample is big enough, and who is included in it. Regarding the size of the sample we checked the results obtained from only half our respondents, 88 developers and 22 researchers, and found that the results for developers are essentially the sa m e , and for researchers ve ry close, despite their low number. It therefore seems that the sample size is not a problem, and the results are representative for developers and researchers who respond to such surveys. However, external validity may still be compromised due to a possible selection bias. Our participants reﬂect a self-selection to accept the invitation and a nswer the survey. It is reasonable to assume that pra ctitioners who knew about the Linux-UMN incident — and especially those who have strong opinions about being experimented on — had a higher tendency t o participate. I ndeed, some of the respondents included ra ther emotional comments such as “We are NOT computers” and “Consent. It’s a thing now. Get it.” and even much stronger la nguage. At the same time, those who couldn’t care less about ethics most probably just deleted the invitation email and did not participate. The results may therefore not be representative of t he whole population of developers and researchers. Note, howev e r, that this implies t hat our results may be conservative. Both open source developers and software engineering researchers come from a t e chnical background. As such the y may have blind spots when it comes to social issues and to ethics. As Harrison wrote, “Physicis ts don’t have to ask an electron if t hey can m e asure it, nor are they obligated to allow the electron to quit the experiment at any time” [27]. And awareness of this often leads to a reliance on (and conﬁnement to) legal requirements and licenses [5], [23]. But the laws originate from a background of privacy iss ues, and the licenses from a background of code distribution, so their implications regarding ethics issues like consent are incidental rather than intended. Current ethics guidelines were deﬁned in the context of bio-medical research, and their app lication to software engineering research requires some adjustments. For example, issues that are not well covered include opment his tory, documentation, a nd communications among developers) code, contributing tools, collaborating in other ways) One approach to reduce ethical friction is therefore to develop guidelines that are bett e r aligned with the practices of software development. S ome ideas a long this line were proposed above in Table3. Another possible approach is to join forces: instead of imposing on the research subjects and potentially alienating them, involve them as participants in the research [6]. Such an approach is in line with the open source philosophy, a nd may be expected to lead to bette r scientiﬁc results — results that are more correct and more relevant, being based on the developers’ point of view. A further step is this direction is to use participatory research: given that many researchers are also contributing developers, they can study the projects they work on from within. This proactively returns to the community [41], in a way that may be better appreciated than the publication of an academic pa per. Another alternative is to try to use industrial collaboration [43]. Such collaborations naturally enjoy high relevance, because they necessarily focus on real needs . In addition, for smaller research projects one can hire developers for experiments [48], [49], or e ven use “human computation” platforms like Mechanical Turk [44]. Like experiments on open source projects, these approaches hav e the advantage of having developers work in their normal environment. Last, the reaction to ethics violations should be carefully considered. Research like the HC study is important, and should not be discounted outright. In this speciﬁc case, its main contribution was to show how potential vulnerabilities could be turned into real vulnerabilities, and suggest that this could be hidden in innocent-looking patches. Another unintended contribution was to show that t he Linux vetting procedure works, and in fact prevented these innocentlooking commits from being accepted. But the study suffered from a s igniﬁcant ethics blind spot. To be acceptable, it should have been coordinated with the t arget project, and performed in a manner they approve. To prevent such incidents from repeating, we do not need to chastise UMN — we need to develop procedures and mechanisms to coordinate research on open-source projects. Data Availability The full responses to the survey are available on Zenodo using DOI 10.5281/zenodo.5752053. Acknowledgments Many thanks are due to all the su rve y participants, especially those who invested extra effort to write comments and explain their positions.