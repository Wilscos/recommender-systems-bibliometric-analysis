Thanks to the mature manufacturing techniques, solid-state drives (SSDs) are highly customizable for applications today, which brings opportunities to further improve their storage performance and resource utilization. However, the SSD eciency is usually determined by many hardware parameters, making it hard for developers to manually tune them and determine the optimal SSD congurations. In this paper, we present an automated learning-based framework, named LearnedSSD, that utilizes both supervised and unsupervised machine learning (ML) techniques to drive the tuning of hardware congurations for SSDs. LearnedSSD automatically extracts the unique access patterns of a new workload using its block I/O traces, maps the workload to previously workloads for utilizing the learned experiences, and recommends an optimal SSD conguration based on the validated storage performance. LearnedSSD accelerates the development of new SSD devices by automating the hardware parameter congurations and reducing the manual eorts. We develop LearnedSSD with simple yet eective learning algorithms that can run eciently on multi-core CPUs. Given a target storage workload, our evaluation shows that LearnedSSD can always deliver an optimal SSD conguration for the target workload, and this conguration will not hurt the performance of non-target workloads. Flash-based solid-state drive (SSDs) have become the backbone of modern storage infrastructures in various computing platforms, as they oer orders-of-magnitude better performance than hardware-disk drives (HDDs), while their cost is approaching to that of HDDs [8,32,36,54,55,62,68]. Thanks to the development of manufacturing and shrinking process technology [1], the industry has been able to rapidly produce SSD devices with dierent hardware congurations. Although SSD devices are becoming highly customizable to meet the ever-increasing demands on storage performance and capacity for new applications [19,55], identifying optimal device congurations is on the critical path of SSD development. This is because the SSD hardware congurations are usually determined by the requirements from applications and customers [20,41], and these congurations involve many components in the storage controller, such as ash chip specications, chip layout, block/page sizes, device buer sizes, and so on. In order to deliver optimal performance for applications in a new generation of storage device development, storage vendors usually use typical application workloads as their benchmarks to aid them to determine the device congurations. However, an SSD device has hundreds of parameters in its congurations, and these parameters usually have dependencies (i.e., the update of one parameter may aect other parameters), making it hard for hardware engineers to tune the device congurations and identify the optimal ones in a short time. This signicantly hurts the productivity of new SSD device development [20]. Furthermore, there is an increasing demand for customized storage devices from various computing platforms and applications. This is for two reasons. First, computing platforms always wish to deploy the best-t storage devices for their workloads, such that they can achieve the maximum performance. This is especially true for cloud platforms that require highly customized SSDs to support their cloud services, such as Database-as-a-Service [3] and web services [2]. As applications such as cloud storage services are evolving quickly, we need to revolutionize the conguration tuning procedure to shorten the lifecycle of producing new SSDs. Second, our study shows that storage workloads can be categorized with learning algorithms, which provides the evidence that it is feasible to customize storage devices for a specic workload type (see Figure 2), especially considering the SSD manufacturing techniques become mature today. However, there is still a long-standing gap between application demands and SSD device congurations. And our community lacks a framework that can instantly transfer application demands into device congurations of SSDs. In this paper, we develop an automated framework named LearnedSSD, which exploits both supervised and unsupervised machine learning (ML) techniques to drive the hardware congurations for new SSDs. Given a storage workload, LearnedSSD will recommend an optimal SSD conguration that delivers optimized storage performance. It leverages the linear regression techniques to expose the device congurations that have the strongest correlation to the storage performance. To present reasonable device congurations, we formulate dierent types of hardware parameters in the SSD, transfer them into the vectors in the ML model, and utilize learning techniques to explore the optimization space and identify the near-best options, with specied constraints such as SSD capacity, interfaces (NVMe or SATA), and ash memory types. To reduce the execution time of learning an optimal SSD conguration while ensuring the learning accuracy, we develop pruning algorithms to identify the most important hardware parameters in SSDs. LearnedSSD also maintains a conguration database named ConfDB that stores the learned workloads and SSD congurations. For a new workload, LearnedSSD will extract its features and compare them with the records in the ConfDB using similarity comparison networks. If LearnedSSD identies a similar workload in its ConfDB, it will recommend the corresponding SSD conguration directly, such that we can utilize the previously learned experience. Otherwise, LearnedSSD will learn a new SSD conguration for the workload, and add them into its ConfDB for future references. As many storage workloads share similar data access patterns and can be categorized into a general type (see Figure 2), LearnedSSD can assist developers to identify the most critical parameters for a type of storage workloads, and recommend an optimal SSD conguration. Our study with LearnedSSD leads to interesting insights. We summarize them into learning rules that can aid developers to prioritize their optimization strategies when producing new SSDs. For instance, (1) not all SSD parameters are equal, the layout arrangement of ash chips is an important factor for storage performance; (2) with dierent targets and conguration constraints, the tuning prcedure of device congurations are dierent, and for each parameter, its correlation with SSD performance is also dierent; (3) not all parameters are sensitive to storage performance, and some of them can be congured as the same as commodity SSDs today. To evaluate the eciency of LearnedSSD, we implemented our proposed techniques using PyTorch [72], the scikit-learn tool [5], and a production-level SSD simulator MQSim [70]. We perform experiments with a variety of storage traces. Our experimental results show that LearnedSSD delivers an SSD conguration that can achieve 1.28–34.61×performance improvement for a target workload, without hurting the performance of non-target workloads, compared to the congurations specied by the released commodity SSDs. We also show that LearnedSSD can learn a new conguration in 37.3 seconds, and nalize an optimal conguration in 121 iterations on average for a workload, with a multi-core server processor. Overall, we make the following contributions: •We present the rst study of SSD hardware parameters and popular storage workloads with learning in mind, and demonstrate the feasibility of applying the learning-based approach for identifying optimal SSD specications. •We formulate the tuning problem of SSD device congurations using a learning-based approach, and develop an Figure 1. Internal architecture of ash-based SSDs. automated learning framework that can eciently recommend optimal SSD congurations for dierent workloads. •We summarize a set of learning rules that can facilitate the hardware congurations and development of new SSDs, based on our study with LearnedSSD. •We study the eciency of LearnedSSD and show its benets in comparison with released commodity SSD settings. SSD has proven to be a revolutionary storage technology. It performs much faster than hard-disk drives (HDDs), while its price is reaching to that of HDDs. The rapidly shrinking process and manufacturing technologies have accelerated the SSD device development and enabled their widespread adoption in a variety of computing platforms, such as data centers [4, 22, 55, 68]. 2.1 SSD Architecture We present the internal system architecture of a typical SSD in Figure 1. An SSD consists of ve major components: a set of ash memory packages, an SSD controller having embedded processors like ARM, o-chip DRAM (SSD DRAM), ash controllers, and the I/O interface that includes SATA and NVMe protocols [23,31,42]. The ash packages are organized in a hierarchical manner. Their organization not only determines the storage capacity but also aects the storage performance. Each SSD has multiple channels where each channel can receive and process read/write commands independently. Each channel is shared by multiple ash packages. Each package has multiple ash chips. Within each chip, there are multiple planes. Each plane includes multiple ash blocks, and each block consists of multiple ash pages. And the page size varies in dierent SSDs. In order to manage the ash memory, the SSD controller usually implements the Flash Translation Layer (FTL) in its rmware. The FTL was developed for taking care of the intrinsic properties of SSDs. When a free ash page is written once, that page is no longer available for future writes until that page is erased. However, erase operation is performed only at a block granularity. To remove the expensive erase operations from the critical path, writes are issued to free pages that have been erased, which is also called out-of-place update. The SSD controller will perform Garbage Collection (GC) later to clean the stale data. As each ash block has limited endurance, it is important for blocks to age uniformly (i.e., wear leveling). Modern SSD controllers employ outof-place write, GC, and wear leveling to overcome these aforementioned shortcomings and maintain indirections for handling the address mapping in their FTL. 2.2 SSD Manufacturing and Parameter Tuning According to the interviews with SSD product managers [21] and our discussions with SSD vendors, nalizing the SSD hardware specications or parameters is on the critical path in the SSD design. These specications are usually determined by the requirements from applications and customers. And they involve the components of the SSD controller as shown in Figure 1. Without these specications, the SSD development cannot proceed to the manufacturing stage. With the conrmation from SSD vendors, there are more than a hundred tunable parameters in a typical SSD. To nalize the SSD specications, a straightforward approach is to test and prole application workloads with different hardware congurations. However, this is not scalable as we target dierent application workloads. Given an application workload, it is challenging for developers to test all the combinations of the device parameters. And likewise, give a new SSD specication, it requires signicant manual eort to quantify the eectiveness of the selected specications. In this work, we use the learning-based approach to automate the SSD hardware congurations. 2.3 Software-Dened Solid-State Drive With the increasing demands on storage performance from applications, we have seen a trend that modern storage systems are embracing software-dened hardware techniques [4, 22]. This allows upper-level applications to achieve maximum performance benets and resource eciency with customized storage devices. For instance, the recent development of software-dened SSDs [19,37] enables platform operators to customize the number of ash channels and chips in an SSD, with the cooperation with SSD vendors. This is especially true for both public and private cloud platforms that require highly customized SSDs to support their cloud services, such as database-as-a-service [3], web services [2], web search [37], and batch data analytics [25]. For these applications, their workloads can be highly classied. For instance, we use our proposed learning-based workload characterization approach (see the detailed discussion in§3.3) to study the storage traces from a set of popular application workloads (see Table 1). Our experiments demonstrate that each workload type has its unique characteristics, and I/O traces from the same workload type have similarities in their data access pattern, as shown in Figure 2. This provides the evidence showing that it is feasible to customize storage devices for a specic category of applications. Figure 2. A clustering of popular storage workloads. Unfortunately, our community lacks a framework that can eciently transfer application demands and characteristics into the hardware congurations of SSDs. 2.4 Learning-Based Parameter Tuning We have seen a disruptive advancement of machine learning (ML) techniques over the past decade. In general, we can categorize machine learning techniques into two types: supervised learning and unsupervised learning. As for supervised learning, it learns a set of rules with labeled datasets and then generalizes these rules to make predications for new inputs. Typical example algorithms include decision trees [26], support vector machines [69], Bayesian networks [16], and articial neural networks [14]. Unlike supervised learning, the unsupervised learning can identify unknown patterns based on unlabeled datasets, such as k-means clustering and principal component analysis (PCA) [27]. that the learning-based method is a promising approach to solve system optimization problems. However, none of them investigated their applications in SSD development, and it is unclear how can we utilize learning-based approaches to overcome the challenges of tuning hardware specications of SSDs. In this work, we will use both supervised learning and unsupervised learning to develop LearnedSSD. In this section, we rst discuss the goals of LearnedSSD. And we will present the system architecture of LearnedSSD, and its core components respectively. 3.1 Design Goals The high-level goal of LearnedSSD is to enable the automated tuning of hardware congurations of SSDs for a specic application workload with learning techniques. Specically, LearnedSSD will achieve the following goals: •It can generate an optimal SSD conguration for a target workload, while this hardware conguration has minimal negative impact on other workloads. Figure 3.System overview of LearnedSSD: LearnedSSD rst learns new workload features with clustering (§3.3). If it is similar to workloads in existing clusters in the conguration database ConfDB, LearnedSSD will recommend an optimal conguration stored in the database. If not, LearnedSSD will rst conduct (§3.4 and §3.5)to identify performance-critical parameters of SSDs. After that, LearnedSSD will conduct automated tuning which consists of three modules:performance regressionwith Gaussian process, validation (§3.6). •It can identify an optimal SSD conguration in a short time, without introducing much extra computation overheads. •It can scale to support diverse target workloads as well as dierent device constraints. In the following, we will discuss how LearnedSSD achieves these goals and overcomes the challenges in both systems building and conguration learning procedure. 3.2 System Overview We develop an automated framework named LearnedSSD, which exploits both supervised and unsupervised learning techniques to drive the specications for new SSD devices. Given a storage workload and design constraints, LearnedSSD will recommend an optimal SSD conguration that can deliver optimized storage performance shortly. To be specic, we leverage linear regression techniques to expose the device specications that have the strongest correlation with the storage eciency. To present reasonable device specications, we formulate dierent types of hardware parameters in the SSD, transfer them into the vectors of the learning models, and learn the optimal options with specied constraints, such as storage capacity and SSD interfaces (NVMe or SATA). To reduce the execution time of learning an optimal SSD conguration while ensuring the learning accuracy, we develop pruning algorithms to identify the most important hardware parameters in SSDs. We will also maintain a conguration database named ConfDB to store the learned workloads and the corresponding SSD specications. Therefore, we can utilize the learned experiences for new workloads in LearnedSSD. For a new workload, LearnedSSD will extract its features and compare them with the records in the conguration database ConfDB, as shown in Figure 3. If LearnedSSD identies similar workloads, it will either recommend a known optimal specication, or retune the SSD congurations with the recorded SSD specications, such that we can utilize previous learned experiences. Otherwise, LearnedSSD will learn new SSD specications and add the learned congurations into ConfDB for future references. As many storage workloads can be categorized into a general type (see Figure 2), LearnedSSD can also assist developers to identify the most critical parameters for a type of storage workloads. It is worth noting that LearnedSSD will ensure the recommended SSD specications will not hurt the storage performance for other generic workloads. 3.3 Learning-based Workload Clustering Unlike traditional ways of using the read/write ratio, and I/O patterns (e.g., sequential and random read/write) to categorize workloads, which cannot capture the whole picture of workload characteristics, we develop a learning-based clustering approach based on block I/O traces. We chose block I/O traces to learn the characteristics of storage workloads, because this approach does not have system dependencies and not require application semantics. To develop the learning-based workload clustering, we rst partition each I/O trace into small windows. According to our study of diverse workloads, we use 3,000 trace entries in each window by default. This is because fewer entries may lose the unique data access patterns of the trace, and more entries would generate less valid data points in a cluster, they both could hurt the accuracy of the workload clustering. The trace information used to conduct the workload characterization include I/O timestamp, I/O size, device number, block address, and operation types. We convert each window of the I/O traces into a data point, and use Principal Component Analysis [7] to transfer the data points into two dimensions. After that, we use k-means to cluster these data points. After we cluster all the data points of a new workload, we will calculate the distance between the center of the examined data points and the center of an existing cluster. If the distance is below a threshold, we make the conclusion that the majority of the examined data points fall into the existing workload cluster. In other words, the new workload belongs to this cluster. If LearnedSSD cannot identify a similar cluster, LearnedSSD will create a new cluster for the new workload. Our experimental results, as demonstrated in Figure 2, show that our learning-based workload clustering can successfully identify a cluster of storage workloads that belong to the same or similar workload type. To further verify the eectiveness of the learning-based approach for workload clustering, we divide the same workload into the training and validation datasets, and evaluate the clustering results for each workload as listed in Table 1. We observe that 95% of their data points fall into the same workload cluster on average. This provides the evidence showing that our proposed learning-based approach is sucient to identify an appropriate cluster for new workloads. It also drives the LearnedSSD design by oering the insight that it is feasible to develop an SSD which can deliver optimized performance for a category of application workloads. 3.4 Transfer SSD Specications into ML Parameters We now discuss how we can transfer the tuning problem of SSD specications for a workload category into a ML problem, such that we can automate the tuning procedure with high accuracy. To address this problem, we rst need to formulate the SSD specications into ML parameters. However, this is not easy, since we have to ensure the parameter formulation does not lose the meaningful semantic of a specic SSD hardware parameter, and the ML parameters should be able to represent the characteristics of dierent hardware specications and their correlations. To model the SSD specications via ML parameters, we formulate them into three major parts in the ML model: (1) the performance metrics used as the optimization targets for SSDs; (2) SSD hardware congurations that can be vectorized as parameters in a ML model; and (3) the conguration constraints (e.g., the SSD capacity) that bound the optimization space of the ML model. We describe each of them as follows. Performance metrics used in the ML model.As for storage performance, LearnedSSD focuses on the storage latency and throughput. To quantify whether a SSD conguration delivers optimized performance or not, we use reference performance as the baseline (e.g., the latency and throughput obtained from a commercial SSD’s congurations), and the relative performance improvements as the evaluation metrics. We set the performance optimization goal as follows: 𝐺𝑜𝑎𝑙 (𝑐𝑜𝑛𝑓 ) = (1 − 𝛼) × 𝑙𝑜𝑔(𝐿𝑎𝑡𝑒𝑛𝑐𝑦) where𝛼is a tunable coecient factor for balancing the latency and throughput at a proper scale. We set𝛼 = 0.9 by default in LearnedSSD, based on our study of dierent coecients. In our evaluation (see§4.5), we will examine the impact of the𝛼on the learning eciency. As discussed, the 𝐿𝑎𝑡𝑒𝑛𝑐𝑦and𝑇ℎ𝑟𝑜𝑢𝑔ℎ𝑝𝑢𝑡will be given as the reference performance in Formula 1 in the ML model. SSD hardware specications as ML parameters.To represent SSD hardware specications in the ML models, we transfer them into four types of parameters and use dierent ways to set their values. They include continuous, discrete, boolean, and categorical parameters. •Continuous parameter: typical examples of continuous parameter include over-provisioning ratio for GC, and the number of ash channels. To set the value of this type of parameters as we run the ML model, we identify a range of possible values it could take in advance, and divide the range uniformly into N small pieces. Therefore, LearnedSSD can take N endpoints as the possible values. For each continuous parameter, we set the range to cover all common values in commodity SSDs for ensuring the learned SSD specications are practical. •Discrete parameter: typical examples of discrete parameter include the SSD DRAM capacity, I/O queue depth, and page size. We select all their possible values and store them in a list. Therefore, we can use the list index in the vector of the ML model. Their possible values also cover all the common values. Each discrete parameter follows dierent rules as LearnedSSD sets the value at runtime. For instance, the SSD DRAM capacity will take the power of 2 as we increase it; and there are only ve PCIe bandwidth settings, according to the PCIe protocol. ML model to indicate whether a function or feature (e.g., statistic wear leveling, and greedy GC) will be enabled in the SSD or not. With the 0-1 boolean parameter, 0/1 means function enabled/disabled respectively. •Categorical parameter: As for the categorical parameter, we convert it to the dummy variable [28]. For example, there are 16 possible values for the plane allocation scheme, we create a list with the length of 16. When LearnedSSD selects one scheme, it will set the value of the corresponding index of the list to 1, and others to 0. Conguration constraints.LearnedSSD allows users to specify the conguration constraints for its conguration tuning. Typical examples include the SSD storage capacity and the interface (e.g., NVMe or SATA) supported by the SSD for interacting with the host machine. When LearnedSSD sets dierent values for its ML parameters, it will simply abandon those congurations that violate the specied constraints. And LearnedSSD will always check the constraints when it learns a new conguration. Note that LearnedSSD mainly works on the tunable parameters in SSD specications. For the lower-level circuit-relevant specications that are strictly limited by the hardware, LearnedSSD does not cover them in its tuning model. 3.5 Learning-based Parameter Pruning After we transfer the SSD specications into ML parameters, we can start to train the model. However, modern SSDs usually have hundreds of hardware specications or parameters. Although ML models today can handle a large set of parameters, it is still desirable to develop ecient and lightweight models for reducing both training and learning time as well as saving computation cycles. For example, we develop a model with 64 SSD parameters, it takes 30.7 hours to converge the model on a modern multi-core server (see the experimental setup in§4.1). Moreover, we nd that not all SSD parameters are strongly correlated to the storage performance, and it is not needed to include these insensitive parameters in the learning model. To this end, we propose a parameter pruning approach to identify the impactful parameters that could aect the storage performance of SSDs. However, we have to overcome two major challenges within the parameter pruning. First, we need an accurate measurement method to examine the importance of a parameter. This is challenging as SSD parameters usually have dependencies. As we tune a single parameter while keeping the values of other parameters xed, this may violate the conguration constraints. For example, increasing the number of ash channels could violate the constraint of the SSD capacity. On the other hand, as we tune a single parameter while updating the values of other parameters accordingly for meeting the conguration constraints, we cannot accurately determine which parameters aect the storage performance signicantly. Second, removing some of the SSD parameters may hurt the overall accuracy of the learning model. And it is challenging to quantify how each SSD parameter could aect the learning accuracy. To address these challenges, we conduct the parameter pruning procedure with two stages. Coarse-grained parameter pruning.We rst adopt a coarse-grained pruning method that adjusts the values of continuous and discrete numerical parameters with large stride length. But we ensure the values of these parameters are congured in a reasonable range, and still satisfy the conguration constraints. At this stage, we eliminate the parameters that do not have much impact on the storage performance, no matter how we change their values. As shown in Figure 4, we increase the values of the 23 numerical parameters of SSDs from their baseline setting to 16×, and measure the storage performance with dierent workloads. We observe that some parameters do not aect the storage performance signicantly (those at lines in Figure 4), we call them as insensitive parameters in this paper. We also nd that these insensitive parameters will be dierent for dierent storage workload types, therefore, LearnedSSD will conduct the coarse-grained parameter pruning for each workload type and identify the corresponding insensitive parameters. In general, we identify 9 insensitive parameters, such as Page_Metadata_Size and SATA_Processing_Delay, according to our study (see Figure 4). Note that these insensitive parameters would be updated for a new workload type. Fine-grained parameter pruning.After eliminating the insensitive parameters with the coarse-grained pruning, we continue the parameter pruning with a ne-grained approach. Figure 5. A study of ne-grained parameter pruning with linear regression for dierent storage workloads. It employs the linear regression technique LASSO [6] to identify the linear correlations between the SSD parameters and performance. Following the discussion in§3.4, we set a regression space by maintaining the SSD capacity constraint, as we vary the values of SSD parameters. Since the SSD capacity is mainly determined by the parameters related to the chip layout, such as ash page size, the number of ash channels, and the ash block size, we rst set the values for these parameters. After that, we vary the values of other parameters, and measure the regression coecient for each SSD parameter. A higher regression coecient score of a parameter means it has a closer correlation with the SSD performance. Based on the reported coecient scores, we abandon the parameter whose score is below a threshold (0.01 by default in LearnedSSD). Therefore, we can focus on the parameter tuning for the important ones. As shown in Figure 5, we remove the insensitive parameters identied by the coarse-grained parameter tuning, and also include the boolean and categorical parameters in the ne-grained parameter tuning. Given the threshold of 0.01 for the regression coecient score, we can eliminate more insensitive parameters for dierent workloads. Observations.The learning-based parameter pruning of LearnedSSD can not only help us to eliminate the insensitive parameters, but also oer interesting insights that would benet SSD development. Specically, we observe that: (1) Dierent workloads have dierent parameter sensitivity. For example, the performance of latency-critical workloads like Advertisement and WebSearch is not sensitive to the page size and over-provisioning ratio of SSDs, as they are read intensive. In contrast, the I/O-intensive workloads such as key-value stores and LiveMaps are sensitive to the ash page size. (2) Not all parameters have linear correlation with SSD performance, which generates diculties for manual tuning, and further motivates us to utilize ML techniques to pinpoint the optimal SSD specications. 3.6 Automated Tuning of SSD Congurations After the SSD parameter pruning, we now develop the ML model to learn the optimal SSD specications for various workloads. We present the system workow of LearnedSSD in Figure 6. Given a workload, LearnedSSD will rst use the congurations stored in the ConfDB as the initial conguration set, and leverage both Gaussian process regression (GPR) and discrete stochastic gradient descent (SGD) algorithms to learn dierent congurations. For each learned conguration, LearnedSSD will use a cycle-accurate SSD simulator to validate its performance until the model converges (i.e., the optimal SSD conguration is identied). In the following, we discuss each step of the workow in details. Identify the initial conguration set for a new workload.For a new workload, LearnedSSD will use the learningbased workload clustering as discussed in§3.3 to cluster the workload, and look up the learned congurations for the corresponding workload cluster in ConfDB (). LearnedSSD will use these congurations and their delivered performance to initialize the ML model. However, if there are insucient congurations in ConfDB (e.g., the ConfDB is empty), LearnedSSD will use a conguration from existing commodity SSDs and its measured performance to initialize the model ( 0 ). Quantify the congurations with a unied grading mechanism.LearnedSSD will start the conguration tuning procedure based on the initial congurations. In order to check the eectiveness of these congurations, LearnedSSD develops a grading mechanism () with the goal of unifying dierent performance metrics (see§3.4). To achieve the maximal optimizations for both data access latency and throughput, LearnedSSD uses the Formula 1 as the goal. To ensure the learned conguration for a target workload does not hurt the performance of other workloads, LearnedSSD introduces a new factor𝛽named penalty balance in its grading. Therefore, we dene the performance grade for a workload as follows: 𝐺𝑟𝑎𝑑𝑒 (𝑐𝑜𝑛𝑓 ) = (1 − 𝛽) × 𝐺𝑜𝑎𝑙 (𝑐𝑜𝑛𝑓 ) where Goal (conf) is dened in Formula 1, and𝛽 = 0.9by default based on our study (see Figure 10 in our evaluation). Search optimal congurations with the stochastic gradient descent technique.With the initial SSD congurations and their grades, LearnedSSD will use SGD to search an optimal conguration (). Specically, LearnedSSD rst identies the top three best congurations (i.e., the congurations whose grades rank at the top) from the learned congurations, and randomly selects one as the search root. In the gradient descent process, LearnedSSD expands the search space from the root by checking all the adjacent congurations under conguration constraints (e.g., SSD capacity) in each searching iteration. Given the capacity constraint, LearnedSSD tunes one or two relevant parameters at one time, and then keep those parameters that satisfy the constraint. For other parameters, LearnedSSD will adjust their values back and forth in the search space. Once we nalize the parameters for one conguration, LearnedSSD will use the GPR model to identify the conguration with the best predicted performance grade (). If its performance grade is better than the search root, LearnedSSD will set this conguration as the new search root and continue the next search iteration. The main challenge with the SGD procedure () is to balance the learning accuracy and exploitation overhead. Since there is no guarantee that the initial conguration set will cover the entire search space, LearnedSSD has to gradually expand its search space to ensure it can identify the optimal ones. However, this may cause a search space explosion. To address this issue, we introduce a heuristic exploit factor, which is the minimum Manhattan distance [77] between the conguration being exploited and the existing learned congurations. We also set a threshold for the number of search iterations (20 iterations by default in LearnedSSD) in the conguration exploration. Predict the grades of explored congurations.As discussed briey in previous descriptions, LearnedSSD uses GPR [59] to predict the grades for new congurations (). This is for three major reasons. First, GPR can provide nearly the same performance as the deep neural networks, especially in the modeling of searching optimal congurations and making recommendations. Second, it oers excellent trade-os between the explorations of new knowledge and learned knowledge [44,67]. Third, GPR provides condence intervals with low computation overhead by default [9]. In LearnedSSD, we build a new GPR model by specifying its mean function and covariance function. The mean function is congured as trainable, as the mean of the performance metrics is unknown before the learning in LearnedSSD. We use the covariance function to represent the correlation between two adjacent points in the model, and adopt both radial basis function (RBF) kernel [75] and rational quadratic kernel [76] as the regression covariance. We also add a white kernel [47] for random noise simulation. Validate the explored congurations.The learning procedure of a new conguration will terminate by checking two conditions: (1) no conguration is better than the current root conguration in the search space; or (2) the search exceeds the threshold for the number of iterations. After that, LearnedSSD will use a cycle-accurate SSD simulator to validate the eciency of the learned congurations (). LearnedSSD will run all the available workloads in the ConfDB with the SSD simulator, and report the grade for the tested conguration. Before the validation, LearnedSSD will warm up the SSD simulator by running diverse workload traces randomly. In the validation, LearnedSSD maintains a set of optimal congurations whose grades rank at the top of all the learned congurations. After a certain number of search iterations, if the overall grade of this conguration set is not signicantly updated, the learning procedure will be converged. Otherwise, LearnedSSD will update the ConfDB with the new learned conguration and start another search iteration until the learning procedure is converged. 3.7 Implementation Details We implement the LearnedSSD framework with Python programming language. LearnedSSD supports the storage traces collected with blktrace which is available on a majority of computing systems. It uses Principal Component Analysis and k-means algorithms in the learning-based workload clustering. LearnedSSD utilizes the Sklearn library [5] to develop the statistic learning model that supports both SGD and GPR algorithms. LearnedSSD adopts the MQSim [70] as the backend SSD simulator to validate the learned congurations. Note that LearnedSSD is also compatible with other SSD simulators, therefore, SSD vendors can replace the open-sourced MQSim simulator with their own simulators. LearnedSSD implements the ConfDB with the key-value store LevelDB, in which the key is the workload cluster ID, and the value includes the corresponding SSD congurations and their performance obtained from the SSD simulator. The value is organized in JSON format. LearnedSSD provides a simple interface set_cons (capacity, interface, ash_type) to enable end users to specify their conguration constraints SSD capacity, interface (i.e., NVMe or SATA), and the ash type (i.e., SLC, MLC, and TLC). We will open source LearnedSSD to benet future study. 3.8 Discussion and Future Work In this work, LearnedSSD mainly works under the congurations constraints that include storage cpacity, interfaces, and ash types. However, its learning techniques and workow Table 1. Application workloads used in our evaluation. are also suitable for identifying the optimal SSD congurations with other constraints, such as the economic cost and energy eciency of the SSD. Unfortunately, a majority of SSD vendors are not willing to open source the specications of the cost and energy consumption of each hardware component of the SSD. Therefore, we do not study these conguration constraints in this work. We wish to explore these dimensions as the future work. Our evaluation shows that: (1) LearnedSSD can learn optimal SSD congurations for a given workload, and the learned congurations can deliver improved storage performance, compared with commodity SSD congurations (§4.2); (2) LearnedSSD can instantly learn an optimal conguration with low performance overheads (§4.3); (3) LearnedSSD works eciently under dierent conguration constraints (§4.4); and (4) LearnedSSD itself is also tunable for satisfying various performance requirements from end users (§4.5). 4.1 Experimental Setup In our evaluation, we use 7 dierent workload categories as shown in Table 1. These workloads cover various workload types that include key-value stores, databases, map services, advertisement recommendations, batch data analytics, web search services, and cloud storage [40]. Each workload type includes multiple storage traces. All the storage traces are either collected from university servers or enterprise servers. We run the LearnedSSD framework on a server, which is congured with 48 Intel Xeon CPU (E5-2687W v4) processors running at 3.0GHz, 96GB DRAM, and 4TB SSD. Since LearnedSSD uses the statistic learning models, it does not require GPUs in its learning procedure. We use the congurations of Intel 590 SSD, Samsung 850 PRO SSD and Z-SSD as the baselines, and compare the learned congurations with them to evaluate the eciency of LearnedSSD. 4.2 Eciency of Learned Congurations We rst evaluate the eciency of the learned congurations with LearnedSSD. We use the Intel 590 SSD as the reference. We set the conguration constraints as [SSD capacity = 1TB, interface = NVMe, ash typ e = MLC]. With its conguration in the SSD simulator, we run all the workloads in Table 1 to measure their performances. After that, we use the reference conguration and the measured performances to initialize ConfDB. And then, we feed the storage traces from dierent Table 3.Learned congurations for dierent workloads. AD: workload types into LearnedSSD to learn new congurations. Once the learning converges, LearnedSSD will report the best SSD conguration for each workload. We show the performance of learned congurations in Table 2. In comparison with Intel 590 SSD, the learned SSD congurations can reduces the storage latency by 1.28–34.61× for the target workload, while decreasing the storage latency by 8.38× on average for non-target workloads. The learned congurations can also improve the storage throughput by up to 5.25×for bandwidth-intensive applications such as the database and cloud storage workloads, without hurting the throughput of other workloads. To further understand the learned congurations, we list the critical parameters of the learned congurations in Table 3, in comparison with the reference conguration of Intel 590 SSD. As we can see, for dierent target workloads, LearnedSSD will learn dierent values for these parameters, although some workload types share the same congurations. To achieve improved SSD performance, LearnedSSD increases the number of channels for most of the workloads, while adjusting the ash chip layout (e.g., the number of chips per channel) accordingly to satisfy the SSD capacity constraint. LearnedSSD will also adjusts the page allocation scheme [71] to optimize the data layout for dierent workloads. Similarly, LearnedSSD tunes the SSD DRAM capacity and I/O queue depth according to workload characteristics. Our work LearnedSSD proves that it is feasible to utilize ML techniques to automate the tuning of SSD congurations. 4.3 Learning Time of LearnedSSD We now examine the learning time of LearnedSSD. We report the numbers for dierent target workloads in Figure 7. Figure 7.Learning time of LearnedSSD for dierent workloads. Table 4. Overhead sources of LearnedSSD. LearnedSSD can learn an optimal conguration in 6.65–23.70 hours. And it will incur 121 search iterations on average to pinpoint the optimal conguration. To further understand the overhead source of LearnedSSD, we prole the execution time of its critical components on the multi-core server as described in§4.1, and show the results in Table 4. Our proling results demonstrate that LearnedSSD can nish each search iteration within only 37.3 seconds. And the major performance overhead of LearnedSSD comes from the simulator validation, as we need to warm up the simulator before each validation. However, LearnedSSD only needs to validate the best conguration (selected based on the predicted grade with GPR) in each search iteration. 4.4 Sensitivity to Conguration Constraints We now evaluate how LearnedSSD performs as we change the conguration constraints that include the ash types and device interface. To evaluate the sensitivity to ash types, we use Samsung Z-SSD, which is a NVMe SLC SSD, as the reference conguration. To evaluate the sensitivity to device interface, we use Samsung 850 PRO, which is a SATA MLC SSD, as the reference conguration. We present the performance of the learned congurations for dierent workloads in Table 5 and Table 6 respectively. Table 5 shows that the congurations learned by LearnedSSD can reduce the storage latency by 3.61–19.28×, and improve the storage throughput by up to 8.00×for NVMe SLC SSDs for the target workload, compared to the Samsung Z-SSD. Figure 8. The learning procedure of LearnedSSD for NVMe and SATA SSDs, as we target batch data analytics workload. Table 6 demonstrates that our learned congurations can deliver up to 8.41×latency reduction and 2.63×throughput improvement for SATA SSDs for the target workload, in comparison with Samsung 850 PRO. In order to understand how LearnedSSD tunes the device parameters, we record its learning procedure and conguration grades at runtime. As shown in Figure 8, we present the proling results of learning the optimal congurations for the target workload BatachDataAnalytics for NVMe and SATA SSDs, respectively. The top subgures in Figure 8 demonstrate how the conguration grade will be updated after each search iteration. As discussed in§3.6, the learning procedure will converge when the grade of the congurations becomes stable. We show the learning procedure of the critical SSD parameters in the below subgures in Figure 8. We observe that, with dierent conguration constraints (NVMe vs. SATA), (1) the learning procedure will be different; (2) for each parameter, its correlation with the SSD performance is also dierent, making it impossible for developers to manually tune them; (3) not all parameters are equal, some parameters are insensitive to storage performance. LearnedSSD framework can help developers identify such parameters for dierent workloads under dierent conguration constraints, which could improve the productivity of SSD development. 4.5 Performance Impact of the Balance Coecient As discussed in§3.4 and§3.6, LearnedSSD uses the coecient factor𝛼(Formula 1) to balance the storage latency and throughput in the learning procedure, and denes the coefcient factor𝛽(Formula 2) to balance the penalty (weight) between the target workload and non-target workloads. Both of them are tunable in LearnedSSD, which allows end users Figure 9.Performance impact of the coecient factor for balancing the latency and throughput for a target workload. to adjust them per their needs. In this part, we evaluate their impact on storage performance. We vary their values from 0.01 to 0.99, and measure the performance of the learned congurations for the three representative workloads database, key-value store, and LiveMaps. As we examine each value of𝛼and𝛽, we reset the ML model and initialize the ConfDB. We show the experimental results in Figure 9 and Figure 10. With the coecient factor𝛼, our goal is to achieve the maximum improvement for both latency and throughput. In Figure 9, as we increase the value of𝛼from 0.01 to 0.3, the latency of the target workload is dramatically improved, however, its throughput is lower than the reference conguration. As we further increase its value to 0.9, we can achieve both improved latency and throughput for all the three target workloads. Thus, LearnedSSD sets 𝛼 = 0.9 by default. With the coecient factor𝛽, our goal is to achieve the maximum performance improvement for both the target workload and non-target workloads. As LearnedSSD learns new congurations, it is usually easy to achieve the improved performance for the target workload. However, this may decrease the performance for non-target workloads, which could impede the widespread adoption of the learned congurations. As we vary the value of𝛽, we observe that there is such a sweet spot (𝛽 = 0.9) that can delivers maximal performance improvement for the target workload, while having minimal negative impact on the non-target workloads. SSD Performance Optimization.SSDs has been widely used in modern storage systems to meet the I/O performance and storage capacity requirements of data-intensive applications, such as databases, cloud storage, web search, and big-data analytics [35,46,50,63,64,81]. Although these applications have high demands on I/O performance and their workload have unique data access patterns [17,34,82], they normally employ generic SSD devices [13,57,65], which Figure 10.Performance impact of the coecient factor for balancing the performance between the target workload and non-target workloads. causes suboptimal performance and resource eciency. In this paper, we develop LearnedSSD to facilitate the development of customized SSD devices for applications with improved performance. Recently, researchers proposed the software-dened ash and open-channel SSDs to enable applications to develop their own storage stack for improved storage utilization and performance isolation [36,48,56]. They show that there is an increasing demand on softwaredened storage. However, there is a longstanding gap between the application demands and device specications. We develop LearnedSSD with the goal of bridging this gap. Machine Learning for Systems.Most recently, researchers have started to leverage machine learning techniques to solve system optimization problems, such as the task scheduling [58,74,83], cluster resource management [12,18,24, 52,79], performance optimizations [33,45,51,84], data management [10,43,49,73], and others [53,78]. However, few studies conduct a systematic investigation of applying the learning techniques to develop SSD devices. To the best of our knowledge, LearnedSSD is the rst work that utilize the learning techniques to enable the automated tuning of SSD specications. We believe it will not only benet SSD vendors and manufacturers but also platform operators such as those for cloud services and data centers. SSD Device Development.Along with the architecture innovation, the industry community has developed mature manufacturing techniques and fabrication process to produce new storage devices, such as Z-SSD [61], Optane SSD [39], ZNS SSDs [60,85]. As the industrial revolution has moved into the fourth/fth generation (Industry 4.0/5.0) powered by the articial intelligence [29,38], storage devices should also become highly customizable for applications. Unfortunately, we are lacking an eective framework that can transfer application demands into storage device development. In this work, we focus on building a learning-based framework to address a critical challenge with the SSD development – how to eciently identify the optimal SSD specications for meeting the needs from target applications under constraints. We build a learning-based framework named LearnedSSD for enabling the automated tuning of SSD specications. Given a storage workload, LearnedSSD can eciently learn an optimal SSD conguration that delivers the maximum performance improvement even under dierent conguration constraints. LearnedSSD can signicantly reduce the manual eorts in the SSD device development. Our experiments show that our learned SSD congurations can signicantly improve the storage performance for a target workload, without hurting the performance of non-target workloads.