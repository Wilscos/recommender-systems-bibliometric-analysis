Recommender Systems are algorithms that predict a user’s preference for an item. Reciprocal Recommenders are a subset of recommender systems, where the items in question are people, and the objective is therefore to predict a bidirectional preference relation. They are used in settings such as online dating services and social networks. In particular, images provided by users are a crucial part of user preference, and one that is not exploited much in the literature. We present a novel method of interpreting user image preference history and using this to make recommendations. We train a recurrent neural network to learn a user’s preferences and make predictions of reciprocal preference relations that can be used to make recommendations that satisfy both users. We show that our proposed system achieves an F1 score of 0.87 when using only photographs to produce reciprocal recommendations on a large real world online dating dataset. Our system signicantly outperforms on the state of the art in both content-based and collaborative ltering systems. Recommender Systems, Reciprocal Recommender Systems, Recurrent Neural Networks, Social Recommendation Recommender Systems (RS) are personalisation tools that are used by online services to recommend items to users [20]. RSs usually make recommendations by computing a preference score between 0 and 1 that represents the extent to which a particular user would like a particular item. This is done by using explicit preference information (for instance, a user’s prole where they have specied their preference) or implicit preference information, such as a user’s purchase history. RSs have become increasingly advanced over the last decade, and most popular online services such as Amazon and Netix use them to enhance their users’ experience [3]. Reciprocal Recommender Systems (RRSs) are a subtype of RSs that recommend people to other people. They are commonly used in online dating and social services. While RSs make recommendations based on a unidirectional preference relation involving an inanimate item, RRSs are inherently more complex in that they must make recommendations based on both sides of a bidirectional preference relation. Applying a conventional recommender system to a reciprocal environment results in recommendations that are only satisfying to one of the two users involved in the interaction. RRS design also involves a number of considerations that are not involved in unidirectional recommendation. For instance, a popular product being repeatedly recommended is not usually a problem, but a popular user appearing in everyone’s recommendations often represents a negative experience for that user [10]. RRSs are often adapted from RSs, where two unidirectional preferences are computed and then combined into a single preference score that represents the preference of two users for each other. RSs (and therefore RRSs) are often categorised as content-based or collaborative ltering systems. Content-based systems make recommendations based on a user’s preference for specic aspects of an item. These preferences are sometimes explicit, but are more usually inferred implicitly from a user’s preference for previous items [1]. Collaborative ltering algorithms use correlations between multiple users to make recommendations, often by extracting latent factors from a preference matrix of users and items, and inferring preference for those latent factors through historical preferences. Historically, collaborative ltering algorithms have been more effective than content-based algorithms [1]. However, in content-rich environments, the reverse can be true. Content-based ltering algorithms also tend to be more eective at solving the Cold-Start Problem [12,16], where it is dicult for the system to make eective recommendations for new users because of the lack of preference history. Online dating services and social networks often provide a contentrich environment, with users making decisions about whom to express preference to based on a great many factors, including image data, free text proles and categorical data such as age and job. In particular, image data is extremely important to modern social services, with many such as Instagram using images as the basis for interactions. This has been demonstrated by informal research from industry. In this paper, we present a novel recommender system, Temporal Image-Based Reciprocal Recommender (TIRR), that uses a Recurrent Neural Network (RNN) to interpret a user’s history of preferences for images, and make predictions about their future preferences in order to make recommendations. This is a signicant improvement on the only other previous image-based RRS, ImRec[18], in the sense that it outperforms both ImRec (previously the state of the art in content-based reciprocal recommendation) and also the current state of the art collaborative ltering solutions. In addition to the advantages in terms of its improvement in the ROC curve on cross-validation, TIRR is also an advance of the eld in the sense that it provides a unied system that predicts matches directly, as opposed to two separate predictions of unidirectional preferences followed by an aggregation. There is some doubt as how to combine two unidirectional scores into a single bidirectional score in a way that is fully representative of two users’ bidirectional preference for each other; TIRR solves this by predicting the bidirectional relation end to end. The system was tested using a popular online dating service. We used 200000 users and approximately 800000 expressions of preference combined split across train and test sets. The original contributions of this paper are therefore threefold: (1)We present a content-based RRS, TIRR, that makes recommendations based on historical sequences of images utilizing Siamese networks and LSTMs. (2)Previous RRSs predict two unidirectional preferences and then aggregate them; the end-to-end algorithm detailed in this paper predicts the probability of a match directly. (3)Based on tests using real-world data, TIRR outperforms not only other content-based RRSs but also the state-of-the-art collaborative ltering RRS. This section contains a review of other academic works that formed the background for this study. This includes works on RRSs, contentbased recommendation and on recurrent neural networks for understanding image-based histories. RRSs are recommender systems used for person-to-person matching, in settings such as online dating, social networks [6] and job recommendation [22]. They are complex in the sense that they need to consider the preferences of both sides. The earliest RRS in the literature is RECON [21]. This is a contentbased recommender system designed by Pizzato et al. based on recommendation using categorical data such as age and hobbies. For two users𝑥and𝑦, the algorithm calculates the preferences of the two users𝑃and𝑃as vectors based on their historical preferences for individual attributes. Using these historical preferences, RECON estimates unidirectional preferences𝑄and𝑄and combines them using the harmonic mean into a single bidirectional preference relation that represents the projected preference of the two users for each other. RCF [27] extended reciprocal recommendation with an implementation of a collaborative ltering system. RCF uses nearestneighbour-based recommendation, where for candidate users𝑥and 𝑦it calculates the similarity between𝑥and the other users that have liked𝑦and vice-versa. RCF demonstrated improvements in a number of areas over RECON, and was at the time considered the best in class reciprocal recommender system. Subsequently, a number of systems have made improvements to both collaborative and content-based systems, in addition to designing hybrid systems that exploit the best of both subtypes. For example, Kleinermann et al. improved on RCF by reducing the bias of user popularity on recommendations [10]. ImRec demonstrated that image-based recommendation was more eective than recommendation based on categorical prole data [18]. Content-based recommender systems make recommendations based on users’ preferences for specic content on a service. This might be structured content such as the category of an item, or it might be unstructured content such as images and free text description. Recommendations based on unstructured data appear most often in news recommendation [13,24]. This is a rich area for research because news articles are often written with set structures that make them easier to process, and also because of concerns about serendipity and recommendations reinforcing existing echo chambers. Papers such as [2] demonstrate the capacity for deep learning systems based on freetext information to make eective recommendations. Examples of content-based recommender systems basing their results on images is much less common. Lei et al. used user preferences to train a model based on ImageNet [5] that predicted user preference for one of two images [14]. This trains a network to map both users and images into the same space by generating embeddings for both, with images that the user preferred being close to the user in the space, and images the user did not like being further away. User preference for subsequent images can then be predicted by relative distance from the user. Another example is DeepStyle [17], which uses a Siamese Network to predict user preference for clothes based on images. DeepStyle uses pairs of positive and negative samples with user preference as the output to dierentiate between the two images. This can then be used to make predictions about whether a user might like a new image by comparing it to an existing liked image. This paper uses Recurrent Neural Networks (RNNs) to interpret time series data for recommendation. RNNs contain loops, which feed the output of a network back into current neurons. This means that they implement a concept of memory: they store computed results, and these results have an impact on subsequent predictions. Each step therefore incorporates information from the previous steps into the prediction. Standard RNNs are particularly good at processing short sequences, but their memory is short-term memory: when training them using longer sequences, the early items in the sequence have very little impact on the nal prediction. This is known as the vanishing gradient problem [8].This also exists in deep neural networks, where early layers learn very slowly when trained with backpropagation. Various architectures have been proposed to overcome this limitation. One that has been particularly successful in allowing RNNs to hold and use information for longer is the Long Short-Term Memory Network (LSTM) [9]. A LSTM uses a forget gate comprised of a Sigmoid function that determines whether information is kept or not: a value close to 0 results in the information being forgotten by the network, whereas closer to 1 results in the information being stored. This allows for much longer sequences to be processed, which is particularly useful in the eld of recommendation, where long sequences of user behaviour are common. RNNs have been used successfully in recommender systems to incorporate time series data into recommendations [23,26], but not in reciprocal recommender systems. In this section, we describe a model that produces predictions about user preferences based on the RNN interpretation of user history. The RNN-based model uses a pre-trained siamese network at its core, so we describe that independently rst, and then its use in the context of the RNN. The online dating service we used currently only supports heterosexual relationships. We can therefore assume that for a set of users of one gender𝑋 = {𝑥, 𝑥, . . . , 𝑥}there is a set of candidate users for recommendation𝑌 = {𝑦, 𝑦, . . . , 𝑦}. A user may have an ordered history of preference expressions for users of length 𝑛, for example,𝑆𝑥 = {𝑆𝑥, 𝑆𝑥,, . . . , 𝑆𝑥}where𝑆𝑥∈ 𝑌 represents the expression of positive or negative preference of user 𝑥 for the user 𝑦at time 𝑡. In our reciprocal system, our objective is to estimate𝑅, the reciprocal preference score that represents the projected degree of preference of two users for each other. We consider that𝑅is a function of the historical preferences of𝑥and𝑦as well as the two users themselves, and train a model to predict it using all of this information: Where𝜃represents the parameters of the model. Note that contrary to most previous approaches to RRSs, our approach trains a single model to predict reciprocal preference using all of the information, as opposed to combining the results of two models predicting unidirectional preference. Also note that the reciprocal preference is symmetrical i.e. 𝑅= 𝑅. The data for our model was provided by a popular online dating service with several million registered users. On this service, the user experience is streamlined so that everyone goes through the same process of interaction. A user𝑥nds other users by searching, or by viewing recommendations on a list page. From the list page, they can view proles with images, text and categorical data. If𝑥nds a user𝑦that they want to interact with, they can send a𝐿𝑖𝑘𝑒. In our algorithm, this 𝐿𝑖𝑘𝑒 is used as a unidirectional indicator of preference. User𝑦can choose whether or not to reciprocate this𝐿𝑖𝑘𝑒. If they do reciprocate, this is considered a𝑀𝑎𝑡𝑐ℎ; if not it is considered a𝐷𝑖𝑠𝑙𝑖𝑘𝑒. These represent bidirectional indicators of preference or negative preference respectively. Users who have𝑀𝑎𝑡𝑐ℎ𝑒𝑑can subsequently message each other, and potentially agree to meet in person. As we wanted to focus on an algorithm that measured personal attractiveness of users for each other, we made the decision to exclude images from the dataset that did not include user faces using automatic face detection. It is common for deep learning based on faces to also include cropping an ane transformation of features, but preliminary experiments showed that this did not improve our results. We also made a number of exclusions in order to increase the reliability of the dataset. We excluded users who had been removed from the service for any reason (often these users are not using the service correctly, which implies that they are not expressing preferences based on their own intuition). Although for privacy reasons we are unable to release the dataset used in our experiments, we do hope that the algorithm will be reproduced on other services. Figure 1: The architecture of the Siamese network used to learn unidirectional user preferences, which forms a component of TIRR. In this section, we briey describe the Siamese network [11] we used to learn unidirectional user preferences, a building block of our proposed method, originally included as a component of ImRe c [18]. We will utilize this in a novel way to ImRec to demonstrate superior performance. 3.3.1 Siamese Network Concept. Siamese networks are commonly used in object recognition [25] and tracking [4], where they have excelled for face verication in scenarios with relatively little training data, known as one-shot or few-shot learning. As shown in Figure 1, a Siamese network consists of two symmetrical CNNs with shared weights, and a loss function based on the outputs of these two networks and a ground truth label. The network is trained from tuples of the form(𝑦, 𝑦, 𝑦)from 𝑌where𝑦and𝑦are photos of𝑦that have been Liked by𝑥and𝑦 is a photo of𝑦that has been Disliked by𝑥. Using𝑦as an anchor, two pairs are made from the tuple;(𝑦, 𝑦)is a positive pair where the expected output is 1.0 and(𝑦, 𝑦)as the negative pair where the expected output is 0.0. From these pairs, the network is trained to dierentiate between a Liked and a Disliked image, given another Liked image. The key to this is that the network uses shared weight parameters 𝑊for the training and inference process. We map𝑦and𝑦toℎ andℎusing𝑊, which are two points in a 128 dimensional space. We calculate the dierence between the two points as follows: Relating the Siamese network back to our original problem formulation in Section 3.1, this gives us a basis for estimating a unidirectional preference relation𝑃based on two images, one image from𝑥’s preference history𝑆, and the current user𝑦, solving the problem: Table 1: The layers of the CNN used as the symmetrical part of the Siamese Network. 3.3.2 Network Layers. Table 1 shows the architecture of the CNN that makes up the two symmetrical branches of the Siamese network. The small convolution kernels used have been shown to eectively identify facial features in deep convolutional networks [19]. The network was trained using an Adam optimiser, with a learning rate of 0.0001. The output of the network is a value between 0 and 1 expressed by a Sigmoid function, representing whether𝑥is more likely to Like or Dislike𝑦based on the two images. In the next section, we extend this to use the whole of𝑥’s preference history𝑆and show how this becomes an even more eective predictor of preference. 3.3.3 Loss Function. The Siamese network was trained using binary crossentropy. This is a standard loss function used in training neural networks, the formula for which is given below. In the following equation,𝑌is the binary variable representing Like and Dislike,𝐷(𝑦, 𝑦)is the embedded distance between two images, 𝑔is a neural network and𝑔(𝐷(𝑦, 𝑦))is the predicted probability of 𝐷(𝑦, 𝑦) resulting in a Like. 𝐿(𝑦, 𝑦) = −(𝑌 log(𝑔(𝐷(𝑦, 𝑦))) + (1 − 𝑌 ) log(1 − 𝑔(𝐷(𝑦, 𝑦)))) Binary crossentropy was shown experimentally to result in the highest eectiveness metrics for the network. We note that it is also common to train Siamese networks using a contrastive loss function, which uses a margin𝑚to increase the network’s error when it misclassies two very similar images. In most situations where a Siamese network is applied, such as face detection, misclassifying two very similar images is as incorrect as misclassifying two very dierent images. However, this is not true in our application, where user preferences are not necessarily categorical, and similar images are more likely to be liked by a user than very dierent images. This explains why binary crossentropy may have been more eective in our tests. The contrastive loss function is dened below, where the terminology used is the same as in equation 4 and 𝑚 is the margin: 𝐿(𝑦, 𝑦) = (1 − 𝑌 )12(𝐷(𝑦, 𝑦))+𝑌12(𝑚𝑎𝑥 (0,𝑚 − 𝐷(𝑦, 𝑦)) The Siamese network described above, when trained on unidirectional preference, is an eective if elementary model. In this section, we describe the RNN we use to interpret the user history based on the results of the Siamese network. The output of the Siamese network is a point in 128-dimensional space that represents the preference of a user𝑥for an image𝑦 based on comparison with the anchor image𝑦. Based on initial experimental work, we chose an LSTM-based RNN architecture to interpret the time series of images. The forget gate of the LSTM is particularly intuitive in this case. For a state𝑠at time𝑡, a forget gate described by𝑓, a write gate𝑖and a candidate write˜𝑠derived from the input and the previous state, the next state is described by the equation: We might intuitively expect that preferences expressed by users would change over time, and the forget behaviour of the LSTM allows us to model this, with the input for the state𝑠of the LSTM modelling the preferences of user𝑥being the user𝑆, and the nal input at𝑠being the user𝑦whom we wish to estimate𝑥’s preference for. The LSTM is visualised in Figure 2. Because users have variable length preference histories, we ll the histories of users with shorter histories with dummy images and use a masking layer to lter them. The LSTM and subsequent dense neural network form a representation in 256-dimensional space of the user’s preference as a time series. Table 2: The layers of TIRR following the mapping of images into 128-dimensional space by the pre-trained Siamese network Specically, the network consists of an input layer, which accepts a maximum of 15 outputs from Siamese networks in 256dimensional space concatenated together. Experiments determined that more than this did not signicantly alter the performance of the network. The layers are described in Table 2. If a user has fewer preferences expressed than this, the earlier images are lled with zeroes, and the network learns to interpret this as dummy data. Following the LSTM, the network consists of a single dense layer Figure 2: TIRR: the architecture to predict matches using an LSTM to interpret historical preference data on user photos. preprocesstrain LSTM imagesnetwork Figure 3: The process by which TIRR is trained. Three independent datasets used represented by dierent colours. of 128 neurons, and then a dropout layer with a dropout rate of 0.4. The network was trained with an Adam optimiser with a learning rate of 0.0001. This section describes training the network to predict matches between two users. As described in Section 3.2, our objective is to dierentiate between interactions consisting of bidirectional expressions of preference, Matches, and unidirectional expressions of negative preference, Dislikes. The full training process is visualised in Figure 3. Our experiments determined that the network trained extremely slowly when trained in its full form from an initial randomised state, and we therefore pre-trained the Siamese network segment of the network using one dataset, shown in green. The subsequent training of the full system on matches was done using a separate dataset, shown in red. The nal evaluation was done using a third dataset, shown in blue. In addition, Neve et al. demonstrated that the Siamese Network training was more eective when two networks were trained separately on male and female data [18]. As the service providing our data currently only supports heterosexual dating, this split does not decrease the usefulness of the application in this case. Training for the Siamese networks were based on 500000 triplets (𝑦, 𝑦, 𝑦)sampled from 250000 users split evenly over male and female images. Images were cropped and centered on the faces of users before training. Other methods of preprocessing such as ane transformations, which have been shown to improve the predictive power of other networks [15] did not have any impact on performance. The Siamese networks were trained to predict unidirectional preferences i.e.𝑦was an image𝑥had Liked (but not necessarily with reciprocity) and 𝑦was an image 𝑥 had Disliked. Following convergence of the Siamese network, the LSTM network was trained based on the preference histories of 100000 users to predict Matches and Like-Dislike Tuples. This dataset was separate from the dataset used to train the Siamese network. Histories were capped at one year, because of concerns that changes to the service’s design and search algorithm over time might have an eect on user preferences. They were also capped to a maximum of 15 preferences, because initial experiments showed that longer sequences did not improve accuracy, and because some outlier users express thousands of preferences, which results in an unreasonable increase in training and prediction times. Finally, the LSTM was validated on a separate dataset of 20000 Matches and Like-Dislike Tuples. There was no overlap in preference expression between the three datasets. There was overlap between the users contained in these datasets, but as in a real-world situation the system would be trained based on users on the service and subsequently used to make predictions for those users in addition to new users, testing in this way is valid and representative. In this section, we present the results for TIRR compared to the current state of the art in both content-based and collaborative ltering. RRSs generally use similar metrics for success as standard machine learning models: evaluation via the ROC Curve and the related metrics Precision, Recall and their combined metric F1 Score. However, because of the requirement for reciprocal success, their denitions are a little dierent in this scenario, so we present them here as dened by Pizzato et al. in [20]. In the following equations,𝑅is the set of recommended users,𝑅𝐿is the set of recommended users who matched with each other, and𝑅𝑁is the set of recommended users where at least one expressed negative preference for the other. As the models predict a value between 0.0 and 1.0 that represents the strength of the mutual preference relation, the ROC curves in this section are drawn by moving a threshold between these two values and plotting the true and false positive rates. We rst describe the results generated by the pretrained Siamese network. This network provides a basis for the main user preference prediction model, as the output embeddings from this network provide an input for the RNN. The ROC curve for the Siamese network is displayed in Figure 4 as the blue line (the green dotted line is the 1-0 reference line). This curve was drawn based on a test set of 20000 samples not in the original training dataset. In general the network is capable of dierentiating between a single Liked image and a single Disliked image based on an anchor image. The curve itself is slightly erratic, but this is not entirely unexpected: a single anchor image is unlikely to enough information to dierentiate between positive and negative preference. As the model by itself is not directly the source of the recommendations, it would not be appropriate to compare it to other recommender systems. For this reason, we present this model without a point of comparison. However, in Section 4.3 we will compare two approaches that use this model as a building block for reciprocal recommendation. As the embeddings in 128-dimensional space from the output of the Siamese network form the input of the RNN. It is therefore Figure 4: Pretrained Siamese Network ROC curve. This forms a building block of both ImRec and our proposed TIRR model. Figure 5: UMAP embeddings of the pretrained Siamese network forming part of TIRR. The red points represent Liked images while black p oints represent Disliked images. useful to visualise these embeddings. In order to do this, we use Uniform Manifold Approximation and Projection for Dimensionality Reduction (UMAP) to reduce the 128-dimensional vectors to twodimensional vectors for visualisation. This visualisation is displayed in Figure 5. In this visualisation, the black datapoints represent Disliked images and the red datapoints represent Liked images. It is clear from the visualisation that the embeddings are separable to some extent, even in two dimensions. The anomalous black cluster in the top right of the image represents heavily distorted or very poor quality images, or images misclassied by the face detection algorithm (i.e. images that do not contain a face). These tend to be almost universally Disliked. As described in Section 1, recommender systems are divided into content-based algorithms and collaborative ltering algorithms. Figure 6: Content Based Algorithm ROC Curves demonstrating the signicant improvement in AUC with TIRR. Figure 6 displays a comparison of TIRR with other content-based algorithms. As described in Section 2, RECON [21] is a an algorithm that identies a user’s implicit preferences for categorical data, and ImRec [18] is an algorithm that uses images to make predictions without the RNN-based component of TIRR, instead using a Random Forest and aggregation function. RECON struggled to generate eective recommendations on our dataset. As RECON was also evaluated on a private dataset, without comparing the datasets directly, it is dicult to establish why this is, but one possibility is that modern dating services place a higher emphasis on visual content than services did ten years ago, at the time RECON was developed. ImRec performs better than RECON, but performs signicantly worse than our proposed method TIRR. The key dierence between TIRR and ImRec is the RNN-based process that allows TIRR to interpret historical and timeseries data in order to make predictions, whereas ImRec treats user preferences in a global way, with no ability to capture individual users preferences. Table 3: Results based on best F1 score for content-based algorithms. Here we can see that our proposed method TIRR signicantly outperforms the other approaches. The AUC and maximum F1 score for the three algorithms is described in Table 3. The scores are based on the threshold that gave the best F1 score in the training set, used in the test set. We consider that this signicant improvement of our proposed method TIRR derives from the ability of our algorithm to interpret a user’s history of preferences for images over time, and take account of a user’s potentially shifting preferences, whereasImrecprovides a global model across all users without distinguishing more than one preference per user at a time, and RECON doesn’t make use of images at all. The table also lists the precision and recall at the points where the best F1 score was recorded. While F1 is an excellent measure of overall performance of an algorithm, the individual precision and recall numbers and their balance are particularly important in RS research because precision tends to inuence the trust users have in the RS, which in turn aects their use of it [7]. It is noteworthy that while ImRec was relatively successful at predicting which image a user would like, its precision was relatively low in comparison with other algorithms, whereas TIRR has very high precision, and is therefore more likely to be trusted and used. In addition to comparing TIRR to other content-based RRSs, we also ran tests comparing it to the current best-in-class collaborative ltering algorithms, RCF and LFRR. Figure 7: ROC Curves showing the performance of the content-based TIRR against the current state of the art collaborative ltering algorithm LFRR. LFRR is a collaborative ltering algorithm based on latent factor models trained by stochastic gradient descent, and RCF is a neighbourhood-based collaborative ltering algorithm. TIRR outperformed both of these algorithms on our test dataset, although by a slimmer margin than its lead on current content-based ltering algorithms. Nonetheless, this represents a signicant advancement in the eld of reciprocal recommendation, as in services where images prominently used, our algorithm is likely to be more eective than current collaborative ltering methods. Table 4: Results based on best F1 score for the TIRR and LFRR algorithms. Here we can see that the content-based TIRR improves upon the collab orative ltering-based LFRR. Table 4 lists the peak performance metrics for the two algorithms. In addition to the higher F1 score, TIRR also has a comparable balance of precision and recall to LFRR. In this paper, we presented a novel algorithm to interpret user preference history using only photos and make predictions about future preferences for reciprocal recommendation. We demonstrated that this can eectively be used as a predictor for the probability of mutual preference between two users, and therefore forms the basis for an eective recommender system. We also demonstrated that our algorithm outperforms state of the art reciprocal recommender systems in oine tests using a large dataset from a dating service with real users. This research demonstrates the value of including historical preference in reciprocal recommendation. Previous research has demonstrated the value of using RNNs to interpret sequences of preferences in user-item recommendation, but this is the rst time it has been used in reciprocal recommendation. The improvement over a similar algorithm that does not use sequences of data shows the value of this approach. Finally, the model itself represents a signicant advance in the eld of content-based reciprocal recommendation. The model’s success also allows us to draw interesting conclusions about the signicance of photos in online dating, given their strong predictive power in this dataset. It also provides interesting insight into the potential power of content-based algorithms in online dating: while in many elds, they are outperformed by collaborative ltering, the algorithm presented in this paper performs better on evaluation metrics than the current state-of-the-art collaborative ltering algorithm.