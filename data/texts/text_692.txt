<title>US-Rule: Discovering Utility-driven Sequential Rules</title> <title>arXiv:2111.15020v1  [cs.DB]  29 Nov 2021</title> provide analysis results for various services. Compared to FPM, sequential pattern mining (SPM) 11 16 ] considers the chronological order of items in the database. In a transaction record, the order of items generally follows the occurred order. SPM can discover sequential patterns within a certain time frame with better analysis. SPM has many applications in real life, as reviewed in [ 11 ], such as bioinformatics [ 29 ], analysis of customer consumption behavior [ 26 ], and web-page click event mining [ ]. However, both FPM and SPM mainly consider the frequency of each items and assume that each items in one transaction event can only appear once. This limitation often not holds in many real applications. In a real transaction record, not only the quantity of commodities should be considered, but also we need to pay more attention to the price of commodities. Generally speaking, in business, we should consider prots more than the number of sales. For example, there is no doubt that the prot of diamond, ring is far greater than the prot of milk, bread . However, as people buy milk and bread daily, the frequency of milk, bread in the transaction database is often very large. Therefore, FPM and SPM will consider milk, bread as a more valuable pattern. Although diamond, ring can bring higher prots, its sales volume is too small. If minsup is set to a larger value in FPM or SPM, the really valuable pattern <diamond, ring> may be missed. For the sake of the problems posed by this situation, Ahmed et al. [ ] have introduced the concept of utility and proposed the problem of high-utility pattern mining (HUPM). HUPM considers internal utility and external utility of items to discover more valuable patterns. In general, the internal utility is the occurred quantity (e.g., purchased quantity) of items and the external utility is the unit utility (e.g., price) of each items. Then, the product of internal utility and external utility is the total utility of each items in the database. Dierent from FPM, HUPM is more challenging to nd out all high-utility patterns (HUPs). The support value of a pattern is anti-monotonic, while in HUPM, if a pattern satises the minimum utility threshold (minutil), the utility of its super-patterns may be smaller, equal to, or larger than the utility of itself. For example, consider patterns milk, bread and milk, bread, bike , the latter will be more protable. However, the purchased number of milk, bread , as we mentioned about, is a very large value. Hence, the total prot of these two patterns is dicult to compare. After that, for further considering the order of items in a transaction record, high-utility sequential pattern mining (HUSPM) [ 34 ] was proposed. HUSPM considers the chronological order of items in a pattern to address this issue. For milk, bread , we only know that customers purchase these shopping goods in HUPM. While in HUSPM, we can know that after buying milk, customers will continue to purchase bread. Obviously, these high-utility sequential patterns can carry more crucial and valuable information. In many real applications such as smart retail, HUSPM can utilize the chronological order of these items in a pattern to promote sales and generate high prots. There are many algorithms about SPM [ 19 26 35 ] and HUSPM [ 17 18 31 34 ] proposed to deal with many special scenarios in real-word, and they only use frequency or total utility to decide what patterns are useful. In some scenarios, if we want to predict what will happen next, SPM and HUSPM can only make a rough prediction. Even if the chronological order of items is considered in SPM and HUSPM, it can not provide accurate prediction rate for users. For instance, if we have two frequent sequential patterns milk, egg and milk, egg, bread , we can know that some customers would buy bread after buying milk and egg. However, we don’t know the proportion of these customers in all customers. That is, we can only know approximately the predicted items without knowing the accuracy. Sequential rule mining (SRM) was proposed by Fournier-Viger et al. 13 ] and it uses the concept of condence to nd out all sequential rules (SRs) whose support value and condence value satisfy the minsup and the minimum condence (minconf ) predened by users. In general, SR is denoted as {𝑋 } → {𝑌 } . For a SR {milk, egg} {bread}, if its condence value is 0.5, we can know that 50% customers will buy bread after buying milk and egg. SRM is widely applied to various elds, such as business transactions, weather forecast, and nancial analysis. Because the minsup is also set in SRM, SRM also faces the problem of SPM. For example, the support value of {milk, egg} {bread} is greater than {diamond, ring} {rose}. If the condence values of these two SR are high and satisfy the minconf, but the minsup is set too high, the more protable SR {diamond, ring} {rose} may be ignored. To this end, Zida et al. [ 40 ] combined the concept of utility with SRM and proposed high-utility sequential rule mining (HUSRM). HUSRM considers minconf and minutil to generate all high-utility sequential rules (HUSRs). HUSRM can be seen as a combination of SRM and HUSPM. It can also be seen as a special version of SRM when both the external utility and internal utility are equal to one. As a result, HUSRM has many applications and extensions. Although HUSRM plays an important role than SRM in many real applications, there are few relevant studies about it. As far as we know, there is only one algorithm [40] proposed to nd out the complete set of HUSRs. In light of some relevant studies in HUIM and HUSPM, in this paper, we propose a more ecient algorithm, named US-Rule. Inspired by the use of co-occurrence map [ 14 ], we propose rule estimated utility co-occurrence map (REUCM) and rule estimated utility co-occurrence pruning strategy (REUCP) to avoid the unnecessary computations of US-Rule. There are four more tight upper bounds introduced by US-Rule, including left expansion estimated utility (LEEU), right expansion estimated utility (REEU), left expansion reduced sequence utility (LERSU), and right expansion reduced sequence utility (RERSU). Based on these upper bounds, we design corresponding novel data structures and propose several pruning strategies. The major contributions of this paper are as follows: A novel algorithm, called US-Rule, is proposed to discover the complete set of HUSRs. Compared to the only algorithm HUSRM, US-Rule with the use of REUCP can achieve better performance. REUCP can avoid meaningless computations of sequential rules. For better eciency on dense and long sequence datasets, we propose four tighter upper bounds and design their corresponding auxiliary data structures. Based on these upper bounds, we utilize depth-rst search pruning strategies (LEEUP and REEUP) and width-rst search pruning strategies (LERSUP and RERSUP) to reduce the number of expansion of US-Rule. To address the issue of US-Rule on sparse and short sequence datasets, we propose the rule estimated utility recomputing pruning strategy (REURP) to reduce unnecessary rule expansion and improve eciency by recalculating the SEU of items multiple times and removing unpromising items from the database. Experiments using US-Rule and its dierent variants (with dierent strategies) on both real and synthetic datasets show that US-Rule with dierent strategies can achieve dierent degrees of improvement over the state-of-the-art HUSRM algorithm on dierent datasets. The remainder part of this paper is organized as follows. In Section 2, we review the related work about SRM, HUSPM, and HUSRM. Then, we introduce the denition of HUSRM and formalize the problem of HUSRM in Section 3. The proposed US-Rule algorithm with several pruning strategies is presented in Section 4. Experimental results and evaluation on dierent datasets are shown and discussed in Section 5. Finally, in Section 6, we conclude this paper and discuss the future work of our research. Since frequent pattern mining (FPM) [ ] was proposed, several sequential rule mining (SRM) algorithms have been proposed. A sequential rule can be divided into two parts, denoted as {𝑋 } → {𝑌 } 𝑋 ∩ 𝑌 is the antecedent of a sequential rule, and is the consequent. For a sequential rule, it must be satised the dened minimum support value (minsup) and the minimum condence value (minconf ). According to the total in order or partial in order, SRM can be divided to total-ordered SRM and partially-ordered SRM. The former means that all itemsets in a sequential rule depend on the order of itemsets in the original sequence. And the later indicates itemsets in antecedent or consequent of a sequential rule can be disorganized, but the order of an itemset which appears in the consequent of a sequential rule should be after the antecedent of a sequential rule. Partially-ordered SRM is the key research direction. RuleGen [ 35 ] adopts a method of violent enumeration. Generating sequential rules from two sequential patterns. As the length of the traversed sequential pattern increases, the length of the obtained sequential rules also increases. Fournier-Viger et al. proposed CMDeo [ ] and CMRules [ ] to improve eciency. CMDeo is a two-phases-based algorithm. It rst discovers association rules by using an association rule mining algorithm, and then these association rules are used to generate sequential rules. There is no doubt that since both RuleGen and CMDeo use the generate-and-test approach, they usually very inecient. CMRules introduces the concept of left- and right- expansion of sequential rules, which greatly improves eciency. The idea of left- or right- expansion through frequent items is clearly not good enough. Similar to PrexSpan [ 19 ], the RuleGrowth algorithm [ 13 ] was further proposed, and it uses left- and right- expansion and pattern-growth approach for generating sequential rules, and then achieves excellent performance. To reduce the running time of SRM algorithms, an equivalence class method was proposed in ERMiner [ 10 ]. ERMiner continuously merges equivalence classes with the same antecedent or consequent, thus generating longer sequential rules. ERMiner also introduces a new data structure, called Sparse Count Matrix (SCM), to prune the search space by avoiding useless emergence. However, the memory consumption of ERMiner is greater than RuleGrowth. In addition to the algorithms mentioned above, there are other popular topics in SRM. Several constraint-based SRM algorithms that can obtain valuable sequential rules are TRuleGrowth 13 ], BMSRIC-R [ 28 ], and IFERMiner [ 27 ]. TRuleGrowth uses a sliding window to discover the sequential rules over a time period. BMSRIC-R constrains the itemset in the sequential rules to obtain more compact rules, and IFERMiner discovers the required sequential rules in a quantitative sequence database. In addition, TNS [ 12 ] was proposed to address topSRM that discovers topSRs without setting minsup. In incremental mining, IERMiner [ ] was proposed to deal with the dynamic sequence database. Since Agrawal and Srikant [ ] proposed the sequential pattern mining (SPM) to discover all frequent sequential patterns, a growing number of researchers are focusing on this area. There are many algorithms about SPM [ 11 16 ], such as GSP [ 26 ], PrexSpan [ 19 ], SPADE [ 35 ], SPAM [ ], and non-overlapping SPM [ 33 ]. GSP is a relatively violent method that generates longer sequential patterns by continuously merging sub-sequential patterns. It mainly utilizes the Apriori property and the support decreases with the merging of sequential patterns, thus this method is very time consuming and memory cost. In order to improve eciency and save much memory, PrexSpan adopts the projection mechanism to grow sequential patterns. The main idea of PrexSpan is to avoid generating a large number of candidates by using two pruning strategies. However, PrexSpan faces the problem of memory consumption when the projected database is too large. And then, SPADE with the equivalence class and SPAM with the bitmap both optimize the memory consumption problem. Nevertheless, the main problem of SPM is the use of support to mine sequential patterns. The researchers then introduced utility into SPM and proposed a new framework called utility mining [ 15 ] as well as many utility-related calculation methods. The goal of high-utility sequential pattern mining (HUSPM) [ 15 ] is to nd out all high-utility sequential patterns (HUSPs) whose total utility is not less than the predened minimum utility (minutil ). The concept of utility takes into account some theories of economics (e.g., prot, risk, and importance). In SPM, many algorithms can utilize the Apriori property to prune unpromising sequential patterns. Unfortunately, this property makes no eect on HUSPM. Due to the use of utility, the analysis of HUSPM is much more dicult. Utility is a not anti-monotonic and not monotonic value [ 15 25 ]. To address this problem, Ahmed et al. [ ] introduced sequence weighted utilization (SWU) as a downward closure property. SWU is the rst upper bound about HUSPM. Similar to the Apriori property, we can utilize SWU to reduce search space. And then, UtilityLevel (an Apriori-like algorithm) and UtilitySpan (an algorithm based on PrexSpan) were proposed by Ahmed et al. [ ]. Both UtilityLevel and UtilitySpan are two-phases-based algorithms. They use SWU to discover all candidate sequences at rst, then extract real HUSPs according to minutil. Next, inspired by the idea of tree, UWAS-tree [ ] and IUWAS-tree [ ] are proposed to nd HUSPs from web log data. In addition, Shie et al. [ 24 ] designed the UMSP algorithm for analyzing mobile data. However, these algorithms face the problem that too much memory consumption is caused by a large number of candidate patterns. What’s more, they only consider single-item sequences whose itemsets only contain one item. In order to deal with multiple-item-based sequences, Yin et al. [ 34 ] proposed a novel algorithm, called USpan. USpan can discover multiple-item sequences through its utilitymatrix structure. Thus the order of items in itemsets can be considered, and the discovered HUSPs are more valuable. Besides, USpan also utilizes SWU and sequence projected utilization (SPU) in two designed depth and width pruning strategies to prune search space. Both the pruning strategies can be applied into the lexicographic tree to improve eciency. Unfortunately, USpan not only will generate too many promising sequences with a high SWU value, but also will miss some real HUSPs due to the use of SPU. Alkan et al. [ ] then designed HuspExt for better eciency. Lan et al. [ 20 ] also introduced a projection-based algorithm namely PHUS to improve the mining performance. PHUS utilizes a sequence-utility upper-bound model (SUUB) to discover all HUSPs, and SUUB introduces the maximum utility measure to calculate the more accurate utility of a sequence. Wang et al. [ 30 proposed HUS-Span for further improve eciency. HUS-Span introduces a new upper bound, called the prex extension utility (PEU). HUS-Span discovers all HUSPs, but it’s eciency is not very good. A large number of candidate sequences will cause too much memory in HUS-Span. Recently, Gan et al. [ 17 ] proposed a projection-based utility mining algorithm, called ProUM. ProUM can quickly grow sequences through a new data structure, called utility-array. Besides, the sequence extension utility (SEU) and its corresponding pruning strategies are also introduced in ProUM. Subsequently, Gan et al. [ 18 ] proposed a faster algorithm, called HUSP-ULL, which utilizes a new data structure, called UL-list, to quick generate projected sub-databases. Besides, two powerful pruning strategies are also introduced by HUSP-ULL. There are many fast algorithms have been proposed to discover HUSPs. In recent years, researchers have also extended HUSPM to other elds. TKHUS-Span [ 30 ] and TKUS [ 37 ] are topHUSPM algorithms that can nd out tophigh-utility sequences without setting minutil. Recently, the TUSQ approach [ 36 ] was proposed to deal with a new problem of utility-driven targeted sequence querying, and OSUMS [ 38 ] was introduced for on-shelf utility mining (OSUM). HAOP-Miner [32] aims at mining high-average utility one-o sequential patterns. Although many algorithms for SRM have been proposed and SRM has been studied in many extensions, there is only one algorithm makes use of utility to discover high-utility sequential rules. Dierent from SRM, HUSRM assumes that the input sequences have rich utility factor but do not have duplicate items. To the best of our knowledge, Zida et al. [ 40 ] rst dened the concept of HUSRM and proposed the rst algorithm called HUSRM. HUSRM introduces the minutil as a measure to judge a sequential rule whether is a high utility sequential rule (HUSR). Based on one data structure called utility-table and several optimizations, the HUSRM algorithm can eciently mine all HUSRs. The information of each rule is stored in its utility-table, thus HUSRM can accelerate the process of utility calculation of sequential rules. Besides, ve optimizations are used to improve eciency. The rst optimization is to remove the unpromising items at an early stage, and this can avoid useless items be a part of a rules. The second one is to remove the unpromising rules at an early stage, then reduce the count of expansion. The third one saves memory consumption by the use of bitmap. The fourth one also can save memory by the use of more compact utility-table for left expansion. The last one utilizes tighter upper bounds as expansion condition to improve eciency. After that, several extensions of HUSRM have been studied. For example, Zhang et al. 39 ] incorporated the concept of negative sequence into HUSRM and proposed a solution to nd out high-utility negative sequential rules. This section introduces fundamental concepts and notations used in this paper. And then, we formalize the problem denition of high-utility sequential rule mining. Denition 3.1 (Sequence database). Let = { · · · } be a set of distinct items. An item is denoted as (𝑖, 𝑞(𝑖)) , and 𝑞(𝑖) is its internal utility. An itemset (element) is a subset of , and = { · · · ⊆ 𝐼 . We assume that all distinct items in are ordered according to , which is a lexicographical order (𝑎 < 𝑏 < · · · < 𝑧) . For a sequence , it is composed of itemsets and can be denoted as <𝐼 · · · ⊆ 𝐼 ( ≤ 𝑘 ≤ 𝑛) . A sequence database consist of all sequences, <𝑠 · · · , and each sequence own its unique identier (SID ). Like HUSRM 40 ], we assume that an item cannot appear in one sequence more times. Each dierent item has its corresponding external utility, denoted as 𝑒𝑢 (𝑖) . Note that both internal utility and external utility are positive. SID Sequence < (𝑎, 1) (𝑏, 2) {(𝑐, 1)(𝑔, 1)}> < (𝑎, 1)(𝑐, 1) {(𝑒, 1)(𝑔, 1)}> < (𝑏, 1) (𝑑, 1) (𝑔, 2)> < (𝑒, 1) (𝑓 , 2)> As shown in Tables 1 and 2, in this paper, the example sequence database has ve sequences. We use , and to present their SID. Each item is a single letter, owning its internal utility in the itemset and is ordered according to . If an itemset contain only one item, we omit curly brackets to present it. For each item, Table 2 shows their external utilities. For example, given an item (𝑎, 1), we can know that 𝑞(𝑎) = 1 and 𝑒𝑢(𝑎) = 2. Denition 3.2 (Sequential rule and sequential rule size). A sequential rule is denoted as → 𝑌 , and is the antecedent of sequential rule while is the consequent. Both and are not empty and unordered itemsets, and 𝑋 ∩ 𝑌 . For partially-ordered SRM, if appears in a sequence, will occur after . Note that we stipulate that the items in a sequence appear no more than once. Therefore, we argue that is the number of distinct items in the antecedent of , and is the number of distinct items in the consequent of . Then, the size of can denoted as 𝑘 ∗ 𝑚 Given another sequential rule and its size is 𝑓 ∗ ℎ , if the size of is larger than , it must be 𝑓 > 𝑘 and ℎ ≥ 𝑚, or 𝑓 ≥ 𝑘 and ℎ > 𝑚. For example, as shown in Table 1, {𝑎, 𝑏} → {𝑐} is a sequential rule, and its size is 2 1. Given another sequential rule {𝑎, 𝑏} → {𝑐, 𝑔} , we can know that is larger than . It is because the size of 𝑟 is 2 ∗ 2. Denition 3.3 (Support and condence). We use seq (𝑟) to present the sequence containing the sequential rule . For a sequential rule 𝑋 → 𝑌 , its support value is the number of sequences in whose sub-sequences contain seq (𝑟) . And it can dened as sup (𝑟) = seq (𝑟) |D| . While the condence of rule is the proportion of occurs after and it can be dened as conf (𝑟) = sup (𝑟) / sup(𝑋 ). For example, from Table 1, we can clearly see that the support of {𝑎} → {𝑐, 𝑔} is 2, because appears in sequences and . And the condence of is 1, because {𝑎} appears in sequences and 𝑠 , and {𝑎, 𝑐, 𝑔} also appears in these two sequences. Therefore, sup(𝑟) = 2, and conf (𝑟 ) = 1. Denition 3.4 (Utility of an item/itemset in a sequence). We specify that for an item in a sequence, its utility value is equal to the product of its internal utility and external utility. It can denoted as 𝑢(𝑖, 𝑠 and dened as 𝑢(𝑖, 𝑠 𝑞(𝑖, 𝑠 ) × 𝑒𝑢(𝑖) . Similarly, for an itemset , its utility in a sequence is the sum of the utility of all items in this itemset. It can denoted as 𝑢(𝐼, 𝑠 and dened as 𝑢(𝐼, 𝑠 𝑞(𝑖, 𝑠 ) × 𝑒𝑢 (𝑖). Denition 3.5 (Utility of an item/itemset in a database). As for the utility of an item in a database is the sum of utilities in all sequences. It can be denoted as 𝑢(𝑖) and dened as 𝑢(𝑖) 𝑞(𝑖, 𝑠 ) × 𝑒𝑢 (𝑖) . For an itemset , its utility in a database is the total utility of all itemsets in this database. It can be denoted as 𝑢 (𝐼) and dened as 𝑢 (𝐼 ) = 𝑞(𝑖, 𝑠 ) × 𝑒𝑢 (𝑖). For example, in Table 1, the utility of item (𝑎, in sequence 𝑞(𝑎, 𝑠 ) × 𝑒𝑢 (𝑎) = 2, and the utility of itemset {(𝑐, )(𝑔, )} 𝑞(𝑐, 𝑠 ) × 𝑒𝑢 (𝑐) 𝑞(𝑔, 𝑠 ) × 𝑒𝑢 (𝑔) = 4 + 1 = 5. 𝑢(𝑎) 𝑞(𝑎, 𝑠 ) × 𝑒𝑢 (𝑎) 𝑞(𝑎, 𝑠 ) × 𝑒𝑢 (𝑎) = 2 + 2 = 4, and 𝑢((𝑐, 𝑔)) 𝑞(𝑐, 𝑠 ) × 𝑒𝑢 (𝑐) 𝑞(𝑔, 𝑠 ) × 𝑒𝑢 (𝑔) = 4 + 1 = 5. We can know that the total utility of 𝑎 in D is 4, and the total utility of (𝑐,𝑔) in D is 5. Denition 3.6 (Utility of a sequential rule in a sequence and database). The utility of a sequential rule in sequence can be denoted as 𝑢(𝑟, 𝑠 and dened as 𝑢(𝑟, 𝑠 𝑞(𝑖, 𝑠 ) × 𝑒𝑢 (𝑖) . The utility of a sequential rule in database can be denoted as 𝑢(𝑟 ) and dened as 𝑢(𝑟 ) 𝑞(𝑖, 𝑠 ) × 𝑒𝑢 (𝑖). Denition 3.7 (High utility sequential rule mining). We assume that the minutil value is positive and the minconf ∈ [ , and they are predened by users. Given these two thresholds and a sequence database , if a sequential rule is satised 𝑢(𝑟 ) ≥ minutil and conf (𝑟) ≥ minconf simultaneously, we call it a high-utility sequential rule (HUSR). Otherwise, it is an invalid rule. The problem of high-utility sequential rule mining (HUSRM) is to discover a complete set of all HUSRs from a sequence database. Table 3 shows the discovered HUSRs under the setting of minutil = 10 and minconf = 0.5. From the results, we can see that totally four HUSRs are found, and they both satisfy the two predened thresholds. Although {𝑏} → {𝑔} has a high condence and its support is 2, it is removed due to its low utility. Obviously, the results of HUSRM are very dierent from those of SRM. Denition 3.8 (The expansion of a sequential rule). US-Rule utilizes the approach similar to RuleGrowth [ 13 ] to grow a sequential rule {𝑋 } → {𝑌 } . This means that US-Rule also uses the left and right expansion. For an expanded item 𝑖 ∈ 𝐼 , the left expansion of is dened as 𝑋 ∪ {𝑖} → , and must be larger than all item in according to and 𝑖 ∉ 𝑌 . While the right expansion of is dened as 𝑋 → 𝑌 ∪ {𝑖} , and must be larger than all item in according to and 𝑖 ∉ 𝑋 Let be a new rule expanded from , the support of can be lower or equal to sup (𝑟) . As for the eect on condence, the utility of can be lower, higher, or equal to conf (𝑟) . Similarly, the utility of can be lower, higher, or equal to 𝑢(𝑟 ) . Relevant proofs can be referred to Ref. [ 13 40 ]. In order to avoid generating the same sequential rule twice, US-Rule utilizes the following regulation: a sequential rule cannot perform the right expansion after it performs the left expansion. In this section, we introduce the key denitions and new upper bounds, and then present our designed data structures and pruning strategies. Finally, we present the complete pseudocode of US-Rule which is an one-phase rule-growth-based algorithm. Note that the US-Rule algorithm adopts some concepts from previous studies in utility-based sequence mining to reduce the search space. Left expansion estimated utility (LEEU) and right expansion estimated utility (REEU) are inspired by prex estimated utility (PEU), while left expansion reduced sequence utility (LERSU) and right expansion reduced sequence utility (RERSU) are inspired by reduced sequence utility (RSU). In addition to using the four new upper bounds, we also use the sequence estimated utility (SEU). The details can be referred to Ref. [30, 34]. Denition 4.1 (Sequence utility). For a sequence , its sequence utility is the total utility of all items in this sequence, and it can be dened as SU (𝑠 ) = 𝑞(𝑖, 𝑠 ) × 𝑝 (𝑖). For instance, in Table 1, the utility of sequence 𝑠 , 𝑠 , 𝑠 , and 𝑠 are 9, 8, 10, and 5, respectively. Denition 4.2 (Sequence estimate d utility of item/rule). For an item , its sequence estimated utility (SEU) is the sum of the utility of sequences containing and it can be dened as SEU (𝑖) SU (𝑠 . For a sequential rule , its SEU is the SEU of seq (𝑟) and it can be dened as SEU (𝑟 ) = SU (𝑠 ). Then SEU (𝑖) ≥ 𝑢(𝑖) and SEU (𝑟) ≥ 𝑢 (𝑟). For example, in Table 1, the SEU of is SEU (𝑎) = 9 + 8 = 17, because appears in sequence and sequence . Also the SEU of sequential rule {𝑒} → {𝑓 } is SEU (𝑟) = 5, because only sequence contains 𝑟 . Denition 4.3 (Promising item and promising rule). If SEU (𝑖) ≥ minutil, the item is a promising item. Otherwise, it is an unpromising item. For a sequential rule , if SEU (𝑟) ≥ minutil, is a promising rule. Otherwise, it is an unpromising rule. For instance, if minutil = 10, we can see that is an unpromising item, because SEU (𝑓 ) = 5 10. For a sequential rule 𝑟 = {𝑒} → {𝑓 }, 𝑟 is an unpromising rule, because SEU (𝑟) = 5 < 10. Strategy 1 (Unpromising items pruning strategy). Given an item , if is an unpromising item, US-Rule will remove it from the database. The reason is that if SEU (𝑖) < minutil, the utility of a rule contains 𝑖 will be smaller than minutil. Strategy 2 (Unpromising seqential rules pruning strategy). Given a sequential rule according to unpromising sequential rules pruning strategy (USRP), if is an unpromising rule, US-Rule will terminate its expansion. The reason is that if SEU (𝑟) < minutil, the utility of the expansion of a rule will be smaller than minutil. Note that both Strategy 1 and Strategy 2 can be referred to Ref. [40]. Denition 4.4 (Rule estimated utility co-occurrence pruning map). We propose a novel data structure, called rule estimated utility co-occurrence pruning map (REUCM) to store the SEU of item and item . Item must be in front of item . Then there will be two situations. The rst one is that the itemset of item precedes the itemset of item . The second one is that item and item appear in the same itemset. In general, using a matrix for storage will consume a lot of memory and there are many zeros in the matrix. Therefore, US-Rule utilizes a hash-table for the design. For instance, the SEU of item and item can be denoted as REUCM (𝑎, 𝑏) and dened as REUCM (𝑎, 𝑏) 𝑢(𝑠) . Note that it is dierent from the estimated utility co-occurrence structure (EUCS) [ 14 ]. In EUCS, the order of item and item does not need to be considered. While in REUCM, we need to consider this. For REUCM (𝑎, 𝑏) , it is not equal to REUCM (𝑏, 𝑎) . It is because {𝑎} → {𝑏} is dierent from {𝑏} → {𝑎} . Note that REUCM (𝑎, 𝑏) ≥ SEU ({𝑎} → {𝑏}). Theorem 4.5. Given two items and in front of ), and a sequential rule {𝑎} → {𝑏} REUCM(𝑎, 𝑏) ≥ SEU(𝑟 ). Proof. We can know that item appears in front of item . Then there will be two situations. The rst one is that the itemset of item precedes the itemset of item . The second one is that item and item appear in the same itemset. For the rst case, its estimated utility can be expressed as SEU = SEU ({𝑎} → {𝑏}) . For another case, the estimated utility of it can be expressed as SEU SEU (seq((𝑎, 𝑏))) and SEU (𝑟) = 0. Therefore, REUCM(𝑎, 𝑏) = SEU + SEU ≥ SEU (𝑟 ). □ Strategy 3 (Rule estimated utility co-occurrence pruning strategy). Inspired by EUCP 14 ], US-Rule proposes the rule estimated utility co-occurrence pruning strategy (REUCP) to void meaningless operation in expansion. Relied on the novel data structure of REUCM, given a sequential rule {𝑋 } → {𝑌 } , item and item respectively are the largest item of and according to . For an item , if REUCM (𝑖, 𝑛) < minutil, item will not perform this left expansion; and if REUCM (𝑚, 𝑖) < minutil, item 𝑖 will not perform this right expansion. Proof. Given a sequential rule {𝑋 } → {𝑌 } and an item that can only be left extended. We assume that the sequential rule {𝑋 } ∪ 𝑎 → {𝑌 } is generated form by performing left expansion on . Let be the sequences set of seq (𝑟) , and to denote the sequences set of seq (𝑟 Since seq (𝑟) ⊂ seq (𝑟 , we can know that ⊆ 𝑆 . As discussed in Denition 3.2, let be the largest item in , and will be front of . And let denote {𝑎} → {𝑛} and denote the set of all sequences which contain seq (𝑡) . Because seq (𝑡) ⊂ seq (𝑟) ⊂ seq (𝑟 ⊆ 𝑆 ⊆ 𝑆 . And we can know that SEU (𝑡) ≥ SEU (𝑟) ≥ SEU (𝑟 . If REUCM (𝑎, 𝑛) < minutil, there will be SEU ( ) ≤ SEU (𝑟) ≤ SEU (𝑡) REUCM (𝑎, 𝑛) < minutil. Therefore, is an unpromising rule, we can terminate this expansion. The proof about the right expansion is similar to this proof. □ Upper bound 1 (Left expansion estimated utility). The left expansion estimated utility (LEEU) of a sequential rule 𝑟 in sequence 𝑠, denoted as LEEU (𝑟, 𝑠), is dened as: Here ULeft (𝑟, 𝑠) denotes the total utility of all items in sequence which can only extend sequential rule by left expansion and ULeftRight (𝑟, 𝑠) denotes the total utility of all items in sequence which both can extend sequential rule by left expansion and right expansion. The left expansion estimated utility of a sequential rule in sequence database , denoted as LEEU (𝑟) , is dened as: LEEU (𝑟 ) = LEEU (𝑟, 𝑠 Consider the sequential rule {𝑎} → {𝑐} appears in sequence and . In sequence , item can only extend by left expansion, ULeft (𝑟, 𝑠 𝑢(𝑏) = 2, and LEEU (𝑟, 𝑠 will be equal to 𝑢(𝑟 ) + ULeft (𝑟, 𝑠 + ULeftRight (𝑟, 𝑠 = 6 + 2 + 0 = 8. This is because there is no item can extend in sequence 𝑟 , LEEU (𝑟, 𝑠 ) = 0. Therefore, LEEU (𝑟 ) = LEEU (𝑟, 𝑠 ) + LEEU (𝑟, 𝑠 ) = 8 + 0 = 8. Theorem 4.6. Given a sequential rule {𝑋 } → {𝑌 } and its left expansion {𝑋 } ∪ 𝑎 → {𝑌 } 𝑢(𝑟 ) ≤ LEEU(𝑟). Proof. In sequence , since the item can be an item of left expansion for , then 𝑢(𝑎, 𝑠) ≤ ULeft (𝑟, 𝑠) + ULeftRight (𝑟, 𝑠) . And we can know that 𝑢(𝑟 , 𝑠) 𝑢(𝑟, 𝑠) 𝑢(𝑎, 𝑠) ≤ 𝑢(𝑟, 𝑠) + ULeft (𝑟, 𝑠) + ULeftRight(𝑟, 𝑠) = LEEU (𝑟, 𝑠). Therefore, 𝑢 (𝑟 ) ≤ LEEU (𝑟 ). □ Upper bound 2 (Right expansion estimated utility). The right expansion estimated utility (REEU) of a sequential rule 𝑟 in sequence 𝑠, denoted as REEU (𝑟, 𝑠), is dened as: We use URight (𝑟, 𝑠) to denote the total utility of all items in sequence which can only extend sequential rule by right expansion and UtilityExtend (𝑟, 𝑠) to denote the total utility of all items which can extend sequential rule by left expansion or right expansion. We can know that UtilityExtend (𝑟, 𝑠) = ULeft (𝑟, 𝑠) + ULeftRight (𝑟, 𝑠) + URight (𝑟, 𝑠) . Dierent from the equation of LEEU, UtilityExtend (𝑟, 𝑠) is a larger value. This is because the right extension can be followed by the left extension, and the right extension needs to take into account that the left extension may make the utility of a sequential rule larger. The right expansion estimated utility of a sequential rule in database , denoted as REEU (𝑟) is dened as: REEU (𝑟 ) = REEU(𝑟, 𝑠 Consider the sequential rule {𝑎} → {𝑐} , where appears in and . In sequence , item and item can only extend , because UtilityExtend (𝑟, 𝑠 𝑢(𝑏) 𝑢(𝑔) = 2 + 1 = 3. REEU (𝑟, 𝑠 will be equal to 𝑢 (𝑟 ) + UtilityExtend (𝑟, 𝑠 ) = 6 + 3 = 9. The items 𝑒 and 𝑔 can extend 𝑟 in sequence , thus REEU (𝑟, 𝑠 ) = 8. Therefore, REEU (𝑟 ) = REEU (𝑟, 𝑠 ) + REEU (𝑟, 𝑠 ) = 9 + 8 = 17. Theorem 4.7. Given a se quential rule {𝑋 } → {𝑌 } and its right expansion {𝑋 } → {𝑌 } ∪ 𝑎 𝑢(𝑟 ) ≤ REEU(𝑟). Proof. In a sequence , since the item can be an item of right expansion for , then 𝑢(𝑎, 𝑠) ≤ UtilityExtend (𝑟, 𝑠) . And we can know that 𝑢(𝑟 , 𝑠) 𝑢(𝑟, 𝑠) 𝑢(𝑎, 𝑠) ≤ 𝑢(𝑟, 𝑠) + UtilityExtend (𝑟, 𝑠) REEU (𝑟, 𝑠). Therefore, 𝑢 (𝑟 ) ≤ REEU (𝑟 ). □ Upper bound 3 (Left expansion reduced seqence utility). Let be a sequential rule able to generate sequential rule by left expansion. The left expansion reduced sequence utility (LERSU) of 𝑟 in sequence 𝑠, can be denoted as LERSU (𝑟, 𝑠) and dened as: The left expansion reduced sequence utility of a sequential rule in database , denoted as LERSU (𝑟 ), is dened as: LERSU (𝑟 ) = LERSU (𝑟, 𝑠) Consider the sequential rule {𝑎, 𝑐} → {𝑔} appears in sequence , and it generated from = {𝑎} → {𝑔} by performing the left expansion. Therefore, LERSU (𝑟 ) = LEEU (𝛼, 𝑠 ) = 8. Theorem 4.8. Given a sequential rule {𝑋 } → {𝑌 } and its left expansion {𝑋 } ∪ 𝑎 → {𝑌 } 𝑢(𝑟 ) ≤ LERSU(𝑟). Proof. Let be a sequential rule able to generate sequential rule by left expansion. In a sequence , LERSU (𝑟, 𝑠) = LEEU (𝛼, 𝑠) . Based on the Theorem 4.6, we can know that 𝑢(𝑟 , 𝑠) ≤ LEEU (𝑟, 𝑠) ≤ LEEU (𝛼, 𝑠) = LERSU (𝑟, 𝑠). Therefore, we have 𝑢 (𝑟 ) ≤ LERSU (𝑟 ). □ Upper bound 4 (Right expansion reduced seqence utility). Let be a sequential rule able to generate sequential rule by right expansion. The right expansion reduced sequence utility (RERSU) of 𝑟 in sequence 𝑠, denoted as RERSU (𝑟, 𝑠), is dened as: The right expansion reduced sequence utility of a sequential rule in database , denoted as RERSU (𝑟 ), is dened as: RERSU (𝑟 ) = RERSU (𝑟, 𝑠) Consider the sequential rule {𝑎} → {𝑐, 𝑔} appears in sequence and , and it generated from {𝑎} → {𝑐} by performing the right expansion. Therefore, RERSU (𝑟) = REEU (𝛼, 𝑠 REEU (𝛼, 𝑠 ) = 9 + 8 = 17. Theorem 4.9. Given a se quential rule {𝑋 } → {𝑌 } and its right expansion {𝑋 } → {𝑌 } ∪ 𝑎 𝑢(𝑟 ) ≤ RERSU(𝑟). Proof. Let be a sequential rule able to generate sequential rule by the right expansion. In a sequence , RERSU (𝑟, 𝑠) = REEU (𝛼, 𝑠) . Based on the Theorem 4.7, we can know that 𝑢(𝑟 , 𝑠) ≤ REEU (𝑟, 𝑠) ≤ REEU (𝛼, 𝑠) = RERSU (𝑟, 𝑠). Therefore, we have 𝑢 (𝑟 ) ≤ RERSU (𝑟 ). □ Strategy 4 (Left expansion estimated utility pruning strategy). According to Theorem 4.6, in the left expansion of a sequential rule , US-Rule proposes the left expansion estimated utility pruning strategy (LEEUP) to safety prune which satises LEEU (𝑟) < minutil. We can know that 𝑢(𝑟 ) ≤ LEEU (𝑟 ) < minutil, the expanded sequential rule 𝑟 is an unpromising rule. Strategy 5 (Right expansion estimated utility pruning strategy). According to Theorem 4.7, in the right expansion of a sequential rule , US-Rule proposes the right expansion estimated utility pruning strategy (REEUP) to safety prune which satises REEU (𝑟) < minutil. We can know that 𝑢(𝑟 ) ≤ REEU (𝑟 ) < minutil, the expanded sequential rule 𝑟 is an unpromising rule. Strategy 6 (Left expansion reduced seqence utility pruning strategy). According to Theorem 4.8, in the left expansion of a sequential rule , US-Rule proposes left expansion reduced sequence utility pruning strategy (LERSUP) to safety prune 𝑟 which satises LERSU (𝑟) < minutil. We can know that 𝑢(𝑟 ) ≤ LERSU (𝑟) < minutil, the expanded sequential rule is an unpromising rule. Strategy 7 (Right expansion reduced seqence utility pruning strategy). According to Theorem 4.9, in the left expansion of a sequential rule , US-Rule proposes left expansion reduced sequence utility pruning strategy (RERSUP) to safety prune which satises RERSU (𝑟) < minutil. We can know that 𝑢(𝑟 ) ≤ RERSU (𝑟) < minutil, the expanded sequential rule is an unpromising rule. Strategy 8 (Rule estimated utility recomputing pruning strategy). Strategy 1 can remove some unpromising items to avoid low-utility sequential rules are generated. However, in some sparse databases, there are also many items may not satisfy the condition SEU (𝑖) ≤ minutil when removing unpromising items once. Because when removing unpromising items once, the SEU of some items may become smaller. To address this issue, US-Rule proposes rule estimated utility recomputing pruning strategy (REURP) to recalculate the SEU of all items multiple times and remove unpromising items. For eciency and less memory consumption, we design the corresponding data structures for the introduced upper bounds (LEEU, REEU, LERSU, and RERSU). The details are described below. Denition 4.10 (RE-table of a sequential rule). The RE-table is designed for the expansion of sequential rule . In a sequence database , its format can presented as a tuple, like (SID, Utility, LEEU, REEU, RE-elements). SID is the unique identier of sequence which contains , and can also be dened as ∀SID ∈ seq(𝑟) . Utility is the total utility of this sequential rule . LEEU and REEU are corresponding upper bound value of . By storing both LEEU and REEU values, US-Rule can quickly utilize Strategy 4 and Strategy 5, thus avoiding the associated computation. As for RE-elements, it is a list of RE-elements. RE-elements records the related information of a sequence containing We can see that RE-elements is presented as (SID, Utility, ULeft, URight, ULeftRight, LEEU, REEU, Position). In RE-elements, the rst seven variables have been mentioned in the previous content. Position is used to store the position of related itemset for eciency. Denition 4.11 (LE-table of a sequential rule). Since we specify that the right expansion cannot be performed after left expansion, then URight and REEU will carry little impact. Therefore, we designed LE-table for better memory saving. LE-table can presented as a tuple like (SID, Utility, LEEU, LE-elements). US-Rule just needs to use LEEU to leverage the Strategy 4. LE-elements can denoted as (SID, Utility, ULeft, LEEU ), US-Rule has simplied it equally. Note that ULeft is a little dierent from the above illustration. It is the sum of previous ULeft and previous ULeftRight. US-Rule uses one variable to optimize memory consumption. Note that RE-table and LE-table are modied from HUSRM [40]. Denition 4.12 (RSU-table of a sequential rule). Unlike LEEU and REEU, US-Rule uses a RUS-table to store and update LERSU and RERSU in left expansion or right expansion. The RUS-table is a hash-table and US-Rule will keep updating it in the expansion. For each expanded item, US-Rule updates the RUS-table once every time it scans a sequence containing it. If the sum of the value of the expanded item in the RUS-table and the remaining LERSU or remaining RERSU is less than minutil during the update process, US-Rule stops the operation associated with the expanded item by using Strategy 6 and Strategy 7. Based on the aforementioned discussions, we propose the US-Rule algorithm in this section. USRule rst scans the sequence database to generate all sequential rules of 1 1. And then, it uses a depth-rst search to expand all 1 1 rules. As discussed in Denition 3.8, to ensure that no unnecessary sequential rule is generated, a sequential rule cannot perform the right expansion after it has performed the left expansion. There are two procedures in US-Rule, one is the leftExpansion procedure, and another is the rightExpansion procedure. The pseudocode of US-Rule is shown in Algorithm 1. US-Rule rst scans the database to access all items which appear in this database and calculates the SEU of these items (Line 1). According to the REUCP, US-Rule continuously removes unpromising items from the database and updates the SEU of the items that have not been removed (Lines 2-5). US-Rule then scans the database again, generates the set of all 1 1 sequential rules, and calculates their corresponding SEU values (Lines 6-7). According to the USRP, US-Rule removes unpromising rules from (the set of all 1 1 sequential rules) (Line 8). Subsequently, US-Rule traverses all sequential rules in . And then, after calculating its utility and condence, if both its minutil and minconf are satised, sequential rule is a high-utility sequential rule and US-Rule will output it (Lines 10-13). Immediately afterwards, according to LEEUP and REEUP, US-Rule determines whether the REEU and LEEU of are greater than minutil. If this condition is satised, the corresponding left extension and right extension are recursively executed (Lines 14-19). Obviously, in the main program of the US-Rule algorithm, we can see that for the use of the pruning strategies for the new upper bounds, US-Rule uses only the depth pruning strategy (REEUP and LEEUP). And in the two expansions, the width pruning strategy and the depth pruning strategy will be used. Note that REUCP is also used in these two expansions. The pseudocode for the rightExpansion and the leftExpansion is shown in Algorithm 2 and Algorithm 3 respectively. In rightExpansion, US-Rule rst initializes the RSU-table, RE-table and rules to the empty set (Line 1). As discussed in Denition 4.12, the RSU-table is used to utilize RERSUP and LERSUP. Then the RE-table and rules are used to store information related to the expanded sequential rules. Subsequently, US-Rule scans the sequences containing the rules in . The RRSU of and the largest item in the antecedent of are obtained (Lines 2-5). If the expanded item does not satisfy REUCM(𝑁, 𝑖) greater than minutil, according to REUCP, US-Rule can stop the expansion of with (Lines 7-9). If this condition is satised, US-Rule lets be the expanded sequential rule and updates the RSU-table (Lines 10-11). And then, US-Rule determines whether RSU(𝑡) satises minutil, if not, US-Rule can use RERSUP to stop the operation associated with it and remove from rules (Lines 12-17). Otherwise, US-Rule updates rules and the corresponding RE-table of (Line 18). Subsequently, US-Rule repeats the session similar to the main program. Calculating the utility value of 𝑡 by scanning its RE-table (Line 23). If it is a high-utility sequential rule, US-Rule outputs it (Lines 24-26). Then the REEU and LEEU of are compared to minutil and US-Rule determines whether to continue expansion based on LEEUP and REEUP (Lines 27-32). The procedure of leftExpansion is similar to the rightExpansion. There is a little dierent from the rightExpansion. We can consider that the procedure of the leftExpansion is the rightExpansion without consequent growth. Therefore, we do not discuss the more details about it. In this section, in order to evaluate the performance of US-Rule algorithm, we perform experiments on several real-life datasets and synthetic datasets. Considering that dierent strategies have dierent eects on dierent datasets, we designed four versions of the US-Rule algorithm to compare the state-of-the-art HUSRM algorithm [ 40 ]. We use US-Rule , US-Rule , US-Rule and US-Rule to denote the four versions of the US-Rule algorithm. These four versions use the Strategy 1 and Strategy 2. In addition, US-Rule only uses REUCP, US-Rule uses REUCP and four pruning strategies (including LEEUP, REEUP, LERSUP, and RERSUP). US-Rule uses four pruning strategies and REURP. As for US-Rule , it uses all pruning strategies including REUCP, four pruning strategies, and REURP. We conducted our experiments in a PC equipped with a 64-bit Windows 10 operating system, 3.6 GHz AMD Ryzen 5 3600 CPU, and 8 GB RAM. Both HUSRM and US-Rule algorithms are implemented in Java language. The details of the experiment are given below. To assess the eciency and scalability of the US-Rule algorithms on dierent characteristic datasets, we use six datasets. There are four real-life datasets and two datasets. In our experiment, the real-life datasets are generated from book, click-stream, and sign language. They are generated from linguistic datasets, and they can be obtained and transformed from a page or a book. It can be considered that we test a single item sequence in real datasets and multiple item sequences in synthetic datasets. We use bible, kosarak, leviathan, and sign as four real-life datasets which can be obtained from SPMF . These include sparse datasets, dense datasets, and long sequence datasets, allowing the experiments to evaluate the algorithms from dierent types of data. As for synthetic datasets, we can consider that they are generated from IBM data generator [ ]. The details of all experimental datasets are shown in Table 9 and the description of them are given as following. • Bible is a moderately dense dataset converted from the Bible. It is also a slightly long sequence and one item dataset, with each sequence corresponding to a sentence of the Bible. • Kosarak is a particularly sparse short sequence dataset of click-stream from a Hungarian online news website. Likewise, it is also an item-based dataset. • Leviathan is a dataset generated from the novel Leviathan written by Tomas Hobbes. It is a slightly dense and moderately long sequence dataset, and each item contains one item. • Sign is a sign language and item-based dataset. It is the densest in our selection of real datasets, with many long sequences and a few hundred items. • Syn10k is a synthetic dataset generated from IBM data generator. It has 10,000 sequences and many moderately long sequences. Dierent from real datasets, it is a multiple-items-based dataset. • Syn20k is also a synthetic dataset generated from IBM data generator. It has 20,000 sequences. Dierent from the Syn10k, the number of dierent items is increased a little. In this subsection, we perform a number of experiments in terms of the running time. Four versions are used to compare the state-of-the-art HUSRM. When setting minconf to 0.6 and setting various minutil on dierent datasets, the experimental results are shown in Fig. 1. From the results, we can see that all four variants of US-Rule are better than HUSRM, especially on dense and long sequence datasets. On moderately datasets, such as Bible, Leviathan, and Synthetic datasets, we can clearly see that both REUCP and upper bounds pruning strategies can be eective. US-Rule is the fastest algorithm on datasets Bible and Leviathan. The dierence between USRule , US-Rule , and US-Rule is not signicant on Bible. While on Leviathan, we can see that as the number of optimization strategies increases, the running eciency improves. On the two synthetic datasets, the running times of the three variants US-Rule , US-Rule and US-Rule are almost the same. US-Rule is the fastest algorithm on datasets Syn10k and Syn20k. The reason is that the eect of REUCP is very obvious than the pruning strategies on synthetic datasets. Although pruning strategies are powerful, they are not as eective as REUCP. On the Kosarack, a sparse and short sequence dataset, US-Rule and US-Rule can achieve a signicant performance. REURP can quickly lter many unpromising items after the re-calculation of SEU. Among HUSRM, US-Rule and US-Rule , there is also a gap in their running time, and usually HUSRM is the slowest one. As minutil decreases, these algorithms can not discover HUSRs from datasets within an acceptable running time. On the dense dataset Sign, we can see that the running time of US-Rule and HUSRM are basically the same. This is consistent with our expectation that RECUP does not reduce much invalid computation on dense datasets. As for US-Rule and US-Rule , their running time is almost the same. US-Rule , which uses REURP, further optimizes the runtime. In summary, we can draw the conclusion as follows: on dierent types of datasets, although there are performance dierences between the variants of US-Rule algorithm using dierent strategies, they are always more ecient than HUSRM. The experimental results for the usage of memory are shown in Fig. 2. On the Bible dataset, we can see that the memory consumed by HUSRM, US-Rule , and US-Rule is not very dierent. For US-Rule , which does not use SEUCP, it consumes the least amount of memory. While US-Rule which only uses SEUCP, consumes more memory. On Kosarack10k, since REURP lters many unpromising items, it makes the memory consumption of US-Rule and US-Rule particularly low. For US-Rule and US-Rule , the use of REUCM increases the memory consumption. On the Leviathan dataset, the memory consumption uctuates a bit. We can still see that it is similar to the case on the Bible dataset, i.e., US-Rule generally uses less amount of memory. On the Sign dataset, the memory of each algorithm does not dier much, which may be due to the very small number of items in Sign. On the rst synthetic dataset, we can see that HUSRM and US-Rule use more memory. REUCP works well on this dataset. In contrast, on the second synthetic dataset, the algorithm which uses REUCP usually consumes more memory. This is exactly as expected, since the second synthetic dataset is denser, making REUCP less eective. In this subsection, to better compare the scalability of each algorithm, we use synthetic datasets and increase their size from 15k to 20k. We evaluate these algorithms in terms of running time and memory consumption. The minconf is set to 0.6 and the minutil is set to 2000. The experimental results are shown in Fig. 3. Obviously, as the dataset size increased, both the running time and memory consumption of each algorithm are increased too. The experimental results are also expected, and the algorithm using the most optimized strategies can always achieve the best eciency, but consumes much memory. The algorithm using only the pruning strategies can improve the eciency and does not cost much memory. In terms of runtime, although all algorithms show a linear increasing trend, all versions of US-Rule do not increase as much as that of HUSRM. In this paper, to improve the eciency of high-utility sequential rule mining, we proposed a novel US-Rule algorithm. Based on REUCP, US-Rule can achieve a better performance. In order to solve the eciency on dense or long sequence datasets, we introduced four tighter upper bounds and proposed their corresponding pruning strategies. To better address the issue on sparse and short sequence datasets, we further proposed REURP to lter unpromising items by recalculating the SEU of items multiple times. Finally, we conducted a large number of experiments on dierent datasets to evaluate dierent variants of the US-Rule algorithm. Combining the results of each experiment, we can say that US-Rule has better performance and scalability than the state-of-the-art HUSRM algorithm. Our future work may apply the US-Rule algorithm to deal with some applications in other elds, and also will adapt US-Rule with several constraints for more valuable sequence mining. This research was partially supported by National Natural Science Foundation of China (Grant No. 62002136), Guangdong Basic and Applied Basic Research Foundation, Guangzhou Basic and Applied Basic Research Foundation (Grant No. 202102020277).