Machine learning (ML) classiﬁers are increasingly being used for consequential decision-making in domains such as justice and ﬁnance (e.g., granting pretrial bail or loan approval) preserve human agency despite the rise in automatic decisions faced by individuals has motivated the study of algorithmic recourse, which aims to empower individuals by providing them with actionable recommendations to reverse unfavourable algorithmic decisions for recourse to warrant trust, the decision-maker must commit to reversing an unfavourable decision upon the decision-subject fully adopting their prescribed recourse recommendations argue that if algorithmic recourse is indeed to be treated as a contractual agreement, then recourse recommendations must be robust to plausible uncertainties arising in the recourse process. For instance, consider a bank that commits to approving the loan of an individual if they increase their salary by some amount. However, by the time the individual achieves the prescribed salary increase the country’s economic situation has slightly worsened and the classiﬁer still deems the individual likely to default on the loan. Shielding the recourse recommendation against uncertainty ex-post by nonetheless granting the loan may be detrimental to both the bank (e.g., monetary loss) and the individual (e.g., bankruptcy and inability to secure future loans), while breaking the recourse promise would negate the effort exerted by the individual and erode trust in the decision maker. We therefore argue for the necessity of ensuring that recourse recommendations are ex-ante robust to uncertainty. In this work, we direct our focus towards robustifying recourse recommendations against uncertainty in the features of the individual seeking recourse. Such uncertainty may arise due to the temporal nature of recourse (e.g., some features may not be static adversarial manipulation Preprint. Under review. Max-Planck-Institute for Intelligent Systems, Tübingen, Germany Algorithmic recourse seeks to provide actionable recommendations for individuals to overcome unfavorable outcomes made by automated decision-making systems. Recourse recommendations should ideally be robust to reasonably small uncertainty in the features of the individual seeking recourse. In this work, we formulate the adversarially robust recourse problem and show that recourse methods offering minimally costly recourse fail to be robust. We then present methods for generating adversarially robust recourse in the linear and in the differentiable case. To ensure that recourse is robust, individuals are asked to make more effort than they would have otherwise had to. In order to shift part of the burden of robustness from the decision-subject to the decision-maker, we propose a model regularizer that encourages the additional cost of seeking robust recourse to be low. We show that classiﬁers trained with our proposed model regularizer, which penalizes relying on unactionable features for prediction, offer potentially less effortful recourse. robustness of recourse with respect to uncertainty in the features of the decision-subject have studied whether the cost of recourse is robust recourse recommendations with similar cost. In contrast, we focus on the validity of recourse, and seek recourse recommendations which remain valid (i.e. lead to favourable classiﬁcation outcomes) for all plausible individuals similar to the individual seeking recourse. We refer to this notion of robustness as the adversarial robustness of recourse, in order to distinguish it from other robustness considerations previously studied in the recourse literature (e.g., robustness with respect to changes to the decision-making classiﬁer which considers robustness of prediction precisely against uncertainty in the features of the data. We study the adversarial robustness of recourse from the lens of causality views recourse recommendations as causal interventions on the features of the decision-subject and therefore presents a more faithful account of how the features of the individual change as the individual acts on its recourse recommendations, provided that the underlying structural causal model is known or can be approximated reasonably-well of robustifying recourse against uncertainty in the features of the individual seeking recourse. In Section 2, we discuss the different sources of uncertainty present in the recourse process and relate them with previous works on the robustness of recourse. In Section 3, we model the uncertainty in the features of the individual seeking recourse by leveraging a counterfactual notion of similarity between individuals which explicitly considers the causal relationships between features. In Section 4, we formally deﬁne the adversarially robust recourse problem, we show that minimum-cost recourse fails to be adversarially robust, and we derive sufﬁcient conditions for the existence of adversarially robust recourse. In Section 5 we discuss how to generate adversarially robust recourse in the linear and in the differentiable case. In Section 6, we theoretically motivate a model regularizer that encourages the additional cost of seeking robust recourse to be low. Finally, in Section 7 we empirically evaluate the proposed methods in both the causal and non-causal recourse setting. 2.1 Structural causal models, interventions, and counterfactuals We assume that the data-generating process of the features x ∈ X structural equations any given feature function distribution observed in the data. We assume that the causal graph and edges observational distribution mapping the exogenous variables are mutually independent (causal sufﬁciency), if there exists some inverse mapping corresponding to some individual x ∈ X are uniquely identiﬁable by U|x = S SCMs allow for modelling and evaluating the effect of interventions on the system which the SCM models. Hard interventions θ ∈ R while preserving the rest of the structural equations interventions sever the causal relationship between an intervened upon variables and all of its ancestors in the causal graph. Soft interventions, on the other hand, may modify the structural equations in a more general manner perturbation vector structural equations according to S Moreover, SCMs imply distributions over counterfactuals, allowing to reason about what would have happened under certain hypothetical interventions all else being equal. Under the aforementioned assumptions, the counterfactual x ∈ Xunder some hypothetical hard intervention is characterised by a known structural causal model (SCM)[26] M = (S, P). The f. The exogenous variablesU ∈ U, which are distributed according to some probability P, represent unobserved background factors which are responsible for the variations {(v, X) : v ∈ X∪ U, i ∈ [1, n]}, is acyclic. The SCMMthen implies a unique S : U → Xbetween exogenous and endogenous variables. Under the assumption that S: X → Usuch thatSS(x)= x ∀x ∈ X, then the endogenous variables by altering the structural equations of the intervened upon variablesS= X:= θ Figure 1: Overview of the recourse process. Elements where uncertainty may be present are represented with dashed circles. Possible relations between uncertain elements are represented with non-bold dashed lines. Bold dashed lines represent temporal jumps. be computed by ﬁrst determining the exogenous variables the individual dogenous to exogenous variables x= CF (x, do(X We use the notation the counterfactual corresponds to a particular structural causal model M. Consider the classiﬁcation setting where a classiﬁer or unfavourable outcomes to individuals provide unfavourably classiﬁed individuals a set of recommendations which if acted upon would result the individual being favourably classiﬁed introduced by Karimi et al. of the individual seeking recourse, that is, rather than individual x to propagate to the recourse action a. For a recourse action be favourably classiﬁed, that is, (e.g., race) or bounded (e.g., age), only feasible actions should be recommended. The action feasibility set recommendations should incur the least amount of effort possible for decision-subjects. The cost function Finding the minimum-cost recourse action for some individual following optimization problem: The non-causal recourse setting is equivalent to the causal recourse setting under the independently manipulable features (IMF) assumption, that is, if no causal relationships exist between features. Under such assumption, CF (x, do(X = x + θ)) = x + θ. Uncertainties may arise throughout the recourse process, as depicted in Figure 1, and may alter the validity of recourse, as highlighted in Equation 1. Some well-studied sources of uncertainty in the classiﬁcation setting naturally extend to algorithmic recourse. A great deal of the robust classiﬁcation literature has focused on uncertainty in the inputs presence of noise in the data often does not have unique optimal solution and multiple models may perform equally well in the p(x, y) x, and then applying the interventional mappingS(resp.S) from ena = do(X= θ)as Karimi et al.[14], to explicitly allow for the uncertainty in the factual F(x)captures the set of feasible actions available to the individualx. Ideally, recourse c(x, a)models the effort required by an individualx ∈ Xto implement the recourse actiona. arg minc(x, a) s.t. a ∈ F(x) ∧ hCFx , a, M [42]. Regarding the classiﬁerh, the optimization problem solved for model training training data circumstances under which recourse is generated may change by the time the individual is able to implement their prescribed recourse. For instance, the distribution over inputs itself may change at inference time, under phenomena such as data-set shift distribution generalization distribution are a consequence of changes to the underlying SCM [5]. Indeed, the data-generation process characterised by the SCM may dynamically change over time to some other SCM over future SCMs. Consequently, the counterfactual individual resulting from the prescribed recourse intervention may also change. Furthermore, decision-makers may have to periodically retrain their models to prevent performance degradation due to the distribution shift resulting from a change in the SCM, producing further uncertainty over the future classiﬁer unreasonable to expect the individual period of time (e.g., suffering an accident causing a decrease in savings) in the future individual classiﬁcation due to changes to the SCM We now draw connections with existing literature on the robustness of recourse. Previous works have identiﬁed that small changes to the features of the decision-subject recommendations with very different costs being offered. Slack et al. based recourse methods it is possible to maliciously train a classiﬁer such that small perturbations to the features of an individual drastically alter the cost of the generated recourse, and von Kügelgen et al. race, gender) may be assigned recourse actions with drastically different cost. While these works study the robustness of the cost of recourse, we instead focus in the robustness in the validity of recourse, that is, ﬁnding a recourse action which remains valid under uncertainty in the individual Other works have considered the problem of generating recourse actions which remain valid under uncertainty in the classiﬁer counterfactual individual in regions of the feature space with large data support are more robust under predictive multiplicity compared to minimum-cost recourse actions. However, recourse actions with large data support may be unnecessarily costly. In contrast, our approach seeks counterfactual individuals which are sufﬁciently far from the decision-boundary to be robust but not overtly so, thus ensuring robust recourse while maintaining a relatively low cost of recourse. Another line of work has considered the robustness of recourse with respect to changes to the classiﬁer in response of dataset shift. Rawal et al. Upadhyay et al. procedure where the cost the recourse is minimized subject to the recourse action being valid under adversarial changes to the classiﬁer in the individual x rather than the classiﬁer h, and we consider the causal recourse setting. Finally, Karimi et al. be approximated, and propose a recourse method to generate recourse recommendations which have low probability of being invalid due to the misspeciﬁcation of the underlying SCM. Our work is tangential to Karimi et al. [13] and both approaches can be used in tandem. In the adversarial robustness literature, uncertainty in the features of some observed data point often modelled by an normk·k the data point interpreted as a neighbourhood of plausible data points similar to the observed x. From a causal perspective, such feature changes features However, in the causal recourse setting we assume to know such causal relationships, which are fully [4, 32]. Moreover, the temporal nature of recourse introduces a unique challenge: the [39]show that “counterfactual twins” obtained by intervening on sensitive attributes (e.g., [30]show that recourse actions are typically not robust to such model changes, and [36]aim to mitigate this issue by generating recourse with a minimax optimization characterizes some notion of similarityd(x, y) = kx − yk. Intuitively, small changesδto xresult in similar data pointsx= x + δ. The uncertainty setB(x)can therefore be xunder the IMF assumption, that is, if not causal relationships exist between features. Figure 2: (a) Illustration of the observational and counterfactual neighbourhoods of similar individuals for the SCM actions must ensure that, for every plausible factual individual counterfactual resulting from the suggested recourse intervention is favourably classiﬁed. speciﬁed by the assumed SCM can potentially provide more informative neighbourhoods of individuals. Deﬁnition 1 k·kand SCM deﬁned as the set of counterfactual individuals under all possible -small additive interventions As a motivating example, consider the SCM tively denoting the income and savings of some individual and counterfactual neighbourhoods of similar individuals for the 2-norm similarity metric serve that under the counterfactual neighbourhood, the individual ¯xwith higher income and higher savings than to some other individual lower savings, since the latter is not well explained by the SCM substantially differ from those of resulting in lower savings despite its higher income). Therefore, we ague that counterfactual neighbourhoods can be more informative than observational neighbourhoods, since the causal relationships between features are explicitly considered. While we solely consider counterfactuals resulting from additive interventions, we recognize that other interventions could be considered, such as hard interventions or interventions on the distribution over exogenous variables are equivalent to shifts in the exogenous variables U. We leave possible extensions for future work. We consider the problem of generating recourse recommendations which are robust to uncertainty in the features of the individual seeking recourse. We draw inspiration from the adversarial robustness literature, and require robust recourse actions the uncertainty set illustrated in Figure 2b, for every plausible factual individual counterfactual resulting from the recourse intervention a must be favourably classiﬁed. Deﬁnition 2 cost recourse action which remains valid for all plausible individuals x X= U,X= X+ Uunder the 2-norm similarity metrick·k. (b) Robust recourse (-Neighbourhood of counterfactually similar individuals).For some similarity norm M, the-neighbourhood of counterfactually similar individuals to some individualxis (Adversarially robust recourse problem).For some uncertainty setB(x), the minimumarg minmaxc(x, a) s.t. a ∈ F(x) ∧ h (CF(x In this section, we ﬁrst show that under mild conditions, minimum-cost recourse is fragile to arbitrarily small uncertainty in the features of the individual seeking recourse. Then, we derive sufﬁcient conditions for the existence of adversarially robust recourse, summarized in Table 1. Intuitively, minimum-cost recourse actions place the counterfactual individual arbitrarily close to the decision boundary of the classiﬁer, since pushing the counterfactual further into the favourably classiﬁer region of the feature space would incur additional cost. Consequently, under arbitrarily small uncertainty in the features of the individual seeking recourse, some of the plausible counterfactuals may be unfavourably classiﬁed, as illustrated in Figure 2b. Theorem 1 states mild conditions under which minimum-cost recourse actions are indeed fragile. Theorem 1. Let a (iii) The SCM M is an additive noise model [26]. The conditions in Theorem 1 are often assumed by previous works. The ﬁrst condition requires that larger changes to the features imply strictly more effort from the individual, which is satisﬁed by the most widely used cost functions, namely weighted p-norms condition states that if it is feasible to change a feature by some amount, then it must also be feasible to change that feature to a lesser degree, which is satisﬁed for the box actionability constrains commonly assumed in the recourse literature (e.g., features are unbounded, bounded or immutable third condition is assumed by causal recourse approaches which estimate the underlying SCM from data Therefore, in the settings commonly considered by the algorithmic recourse literature, recourse methods seeking minimum-cost recourse generate recourse recommendations which are fragile to even arbitrarily small uncertainty in the features of the individual seeking recourse. 4.2 Sufﬁcient conditions for the existence of robust recourse The conditions required for the existence of robust recourse are strictly more restrictive than those required for the existence of standard recourse, since all plausible counterfactuals must be favourably classiﬁed rather than solely the one corresponding to the factual A.2, shows that even under the strong assumption that all features are actionable and that there exists recourse for every individual x ∈ X , robust recourse may not exist for any individual x ∈ X . Example 1. B(x) = {x + ∆ | k∆k there does not exist any adversarially robust recourse recommendation for any x ∈ R The above example relies on the fact that the classiﬁer does not produce robust predictions for any x ∈ X, and therefore no counterfactual can remain valid (i.e. favourably classiﬁed) in the presence of uncertainty. This hints to some relation between robustness of prediction and robustness of recourse. In particular, we show that for recourse to exist, the classiﬁer must be minimally robust in the sense that there must exist at least one individual x Lemma 1. x∈ B(x In order to relax the condition that all features must be actionable, we restrict ourselves to the case where both the classiﬁer and the SCM are linear. Then, the existence of at least one actionable and unbounded feature is sufﬁcient to guarantee the universal existence of robust recourse. Intuitively, the decision-maker can require arbitrarily large changes to an actionable and unbounded feature such that all plausible counterfactuals are favourably classiﬁed (e.g., increase savings for loan approval). = x+ θ)) ∈ F(x) =⇒ do(X= x+ tθ)) ∈ F(x) ∀ 0 < t < 1  > 0there existsx∈ B(x) = {CF (x; ∆)) | k∆k ≤ }such thath(CF(x, a)) = 0, [13], and also holds in the non-causal recourse setting (i.e. under the IMF assumption). Considerx ∈ R,h(x) = sin(2γπx) ≥ 0for0 < γ < and the uncertainty set If all features are actionable and there exists somex∈ Xsuch thath(x) = 1for all ), then there exists some adversarially robust recourse recommendation for all x ∈ X . Lemma 2. if there exists a feature at least one adversarially robust recourse action for all x ∈ X . If all features are bounded and there exists at least one immutable feature, then as per Ustun et al. Remark 3, it is not possible to guarantee the universal existence of recourse even in the linear case, and therefore it is also not possible to guarantee the universal existence of adversarially robust recourse. We now present methods to solve the adversarially robust recourse problem introduced in the previous Section. We consider both the linear and the differentiable case. For a linear classiﬁer to generating standard recourse for a modiﬁed classiﬁer threshold” is sufﬁciently increased (i.e. the acceptance threshold of the original classiﬁer, as illustrated in Figure 3. Theorem 2. andB(x) = {CF (x, ∆) | k∆k ≤ } set is invariant to perturbations to robust recourse problem is equivalent to the following optimization problem wherek·k resulting from hard-intervening on features X Corollary 1. adversarially robust recourse problem for the classiﬁer standard recourse problem for the modiﬁed classiﬁer h We highlight the importance of this result: if the conditions for Theorem 2 are satisﬁed, then generating recourse recommendations with respect to the modiﬁed classiﬁer recourse is adversarially robust. Conveniently, one may use any given recourse generation method from the rich corpus on algorithmic recourse in order to enforce, together with adversarial robustness, other desiderata such as large data-support [11, 23] or fairness constrains [10, 39]. Table 1: Sufﬁcient conditions for the existence of robust recourse. Classiﬁer hActionabilityconstraintsSCM MExistence ofrecourseExistence ofrobust recourse ∈ B(x)actionable(Ustun et al. [37])(Lemma 1) Linear∃ Xactionableand unboundedLinearGuaranteed(Lemma 2)Guaranteed(Lemma 2) AnyAll bounded,≥ 1 immutableAnyNot guaranteed(Ustun et al. [37])Not guaranteed(Follows directly) For a linear classiﬁerh(x) = hw, xi ≥ band an SCMMwith linear structural equations, Leth(x) = hw, xi ≥ bbe a linear classiﬁer,Man SCM with linear structural equations, minc(x, a) s.t. a ∈ F(x) ∧ hw, CF (x, a)i ≥ b +Jw denotes the dual norm ofk·kandJdenotes the Jacobian of the interventional mapping Under the conditions of Theorem 2 and additionally under the IMF assumption, the Figure 3: Illustration of the “robust classiﬁer” for which recourse is robust. Similarly to Wachter et al. [40], we consider the objective function where`is the binary cross entropy loss. The adversarially robust recourse problem is then equivalent to the following unconstrained penalty problem For the outer maximization problem in Equation 6, we adopt a common approach in the literature[25, 13] recourse action is found. Intuitively, small values of iteratively increasing order for the counterfactual individual to be favourably classiﬁed. For the minimization problem in Equation 6, we use projected gradient descent. The actionability constrains typically considered in the algorithmic recourse literature (e.g. whether features are actionable and bounded amount to box constrains, and thus projecting to in Equation 6 can be readily solved using projected gradient ascent B(x) = {CF(x, ∆)| k∆k ≤ } order Taylor approximation of We summarize the proposed optimization procedure in Algorithm 1. Note that if there is no uncertainty in the features of the individual, that is that of Wacther et al. Our approach is also similar to Upadhyay et al. maximization problem over perturbations to the classiﬁer as a ﬁxed hyperparamater, and they consider the non-casual recourse setting. In the previous sections, we have assumed a ﬁxed classiﬁer for which robust recourse must be generated. Then, to ensure that recourse recommendations are robust, individuals are asked to make more effort than they would have otherwise had to. Consequently, the burden of immunizing recourse Decision boundary Robust decision boundary10: return θ and, starting with a sufﬁciently smallλ > 0, we iteratively increaseλuntil some against uncertainty falls solely on the decision-subjects. We argue, however, that robust recourse desiderata could be directly embedded into the training of the classiﬁer. Satisfying such desiderata may come at a cost in predictive accuracy, thus shifting part of the burden of robust recourse from the decision-subject to the decision maker. In this section, we ﬁrst restrict ourselves to the linear case in order to theoretically motivate a regularization penalty to reduce the additional cost of robust recourse. We then extend this regularization penalty to the differentiable case by drawing inspiration from local linearity regularization 6.1 An upper bound on the additional cost of robust recourse We restrict ourselves to the linear case in order to derive an upper bound on the additional cost of robust recourse under certain actionability assumptions. For some recourse action we provide an expression for the increase in action magnitude recourse action a Theorem 3. equations, a = do(X such that for feasible action a Corollary 2. cost function is subadditive, then the additional cost incurred by robustifying action a is Consequently, decision-subject as a result of seeking robust recourse. Observe that the weights of the classiﬁer bound on the additional cost of recourse assumption, such that actionable (resp. unactionable) and (m)= 1 ⇐⇒ i ∈ A weights corresponding to actionable features and those corresponding to unactionable features: where the classiﬁer weights corresponding to the unactionable features directly reduces the value of is, the upper bound on the additional cost of robust recourse. In particular, we propose to use the unactionability penalty bias “the classiﬁer should rely more strongly on actionable features for its predictions”. We consider classiﬁers of the form the aim of reducing the additional cost of robust recourse, we propose the following regularizer. which we denote as the actionable locally linear regularizer (ALLR). The ﬁrst term corresponds to the previously motivated actionability penalty for the linear approximation of the classiﬁer Lethbe a linear classiﬁerh(x) = hw, xi ≥ b,Man SCM with linear structural x ∈ Xa negatively classiﬁed individual for which there exists some recourse action = x+ θ), and B(x) = {CF (x, ∆) | k∆k ≤ }. Then, there exists some constant a= do(X= x+ (1 + β)θ)it holds thatCF(x, a) = 1 ∀x∈ B(x). Ifais a ∈ F(x), then it follows that ais an adversarial robust recourse action. Under the assumptions of Theorem 3 and additionally under the assumption that the βconstitutes an upper bound on the additional cost of recourse incurred by the β =kwkhw, θi=km w + m wkhw, m θi=km wk+ km wkhm w, θi(10) denotes the elementwise product. Consequently, reducing the dual normkm wkof R(x) = µ km ∇g(x)k+ γ max|g(x + δ) − hδ, ∇ haroundx, whereb= b + h∇g(x), xi − g(x). The second term, inspired by the locally linear regularizer (LLR) the linear classiﬁer term aims to reduce the upper bound on the additional cost of robust recourse for the linear classiﬁer hwhich locally approximates reasonably accurate for the actual classiﬁer of regularization. The classiﬁer is then trained by minimizing the following objective where`is some loss function (e.g., binary cross-entropy) and Firstly, we empirically validate the method proposed in Section 5.2 for generating adversarially robust recourse in the differentiable case. Secondly, we empirically show that classiﬁers trained with the proposed actionable locally linear regularizer (ALLR) potentially offer recourse at a lower cost. For the causal recourse setting, we consider one semi-synthetic dataset and one real-world dataset. Firstly, we consider a 7-variable semi-synthetic SCM introduced by Karimi et. al by the German Credit UCI dataset credit risks. We consider two features as actionable: education and income. Some of the structural equations in the SCM are non-linear. Secondly, we consider the Adult dataset census data from 1994 on over 45,000 individuals with the prediction target being individuals have a yearly salary greater than $50,000. We consider the causal graph assumed in Nabi and Shpitser [ and ﬁt the structural equations as 1-layer MLPs. We use 6 features, out of which we consider two actionable: the education level and the number of weekly working hours. For the non-causal recourse setting, we consider two real-world datasets. The COMPAS dataset contains information on over 10,000 criminal defendants in Broward County, Florida, and the prediction target is whether the defendants reoffended in a two year period. We use 9 features, out of which we consider one actionable: the number of previous crimes. Lastly, we use a dataset (denoted as Bail for consistency with Ress et al. released from prison in 1978 in the state of North Carolina the individuals reoffended in a two year period. We use 15 features, out of which we consider two actionable: the number of years of school coursed, and the number of reported prison rule violations. For the considered datasets, all actionable features and all of its causal descendants are real-valued, with the exception of “education” in the Adult data set, which we assumed to be real-valued. We standarize all real-valued features. We generate recourse for negatively classiﬁed individuals from the test data, and we use as the cost function the c(x, a = do(X model, and a 3-layer MLP with 100 hidden units and tanh activation. We deﬁne the uncertainty set B(x) with respect to the 2-norm, that is, B(x) = {CF(x, ∆)| k∆k We ﬁrst evaluate whether the method proposed in Section 5.2 generates recourse actions which are robust to uncertainty in the features of the individual seeking recourse. To do so, we assess whether the generated recourse individuals in the uncertainty set intervention ∆ If the magnitude of such intervention recourse against, that is experiments, we use the method proposed in Section 5.2 to generate recourse recommendations against different magnitudes of uncertainty the standard non-robust recourse setting. For each generated recourse action, we use the Carlini & Wagned (C&W) attack the smallest intervention standard recourse ( = 0), we assume that there exists a small amount of uncertainty  = 0.01. = x+ θ)) = kθk. For the classiﬁers, we consider a logistic regression (LR) on the features of the individual such that a is no longer a valid recourse action ∆= arg mink∆ks.t. h(CF(x, a)) = 0, x Figure 4: Fragility and cost of the actions generated using the method proposed in Section 5.2, for different levels of uncertainty proposed method generates robust recourse for reasonably small amounts of uncertainty. The experimental results are presented in Figure 4. Firstly, we observe that standard recourse may be invalidated by very small amounts of uncertainty in the order of portion of the recourse actions may be fragile. While we have showed that minimum-cost recourse actions are guaranteed to be fragile, in practice due to computational constrains the recourse problem is not solved exactly (e.g., optimization may be stopped after some maximum number of iterations) and the recourse action found may not be the minimum-cost recourse action. For recourse that has been robustiﬁed against reasonably small amounts of uncertainty the magnitude of the smallest additive intervention required to invalidate the recourse action is no lower than (i.e. = 0.5 not be accurate, and consequently some of the offered recourse actions can be fragile. This can be remedied by solving the inner maximization problem with greater accuracy (e.g., using multi-step projected gradient ascent), at the expense of greater computational cost. Finally, we observe that robustifying recourse against larger uncertainty  results in more costly recourse actions. For completeness, in Appendix B.1 we consider two other popular adversarial attack techniques, the projected gradient descent attack results for the non-causal recourse setting for the COMPAS and Bail datasets. 7.2 Actionable local linearity regularization: reducing the cost of recourse We empirically evaluate whether classiﬁers trained with the proposed ALLR regularizer offer lower cost recourse compared to classiﬁers trained with empirical risk minimization (ERM), the standard model training setting considered in the algorithmic recourse literature. Since our proposed ALLR regularizer enforces the inductive bias “the classiﬁer should rely more strongly on the actionable features”, we also train as a baseline comparison classiﬁers which only use actionable features (AF). Such case corresponds to ALLR with arbitrarily large strength of regularization γ. For each of the three different model training approaches discussed (ERM, AF, ALLR), we train ﬁve different classiﬁers using different train and test data splits. We then generate standard recourse and , and therefore the generated recourse actions are robust. For large amounts of uncertainty ), the ﬁrst-order approximation made for solving the inner maximization problem may Figure 5: Mean cost of robust recourse and classiﬁcation accuracy for each of the three model training approaches considered. Classiﬁers trained with ALLR offer lower-cost recourse compared to classiﬁers trained with ERM, while maintaining higher classiﬁcation accuracy than AF classiﬁers. robust recourse ( recourse as well as the percentage of individuals for which recourse was found. We present the experimental results in Figure 5. Compared to ERM, our proposed regularizer reduces the mean cost of recourse by up to 60%, while classiﬁcation accuracy may only decrease by up to 2%, and in some cases it does not decrease at all. While the proposed regularizer is theoretically motivated for reducing the additional cost of robust recourse, we observe that the cost of standard recourse also decreases for all but one of the datasets considered. We also observe that using only actionable features (AF), equivalent to ALLR with arbitrarily large regularization, can result in even greater reductions in cost of recourse compared to both ERM and ALLR. However, both classiﬁcation accuracy and the percentage of individuals for which recourse is found may signiﬁcantly decrease. Therefore, we argue that ALLR provides a the most favourable trade-off between classiﬁcation accuracy and cost of recourse. Consequently, ALLR can be an effective technique in regulating the burden of (robust) recourse between the decision-maker and the decision-subject. For completeness, in Appendix B.2 we compare our proposed regularizer against other related model-training approaches (L2 regularization, local linearity regularization training ALLR. On the contrary, we ﬁnd evidence that model training approaches which promote robustness of prediction produce classiﬁers that offer recourse at much greater cost. We leave the study of the relation between robustness of prediction and robustness of recourse for future work. Uncertainty in the recourse process is inevitable. Previously suggested ex-post solutions to mitigate the effect of uncertainty in the recourse process may result in negative outcomes for both the decision-maker and the individual. We instead adopt an ex-anti approach to robustness of recourse by requiring the recourse recommendations to be robust to uncertainty in the features of the individual seeking recourse. We show that, in practice, minimum-cost recourse is fragile to arbitrarily small uncertainty in the features of the individual. To address this, we formulate the adversarially robust recourse problem, and present methods to generate adversarially robust recourse in both the linear and differentiable case. Finally, in order to regulate the burden of robustness between the decision-maker and the decision-subject, we theoretically motivate a model regularizer that encourages the additional  = 0.1) for 100 negatively classiﬁed individuals. We compute the mean cost of [35, 17]). None of these approaches reduces cost of recourse to an extent comparable to cost of seeking robust recourse to be low. We empirically show that classiﬁers trained with our proposed model regularizer, which penalizes relying on unactionable features for prediction, offer potentially less effortful recourse in both the causal and the non-causal recourse setting.