Introd uction: There is increasing interest in Artiﬁcial Intelligence (AI) and its application to medicine. Perceptions of AI are less well-known, notably amo ngst children and young people. This exploratory patient and public engagement (PPEI) worksh op investigates attitudes towa rds AI and its future applications in medicine and healthcare from the perspective of children and young people with lived experienc es at a specialised paediatric hospital using practical design scenarios. Method: Membe rs of Great Ormond Street Hospital for Children’s (GOSH), Young Persons Advisory Group for research (YPAG) contributed to a one-hour AI workshop to ascertain potential op portunities, appreh e nsions, and prior ities. Quantitative polling using a series of nine AI-related d e sign scenarios were scored voluntarily and anonymously on a 10-point Likert scale and mechanisms for effectively engaging with patients and families on the potential for AI were discussed. Results: 21 GOSH YPAG members (aged 10-21 years) participated. Human-centeredness, governance and trust emerged as major themes, with empathy and safety considered as important when introducing AI to healthcare. Of the scenarios presented , sensor technology to r e duce overcrowding (M 7.4, SD 2.7), cleaning robots (M 7.9, SD 2.4), vir tual reality visits (M 6.5, SD 2.8) and 3 D prin te d organs (M 6.2, SD 3.5) were the most acceptable, whilst AI-powered nurses the least acceptable (M 2.4, SD 2.3). Educational workshops with practical examples using AI to help, but not replace, humans were suggested to address issues, build trust and effectively communicate about AI. Conclusion: Whilst policy guidelines ac knowledge the need to include c hildren and you ng people to develop AI, this ignores in frastructure needs to encourage digital cooperation. For AI in medicine and healthcar e this re quires an enabling environment for hu man-centre d AI involving children and young people with lived experiences of healthcare. This PPEI work shop is an important me chanism to shape futur e research questions. Future research should focus on building consensus on enablers for an intelligent healthcare system designed for the next generation, which fundamentally, allows co-creation. There is growing in te rest in the application of Artiﬁcial Intelligence (AI) to medicine. Initially described as exotic, expensive, and not of beneﬁt to ordinary people, global intere st within the ﬁeld ha s increased exponentially. H ighquality reviews of AI in healthcare have addressed its use, value, and trustworthiness. In children’s healthcare, parents ask for openn ess durin g AI development, and ask that technical experts consider shared decision making, the human element of ca re and social justice as part of the development process. However, whilst views of Children and Young People (CYP) can shape healthcare provision, few policy recomm e ndations reﬂect their views an d beliefs. This is particularly the case for CYP w ith tacit healthcare knowledge. Great Orm ond Street Hospital for children (GOSH) is the largest paediatric centre in the UK and an international centre of excellence for many c linical specialties. As p art of the hospital, the Digital Research, In formatics, and Virtual Environme nts (DRIVE) unit aim s to accelerates resear c h and deployment of new technology including working with patients and families to optimise technologies such as AI. The Young Persons Advisory Group (YPAG) is a patien t and public involvement gro up embedded at the hospital comprising CYP who are interested in improving hea lth by advising on research, and forms part of a nation al network (Gen e ration R). Using a workshop entitled AI&me, we address a c urrent deﬁcit in AI health c are policy and practice, by exploring the perspective of CYP with lived experiences of healthcare including establishing priorities of GOSH YPAG in an exploratory PPEI design workshop on Healthcare AI. A single design workshop examined perceptions and attitudes of CYP on AI applications in medicine and healthcare. Findings were reported using the COREQ 32 -point check list for focus g roup reﬂexivity, de sig n and analysis (included as a supp le ment) Members of GOSH YPAG contributed to an exploratory engagement workshop run virtua lly, lasting one hour to explore their perceptio ns of AI in medicine and healthcare. They rated levels of comfort with AI-related design scenarios and discussed mechanisms to effectively engage w ith patients and families on AI’s future potential. The v irtual workshop opened with a sho rt broad discussion about AI, after which nine design scenarios were presented, including: Virtual Reality visits to hospitals, cleaning robots, talking ro bots, chatbots to diagnose disease, self-driving vehicles, AI-powered nu rses, 3D printed hearts and senso r technology to reduce overcrowding. These were developed from a rec ent survey of 2000 parentsand predominantly fo cused on healthcare applications of tech nologies intend ed to d elight, inform, predict, automate or diagnose/treat. Quantitative polling of scenarios was undertaken anonymously using a 10-point Likert- scale . To collect comments, a virtual chat function and an agile, Audience Response System (Mentimeter AB, Stockholm, Stock holms Lan, Sweden) were used since these are effective for encouraging participation in virtual learning environments. Comments were collected verbatim. Inductive qu a litative content analysis identiﬁed conc e pts and emergent themes using NVivo for Windows v.1.4.1 (QSR Inter- national, Melbourne, Australia) to shape fu ture research questions, as there is limited existing qualitative research regarding perceptions of AI in medicine and he althcare amo ngst CYP with lived experien ces. This involved data familiarisation, immersion a nd iterative identiﬁcation of codes, concepts, phrases and language. Open codes were collated under emerging themes and ﬁndings supported by verb atim quotes. 21 YPAG members (aged 10- 21 years) participated, generating 128 unique comments across platforms. The language used by participants comprised words that described how AI made them feel (58 generalised occurrences that included affect, care, compassion, consider, exp erience and f ear), AI was commonly referred to as a ‘robot’ (18 incidents) and ‘creepy’ on six occasions. Patients were commonly mentioned (18 occurrenc es) and generalised words relating to comfort (assure and reassure) were used 26 times. The comments wer e conversational, but several comments we re structured as questions (n=28, 22%) suggesting interest to understand more about AI (Figure 1b). Of the nine design scenarios presented, sensor technology to reduce overcrowding (M 7.4, SD 2.7), cleaning robots (M 7.9, SD 2.4), virtual reality visits (M 6 .5, SD 2.8) and 3D printed organs (M 6.2, SD 3.5) were the most accepted scenarios, wh ilst AI-powered nu rses the least (M 2.4, SD 2.3; Figure 1c). Three themes emerged from the exploratory eng a gement workshop: governance, human centredness and trust (Figure 1a). Safety and beneﬁts formed the basis of a numbe r of early inquiries about AI. There was an interest that access to AI-enabled technologies was fair and available to all. Ensuring safety, security risks, and re liability was of particular interest, one participant asking: “What safety measures are in place?”, another: ‘What happens if the robot makes(s) a mistake or the software breaks down?”, expanding to ask: “Would the ro bot get the beneﬁt of the doubt?” More broadly, on ethical use of AI, one participant asked: “How do you stop people abusing the sy stem?” As members of YPAG at a spec ia list paediatric hospital, a number of questions were raised about the role of AI for rare diseases, and pote ntial beneﬁts to challenges faced in healthcare, on e participant asking: “Will it speed up waiting times in A&E” and on effectiveness, one participant asked: “If a rare disease occurs, how will the robot know what to do as there is no speciﬁc tre a tment”, another: “How do you train AI if someone develops a new illness” and: “Is an onlin e chat bot actually more beneﬁcial to patients?” The role of human-centred care in healthcare was another emergent theme with empathy, agency and power dynamics considered important. It was thought that AI would not take emotions into acco unt and this could have an impa c t on treatment, especially where mental health and wellb e ing are considered. One participant asked: “How do you teach AI to be empathetic and unde rstand pain?” ano ther: “How would bad news be broken to patients?” Agency and control over th e use of AI was a pertinent topic, one particip ant reﬂecting: “I like the idea of AI looking at scans and in surgery, but deﬁnitely not for decision making or patient interaction”, another asking: “Would AI make the decision or be the advisor to the doctor?” and another: “Would doctors be able to overrule AI if they’re not happy with th e decision/ course of action?” Replacing human s was commo nly associated to the impact on jobs, one participant expressing: “I don’t like the idea of robots taking jobs” and another asked: “What will happen to the doctors who are working now?” expanding to: “will their jobs get replaced?”. Another par ticipant reﬂected on the potential impact on skillset and disparities betwe en countries using AI and others that do not, asking: “Will doctors need to be less qualiﬁed if the use of AI is no rmalised?” A popular remark anticipated the role of AI as supportive rather than to replace healthcare staff, one participant stating : “I will ﬁnd it ok as long as it is just helping and does not replace humans”, The inﬂu ence of movies, games and science ﬁction on perce ptions of AI was a popular topic. Opinions on AI amongst children and you ng people are inﬂuenced by pop culture and science ﬁction, which ofte n depict robots as evil, one participant reﬂectin g: “I thin k we watch too many sci-ﬁ movies”, anothe r “that’s why I’m scared of robots” This le d to comments about creepiness, one participant stating: “AI is creepy if it acts like a huma n” Educational workshops with reassurance, practical examples that use AI to help, but not replace humans were suggested to address common worries, build trust and to effectively communicate about AI. To cultivate trust, it was recommended that healthcare staff are transpar ent about its use, with clear explanations and examples of its use in everyday life (Figure 1d), one par ticipant recommended: “Being transparent when you are already using it e.g., when AI is used in conjunction with surgeons” with “success stories & when things go wrong & how it was reso lved ” . Ethical considerations about who would make decisions and what might happen should something go wrong were considered. One participant stating: “Make sure you address common worries instead of avoiding them when explaining AI”. Overall, participants were interested to engage on further discussions about AI, and a gene rational gap was identiﬁed, that considers young people more open to and comfortable with AI in general. “YPAG members are keen to be involved, for our perspective and ideas, especially as AI is our future”. The ﬁndings of this exploratory workshop, intended to infrom furture research have demonstrated that CYP are openminded to using AI in me dicine and healthcare and believe that this technology w ill chan ge everyday life in fundamental ways but ﬁnd it difﬁcult to articulate their views on how AI should be developed. This is partly due to the breadth of applications and their impacts. CYP need to be educated about AI and enco uraged to participate in its development including making AI explainable to child ren and young people by including them in AI policy development cycles. Outside of healthcare, UNICEF recommends nine requirements for child-cen tred AI, including inclusion, safety, privacy, transparency, and the need to cr eate an enabling environment to discover whether AI systems are designed for children and potential impacts. Whilst participatory research is described as a key elem ent, such policy guidelines are not accompanied by practical recommendations to enable such digital co operation. This is the ﬁrst exploratio n through a virtual, group-based workshop to engage with CYP with lived experienc es of healthcare regarding perceptions of AI in medicine and healthcare. We demonstrate that by creating an open and enabling environment and using design scenarios to discuss potential applications, YPAG members were keen to participate, share opinions, outline concerns, and further develop their own u nderstandin g of AI. By including and involving CYP in this space, we can optimise AI to e nhance future experiences of care. To achieve this sha red aspiration requires collaboration, and where there are areas of disagreement or uncertainty, these need to be clear ly identiﬁed. This involves creating an enabling environment for CYP-centred AI an d involving CYP with lived experiences of healthcare in the process in ways that engage, inspire and empower. The preliminary ﬁndings reported reﬂect a PPEI workshop intended to inform future research and spur deliberations on this topic. Whilst content analysis represents an appropriate analytic approach which is unobtrusive, nonreactive and time-efﬁcient when compared to methods such as ethno graphy, this workshop in its design was lim ited to the breadth of speciﬁc potential AI applications discussed, and by the depth of discussion achieved during a virtual onehour group session. Data saturation was not in te nded to be achieved, rathe r emergent themes identiﬁed to shape future research. Whilst the design of this exploratory workshop allowed for rapid, and well attended virtual p a rticipation, future research approaches might also include supplementary in-depth interviews and consensu s building methods. CYP want to be included in the development of AI in medicine and healthcare. Whilst policy guidelines acknowledge the need to include CYP this ignores the infrastructure required to support ongoing digital cooperation . For AI in medicine, this requires an enabling environment for human-centred AI that involves CYP with lived experiences of healthcare and health c are/AI professionals. With publication of the recent UK National Strategy for AI, futu re research should explore the ways CYP can participate in shaping an intelligent, empathe tic, a nd inclusive hea lthcare system o f tomorrow and in the application and development of AI in healthcare. 1. Coles LS. The application of artiﬁcial intelligence to medicine. Futures. 1977 A ug; 9 (4):315 –23. 2. Chang AC. Intelligence-Based Medicine: Artiﬁcial Intelligenc e and Human Cognition in Clinical Medicine and Healthcare. Academic Press; 2020. 549 p. 3. Hamet P, Tremblay J. Artiﬁcial in te lligence in medicine. Metabo lism. 2017 Apr 1; 69:S36–40. 4. Szolovits P. Artiﬁcial I ntelligence In Medicine. Routledg e; 2019. 255 p. 5. Davendralingam N, Sebire NJ, Arthurs OJ, Shelmerdine SC. Artiﬁcial intelligen ce in paediatric radiology: Future opportunities. Br J Radiol. 2020 Sep 17; 94(11 17):20200975. 6. Liang H, Tsui BY, Ni H, Valentim CCS, Baxter SL, Liu G, et al. Evaluation and accurate diagnoses of pediatric diseases using artiﬁcial intelligence. Nat Med. 2019 Mar; 25(3):433– 8. 7. Sisk BA, Antes AL, Burrous S, DuBois JM. Parental Attitudes toward Artiﬁcial Intelligence-Driven Precision Medicine Technologies in Pediatric Healthcare. Children [Internet]. 2020 Sep 20 [cited 20 21 Apr 29]; 7(9) . Available fr om: 8. Weil 9. WHO | Making health serv ic e s adolescent friendly [Internet]. WHO. World Health Organization; [cited 20 21 Apr 29]. Available fr om: 10. Hargreaves DS, Lemer C, Ewing C, Cornish J, Baker T, Toma K, et al. M e asuring and improving the q uality of NHS care f or children and youn g people. Arch Dis Child. 2019 Ju l; 104 (7):618 –21. 11. Well 12. UNICEF policy guidance on AI for children [Internet]. The Commonwealth. [cited 2021 Jul 18]. Available from: 13. Adolescent perspectives on artiﬁcial intelligence [Inter net]. [cited 2021 Apr 29]. Available from: https://www. un icef.org/globalinsight/stories/adolescent-p erspectives-artiﬁcial-intelligence 14. Artiﬁcial Intelligence fo r Children: Beijing Principles [Internet]. [cited 2021 Jun 10]. Available from: https:// ww w.baai.ac.cn/ai-for-children.html 15. Generation AI 20 20: Health, Wellness and Technology in a Post-COVID World [Internet]. IEEE Transmitter. 2020 [cited 2021 Jun 10]. Available from: https://transmitter.ieee.org/generation-ai-2020/ 16. Mayhew E, Davies M, Millmore A, Thompson L, Bizama AP. The impact of audience response platform Mentimeter on the student and staff learning exper ience. Res Learn Technol [I nternet]. 2020 Oct 30 [cited 2021 Jul 7]; 28. Available from: https://journal.alt.ac. uk/index.php/rlt/article/view/2397 17. Little C. Mentimeter Smartphone Student Response System: A class above clickers. Compass J Learn Teach [Intern e t]. 2016 Nov 8 [cited 2021 Jul 16]; 9(13). Available f rom: https://journals.gre.ac.uk/ind e x.php/compas s/articl e/view/328 18. Tong, Sainsbury P, Craig J. Consolidated criteria f or repo rting qualitative research (COREQ): a 32-item checklist for inte rviews and focus groups. Int J Qual Health Care. 20 07 Dec 1; 19(6):349–57. 19. Cameron D, M aguire K. Public views of machine learning: Digital Na tives. Available from: https://royalsociet y.org/-/media/policy/projects/machine-learning/digital-natives-16-10-2017.pdf 20. Hargreaves DS, Sizmur S, Pitchforth J, Tallett A, Toomey SL, Hopwood B, et al. Children and young p eople’s versus par e nts’ responses in an English national inpatien t survey. Arch Dis Child. 20 18 May; 103(5):486–91. 21. Freire, K & Sangiorgi, D. Ser vice design and healthcare inn ovation: from c onsumption, to co-production to co-creation. 2010. Paper presen te d at Nordic Ser vice Design Confe rence, Linkoping, Swed e n We thank the 21 members of GO SH YPAG for their engagement in this exploratory workshop. This work is supported by the NIHR GOSH BRC. SV, NJS conceived the p roject. DL, DB were involved with arr anging the YPAG meeting and inviting interested YPAG members to engage. SV, NJS led the facilitation of the YPAG session and data collection. DB collected indepen dent observations to triangulate ﬁnd ings. SV conducted the analysis and reported o n ﬁnding s in compliance with the COREQ 32-point ch ecklist, and creating Figure 1. OA represented th e viewpoint of a YPAG member to validate emerging themes, add ref e rence to co-creation, and review the manuscript for la yman language and style. All authors contributed to the validation process, checking for accurate representation of ﬁndings, completeness and provided revisions to early drafts of the manu script. SV acknowledges doctoral funding from Great Ormond Street Hospital for Children charities. Computer Interaction (SV), Profe ssor of Pathology and Chief Research and Informatics Ofﬁcer (CRIO) (NJS) (SV), Professor of Pathology, CRIO and Director of GOSH DRIVE (NJS) ence/ Human Computer I nteraction (SV), Pr ofessor o f Pathology and Chief Research and Informatics Ofﬁcer (CRIO) (NJS) YPAG in th eir role to provide feedback on research and so the participants were familiar with who the facilitators were. tors a nd that SV is condu c ting research on humancentred aspects of tech nology adoptio n. This is an explorator y workshop and did not intend to prove o r disprove a hypothesis, but instead garner perceptions of c hildren and young people to shape future research. sign scenarios involving AI, and Content analysis of 128 short comments or micronarratives. ment Research Lead, NIHR GOSH Biomedical Research Centre ment session comments posted anonymously to an audience response system and in chat functions. NIHR GOSH Biomedical Research Centre (1) , Biomedical Research Centre staff (1), Biomedical Research Centre staff as a note taker for ﬁeld notes (1) age, typ ic ally with lived experiences of healthcar e and members of YPAG, an advisor y group that feeds back on research. months prior to the session and the questions were circulated to the team at GOSH DRIVE the session which were used to cross reference codes and emerging the mes from the data uration was not anticipated available to p articipants, and comments made anonymously on the audience resp onse systems displayed as a rolling grid in real time during the session. ness, governance and trust) Coding tree on NVivo (Figure 2) Melbourne, Australia) ing codes and themes for accuracy and co-author the paper that presented preliminary ﬁndings were not identiﬁed as comments were made anonymously. This was intended to encoura ge open and honest discussions ness, governance and trust)