Nurendra Choudhary nurendra@vt.edu, {nikhilsr, katsumee, ksubbian}@amazon.com, reddy@cs.vt.edu Knowledge Graphs (KGs) are structured heterogeneous graphs where information is organized as triplets of entity pair and the relation between them. This organization provides a ﬂuid schema with applications in several domains including e-commerce [ research [ of ﬁrst-order existential (FOE) queries (translation, intersection, and union) using the KGs’ relation paths. A myriad of queries can be answered using such logical formulation (some examples are given in Figure 1). Current approaches [ representational latent space such that the FOE queries can be reduced to mathematical operations in order to further retrieve the relevant answer entities. Euclidean vectors [ leveraging their neighborhood relations. They utilize a ﬁxed threshold over the vector to query for answer entities (such as a k-nearest neighbor search). However, queries differ in their breadth. Certain queries would lead to a greater set of answers than others, e.g., query higher number of answers than query behavior, spatial embeddings [ 35th Conference on Neural Information Processing Systems (NeurIPS 2021). Logical reasoning over Knowledge Graphs (KGs) is a fundamental technique that can provide efﬁcient querying mechanism over large and incomplete databases. Current approaches employ spatial geometries such as boxes to learn query representations that encompass the answer entities and model the logical operations of projection and intersection. However, their geometry is restrictive and leads to non-smooth strict boundaries, which further results in ambiguous answer entities. Furthermore, previous works propose transformation tricks to handle unions which results in non-closure and, thus, cannot be chained in a stream. In this paper, we propose a Probabilistic Entity Representation Model (PERM) to encode entities as a Multivariate Gaussian density with mean and covariance parameters to capture its semantic position and smooth decision boundary, respectively. Additionally, we also deﬁne the closed logical operations of projection, intersection, and union that can be aggregated using an end-to-end objective function. On the logical query reasoning problem, we demonstrate that the proposed PERM signiﬁcantly outperforms the state-of-the-art methods on various public benchmark KG datasets on standard evaluation metrics. We also evaluate PERM’s competence on a COVID-19 drugrepurposing case study and show that our proposed work is able to recommend drugs with substantially better F1 than current methods. Finally, we demonstrate the working of our PERM’s query answering process through a low-dimensional visualization of the Gaussian representations. 4,5]. Chain reasoning is a fundamental problem in KGs, which involves answering a chain Figure 1: Sample FOE queries from different datasets that utilize existential quantiﬁcation ( intersection ( end-to-end objective function to retrieve relevant results for complex queries. queries by controlling the volume of space enclosed by the query representations. However, these spatial embeddings rely on more complex geometries such as boxes [ form solution to the union operation, e.g., the union of two boxes is not a box. Thus, further FOE operations cannot be applied to the union operation. Additionally, their strict borders lead to some ambiguity in the border case scenarios and a non-smooth distance function, e.g., a point on the border will have a much smaller distance if it is considered to be inside the box than if it is considered to be outside. This challenge also applies to other geometric enclosures such as hyperboloids [8]. Another line of work includes the use of structured geometric regions [ the representations for modeling individual entities and relations between them, we aim to provide a closed form solution to logical queries over KGs using the Gaussian density function which enables chaining the queries together. Another crucial difference in our work is in handling a stream of queries. Previous approaches rely on Disjunctive Normal Form (DNF) transformation which requires the entire query input. In our model, every operation is closed in the Gaussian space and, thus, operations of a large query can be handled individually and aggregated together for the ﬁnal answers. Figure 2: Results of the query probability of being the answers than lighter areas. We can observe from (c) that the non-smooth borders of box geometry do not encompass the answer Hinton. To alleviate the drawbacks of operations not being closed under unions and border ambiguities, we propose Probabilistic Entity Representation Model (PERM). PERM models entities as a mixture of Gaussian densities. Gaussian densities have been previously used in natural language processing [ and graphs [ ∩), and union (∪) operations. The simple operations need to be chained together in an ,15] instead of vector points for representation learning. While these approaches utilize 15] to enable more expressive parameterization of decision boundaries. In our case, we utilize a mixture of multivariate Gaussian densities due to their intuitive closed form solution for translation, intersection, and union operations. In addition, they can also enable the use of a smooth distance function; Mahalanobis distance [ the non-smooth boundaries of box query embeddings are not able to capture certain answers. We utilize the mean ( the semantic position and spatial query area of an entity, respectively. The closed form solution for the operations allows us to solve complex queries by chaining them in a pipeline. PERM does not need to rely on DNF transformations, since all the outputs are closed in the Gaussian space and complex queries can be consolidated in an end-to-end objective function, e.g., in Figure 2b, Europeans ∪ Canadians between the mixture and entity two independent objectives to minimize the distance from each box in the union query. Summarizing, the contributions of our work is as follows: 1.We develop Probabilistic Entity Representation Model (PERM), a method to reason over KGs using (mixture of) Gaussian densities. Gaussians are able to provide a closed form solution to intersection and union, and also a smooth distance function. This enables us to process a chain of complex logical queries in an end-to-end objective function. 2.PERM is able to outperform the current state-of-the-art baselines on logical query reasoning over standard benchmark datasets. Additionally, it is also able to provide better drug recommendations for COVID-19. 3.PERM is also interpretable since the Gaussian embeddings can be visualized after each query process to understand the complete query representation. The rest of the paper is organized as follows: Section 2 presents the current work in the ﬁeld. In section 3, we present PERM and deﬁne its various operations. Section 4 provides the formulation for building the reasoning chains for complex queries. We provide the experimental setup and results in section 5. We conclude our paper in section 6 and present its broader impact in section 7. The topic of multi-hop chain reasoning over KGs has gained a lot of attention in recent years results using a ﬁxed threshold. While such representations are efﬁcient at encoding semantic information, the ﬁxed thresholds that are typically used in these models do not allow for an expressive (adjustable) boundary and, thus, are not best suited for representing queries. Spatial embeddings controls the spatial area around a query representation. These methods have strict borders that rely on non-smooth distance function that creates ambiguity between border cases. On the other hand, in our model, the variance parameter of the query’s Gaussian densities creates soft smoothly increasing borders in terms of the Mahalanobis distance. Additionally, the previous methods do not provide a closed form solution for unions which we solve using Gaussian mixture models. Density-based embeddings have seen a recent surge of interest in various domains. Word2Gauss [14] provides a method of learning Gaussian densities for words from their distributional semantic information. In addition, the authors further apply this work to knowledge graphs [ approach [ methods are, however, focused on learning semantic information and do not easily extend to logical queries over knowledge graphs. PERM primarily focuses on learning spatial Gaussian densities for queries, while also capturing the semantic information. To achieve this, we derive closed form solutions to FOE queries. Knowledge Graphs (KG) (R). Each relation relation r exists between a pair of entities. Without loss of generality, KGs can also be organized as a set of triples µ) and co-variance (Σ) parameters of multivariate Gaussian densities to encode ,6]. These approaches utilize vector spaces to model query representation and retrieve ] enhance the simple vector representations by adding a learnable border parameter that 15] aims to learn Gaussian graph representations from their network connections. These he, r, ei ⊆ G, deﬁned by the Boolean relation functionr(e, e). In this work, we focus on the following three FOE operations: translation (t), intersection ( operations are deﬁned as below: where Q Vare the corresponding results [ part of a query and another as a candidate answer to a query. In PERM, we model the query space of an entity parameters density of the entity, respectively. As a candidate, we only consider the the entity. We deﬁne the distance of a candidate entity e= N (µ Additionally, we need to deﬁne the FOE operations for the proposed Probabilistic Entity Representation Model. A visual interpretation of the operations; translation, intersection, and union is shown in Figure 3. The operations are deﬁned as follows: Translation (t). We deﬁne the translation query representation of an entity resultant entity v Intersection (∩). that belongs to both the densities. Given that the entity densities are independent of each other, we deﬁne the intersection of two entity density functions We provide a brief sketch of the proof that the intersection of Gaussian density functions is a closed operation. A complete proof is provided in Appendix A. Let us consider two Gaussian PDFs P (θ) = N (µ distributed as the product, P (θ Union (∪). density functions given by self-attention mechanism over the parameters of the Gaussians in the mixture, i.e., q[Q] =?V: {v, v, ..., v} ⊆ E ∃ a(1) q[Q] =?V: {v, v, ..., v} ⊆ E ∃ a∩ a∩ ... ∩ a(2) q[Q] =?V: {v, v, ..., v} ⊆ E ∃ a∪ a∪ ... ∪ a(3) q, andqare the translation, intersection, and union queries, respectively; andV,V, and e∈ Eas a multivariate Gaussian density function;e= N (µ, Σ), where the learnable µ(mean) andΣ(covariance) indicate the semantic position and the surrounding query , Σ) using the Mahalanobis distance [16] given by: Each entitye ∈ Eandr ∈ Rare encoded asN (µ, Σ)andN (µ, Σ), respectively. ∈ Vfrom the query as dgiven by: Intuitively, the intersection of two Gaussian densities implies a random variable from the query as dgiven by: q= N (µ, Σ)N (µ, Σ) = N (µ, Σ); d= d(v, q where, Σ= Σ+ Σ , Σ)andP (θ) = N (µ, Σ). Their intersection implies a random variable that is (x − µ)Σ(x − µ) = (x − µ)Σ(x − µ) + (x − µ)Σ(x − µ) Comparing coefﬁcients; Σ= Σ+ Σ; µ= Σ(Σµ+ Σµ) We model the union of multiple entities using Gaussian mixtures. The union of entity from the query as dgiven by: where, φ=exp (N (µ, Σ))PexpN (µ, Σ) are the weights for each Gaussian density in the Gaussian mixture, calculated using the Figure 3: The logical single (top row) and chain operations (bottom row) of translation, intersection, and union in the Gaussian space. The operations are closed and will result in either a Gaussian density or a Gaussian mixture. The input operands are given in blue and red and the resultant Gaussian density/mixture is depicted in purple. For simplicity, the example is given for a univariate Gaussian model, but in our work, we use multivariate Gaussian densities. We consider the Gaussian density function (embedding of a single entity) as a special case of Gaussian mixture with a single component. This ensures that all the operations deﬁned in Section 3 are closed under the Gaussian space with an output that is either a single (for translations and intersections) or multi-component Gaussian mixture (for unions). Hence, for chaining the queries, we need to deﬁne the logical operators with a Gaussian density and a Gaussian mixture input. In this section, we deﬁne the different operators (depicted in Figure 3), in the case of a Gaussian mixture input. Chain Translation.P p = like to translate all the Gaussians in the mixture with the relation. Hence, we model this translation as cand the distance from entities v Chain Intersection. tributive law of sets, an intersection over a Gaussian mixture e = N (µ the mixture. Hence, we derive this intersection as c Chain Union. the addition of the entity to the mixture. Hence, the union (a) Translation (q) N (µ, Σ)and we need to translate it with relationr = N (µ, Σ). Intuitively, we would , Σ)implies the union of the intersection between the entity and each Gaussian density in where, Σ= Σ+ Σand µ= Σ(Σµ+ Σµ) The union of an entitye = N (µ, Σ)with a Gaussian mixturePφN (µ, Σ)is dcan be deﬁned as follows: Implementation Details. popular self-attention mechanism [ and derivation for the product of Gaussians (Eq. 6) are given by [ Another important note is that we do not need to compute need to compute the density of d × (r + 1) (6), we use a linear solver ( in Pytorch [23] and run on four Quadro RTX 8000. This section describes the experimental setup used to analyze the performance of PERM on various tasks with a focus on the following research questions: 1.Does PERM’s query representations perform better than the state-of-the-art baselines on the task of logical reasoning over standard benchmark knowledge graphs? 2. What is the role of individual components in PERM’s overall performance gain? 3.Is PERM able to recommend better therapeutic drugs for COVID-19 from drug re-purposing graph data compared to the current baselines? 4. Are we able to visualize the operations on PERM’s query representations in the latent space? We utilize the following standard benchmark datasets to compare PERM’s performance on the task of reasoning over KGs: • FB15K-237 entity pairs. All the simply invertible relations are removed. • NELL995 Language Learning (NELL) system. • DBPedia over 240,942 articles. • DRKG model on both the logical reasoning and drug recommendation tasks. Table 1: Dataset statistics including the number of unique entities, relations, and edges, along with the splits of dataset triples used in the experiments. Implementation code: https://github.com/Akirato/PERM-GaussianKG https://www.kaggle.com/danofer/dbpedia-classes dvariables requiresd × dparameters forΣ. So, we only store a decomposed matrix : Σ= LL. Thus, for a Gaussian density ofdvariables our memory requirement is parameters (dforµandd × rforΣ). For computing theµfor intersection, in Eq. [24] is comprised of the 149,689 relation triples and textual mentions of Freebase [25] consists of 107,982 triples obtained from the995iteration of the Never-Ending is a subset of the Wikipedia snapshot that consists of a multi-level hierarchical taxonomy [26] (Drug Re-purposing Knowledge Graph) is used to evaluate the performance of our More detailed statistics of these datasets are provided in Table 1. For our experiments, we select the following baselines based on (i) their performance on the logical reasoning task and (ii) their ability to extend to all FOE query combinations. • Graph Query Embedding (GQE) [17] to learn the query embeddings. The distance of the answer entities is calculated using L1-norm. • Query2Box (Q2B) utilize FOE queries to learn query representations. The distance of answer entities is given by a weighted combination of the answer’s distance from the center and the border of the query box. • Beta Query Embedding (BQE) from FOE queries with a novel addition of negation queries. The distance is calculated as the dimension-wise KL divergence between the answer entity and the query beta embedding. • Complex Query Decomposition (CQD) simpler sub-queries and aggregating the resultant scores with t-norms. Some of the other baselines [ intuitively extended to handle all FOE queries, and hence, we did not include them in our study. Table 2: Performance comparison of PERM against the baselines to study the efﬁcacy of the query representations. The columns present the different query structures and the overall average performance. The last row presents the Average Relative Improvement (%) of PERM compared to CQD over all datasets across different query types. Best results for each dataset are shown in bold. The MRR results for experiments are given in Appendix C. To evaluate the efﬁcacy of PERM’s query representations, we compare it against the baselines on different FOE query types; (i) Single Operator: 1 ∩t, t∩, ∪t. We follow the standard evaluation protocol [7, 11, 8] and utilize the three splits of a KG for training DBPedia has an extremely large number of resultant grand-children leaves ( 2t task and, thus, we notice poor performance on 2t task across all the evaluation models. PERM .950 .007N.A. 1.00 1.00 .782 .232 .952 0.00 .615 G, validationG, and evaluationG(details in Table 1). The models are trained G. For the baselines, we calculate the relevance of the answer entities to the queries based on the distance measures proposed in their respective papers. In PERM, the distance of the answer entity from the query Gaussian density is computed according to the measures discussed in Sections 3 and 4. We use the evaluation metrics of HITS@K and MRR to compare the ranked set of results obtained from different models. Given the ground truth are calculated as follows: From the results provided in Table 2, we observe that PERM, is able to outperform all the current state-of-the-art approaches, on an average across all FOE queries by consistent improvement for union queries; Comparing the models based on only geometries, we notice the clear efﬁcacy of PERM query representations with an average improvement of boxes (Q2B), and beta distribution (BQE), respectively. Given these improvements and the ability to handle compound queries in an end-to-end manner, we conclude that Gaussian distributions are better at learning query representations for FOE reasoning over KGs. Additionally, we provide PERM’s results on sample queries from different datasets in Table 3. Table 3: Qualitative results of PERM on samples from different datasets. Results given in green and red indicate a correct and incorrect prediction, respectively. Who are European and Canadian Turing awards winners? Which Actors and Football Players also became Governors? Which treatment drugs interact with all proteins associated with SARS diseases? In this section, we evaluate the need for different components and their effects on the overall performance of our model. First, we look at the contribution of utilizing different types of queries to the performance of our model. For this, we train our model on different subsets of queries; (i) only 1 of Gaussian mixtures. We test other methods of aggregation; (i) vanilla averaging and (ii) MLP [ Table 4: Ablation study results. Performance comparison of PERM (ﬁnal) against different variants of our model. 1t, translation and single utilize the 1-hop queries, all translation queries and all single operator queries, respectively. The average and MLP variants utilize vanilla averaging and MLP for aggregation in union queries. The metrics reported here are an average over all the datasets. Finer evaluation with results for each dataset is given in Appendix D. Best results are given in bold. PERM-translation .649 .182 .179 .463 .535 .479 .128 .308 .143 .341 From Table 4, we notice that utilizing only 1 model by with validation onG. The ﬁnal evaluation metrics for comparison are calculated on tqueries, (ii) only translation (1t,2t,3t) queries and (iii) only single operator queries 2∩,3∩,2∪). Furthermore, we look at the need for attentive aggregation in the case of union 22.3%and even increasing the scope to all translation queries is still lower in performance by12.5% comparable performance to the ﬁnal PERM model. But, given the better overall performance, we utilize all the queries in our ﬁnal model. For union aggregation, we observe that attention has a clear advantage and both vanilla averaging and MLP lead to a lower performance by respectively. Thus, we adopt self-attention in our ﬁnal model. In this experiment, we utilize the expressive power of PERM’s query representations to recommend therapeutic drugs for COVID-19 from the DRKG dataset. Drugs in the dataset are already approved for other diseases and the aim is to utilize the drug-protein-disease networks and employ them towards treating COVID-19. This can potentially reduce both the drug development time and cost [ this experiment, we utilize the treatment relation in DRKG and retrieve drugs whereX limited set of entity types (only SARS diseases and drugs) and relation types (only treatments), we only consider the DRKG subgraph that contains this necessary set of entities and relations for learning the representations. We compare the recommendations of different models against a set of actual candidates currently in trials for COVID-19. We use the top-10 recommendations with the evaluation metrics of precision, recall, and F1-score for comparison. Table 5: Performance comparison of various models on the COVID-19 drug recommendation problem using precision (P), recall (R), and F1-score (F1) metrics. The top three drugs recommended by the models are given in the last column. The recommendations given in green and red indicate correct and incorrect predictions, respectively. The last two rows provide the average relative improvement of PERM compared to the state-of-the-art baselines Q2B and CQD. We can observe from Table 5 that PERM is able to provide the best drug recommendations, across all evaluation metrics. Our model is able to outperform the current methods by atleast 8.2%in precision, recall, and F1, respectively. Also, the top recommended drugs by our PERM are more inline with the current drug development candidates, thus, showing the better performance of our model’s query representations. To visualize the entity and query in the latent space, we extract representative entity samples from the FB15K-237 dataset and present them in a 2-dimensional space for better comprehension. Figure 4 depicts the different entities and the mechanism through which PERM narrows down to the particular answer set. Notice that, we are able to perform an intersection after a union operation due to the closed form nature of our operations. This is currently not possible in state-of-the-art baseline methods. Additionally, it should be noted that, unions widen the query space and intersections narrow them down (as expected). Furthermore, the variance parameter acts as a control over the spatial area that an entity should cover and more general entities such as larger area than their respective sub-categories, namely, winners and Europeans. In this paper, we present Probabilistic Entity Representation Model (PERM), a model to learn query representations for chain reasoning over knowledge graphs. We show the representational for this case. However, we notice that training on all single operator queries results in is a set of SARS diseases related to the COVID-19 virus. Given that we only need these (a) Query processing in PERM. This ﬁgure depicts a univariate version of the entity Gaussian embeddings for better visualization of the process. The same property, however, generalizes over an increased number of dimensions, i.e., multivariate case. Figure 4: An illustration of the ﬂow for a sample complex query in the representational space. We note that intersection after union is possible in our PERM model because the operations are closed in Gaussian distributions and this is not possible in current methods including BQE, Q2B, and CQD. power of PERM by deﬁning closed form solutions to FOE queries and their chains. Additionally, we also demonstrate its superior performance compared to its state-of-the-art counterparts on the problems of reasoning over KGs and drug recommendation for COVID-19 from the DRKG dataset. Furthermore, we exhibit its interpretability by depicting the representational space through a sample query processing pipeline. PERM is the ﬁrst method that models an individual entity in knowledge graphs using Gaussian density function, making it possible to solve FOE queries using a closed form solution. This enables its application in domains that require chain reasoning. The main idea of the proposed solution can also be extended to any domain that can encode its basic units as Gaussians and extend the units through FOE queries, e.g., in topic modeling, topics can be encoded as Gaussians and documents as union of topics. However, PERM depends on the integrity of the knowledge graph used for training. Any malicious attacks/errors [ the conﬁdence of our model. Furthermore, due to the connected nature of complex queries, this attack could propagate and affect a larger set of queries. Such incorrect results would be problematic in sensitive areas of research such as drug recommendations and cybersecurity and, thus, it is necessary to maintain the integrity of training data before learning representations and querying with PERM. 30,31] that lead to incorrect relations could, further, lead to incorrect results and affect