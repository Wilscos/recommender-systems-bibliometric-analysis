 on their data; data received from users’ experience using the app such as searching the songs they like. There are lots of current technological advancements in AI due to the competition between music platform owners such as Spotify, Pandora, and more. In this paper, 6 machine learning algorithms and their individual accuracy for predicting whether a user will like a song are explored across 3 different platforms including Weka, SKLearn, and Orange. The algorithms explored include Logistic Regression, Naive Bayes, Sequential Minimal Optimization (SMO), Multilayer Perceptron (Neural Network), Nearest Neighbor, and Random Forest. With the analysis of the specific characteristics of each song provided by the Spotify API [1], Random Forest is the most successful algorithm for predicting whether a user will like a song with an accuracy of 84%. This is higher than the accuracy of 82.72% found by Mungekar using the Random Forest technique and slightly different characteristics of a song [2]. The characteristics in Mungekar’s Random Forest algorithm focus more on the artist and popularity rather than the sonic features of the songs. Removing the popularity aspect and focusing purely on the sonic qualities improve the accuracy of recommendations. Finally, this paper shows how song prediction can be accomplished without any monetary investments, and thus, inspires an idea of what amazing results can be accomplished with full financial research. especially applies to music. Music has been present for a long time, way before even the thought of computers, algorithms, and Artificial Intelligence. It is worth explaining the diversity of music in different cultures because the idea of different characteristics of a song is a crucial factor of our algorithm in finding the similarity between songs the user likes, compiling them into the same playlist, and suggesting them to the user [3]. Nowadays, fortunately, every piece of music is available online on different platforms such as Spotify, Pandora, Apple Music, and YouTube. Therefore, finding the most efficient way to determine whether a user will like certain songs is crucial for a music recommendation system. Some systems focus on looking at other users’ likes and dislikes, while other systems look at the characteristics of the song itself [4]. appearances, but also the algorithms that make the final predictions in song recommendations to the users [5]. Better recommendations create a bigger appeal for users to choose one platform over another. These platforms are ravenous for more users because that’s their way of income. These music streaming platforms run lots of commercials and advertisements and more users mean the platform can charge a higher rate to the companies paying for them. Additionally, there are paid subscription options offered in most services to bypass the ads, so the platform makes money more directly. As a result, to strive for better recommendations [6], these platforms are investing in research for better accuracy and outcomes. recommendations can be used. For example, according to Gironacci, Professor at the University of Technology in Australia, AI is used in TV streaming platforms (Netflix, YouTube, etc.), news feeds (CNN, etc.), shopping platforms (Amazon, eBay, etc.), and more [7][8]. incorporated into our research. These ideas include songs analysis, the effect of music, human nature, AI application, etc. Abstract— Artificial Intelligence (AI ) has been very successful in creating and predicting music playlists for online users based We live in the twenty-first century where everything is moving online— easily accessible, anywhere, and at any time. This As previously mentioned, different music platforms are in a big competition to improve not only the app features and AI and Deep Learning are commonly used in music recommendation systems, but music is not the only place where AI In this section, the ideas from the Introduction section are researched more in-depth and explained how those ideas can be A. Filtering Types combination of the two [9]. Collaborative filtering is when recommendations are based on the likes of other users with common interests. For example, if user 1 and user 2 both like the same song, the recommendation system might recommend another song that user 1 likes but user 2 has not heard, to user 2. The effectiveness of collaborative filtering is highly debated within the field. Some scholars such as van den Oord, argue it is ineffective, while others, like Knees, believe it is highly successful [10] [11]. Context-based filtering looks at the attributes, such as lyrics, tempo, etc. of a song and sees how it compares to the same attributes of songs the user likes [12]. Scholars of the field tend to agree that a combination of the two filtering methods provides the most accurate recommendation, although this particular music recommendation project focuses on context-based filtering only. B. Adaptive Personalized Playlists: Advantages, Limitations, Challenges the background to base suggestions on, and tastes change. Humans are not machines. People’s music preferences depend on their mood, location, and activity. Some recommendation systems cope with this by trying to take in environmental factors of the user into the algorithm, while some simply attempt transitional songs. Recommendation systems also perform differently for people with certain personality traits. According to Melchiorre and team, music recommendation systems perform better for people with high levels of neuroticism and agreeableness [13]. Author Prey suggests there is no individuality possible in these recommendation systems, only ‘algorithmic individuation’ [14]. people based on their race, gender, or other factors [15]. Authors Porcaro, Castillo, and Gomez suggest all AIs recommending music should meet a certain diversity requirement before being widely accepted [16]. The systems most frequently used today are heavily rooted in the western ideal of music. Recommendation systems do not always collect the most accurate information either. According to Lupker and Turkel, Spotify’s value for mode was accurate only 18% of the time, and key a mere 2% [17]. More accurate contextual analysis through music theory could lead to better recommendations. on their earnings according to O’Dair and Fry [18]. Collaborative filtering especially frequently leads to systems ignoring a lot of possibly recommendable songs because they are not as widely known. The audio features of a track can sometimes indicate how well it will perform, with tracks that consist of higher energy and valence generally performing better, but trends change and songs don’t always get the chance to get out to the public [19]. This creates the problem of a trade-off between relevance, fairness, and satisfaction of users and musicians. C. Machine Learning and AI Techniques algorithms. For collaborative filtering, Pichl’s team used a machine learning library called Mahout to compare the similarity of two users and recommend a song based on their history [5]. Other scholars used the SVD algorithm, which is a matrix that helps narrow down relevant data and recommendations [20]. When it comes to context-based filtering, there are many, arguably simpler, techniques to implement. The Naive Bayes model looks at the probability of each song being liked when comparing values of the attributes. The nearest neighbor method finds the training song with the most similar attributes and assigns the “liked” value of the test song based on that. Decision Trees continuously find the category that is best at predicting the outcome and build a path to follow for assigning “liked” or “disliked” to each song. can be difficult to implement because of the lack of multimodal datasets and the lack of knowledge about playlist properties [21]. Authors Wang and Wang suggest combining the two steps of feature extraction and recommendation into one step using a technique called deep belief networks [22]. This significantly improved the performance of music recommendation systems in their study. Deep belief networks consist of intertwined, connected layers and the combination of an unsupervised learning pre-training stage with a supervised learning training stage. similar song might give the most short-term benefit, a reinforcement learning algorithm tries to maximize long-term benefit. This involves recommending transitional songs, which greatly improve the performance of the recommendation system overall [23][24]. Sequential Minimal Optimization (SMO), Multilayer Perceptron (Neural Network), Nearest Neighbor, and Random Forest, to predict whether an individual will like or dislike a song. Each algorithm is run four times to create four models, one for each individual. The input for each model consists of a file for each individual with a list of between 100 and 150 songs and numerical values of the song characteristics as determined by the Spotify API, as well as a binary variable indicating whether a user liked a song or not. The exact number of data points varied between users because each user put a different number of songs on their playlists. The characteristics include Acousticness, Danceability, Energy, Instrumentalness, Key, Liveness, Loudness, Mode, Speechiness, Tempo, Time-Signature, and Valence, described in Table I [1]. Each model is built and run using stratified cross-validation with 10 folds. Each algorithm is run using 3 different machine learning libraries, SKLearn, Orange, and Weka. The output consists of the percentage of songs that were correctly predicted by the model. B. Data Collection between 50-75 disliked songs. The exact length of the playlists varied by user. The Spotify API was used to extract the characteristics of the songs in the playlists. A description of these characteristics can be found in Table I. The song characteristics for each playlist were formatted into a .txt file and the binary “liked” variable was added accordingly. The “liked” songs file and “disliked” songs files were run through code that calculated the means for each characteristic. The results are shown in Table II. These two files were then combined into a single .txt file for each user, which created a complete dataset. These .txt files were converted as needed to the formats required by each data processing platform. Multilayer Perceptron (Neural Network), Nearest Neighbor, and Random Forest. These algorithms were chosen due to their classificatory nature and relative popularity within machine learning. Each of these algorithms were run on the machine learning platforms using the default parameter settings given by the platform. D. Data Processing Platforms algorithms on three different open source processing platforms. The first platform, Weka, is a visualization software, which only requires .arff file inputs and classification selections within the program to begin analysis. The second platform, SKLearn, is a Python library, so code had to be written to run the data through each of the 6 algorithms. Similar to Weka, Orange is a visualization software requiring only a file input, but the data needed to be in .tab format. This was a quick conversion that only required saving the .txt file as a new type. Neither Weka or Orange needed separate code to run the algorithms. Both platforms have drop-down menus to choose the algorithm type, and a run button to process the data. E. Overfitting automatically implements a stratified k-fold cross-validation of size 10. This separates the data into 10 smaller sections, runs the algorithm on each section and retains the evaluation score. The final performance is the result of the entire dataset being run through the model with the highest evaluation score for that algorithm. Splitting the data into even smaller sections allows the model to not be trained on all of the data, and therefore can predict new instances. To regain consistency, this same cross-validation technique was chosen for SKLearn and Orange as well. F. Fine Tuning the Best Model (Optimization) Random Forest had the highest average accuracy rating, and SKLearn’s implementation of that algorithm was the most successful from the three platforms, so that version was fine-tuned by adjusting the parameters provided in the code. To optimize, an SKLearn optimization function called BayesSearchCV was used to determine the best parameters to adjust. BayesSearchCV is an optimization method that uses hyper parameters and a “fit” and “score” method to make predictions on which parameters would be the best to use. They do this by testing training data and actual data and returning the parameter grouping that resulted in the best outcomes [30]. This function allows every parameter to be tested at once (even the optional and universal ones), outputting the best score and best parameter decisions. BayesSearchCV function example: opt = BayesSearchCV( RandomForestClassifier(), 'n_estimators': [1,10,75,100,200,1000], 'criterion': ['gini', 'entropy'], 'max_depth': [1,10,100,1000,10000000000], # integer valued parameter algorithm. The second highest average accuracy rating was Naive Bayes at 80%. The average accuracy for each algorithm is shown in Table III. The performance of the most accurate algorithm, Random Forest, is shown in Figure 1. rating out of the three platforms with only 70% of instances correctly predicted. The highest performing platform was Weka, with an average accuracy of 79%. This is shown in Figure 2. 'min_samples_split': [2,20,50,100], # categorical parameter 'min_samples_leaf': [1,2,3,4,5,6,7,8], 'min_weight_fraction_leaf':[0.0,0.25,0.5], 'max_features': ['auto','sqrt','log2'], 'max_leaf_nodes':[2,5,10,20,50,100], 'min_impurity_decrease':(1e-6, 1e+6, 'log-uniform'), 'bootstrap':[True,False], 'random_state':(0,10), 'verbose':(0,10), 'warm_start':[True,False], 'ccp_alpha':(1e-6, 1e+6, 'log-uniform'), n_iter=32, cv=kf1 opt.fit(X_train, y_train) print("val. score: %s" % opt.best_score_) print("test score: %s" % opt.score(X_test, y_test)) print("best params: %s" % str(opt.best_params_)) However, all attempts at optimizing the model returned an average accuracy of 79%, where the default SKLearn implementation of Random Forest gave an average of 84%. This proves that the optimized model is the original model with the default parameters. The average accuracy level across platforms for the Random Forest algorithm was 83%, making it the most successful Although SKLearn had the top 2 highest average performances of individual algorithms, it had the lowest average accuracy Sequential Minimal Optimization, and Orange’s Multilayer Perceptron (Neural Network), all with an average accuracy of between 83%-85%. All five of these algorithms using the context-based sonic features were an improvement on the 82.72% accuracy found by Mungekar’s Random Forest Algorithm [2]. This can be seen in Table IV. The performance of each of the platforms can also be seen in Figure 3. individual’s data averaged between algorithms. Similarly, SKLearn also had the lowest accuracy for each individual’s data averaged between algorithms. One individual’s data had the highest performance ratings across all algorithms and platforms other than SKLearn’s Sequential Minimal Optimization, for an average accuracy of 86%. Opposingly, one individual’s data had the lowest performance ratings across all algorithms and platforms with an average accuracy of only 62%. The poor performance for user 2 was due to the wide taste in genres for both “liked” and “disliked” songs. Table IV shows the performance of each algorithm on each platform for each individual, as well as average accuracy ratings. would like a song or not, with an average accuracy of 84%, although individual performances ranged from 72% to 90%. This is an improvement on the 82.72% accuracy found by Mungekar [2]. It should be noted that those individuals who had larger distinctions between “liked” and “disliked” averages as shown in Table 2 saw notably better performance of the algorithms. If an individual only The top algorithm performances were SKLearn’s Naive Bayes, SKLearn’s Random Forest, Weka’s Random Forest, Orange’s Not only did Weka have the highest average accuracy of the platforms, Weka also had the highest accuracy for each For this dataset, SKLearn’s Random Forest algorithm had the best average performance when predicting whether a user has one or two similar genres of music that they enjoy, the algorithm will be better at predicting if they will like the song. On the other hand, a broader taste in music will make it more challenging for the algorithm to perform well. popularity, leveling the playing field for new artists to get their music out into the population. Because Spotify’s API is based on western music customs and likes, this approach to music recommendation is not all encompassing, but shows promising results for future research. same area. Although they each had individual music preferences, further research should be done with more users with more diversity between them, and larger “liked” and “disliked” playlists for more accurate results. Different epochs for training and testing could also be used. An additional pro of this purely context-based approach: it does not take into account an artist or song’s newness or Due to time constraints, the scope of this project was limited to testing algorithms on four similarly-aged people living in the