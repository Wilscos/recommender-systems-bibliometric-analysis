Noname manuscript No. (will be inserted by the editor) Abstract Machine Learning (ML) can substantially improve the eﬃciency and eﬀectiveness of organizations and is widely used for diﬀerent purposes within Software Engineering. However, the selection and implementation of ML techniques rely almost exclusively on accuracy criteria. Thus, for organizations wishing to realize the beneﬁts of ML investments, this narrow approach ignores crucial considerations around the anticipated costs of the ML activities across the ML lifecycle, while failing to account for the beneﬁts that are likely to accrue from the proposed activity. We present ﬁndings for an approach that addresses this gap by enhancing the accuracy criterion with return on investment (ROI) considerations. Speciﬁcally, we analyze the performance of the two state-of-the-art ML techniques: Random Forest and Bidirectional Encoder Representations from Transformers (BERT), based on accuracy and ROI for two publicly available data sets. Speciﬁcally, we compare decision-making on requirements dependency extraction (i) exclusively based on accuracy and (ii) extended to include ROI analysis. As a result, we propose recommendations for selecting ML classiﬁcation techniques based on the degree of training data used. Our ﬁndings indicate that considering ROI as additional criteria can drastically inﬂuence ML selection when compared to decisions based on accuracy as the sole criterion. Keywords Machine Learning · Return on Investment · Accuracy · BERT · Random Forest Machine Learning (ML) includes methods, tools, and techniques for inferring models from data and has provided successful applications of classiﬁcation and prediction algorithms. In the area of software development and evolution, a recent study [1] revealed that there is a spectrum of applications of ML across the software development life-cycle, with most of the applications belonging to the category of Quality Assurance and Analytics. There exists an extensive variety of ML algorithms and this pool is growing steadily. A recent study [1] listed Decision Trees, Naive Bayes, and Random Forrest as the techniques most frequently applied in Software Engineering. However, it is important to determine which algorithm works well for a given problem and which are less eﬀective. The performance of any ML technique is generally measured in terms of accuracy (or similar measures). However, the success of ML does not only depend on the algorithms used because ML is a process with various interdependent steps and the investments made in this process need to be related to the return gained from its results. This paper puts estimating the return-on-investment (ROI) of ML in the spotlight. ROI is most widely used in the context of business analysis, which we extend to ML classiﬁcation problems. In particular, we focus on the decisionmaking of ML method selection, i.e., to determine when to stop the process and how much additional investment is needed to achieve a target goal (result). The most important prerequisite for generating accurate ML models is high-quality training data, however securing such data is often an arduous task. Additionally, engineering and selecting appropriate features is especially time-consuming and requires a vast amount of eﬀort and resources [2]. The beneﬁts gained from the application of ML can be dramatically oﬀset due to data collection and data pre-processing activities, which incur substantial costs and eﬀort. ROI is of great interest in engineering and business, where it is widely used as a guide for decision-making. This is true in Software Engineering (SE) as well. For example, Silverio et al. [3] evaluated cost-beneﬁt analysis for the adoption of software reference architectures for optimizing architectural decision-making. Cleland et al. [4] studied the ROI of heterogeneous solutions for the improvement of requirements traceability. However, the recent data explosion in the form of big data and advances in Machine Learning (ML) have posed questions on the eﬃciency and eﬀectiveness of these processes that have become more relevant. In this paper, we present two empirical studies from the ﬁeld of requirements engineering. While it serves as one sample topic for a broader problem, Requirements Dependency Classiﬁcation (RDC) has been a topic of interest for both researchers and practitioners. In particular, we study a ﬁne-tuned BERT (Bidirectional Encoder Representations from Transformers) [5], a recent technique published by researchers from Google, with Random Forest for solving RDC. BERT uses bidirectional training of transformer, a popular attention model, to language modelling, which claims to be state-of-the-art for NLP tasks. We compare BERT with Random Forest (RF), a widely used ML technique that serves as a baseline for comparison. The objective of this study is to present an alternative method to evaluate ML algorithms. In that sense, we demonstrate the perspective of the returns ML algorithms would generate for the investment done while choosing a particular method for a given problem. Our research contributions are as follows – Describe an ML process model for ML classiﬁcation and perform related ROI modeling. – Empirically evaluate Random Forest and ﬁne-tuned BERT for textual classiﬁcation in the context of requirement dependency classiﬁcation (RDC) using accuracy and ROI. The remainder of the paper is structured as follows: Section 2 provides a motivating example of this study, followed by the description of related work in Section 3. Section 4 explains requirement dependency, its extraction, practical relevance, and research questions. Section 5 elaborates our ROI modeling of the ML process. Data used in this study are detailed in Section 6 followed by empirical results in Section 7. The discussion Section 8 details implications and limitations of this study before summarizing conclusions in Section 9. Figure 1 shows a prototypical ROI curve for technology investment [6]. When trying to achieve better results, the investment’s cost (or eﬀort) is growing over time, typically non-linearly. However, the beneﬁt achieved from that investment eventually reaches some saturation point beyond which almost no further improvement is achieved. In total, a saturation point is achieved, after which further investment does not pay oﬀ anymore (i.e., point of diminishing returns). Thus, the most crucial question arises-Do similar arguments apply for ML classiﬁcation in Software Engineering? While this could be true in general, we study it in the context of the requirements dependency classiﬁcation problem. Deshpande et al. [7] report the results of a recent survey for requirements dependency classiﬁcation and maintenance, with 76% of responses (out of 70) from practitioners. More than 80% of the participants agreed or strongly agreed that dependency type classiﬁcation is diﬃcult in practice; dependency information has implications for maintenance, and ignoring dependencies has a signiﬁcant impact on project success [7]. Applying the advanced NLP technique BERT, we performed an ROI analysis on the requirements dependency classiﬁcation. Automating this process saves time, and making the classiﬁcation more eﬀective helps better align the development process with the existing dependencies. For example, if a requirement r depends on another requirement s, then the implementation of s should precede implementing r. Violating this logical dependency will not only delay the usage of r but also decrease the eﬀectiveness of testing. Fig. 2: ROI vs F1 of BERT for Firefox dataset [8] Figure 2 shows that there is an early peak in the ROI of using BERT. Since it is a very data-intensive technique, the ROI goes down with increasing training set size before the ROI reaches the global maximum. By comparison, considering only the harmonic mean (F1) of precision and recall gives a diﬀerent recommendation for training set size. We discuss this in detail in Section 3 Related Work Although ROI is used in various contexts in Software Engineering and Data analytics, we discuss noted ﬁndings from the literature in the context of our proposed research. 3.1 Exploration of ROI in Software Engineering Farbey et al. [9] explained that as a product moves through its life cycle, various evaluation methods such as ROI, Multi-Objective multi-criteria, Value analysis etc. play an important role in decision making. In this study, ROI was recommended either as a strategy to decrease uncertainty in the business area or to improve knowledge of how technology would operate. Khoshgoftaar et al. [10] presented an interesting case study of a large telecommunication software system and demonstrated a methodology for cost-beneﬁt analysis of a software quality classiﬁcation model. The cost and beneﬁt computations were based on the typeI (FP) and type-II (FN) values of classiﬁcation models. Although these cost-beneﬁt models were ahead of their time, they did not consider the time and eﬀort investment done on data and metrics gathering for cost computation. In another study on calculating ROI in the software product line, Bockle et al. [11] derived cost and beneﬁt estimates based on organization level criteria, such as cost to the organization and cost of reuse. However, this did not involve data analytics of any form. The guesswork could be eliminated from the decision-making process while evaluating the proﬁtability of expenditure, which could help measure success over time. For instance, Erdogmus et al. [12] analyzed the ROI of quality investment to bring its value into perspective; posed an important question, "We generally want to increase a software product’s quality because ﬁxing existing software takes valuable time away from developing new software. But how much investment in software quality is desirable? When should we invest, and where?", which we think is diﬃcult to quantify yet crucial for the success of software-based products. Begel & Zimmermann [13] gathered and listed a set of 145 questions in a survey of 200 Microsoft developers and testers and termed them relevant for DA at Microsoft. One of the questions: "How important is it to have a software DA team answer this question?", expected answer on a ﬁve-point scale (Essential to I don’t understand). Although this analysis provides a sneak peek of the development and testing environments of Microsoft, it does not provide emphasis on any form of ROI. Essentially, we speculate that the ROI aspect was softened into asking for the perceived subjective importance through this question. Boehm et al. [14] [15] presented quantitative results on the ROI of Systems Engineering based on the analysis of the 161 software projects in the COCOMO II database. Ruhe and Nayebi [16] proposed the Analytics Design Sheet as a means to sketch the skeleton of the main components of the DA process. The four-quadrant template provides direction to brainstorm candidate DA methods and techniques in response to the problem statement and the available data. In its nature, the sheet is qualitative, while ROI analysis goes further and adds a quantitative perspective for outlining DA. Ling et al. [17] proposed a system to predict the escalation risk of current defect reports for maximum return on investment (ROI), based on mining historic defect report data from an online repository. ROI was computed by estimating the cost of not correcting an escalated defect (false negative) to be seven times the cost of correcting a non-escalated defect (false positive). Ferrari et al. [18] studied the ROI for text mining and showed that it not only has a tangible impact in terms of ROI but also intangible beneﬁts, which arise from the investment in the knowledge management solution. This solution translates the returns directly that must be considered while integrating the ﬁnancial perspective of analysis with the non-ﬁnancial ones. Weiss et al. [19] emphasized how the quality of external data inﬂuence the results and quantiﬁed the effort of gathering and using such data when it is available at a premium into cost in terms of CPU time, even though the treatment of the subject is limited to a static setting. In a similar vein, Nagrecha et al. [20] proposed a Net Present Value model to determine the cost and impact of analytics programs for an organization. Taking inspiration from these studies in our research, we not only consider data pre-processing costs as an additional cost aspect but also transform machine learning metrics to dollar amounts, with derived costs and beneﬁts being also validated by industry experts. Requirements dependencies classiﬁcation is an active ﬁeld of SE research. The practical importance of the topic was conﬁrmed by a survey [7] of over 90 participants from the SE industry. Results showed that more than 80% of the participants agreed or strongly agreed that (i) dependency type extraction is diﬃcult in practice, (ii) dependency information has implications on maintenance, and (iii) ignoring dependencies has a signiﬁcant negative impact on project success. Several empirical studies have explored diverse computational methods that used natural language processing (NLP) [21] [22], semi-supervised technique [23], hybrid techniques [24] and deep learning [25] in this context. Recently, Wang et al. [26] explored a semiautomatic ML approach based on traceability to identify requirement dependencies to further identify security vulnerabilities. However, none of the approaches considered ROI to decide among techniques and the depth and breadth of their execution level. 3.4 Exploration of Machine Learning process in Software Engineering We analyzed 96 papers from IEEE, Scopus, ScienceDirect, and ACM Digital Library which exclusively used ML, and data analytics within software engineering, and software development domains. Precision, Recall, Accuracy, and AUC were by far the most common performance measures used by researchers in these papers. Additionally, the choice of performance measure was generally not justiﬁed. Most studies did not present all steps of the ML process, and most of the papers formally present only 3 steps of the ML process such as data pre-processing, evaluation, and parameter tuning and all these steps are underestimated in terms of eﬀort spent. This study highlights the merits of simultaneously considering technical and business criteria when evaluating tradeoﬀs faced within machine learning approaches for requirements dependency classiﬁcation (RDC). We extend prior work that focused on comparing various ML techniques based upon technical criteria of accuracy to include broader consideration of the impact i.e. Evaluating value generated by the analysis compared to the costs incurred for the analysis. Similar to requirements elicitation [27], extraction of requirements dependencies is a cognitively diﬃcult problem. These dependencies not only inﬂuence the development of software but also impact how requirements operate. In this section, we provide the formal problem deﬁnition which serves as an example to demonstrate the value of looking beyond accuracy measure and investing in more general concepts of ROI analysis. Figure 3 is an illustration of the practical relevance of considering requirements dependencies for incremental and iterative software development. Having multiple release cycles: R, R, Rdeﬁnes the order of implementing and testing new or updated features. However, if a requirement is implemented in a release Rbut requires a requirement implemented in a later release, then the requirement will not be usable. Similar arguments hold for two requirements that are related to each other but are implemented in diﬀerent releases. Thus, identifying the dependencies early on is crucial as it drives the implementation as well as testing and rework eﬀorts immensely. While there are diﬀerent types of dependencies between requirements [28], [29] we provide the deﬁnitions just for the ones used in the empirical study . For a set of requirements R and a pair of requirements (r, s)  R× R 1) Two requirements r, s are called INDEPEN- DENT if handling one of them has no logical or practical implication for handling the other one. Otherwise, they are called DEPENDENT . 2) REQUIRES is a form of DEPENDENT relationship. If requirement r requires the requirement s to be implemented, then, r and s are in a REQUIRES relationship. REQUIRES is an asymmetric relationship. 3) RELATES_TO is another speciﬁc form of DE- PENDENT relationship. Requirement r relates_to requirement s if changing one of them has an impact on the other. RELATES_TO is a symmetric relationship. Problem: Binary Requirements Dependency Classiﬁcation (RDC) For a given set R of requirements and their textual description, the binary Requirements Dependency Classiﬁcation problem (RDC) is to decide for a given pair (r,s)  R × R if (r,s) is in a REQUIRES (called problem RDC_1) or in a RELATES_TO (called problem RDC_2) relationship. In this paper, two research questions (RQs) are addressed: RQ1: How to model the ROI for ML classiﬁcation? Speciﬁcally, how to instantiate the model for the problem of RDC? Rational: The exclusive consideration of accuracy in the selection of ML classiﬁcation techniques might be misleading. We consider ROI as an alternative and additional criterion. To study the cost and beneﬁt of the ML classiﬁcation in a speciﬁc context, it is essential to consider the complete process of ML classiﬁcation and the impact of the results in the original problem space. RQ2: For RDC, how is the preference decision between RDC-BERT and RF impacted by the accuracy criteria F1 that includes ROI? Rational: We evaluate the impact of the selection criteria through two empirical studies on two opensource software (OSS) datasets: Firefox, a software application from Mozilla family [30] and Typo3 [31], a content management software. Our goal is to evaluate two extraction techniques (RDC-BERT and RF) to demonstrate the impact of the consideration of ROI in addition to accuracy considerations. 5 ROI Modeling of ML Classiﬁcation - RQ1 Machine Learning classiﬁcation is an iterative process comprising a series of steps. Aiming at ROI analysis of ML classiﬁcation requires a look at the eﬀort consumed for all these steps. In what follows, we describe various ML process steps, we estimate cost and beneﬁt, and project the ROI of ML classiﬁcation. Although various ML workﬂow has been deﬁned in the literature [32] [33] [34], in this section, we present the simpliﬁed version of it mainly focusing on the ML process. The process steps are organized into four Phases: A, B, C, and D called Planning, Data Preparation, Execution, and Validation, respectively. Depending on the context, the eﬀort allocated for these steps may vary. However, this approach parallels the process steps and guidelines for pragmatic optimization in software engineering by Ruhe et al. [6]. An overview of the steps is illustrated in Figure 4. Here, we did not show all the possible arrows to indicate that loops can, and do, occur between any two steps in the process. The iterative and interactive ML process, involving various phases is summarized as: Step 1: Scoping and problem formulation Scoping deﬁnes the problem context and its boundaries. Problem formulation addresses the key independent and dependent attributes to be considered. As a result of later steps, the problem formulation eventually needs to be adjusted as asking the right question constitutes the largest eﬀort for any application eﬀort. Step 2: Evaluation of candidate machine learners A variety of ML algorithms exist and new ones are discovered regularly. Commonly used machine learning algorithms include Linear Regression, Logistic Regression, Decision Trees, K-means, Support Vector Machines, Naïve Bayes, Random Forest, and Neural Networks. There is no obvious preference in the sense that "One size ﬁts all". However, there could be recommendations for a particular ML algorithm for a given problem based on its exemplary performance for a similar problem(s). An initial evaluation helps to select the most promising one(s). The selection is inﬂuenced by the success criterion of the classiﬁcation (e.g., accuracy). Step 3: Data collection Diﬀerent sources of data might exist for performing ML classiﬁcation. Data collection looks into what is potentially relevant and checks the type and availability of the data. Step 4: Data pre-processing Raw data would not be ready for processing through the ML algorithm as it could have duplicates, missing values, and contradictions that need to be tackled ﬁrst for error-free results. Performing such pre-processing operations, for example, data cleaning, normalization, transformation, feature extraction and selection, etc. are essential for the success of ML classiﬁcation, but these steps consume a considerable amount of human resources and processing time. The outcome of data pre-processing is the training set which could be processed through ML algorithm further [35]. Step 5: Labeling Labeling is to assign labels to ground truth data [33]. Supervised ML methods need labeled data unlike unsupervised ML methods. Labeling is generally performed by domain experts who identify a set of samples (that are most likely representative of the real-world data) to train the ML models. Depending on the nature of the problem, online crowdsourced platforms could also be used for labeling tasks [36]. Step 6: Training The key idea of ML is to learn from existing data and then apply the resulting model to new data. The quality and quantity of the training data are often as important as the actual machine learning algorithm. To learn from existing data also means that the data set is complete, with known input and output of the observations. Step 7: Hyper-parameter tuning ML algorithms depend upon several parameters such as named model parameters and named hyper-parameters. Named model parameters can be initialized and updated through the data learning process (e.g., the weights of neurons in neural networks). Named hyper-parameters cannot be directly estimated from data learning and should be set before training an ML model because they deﬁne the model architecture. Tuning these parameters means achieving settings that enable good algorithmic performance [37]. Step 8: Testing After training, the model is applied to the selected test set(s) (a small part of labeled data that is held out and excluded from the training process). The larger the number of variables in the real world, the bigger the training and test data should be. From performing testing, classiﬁcation error counts are captured in the form of a confusion matrix. Step 9: External validation Success from Step 8 does not automatically imply the success of the results in the context of the application. The validity of the problem formulation and the data might prevent the applicability of the results (i.e., not actionable within the organization resulting in signiﬁcant wasted eﬀort). Internal validation approaches such as crossvalidation can not guarantee the quality of a machine learning model due to potentially biased training data. External validation is critical for evaluating the generalization ability of the machine learning model, where independently derived datasets (external) are leveraged as validation datasets. While such independent validation is also sometimes used to refer to a validation study by other researchers that the researchers who developed the model [38]. 5.2 Modeling Cost and Beneﬁt Acknowledging that ML classiﬁcation is a process of steps with possibly multiple iterations suggests the need to look at the estimated cost for all these steps. Cost estimation is known to be inherently diﬃcult in software engineering [39]. The same is true for value prediction. Despite many factors inﬂuencing the costs and beneﬁts of ML classiﬁcations, we provide a preliminary model to allow a rough estimate of the ROI. For cost estimation, we make the assumption that the total cost of performing ML classiﬁcation with any given ML technique is the sum of cost components of the four phases outlined in the previous section. To simplify the model, we focus on Phase B (Data Preparation) and Phase C (Execution) and ignore the other two phases. Finally, we assume an 80:20 eﬀort (and cost) ratio between Phase B and Phase C, emphasizing the fact that the majority of eﬀort is spent on data preparation. For modeling the beneﬁt of the classiﬁcation results, we are looking at classiﬁcation errors and their cost (penalty) created. A confusion matrix CM is a matrix that contains information relating actual with predicted classiﬁcations. For n classes, CM will be an n× n matrix associated with a classiﬁer. Table 1 shows the principal entries of CM for binary classiﬁcation. The F1 score is a measure of the model’s accuracy based on the training set and deﬁned as the harmonic mean of the model’s precision and recall in (1). F 1 =2 × T P2 × T P + F P + F N(1) In the context of dependency classiﬁcation, the beneﬁt could be modeled in terms of the ability of the ML model to produce the least amount of overhead by 1) Incorrectly classifying independency as a dependency (False Positive) 2) Incorrectly classifying dependency as independent (False Negative). So, using Costand Costas estimated re-work costs due to classiﬁcation overhead, Sum(Cost, Cost) would be the cumulative expense that a company has to bear. In a release cycle, if estimated value that a product could generate is :V aluethen the Benef it would be the diﬀerence of the estimated value and the classiﬁcation overhead. Table 2 lists the relevant cost components and their corresponding units. 5.3 Modeling ROI During every classiﬁcation, Cost and Benef it were computed using the parameters explained in Table 2. Cost factors are data processing costs (Phase B and Phase C) for all the train (N) and test (N) samples (n) in every iteration. This is further translated into dollar-cost by multiplying with hourly charges (C) of Nhuman resources. Cost = n ×Cost f actors × N× C(2) Return computations for RDA, assumes reward (Cost) for misidentifying the independent requirements (FP) and heavily penalizing (Cost) instances that were falsely identiﬁed as independent (FN). T otalP enalty = F P × Cost+ F N × Cost(3) Return and investment are context-speciﬁc terms, and studying the ROI of Machine Learning classiﬁcation needs tailoring to the context of the study. To determine the ROI, we follow the simplest form of its calculation relating to the diﬀerence between Benefit and Cost to the amount of Cost as shown in (5). Both Benef it and Cost are measured as human eﬀort in person-hours. The core investigative focus of our study is to evaluate various conditions under which RDC-BERT (ﬁne-tuned BERT using data speciﬁc to requirement dependency extraction) is preferable to the baseline ML method: Random Forrest (RF). In this empirical analysis, beginning with a small train set, classiﬁers were created, and then the train set was incremented slowly by a ﬁxed factor to generate new classiﬁers in every iteration until all the data available for training was exhausted. In every iteration, the classiﬁers were tested for a small ﬁxed data set to capture the results. Online bug tracking systems such as Bugzilla [40] and Redmine [41] are widely used in open-source software development. Feature requests, tasks, bugs, epics, stories, features, enhancements, and new requirements are logged into these systems in the form issue reports [42] [43] which help software developers to track them for eﬀective implementation [44], testing and release planning [45]. We mined data from Bugzilla and Redmine related to features for the two OSS projects namely, Firefox - a Mozilla web browser application and Typo3 - a content management system. In Bugzilla, feature requests are speciﬁc types of issues that are typically tagged as “enhancement” [30]. We retrieved these feature requests for the Firefox project using the search engine in the Bugzilla issue tracking system and exported all the related ﬁelds such as Title, Type, Priority, Product, Depends_on, and Blocks. Each issue report contains dependency relationships with other issue reports as references metadata [46]. Using this information, 3,773 depends_on (also interpreted as REQUIRES dependency type) requirements pairs were retrieved. To generate negative samples, requirements that had no relationship were paired and 21,358 samples were generated. 6.2 Typo3 Redmine [41] is a free and open-source web-based management and issue tracking tool website. It allows users to manage multiple projects and associated projects. Various issues across a range of projects are updated each day which helps software developers to track them for eﬀective implementation. In Redmine, features are a speciﬁc type of issue that is extracted in this paper for further data analysis. Typo3 Content Management System (CMS) is an Open Source Enterprise Content Management System[31] with a large global community of approximately 900 members of the TYPO3 Association. We collected information such as issue_links, description, the version found, the version released, issue_id etc. for 5,017 features using Redmine’s REST API through a Python script for this study. All feature descriptions that had fewer than three words in them were ﬁltered out, resulting in 1,324 feature pairs with dependency type RELATES_TO. Using the rest of the features that were not in any type of dependency with others, 9,270 pairs were generated as a negative sample set. Table 3 mentions sample pairs of requirements dependencies. For example, to be able to associate the address with payment card REQUIRES ability to use a new billing address when adding a new payment card. For both data sets, to perform binary classiﬁcation, both positive and negative samples are needed for training. Since we only had dependent (positive) samples in the data, we generated negative samples by pairing the requirements which were not related in the given snapshot of the dataset. Typo3, currently at released version 11, is a complex content management system that is developed as a hybrid OSS software product. It has a core team of 12 members with varying skills and expertise. They have a major release cycle of 18 months and they plan two or more releases ahead of time. Developers are encouraged to track the dependencies in Jira, however, a few of the team members utilize post-its to work and track them. Typo3 does not explicitly consider Requirements Engineering as a development phase, but they term the eﬀorts towards identifying features and extracting dependencies as conceptual work or scoping. Over 15% of the release, the cycle is identiﬁed as scoping eﬀort and about 25% of scoping in a release cycle is identiﬁed as dependency extraction and identiﬁcation. Nine team members and the CTO are involved, mostly in identifying the dependencies. The CEO conﬁrmed that about 80 % of the features are in some form of dependency with each other and missing the dependencies is more problematic than misidentifying them. As he puts this in words, “if you miss dependencies then it starts to ramp up quickly and this is when things go wrong, and breaks deadlines. we wanted to release in April (4 weeks ago) now deadline is mid October”. Typo3 identiﬁes and manages seven diﬀerent types of dependencies and their inversions such as precedes, blocks, clones, caused_by etc. Most of the dependency issues are identiﬁed rigorously through testing and the estimated re-work is about 12%. They have minimal manual testing as they have test suits of over 75,000 test cases. The CEO estimated that the overwork caused by missing dependencies is about 10% of the eﬀorts. The average salary of the nine people involved in re-work is $70 (CAD). A summary of all estimates is provided in Table 5. Figure 5 depicts the overview of our experiment setup. The complete approach is multi layered as highlighted in the shades. Each one of these could be further expanded to include additional elements for solution space evaluation further. In this study, to generate the results, RF, Naive Bayes and SVM ML algorithms were compared against RDC-BERT for the two datasets: Firefox and Typo3. Overall eight experiments were conducted. Since RF performed better among all the conventional ML algorithms [8], we report the results of RF and RDC-BERT (i.e. totally four experiments). For each experiment, we computed ROI using False Negative and False Positive values (from Confusion matrix). In Section 7 we present the insights to aid decision-making in algorithm selection based on these eight outcomes. For additional clarity, we list the names of the analysis of the results and their description in Table 4. Requirements pairs were pre-processed to eliminate noise such as spatial characters and numbers. The generated output is fed to RDC-BERT and RF for training. Care was taken to process the same data snapshot through RF and RDC-BERT models. Further, the ﬁnetuned BERT model (RDC-BERT) is then used for classiﬁcation. The data was split (80:20) into train and test sets, and balanced between both classes. In this empirical analysis, we conducted classiﬁcation by utilizing a fraction of the whole dataset for training and testing for a small ﬁxed data set. This was repeated by slowly increasing the training set and results were captured. generate word vectors before training. Also, hyperparameter tuning was performed and the results for 10-fold cross-validation were computed, followed by testing. RDC-BERT: For ﬁne-tuning BERT, a pre-trained BERT model is used in combination with our RDC speciﬁc dataset. The result is a ﬁne-tuning BERT model called RDC-BERT. To ﬁne-tune the BERT model, we used NextSentencePrediction, a sentence pair classiﬁcation pre-trained BERT model, and further ﬁne-tuned it for the RDA speciﬁc dataset on Tesla K80 GPU on Google Colab. In every instance, for a given training set size, RDCBERT was trained through three epochs with a batch size of 32, and a learning rate of 2e-5. In each epoch, the train set was divided into 90% for training and 10%for validation. Finally, RDC-BERT was used to classify the test set and the resulting F1-score and confusion matrix were captured. BERT eliminates the need for feature extraction since it is a language model based on deep learning. BERT, pre-trained on a large text corpus, can be ﬁne-tuned on speciﬁc tasks by providing only a small amount of domain-speciﬁc data. 7 Empirical Analysis - RQ2 In this section, we report the results of our empirical analysis and answer RQ2. We structure results by the type of decisions to be made: (i) RQ 2.1: When comparing two techniques: Which one is preferable under conditions selected?, and (ii) RQ 2.2: When looking at one technique, when to stop the analysis? For both decisions, we present the results of the analysis for the two data sets introduced above and the two techniques under investigation using estimates from Table 5. 7.1 RQ 2.1: Comparison between RDC-BERT and RF The traditional approach for comparing techniques is to look at just accuracy for some ﬁxed training set. Figures 6 (F1_Firefox) and 7 (F1_Typo3) show the comparison of the F1-scores for varying training set sizes for the two datasets. Results show that RF achieves a higher accuracy more quickly for even small-sized train sets respectively. However, with a training set greater than 40% of the dataset for Firefox and 30% for Typo3, RDC-BERT achieves better results overall. Comparison of ROI for the two datasets and two methods (RDC-BERT and RF) is shown in Figures 8 (ROI_Firefox) and 9 (ROI_Typo3) respectively. For Firefox, with a smaller-sized train set, RF once again performs better comparatively, even though the ROI is negative. Similar results are evident for Typo3. RF performs marginally better ROI-wise for the smaller training set. ROI of RDC-BERT picks up pace only beyond 40% and 30% train set for Firefox and Typo3, respectively. In the second part of the analysis for RQ2, we look at one technique at a time from the perspective of both F1-score and ROI. This will support decision-making towards the question of when does increase accuracy no longer pays oﬀ? As illustrated in ﬁgures 6 and 7, increased training set does not yield better F1-score beyond 65%. The F1score hits a plateau and even starts to degrade for both of the methods and datasets. However, if we look at the trade-oﬀ between the F1 and ROI for both datasets, the results become interesting. Figures 10: F1_ROI_RDC-BERT_Firefox show that for RDC-BERT, F1-score increases linearly, however, max ROI is achieved when the train set is 70% of the dataset. Whereas, for RF, in Figure 11 : F1_ROI_RF_Firefox shows that F1 and ROI for the train set lower than 40% is better than that of RDCBERT. Chasing for a higher F1 score does not payoﬀ and one needs to take a closer look at the beneﬁts vs investment in more training data, eventually. For Typo3, in Figure 12: F1_ROI_RDCBERT_Typo3 shows that F1-score and ROI grow steeply for RDC-BERT with the increasing train set. However, similar to Firefox, ROI and F1 of RF are stable and better than RDC-BERT for the train set smaller than 30%. These ﬁndings once again emphasize the need to relook at how F1 and ROI together could aid in deciding on the ML selection. In both datasets studies, it is evident that RDCBERT models require large amounts of data (at least 30% or more) to stabilize and show value (steady positive ROI). When comparing RDC-BERT with RF using ROI criteria (Fig 8 and 9) across the two data sets, RF outperforms RDC-BERT for the lower train set (incurring lower negative returns). However, positive ROIs are observed only at the larger train set at which RDC-BERT is consistently better than RF. Based upon Fig. 10: F1 vs ROI of RDC-BERT for Firefox dataset, utilizing values from Table 5 the Firefox ﬁndings (Fig 10 and 11), RDC-BERT approaches the 80% benchmark accuracy with approximately 50% of the training data while RF requires 70% training data to attain the same level of accuracy. However, both techniques can achieve positive ROI with as little 50% training data but RBC-BERT achieves maximum ROI (30) with an accuracy of 0.87 with approximately 70% training data, while RF achieves maximum Fig. 9: ROI of RDC-BERT vs RF for Typo3 Fig. 11: F1 vs ROI of RF for Firefox dataset, ROI (2.2) with an accuracy of 0.75 with approximately 70% training data. Based upon the Typo3 ﬁndings (Fig 12 and 13), RDC-BERT approaches the 80% benchmark accuracy with approximately 55% of the training data while RF requires 70% training data to reach the same level of accuracy. However, both RBC-BERT and RF can achieve positive ROI with as little 15% training data, but RBC- Fig. 12: F1 vs ROI of RDC-BERT for Typo3 dataset, utilizing values from Table 5 BERT achieves maximum ROI (73.5) with an accuracy of 0.86 with approximately 65% training data, while RF achieves maximum ROI (48) with an accuracy of 0.80 with approximately 70% training data. Thus, RBCBERT can deliver much higher ROI and similar levels of accuracy than RF given approximately the same amount of training data. Finally, the parameter settings that seeded the initial model (Table 5) were based upon industry estimates, which were possible were veriﬁed by senior management in the respective ﬁrms. However, some of the ﬁndings may be sensitive to these initial conditions. Thus, these would need to be set for the speciﬁc context upon which the data sets are based. This is also the basis upon which scenario analysis could be conducted to evaluate the worst case, best case and most likely initial conditions to evaluate the impacts on subsequent decisions. ML is not simply a cost of doing business, rather it is a foundational activity that can provide value for the money invested. Our proposed approach aligns this notion with the strategic direction of the organization. While return on investment (ROI) is a common approach used for business planning and decision making, it is not applied as widely within software engineering or speciﬁcally within applied ML. In our study, we demonstrate how to instantiate ROI in the context of RDC. Our approach provides a pragmatic link between the business and technical aspects of the organization by providing a common language that incorporates both the technical aspects inherent in the evaluation of accuracy, with the business considerations of costs and beneﬁts. We argue that this Fig. 13: F1 vs ROI of RF for Typo3 dataset, is an extremely powerful approach that provides evidence that is compelling and consistent for both technical and business decision-making. In addition, we think that the ROI approach could sensitize the ML team to the entire process of ML classiﬁcation and how that process ﬁts into organizational processes. The ROI approach is essential for evaluating the possible tradeoﬀs between accuracy and the beneﬁts. Mainly because without consideration of the key dependencies within the process, beneﬁts in one part of the process (e.g., improved accuracy) can easily be undermined by excessive costs in another part of the process that would not typically be considered if focused exclusively on accuracy. Alternatively, lower levels of accuracy in the ML process might be acceptable if other beneﬁts are accruing at reasonable costs. Thus, valuable ML investments are potentially being avoided based upon not meeting accuracy expectations, when those ML solutions could be suﬃcient to realize high payoﬀs for the organization. Our approach increases the transparency of the decision-making process by adding diversity to the evaluation criteria that foreground the various tradeoﬀs being made. The development of AI tools that businesses and consumers can trust is essential for their continued adoption, especially as there is increasing regulatory scrutiny of the biases that arise in the ML algorithms or inherent in the data used for training. While ML algorithms are generally trusted for relatively mechanical well-deﬁned problems, this trust plummets when the decisions are subjective, and likely to vary by contextual variables that are not well understood. This in turn increases the pressure to adjust ML algorithms for variations in speciﬁc markets further driving up development costs. Such pressure directs the focus on customizing products and services based upon ML algorithms for speciﬁc markets while increasing costs further and undermines the beneﬁts for certain markets or customers [47]. The proposed approach considers technical and business aspects simultaneously and provides a more traceable set of interconnected processes. This approach includes business and technical considerations to enable management to evaluate the risks of some undesirable decisions and the tradeoﬀs needed to realize the likely beneﬁts. We have explored RF and RDC-BERT in the context of the RDC problem and presented our results. Since there is no single method which could work for any given problem, comparison of multiple approaches and their results remains out of the scope of this study. Another threat to validity is the related to the conclusions made. Although we have taken care to randomize the data by shuﬄing and used stratiﬁed split to take care of balanced data in both training and validation, multiple runs with varying ﬁrst iteration data sample are needed to be more conﬁdent on the conclusions made. However, we argue that the key observations made are valid from the restricted empirical validation performed. ML classiﬁcation is widely used in many disciplines of Science and Engineering. In this study, we demonstrate that just looking at performance measures such as accuracy could be misleading when, for example, deciding between two ML techniques evaluated for solving the same problem. Conversely, ignoring the cost and beneﬁt of such a classiﬁcation could cause the risk of unprecedented emphasis on improving accuracy that might not generate any value for the additional eﬀorts spent. Additionally, in this research, we also provide a high-level ML process for classiﬁcation (supervised machine learning). However, with minuscule changes, this process can be adapted to unsupervised or semisupervised ML methods easily. We use Requirements Dependency Classiﬁcation as a sandbox to build a proof of the concept based on the two ML techniques used to solve RDC. In the future, we will extend the results in various dimensions. The concepts of this paper will be applied and evaluated for problems from other domains. However, the challenge is to project the beneﬁt of achieving better accuracy results and estimating the total eﬀort of data analysis. Also, depending on the problem, we will investigate other ML techniques and additional data sets. With a broader data and knowledge base, we aim at developing a customized recommendation system that would support practitioners in their decision-making in terms of "How much Data Analytics is Enough". The authors declare that they have no conﬂict of interest.