Recommender systems are software applications that help users ﬁnd items of interest in situations of information overload in a personalized way, using knowledge about the needs and preferences of individual users. In conversational recommendation approaches, these needs and preferences are acquired by the system in an interactive, multi-turn dialog. A common approach in the literature to drive such dialogs is to incrementa lly a sk users about their preferences regarding desired and undesired item features or regarding individual items. A central research goal in this context is eﬃciency, evaluated with resp ect to the number of required interactions unt il a satisfying item is found. This is usually accomplished by ma king inferences about the best next question to ask to the user. demonstrate, for example, that one strategy for selecting questions is better than another o ne in a given application. With this work, we complement empirical research with a theoretical, domain-independent model of conversational recommendation. This model, which is designed to cover a range of application scenarios, a llows us to investigate the eﬃciency of conversational approaches in a formal way, in particular with respect to the computational Today, research on dialog eﬃciency is almost entirely empirical, aiming to complexity o f devising optimal interaction strategies. Through such a theoretical analysis we show that ﬁnding an eﬃcient conversational strategy is NP-hard, and in PSPACE in general, but for particular kinds of catalogs the upper bound lowers to POLYLOGSPACE. From a practical point of view, this result implies that catalog characteristics can strongly inﬂuence the eﬃciency of individual conversational stra tegies and should therefore be considered when designing new strategies. A preliminary empirical analysis on datasets derived from a real-world one aligns with our ﬁndings. Keywords: Conversational Recommender Systems, Complexity Analysis 1. Introduction modern online services such as e-commerce sites, media streaming platf orms and social networks. In many cases, the suggestions made by the underlying recommender systems are individualized according to the stated or assumed needs and preferences by the user. In t he most prominent a pplications of recommender systems, e.g., on Amazon.com, Netﬂix or YouTube, the user preferences are estimated based on the observed past user behavior. There are, however, also a number of application domains where no past interactions logs are available or where the user’s needs and preferences might be diﬀerent each time the user interacts with the service. Consider, for example, someone seeking a recommendation for a restaurant this evening for a party of four, where the requirements include that the location is nearby, that the prices are modest, and that there is a vegetarian option. In such a situation, the user’s current needs and preferences have to be interactively acquired by the system to make a suitable recommendation. tional Recommender Systems (CRS). In these systems, the recommendation process consists of an interactive, multi-t urn dialog, where the system’s goal is to learn about the user preferences to the extent that appropria t e recommendations can be made. The corresponding preference elicitation process can be implemented in diﬀerent ways, ranging from predeﬁned ﬁll-out forms to natural language interfaces—see [1] for an overview. In particular for this latter class o f interfaces we observed substantial progress in terms of voice recognition and nat ural language understanding in recent years, leading to the development of voice-controlled devices like Apple’s Siri or Amazon’s System-generated recommendations have become a common feature of The class of systems that support such interactions are called Conversa- Alexa, a nd continuously improved chat-bo t systems. in many CRS is to ask users about desired or undesired f eat ur es in sought items, or to ask them about individual items they like or dislike. This applies both for traditiona l critiquing approaches [2], interactive advisory systems [3], and recent learning-based approa ches [4, 5]. In that context, a typical goal when designing a CRS is to minimize the eﬀort for users by asking as few questions as possible, i.e., to increase the eﬃciency of the dialog. The underlying assumption is that a lower number of required interactions leads to a b etter usable system. Diﬀerent proposals were ma de in the literature to increase the eﬃciency of the recommendation process. These include the selection of predeﬁned dialog paths according to the user’s expertise [3 ], the automatic creation of compound critiques based on diﬀerent stra t egies [6, 7], or the selection of the best next question to ask based o n reinforcement learning strategies [8, 4]. designs are based on simulations or user studies, in which two or more interaction strategies are compared in one or two applicatio n domains based on real or synthetic datasets. The corresponding eﬃciency measures are, for example, the number of required user interactions or the perceived diﬃculty and eﬀort of the recommendation dia logs. Such empirical studies are certainly important and insightful. Little is known, however, about the theoretical aspects of the underlying interactive recommendation processes. In many cases, the recommendation process is deﬁned in an infor ma l or semi-formal way, or only given implicitly in terms of an algorithm that selects the next questions to ask. Theoretical questions regarding, e. g ., the computational complexity of determining a good or the best interaction strategy can, however, not be answered without a formal characterization of the underlying problem. cal model of conversational recommendation. The model is designed in a domain-independent way and aims to cover a wide range o f realistic application scenarios. A conversational recommendation process is modeled as a sequence of states, where state transitions correspond to common conversational mo v es [9] tha t can be found in the literature, including in particular preference statements r egarding item features or individual items and the relaxation or r evision of previously stated preferences. Furthermore, since the model is agnostic about the a lgorithm that is used to select and ra nk Independent of the interactio n modality, a common approach implemented Today, research in this area is almost entirely empirical. Typical research With this work, we address this research gap and provide a theoretithe objects for recommendation—i.e., the recommendation algorithm—this model can be applied in various application domains. As a result, the model serves as a basis to analyze important theoretical properties of conversational recommendation processes. We particularly focus on the problem of the computational complexity of ﬁnding an eﬃcient conversational strat egy. Our theoretical analysis reveals that this problem is NP-hard, but in PSPACE in general, a nd we furthermore derive which factors in the catalog inﬂuence the complexity of t he problem; in particular, we show that for a special class of catalogs, the upper bound lowers to POLYLOGSPACE. From a practical perspective, this analysis speciﬁcally shows that the eﬃciency of individual conversation strategies is tied to the characteristics of the available it em catalog. Observations from an empirical analyses on real-world datasets support these theoretical considerations. works a nd outline our research goals. We provide a model formalization in Section 3, then our theoretical results in Section 4, and the outcomes o f our empirical analyses in Section 5. 2. Previous Work and Research Goals ated in research literature [1]. Here, eﬃciency usually refers to the t ime or eﬀort that is needed by a user to ﬁnd a suitable item. The corresponding underlying assumption is that users will ﬁnd a system more useful if it requires less eﬀort for them. Likewise, if a recommendation dialog takes too many steps, users might quit the conversation or, even wor se, abandon the system as a whole. 2.1. Increasi ng Dialog Eﬃcien c y that guides users more directly to the items that match their preferences. In a non-interactive recommender system, eﬃciency is achieved through accurate predictions of what is relevant for users given their long-term preferences. In CRS, where the preferences are interactively elicited, o ne can in addition try to ﬁnd better conversation strategies. By “conversation strategy” we mean the choices tha t CRS can make during the dialog. After a few interaction steps, a system might, for example, either decide to make a recommendation or to ask more questions in o r der to obtain a more complete picture of user The paper is organized as follows. Next, in Section 2, we discuss existing Dialog eﬃciency is one of the main dimensions in which CRS are evalu- Eﬃciency can in general be increased by designing the system in a way preferences. While asking more questions means more interaction cycles in the short term, having more informa tion might reduce the risk of providing irrelevant recommendations and more user eﬀort in later phases of the dialog. Another decision point exists after the system has decided to ask more questions. In this case, the system can usually select between several options regarding what to ask next. the eﬃciency of the recommendation process though improved conversation strategies. Here, we give a few examples of diﬀerent types of such a pproaches. Note, however, that with this work our aim is not to propose a new strategy, but to understand, on a theoretical level, how complex it is to make optimal choices. on a static set of application-speciﬁc rules about how to continue the dialog. In the interactive sales advisory system Advisor Suite [3, 10], for example, the possible dialog paths are predeﬁned in terms of a state-machine. How the system can proceed in the dialog is thus determined through the transition graph. The actual choice of the system is then determined based on manually-deﬁned decision rules. For example, the system could adapt the way the questions are asked depending on the user’s self-reported expertise in the domain or based on previous user answers. To what extent such handcrafted decision rules actually increase the eﬃciency of the conversations was unfortunately not evaluated in the mentioned papers. that are based on critiquing. In critiquing-based systems [2], the idea is that the CRS provides a recommendation relatively early in t he dialog or even starts with an initial recommendation. Users can then apply critiques on a given recommendation—e.g., in the form “cheaper” or “lighter” for a camera recommender system—after which the system ma kes a new recommendation. The system therefore interactively reﬁnes the preference model until a recommendation is accepted (or no recommendation is found to be suitable). While such an approach in its basic form is intuitive and conceptually simple, it might turn out to be not very eﬃcient in particular when there are many item at t ributes the user can apply critiques on. Depending on the implementation, a critiquing system might oﬀ er all attributes for critiquing at once or incrementa lly ask for desired f eat ure values, also known as “slot ﬁlling”. In case of incremental slot ﬁlling, a naive implementation might end up asking too many questions about features that are either (i) not relevant for most In the literature, diﬀerent technical approaches were proposed to increase The conceptually most simple approa ch is to build a CRS that is based Various more elaborate approa ches were proposed in the context of CRS of the users or (ii) not particularly well-suited to nar r ow down the range of remaining options. were proposed [11, 7, 12, 13, 14]. In the compound critiquing approach [7], for example, the idea is not only to present critiques to the user that concern more than one feature (e.g. , “less expensive and lighter”), but to determine possible compound critiques based on the properties of the item catalog. During an ongoing session, it might for example be most helpful to propose compound critiques that, if applied, would rule out a larger f raction of the available optio ns. generally, the next conversational move, is however not limited to critiquingbased approaches. In the context of such slot-ﬁlling stra tegies—where the system questions mostly relate to item properties (or: facets)—various approaches were put forward to determine the best order of the questions. Often, such approaches are e ntropy-based and consider the potentia l eﬀects of individual questions (and their answers) on the remaining space of options [15, 16, 1 7, 18]. In some cases, feature popularity information is considered as well [15 ]. Several alternative technical approaches to decide on the next action are ba sed on machine learning, using, for example, reinforcement learning techniques [19, 20, 8] or r ecurrent neural networks [21]. on eliciting feedback on items considered as a whole. This could be done by asking for like or dislike statements for individual items or by asking for the relative preference regarding two or more items [22]. One main question in t hat context is how to select these items or sets of it ems t o maximize the eﬃciency of the process. Such a selection can for example be based on item popularity or based on diversity considerations [23, 24, 25]. In some approaches, the system can also learn to decide if an a bsolute rating should be elicited or pairs of it ems should be presented to the user [4, 26]. 2.2. Mea suring Dialog Eﬃciency is to count the number of required interaction cycles until a recommendation is accepted by the user. Such an approach is followed in many works that are based on critiquing, but also in chatbot-like applications and in mo r e recent learning based systems [27, 28, 29, 30, 8, 6, 31, 32, 33, 34, 23, 35, 36, 19]. In most of these works, the interaction between a user and the CRS is To deal with such problems, dynamic and co mpound critiquing a pproaches The dynamic and data- based selection of the next question to ask or, more Instead of asking for desired item features, some approaches are based The most common a pproach to measure dialog eﬃciency in the literature simulated. In such simulations a software agent is developed, that has a certain preference proﬁle a nd answers requests made by the system based on the underlying preferences. The common assumptions here are that the agent knows all preferences from the beginning, behaves rationally and truthfully, and does not change its mind during the conversation. In reality, not all assumptions might ho ld, and we include this aspect in our simulations (see later sections), by having users revise their preferences, e.g., in case no item matches the initial preferences. studies include the task completion time [8, 3 5, 37]. We may in general assume t hat shorter task completion times usually means that the recommendation process was more eﬃcient. However, a longer task completion time can, depending on the domain, also mean that the users f ound more interesting options to explore [38]. task completion time—some researchers also rely on s ubjective measures in the context of studies that involve humans. In such studies, the participants are usually asked after the main experiment task how they perceived the eﬀort that was needed, e.g., to ﬁnd a suitable item. In most cases, eﬃciency is only one of several variables that are assessed in such post-task questionnaires. Examples of works that use eﬃciency-related measures are [39, 40, 22, 41, 8]. 2.3. Research Goals Research Gaps and Goals. Existing research on the eﬃciency of diﬀerent conversational recommendation strategies, as mentioned above, is entirely empirical. Either the research is based on studies with simulated users, or it is based on user studies in which part icipants usually interact with a prototype system. In either case, such studies are based on one or a few particular experimental conﬁgurations. In particular, often o nly one speciﬁc item catalog is considered when the eﬃciency of a newly proposed conversation strategy is demonstrated. However, as the theoretical analysis shows later in this paper, t he characteristics of the catalog, in particular, in terms of the number of item features, and the number of feat ur e values t hat are shared by several items, may have an impact on the eﬃciency o f a given strategy. Depending on such characteristics, fo r example, in one case it might be much more eﬃcient to ask the user about a feature preference than asking for an item preference, whereas in another situation, the adva ntage is negligible. Alternative eﬃciency measures that are often used in the context of user In a ddition to these objective measures—number of interaction turns and plexity of choosing an optimal strategy in a conversation. Our research aims at closing this gap and provides a formal deﬁnition of the conversational recommendation problem, based on which such complexity analyses are performed. Furthermore, we complement our theoretical analysis with results obtained from simulation-ba sed experiments with data elicited from a real dataset (MovieLens). Research Scope. A multitude of CRS have been proposed in the past, focusing on a variety of diﬀerent problem domains. Depending on the target domain, such CRS are often diverse in terms of what functionality they oﬀer. Speciﬁcally, existing CRS vary largely in terms of the supported user intents. In their recent work, Cai and Chen [42] developed a comprehensive list of user intents a nd corr esponding system a ctio ns (or: conversational moves) in CRS. that base their conversations on desired or undesired values for item features (“slot ﬁlling”) and/or the acquisition of preferences of users regarding an item as a whole. Our formalization therefore includes actions that, for example, relate to the initial acquisition of preferred featur e values, but also considers additional user actions in such applications, such as the relaxation or revision of constraints [43]. The resulting formalization t herefore represents an abstraction from various existing approaches from the lit era ture, and the resulting insights therefore apply to a larger range o f CRS implementations. In this context, note that our formalization considers the actual item ranking task as a black box. This means t ha t our theoretical framework is indep endent of the speciﬁc type of algorithm that is used for determining the order of the recommendations. Thus any type of approach, e.g., collaborative, content-based, or hybrid, can be used internally. number of a lternative measures were applied in the literature, counting the number of required interaction steps is the predominant choice o f researchers. Therefore, we also use this measure in our theoretical analysis and in our simulations. 3. Model Formalization lows. The system main task in the interaction with the users is to elicit their Moreover, existing research has not looked yet at the computational com- In our work, we focus on the most common CRS in the lit era t ur e: those Regarding the measure for eﬃciency, our discussion showed that while a On a conceptual level, a CRS—as considered in our study—works as f olpreferences maintains information about these preference statements in a user model. These preference stat ements determine which of t he items of a given cata log qualify to be recommended. Therefore, in our theoretical framework we assume a retrieval-ba sed item ﬁltering appro ach, which is commonly used in critiquing-based and constraint-based approaches to recommendation [44]. In analogy to da t abase-oriented approaches, we therefore use the term “query” when referring to the user’s preferences, as these preferences lead to the retrieval of matching items from the catalog. The retrieved items are then ranked according to their assumed utility for the user. Such a ranking can be based on any type of information, e.g., the popularity of certain it ems. In order to carry a general analysis, in our approach we abstract from the details of this ranking, as mentioned above. tion of state of a conversation, and what transformations this state can be subject to, depending on the interaction. Each expressed user preference, for example, leads to a change of t he state of the conversation and may also imply that the set of suitable item recommendation changes. This formalization through conversation states ultimately serves us as a basis to study the eﬃciency of conversational strategies, in the sense that the most eﬃcient conversational strategies will be the ones minimizing the number of states the conversation must pass through, to reach an end. 3.1. Basic components and we explain them in detail in the rest of the section. In particular, we have: 1. a Catalog of items C; 2. the user model, which is a 4-vector U = hQ, K, P, N i, where the To model the conversational recommendation process, we rely on the no - We summarize below the components and symbols of our f ormalization, query Q denotes the user’s positive preferences regarding it em features (desidera ta), K are constraints, in the form of undesired values for a feature, P is a set of positively-rated preferred items, and N is the set of items that are negatively rated by the user; 3. the Recomme nder system R (a black box in this paper), that g iven 4. the s tate o f the conversation as the 5-vector hQ, K, P, N , R(U)i which 5. the interactions between the user and the recommender as tr ansforma- This formalizat ion provides us with the necessary notation to study strategies , i.e., algorithms that, given a state of the conversation, suggest the next move in order to proceed towards a successful recommendation. ments ar e denoted by lowercase letters, e.g . , x, t, v; sets and vectors of ato mic elements ar e denoted by uppercase letters, e.g., C, D, I, Q; and sets and vectors of the previous sets and vectors are denoted by calligra phic letters, e.g . , C, K. We now delve into each element in detail. Features. L et {f each feature f we assume that features ar e only single-valued, i.e., we do not consider setvalued features. When making examples, we often characterize the feature with a name instead of the index, as in f Boolean domain B = {false, true} as a special one. While any do ma in D could be translated into a number of |D| Boolean domains via one-hot encoding, we prefer not to use such an encoding because of its exponential-space blowup the union of all domains as V = ( U ranks items in C, and returns the t op-k items, which we abbreviate as R(U ); we stress our being agnostic in modeling R, which could be content-based, or based on collaborative ﬁltering, etc. Following the intuition, we assume that R(U) ∩ N = ∅—that is, no negatively-rated item is ever proposed; we denotealso as U + R(U), i.e., the state is composed by all of the above elements but for the catalog, which we consider constant during the conversation; tions of U , denoted by τ. To ease reading, we adopt the following syntax conventions: atomic elethat would hamper our subsequent computational study. We denoteS Variables . In addition to domain values, let X = {x variables. Intuitively, a variable is a placeholder for a query feature which the user has not yet expressed a preference on. As an abstraction of both variables and values, we deﬁne terms. A term t can be either a value in a domain, or a variable; so the set o f terms is T = V ∪ X. Terms are needed to model user queries, which we introduce next. Queries. The user’s stated preferences are represented by a query vector of terms Q = ht is associated with a feature f similar to ﬁeld names in relational databases. We say that “the feature fcontains the term t t—written f x, it means that we have no knowledge about the user’s preferences in this respect. Remember that one goal of the interactive process is to ﬁll in such features/slots. Constraints. A query represents the po sitive part of a user’s desires; to represent t he negative part—what the user deﬁnitely does not want—we deﬁne the con s traints on Q as another vector K = hC constraint C a constraint represents the negative part of the history of the conversation, namely, the negative answers given by the user during the interaction—e.g., “I don’t want horro r movies tonight”, which is formalized as horror ∈ C Observe that for such negative constraints, we limit this formalization to the most common case implemented in CRS, that is, we consider here only single values. Items. We represent items using the same feature space as the queries, but for variables. G iven a catalog C = {I I = hv v—written f i.e., all f eat ure values are known. Substitutions. During the interactive recommendation process, we continuously learn more about the user’s preferences, which leads to changes in the user model U. We call such changes transformations. We deﬁne the simplest , v, ..., vi be a vector where each feature fin position i contains value form of transformation as slot ﬁlling, which in our setting means substituting a variable with a value. A simple substitution σ : X → V is a function mapping a variable x to a value v. Apart from such a change, the substitution leaves the rest untouched—more formally, the substitution σ is the identity function on every term but x, which is changed to v. Recall that we are interested in substitutions in the user model U , and not in the items, whose descriptions do not contain var iables. hσ(t that σ will change only the feature containing x. Clearly, if a user a lready stated tha t s/he dislikes a speciﬁc feature value, such a value should never be proposed again during the conversation. Formalizing such an intuition, we say that a substitution is coherent with K if it does not substitute a variable with a value forbidden by the constraints, in formulas: for all i = 1, . . . , p it holds that σ(t with K. σ(t) = σ applied to vectors position-wise, written a s σ(Q) of such nested substitutions preserves the order (in reverse) in which the subsequent slot-ﬁlling interactions cha ng e the stat e of the conversation. K, such that σ(Q) = I. In practice, σ formalizes all the slot ﬁllings that would lead from Q to the proposal of (exactly) I. We say that a substitution σ, coherent with constraints K, satisﬁes a query Q in C if t here is an item I ∈ C such that σ(Q) = I. Given a catalog C, we write Q(C) for the set of items matching Q, in fo rmulas: Q(C) = {I ∈ C | ∃σ : σ(Q) = I}. speciﬁes no preference for f —we do not know whether the user does not care about f—so that the user would accept any value for f —or the user does not know that there are some alternatives that ﬁt her preferences while others do not. For instance, suppose a restaurant recommender describes items with some features, among which there is a Boolean feature regarding dress code; We extend σ to vectors position-wise, i.e., we have σ(ht, t, . . . , ti) = ), σ(t), . . . , σ(t)i. In this way, we can use the notation σ(Q), knowing We let substitutions σ, σ, . . . , σbe repeatedly applied to a term as (σ(. . . (σ(t) . . .)), and also such nested substitutions σ can be An item I matches a query Q if there is a substitution σ coherent with We note that when a feature f contains a variable—i.e., when the user and suppose tha t when starting the conversation, the user did not mention preferences about dress code. When f acing the proposal of a restaurant whose dress code feature is true, the user might say “no, I don’t want dress code restaurants; sorry I didn’t mention it before”. Formally, this would mean that the conversation starts with a query Q the recommender (after some interaction) proposes a restaurant I for which it with the above dialog, and the conversation proceeds with the updated constraints K Positively- and negatively-rated items.. Both Q and K formalize the “analytic” part of a user’s preferences, i . e ., what s/he thinks about particular values of item features. However, sometimes the user may want to express a holistic opinion on an item a s a whole, e.g., “I don’t want to go to restaura nt Y a nymore, I had a bad impress i on last time I went” (dislike), or “I liked movie Z very much” (preference). We model such statements as two sets of items, P ⊂ C (positive rating) and N ⊂ C (negative rating). P and N are part of the user model U as mentioned above, so that our formalization is as general as possible. We exclude from the formalization o f the conversation the trivial solution that directly proposes items in P; such items are not proposed (e . g., in the movie domain, they might be movies already seen; in the restaurants domain, they could be appreciated restaurants far away from the user’s current position). 3.2. States and Tra nsformations with U U+ R(U from previous interactions, we face a ‘cold start’ situation where P ∅. When a new conversational session starts, we let Q (all variables) and K individual features was expressed yet. Recall that we assume t he catalo g C as constant in time—i.e., no items enter or exit the catalog during the conversation. conversation consists of a sequence of interactions. Given a state U + R(U), the interactions initiated by the system can be one of the following. (I) = true (so I matches Qwith σ(x) = true), the user rejects A s tate of a CRS is the 5- vector U + R(U). The conversation starts = hQ, K, P, Ni as the initia l information a bout the user, and ) as the initial state. If there are no past item ratings available In our model, we are formalizing system-driven conversations, where a 1. the system asks the user to ﬁll in (provide) a value for a particular 2. the system asks the user to enlarge a too narrow choice for a feature 3. the systems asks for changing a feature value in Q; 4. upon rejection of one or more items, the system can ask the user The user can react to the above system prompts with one of the following interactions: (a) given one or more recommendations R(U), the user can accept one of (b) the user can state that she dislikes every item whose feature f is ﬁlled it covers a wide range of conversation strategies that were described in the literature, as discussed in Section 2 . Regarding the speciﬁc user reactions, Interaction (a) amounts to adding the rejected item(s) to N , while Interaction (b) amounts to a dding the value v to a set C Regarding system prompts, in what follows we show how such interactions can be expressed in terms of transformations on U, which extend substitutions as f ollows: a transforma t ion τ : T → T can map any term to another term. In this way, substitutions are just a particular case of transforma t ions. We need transformations to model system-user interactions in a more general way than just turning a variable into a value (as is the case for slot ﬁlling) . 3.2.1. Interaction 1: Slot ﬁlling would like to go to a restaurant tonight”. The system has so many answers to this query that presenting only the top-k ranked items R(U ) might miss a satisfying experience, and given that f kind of cuisine do you prefer?” and provides a set of possible feature values of the available items. When this set is too larg e to be presented to the user, another variant could be that the system actively suggests some value, feature under-speciﬁed so far (a variable in Q); value in Q; whether there is a speciﬁc feature of these item(s) she dislikes. them, or reject them; with a particular value v (e.g., “I don’t like green cellphones”) While this set of possible interactions might seem limited, remember that Suppose the user issued a very general query Q to start with, e.g., “I e.g., “What abo ut French cuisine? ” given that there are plenty o f French restaurants in the catalog. The formal counterpart of this dialog is a simple substitution σ such that σ(x) = Fre nch, expressing the user’s choice, and after this simple transformation is performed, the new state is U where U Imagine a conversation between a restaurant recommender and a user, in which after some questions (slot ﬁllings) regarding cuisine, location, price level, etc. the recommender asks the user: “What about Restaurant I Japanese cuisine, midtown, upper-level price, no dress code? ”; yet getting a “Dislike” from the user. Suppose there are no more restaurants with the features set so far. Then the recommender may say “May I propose you other types of cuisine? ”. Formally, N jected), and the query Q in which f by τ (Japanese) = x (a fresh variable), yielding a new state U with U a ﬁrst convenient way of driving a conversation out of a dead end, without committing on a new choice. 3.2.3. Interaction 3: Slot Change poses a speciﬁc change to the user: “I have no o ther Japanese restaurants in midtown, upper-level, with no dress code; but downtown, there are a fe w. Are you willing to change midtown for downtown? Other alternatives are : north outskirts, or riverside” ture should change value. The formalization is also similar to the previous case: the conversation is in a state U + {I the value midtown. Again, since the user dislikes I We let τ (midtown) = downtown (or whatever other value is chosen by the user), stepping into the new state U that R(U town). = hσ(Q), K, P, N i, and f(σ(Q)) = French. Here transformations more general than substitutions come into play. This interaction is similar t o the previous case, but now t he system pro- ) 6= ∅ (since t here are recommendable Japanese restaurants downbe considered a special case of knowledge co ntraction [48], while slot change is a form o f revision [49]. We occasionally use such names instead of slot unﬁlling and slot change in the rest of the paper. conversation as follows. Deﬁnition 1. A Conversation is a sequence of transformations τ that starting from an initial state U (the user choos e s an item), or failure. of interactions has been reached, or (ii) the user gives up after a number of interactions, or ( i i i ) the conversation reaches a state U +∅ in which it happens that both the CRS has no more items satisfying the user’s preferences, and the user does no t wa nt to reconsider a ny of the preferences stated in U. 4. Devising Optimal Strategies stone is the method the CRS uses to decide how to proceed in the conversation; we call such a method a strategy. Our g oal in this section is to study the problem of developing eﬃcient conversation strategies for CRS. For our setting, a CRS strategy is a n algorithm that, in every possible state of a conversation, suggests the system its next action, among the ones formalized above. As discussed in Section 2 , the eﬃciency of a CRS strategy can be studied in terms of the number of interactions the user needs to reach an item I. One can consider the worst case, i.e . , the maximum number of interactions (f or some “diﬃcult” item), or the average case, with respect to a probability estimating how likely item I will be the chosen one. In this paper we study the minimization of the maximum number of interactions, leaving the probabilistic setting for future work. about how the user answers the system prompts. In our work, we assume that there is a set J of ideal items the user would be satisﬁed with. Without loss of generality, since we a r e studying eﬃciency, we assume that J ∩ C 6= ∅, meaning that there always exist at least one item in the catalog that would satisfy the user, and the only point is how many interactions are needed We note that in the area of Knowledge Representation, slot unﬁlling could The formalization described so f ar can be distilled into a deﬁnition of We observe that fa ilure may occur because (i) either a maximum number In the development of CRS with system-driven conversations, a corner- To study conversation strategies, we need some reasonable assumptions to ﬁnd it there are “ideal” items the user would like, but which are not available in the catalog. They are exactly such items that ma ke search diﬃcult, since the user might drive the search (in the conversatio n) towards such unavailable items, heading towards available ones only later on. tionally) the following truthful attitude when interacting with the CRS: 4.1. Lower Bounds includes Binary Decision Trees (BDT) minimization as a special case. We recall the deﬁnition of a BDT [50] for our purposes. A BDTs is a procedural representat ion of a decision table deﬁned as a tabular representation of a function whose domain is contained in B decisions. Given integers p, and q ≤ 2 matrix or false, and the q rows represent the combinations of such conditions—one . Observe also that we do not set J ⊂ C, i.e., we assume that We assume that the user, during the conversation, adopts (even uninten- • the user chooses a slot ﬁlling σ(x) = v for a f eat ur e f, if and only if there is at least one ideal item I ∈ J whose feature fis actually ﬁlled by v—in symbols, ∃I ∈ J : f(I) = v. Note that this is a double implication, i.e., if t here is no such ideal item, the user does not choose (or accepts as a suggestion) to ﬁll the slot fwith value v; • similarly for slot change: the user chooses (or accepts the suggestion) the change of a slot value τ(v) = w for a feat ure f, if an d onl y if there is at least one ideal item I ∈ J such that f(I) = w; • user’s like/dislike statements about whole items ar e always coherent with ideal items J , i.e., when t he user states that she likes an item I, it is I ∈ J , and when the user states that she dislikes an item I, t hen I 6∈ J . We ﬁrst show that our problem of devising eﬃcient stra t egies for CRS in which the p columns represent conditions/tests that can be true of which has to be assessed to take the appro pr iate decision. Each decision could be associated t o one or more rows—all the combinations of conditions in which this decision has to be taken—and rows corresponding to impossible combinations are usually omitted. We give an example in Table 1 (left). in every possible situation. In particular, the tree contains a test in each internal node, a label true/false in each arc, and a decision in every leaf (possibly repeated). An example of BDT is given in Table 1 (right). The procedural interpretation of the BDT is: starting from the root, test the condition in the node, and proceed along the arc labeled with the result of the test. Repeat until a leaf is reached, which represents the decision t o be taken. The cost of the decision taken is t he number of tests performed, which coincides with the length of the path f r om t he root to that leaf. For a given table, there can be several BD T representing it, and BDT minimization is the problem of ﬁnding a BDT whose decision costs are all within a maximum, which coincides with the depth of the tree (i.e., the maximum path length from the root to a leaf in the tree). minimum expected cost. decision table and an integer M, is there a BDT representatio n of the table A BDT is a strategy for testing the conditions that leads to a decision . The cost could also be averaged over all leaves, yielding a search for the The decision problem related to such optimization problem is: “Given a whose decision cost is ≤ M?” This problem was proved NP-complete the minimum expected cost by Hyaﬁl and Rivest [51], and then extended to minimum depth by Chikalov et al. [52, Prop. 13]. devising optimal CRS strategies, given a decision table q × p we ﬁx a catalog C of q items, each item with p Boolean features. Decisions are one-one with items, so the number of decisions is |C|, a nd conditions/tests are one-one with Boolean features. The CRS begins the conversation from a cold-start state in which no preference is known yet. More precisely, Moreover, fo r our lower bound we suppose that the a nswers given by the user always lead to an item that exists in the catalo g, that is, J ⊆ C, so that once the system eventually proposes an item (after a conversation in which the user has the truthful attitude explained above), the user immediately accepts it. In this situation, the minimal interaction sequences are the ones in which only slot ﬁlling is performed, g oing from the root of the tree to a chosen item in a leaf. Such conversations composed solely by slot ﬁllings on Boolean features are equivalent to the paths of a BDT, hence a lower bound on the eﬃciency of such conversations is also a lower bound for minimizing general conversational strategies. prove below t hat the problem o f ﬁnding an eﬃcient CRS strategy is NP-hard in general, since it includes a decision problem which is NP-complete. Theorem 1. The f ollowing problem is NP-hard: “given an integer M, a catalog C, an initial cold-start state U and Q and P questions, such that the maximum number of interactions with the user is less than or equal to M?” To show that BDT minimization is a pa r ticular form of the problem of • the query contains only variables: Q= hx, x, . . . , xi; • the constraints vector is a p- vector of empty sets K= h∅, ∅, . . . , ∅i ; • P= N= ∅. Borrowing from results about the complexity of ﬁnding optimal BDTs, we = hx, x, . . . , xi, the constraints Kare a p-vector of empty sets, = N= ∅, is there a conversation strategy made only of slot ﬁlling Proo f . We give a polynomial reduction from BDT minimization, that we precisely recall here: given a set of objects O T, . . . , T whether there is a BDT whose internal nodes are t he t ests, whose leaves are the objects, and whose depth is less than or equal to a given length M. problem in conversational recommendation. Let the catalog C be made by c items: for each object O, there is an item I 1, . . . , p while the items are deﬁned as I feature f on Object O. problem, whose depth is less than or equal to M if and only if t here is an eﬃcient strategy for the target CRS, whose maximum number of slot ﬁlling interactions is less than or equal to M. Without lo ss of generality, we represent the stra t egy of the CRS as a binary tree, too. as f ollows: take the BDT T , and substitute test labels T nodes with feature labels f edge connections untouched (true/false test results in BDT are one-one with true/false user ﬁlling in the CR S strategy). Then substitute each leaf node of the BD T, marked with object O, with a leaf marked by item I target pr oblem deﬁned above—with p Boolean features and c items—whose maximum number of slot ﬁlling questions is within M. Such a strategy deﬁnes a BDT whose maximum path length is M as follows: transform the binary tree representing the strategy by substituting each internal-node feature label f Clearly such a BDT is isomorphic to the strategy, hence its depth is M. in the case in which the only transformation is slot ﬁlling; o ne may wonder how representative of the general case such “simple” case is, and whether , such that each test r eturns true for exactly three objects, decide Given an instance of the source problem as above, we construct the target We let the Boolean features be one-one with tests i.e., f= T, for i = of an item Ihas the same value as the one returned by Test T We now prove that there exists a BDT solving an instance of the source “⇒” Suppose there exists such a BDT. Then deﬁne an eﬃcient strategy “⇐” Suppose now that there exists an eﬃcient CRS strategy for t he The above theorem highlights the diﬃculty in optimizing CRS eﬃciency interactions with slot unﬁlling/change could be more eﬃcient than slot ﬁlling, after all. The following theorem shows that the other transfor ma t ions are just “deroutes” from the shortest interaction paths, showing that conversations containing slot unﬁlling/change can always be transformed into conversations containing only slot ﬁlling, whose length is no worse than the initial one. Theorem 2. For every sequence of interactions from U state U interactions f rom a state U tions are o nly substitutions (slot ﬁllings), and whos e number of interactions m is not larger than the initial one, i.e . , m ≤ n. Proo f . If the interaction is already composed by substitutions only, the claim is trivially true; suppose then that there are also slot unﬁlling and slot change interactions. For every contraction σ(v) = x, we focus on the state in which the feat ure contained v. If f Q, let Q from the very beginning. If instead the ﬁlling ha ppened in an intermediate interaction, we just remove the interaction in which f by v. Of course, we eliminate also the subsequent slot unﬁlling interaction. In both cases, the new sequence of interactions is shorter (by 1 or by 2) t han n. We proceed in a similar way a lso for slot changing, a nd repeat the steps until no more such steps are performed. In the end, we obtain a n interaction sequence that starts from U ends with the same satisfying item at U clude the ones in which o nly slot ﬁlling is performed. Such conversations are the lucky ones, because there is no later revision of the slot ﬁllings made. The goal o f the CRS in this case is just to ask the least number of slot ﬁllings leading to one item to propose, and stop. Hence, the a bove theorem evidences the signiﬁcance of o ur NP-hardness reduction for CRS in general. We now make some points a bout this result. 4.1.1. Discussion on the lower bound how it enriches the understanding of t he computational problem of eﬃciency in CRS, thanks to the following observations: + {I}, where I is accep ted by the user, there is another sequence of = τ(Q) where τ(v) = x, that is, we start with the variable unﬁlled The above theorem tells us that the shortest possible conversations in- We stress that we are not interested in the above proof by itself, but in 1. The problem is NP-hard for the case in which each true feature selects 2. Hardness is instead entangled with catalog incompleteness, that is, 3. The proof does not mention how the t r ee is represented, only the deci- 5. The proof does not rely on the existence of more than one user; hence 6. The complexity analysis conﬁrms the intuition that cold start is a worst three items. This means that NP-hardness does not depend on feature entropy, that would be maximal when a feature selects half the catalo g. Moreover, t he stra t egy t hat selects the feature with maximum entropy is only a heuristic, which does not guarantee optima lity. Not e also that since the original reduction [51] is from exact-3-cover, and the more general problem exact-cover is NP-hard too, our problem is NP-hard when a feature selects at least three items. the fact that not all combinations of feature values correspond to an available item; for (although unrealistic) complete catalogs—catalogs in which there is an item for every possible combination of feature values—optimal decision trees can be constructed in time polynomial in the catalog size [53]. sion whether there exists such a tree or no t . Hence, NP-har dness holds also in the case in which the tree is represented implicitly, as a circuit (or a neural network) which, given as input a state of the conversation, suggests the next feature to ﬁll ( usually called a succinct representation [54] of a tree). O(n)—i.e., the number of feat ures is bounded by a (low) polynomial in c. This means tha t NP-hardness shows up even when the number of features p and the number of items are polynomially related. the problem is NP-hard even if we want to devise an eﬃcient strategy only for one particular user (or, equiva lently, for non-personalized CRS). case for CRS. When some feat ures in Q contain a value, or P and N are not empty, this prunes some parts of t he decision tree. Of course, the problem remains NP-hard in the size of the remaining features and items. Many solutions have been pro posed to alleviate such a coldstart problem, however, as in many applications new entries are very 7. Theorems 1 and 2 to gether show that, although the conversation is 4.2. Upper Bounds strategies for CRS. Since generally feature domains contain several values, we represent slot ﬁlling strategies by (general) Decision Trees ( DT), which are trees whose internal nodes can have more than two o ut going edges ( one edge for each possible feature value). Rephrasing the deﬁnition of BDTs of the previous section, a DT for driving the conversation of a CRS contains a feature f in each internal node, a label with a va lue v ﬁlling f in each arc outgoing from the node, and an item in every leaf. An example of a catalog and a possible slot ﬁlling strategy for the conversation (represented as a DT) are given in Table 2. common (new-user and new-item problems), cold-start situations seem unavoidable, and algorithms that implement eﬃcient strategies should cope with such situations. composed by actions of slot ﬁlling, slot unﬁlling and slot change, the problem o f devising an eﬃcie nt strategy is not a probl em of optima l planning of the order of such actions. Slot unﬁlling and slot change are fundamental for another dimension of CRS evalua t ion, namely, eﬀectivene s s: when slot ﬁlling comes to a dead end (an item rejection), only the other two actions may steer the conversation o ut of that dead end, a nd lead to an acceptable alternative recommendation. We now study the upper bound of the complexity of devising eﬃcient to ﬁll the feature in t he node with a preferred value, a nd proceed along the arc labeled with the user’s answer. R epeat until a leaf is reached, which identiﬁes the item to propose. The maximum cost of such a part of the conversation is the maximum number of slot ﬁllings asked to the user—i.e., the depth o f the tree. We recall that the problem of ﬁnding an optimal decision tree (in terms of minimum depth) is trivially NP-complete: it is NP-hard, because it contains BDT optimization (see previous section) as a special case, and it belongs to NP because the DT representing the strategy is polynomial in the size of the catalog. Hence a nondeterministic Turing Machine can compute such a n optimal DT in polynomial time, making nondeterministic choices about which feature labels each internal node. to a set of recommendable items S ⊆ C compatible with the answers given by the user so far; for example, if a user tells the system that one of her most favorite directors is Spielberg, the system concentrates on Spielberg’s movies (the set S) excluding (for the moment) the others. In such a set of items, all possible values in it s domain D movies. Continuing the example, for the items in S the feature f contain a value among Hanks, Duvall, Cruise, etc., but it never contains De Sica, because there are no movies starring De Sica whose director is Spielberg. We call such compatible values Active Values for f More formally, AV (S, f example, once the user’s answers restrict the movies t o the set S of the movies directed by Spielberg, AV (S, f values will be useful both in the rest of this theoretical section, and in the next section regarding experiments. for a strategy using only slot ﬁlling. However, a single D T would be an incomplete strategy for CRS, since it does not consider the possibility of a reject actio n by the user, and consequently, slot unﬁlling and slot change. On the other hand, observe t hat the possible actions of the CRS cannot be mixed in any possible way: inﬁnite loo ps—such as a slot ﬁlling followed immediately by an unﬁlling of the same slot—must be avoided. Hence, in what follows we make a reasonable restriction on possible strategies: every slot unﬁlling (contraction) or slot change (revision) can be performed only if, immediately before them, at least one item has been rejected by the user. The strategy represent ed by the D T is: starting from the root, ask the user Observe that at any g iven point of the conversation, the focus is restricted = Spi e l berg, and each other feature fmay contain only a subset of An algorit hm computing a D T for the catalog C could be used in CRS Such an item can therefore be added to the set N the user dislikes, and will not be proposed again. Recalling that the CRS can propose only items in C − N , this incrementality in N mirrors a reduction of the items to propose, and leads to a trivial upper bound on the possible strategies: each item could be proposed at most once. After all possible items in the catalo g have been proposed and rejected, the conversation must stop. We call such strategies well founded, in analogy with well-founded sets, and we restrict ourselves to them in the analysis below. for a catalog C, which ends in at most M interactions, is a problem that can be solved by exploring recursively all possible transformations, and all active values for a feature in a slot ﬁlling or slot changing transformation. However complex, such an exhaustive exploration needs only polynomial space (the size of the catalog times the size of feature doma ins), and would prove that the problem of devising an optimal strategy is in PSPACE. We prove t his intuition by ﬁrst exhibiting Algorithm 1 below, and then ana lyzing its space complexity. Theorem 3 ( Correctness). Given as input a catalog C of items, a n integer M, and an initial state U there exists a well-found ed strategy fo r the CRS which, starting from U R(U Proo f . First of all, observe that Algorithm 1 terminates, since in every recursive call either the number M decreases, or the set N of disliked items enlarges, or both, leading necessarily t o a base case. Once termination is proved, correctness of Algorithm 1 can be proved by induction on M. For the base cases M ≤ 0 (Line 1), |C − N | ≤ M (Line 3), and user acceptance (Line 7), the result is obviously correct (see also comments aside base cases). Suppose now that the algorithm is correct for any state and interaction bound less than M. can be divided in two branches: ﬁrst one spans Lines 6–37, while second one spans Lines 3 8–48. We refer to these two branches in the rest of the proof. “⇒” Suppose the algorithm terminates with true on input U + R(U ) and M. Either this result comes from the ﬁrst branch, or from the second one; for both branches, in the lines marked with (∃), the algor ithm chose a feature f — and possibly a transformation in case of the ﬁrst branch—such that for any Intuitively, deciding whether or not there exists a well-founded strategy ), ends in at most M interactions. To ease the proof presentation, note t hat the recursive part of Algorithm 1 possible value chosen by the user (in the lines marked with (∀)), all recursive calls value chosen by the user) and m ∈ {M −1, M −2}. By inductive hypothesis, each recursive call ensures the existence of a well-founded strategy f or the CRS which, given U overall strategy o n input U + R(U), M is the one that makes exactly the choice made in (∃), followed by the strategies deﬁned by the recursive calls. “⇐” Suppose t he algorithm terminates with false. This means that in either branch, for any possible choice (feature, transformation) made in (∃)- lines, there is at least one possible choice (feature value v) the user can make in (∀)-lines that makes at least one recursive call end with false on input U+ R(U when the user choo ses v, there is no strategy starting from U ends in at most m interactions. Hence there is no strategy starting from U + R( U ) and ending in M interactions, either. Theorem 4. Given as in put a catalog C of items—with p features and at most K values i n each feature domain—an integer M, and an initial coldstart state U Proo f . As in t he previous proof, we refer to Lines 6–37 as “ﬁrst branch”, while “second bra nch” refers to Lines 38–48. merating features (either Line 18 or Line 39, depending on which branch) and a counter o f ⌈log K⌉ bits for enumerating values in the chosen feature (lines immediately below the above ones). Hence, the space of a single recursive call is O((log p) · (log K)). most p nested calls can be made in the second branch—ﬁlling all p features in Q—after which a single item has been isolated, and the ﬁrst branch must be taken. Each time the ﬁrst branch is taken, at least one item is added to N (in the worst case), reducing the set of items C − N that can be proposed. Clearly, at most |C| calls can recur into the ﬁrst branch. Overall, the recursion terminate with true on input U+ R(U) (where Udepends on the ), m ∈ {M − 1, M − 2}. By inductive hypothesis, this means that First of all, a single recursive call needs a counter of ⌈log p⌉ bits for enu- A bound on the height o f the call stack can be computed as follows: at stack height is bounded by p·|C|, so the total space occupied by the recursion stack is O(p · |C| · (log p) · (log K)). value among K possible ones), needs p · ⌈log K⌉ bit s of encoding, hence the input of a catalog of |C| items has size n = |C| · p · ⌈log K⌉. With respect to such an input size, the stack space is O(n · log p). Now from the product expressing n, it follows that log p < log n, hence O(n · log p) ⊆ O(n · log n). This proves that Algorithm 1 uses polynomial space. whether there exists a strat egy for CRS terminating in a given number of interactions can be solved in Nondeterministic Polynomial Space (NPSPACE), and since NPSPACE = PSPACE [55], the problem belongs to PSPACE, too. Recall that P SP ACE ⊆ EXP T IM E, and in fact, it can be easily seen that Algorithm 1 runs in exponential time in the worst case. 4.3. Improving the upper bound ﬁcient strategies for CRS between NP (lower bound) and PSPACE (upper bound). Since the aim of this paper is to bridge CRS practical eﬃciency with theoretical results, we leave investigation on how to close this g ap to fut ure (more theoretically-o r iented) research. On the practical side, our PSPACE upper bound ensures tha t usual t echniques for solving NP-complete problems, and in particular, ﬁnding optimal DT—e.g., Mixed-Integer Optimization [56], branch-and-bound search [57], SAT and MAXSAT encoding [58]— can be used for devising optimal conversational strategies, but only—as far as our result proves—as steps inside an overall r ecursive procedure, while our NP lower bound ensures t hat employing such techniques is not an overshoot. ular feature value—e.g., “I don’t like gree n phones”, as taken into account in Line 11—this fact rules out all items sharing the same feature value, thus improving the worst case of the strategy. Let us call Protocol P1 the protocol in which the CRS does not ask for disliked values when an item is rejected (i.e., Algor ithm 1 never enters Line 1 1), and call Protocol P2 t he one in which the CRS always asks fo r a disliked value when the user rejects an item, the user provides such a value, and the CRS discards all items sharing the same feature value. Observe now that an item with p features (each feature containing one Combining Theorems 3 and 4, one obtains that the problem of deciding The above lower and upper bounds restrict the complexity of ﬁnding ef- To improve the upper bound, remark t hat when the user rejects a partic- Algorithm 1 ExploreStrategies(C, U, M) in what follows that, in fact, the diﬀerence between P1 and P2 carries over to an improvement in the upper bound of the eﬃciency problem, backing up intuition, but highlighting when such intuition fails. For this part, we recall θ-notation: f or a function f(n), we write f (n) ∈ θ(g(n)) if both f (n) ∈ O(g(n)), and f (n) ∈ Ω(g(n)), i.e., f(n) grows no faster than g(n), but also there are inﬁnitely many (worst) cases in which f (n) grows as fast as g(n). Recall that the relation “∈ θ” between two functions is symmetric and transitive Corollary 1. Let the given data as in Theorem 4, and additionally, suppose the number of values of all feature domains be bounded by a constant K, and |C| ∈ θ(K terminating within M interactions, that applies Protocol P2, is a problem that belongs to POLYLOGSPACE. Proo f . We prove membership in POLYLOGSPACE using the same Algorithm 1 above, plus the fact that in every iteration of the algorithm the condition in Line 11 is satisﬁed, as required by Protocol P2. p combinatio ns of feature values. After K − 1 rejections in Line 11, each ruling out a value for a feature, the number of r emaining items |C − N | is bounded by K eliminated, hence that feature does not count in the exponent). When the values ruled out v the bound is a more complex product most p · (K − 1) rejections and disliked values, all values but one have been ruled out for each feature domain. At t hat point, either the user accepts the last item—the one whose features contain the last remaining value in each domain—or the user rejects it, and in any case the conversation concludes. This means that now the stack height of Algorithm 1 is no more bounded by p · |C| ( where the f actor |C| was the bound on possible rejections) as in the proof of Theorem 4, but is bounded by p · p(K − 1) = p Intuitively, it seems that P2 is always more eﬃcient than P1. We prove Observe that |C| ≤ Ksince there cannot be more items than all possible space needed by the call stack is O(p for constant K. We now prove tha t the above expression implies that space requirements drop to a polynomial in the logarithm of the input. p ∈ θ(log |C|) when K is a constant. Hence, by transitivity the number of nested recursive calls is in θ(log drops to θ ((log |C| · p · ⌈log K⌉, which belongs to θ(|C| · log |C|) in the hypotheses of this theorem, hence lo g n ∈ θ(log |C| + log log |C|) = θ(log |C|). Summing up, the space needed by nondeterministic Algorithm 1 is in O(log Savitch’s theorem [55], implies that the problem complexity now drops to DSP ACE(log O(log the upper bound was expo nentially reduced with respect to PSPACE. Moreover, from the well-known relation P OLY LOGSP ACE ⊆ DT IME(2 (problems solvable by a deterministic algorithm whose time is bounded by a subexponential function, a class which is also known as Quasi-Polynomial time (QP) ), we note that also time upper bounds provably improve over the previous EXPTIME ones whose strategies enforce Protocol P2. However, observe that the above result holds only in the situation in which the input catalog ha s a number of items that gr ows as fast as K features—and K is a constant, hence the input increases because more features f not because each domain D If, instead of considering K as a constant, we would consider p a s a constant, the improvement on the upper bound due to Protocol P2 would not theoretically show up. In other words, when the number p o f features is ﬁxed, and the catalog increases because more possible values are added to each feature, asking to rule out such values one by one (as in Protocol P2) is not provably more eﬃcient than asking to rule out items one by one (as in Pro t ocol P1). Observe that |C| ∈ θ(K) implies by symmetry K∈ θ(|C|), that is, n) space), which is strictly included in POLYLOG SPACE. However complex the class DSP ACE(logn) might seem, observe that Hence, the above result backs up theoretically CRS implementations , f, . . . are added—i.e., more domains D, D, . . . are added— Hence, o ur theoretical analysis points out which characteristics of the catalog must be evaluated when implementing eﬃcient strategies for a CR S: if the catalog is composed by items with few features, and lots of possible values in each feature, there is not yet any theoretical evidence that Protocol P2 yields a tang ible increase in eﬃciency with respect to Protocol P1; if instead the catalog consists of items described by lot s of features, each f eat ure with few values, then P2 improves eﬃciency over P1 in a complexity-theoretical provable way. In the next section, we provide an evidence of such a diﬀerence in a practical setting. Namely, we set up two catalogs IS1, IS2—both derived from real data on movie recommendation—with the characteristics described above, and simulate conversations with users—whose preferences are taken from real user preferences—testing both protocols. The results conﬁrm the theoretical expectatio ns, namely, that the additional steps of Protocol P2 really pay oﬀ only for the second catalog, IS2. 5. Experimental Evaluation alternatives in Algorithm 1—that is, entering or not Line 11—lead to diﬀerent results in terms of the eﬃciency of a CRS, depending on the characteristics of the catalog. More speciﬁcally, a user can take two distinct actions when she rejects a recommendation, and each action corresponds to one of the above-deﬁned protocols: P1 - the user rejects the recommendation and the CRS does not ask the P2 - the user rejects t he recommendation and the CRS asks for a speciﬁc We will describe the details and assumptions of how we simulate the conversations below. The goal of our experimental evaluation is to demonstrate that the two user to provide a speciﬁc reason, i.e., a reason that refers to a disliked feature value. Examples o f such more unspeciﬁc feedback—if any feedback is given at all—could be, “I don’t want to go to the Blue Smoke restaurant” (maybe because a friend of mine repor ted privately to me a bad impression), or “I don’t want to see the movie American Beauty” (because the title sounds silly to me, but I cannot explain this to a system); item characteristic (i.e., feature value) she does not like at all. For example, green color for cellphones, sea-view restaurants, a particular movie director, etc. We assume that a user will truthfully answer such a question when asked. 5.1. Research Hypothes es theoretical analysis provided at the end of Section 4.3. H1 We do not expect a strong diﬀerence in terms of eﬃciency between P1 H2 We do expect a strong diﬀerence in terms of eﬃciency between P1 and which is the independent variable in our experiment. 5.2. Experimental se tting interaction strategies (i.e., protocols) within a system-driv en model: the CRS a sks, the user answers. Examples of corresponding dialogs ar e out lined in Section 5 .3. 5.2.1. Evaluation Metric tions (NQ) the CRS a sks before the user accepts a recommendation. A smaller number of required questions indicates hig her interactio n eﬃciency. This metric, as mentioned above, is commonly used in the CRS literature [37]. 5.2.2. Da tase t and Catalog Description used in recommender-system research, and which contains movie ratings by a larger user community Unfortunately, in this dataset the items do not have textual features associated to them. Therefore, we mapped the MovieLens dataset with DBpedia resources to obtain side information for each item in the cata log. To close this gap we follow the approach of Anelli et al. [59]. We formulate two hypot heses for our experiment aiming to conﬁrm the and P2 when the items in the catalog have few features with a large number of distinct values. P2 when the it ems in the catalog have several f eat ures with few distinct values (i.e., IS2). Basically, the only diﬀerence between H1 and H2 is the item catalo g, We designed an oﬄine experiment that simulates the two above-mentioned In order to evaluate interaction eﬃciency we count the number of ques- In our experiments, we rely on the MovieLens-1M dataset, which is widely Movielens-1MC (with content) edge graph, the number of items became 3,308, and the total number of ratings after the mapping is 511,260. Through the mapping, 279 f eat ures were introduced into the dataset. Each item has one or more of these features expressed by a triple: hItem, Feature, Valuei. As an example, consider the movie The Hateful Eight directed by Quentin Tarantino. For this movie, we have the following triple: hThe Hateful Eight, director, Quentin Tarantinoi. We denoted this data set as MovieLens-1MC - with content in Table 3. MovieLens-1MC: Speciﬁcally, to make the datasets suﬃcient ly diﬀerent and that reﬂect the characteristics described in our research hypotheses, IS1 and IS2 have 4 and 10 features respectively (selected from the 279 content features of Movielens1MC) for each item. For each feature of IS1 there are from 1,500 to 2,500 distinct values, whereas there are about 100 for IS2. The characteristics of the two itemsets are reported in Table 4. that the eﬃciency of diﬀerent strategies depends on itemset cha r acteristics— we make the same assumptions as in Section 3 that (i) values fo r all f eat ur es exist and (ii) that all features have singleton values. Accordingly, we replaced After this processing, since not all the items have a mapping to the knowl- In order t o prove our hypotheses, we built two diﬀerent itemsets from • Itemset1 (IS1) has only a few features, but with a larger number of distinct values and is designed to prove H1 (we do not expect a strong diﬀerence in terms of eﬃciency between P1 and P2 when the items in the catalog have f e w features with a large number of distinct values). • Itemset2 (IS2), in contrast, has a larger number of features, but each of them only has a few distinct values and is designed to prove H2 (we expect a strong diﬀerence in terms of eﬃciency between P1 and P2 when the items in the catalog have several features with few distinct values). In order to focus on the main goal of our experiment—to provide evidence null values with a value randomly chosen from the set of possible values for that feature, and set-valued features (e.g., the movie cast) with a single value randomly chosen among them. Note that f or the purpose of our experiment, this r eplacement does not eﬀect the ﬁnal result. 5.2.3. Experimental Protocol—Details where this lat t er drives the interaction by asking questions to the user about preferred item features and by making recommendations for items. We assume that the simulated user has certain pre-existing preferences regarding item features, and truthfully responds to the system’s questions about these preferences. When provided with a recommendation, the user either rejects it, which means that the dia log continues, or accepts it and the dialog ends. The CRS in our simulation implements one of the described conversation strategies, P1 or P2. Remember that—depending on the cata log characteristics—we expect to see diﬀerences in terms of how many interaction steps are necessary before the dialog successfully ends. is exactly one distinguished item which we call test item or ideal item. This item the user (even if it is not the only item in C that matches the pre-existing general user preferences). Remember here the pre-existing user preferences consist of a number of desired value for features. With respect to the genre feature, a user might for example have a preference for action and romantic movies. When asked by the system for a particular genre preference, the user might therefore state one of the two values. During the conversation, the recommender will only consider such a stated preference when retrieving suitable items S ( as deﬁned in Section 4.2 ) . do not know before the recommendation process which item (movie) they want exactly. Translated to our setting, this means that the user does not know about In our experiment, we simulate conversations between a user and a CRS For the sake of the simulation, we assume that in each conv ersation there In our experiment, we aim to simulate a realistic situation where users it once it is present ed to her based on the stated preferences. As a result, the conversation with the system might often reach a dead end, i.e . , where the system does not recommend stated preferences. In our example, the user might have stated to prefer action movies when asked by the CRS, even if the ideal item romantic movie. Hence, the user has to revise the stat ed preference at some stage so that t he ideal item can be recommended by the CRS. note that in our experiment we simulate a user cold-star t situation, i.e., we are not taking a ny long-term user pro ﬁle into account the during the dialog. Without loss of generality, to avoid the introduction of further notation, in this section we will use f the dia log. We also remember that during the dialog, feat ures are selected randomly. based, we select a set of positively-ra t ed items (PRI) for each user. This set consists of those items tha t the user has ra ted with a value that is greater or equal to their average rating. We use this set PRI for two purposes. First, we simulate a dialog f or each element I o f PRI as an ideal item. Second, we use the items in PRI to determine the pre-existing preferences of a user and simulate their answers t o the questions posed by the system. The user preferences on the feature f f(I) | I ∈ PRI} (fo r U ser Preferences). Therefore, if the user previously liked ac tion and romantic movies, t he set of pre-existing preferences for that feature contain exactly these two values. Remember that since we want the dialog to be successful only in case it ends with the acceptance of conversation the catalog consists of C items in PRI but items the user has already seen before. will ask a question on a feature e.g., “What is your favori te genre?”. The simulated user will then respond by choosing a value from the set UP AV (S, f example, f In order to determine the pre-existing user preferences and the ideal items When the simulated dialog with a deﬁned ideal itemˆI starts, the system ), where AV is the set of Active Values (see Section 4.2). In our during the interaction as it is obtained through the intersection between all the pre-existing preferences for that feature (U P the set of recommendable items S. As a consequence, in o ur simulation t he user cannot answer with a value that is not present in any recommendable object in S. the CRS. If the user, for example, answered to prefer action movies, all movies with a diﬀerent genre are not recommendable anymore at the next stage of the dialog and are then removed from S. We remember that the user does not know about the ideal item I in this session nor its features. Therefore, the choice of the user answer v ∈ UP randomized manner in our experiment. This also avoids the introduction of any bias or any optimization. ask. This may happen in two cases: a) The system has asked the user p questions, with p being the number b) After the user’s answer to the q-th question, with q < p, we have |S| = The user rejects the r ecommendation when I is not present in the list of recommended items. If the recommendation is rejected, the recommended items are removed from the catalog C questions to the user. It is noteworthy that, since we may have more than one item in C dialog, the ﬁnal r ecommendation may contain also a set of items. starts again from a ﬁrst randomly selected feature a nd discards all the values previously selected for each f In protocol P2, in contr ast, the user declares one of the feature values she dislikes in the recommended items. Once the user declares she dislikes a value v for a feature f of f eat ures f fand the following ones f After each user answer, t he set of recommendable items S is updated by A recommendation is shown when the system has no more questions to of f eat ures; 1. In this case, the system recommends the only item in S without asking any explicit preference for the features f—with q < i ≤ p— to the user. In other words, the systems does not try to elicit preferences for the remaining features that have not been asked yet. In case of r ejection P1 and P2 behave diﬀerently. In case of P1, the system selected in the sequence of features f after the user selects a new value v changes a nd, as a consequence, the same happens to UP to select values from U P enters Line 11 in Algorithm 1. item I is in the list of recommendations— the dialog is successfully ended and the simulation continues with a new dialog for another user and/or target item. The simulatio n ends when a dialog was simulated for each element in PRI for every user. 5.3. Running Examples using two ﬁctitio us dialogs. Example 1 (Protocol 1 - The user rejects a recommendation and the item is discarded f rom the dataset.). System: Tell me a ﬁlm score com poser you like, I have these options: Ennio User: I li ke Ennio Morricone. System: Who is one of your most liked actors, in your opinion among User: I li ke Ennio Morricone. System: Do you like Quentin Tarantino as ﬁlm director? User: Yes, I like Quentin Tarantino. System: Based on your answers, I recommend you Django Unchained . What User: Sorry, I don’t want it—a friend of m i ne spoiled the plot for me. The recommendation failed. Django Unchained is removed from the set of recommendable items and the conversation goes on. After several failures the conversation may continue as in the following conversation. (and the remaining features). Regarding feature f, t he user is allowed On the other side, when the recommendation succeeds —when the ideal We show the main diﬀerences between the two protocols deﬁned above Morricone, Alessandro Alessandroni, Paul Sawtell, Frank Skinner. Leo nardo Di Caprio, Clint Eastwood, Gian Maria Volont´e? do you think about it? System: Who is one of your mo s t loved ﬁlm score composers amon g Piero User: I li ke Piero Umiliani. System: Do you like Mario Monicelli as ﬁlm director? User: Yes, I do. I like Mario Monicelli. System: For the above choices , I have movies of the foll owing genres: Com- User: Let’s try comedy movies. System: Which actor/actress would you prefer most among Vittorio Gassman, User: I li ke Vittorio Gassman. System: Based on your answers, I recommend Big Deal on Madonna Street. User: Great, I’ll try this one! The recommendation is successful. The dialog is over. Example 2 (Protocol 2 - The user rejects a recommendation and the CRS asks to declare a disliked feature.). System: What kind of genre do you prefer among Western, Historical and User: I would like to explore Western movies. System: Who is o ne of your favorite ﬁlm score composers? I ha ve these op- User: I li ke Ennio Morricone. System: Who i s one of the best actor among Leo nardo Di Caprio, Clint Umiliani, Armando Trovajoli, Piero Piccioni ? edy, Neorealistic, Historical. Which one would you pref e r? Vittorio De Sica, Sophi a Loren? What do you think? Love Story? tions: Ennio Morricone, Alessandro Alessandroni, Paul Sawtell, Frank Skinner. Eastwood, Gian Maria Volont´e and Tim Roth in your opinion? User: I li ke Leonardo Di Caprio. System: Do you like Quentin Tarantino as ﬁlm director? User: I li ke Leonardo Di Caprio. System: Based on your answers I recommend D j ango Unch a ined. Do you User: No, I don’t. System: With the choices you gave me, I have no more matching movies. User: Ok, let’s f orget about Leonardo Di Cap rio. I als o like Tim Roth. At this point the system discards movies by Leonardo Di Ca prio and concentrates on movies starring Tim Roth. System: Do you like Robert Richardson a s director of photogra p hy? User: Sure, I know Robert Richard son as a good director of photography. System: Would you prefer m o vies that have won an Oscar? User: Yes, I do. System: Based on your answers, I recommend The Hateful Eight. Will you User: Sounds good, I will. The recommendation is successful. The dialog is over. 5.4. Results an d Discussion and I2 ) we compared the two protocols (i.e., P1 and P2 ) and we counted the Number of Questions (NQ) required for reaching the test item and 1b report the average number of questions required to reach a test item (the average is computed on all the conﬁgurations), and the overall maximum number of questions for each prot ocol and itemset. think you’ll like it? Would you mind reconsidering one of your stated preference s? try it out? In t his section we show the exp erimental results. For each itemset (i.e., I1 ferences between the two protocols in terms of number of questions made by the system before reaching and recommending the test item. More speciﬁcally, P1 needs 72.64 as average number of questions with IS1, whereas P2 needs 67.45 questions. The diﬀerence is however huge for IS2 where P1 needs more than 1,000 questions on average t o reach the test item, while P2 needs around 166 questions. Hence, we can conﬁrm that when the items in the catalog have several features with few distinct values, the eﬃciency of P2 grows drastically compared to P1. Also maximum number of questions—reported in Figure 1b for each pair of protocol and itemset—conﬁrms this diﬀerent eﬃciency for IS1 and IS2. combination (P2 with IS1), the number of questions is close to 70, which sounds unrealistic for any real user. It is worth noting that in this experiment we implemented the very worst-case scenario. Our experiment used an unrealistic setting on purpose. In our particular scenario the recommendation ta sk is deliberately very diﬃcult: As expected from the theoretical analysis, with IS1 we observe minor dif- We now discuss the fact that NQ is very large—indeed, also in the best • for each dialog, there is only one test item (true positive) to be found in the cata log and we do not consider the usual possibility that the user our theoretical ﬁndings and we can thus conﬁrm both the research hypotheses H1 and H2. retical analysis, namely that the diﬀerence between protocol P1 and protocol P2 shows up clearly only in a dataset in which there are many features with a small set of diﬀerent values. 6. Summary and Outlook since the late 1990s, we observe an increasing interest in these types of system in recent years in particular due to recent developments in natural language processing. Independent of the interaction modality, eﬃciency in terms of required dialog turns has commonly been a main target of research. So far , however, questions of eﬃciency were almost exclusively investigated in an empirical manner. With this work, we contribute to a better understanding of theoretical properties of conversational recommendation problems and we speciﬁcally address questions related to the computational complexity of ﬁnding eﬃcient dialog strategies. One main insight of our theoretical analysis—which was also conﬁrmed by a computational experiment—is that when designing an eﬃcient conversation strategy, we must always consider the characteristics of the item catalog. O n a more general level, we hope that our work helps to stimulate more theory-oriented research in this ar ea which leads us t o a better understanding of foundational properties of an important class of interactive AI-based systems. ization chosen in our wo r k targets at the predominant class of CRS in the literature—systems that interactively elicit user preferences regar ding item features—and covers a set of common interaction types in these types of would accept several items; • the CRS works in cold-start condition without any user proﬁle, thus several questions are needed for acquiring the user preferences; • the CRS does not implement a cut-oﬀ on the number of questions to ask the user. In conclusion, the results of our experimental evaluation are aligned with In other words, our simulation conﬁrmed what was foreseen by the theo- While conversational approaches to recommendation have been explored Regarding potential f utur e works, remember that the pro blem formalsystems. For the purpose of the current study, we however limited our formalization to two basic types of providing positive or negative preferences: (a) by providing information about individual f eatur e values, and ( b ) by providing feedback for individual items as a whole. In our fut ure work, we plan to extend the formalization to allow users to state preferences on combination of feature values, e.g., “I don’t like open-air Japanese restaurants”, or “I li k e ocean-view, romantic Italian restaurants”. Other simpliﬁcations in our current work that we will address in the future include the consideration of multi-valued features, both in t he queries and the item catalog, and situations where individual item features might be unknown. ture research in the explicit consideration of individual long-term user preferences in t he interactive recommendation process. Technically, this may for example be implemented by the introduction of a function that predicts, based on past behavior of a user, if she will be satisﬁed by a certain item I in the ongoing conversation. The corresponding goal of CRS development would then be to devise eﬃcient strat egies that drive the user towards those items that the system assumes she will most probably choose, again with the aim of optimizing the eﬃciency of the process. Finally, we see another and potentially more far-reaching direction for fu-