Traditional recommendation algorithms develop techniques that can help people to choose desirable items. However, in many real-world applications, along with a set of recommendations, it is also essential to quantify each recommendation’s (un)certainty. The conformal recommender system uses the experience of a user to output a set of recommendations, each associated with a precise conﬁdence value. Given a signiﬁcance level ε, it provides a bound ε on the probability of making a wrong recommendation. The conformal framework uses a key concept called nonconformity measure that measures the strangeness of an item concerning other items. One of the signiﬁcant design challenges of any conformal recommendation framework is integrating nonconformity measures with the recommendation algorithm. This paper introduces an inductive variant of a conformal recommender system. We propose and analyze diﬀerent nonconformity measures in the inductive setting. We also provide theoretical proofs on the error-bound and the time complexity. Extensive empirical analysis on ten benchmark datasets demonstrates that the inductive variant substantially improves the performance in computation time while preserving the accuracy. mender System 1. Introduction the overall success of any online community. In this context, an automatic recommendation has become even more indispensable. Recommender systems are software tools that use past behaviour (usage information) of individuals to provide personalized recommendations for a large variety of available products such as movies, books, music, etc. There have been numerous research proposals on recommendation problem focusing on improving recommendation accuracy [1, 2, 3]. With the upcoming importance on accountability and Venkateswara Rao Kagita, Arun K Pujari, Vineet Padmanabhan, Vikas Kumar Recommending quality services to improve customer satisfaction is of prime concern for explainability of AI techniques, deployment of a plain recommendation whatsoever accurate it may be on a testing platform will not be satisfactory without value additions such as explanations, conﬁdence, or sensitivity. Among the desirable features of the future of recommender systems, providing a conﬁdence measure (or, equivalently, a probable error bound) on recommendation is essential. Most of the existing recommender systems do not oﬀer any such measure to indicate the level of conﬁdence till very recently when the present authors propose Conformal Recommender Systems (CRS) [4]. Though some of the earlier systems endeavour to provide conﬁdence [5, 6, 7], the conﬁdence values so provided are not related to or bound to the error values. On the other hand, Conformal Recommender Systems (CRS) satisﬁes a validity property that ensures that the error value does not exceed a predetermined signiﬁcance level ε. In other words, the correctness-conﬁdence of a recommendation is 1-ε. It is observed that though CRS is an advancement in research in the area of Recommender Systems, the underlying process is computationally intensive and expensive. Having established the point that a valid quantitative measure of conﬁdence can be computed using the principles of conformal prediction, the need arises to provide a computationally eﬃcient method of accomplishing this task. The objective of the present work is to investigate eﬃcient alternative techniques retaining the strength of CRS. This paper proposes an inductive variant of a conformal recommender system that is computationally eﬃcient and retains the validity property of CRS. vector of i a class label y a set of class labels as prediction regions and corresponding probability-bounds of error. A (1-ε) conﬁdence prediction region is deﬁned by the probability that the correct label is not in the prediction region does not exceed ε. To predict the class label of an unclassiﬁed object, say x conformal predictors deﬁne suitable numeric measure to compute a nonconformity measure for each pair of training example and class-label. Intuitively, it is a measure of how well an unknown data x y. This is done by measuring the change in predicting behaviour of S when z The nonconformity measures for all such pairs are analysed to compute p-values and then to determine (1-ε) region subsequently. cess is hinged on the deﬁnition of suitable nonconformity measure. We observe that depending on the context, it is sometimes easier to use a conformity measure instead of a nonconformity measure, though both processes are equivalent intuitively. For the sake of notational convenience, we use the term nonconformity measure to refer to both situations. Second, the measure is required to be computed for all pairs of x termine the p-values. In order to show the relevance and applicability of the principle of conformal prediction, a nonconformity measure is introduced by Kagita et al. [4] in the context of recommender systems using precedence information. Based on the rating data of a set of users on a set of items, a nonconformity measure is calculated for all possible rec- For a set of training examples S = {z, . . . , z}, where zis a pair (x, y) with x∈ Ris a to one of the class labels, say y, based on the available information in terms of S, . The predicting behaviour is observed by applying any of the conventional predictors. Two important observations can be made from the foregoing discussion. First, the proommendations by examining how well the tentative recommendation conforms to all other known recommendations and earlier ratings for any user. The underlying algorithm uses precedence mining as proposed in [8]. A diﬀerent nonconformity measure is deﬁned in [9], wherein the matrix factorization is used as the underlying algorithm. possibilities of deﬁning nonconformity measures in the context of inductive CRS by using the precedence relations among items. As stated earlier, deﬁning a conformity measure is observed to be more relevant than a nonconformity measure in some situations. We adopt diﬀerent probability measures using pairwise precedence statistics characterized by Parameswaran et al. [8] for deﬁning suitable (non)conformity measures. Second, we introduce the concept of inductive conformal recommendation, which is a computationally eﬃcient alternative to the CRS framework. Further, we theoretically and empirically establish the crucial properties of the conformal framework, i.e., validity and eﬃciency. To verify its eﬃcacy, we conducted extensive experiments on seven bench-mark datasets using various standard evaluation metrics. We show that the proposed inductive conformal recommender system improves the computational time while retaining a similar level of accuracy. related work. Section 3 describes the key concepts required to build the proposed system. Section 3.1 presents the background on conformal prediction framework. In Section 3.2, we discuss the underlying precedence mining based recommender systems. We discuss the existing conformal recommender system in Section 4. We introduce the proposed inductive conformal recommender system in Section 5. We report experimental results in Section 6. Finally, Section 7 concludes and indicates several issues for future work. 2. Related Work: Conﬁdence Measure in Recommender System can assist the user in decision making [10, 11]. These systems exploit the user’s consumption experience collected via implicit or explicit feedback data to infer their preferences [12, 13, 14]. However, most of these systems are less transparent because of the unavailability of conﬁdence with which an item is recommended [9, 15]. Despite the enormous application of recommender systems, a limited number of methods are available that associate conﬁdence value with the recommendations. In this section, a brief review of the earlier work concerning conﬁdence measures in the recommender system is presented. Readers’ familiarity with recommender system is assumed here. an elementary conﬁdence computation in existing collaborative ﬁltering algorithms and have shown that a conﬁdence display increases user satisfaction. In [7], the authors have considered the previously collected user’s rating as noisy evidence of the user’s actual rating and proposed a Belief Distribution algorithm that explicitly outputs the uncertainty in each predicted rating along with the predicted rating value. Adomavicius et al. [17] proposed a rating variance-based conﬁdence measure to reﬁne the prediction generated by any traditional recommendation algorithm. Symeonidis et al. [18] constructed a feature proﬁle of The main contributions of the present work are as follows. First, we analyze diﬀerent The rest of the paper is structured as follows. In Section 2, we brieﬂy discuss the Recommender systems are generally employed to provide tailor-made suggestions that To measure the eﬀect of conﬁdence and uncertainty measures, McNee et al. [16] involved each user, and then the prediction is justiﬁed by considering the correlation between users and features. Shani et al. [19] suggested measuring the signiﬁcance level of recommendation by running a signiﬁcance test between the results of diﬀerent recommender algorithms. OrdRec [20] provides a richer expressive power by producing a full probability distribution of the expected item ratings. Mazurowski [5] compared the concept of conﬁdence in collaborative ﬁltering with similar concepts in other ﬁelds within machine learning. Bayesian conﬁdence intervals-based evaluation method has been proposed to measure recommendation algorithms’ performance. The author also proposed three diﬀerent resampling-based methods to estimate the conﬁdence of individual predictions [5]. In [6], for a target user, the conﬁdence in prediction for an item is deﬁned based on k-nearest neighbors of the user. In [15], a content-based fuzzy recommendation model is proposed that utilize similarity and dissimilarity score between user and item for the rating prediction task. For every unknown (user, item)-pair, the prediction conﬁdence is computed based on the diﬀerence between the actual ratings given by that user and their corresponding predictions by the fuzzy model. A recommendation model is proposed in [21] to integrate the trust and certainty information for conﬁdence modeling. Mesas et al. [22] explored the prediction conﬁdence from the perspective of the system. The idea is to embed awareness into the recommendation models that help in deciding the more reliable suggestions rather than all potential recommendations. A Course Recommender system is proposed in [23], where a course-speciﬁc regression model is trained over the course contents and students’ academic interests for the grade predictions. To complement the model predicted grades, the authors have employed an Inductive Conﬁdence Machine (ICM) [24] to construct prediction intervals attune with each student. In [9], two variants of conformal framework, namely transductive and inductive, are proposed in the matrix factorization (MF) setting that associate a conﬁdence score to each predicted rating. The method proposed in [9] can be seen as a two-stage procedure. At ﬁrst, a MFbased model is applied over the partially ﬁlled rating matrix to get the rating prediction for each (user, item)-pair. These predictions are then used to calculate the conﬁdence score for individual predicted ratings. A conﬁdence-aware MF model is proposed in [25], which can be seen as a comprehensive framework that optimizes the accuracy of rating prediction and estimates the conﬁdence over predicted rating simultaneously. Costa et al. [26] proposed an ensemble-based co-training approach for the rating prediction problem. In the co-training phase, two or more recommender algorithms are trained to predict the rating for all unobserved user-item pairs. The training set for the next iteration of the co-training is then augmented with the M most conﬁdent predictions. The conﬁdence is calculated based on the deviation from the baseline estimate and the rating predicted by the recommendation algorithm. However, none of these works provide conﬁdence to the recommendation set. They focus on providing conﬁdence to the individual rating prediction, and it is non-trivial and cumbersome to obtain the conﬁdence of recommendation from conﬁdence regions of point predictions. prediction. The only work that focuses on providing conﬁdence to the recommendation is our previous work on conformal recommender system [4], wherein a conformal framework is introduced for the recommender systems, and a new nonconformity measure is proposed for In this work, we focus on providing conﬁdence to the recommendation, not for rating the conformal recommender system. It is also shown that the proposed nonconformity satisﬁes the desirable properties of conformal prediction, such as exchangeability, validity, and eﬃciency. Nonetheless, the framework proposed in [4] suﬀers from similar shortcomings of traditional conformal predictions and requires high computation times. We brieﬂy describe the approach in the following section. 3. Foundational Concepts main framework we use to build our proposed conﬁdence-based recommender system. We then give a brief description of precedence mining, a collaborative ﬁltering model, on which we apply our conformal prediction framework for producing conﬁdence-based recommendations. 3.1. Conformal Prediction to provide the relevant background. We start with a training example z training set S = {z for unclassiﬁed objects x for each unclassiﬁed object x exceed ε. Let us consider one unclassiﬁed object x a class label y is tentatively assigned to x is a measure of how well z of view, it can be seen as a measure of how well z by measuring the change in predicting behaviour of S when z p-value is the proportion of z all possible values of y (1 −ε)−prediction region. Intuitively, the predicting behaviour is observed by applying any of the conventional predictors which uses S as the training set. The conformal prediction algorithm makes (n+1)×n number of candidate items, and C is the number of class labels. The conformal prediction framework has been well-studied from diﬀerent perspectives in recent years [27, 28, 29, 30]. head [27] of initial proposal of conformal prediction. In an inductive setting the training set S = {z and calibration set S prediction model and the latter is used for computation of p-values. The system uses an underlying conventional prediction algorithm to learn a model using proper training set S The same model is then used to determine (non)conformity measures and p-value for every example in S model only once, leading to a signiﬁcant reduction in computation time and eﬀort. In this section, we ﬁrst introduce the basic concepts related to conformal prediction, the In this section, a brief account of the principle of conformal prediction is reported in order is a feature vector of iexample and yis the corresponding class label. Given the On the other hand, the inductive conformal framework avoids the computational over- , . . . , z} is divided into two sets, namely proper training set S= {z, z, . . . , z} Example 1. Consider a problem of classifying samples as cancerous (+ve) or noncancerous (−ve) based on the tumor size and other pathological features. Let x vector describing an i S = {(x ferent individuals. Given the new instance, say x or −ve. Assume, Support Vector Machine (SVM) is the underlying classiﬁer that also assigns a nonconformity value as the deviation between the actual and the predicted class label. The conformal prediction framework labels the new instance with all possible classes and sees which conforms more to the existing ones. At ﬁrst, it considers z adds it to the training set. After that the the SVM classiﬁer is trained for each i with the training set {S ∪ z conformity (α other label NC, i.e., for (x prediction region includes the labels with a p-value greater than the signiﬁcance level ε. We can also observe that for the given example, the conformal predictor requires training of 22 11 × 2 = (n + 1) × C would be (n + 1) × C × n namely proper training set S Sand uses the same to evaluate the nonconformity of S one SVM classiﬁer is learnt using the set S it is n computation time. 3.2. Precedence Mining based Recommender Systems [8] maintains precedence statistics, i.e., the temporal count of all the pairs of items. The precedence mining model estimates the probability of future consumption based on past behaviour. For example, a person who has seen Godfather I is more likely to watch Godfather II in the future. In most of the traditional CF techniques, the aim is to ﬁnd users having similar proﬁles as the active user u, and then restrict its search to items consumed by this subset of users and not consumed by u. Thus, certain consumption patterns of items exhibited by the whole set of users are not captured as the search is restricted. The precedence mining model overcomes these shortcomings and attempts to capture pairwise precedence relations frequently occurring among all users. It calculates a recommendation score for each item based on the precedence statistics, and then the set of items having scores greater than the threshold are recommended. Example 2. Figure 1 shows the diﬀerence between traditional collaborative ﬁltering and precedence mining. The leftmost table in the ﬁgure is a toy example in which we provide the proﬁles of diﬀerent users. Let u interpreted as a sequence of movies that the user has watched. For instance, u , y), (x, y), . . . , (x, y)} be the training set containing observations of ten dif- =. The conformal predictor repeats the same procedure concerning an- On the other hand, the Inductive Conformal Predictor divides the dataset into two sets, × (|S| + C), which is a drastic improvement over conformal predictor in terms of The precedence mining model [8] is a Collaborative Filtering (CF) based model that movies m working of collaborative ﬁltering. Here, we assume that the set of users who have at least two movies in common with the active user are in its neighbours. The most popular movie among the neighbours are then recommended to the active user. A careful observation of Figure 1 reveals that the movie m collaborative ﬁltering recommends movie m of items in collaborative ﬁltering is limited to the neighbours space. In contrast, precedence mining looks for patterns in which one item follows the other in the whole user space. The rightmost image in the Figure 1 demonstrates the idea of precedence mining. We highlight the patterns that occur at least thrice using diﬀerent colors, for instance, m dence relations among items consumed by users and thereafter recommends new items having high relevance score computed using precedence statistics. The nicety and novelty of this approach is the use of pairwise precedence relations between items. We describe the score computation formally as follows. of users. profile(u be the set of items consumed by u items to a user based on proﬁles of diﬀerent users. A recommender system aims at selecting items for recommendation such that these items are absent in profile(u) and are expectedly preferred to other items by the user for whom it is recommended. Let Support(o number of users that have consumed item o of users having consumed item o preceding o Recommender systems based on precedence relations is concerned with mining prece- Let O = {o, o, . . . , o} be the set of items and U = {u, u, . . . , u} be the set The objects with high score are recommended. If the score for a given unutilized item is low, it is highly unlikely to be of interest to the user. We now consider an example which illustrates the working of the preceding precedence mining based recommender system. Example 3. Consider the following PrecedenceCount and Support statistics calculated based on the preferences given by thirty users U = {u Let u u, the candidate items for recommendation are O \ O an item o Similarly, Score(o Score(o is zero, the whole score becomes zero. To avoid this problem, Parameswaran et al. [8] proposed to consider only top-I precedence probabilities in the product term, where I is a hyper-parameter to tune. In our experiments, we have ﬁne tune the value I to be 1. 4. Conformal Recommender System brieﬂy report the proposal of CRS. The readers are requested to refer [4] for details. Let O be the set of items, n signiﬁcance level ε, the problem is to recommend a set of items Γ , o, . . . , o}. be the target user and O= {o, o, o, o, o} be set of items consumed by u. For , u) =× P P (o| o) × P P (o| o) × P P (o| o) × P P (o| o) × P P (o| o) , u) = 0.0028. Hence, it ranks the items in the order of o, o, o, o, and The problem with this approach is even if one of the precedence probabilities (PPs) The principle of conformal prediction is applied to recommender system in [4]. Here, we = {o, o, . . . , o} be the set of items consumed by a user u. Given O, u, O, and the For a given user u The ﬁrst set O are not part of the training set. The conformal recommendation process is to determine the conﬁdence measure of recommending a new object o is to see how well the object o each o the proﬁle is O mendability of c chance of being recommended. The Score is calculated with reference to each of h and for each tentative proﬁle O Deﬁnition 1. (CRS nonconformity measure [4]). Given a subset O set of objects O and are not part of the training set; and a new object o A(o the proportion of examples with α p-value from several p-values. If the selected p-value is greater than ε, then o in the (1 − ε) conﬁdence recommendation region. The procedure is repeated for every new item o Example 4. We consider the precedence statistics given in Example 3 for this example also. Let O recommendation. We append o an item o using the proﬁle O recommendability of o , c, . . . , c}, of candidate items that are consumed by uafter use of items in Oand = {Oo} be the appended set. Nonconformity measure is computed for ∈ Oby ignoring oin Oand examining the recommendability of cwhen With precedence mining [31, 32, 33] as the underlying algorithm, the measure of recom- , o, . . . , o) w.r.t. c∈ Ois (α, α, . . . , α), where α= Score(c, u). The computed nonconformity scores α, h ∈ [1, n + 1] are used to compute the p-value as , i ≥ 1 to get (1 − ε) conﬁdence recommendation set. = {o, o, o} ⊂ Oand O= {o, o}. Let obe the candidate item for α= Score(o, u) =× P P (o| o) × P P (o| o) × P P (o| o) Similarly, Nonconformity score of o of o ois computed as follows. Similarly, we compute the p-value of o 0.75. In order to get the ﬁnal p-value from p(o maximum strategy and CRS-med [4] employs a median strategy. Therefore, the ﬁnal p-value according to CRS-max and CRS-med are 1 and 0.875 respectively. Similarly, we compute the p-value for all the candidate items for recommendation and recommend the items whose p-value is greater than ε with the conﬁdence of (1 − ε). 5. Inductive Conformal Recommender System gauge the conﬁdence of recommendations. The proposed conformal approach determines a recommendation set Γ otal component of the conformal framework is the nonconformity measure quantifying the reliability in prediction. We use precedence relations among the items to determine the nonconformity score. Precedence relations capture the temporal patterns in user transactions. Besides, precedence relations based recommender systems do not require rating information, which is indeed challenging to obtain in a real-time scenario. Furthermore, these systems are ranking systems and thus allow us to deﬁne conﬁdence for recommendation instead of a rating prediction. These are the various reasons for choosing precedence relations to represent nonconformity measures. set O the set of items known to be consumed after O the (non)conformity measure for every item in the calibration set along with a new item better than or equal to that of a new item. Subsequently, we include item o recommendation region if the p-value of o (non)conformity measures to determine the conformity or strangeness of an object concerning the training set. Subsection 5.2 deﬁnes p-value, which quantiﬁes the conformity = Score(o, u) =× P P (o| o) × P P (o| o) × P P (o| o) == 0.043. is α= Score(o, u) = 0.031. The p-value of oconcerning the recommendability of This section presents the proposed inductive conformal recommender system (ICRS) to The brief idea of the proposed approach is as follows. We split Ointo proper training = {o, o, . . . , o} and calibration set O= {o, o, . . . , o}, wherein Ois and determine o’s p-value: the proportion of items having (non)conformity score The following subsections elaborate on the notions of (non)conformity measures and the score of a new item concerning the training set of items and deﬁnes the recommendation set describes the proposed algorithm. In Subsection 5.4, we describe the two important measures of any conformal prediction framework, validity and eﬃciency, in the recommender systems setting. Finally, we proﬀer theoretical time complexity analysis of the proposed approach against the existing methods in Subsection 5.5. 5.1. Nonconformity Measures tion with the proper training set in terms of a scalar value. There are several ways traditional algorithms can construct nonconformity measures; each of these measures deﬁnes a unique ICRS. It is worth mentioning that a particular (non)conformity measure only aﬀects the ICRS model’s eﬃciency, and the validity of the results remains unaﬀected. We propose diﬀerent conformity/nonconformity measures in this section and analyze the eﬃciency. We use precedence count P C(o precedence relation among items to deﬁne various (non)conformity measures. When we compute these quantities for each item in the user proﬁle, we get multiple values. We use diﬀerent aggregation techniques as a design choice to calculate the (non)conformity value using multiple precedence statistics. For the simplicity of notations, we refer to conformity measure as CM and nonconformity measure as NCM in the subsequent discussion. relevance of an item to the user proﬁle to establish the ﬁrst conformity measure. We deﬁne the conformity score of an item o where the algorithm for diﬀerent I values and take I as 1 in the experiments. The score is high when it conforms more to the training set. Note that every measure that we deﬁne here is with respect to a target user u the precedence count of an item with the set of items consumed by the user. The precedence count (P C(o after o o. Hence, we use precedence count to determine a conformity measure. We compute the precedence count of an item o then aggregate them to get a numerical score. Using the diﬀerent aggregation strategies such as minimum, median, mean and maximum, we arrive at the following conformity measures: CM2, CM3, CM4, and CM5, respectively. The detailed formulation of these measures is given in Annexure 1. We also use the precedence probability of an object with respect to the user proﬁle to determine the conformity score of an object. Precedence probability P P (o o) of an item o Hence, we use precedence probabilities of an item o with (1 − ε) conﬁdence. Subsection 5.3 gives the ﬂowchart of the proposed system and Nonconformity measure is a measurable function A that determines a new object’s rela- We adapt the score function proposed by Parameswaran et al. [8] that estimates the in user proﬁles. The higher the number, the more likely it is that oappears after user proﬁle to deﬁne the conformity measures. We again use diﬀerent aggregation strategies to summarize the precedence probability scores of o user proﬁle. The process resulted in four diﬀerent conformity scores, CM6 (minimum), CM7 (median), CM8(mean), and CM9(maximum) with the corresponding aggregation operator mentioned in the brackets. The detailed formulation is given in Annexure 1. We then employ probability of o determine the conformity score of an item o this score with respect to each and every item in the training data and employ diﬀerent aggregation strategies resulting in four diﬀerent conformity scores, CM10 (minimum), CM11 (median), CM12(mean), and CM13(maximum). Finally, we consider the probability that an item o potential nonconformity measure for an item o proﬁle/training set, we use diﬀerent aggregation strategies and deﬁne the nonconformity measures NCM14, NCM15, NCM16, and NCM17 as given in Annexure 1. Lemma 1. (Non)conformity of items {o any permutation π of {m+1, . . . , n+1} i.e., A(o ⇒ A(o Proof. It is easy to see that the nonconformity scores are invariant of permutation π of the calibration set {o changing the permutation of a calibration set does not eﬀect the nonconformity scores and remains the same. Therefore the proposed (non)conformity scores are invariant of permutation of {o Algorithm 1: Inductive Conformal Recommender Systems. , . . . , o}. All the proposed conformity/nonconformity measures are independent of Input: O, target user u, O, ε Output: Recommendation set (Γ) split Ointo two sets Oand O; Γ← ∅ ; for each oin Odo Compute αusing any of the (non)conformity measures; end for each o ∈ O \ Odo Compute (non)conformity score of an item o; Compute p(o) using Equation 4 or 5; if p(o) > ε then Γ← Γ∪ {o} ; end 5.2. p-value and Recommendation Set measures, the proportion of examples having a nonconformity value greater than the new example deﬁnes the p-value, In the case of conformity measure, we deﬁne it as the proportion of examples having conformity value less than the new example, For a target user u value for every unused item. All the items whose p-value is greater than the predetermined signiﬁcance level ε will form a recommendation region Γ 5.3. Algorithm sections. Algorithm 1 outlines the main ﬂow of the proposed method. At ﬁrst, we divide the dataset into a proper training set and calibration set. Next, we compute every item’s nonconformity value in the calibration set and for every candidate item. We then compute the p-value for every candidate item and determine the recommendation set. The ﬂowchart of the proposed algorithm is shown in Figure 2. Example 5. We consider the precedence statistics given in Example 3. We divide the target user u Let αbe the conformity or nonconformity value of an item o. For nonconformity In this section, we describe the algorithm by using the concepts deﬁned in the previous proﬁle into O= {o, o, o} and O= {o, o}. Let us compute the nonconformity values, and p-value with respect to o similar for other (non)conformity measures also. We can compute the p-value for all the other candidate items and include those items whose p-value is greater than ε in the recommendation set. 5.4. Validity and Eﬃciency invariant property in Lemma 1. Hence, following the line of argument given by Vovk et al. [34], it is easy to see that our proposed method ICRS satisﬁes the validity property. Lemma 2. If objects o in terms of their precedence relations with individual items in the history, then the probability of error that o Proof. An error occurs when P(o elements of the set {α precedence relations with the set of items consumed by an user, all permutations of the set largest elements does not exceed ε, which is therefore the probability of error. mendation set. In the conformal framework setting, a narrow set with higher conﬁdence is more eﬃcient. We empirically analyze the validity and eﬃciency properties in Section 6. 5.5. Time Complexity Analysis ductive conformal recommender systems [4] and the underlying precedence mining based algorithm [8]. For simplicity, we assume that the calibration set size is the same as that of candidate-set (|O m is the size of the proper training set, and l is the calibration set size. Let n number of candidate items i.e., n formity scores varies from measure to measure, we assume it to be O(t). With O(t) as the complexity of nonconformity measure, the inductive conformal predictor takes O((l + n time complexity to determine all the required p-values and make recommendations. On the other hand, transductive conformal recommender systems take O(n ) =× top1P P (o| o), P P (o| o), P P (o| o)=×= 0.23. We have already shown that the (non)conformity measures deﬁned above satisfy the , . . . , α} are equiprobable. Thus, the probability that αis among the bε(l + 1)c In addition to satisfying the validity property, it is desirable to have an eﬃcient recom- In this section, we analyze the time complexity of the proposed method against trans- O(t) as the nonconformity measure’s complexity. Kagita et al. [4] reduce it to O(n using the relation between the score and precedence probability, but it is higher than the inductive conformal recommender system. The complexity of the precedence mining based recommender system is O(n Recommender System (ICRS). We provide an in-depth quantitative evaluation with regard to the prediction accuracy and running time on seven real-world datasets of varying size. The characteristics of these datasets are reported in Table 1. In all our experiments, we converted the multi-class (diﬀerent ratings) datasets into one class by setting a threshold to 0. The prediction accuracy of the comparing algorithms are evaluated based on the ranking-based performance metrics that is Average Precision (AP), Area Under Curve (AUC), Normalized Discounted Cumulative Gain (NDCG) and Reverse Reciprocal (RR). We also evaluated the performance based on top-K recommendation metrics that is Precion@K, Recall@K and F1@K [35]. We compared our proposed method ICRS with the underlying Precedence Mining Model [8] and the Conformal Recommender Systems (CRS-max and CRS-med) [4]. In ICRS, to ﬁne-tune the values of parameters n and k, we experimented with diﬀerent combinations and selected n to be 30% of the proﬁle and k to be 30% and the remaining 40% is the test data. All the results reported here are the average of 500 randomly selected instances. We use a notation ICRS < x > to denote an inductive conformal recommender system that uses (non)conformity measure x. For example, ICRS1 uses conformity measure 1 (CM1). imental evaluation of the validity and eﬃciency of the proposed methods. Section 6.2 report comparative experimental results in terms of ranking-based metrics, top-k recommendation metrics and execution time. In this section, we empirically evaluate the eﬃcacy of proposed Inductive Conformal The remainder of the section is structured as follows. In Section 6.1, we report the exper- We adapt the deﬁnitions of validity and eﬃciency given by Kagita et al. [4]. Figure 3 and Figure 4 shows the validity and eﬃciency of the proposed approach respectively, over seven diﬀerent datasets. We report the validity and eﬃciency related to ICRS1, ICRS3, ICRS7, ICRS11 and ICRS15 in the relative bound of ε. Figure 4 reports the error related to eﬃciency. It can be seen from the ﬁgures that even for smaller values of ε, most of the irrelevant items are ﬁltered out hence, resulting in a small error. We also observed that, for higher values of ε, the recommendation set is more informative for all the strategies. 6.2. Comparative Analysis achieve comparable results with signiﬁcantly reduced execution times. Table 3 gives the ﬁndings related to ranking-based evaluation measures over seven datasets. Each result is composed of mean and rank. The rank reﬂects relative performance of an algorithm over a dataset for a given evaluation measure. In the case of ties, we have assigned the average rank. Furthermore, the entries in boldface highlight best results among all the algorithms being compared. test which is widely-accepted as the favorable statistical test for comparing more than two This subsection empirically evaluates the validity and eﬃciency of the proposed approach. In this section, we carried out experiments to demonstrate that the proposed methods To carry out comparative analysis in more well-founded ways, we employed Friedman algorithms over multiple data sets [36]. For each evaluation criterion, Friedman statistics signiﬁcance level α = 0.05, Friedman test rejects the null hypothesis of “equal” performance for each evaluation metric. This leads to the use of post-hoc tests to assess the pairwise diﬀerences between two algorithms within a multiple comparison test. We use the Nemenyi test to check whether the proposed methods achieves a competitive performance against the algorithms being compared [36]. The performance of two algorithms is signiﬁcantly diﬀerent if the corresponding average ranks diﬀer by at least the critical diﬀerence CD = q where the value q test with K = 20, we have q 11.2065 [36]. of each comparing algorithm is marked along the axis (lower ranks to the left). It can be seen from the Figure 5 that the proposed methods achieve better performance than CRS-Med and the corresponding critical value are reported in Table 2. It can be observed that at Figure 5 gives the CD diagrams [36] for each evaluation criterion, where the average rank and Precedence Mining models over most of the evaluation metrics. We can also observe that the proposed approaches achieve similar performance to CRS-Max or even derive a better rank in most cases, especially the median-based inductive approaches (ICRS3,ICRS7, ICRS11, and ICRS15 ) and mean-based inductive approaches (ICRS4,ICRS8, ICRS12, and ICRS16 ). We have also observed similar results with Maximum strategy based methods (ICRS1, ICRS5, ICRS9, ICRS13, and ICRS17 ), whereas Minimum strategy based approaches (ICRS2, ICRS6, ICRS10, and ICRS14 ) performing poorly among the seventeen proposed approaches. This comprehensive analysis reveals that Median and Mean-based approaches capture the true precedence relations of a new item with respect to a user proﬁle compared to the Minimum strategy. The reason could be that sometimes there is a higher chance of a user consuming items that are not of his regular interest but due to other users’ inﬂuence (like family, friends, etc.) or situational context . These items do not follow good precedence relations with users’ actual interests. Therefore, it is evident that there is a higher chance of minimum-based strategies capturing such precedence relations and that do not represent the allure of a new item concerning the user proﬁle. In other words, there may be some noisy/outlier points in the user proﬁle, and minimum-based strategies are more attractive to these points and therefore not suitable to measure (non)conformity. Though the same could be valid with the Maximum based strategies, it is more likely that even a single item in the proﬁle can inﬂuence to consume another item that follows higher precedence relations. For example, a Deep Learning course may have a higher precedence relation with a Machine Learning course, and that could be an inﬂuencing factor for a student to opt for a Deep Learning course irrespective of other courses in the student proﬁle. Experiment results corroborate our claims. mendation measures, namely precision@10, recall@10 and F1@10 (Figure 6). We observe the similar results with varying the number of recommendations. It can be observed from the ﬁgures that conformal approaches methods outperform the underlying precedence mining model. Furthermore, ﬁndings reveal that inductive variants are comparable with the CRS-max and CRS-med. Finally, we compared the execution time (in milliseconds) of the diﬀerent approaches. It can be seen from the Figure 7 that the inductive conformal recommender systems are much faster than traditional conformal recommender systems and better than the precedence mining model. Altogether, the results corroborate our claim that the inductive variant achieves a similar level of accuracy compared to its counterparts but signiﬁcantly reduces the execution time. 7. Conclusions and Future Work that complements the recommendation by quantifying the (un)reliability in predictions. One natural limitation with the existing transductive variants is the computation time that prevents their applicability in the time constraint domains. We address this limitation and propose an inductive variant that maintains the same moderate level of predictive accuracy but reduces the computation time to a large extent. Our conformal approach exempliﬁes In the second set of experiments, we compare the performance in terms of top-k recom- In this paper, we propose an inductive variants of the conformal recommender system conﬁdence in terms of the bounds on the error. Conformity/nonconformity measures are key component of any conformal recommendation framework, and the prediction accuracy largely depends on how well these measures are deﬁned. In this work, we examined sevneteen diﬀerent (non)conformity measures using the precedence relations among objects. We theoretically proved that the proposed (non)conformity measures adhere to the principle of validity under certain assumptions. Further, we emphasized our theoretical results with an empirical demonstration. Rigorous experiments on several real-world datasets demonstrated that the inductive conformal recommendation algorithms outperform the precedence mining based recommender system and non-inductive methods in terms of execution time. We observed that a few of the inductive variants outperforming the other approaches in terms of other crucial measures of the recommender system when the basic assumptions of the model are satisﬁed. conﬁdence in diﬀerent recommendation models by determining suitable (non)conformity measures is one of the exacting directions for enthusiastic researchers. Investigating the conformal prediction for group recommender systems is a direction worth studying. Exploring the conformal approach for diﬀerent matrix factorization-based methods is another exciting direction to pursue. Kumar is supported by the Start-up Research Grant (SRG) under grant number SRG/2021/001931 and the Faculty Research Programme Grant, University of Delhi under grant number IoE/2021/12/FRP. We would also like to thank the anonymous reviewers whose comments/suggestions helped improve and clarify this manuscript to a large extent. The current proposal sets a lot of scope for future research. Attaining the notion of Venkateswara Rao Kagita is supported by the NITW-RSM grant, NIT Warangal. Vikas