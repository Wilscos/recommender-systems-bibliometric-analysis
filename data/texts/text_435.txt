As a critical task for large-scale commercial recommender systems, reranking has shown the potential of improving recommendation results by uncovering mutual inuence among items. Reranking rearranges items in the initial ranking lists from the previous ranking stage to better meet users’ demands. However, rather than considering the context of initial lists as most existing methods do, an ideal reranking algorithm should consider the counterfactual context – the position and the alignment of the items in the reranked lists. In this work, we propose a novel pairwise reranking framework, Context-aware Reranking with Utility Maximization for recommendation (CRUM), which maximizes the overall utility after reranking eciently. Specically, we rst design a utility-oriented evaluator, which applies Bi-LSTM and graph attention mechanism to estimate the listwise utility via the counterfactual context modeling. Then, under the guidance of the evaluator, we propose a pairwise reranker model to nd the most suitable position for each item by swapping misplaced item pairs. Extensive experiments on two benchmark datasets and a proprietary real-world dataset demonstrate that CRUM signicantly outperforms the state-of-the-art models in terms of both relevance-based metrics and utility-based metrics. Recommender System, Reranking, Utility Maximization, Implicit Feedback Recommender System (RS) has been widely deployed in websites and mobile applications, including e-commerce [7,35], videos [7, 14], and news [9,19]. A commercial RS consists of three stages in general, i.e., candidate generation, ranking, and reranking. Thousands of relevant candidates are surfaced in the candidate generation stage, followed by a ranking function to score and select top items in the ranking stage. The last reranking stage further rearranges items in the initial ranking lists from the previous stage by Figure 1: Comparison between evaluation before and after reranking methods. attending to mutual inuence between items, the results of which directly aect user satisfaction as well as the revenue of the RS. Recent attention is increasingly focused on the reranking stage due to its desired outcomes [1, 21, 24, 25]. Foundational work in reranking has shown the potential of improving recommendation results by uncovering mutual inuence among items [1,2,21,25]. In fact, how likely a user favors an item is aected by other items placing in the same list. As such, existing reranking algorithms have focused primarily on designing sophisticated models like recurrent neural networks (RNN) [1,2], Transformer [24,25], or graph neural networks (GNN) [21] to extract such mutual inuences based on the context of initial ranking lists. However, an ideal reranking algorithm, we posit, should be aware of the current item’s position and the alignment of other items in the reranked lists – referred to as the counterfactual context – rather than the input initial lists. The counterfactual context describes where we permutate the initial ranking lists and obtain the lists that have never been displayed to users by the system. Therefore, we are interested in learning from counterfactual context for reranking. The user’s listwise utility (e.g., total clicks or revenue) is inuenced not only by the relevance of items but also by the locations and surrounding items [17,22,23,32], so that even with the same set of items, the listwise utility varies with dierent permutations. Yet current works estimate the utility simply based on the context of the initial lists and then rerank the items by their estimated scores following a greedy strategy, ignoring the fact that such reranking operation already modies the actual utility. We refer to this type of reranking model as the evaluationbefore-reranking method. On the one hand, the utility is sensitive to positions. Evaluation-before-reranking methods, however, only use the initial position information, leading to its failure in modeling the item’s utility in other positions. On the other hand, the reranking operation usually changes the neighboring items, bringing dierent mutual inuences between items from the original list. As shown in Figure 1, for an initial ranking list (dental cares, chocolate, milk), the evaluation-before-reranking methods predict the utility directly under the context of such an initial list and the estimated value is(0.47, 0.5, 0.36). Then the items are greedily reranked. However,0.47represents the utility when dental cares are placed at position1, before chocolate and milk. Once we place dental cares at position2according to the descending order of estimated utility, the context of dental cares is modied, which makes the previous estimation imprecise. To this end, we aim to maximize the overall utility after reranking by nding the optimal permutation with dierent counterfactual contexts. Such an objective indicates that we cannot adopt an evaluation-before-reranking approach but an evaluation-afterreranking approach. Figure 1 presents an example. The evaluationafter-reranking approach rst generates feasible candidate reranked lists, e.g., by swapping two items in the initial list. Then the utility is evaluated according to the current counterfactual context, and the list with maximal overall utility is chosen. However, this brings the following two new challenges to the reranking stage: 1)Evaluation after reranking.Users’ feedback on counterfactual context is unobtainable, as it is impractical to ask users to provide feedback for every permutation of a given list. Therefore, the key concern is how to estimate the utility of the reranked lists precisely according to the dierence between observed context and counterfactual context. 2)Exponential time complexity.Directly nding the optimal reranking list with counterfactual context is a combinatorial optimization problem and has 𝑛!feasible permutations. Generating and evaluating all possible permutations at the inference stage is computationally expensive. To resolve the aforementioned issues, we propose a pairwise reranking framework, Context-aware Reranking with Utility Maximization for recommendation (CRUM), which consists of a positionaware graph embedding, a utility-oriented evaluator, and a reranker. Firstly, to capture the interaction information between items and positions, we construct a novel positional graph and extract the position-aware graph embedding. Next, the utility-oriented evaluator evaluates the new reranked list by modeling the sequential browsing of users and outputs the listwise utility to solve the challenge of evaluation after reranking. Lastly, the reranker derives feasible reranked lists by swapping pairs of items with the guidance of the evaluator. Instead of generating all the permutations, we only adjust the mismatched pairs towards the optimal ranking. We compare the utility given by the evaluator before and after the swap of two items, and update the model with an ecient Lambdaloss framework. Lists are reranked via a well-designed scoring function, which reduces the computation complexity from𝑂 (𝑛!)to𝑂 (𝑛)at the inference stage, and thus solves the challenge of exponential time complexity. To summarize, the contributions of our work are as follows: •We highlight the necessity of leveraging counterfactual context to evaluate the listwise utility after reranking for more precise estimation. We develop a general evaluation-after-reranking solution to learn the reranking strategy for optimizing the overall utility. •To avoid exponential solutions, we propose a novel utility-oriented reranking framework, CRUM, with the position-aware graph embedding to extract mutual inuence between items and positions, an evaluator to estimate the listwise utility using counterfactual context, and a pairwise reranker to nd the most suitable position after reranking for items in a perspective of swap. •Extensive experiments are conducted on two widely-used public datasets and a proprietary real-world recommendation dataset. Those experiments demonstrate the eectiveness of CRUM, which outperforms the state-of-the-art models w.r.t both relevancebased metrics like MAP and utility-based metrics like CTR. The reranking stage is built on initial rankings given by the ranking stage. Learning to rank that applies machine learning algorithms is one of the most widely used methods in ranking stage. According to the loss function, it can be broadly classied into pointmethods. The pointwise methods, e.g., McRank [20] and PRank [8], regard ranking as a classication or regression problem and predict an item’s relevance score at a time. The pairwise methods like SVMRank convert the ranking to a pairwise classication problem to optimize the relative positions of two items. The listwise methods directly maximize ranking metrics of lists. For example, LambdaMART [5] combines boost tree model MART [11,12] and LambdaRank [3] to optimize NDCG directly. In the experiment part of this paper, we discuss how dierent types of learning-to-rank methods aect the performance of the reranking models. Compared to ranking methods, reranking methods utilize initial lists and emphasize the mutual inuence between items. Depending on how to model the mutual inuence of items, these methods can be roughly divided into three categories: RNN-based [1,2,10], Transformer-based [24, 25], and GNN-based [21] methods. RNN-based methods apply RNN to model the item interaction and implicitly extract positional information from the initial ranking. DLCM [1] applies GRU to encode the whole ranking list into the representation of items. Seq2Slate [2] uses pointer network with a decoder to directly generates the ranked list. PRS [10] consists of PMatch and PRank, where PMatch obtains the candidate lists and PRank adopts Bi-LSTM to evaluate lists. However, it is heuristic without a learnable scoring function. Moreover, its high computational complexity for online inference limits its applications. Due to Transformer’s ability to model the interaction between any two items in𝑂 (1)distance, PRM [25] adopts it to encode the mutual inuences between items. SetRank [24] employs multi-head self-attention blocks to capture the local context information and permutation-equivalent representations of items. Usually, position embedding or a designed position embedding function is employed in these Transformer-based models. The GNN-based model IRGPR [21] explicitly models item relationships by recursively aggregating relational information from multi-hop neighborhoods. Though this work makes advances, the required additional item relationship restricts its usage to specic applications like e-commerce. To summarize, above models employ sophisticated mechanisms to model the mutual inuence between items. Whereas most of them belong to evaluation-before-reranking approaches. The only exception, PRS [10], is heuristic and has relatively high complexity. Unlike previous works, our model not only considers counterfactual context, but also learns a scoring function to reduce complexity. A reranking model generally aims at generating better ranking lists by making use of initial ranking lists arranged by the previous ranker. Given a user’s request𝑟 ∈ R, the initial ranker returns an initial ranked list. Then, the reranking model reranks the initial list and generates a list that better meets the user’s need. Mathematically, We denote list interaction logs for user’s request𝑟that the reranking model uses asS = {(x, 𝑏, 𝑘, 𝑐)}, whereS contains𝑛items and each item𝑖is associated with a feature vector x∈ Rand a utility value𝑏∈ R(e.g.,𝑏can be the bid price of each ad in sponsored search). We denote the initial position of item 𝑖as𝑘and𝑐is user’s implicit feedback on item𝑖at position𝑘, i.e., 𝑐= 1 for click and 𝑐= 0 for non-click. The target of reranking is to present better item arrangements than those produced by the initial ranker. We regard better item arrangements as arrangements that yield more utility and dene the utility of request𝑟as the expected sum of the weighted click of each item under a specic permutation, as follows, 𝑈(𝑟) = E𝑐· 𝑏=𝑃 (𝑐= 1) · 𝑏,(1) where𝜋is a feasible permutation that maps an item to a position, while𝜋 (𝑖)represents the position where item𝑖lies. Here,𝑐 denotes whether item𝑖is clicked at position𝜋 (𝑖)and𝑏is a given xed utility value for item𝑖. Notice that the distribution of the click probability𝑃 (𝑐= 1)varies with the counterfactual permutation 𝜋. However, most of the existing works predict the estimated utility scores only based on the initial lists, overlooking the dierence between the distributions of the click probability before and after reranking. As such, the goal of utility-based reranking is to nd the best permutation𝜋of candidate items after reranking for each request to maximize the total utility. The optimal utility is In this section, we propose a general reranking framework, CRUM, to maximize the utility in Eq.(1). Firstly, we briey introduce the overall framework, consisting of position-aware graph embedding, utility-oriented evaluator, and reranker. Then, we present the detailed design of the three parts. The architecture of our proposed CRUM is shown in Figure 2. First, the position-aware graph embedding is proposed to extract the item-item and item-position interaction information. For each request, we construct a fully connected item graph with the initial positions as attribute nodes and use GAT [28] to learn item embedding. Second, taking counterfactual context and graph embeddings into account, we derive a utility evaluator, which estimates listwise utility under dierent contexts. Position-aware graph embedding and the evaluator are rst trained together on click logs before reranker. Then, an ecient pairwise reranker is trained under the guidance of the evaluator, with the parameters of GAT and evaluator xed. In the ensuing part, we will elaborate on the details of the three parts. In the reranking stage, the item-item relationship is an essential factor where many eorts have been made to exploit the mutual inuences among items better. However, we point out, the relationship between items and positions is also of cardinal signicance, from the perspective of matching an item to its most suitable position to optimize the overall utility. However, less attention is paid to this aspect. Previous RNN-based and Transformer-based methods only use item-position information implicitly. To explicitly exploit item-item and item-position interaction information, we construct a fully connected item graph with the initial positions as attribute nodes for each request. As illustrated in Figure 2, node𝑣 stands for the candidate item in a user’s request with position𝑝as its attribute node. Mathematically, this graph can be represented asG = {V, E, P}, where node𝑣∈ Vdenotes item𝑖and edge 𝑒∈ Eindicates the connection between item𝑖and item𝑗. Given that items in a list are naturally related, we build a fully connected item graph. The position attribute setP = {p, p, ..., p}contains all nodes’ position information, andp∈ Ris the one hot position embedding at position 𝑘. Then, we aim to represent each node as a low-dimensional embedding that preserves not only item relationships but also node attribute proximity. We follow the work of graph attention network [28]. At the(𝑡 + 1)-th propagation step, the graph embedding layer takes as input the node featureHand the position attributeP, whereH= {h, h, ..., h}, h∈ Rdenotes the node feature of item𝑖and𝑛is the number of nodes in a request, and𝑚is the dimension of item node’s features. In the rst step, the node featureHis initialized by the item feature{x, x, ..., x}. To get the normalized attention coecients 𝛼, a shared linear transformation function, parameterized by a weight matrixW ∈ R(𝑚denotes the dimension of the new item node’s features in the output of this propagation), and the self-attention mechanism is applied to each node: where𝐹 𝑁 𝑁 (·)is a one-layer feed-forward neural network, applying a weighted matrix and LeakyReLU activate function, and⊕ denotes the concatenation operation. As we use𝑘to represent the initial position of item𝑖,pis the initial position embedding of item𝑖. Finally, we use the normalized attention coecients obtained before, followed by a nonlinear activation function𝜎, to output the updated node feature. To stabilize the performance of self-attention, we deployed the multi-head mechanism. Therefore,𝐿independent attention mechanisms are executed, and all the node features are concatenated to get the nal representation of the next layer: where𝛼andWdenote the normalized attention coecients and the corresponding weight matrix of linear transformation obtained in the 𝑙-th attention mechanism, respectively. After T propagation steps, we obtain the nal item graph embedding for a specic request:H= {h, h, ..., h}, which capture the relationships and interactions between items and positions. As such, the position-aware mutual inuences between items are preserved, which will further help the training of evaluator and reranker. Most of the existing reranking methods directly estimate a score for each item from either human-annotated relevance labels or implicit feedback on initial lists and then places items in the decreasing order of the scores. However, this practice does not necessarily bring high utility for the reranked lists, since it does not take into account the gap between the context of the initial list and the reranked list, leading to imprecise estimation. Therefore, we propose utilityoriented reranking aiming to nd the list with maximal utility after reranking. However, it is still challenging to obtain the feedback for the new permutation of the reranked results. As it is impractical to ask users to provide feedback for every possible permutation of the list, users’ feedback to counterfactual context is unobtainable. We decide to design an evaluator to estimate the utility of the reranked list precisely based on observed ranking lists as well as counterfactual context. As the utility value 𝑏is a given xed value, the goal of the evaluator is to estimate the click probability𝑃 (𝑐= 1), where𝜋 (𝑖)denote the position item𝑖lies under the permutation𝜋. Recently, several deep models [26,33] are proposed to model the complex interaction from click logs, from which we can borrow some mechanisms to build our evaluator. Assuming that the click probability𝑃 (𝑐= 1)can be predicted by a function 𝑔(·) parameterized by 𝜽 , wherexandhdenote the feature and position-aware graph embedding of item𝑖we get in the previous part. We denote the position embedding at position𝜋 (𝑖)asp. Then the loss can be formulated as Eq. (10), where 𝑙 is the cross-entropy loss. Specically, users’ clicks depend on the context of the items ranked both before and after the current items. Thus, it is natural to adopt Bi-LSTM to model the user’s click behaviors and capture the sequential dependencies bi-directionally in the evaluator. Formally, letw, the concatenation of item featurex, position embedding p, and graph embeddingh, be the input vector for the𝑖-th item. The forward output stateqof the 𝑖-th item is computed as: wheref, d, o, andcare the forget gate, input gate, output gate, and cell vector withW,W,W, andWas their trainable weight matrices, respectively,𝜎 (·)is the logistic function, and∗is the element-wise product operator. Similarly, we can obtain the back-←−−→←− ward output stateq. Then, we concatenateqandqto get the−→←− sequential representation q= [q⊕q] of item 𝑖. As a common and powerful technique in modeling interaction in click probability prediction task, multi-layer perception (MLP) is also integrated into our evaluator. Hence, taking the concatenation of the item featuresxand the sequential representationqas input, the function 𝑔(·) can be formalized as follows: where𝜽denotes the union of parameters for Bi-LSTM and MLP and ⊕ represents the concatenation operation. With position-aware graph embedding and Bi-LSTM modeling the context and mutual inuence before and after reranking, the evaluator is able to estimate the listwise utility of any counterfactual permutation. Therefore, it is capable of providing helpful guidance for the following reranker. After obtaining the evaluator, one straightforward evaluation-afterreranking method might be to generate all the possible ranking lists and use the evaluator to estimate their utility. Unfortunately, given that dierent permutations bring dierent contexts and further lead to dierent utility, it is requisite to get all the possible permutations of𝑛!if there are𝑛items in the initial list. Thus, this straightforward solution will have the computational complexity of𝑂 (𝑛!)at the inference stage. Nevertheless, an evaluation-before-reranking method only needs to evaluate the nal list with the computational complexity of𝑂 (𝑛). Thus, instead of generating all the permutations, we adopt a view of swap and use Lambdaloss [29] framework to adjust some improper matching towards the optimal ranking, as shown in Figure 2. A scoring functionΦ(·)parameterized by𝚯is employed to approximate the optimal matching, and then the complexity can be reduced to𝑂 (𝑛)at the inference stage. The scoring function takes the item featurex, the obtained item graph embeddingh, and initial position embedding pas input, and outputs a score 𝑠: After all the items’ scores in a request are computed, the nal list is generated by sorting the scores in descending order. From the perspective of matching an item to its most suitable position, the initial ranking provides reasonable matching results. Therefore, we only need to exchange improper matching towards the optimal ranking by comparing the utility before and after swapping the matching between a pair of items. Hence, we adopt pairwise optimization and choose an ecient pairwise ranking framework, LambdaLoss [29], which is dened as L(𝑟) =|Δ𝑁 𝐷𝐶𝐺 (𝑖, 𝑗)| log(1 + 𝑒) ,(14) where𝑦and𝑠denote the label and predicted score of item𝑖, the parameter𝜎determines the shape of the sigmoid function, and |Δ𝑁 𝐷𝐶𝐺 (𝑖, 𝑗)|is dened as the absolute dierence between the NDCG metric before and after the two items𝑖and𝑗are swapped. Notice that the original LambdaLoss framework aims to optimize the NDCG metric while our goal is to maximize the total utility. We need to replace NDCG with a utility-based metric. Therefore, we derive an unbiased listwise metric of𝑈(𝑟)for any permutation𝜋 in request 𝑟 as where𝑃 (𝑐= 1)and𝑃 (𝑐= 1)denote the estimated click probability of item𝑖displayed in the position of permutation𝜋 and historical logs, which is estimated by the utility-oriented evaluator. The utility metric can be proved unbiased by showing the expectation of 𝑢(r) is equivalent to 𝑈(r) in Eq. (1) , as Then, similar to|Δ𝑁 𝐷𝐶𝐺 (𝑖, 𝑗)|, we sample item pairs from the ranking list provided by the initial ranker, and then calculate the dierence between the listwise utility metric before and after the two items 𝑖 and 𝑗 are swapped: where𝜋is the original permutation of the initial list and𝜋denotes the new permutation after item𝑖and𝑗are swapped. With Δ𝑈 𝑡𝑖𝑙𝑖𝑡𝑦(𝑖, 𝑗) as the weight for each pair, we derive loss function: L(𝑟; 𝚯) =Δ𝑈 𝑡𝑖𝑙𝑖𝑡𝑦(𝑖, 𝑗) log(1 + 𝑒) .(18) In this section, we rst compare our proposed CRUM model with the state-of-the-art reranking algorithms on two public datasets and a real-world industrial dataset. Secondly, we investigate the impact of dierent components and hyper-parameters of CRUM. Finally, we study the reranking performance of CRUM by varying the quality of the initial ranking lists. 5.1.1 Datasets. Our experiments are conducted on two public learning-to-rank benchmark datasets, including Yahoo! LETOR set 1and Microsoft MSLR-WEB10K, and a large scale proprietary dataset obtained from a real-world App Store. • Yahoo! LETOR set 1(Yahoo for short) is used in Yahoo! Learningto-Rank Challenge, consisting of 700 features normalized in[0, 1] extracted from query-document pairs. • Microsoft MSLR-WEB10K(MSLR for short) is a large-scale dataset released by Microsoft Research in May 2010. It is composed of 10,000 queries and 1,200,193 documents with 136 features extracted from query-document pairs. • App Storecontains user click logs from Jan 8, 2021 to Jan 31, 2021 from a mainstream industrial App Store, with 27,928,214 users, 398,053,272 items, and 30 features per item. 5.1.2 Initial ranker and baselines. To generate the initial ranking lists, we select three representative learning-to-rank algorithms, including DNN, SVMrank, and LambdaMART. Those three algorithms use pointwise, pairwise, and listwise loss, respectively. • DNN[7] applies MLP to model the relationship between labels and features of items with pointwise loss. • SVMrank[16] is a classic pairwise learning-to-rank model built upon the SVM algorithm. • LambdaMART[5] is the state-of-the-art listwise learning-torank algorithm, which optimizes NDCG directly. We list the reranking solutions for our empirical comparisons below. As for IRGPR and PRS we mentioned before, IRGPR [21] demands an item relationship graph and PRS requires multiple user behavioral logs, like browsing, favoring, and buying, making them hard to implement in the datasets we use. • Seq2Slate[2] uses pointer network to sequentially encode previously selected items and uses decoder to predict the next one. • DLCM[1] rst applies GRU, which encodes top-ranking items to learn a local context embedding, and then combines it and the original feature to rerank the top results. • PRM[25] employs self-attention mechanism to model the mutual inuence between items and users’ preferences. • SetRank[24] employs a stack of multi-head self-attention blocks to learn a permutation-invariant ranking model. 5.1.3 Click data generation. Given that Yahoo and MSLR are datasets with human-annotated relevance labels, synthetic click data is necessary to simulate user click behavior. Amongst the baselines, DLCM and SetRank directly use human-annotated relevance labels. The click generation adopted by PRM only takes into account the relevance labels and position decay, ignoring the high-order interaction between clicks. Thus, we mainly follow Seq2Slate [2] to generate synthetic clicks for the two datasets. Firstly, we convert the original ratings (0 to 4) to binary labels with a threshold𝑇= 1 (relevant: {2, 3, 4}, irrelevant: {0, 1}) to obtain relevance probability 𝑟𝑒𝑙 (𝑟, 𝑖). Secondly, a user observes each item with a position decaying probability1/𝑝𝑜𝑠(𝑖), where𝑝𝑜𝑠 (𝑖)is the ranking position of item𝑖and𝜂is a decay parameter. Here we set𝜂to 0.7. Then, when observing an item, the user will click if it is similar to previous clicked items. The similarity probability introduces high-order interaction between clicks. Here, we modify the original deterministic similarity in Seq2Slate to a more reasonable similarity probability. If there exists an item clicked before, the cosine similarity between the currently browsing item and the previously clicked item will serve as the similarity probability. If not, the similarity probability will be set to 1. Finally, the click probability is the product of relevance, position decaying, and similarity probability. 5.1.4 Evaluation metrics. For Yahoo and MSLR, all baselines and our model CRUM is evaluated in terms of the relevance-based metrics MAP and nDCG [15], and the utility-based metrics # Click and CTR. Here, # Click and CTR denote number of clicks per list and click probability per item in the reranked lists evaluated by the oracle click model used in click data generation section. Relevance-based metrics are evaluated with binarized relevance labels. For the proprietary dataset App Store,𝑛𝐷𝐶𝐺@𝐾and𝑅𝑒𝑣𝑒𝑛𝑢𝑒@𝐾 are adopted as relevance-based and utility-based metrics, respectively. These two metrics are valuated based on click logs, following PRM [25]. Mathematically,𝑅𝑒𝑣𝑒𝑛𝑢𝑒@𝐾is dened as the average of the expected revenue at top-𝐾 positions in Eq. (19) where𝜔denotes the ordered list of items and𝜔 (𝑘)is the item reranked at position𝑘.𝑏is the bid price of item𝜔 (𝑘), and 𝑐denotes whether the item is clicked in the click logs. 5.1.5 Reproducibility. For public datasets Yahoo and MSLR, we implement our model and baselines in Tensorow 1.9.0. This implementation of our model is available for reviewersand will be publicly available upon the acceptance of this work. We employ Xavier method [13] to initialize model parameters and use Adam [18] as optimizer. The maximum number of positions is set to 10. Firstly, we train the graph embedding and evaluator together. There are two layers in GAT, and the embedding size of GAT and Bi-LSTM are both 64. The architecture of MLP in evaluator is [1024, 512, 128, 64]. The learning rate of the optimizer is 0.0003, and the batch size is set to 128. Then, the reranker is trained with the parameters of GAT and evaluator xed. The architecture of MLP in reranker is the same as the evaluator, and the number of sampled pairs for each list is 10. The learning rate and batch size are set to 0.00001 and 128. For baselines, all hyper-parameters and initialization strategies follow the suggestion from their paper or are tuned on the validation sets. Due to the change of environment and labels, the implementation on the private dataset has some dierences. Most of the settings remain the same with public datasets, and only the modied ones are listed as follows. This model is implemented in Tensorow 1.4.0. The maximum number of positions is set to 30. Instead of MLP, DCN is employed in reranker with three cross-layer and [1025, 512, 256, 128] as the architecture of the deep part. In the evaluator’s training, the learning rate is 0.0005, and the batch size is set to 100. In reranker, the number of sampled pairs for each list is 15. 5.2.1 Benchmark datasets. The overall performance on the two benchmark datasets, Yahoo and MSLR, is reported in Table 1, from which we have several important observations. Firstly, our proposed CRUM signicantly and consistently outperforms the state-of-the-art approaches w.r.t. both relevance-based and utility-based metrics under three initial rankers on both datasets. Taking MSLR as an example, CRUM improves over the best baseline PRM w.r.t utility-based metric CTR by 2.88%, 3.06%, and 1.59% on DNN, SVMRank, and LambdaMART, respectively. In terms of the relevance-based metric MAP, CRUM also achieves 5.35%, 4.80%, 2.74% improvement over the best baseline on three initial rankers. Reranking Model nDCG@3 nDCG@5 nDCG@10 nDCG@20 Revenue@3 Revenue@5 Revenue@10 Revenue @20 This demonstrates the eectiveness of evaluation-after-reranking method and the modeling of counterfactual context. Besides, the results also suggest utility-based and relevance-based metrics are correlated on the two datasets, i.e., a method performs well on utility-based and relevance-based metrics simultaneously. Secondly, the initial rankers with dierent forms of loss function aect the performance of CRUM in various ways. In Table 1, LambdaMART performs better than DNN, and DNN performs better than SVMRank. Although the pairwise method usually is more signicant than the pointwise method, the deep-learningbased method DNN outperforms SVMRank due to the superior expressive ability of the deep network. Nevertheless, the result of CRUM on these three initial rankers is not consistent with the performance of the initial rankers, e.g., CRUM on DNN achieves better results than that on LambdaMART. The reason may be that listwise information is critical in reranking. DNN uses a pointwise loss function without listwise interaction information, and thus has a considerable improvement space. However, LambdaMART has already incorporated listwise information in loss function, which limits its room for improvement, so that the performance of CRUM on LambdaMART is inferior to that on DNN. Finally, we observe that RNN-based algorithms achieve relatively poorer performance than Transformer-based ones in most cases. Transformer-based method PRM yields the best results among all baselines, demonstrating the eectiveness of self-attention to model mutual inuence between any items. Though employing selfattention, SetRank fails to surpass the RNN-based model Seq2slate. One possible reason is that this approach is more suitable for humanannotated relevance labels, as it adopts in its original setting [24]. 5.2.2 Proprietary dataset. In order to verify the eectiveness of our proposed model on real-world click-through data, we also evaluate CRUM and the baseline models on a proprietary click-through dataset from a mainstream industrial App Store. The objective of the industrial platform is to optimize revenue. Thus we modify the proposed CRUM and the baselines accordingly by predicting the revenue (CTR * bid), instead of clicks. From the overall performance shown in Table 2, we have the following observations. Firstly, CRUM consistently yields the best performance in all cases. For example, CRUM improves over the best baseline in relevance-based metrics, SetRank, by 12.99%, 7.42% in nDCG@3, nDCG@5. In terms of utility-based metrics, CRUM outperforms the best baseline PRM by 0.45%, 0.72% in Revenue@3, Revenue@5. These results demonstrate the superiority of our approach over the baselines in optimizing both relevance and utility via modeling counterfactual context. Secondly, unlike the semisynthetic experiments on public datasets, there is an inconsistency between relevance-based and utility-based metrics due to the consideration of the bid prices. When optimizing the revenue, most baselines achieve poor performance in relevance-based metrics, LambdaMART and some baselines (e.g., DLCM and Seq2Slate) even perform worse than the initial ranker. Nevertheless, although there is a trade-o between the two metrics, our model manages to nd a balance to achieve much improvement in both metrics. 5.3.1 Ablation study. To better understand the impact of each component of CRUM, we design three variants of CRUM, which is listed as follows: • CRUM(-BL) removes Bi-LSTM from the evaluator. •CRUM(-GAT) removes the graph embedding from both reranker and evaluator. •CRUM(-GE) removes the graph embedding used in the reranker without modifying the evaluator. The comparison of these three variants and original CRUM on Yahoo and MSLR datasets is shown in Table 3. After removing each component, the performance of CRUM has declined to a certain extent w.r.t. all metrics, which demonstrates the eectiveness of Bi-LSTM and graph in leveraging counterfactual context. CRUM(BL) roughly performs worst, proving the importance of listwise interaction. Comparing to CRUM, the performance of CRUM(-GE) and CRUM(-GAT) also have declined and removing GAT depresses the performance even more. This indicates the position-aware graph embedding not only helps the evaluator to model the counterfactual context, but also improves the performance of the reranker. 5.3.2 Hyper-parameter study. Practically, we notice that a hyperparameter, the number of sampled pairs of user’s requests used in training, inuences the nal results. Thus, we conduct grid-search experiments on Yahoo. We x all the other hyper-parameters and tune the number of sampled pairs per list from 1 to 30. Then, we visualize the change of a relevance-based metric (MAP) and a utilitybased metric (CTR) in Figure 3. We observe both CTR and MAP improve sharply from 1 to 10 and then become stable from 10 to 30. Though sampling 30 pairs per list slightly outperforms others, more samples require more space for training the model, so we set the number to 10 in our experiments. Besides, we also notice that the convergence speed is faster with more samples during the training process. Figure 3: Impact of sampled pairs on CTR and MAP. 5.3.3 Reranking in bad cases. CRUM models the counterfactual context rather than the context given by the initial ranker, and initial ranking only serves as the starting point for the swap of the reranker. Therefore, intuitively, our model does not rely too much on the initial ranker. To verify this, we explore reranking models with dierent qualities of the initial ranking lists on Yahoo in Figure 4. Here, rand means that the initial ranking is randomly generated. In addition, the initial ranking lists given by the original DNN, SVMRank, and LambdaMART are inverted to obtain the reverse DNN, reverse SVMRank, and reverse LambdaMART, which all perform worse than rand ranker. Under these poor rankings, we compare our method CRUM to the strongest baseline PRM. As illustrated in Figure 4, we can see that as the ranking gets worse, the performance of CRUM and PRM both have a tendency to decline. Yet CRUM achieves more stable performance than PRM, which indicates that CRUM does rely less on the initial ranking. During training, we also observe that although initialization aects the convergence speed, it usually converges a little faster when trained with a better initial ranker. It is probably because a better initial ranker provides a better arrangement so that it takes less time for swapping optimization to achieve the optimal ranking. Besides, our approach achieves a relatively poor performance in random cases. One possible reason is that completely random matching is worse than inverse sorting because the matching is unordered and requires more swapping to reach the optimal position. In this paper, we highlight the necessity of leveraging counterfactual context to evaluate utility after reranking and address how to use such information via a general evaluation-after-reranking solution. To avoid exponential candidate lists, we propose a novel utilityoriented reranking framework, CRUM, consisting of position-aware graph embedding, utility-oriented evaluator, and pairwise reranker. The utility-oriented evaluator is designed to estimate the listwise utility via the counterfactual context modeling, and the pairwise reranker nd the most suitable position for each item after reranking eciently. Extensive experiments on two widely used public datasets and a proprietary real-world industrial dataset demonstrate CRUM’s eectiveness, compared to state-of-the-art models w.r.t both relevance-based and utility-based metrics.