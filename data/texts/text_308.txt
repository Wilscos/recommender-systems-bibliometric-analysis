Abstract— We consider a queue with an unobservable backlog by the incoming users. There is an information designer that observes the queue backlog and makes recommendations to the users arriving at the queue whether to join or not to join the queue. The arriving users have payoff relevant private types. The users, upon arrival, send a message, that is supposed to be their type, to the information designer if they are willing to hear a recommendation. The information designer then creates a recommendation for that speciﬁc type of user. The users have to pay a tax in exchange for the information they receive. In this setting, the information designer has two types of commitments. The ﬁrst commitment is the recommendation policy and the second commitment is the tax function. We combine mechanism design and information design to study a queuing system with heterogeneous users. In this setting, the information designer is a sender of the information in the information design aspect and a receiver in the mechanism design aspect of the model. We formulate an optimization problem that characterizes the solution of the joint design problem. We characterize the tax functions and provide structural results for the recommendation policy of the information designer. Decentralized information is an important and inevitable aspect of today’s systems. Each agent in a system can own some information that others might be interested to know. On the other hand, agents usually act strategically and might not be willing to share their information with others. Therefore, incentives have to be put in place to motivate agents to reveal some parts of their information. There are two main approaches, mechanism design and information design, where the sharing of information between agents and their incentives of doing so is studied. In mechanism design [1]–[13], there are a number of agents with some private information. There is a designer that designs messages together with allocation and tax/subsidy functions. Agents, as “senders” of the information, send their messages, which could convey true or false information, to the central authority, acting as the “receiver” of the information. Upon reception of these messages, the central authority will then determine their allocations and taxes/subsidies. The incentives for the agents to send truthful messages are created through allocation and tax functions. Note that the central authority commits to the allocation and tax function and can not change these functions after hearing the agents’ messages. In information design [14]–[19], there is usually one “sender” who owns a piece of information. The sender heydari,anastas@umich.edu shares some part of his information with a number of agents as “receivers” by sending messages to them. The messages are created according to a policy that is to be designed by the sender. The agents will then interpret the messages using the policy based on which the messages are generated and then they take some actions. The sender has to optimally choose his policy to steer agents’ actions to a desired direction. Note that similar to the mechanism design framework, the sender commits to the policy he is using to create messages. The difference is that, the commitment in information design is from the sender while in mechanism design it is from the receiver. Information design problems with one sender and one receiver are usually referred to as “Bayesian persuasion” [14]. In [14], the authors present a geometric form of interpreting information design and show when it is proﬁtable for the designer to not share some part of the information. However, when there are multiple receivers, the information design problem becomes more complex and notions of equilibria must be introduced to analyze the game. As it is shown in [20], an information design model with multiple receivers is in fact a game with incomplete information and the set of outcomes of the information design problem corresponds to the set of Bayescorrelated equilibria (BCE). In the deﬁnition of BCE in [20], the information designer follows a direct strategy where he directly recommends actions to the players. The strategy of the information designer has to satisfy an obedience condition, that is, each player has to be willing to follow the recommendation. In this paper, we combine the two approaches and study joint information and mechanism design for a queuing system. In our model, there is a queue with an unobservable backlog by the incoming users. An information designer observes the queue backlog and makes recommendations to the users arriving at the queue as to whether to join or not to join the queue. This part of the model is an information design setting with the information designer being the sender and the arriving users being the receivers of the information. In our model, the arriving users have payoff relevant private types (we consider a binary type, so users can either be of type 1 or type 2). Upon arrival to the queue, the users send a message to the information designer, that is supposed to be their type. The information designer then creates a recommendation for that speciﬁc user type. The users have to pay a tax in exchange for the information they receive. The information sent by the information designer and the tax function incentivize the users to reveal their true types. Note that in this setting, the information designer has two types of commitments. The ﬁrst commitment is the policy that he uses to generate the recommendations given the queue backlog and declared user type, and the second commitment is the tax function. In this setting, the information designer is a sender of the information in the information design aspect and a receiver in the mechanism design aspect of our model. There are some works in information design where similar to our model, the receivers have private information, e.g., private types. There are two approaches to these problems: without elicitation and with elicitation of the private information. In the case of information design without elicitation [21], the information designer has to send a list of suggestions for each possible type of the receivers. This setting is referred to as public persuasion by Kolotilin et al. in [21]. In the case of information design with elicitation [21]–[23], receivers report their types and instead of the obedience constraint, the decision rule of the information designer should satisfy an incentive constraint. The incentive constraint makes sure each type of the receiver prefers her own recommendation over other recommendations that she can possibly hear if she reports her type untruthfully. Kolotilin et al. [21] refer to this setting as private persuasion. In [22], authors utilize monetary transfers, i.e., taxes/subsidies, to elicit the private types, as opposed to the model in [21] where elicitation is done without taxes. In [24], the persuasion is done not only through information design0 but also by using monetary transfers. However, the receiver does not have any private information. Similarly, monetary transfers have been utilized for Bayesian persuasion in [25] but there is a single receiver and she does not have a private type. In [26], there is also some type of joint mechanism and information design but the information disclosure is public and not a function of the users’ reported types. In addition, there are no monetary transfers. In [27], authors have studied the effect of a thirdparty data provider on simple mechanisms and in this sense, they have considered a joint information and mechanism design problem. They show that simple mechanisms fail to approximate the optimal revenue in the presence of a thirdparty signal. Our formulation of joint information and mechanism design is similar in spirit to the one discussed in [22], where there are multiple players with private prior beliefs about a state of the world. The information designer offers a menu of experiments (that convey information) that players can choose from and they have to pay a tax in return. The information designer maximizes his revenue over the set of experiments and taxes subject to incentive compatibility and individual rationality constraints. Our setting can be considered a special case of the general framework discussed in [22]. However, the speciﬁcs of our model such as users’ utilities being linear in their private types, enable us to evaluate explicit tax functions and formulate a linear optimization problem for the information designer and study the properties of its solution. The queuing system presented in this paper builds on the model by [28] with the main difference being that in our model the users have private types where in [28], the incoming trafﬁc is uniform (there are some discussions on the case of different user types but these types are assumed to be known to the information designer). The rest of the paper is structured as follows. In section II, we discuss the model. In section III, the mechanism objectives are discussed. The tax function is presented in section IV. The information design problem is formalized in section V. Some structural properties are presented in section VI. We present results of numerical analysis in section VII and we conclude in section VIII. The proofs of lemmas and theorems can be found in the Appendix at the end of the paper. We consider a service provider with a service rate of 1. There is a queue with inﬁnite capacity and users arrive at the queue according to a Poisson arrival process with a rate λ > 1. We denote the number of users in the queue by x and we have X ∼ µ(·), where µ(·) is the stationary distribution of the queue backlog. The users have payoff relevant private types i ∈ I = {1, 2} and the a-priori type distribution is known I ∼ P(·). The queue backlog is unobservable by users. There is an information designer who observes the queue backlog and gives the users an option to hear a recommendation about joining or leaving the queue. The users have to follow the recommendation if they decide to hear it and they will have to pay a tax in exchange for the recommendation. If a user chooses not to hear the recommendation, she will decide whether or not to join the queue on her own. Note that if a user decides not to hear the signal, she joins the same queue that she would have joined had she decided to hear the recommendation. One can deﬁne the following sequence of actions that users take at the time of arrival. Note that we refer to a user by she and to the information designer by he. decides to hear the recommendation or not by choosing d = g(i), d ∈ {0, 1}, where d = 1 means she hears the recommendation and then follows it. d = 0, she will decide to join or not join the queue by choosing e = k(i), e ∈ {0, 1}, where e = 1 means she joins the queue. d = 1, she has to send a message m = f(i), m ∈ I to the information designer. This is a direct mechanism and the message m sent by a user with type i is supposed to be her type. The information designer determines a tax t(m) that is to be paid by the user in return for hearing the recommendation. He then generates a (randomized) recommendation s where S ∼ σ(·|x, m) and announces it to the user. The distribution σ(·|x, m) is called the recommendation policy. The user will then follow the recommendation, i.e., if s = 1, she joins the queue and if s = 0 she leaves. Figure 1 depicts the extended form of the game faced by a user with type i at the time of arrival. Based on the steps described above, we can denote the private history (or more appropriately, information set) of a user by h ∈ H, where the set of private histories is deﬁned as H = {(i, d = 0, e = 0), (i, d = 0, e = 1), (i, d = 1, m, s = 0), (i, d = 1, m, s = 1)}. The utility of a user for each of these histories is denoted by u(h), and is described in the following. The users have to pay a price p for the service they receive if they opt out of the mechanism, but choose to enter the queue. As mentioned before, the users pay a tax t(m) in exchange for the recommendation if they decide to hear it. They do not pay anything extra when they receive service after hearing the recommendation (the price of the service is included in the tax function). The user with type i also receives a reward of iv(x) by joining the queue of backlog x, where v(·) is a decreasing function, which can also be negative for large enough x. Therefore, for h = (i, d = 0, e = 1), the user receives the expected utility of u(i, d =P 0, e = 1) = i¯v − p where ¯v = E[v(X)] =v(x)µ(x). For h = (i, d = 0, e = 0), she leaves the queue and receives u(i, d = 0, e = 0) = 0. For h = (i, d = 1, m, s = 1), the user receives the expected utility of u(i, d = 1, m, s = 1) = iE[v(X)|h] − t(m). Finally, for h = (i, d = 1, m, s = 0), the user receives the utility u(i, d = 1, m, s = 0) = −t(m). One can express the joint probability distribution of the random variables described in this model as follows. Note that P(d, e, m|i) is determined by the strategy of the user with type i and we have where 1(b) =and the stationary distribution of X, µ(·), depends on σ and is characterized in the next section in Lemma 2. In the previous section, we described the model and introduced the actions and messages involved in it. To summarize, we have actions/decisions d = g(i), e = k(i), m = f(i) that are taken by the user with type i and S ∼ σ(·|x, m) and t(m) that are to be designed by the information designer. The mechanism M= (σ, t) is designed by the information designer to have the following properties: That is, both types of users should prefer to hear the recommendation, i.e., d = g(i) = 1, ∀i ∈ I. For the mechanism to be IR, we must have the following condition. E(u(i, d = 1, M, S)) ≥ E(u(i, d = 0, E)), ∀i ∈ I. The above equation implies that the expectation is taken at the step of the game where the user has to decide on d and the decision should always be d = g(i) = 1. centive compatible (DSIC). That is, all users that choose to hear the recommendation, should act truthfully no matter what other users do, i.e., m = f (i) = i for all i for which d = g(i) = 1. For the mechanism to be DSIC we should have the following. f(i) = arg maxE(u(i, d = 1, m, S)) = i, Note that the utility u(i, d = 1, m, S) does not depend on the messages of other users and it only depends on the stationary distribution of X, which is affected by the strategies f(·) of users and not the actual messages quoted. Also, note that for whatever strategy f (·) of users, i.e., truthful or not, it must be a dominant strategy for each user to quote her message truthfully. signer’s expected revenue. That is, the information designer solves the following optimization problem. where M = f(I). The above objective comes from the fact that the tax is only paid by the users who participate in the mechanism, i.e., g(i) = 1. Given the joint distribution of the random variables in (1), we can calculate the expected utilities in IR and DSIC constraints as follows. E(u(i, d = 1, M, S)) =u(i, d = 1, f (i), s = 1)P(S = 1|i, d = 1, f(i)) + u(i, d = 1, f(i), s = 0)P(S = 0|i, d = 1, f(i)) (8a) E(u(i, d = 0, E)) = u(i, d = 0, e = 1)1(e = 1) (9a) = k(i) The following lemma characterizes the function k(i). Lemma 1: The function k(i) is given by the following equation. Proof 1: The result is evident by comparing the utility in (9b) with 0. One can use this lemma and the expected values of the utilities to further simplify the IR and DSIC condition as follows. DSIC: f(i) = arg maxiv(x)µ(x)σ(1|x, m) − t(m) where (a)= max(a, 0). Given IR and DSIC constraints, the optimization problem of the information designer can be simpliﬁed as follows. σ, t∈ maxλE[t(I)] = maxλ(P(1)t(1) + P(2)t(2)). In the expected utilities, we see the stationary distribution of X, µ(·) which is characterized in the following lemma. Lemma 2: If we assume that IR and DSIC hold, the stationary distribution of X, µ(·), is given by the following equation. µ(x + 1) = λµ(x)(P(1)σ(1|x, 1) + P(2)σ(1|x, 2)) (13a) In this section we introduce the tax functions for the mechanism and prove DSIC. We will also prove that this type of tax function maximizes the designer’s revenue. We consider the following tax function. where we deﬁne which can be viewed as the “allocation” to a user with quoted message i. We refer to tas the tax offset. Notice that there are two degrees of freedom in the tax functions, tand q, which is determined by σ. We will see in the next theorem that the given tax function guarantees DSIC. The other two requirements of the mechanism, i.e., IR and revenue maximization will determine the two degrees of freedom in the tax function. Furthermore, the given tax function maximizes the information designer’s revenue. Given the tax function described in the previous section and the fact that DSIC holds for a mechanism with such tax function, and if we assume uniform distribution for the types of users, i.e., P(1) = P(2) =, we can simplify the objective of the information designer as follows. λE[t(I)] =λ2(t+ q(1) + t Therefore, by including the constraints, we have the following optimization problem. maxλ(t s.t. − t≥ (¯v − p)(17b) Note that constraints (17b) and (17c) enforce the IR condition. The above optimization problem is not linear with respect to σ because of the stationary constraints of (17e). Furthermore, the constraints are not expressed as linear inequalities. Therefore, we restate the problem in terms of the joint probability distribution on (S, I, X), denoted by γ(S, I, X) to have a linear optimization problem. Note thatPP q(i) =v(x)µ(x)σ(1|x, i) =v(x). Therefore, we have the following linear optimization problem faced by the information designer. maxλt+ 2λ s.t. − t≥v(x) Note that constraints (18b), (18c), (18d), (18e) correspond to linearized constraints of the IR condition, while constraint (18h) is to ensure P(x, i) = µ(x)P(i) according to (1). In this section, we discuss some properties and behaviors of the optimal recommendation policy that is the solution of the optimization problem (18). Theorem 4: Suppose tand γ(or equivalently σ) are the solution of (18). Then, one of the following holds. – If v(x) > 0 and σ(s = 1|1, x) > 0, then σ(s = 1|2, x) = 1. – If v(x) < 0 and σ(s = 1|2, x) > 0, then σ(s = 1|1, x) = 1. we have σ(1|i, x) = 0 for all i ∈ I. Furthermore, for x < ˜x, σ(1|i, x) = 1 for all i ∈ I except for some points in˜X = {x, x, . . .}, x< ˜x for which we can have σ(1|1, x) < 1, or σ(1|2, x) < 1, where all x∈˜X satisfy the following condition. There exists > 0 and ψ such that The intuitive explanation of the above theorem is as follows. If we deﬁne xas v(x) > 0 for x < xand v(x) < 0 for x > x, then case 1 of the theorem implies a threshold behavior for the recommendation policy with the threshold being x. That is, for x below the threshold, the recommendation policy favors type 2 of the users and only allows type 1 to enter the queue if type 2 is allowed in with probability 1. Similarly, for x above the threshold, type 1 is favored for entering the queue and type 2 is allowed to enter the queue if type 1 is allowed in with probability 1. Case 2 of the theorem implies that the designer is sending the same signal (except for x ∈˜X ) for both types of users. Therefore, revenue due to the discrimination between the two user types can only be gained for states x ∈˜X . One question that arises is what the size |˜X | of this set is. Equation (19) indicates that for a given size |˜X |, there are |˜X | equations to be satisﬁed and only two unknowns (and ψ). As a result, it is highly unlikely that for a general utility function v(·), the size of the set is larger than 2. Evaluating the quantities xand xcan be done systematically by ﬁrst evaluating ˜x and then searching over all O(˜x) cases for the values of x and xby checking if (19) is satisﬁed for some > 0 and In this section, we present some numerical analysis of the model discussed in this paper. We have numerically solved the linear optimization problem (18) using Matlab. In our analysis, we have set a maximum capacity for the queue such that it does not affect the stationary distribution of the queue backlog. We consider λ = 1.2, and v(x) = 1−(x/50)as the utility function of the users. Fig. 2 depicts the recommendation policy of the information designer with respect to the queue backlog for p = 0, while the stationary distribution of the queue backlog is plotted in the same ﬁgure. In this case, the revenue of the designer is 0.0786. The recommendation policy in Fig. 2 conﬁrms the results of Theorem 4. The threshold xin this example is x= 50 and we can see for x < x, both types are allowed in with probability 1, and for x > x, either both types are allowed in with probability 1 (states 51-53) or only type 1 is allowed in. This is consistent with case 1 of Theorem 4. In Fig. 3 we plot similar quantities for the case of p = 0.2 and the revenue of the information designer is 0.2693. Similar to the p = 0 case, the results are consistent with case 1 of Theorem 4 because for x < x, type 2 is allowed in with probability 1, and for x > xtype 1 is allowed in with probability 1. In order to evaluate how well the information designer is doing in terms of gaining revenue, we can calculate the revenue of the queue when there is no information designer and the incoming trafﬁc chooses to join the queue without any information. For the given v(·), only one type of users will join the queue (type 2) and the rate would become . Otherwise, the queue becomes unstable. Therefore, the revenue is at most. Hence, for p = 0, the revenue of the outside option is 0 and for p = 0.2, the revenue of the outside option is 0.12 and clearly, the information designer is doing better than the outside option. Fig. 2: Recommendation policy and the stationary distribution of the queue backlog for p = 0. Fig. 3: Recommendation policy and the stationary distribution of the queue backlog for p = 0.2. In this paper, we studied an information design problem for a queuing system where in addition to the information designer that privately observes the queue backlog, the users also have payoff relevant private types. Therefore, a joint information and mechanism design problem was studied. We investigated how the information designer can design tax functions and provide different information for different types of users in order to gain the most revenue. Some structural results were provided for the optimal recommendation policy of the information designer and numerical analysis was done to support the results. A. Proof of Lemma 2 We have a continuous time M/M/1 queue with transition rates g= λP(S = 1|x) and g= 1 for x > 0. Therefore, we have g= −1 − λP(S = 1|x) for x > 0 and g= −λP(S = 1|0). We can calculate the stationary distribution of the queue as follows. which can be written explicitly as µ(x + 1) + λP(S = 1|x − 1)µ(x − 1) and after substituting recursively we ﬁnd λµ(x)(P(1)σ(1|x, 1) + P(2)σ(1|x, 2)), ∀x ≥ 0. (20e) B. Proof of Theorem 3 This theorem can be proved using Myerson’s Lemma [29]. In order to see the connection, note that given the tax function described in equation (14), one can write the following for E(u(i, d = 1, m, S)). E(u(i, d = 1, m, S)) = (i − m)q(m) +q(j)−t, (21) where m = f (i) and if m = f (i) = i, we have By comparing the above utility, which is gained by a user if she acts truthfully, with the one in (21) for any m 6= i, we can see that if q(i) is increasing in i, then DSIC holds. In order to prove the second part of the theorem, note that because of the discrete type space, we do not have uniqueness for the tax functions. In other words, revenue equivalence theorem does not hold. However, we can show that the tax function deﬁned in equation (14) is an upper bound on all of the tax functions satisfying DSIC and therefore, it is the best the designer can do in terms of maximizing his revenue. One can write the following for any tax function satisfying DSIC. Therefore, we have t(2) ≤ t(1) + 2[q(2) − q(1)]. We can see that if tax functions are deﬁned according to equation (14), we have t(2) = t(1) + 2[q(2) − q(1)]. That is, given t(1), the upper bound is reached for t(2). On the other hand, according to IR constraint, we must have t(1) ≤ q(1) and according to (14), we have t(1) = t+ q(1), where tis optimized over subject to IR constraint. Therefore, t(1) is also its maximum possible value. Therefore, the designer can not gain any more revenue using other forms of the tax function. C. Proof of Theorem 4 Since optimization problem (18) is linear in γ, we can use KKT conditions to characterize the solution. We use the following dual variables for each constraints in (18). − 2v(x)γ(s = 1, 1, x) + 2v(x)γ(s, i, x) v(x)γ(s, i, x) − p + t≤ 0 : (26) − 2v(x)γ(s = 1, 1, x) + t≤ 0 : (27) t≤ 0 : (28) v(x)γ(s = 1, 1, x)−v(x)γ(s = 1, 2, x) ≤ 0 : η (29) γ(s, i, x + 1)−λγ(1, i, x) = 0, ∀x ≥ 0 : α(30) 2γ(s, i, x)−γ(s, i, x) = 0, ∀i ∈ I, x ≥ 0 : ν(31) − γ(s, i, x) ≤ 0, ∀s ∈ {0, 1}, i ∈ I, x ≥ 0 : β(33) where ≥ 0, ≥ 0, ≥ 0, ≥ 0, η ≥ 0 and β≥ 0. By taking the derivative of the dual function with respect to γ(1, 1, x), γ(1, 2, x), γ(0, 1, x), and γ(0, 2, x) for x > 0, and also with respect to tand setting them to zero, we have the following. (2+ )v(x) + α+ ν− ν+ ψ − β= 0 (34c) (2+ )v(x) + α+ ν− ν+ ψ − β= 0 (34d) − 1 + + + +  Therefore, we have v(x) =2− − η(35a) −λα+ α+ ν− ν+ ψ − β =2 − 2− + η(35b) Based on the above equations, we can have the following lemma. Lemma 5: If there exists a ˜x > 0 for which we have γ(0, 1, ˜x) > 0, γ(0, 2, ˜x) > 0, γ(1, 1, ˜x) > 0, and γ(1, 2, ˜x) > 0, then η = 0, = = 0, and ν= ν for all x > 0. Further, we have β= βand β= β. Proof: Looking at equations (35c) and (35d), we have 2ν− 2ν+ β= β. Since γ(0, 1, ˜x) > 0 and γ(0, 2, ˜x) > 0 we have β= β= 0 and it results in ν= ν. Also since γ(1, 1, ˜x) > 0 and γ(1, 2, ˜x) > 0, which results in β= β= 0, we must have 2− − η = 2 − 2− + η or equivalently, + = 1 + η. According to equation (34e), we must have η = 0 and = = 0. Further, for any x > 0 and each type i ∈ I, we either have γ(1, i, x) > 0 or γ(0, i, x) > 0 or both. Therefore, either β= 0 or β= 0 or both. Assume β= 0. Then if β= 0, we must have ν= νand the result is proved. If β= 0, then from equations (35c) and (35d) we must have ν≥ ν. From equations (35a) and (35b), we must have ν≥ ν. Therefore, ν= ν. Therefore, due to equation (35), we must have β= βand β= βfor all x > 0. Note that all of the results of Lemma 5 hold if we have 2− − η = 2 − 2− + η, i.e., the denominators of the coefﬁcients in equations (35a) and (35b) are equal. In other words, Lemma 5 states a condition in which we must have 2− − η = 2 − 2− + η and consequently, the rest of the results hold. However, these coefﬁcients might be equal without having the condition stated in Lemma 5. In the next lemma, we show what the solution looks like if we have 2− − η = 2 − 2− + η. Lemma 6: If we have 2−−η = 2−2−+η, then there is a threshold ˜x such that for x ≥ ˜x we have γ(s = 1, i, x) = 0 for all i ∈ I, and for x < ˜x, γ(s = 0, i, x) = 0 for all i ∈ I except for some points˜X = {x, x, . . .}, x< ˜x for which we can have γ(0, 1, x) > 0, or γ(0, 2, x) > 0, where all x∈˜X satisfy the following condition. There exists > 0 and ψ such that Proof: If we have 2− − η = 2 − 2− + η, then η = 0, = = 0, and ν= νfor all x > 0. Further, we have β= βand β= β. This results in the following. v(x) =2 − 2(36a) −λα+ α+ ψ − β =2 − 2(36b) From the above equations, we can conclude that β= βand β= β. It means that we if we have β= β> 0 which results in γ(s = 1, i, ˜x) = 0 for all i ∈ I, the stationary distribution µ(x) is zero for all x > ˜x and therefore γ(s = 1, i, x) = 0 for all i ∈ I. For x < ˜x, we have β= β= 0. We also either have β= β> 0, which results in γ(s = 0, i, x) = 0 for all i ∈ I or we have β= β= 0 which can allow us to have γ(0, 1, x) > 0, γ(0, 2, x) > 0. Suppose either γ(0, 1, x) > 0 or γ(0, 2, x) > 0 for x ∈ {x, x, . . .}. By writing the equation (36) for x = 0 and due to the fact that at least one of βor βis zero, we have v(0) =(−λα+ ψ). For x ∈ {x, x, . . .} we have v(x) =−λα+ α+ ψ2 − 2=−α− ψ2(37) which results in v(x) = −α. Using equations (36) and(37) we have λv(x) =2 − 2(−λα+ ψλ ⇒ (2λv(x))+ (λ)ψ =λv(x). (39) having x, the above is an equation with respect to  and ψ. In general, if we have xand x, we should be able to determine  and ψ and we can have xfor k ≥ 3 only if they result in linearly dependent equations in (39) and this might not be true for general v(·). Note that if for all x < ˜x we have γ(s = 0, i, x) = 0 for all i ∈ I, then q(1) = q(2) and the objective of the information designer would be zero. Therefore, this is probably not the solution of the optimization problem. In order to create discrimination between users of type 1 and type 2, the designer can only consider different policies for these two types at x∈˜X . In Lemma 6, we investigated the solution under the assumption of 2− − η = 2 − 2− + η. Note that due to equation (34e), we can not have 2− − η > 2 − 2− + η. Therefore if the equality does not hold, we have 2− − η < 2 − 2− + η. In the next lemma we present some results under this inequality assumption. Lemma 7: If 2− − η < 2 − 2− + η, then we have the following. If v(x) > 0 and σ(s = 1|1, x) > 0, we have σ(s = 1|2, x) = 1. Furthermore, if v(x) < 0 and σ(s = 1|2, x) > 0, we have σ(s = 1|1, x) = 1. Proof 2: Looking at equation (35), if v(x) > 0, since 2− − η < 2 − 2− + η, we must have the following. v(x) =2− − η(40) =2 − 2− + η(41) ⇒ α− λα+ ν− ν+ ψ − β(42) ⇒ β+ 2ν− 2ν< β(44) We also have the following. We can have three cases for ν−ν. We either have ν> ν, which results in β< β, which means that β> 0 and therefore, γ(s = 1, 1, x) = 0. On the other hand, we must have β> 0 and therefore, γ(s = 0, 1, x) = 0. This is a contradiction for those x’s that µ(x) > 0, which are the ones that we are interested in. If we have ν< ν, we must have β> 0, and therefore, γ(s = 0, 2, x) = 0. If we have ν= ν, we must have β> 0 and therefore, γ(s = 1, 1, x) = 0. Therefore, for v(x) > 0, we have σ(s = 1|2, x) = 1 if σ(s = 1|1, x) > 0. If v(x) < 0, then we must have α− λα+ ν− ν+ ψ − β(47) Consequently, if ν> ν, we have β> 0 and therefore, γ(s = 1, 2, x) = 0. On the other hand, due to equation (46), we have β> 0 and therefore, γ(s = 0, 2, x) = 0, which is a contradiction. Hence, ν≤ ν. If ν< ν, we have β> 0 and so γ(s = 0, 1, x) = 0. If ν= ν, we have β> 0 and therefore, γ(s = 1, 2, x) = 0. Hence, for v(x) < 0 we have σ(s = 1|1, x) = 1 if σ(s = 1|2, x) > 0.