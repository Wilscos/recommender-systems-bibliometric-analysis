Natural language processing (NLP) systems have become a central technology in communication, education, medicine, artiﬁcial intelligence, and many other domains of research and development. While the performance of NLP methods has grown enormously over the last decade, this progress has been restricted to a minuscule subset of the world’s 6,500 languages. We introduce a framework for estimating the global utility of language technologies as revealed in a comprehensive snapshot of recent publications in NLP. Our analyses involve the ﬁeld at large, but also more in-depth studies on both user-facing technologies (machine translation, language understanding, question answering, text-to-speech synthesis) as well as more linguistic NLP tasks (dependency parsing, morphological inﬂection). In the process, we (1) quantify disparities in the current state of NLP research, (2) explore some of its associated societal and academic factors, and (3) produce tailored recommendations for evidencebased policy making aimed at promoting more global and equitable language technologies. The past decade has seen a rapid advance in natural language processing (NLP), the technology that allows computers to process human language. NLP has grown from a relatively technical niche to a fundamental tool in virtually all domains that involve language data in any shape or form. NLP is now instrumental for a vast array of tasks, from the early detection of neurodegenerative diseases (Orimaye et al., 2017), to exposing widespread gender and ethnic biases in societies (Caliskan et al., 2017), and predicting large-scale trends in collective consumer behavior (Kallus, 2014). More ostensibly, NLP has also become a staple technology for everyday frequent tasks in most contemporary societies of the world. For instance, an English speaker with a smartphone can now easily get accurate information on many topics through a quick query to a virtual assistant, they can consult an online translation service to translate a foreign language web page with a click, and they can interact with many different machines and computers through simple speech commands. These technological capabilities can be attributed to several developments over the last few decades: 1. the advent of sophisticated machine learning methods, which allow for more effective creation of NLP systems from existing data (Goldberg, 2017), 2. the existence of standardized benchmark datasets and evaluation metrics, 3. the prestige afforded by the research community to researchers who improve upon these benchmarks, 4. the resulting large number of resources, be they computation, data, or ingenuity, that are poured into optimizing performance thereon. As both a theoretical and technical endeavor, NLP is experiencing an explosive increase: the annual conference of the Association of Computational Linguistics (ACL, the ﬂagship event in NLP) received in 2000 less than 300 papers, growing in 2010 to slightly less than 1,000, to over more than 3,500 submissions in its 2020 edition. Largely as a result of this expansion of research effort, state-of-the-art systems have also achieved evaluation benchmark scores on par with human performance on a variety of NLP tasks such as question answering on English (He et al., 2021), or on automatic translation of news from German, Russian, and Chinese to English (Barrault et al., 2020). These upward slanting curves on standard benchmarks fail to show how uneven this development has been for all potential NLP users. Extensive research across NLP tasks have found systematic performance drops according to dimensions such as gender, racial identity, and language varieties, among others. The reasons for these biases are multifactorial and can be traced to virtually all stages in the process of NLP development, from the data used to train systems (Caliskan et al., 2017; Sap et al., 2019; De-Arteaga et al., 2019; Tatman, 2017; Tatman and Kasten, 2017; Buolamwini and Gebru, 2018; Raji and Buolamwini, 2019) to the very algorithms involved (Speicher et al., 2018; Bellamy et al., 2018; Adebayo et al., 2016). The growing awareness of these biases in NLP technologies brought by these studies, along with the development of novel metrics and tests to evaluate these disparities, have resulted in progressively more efﬁcient and principled strategies to understand and mitigate them. However, similarly systematic approaches are still lacking in one fundamental dimension of variation across individuals: their languages. Out of the over 6,500 languages spoken or signed in the world today (Hammarström, 2015), only a handful are systematically represented in academia and industry (Joshi et al., 2020). In spite of the aforementioned near-human results on translation or understanding of languages from the world’s economic and political superpowers, the experience of any NLP practicioner is that, for the vast majority of languages, they fall far below such standards. Critically, the languages of the world showcase substantial amounts of variation in most domains of description, and in fact, the performance of language technologies has been shown to be sensitive to diverse aspects of the language under study, including morphology, word order, or phonological repertoire, as well as more mundane aspects like data availability (Tsarfaty et al., 2020; Xia et al., 2020; Arivazhagan et al., 2019). Hence, the transfer of NLP developments from one language to another is far from trivial, as it often means that building highly functional language technologies on any particular language is a non-automatic, costly, and technically challenging task. Taking all these considerations together, and given that even the consequences brought by unequal NLP technologies across (racial, gender, socioeconomic) groups within the same nominal language are already substantial, there is a pressing need for measuring and understanding NLP performance inequalities across the world’s languages. Here we develop novel estimates on how the utility afforded by NLP systems is distributed across individuals, languages, and tasks at an unprecedented global scale. These estimates allow us to identify which languages are systematically underserved by language technologies and could beneﬁt the most individuals from focused technology development. We ﬁnally trace these inequalities to the societal, economic, and academic correlates of NLP systems’ performance, shedding light on its latent causes, and indicate how our results favor speciﬁc evidence-based policies in research and development. 2.1 Quantifying utility and demand Our fundamental goal is evaluating the distribution of diverse representative language technologies (and their qualities) across the world’s languages and their populations. Minimally, we would attempt to account for the patterns of association between the demand of language technologies and the utility they confer to users across languages. Thus, the ﬁrst component of our analysis pertains quantifying the utility users in a given languagel receive from a language technology. Ideally, such a measure would capture to what extent a given NLP system solves the speciﬁc problems an individual can pose to them - for instance, how successful an automatic translation is in translating a webpage, or how faithfully a speech recognition system is in executing a series of verbal commands. Intuitively, utility is associated with the nominal performance of the technology - in NLP systems more specifically, performance is typically measured by contrasting the solution offered by the machine against the one a (knowledgeable) human would provide. How this comparison is instantiated and measured depends on the task (see Section 1); however, since our purpose is to allow for comparisons, we deﬁne the utility of a task and language,u, as the corresponding performance normalized by the best possible performance afforded by such task, i.e. u=performancetheoretical max performance In cases where the best possible performance is undeﬁned or technically unattainable, we take the empirical maximum as an estimate of the theoretical one and normalize by the best-performing language across all languagesL, i.e. we replace the denominator in the above deﬁnition by max(performance). Table 1: NLP tasks evaluated in the present study, along with their corresponding performance metric. Deﬁning utility in this manner allow us to explore and contrast language technologies at the broadest scale, which is possible thanks to some necessary simplifying assumptions. As we pointed out before, not all users of the same language technology might beneﬁt in the same manner given a ﬁxed utility, and the relation between nominal performance and “true" utility might be complex and non-linear. With these caveats in mind, we further quantify the second component of our analysis, the demand for a language technology in each languagel,d. We characterizedby taking into consideration demographic and linguistic perspectives. Under the ﬁrst perspective, the demand for a given technology in a language is estimated to be proportional to the number of speakers of the language itself n(d∝ n). Under the second perspective, the demand across the approximately 6,500 languages of the world is identical (d∝ 1). These two alternatives as well as any intermediate combination of them can be simply parameterized through a single exponent τ, whereτ = 1correspond to a demographic notion of demand,τ = 0to a linguistic one, and0 < τ < 1 is in between. Equipped with these notions, we construct a simple family of global metrics (M) revealing to what degree the global demand for language technologies is actually met: Mhas a number of intuitive properties we would like such a metric to have.Mis bounded between 0 and 1; 0 corresponds to a case where no-one beneﬁts from a given language technology, whereas 1 would correspond to a situation where all languages enjoy perfect technology. Increasing the utility of a given language leads to an increase inM, and the magnitude of this increase is inﬂuenced by both the size of the improvement and the demand in that language. We apply our measures of utility and demand to a set of diverse and major representative NLP tasks, which are described below and summarized in Table 1. The ﬁrst three are tasks that technology users interact with directly in their everyday life, so that their output is already in a shape and form that is usable for most individuals. Question answering (QA) consists of crafting a relevant answer to a question formulated in natural language, such as e.g. “what is the capital city of the Philippines?" or “why do dogs like bones?". This task is ubiquitous in online search or virtual assistants. Machine translation (MT) is the task of translating from one language to another (e.g. from Tagalog to Estonian or from Japanese to Basque), and is typically used to facilitate inter-personal communication, information gathering, and e-commerce. Text-to-speech (TTS) is the task of rendering speech from textual input, which is used widely in spoken virtual assistants, car navigation systems, and in general is becoming the standard gateway for the internet of things. Beyond these three user-facing tasks, we also consider three more technical and linguisticallyfocused tasks, which often inform part of the pipelines of the user-facing tasks but which are rarely if ever encountered “in the wild" by language technology users.Morphological Inﬂection (Inﬂection) is the task of generating an inﬂected wordform given a lemma and a morphological speciﬁcation, e.g. producing the third person singular form for “run”:. Syntactic Parsing under the dependency formalism (DEP) is the task of producing a syntactic parse of an input sentence, e.g. given the sentence “dogs like bones” specifying the “dogs” and “bones” are the subject and object of “like” respectively. Natural Language Inference (NLI) is a central task in AI and involves the evaluation of information presented in propostional format. More speciﬁcially, given a sentence called the “premise” (e.g. “the dog chewed a big bone”), NLI systems decide whether a separate sentence called the “hypothesis” is entailed by the premise (e.g. “the dog gnawed at a bone”), negated by it (e.g. “the dog was sleeping”), or neither (e.g. “the dog likes bones”). 2.3 Correlates of NLP utility Beyond the performance of individual tasks, we take a bird’s-eye-view of the ﬁeld of language technologies in general, as we analyze some of the correlates of the scientiﬁc production in NLP. In particular, we follow two broad guiding questions: (1) does the system of academic incentives promote the development of a more linguistically diverse NLP? and (2) is economic centrality or sheer demographic demand the best predictor of NLP technologies in any given language? While a full understanding of the complex causal mechanisms binding society and NLP in general is outside of the scope of the present article, we set out to provide a ﬁrst large-scale exploration of these matters by considering scientiﬁc publications appearing in major international NLP conferences as the basic units of science production. This simpliﬁcation is not without challenges: for instance, some widely used language technologies are developed outside of the traditional scientiﬁc circuit based on proprietary technology, or they are published in local conferences, possibly in languages other than English.In spite of this, studying scientiﬁc publications (and their correlates) allows us to evaluate transparent questions on the basis of publicly available data at a scale that is unfeasible for in-depth analyses. Therefore, we study the ﬁrst question by determining whether the cumulative number of citations a paper receives is correlated with the number of languages it is associated with. We investigate our second question by ﬁnding the best predictive model of the number of NLP papers in any given language by contrasting two predictors: estimated number of users worldwide and approximate GDP associated with its users. We model these regression problems in a Bayesian generalized mixed effects framework (see Appendix B). We manually collect information on task performance for a number of diverse representative NLP technologies, as summarized in Table 1 (see Materials & Methods in Appendix A). These range from user-facing applications like machine translation (i.e. the automatic translation of text in one language into another) to more linguistic NLP tasks such as dependency parsing (i.e. the analysis of syntactic or semantic relationships between words). The data is taken from a combination of multilingual benchmarks, shared tasks and published results in NLP conferences. Demographic and linguistic information necessary for the estimation of demands were obtained from a variety of sources, including Ethnologue, Glottolog, and the World Trade Organisation. Figure 1 presents an overview of our main ﬁndings. Unsurprisingly, most NLP tasks we focus on fare substantially better when utility is measured demographically rather than linguistically. Text-to-speech synthesis is the task with the most linguistic coverage: the published results (due to a single study (Black, 2019)) cover more than 630 languages (or about 10% of the world’s languages). However, for the vast majority of these languages the measured quality of the generated speech is about half as good as the exceptionally good English system (Ren et al., 2021). The next most linguistically diverse tasks are those regarding morphosyntactic analysis, i.e. morphological inﬂection and dependency parsing, which have been evaluated over 140 and 90 languages respectively. For these more esoteric tasks which do not necessarily convey direct utility to a downstream user, the majority of the systems are in general very good. Natural language inference (NLI; a representative natural language understanding task) and question answering (QA) lie on the opposite side of the spectrum: the established benchmarks have only Figure 1: Left panel: linguistic and demographic global utility metrics for a number of language technology tasks. The red curve corresponds to the sequence where ﬁrst the language with the largest number of users is set to utility 1, then the second, and so on. Right panel: recent historical progression of two language technology tasks: Inﬂection and Machine Translation from English. focused on up to 15 and 17 languages respectively, leading to very low scores on the linguistic axis. In Figure 1 (right panel) we observe the progress of the utility metrics in tasks for which we had access to comparable data across a span of the last 7 years. The extensive efforts of the UniMorph project (Kirov et al., 2018) to cover as many languages as possible are visible in the “Inﬂection” plot, with signiﬁcant improvements over time. On the other hand, the machine translation ﬁeld is still in the process of ramping up following demographics and/or socioeconomic priorities, with improved linguistic coverage over the years. The granularity of these ﬁndings can be increased on the basis of available data. Figure 2 additionally presents demographic utility across language populations for all tasks. The visualization allows for identiﬁcation of ostensive gaps in received utility. The two bottom plots of Figure 2 display our metrics over speakers of a single language, based on question answering results for different spoken Arabic and Swahili lectal varieties (Faisal et al., 2021). This analysis shows that utility differences are small between Arabic vernaculars although these systems still lag behind the systems for Modern Standard Arabic, while the utility level of Coastal Swahili speakers in Tanzania is about 10% lower than that for speakers in Kenya. Given the current snapshot of NLP systems, we could ask which languages will lead to the largest global utility improvement. The relative importance of linguistic vs. demographic demands determines the priority ranking, as it can be observed in Figure 3 for a sample of ﬁve tasks. Improving on the demographic-focused utility entails a greater emphasis on Mandarin Chinese, Hindi, Spanish, and other populous languages that are generally well-served by current technologies. Balancing linguistic and demographic considerations leads to prioritizing a more diverse set of languages, mostly Asian and African languages like Amharic, Bambara, Bengali, Thai, or Yoruba, which are both populous and under-served, along with also large but severely under-served languages like Kurdish, Urdu, and Oromo. Further emphasis on linguistic utility would lead to prioritization of indigenous and potentially endangered languages of small communities like Aimele, Itelmen, North Sami, or Warlpiri, which are currently largely ignored by NLP research (Bird, 2020). Now we turn to our large-scale analysis of NLP publications. First, this reveals that a substantial proportion of publications do not even describe in a clear and unequivocal manner the language (or languages) they are dealing with (Bender, 2011). Given the current prevalence of English of a language of study in NLP, in most cases, the lack of an explicit reference to a particular language entails the system deals with English exclusively. Machine Translation (X→Spanish): M= 0.36 Machine Translation (X→Bengali): M Figure 2: Illustration of our metric on demographic-focused utility (τ = 1) on various NLP tasks. Figure 3: The priority languages (top-3 shown) change with different balancing of demographic and linguistic utility, with focus shifting from populous languages e.g. Mandarin (cmn) and Hindi (hin) to more under-served languages. This perhaps reﬂects a more deep-seated issue at play reﬂected in the citation of papers over time. Independently of publication venue, year, or subﬁeld of NLP research, the number of languages a publication deals with is not predictive of how many citations it will accrue over time (see Figure 4, top right panel). In other words, if citations can be regarded as a proxy for academic incentives, scientists and developers are presented with little to no additional academic reward when tackling data, problems, or tasks involving more than one language. This naturally leads to the question of what explains the production of language technologies across languages to start with, which will necessarily involve agents, mechanisms, and data, outside of the scope of NLP publications themselves. Nevertheless, in order to contribute to this investigation, we determined whether approximate measures of economic centrality or number of language users were better predictors of sheer number of papers published for any given language (see Appendix C). While both variables are substantially collinear, we ﬁnd that approximate GDP (rather than number of users) leads to a substantially smaller prediction error of number of published papers. Our study, covering diverse NLP tasks and types of evidence, makes apparent the immense inequality in the development of language technologies across the world’s languages. After English, a handful of Western European languages dominate the ﬁeld -in particular German, French, and and Spanish- as well as even fewer non-Indo-European languages, primarily Chinese, Japanese, and Arabic. Our preliminary investigation suggests it is the economic prowess of the users of a language (rather than the sheer demographic demand) what drives the development of language technologies. In spite of this, for some tasks (such as Inﬂection) there is an encouraging trend of both demographic- and linguistic-utility improving yearover-year. This is due to the nature of the task; reasonably accurate solutions can be achieved through small but highly-curated data. Since linguistic expertise on the languages of the world is, naturally, globally distributed, the main hurdle these tasks face is to pool such expertise under the premise of a common technical goal. In this respect, relatively low-cost and bottom-up actions that gather experts to work on speciﬁc NLP tasks (such as Universal Dependencies and UniMorph) have succeeded in accelerating the cross-linguistic development of language technologies. These prosper mainly on the basis of academic incentives, as those individuals or groups who contribute data and/or expertise are rewarded with individual publications or co-authorship in collective publications. Many of these contributions - which do not necessarily involve hefty resource investments but instead linguistic expertise - are markedly different from the typical publications in language technologies. However, these more esoteric tasks are tenuously associated with those that users are more likely to interact with, such as Machine Translation or Speech Synthesis. User-facing tasks all have in common a tight dependency on computational resources and large data, which in turn hinge on substantial ﬁnancial means. In a context of pressing user needs across multiple populations and languages, we submit that future developments on policies aimed at furthering crosslinguistic technologies would beneﬁt from clear (and possibly standardized) metrics that assist in streamlining complex decisions regarding resource Figure 4: Left panel: treemap of the number of NLP publications per language (with area proportional to the number). eng: English, zho: Chinese, deu: German, fra: French, spa: Spanish, jpn: Japanese, rus: Russian, nld: Dutch, ces: Czech, por: Portuguese, tur: Turkish, swe: Swedish, ita: Italian, ﬁn: Finnish, ell: Greek, lat: Latin, hun: Hungarian, ara: Arabic, kor: Korean, hin: Hindi, pol: Polish, dan: Danish. Right top panel: Relative citation rate vs number of languages in the publication. Right bottom panel: Number of publications according to number of language users and approximate GDP. Point size and transparency scales with number of publications. allocation. Our measures of global coverage fulﬁll that role, and help identifying large but currently under-served languages. While we do not attempt to supplement the necessary in-depth evaluation of the need of each individual group and language, they provide a common ground for coordinating global efforts across heterogeneous actors. This work was supported by NSF Award 2040926.