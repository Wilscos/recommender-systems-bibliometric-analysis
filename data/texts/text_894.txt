<title>Intention Adaptive Graph Neural Network for Category-aware Session-based Recommendation</title> <title>1 Introduction</title> <title>arXiv:2112.15352v1  [cs.IR]  31 Dec 2021</title> Recommender systems (RS) have become indispensable nowadays in scenarios such as online shopping or social media, to provide users with accurate information in an eﬀective way. Thanks to the development in deep neural networks, more and more powerful RS methods have been proposed. Most of them assume the user proﬁle and historical interactions are well recorded. Nevertheless, many services allow user interaction without user identiﬁcation, therefore session-based recommendation (SBR) was proposed specially for this scenario. Most of them are based on recurrent neural networks (RNNs) [8,12] or graph neural networks (GNNs) [25,18]. Fig. 1: A toy example of Category-aware Session-based Recommendation. Previous SBR settings usually focus on the interacted item sequence without consideration of users’ other types of behavior, e.g., clicking the speciﬁc category button to ﬁlter out items. However, in a real-world SBR scenario, there exist this kind of behavior beyond the interactions with items. For instance, as shown in Figure 1, it illustrates a regular page that supports specifying one category and ﬁltering items in other categories, with the selection button on the navigation bar. During an online shopping trip, after several browsing among diﬀerent categories, user may wonder if there is any interesting item in the category “Electronics”. Therefore he taps the “Electronics” button and interacts with items in this target category. This can happen when user has the following requirements: (i) The recommendation direction deviates from the user’s intention, therefore user wants to adjust the recommendation results via additional feedback in time, e.g., specifying the target category in accord with his intention. (ii) Sometimes the recommendation results could not keep up with user’s dynamic and abruptly shifting intention, therefore he may want to ﬁlter the items with target category to locate the right item eﬃciently. (iii) During the interaction, user may tend to concentrate on items in one category than the others, and an autonomous category selection by the user becomes necessary. In summary, these scenarios require the system to model the dynamic and rich interaction sequence (including interactions with item and category), for making more accurate and user-controllable recommendations based on user-speciﬁed target category, rather than general recommendations under all categories. When facing above scenarios, previous SBR settings cannot perceive the speciﬁc category which user intends to view next, and the system fails in reacting to the shifted interest promptly, leading to the failure of meeting user expectations. Due to limitations listed above, we propose a new task for SBR: In an ongoing session, with user-speciﬁed target category and each item’s corresponding category, the system recommends the next item speciﬁcally in the target category. The category selection can be commonly seen in the navigation bar of online applications, e.g., the page of an e-commerce platform in Figure 1. This task, namely Category-aware Session-Based Recommendation (CSBR), extends the interaction mode of users, w.r.t. specifying target category of next items, to accomplish a user-controllable SBR. As for the SBR with target category, the key challenge is how to eﬃciently leverage the category information in addition to the original interaction sequence. A straightforward adaption method is to recommend the next item based on the interaction history via existing SBR models and then ﬁlter the results by the target category. However, this approach overlooks something which are the challenges for CSBR listed as follows: (i) How to inject the auxiliary category information into session representation dynamically. Compared with previous SBR methods, the additional categories information need to be further considered, including category-level user interaction transition and item-category relations. (ii) How to transfer historical interaction information to the user-speciﬁed category domain eﬃciently. Intuitively, the interaction in one category might be helpful to improve recommendation eﬀectiveness in other categories, for the idea that user behavior in diﬀerent categories might reveal a particular user characteristics or interest. For example, as shown in Figure 1, a user might ﬁrstly interact with several items in the order of categories “Electornics”, “Fashion”, “Electronics”, “Sports” and then he clicks the “Electronics” category button to get the recommendation results only in “Electronics” category. During this process, some fashion item like “T-shirt with Super Mario print” may be helpful to predict the next item “Nintendo console” in the “Electronics” category because they are all related to the video game “Mario” series. However, adopting user interaction information from other categories will incorporate helpful but also noisy information at the same time. For instance, a “Swimming google” in “Sports” category might be irrelevant to a game console. Therefore, it is crucial to distill intention-adaptive information for matching the current interest of user. To eﬀectively address the aforementioned challenges, we propose a novel model named Intention Adaptive Graph Neural Network (IAGNN) for CSBR. In detail, we start by converting the complex interaction session into an Categoryaware Graph, which is composed of item-level transitions and category-level transitions, and item-category relations. Besides, to transfer historical interaction information to the user-speciﬁed category domain, we instantiate the message path between target category node and item nodes with explicit links in the graph. Based on the lossless graph, we employ a position-aware graph neural network to learn the item-level and category-level representations. By stacking multiple layers, the complicated historical interaction information is aggregated to reﬁne the user intention representation in target category iteratively. Finally, the user’s intention is characterized by the target category and last item representations for CSBR. Our main contributions of this work are summarized below: – We consider a ﬂexible session-based recommendation scenario when user’s autonomous navigation in possible item category is perceived, which is introduced as the task CSBR, concentrating on leveraging the signals of userspeciﬁed target category and item interaction sequence, for more precise recommendation results. – To address the challenges of CSBR, we propose a novel model named Intention Adaptive Graph Neural Network (IAGNN). Firstly, we construct a category-aware graph not only explicitly models the historical transitions and item-category relations, but also covers the connections of user-speciﬁed target category and historical interacted items. Moreover, we conduct a position-aware intention-adaptive graph neural network on the categoryaware graph to capture user intention by transferring the historical interaction information to the user-speciﬁed category domain. – Extensive experiments on three datasets demonstrate that our model is superior compared with state-of-the-art models for CSBR. <title>2 Related Works</title> In this section, we review some related works of session-based recommendation and category-based recommendation. Various neural network based approaches have been proposed for session-based recommendation(SBR) with the development of deep learning recently. RNN-based SBR. Recurrent neural networks (RNNs) are powerful sequence models which have been widely adopted for SBR tasks [8,12,14,27,21,23]. GRU4Rec [8] by Hidasi et al. was the ﬁrst RNN-based method to capture information in user-item interaction sequences by simply utilizing several GRU layers. NARM [12] takes advantage of attention mechanism beyond GRU4Rec, by referring the last interacted item, and captures user’s preference representations both from global and local perspective of current session. However, these sequential methods are unable to capture the items transition relationship eﬃciently. GNN-based SBR. Recently, graph neural networks (GNNs) has been proved to be competent to extract complex relationships between objects, so there emerges quite a few GNN-based methods for SBR [25,26,20,24,19,22]. SRGNN [25] is the ﬁrst work which leverages gated GNN (GGNN) on a directed graph constructed from the interaction sequence to learn item embeddings. Nevertheless, SR-GNN only propagates messages between adjacent items, which would fail to take long-distance item relations into consideration. LESSR [4] proposes a better architecture, including EOPA layer and SGAT layer to solve the lossy session encoding problem and propagate information along shortcut connections, which leads to lossless information presentation during graph construction and better performance for SBR. Pan et al. proposed StarGNN [18] with a star graph neural network to model the complex transition relationship between items with an additional star node connected to every item in an on going session, and applies a highway network to handle the over-ﬁtting issue in GNNs. As a signiﬁcant auxiliary information for items, category information has been explored in other recommendation areas. Cross-domain recommendation. Cross-domain recommendation (CDR) [9,10] can be considered as general multi-category recommendation, which utilizes data from multiple domains to deal with issues like cold start [1] and data sparsity [17] in target domain (category). Recently, Ma et al. proposed π-net [15] to generate recommendation scores for every item in two domains by integrating information from both. DA-GCN [6] constructs a cross-domain sequence graph which explicitly links account-sharing users and items from two domains to learn expressive representations for recommendation. Category-aware recommendation. Category-aware recommendation utilizes category information to enhance the item representation for better user preference modeling. There are several traditional category-aware recommendation methods. HRPCA [2] proposes a hybrid recommendation method to handle the customer preferences varieties in diﬀerent product categories. Choi et al. [5] design a recommendation algorithm based on the category correlations to a user with certain preferences. Recently, LBPR [7] conducts list-wise bayesian ranking for next category and category-based location recommendation. CoCoRec [3] utilizes self-attention to model item transition patterns in category-speciﬁc action sub-sequences, and recommends items for user by collaborating neighbors’ in-category preferences. As outlined above, the rich category information has not been comprehensively explored by previous SBR methods. Also for previous category-related methods, they rarely focused on recommendation for a session with anonymous users. What is more, none of these task settings explicitly consider the userspeciﬁed category information, and there are huge gaps in this scenario. <title>3 Preliminary</title> Given the entire item set V and category set C, we ﬁrst deﬁne a categoryaugmented item session as s = {(v , c ), (v , c ), ..., (v , c )}, in which (v , c represents the user interacted item v ∈ V in category c ∈ C, and n is the session length. Note that v and c can be repetitive in the sequence, since there can be repeated items in the session. Given session s, the user-speciﬁed target category c and the corresponding item set V = {v |c = c , v ∈ V}, the goal of CSBR is to predict a probability score for any item v ∈ V such that an item with higher score is more likely to be interacted next. <title>4 Methodology</title> Figure 2 illustrates the overall architecture of IAGNN under the context of user’s target category speciﬁed. First, the Embedding Layer will initialize id embeddings for all items and categories. Second, we construct the Category-aware Graph to explicitly keep the transitions of in-category items and diﬀerent categories, along with the relation between items and their corresponding categories. Fig. 2: The overview of IAGNN. Third, a Heterogeneous Graph Attention Neural Network is introduced to propagate embeddings through attentive graph convolution. Finally, by leveraging a Embedding Fusion Layer and a Prediction Layer, items in user-speciﬁed target category will be recommended. According to previous SBR methods, category information is not explicitly integrated in the recommendation process. In our proposal, we take advantage of graph neural network to model the items and categories transition. The graph G = (V , E ) is a directed heterogeneous graph, in which V ({v , v , v , ..., v }, {c , c , c , ..., c }, c ) indicates n item nodes, h category nodes and the user-speciﬁed target node c in the graph. E is comprised of the edges representing item transitions, category transitions, item-category connections and target category connections. Therefore, the semantics of item transition and category transition can be represented by these nodes and their relations. Generally, there are four sub-graphs with independent edge relations, and we will detail them as follows. Item Transitions. At ﬁrst, we split the original interaction sequence into several category-speciﬁc item sub-sequences. For instance, items in category c will be connected with their original interaction order in the session, and the same for other categories. Therefore, the in-category item-to-item transition patterns can be modeled in the sub-sequence. In detail, for each item node v in the category c , we create a link starting from v to its next item v , representing the item transition in the category subsequence. And we also create self-loop for each item node to include the node itself when aggregating. Category Transitions. Considering each item node v in the original session sequence, we can simultaneously initialize a corresponding category node c for it. And a category transition graph can be constructed according to the order of the original session sequence order. For instance, in Figure 2, c , c indicate the categories in colors ‘Green’, ‘Blue’ and ‘Yellow’. The session sequence consists of items in category [c , c , c , c ] respectively, then a subgraph composed of connections between categories can be constructed by the directed link c → c → c → c . Similar to the item transition sub-graph, a self-loop is added to every category node c Item-Category Connections. For representing the inherent item-category relations, we build bi-directed connections between item node v and its corresponding category node c . By this connection, information from non-adjacent items nodes can be propagated in a two-hop way through the corresponding category node as an intermediate node. Besides, the category transition information which implies the user interest changes across diﬀerent categories can be propagated back to all the related item nodes. Finally, this approach can enhance the representation of both items and categories. Target Category connections. Moreover, the user-speciﬁed target category is a given information in our task, to better leverage this information, we add a particular node c to represent the target category, which is connected to all the item nodes (In Figure 2, c represents the same category with c ). Therefore, it can not only solve the long-range information propagation issue between non-adjacent items, but also build the transfer from all the historical information to the target category domain as the the process of message passing from items to target category node. Meanwhile, as a pseudo node for the next item, the representation of c can be an intermediate variable to bridge the gap of all the interacted items and the actual next item in the session. Next, we present how intention-adaptive graph neural networks propagate messages between diﬀerent nodes. Embeddings. For each item v , it is projected by the item embedding layer ∈ R into dense embedding e . In which d denotes the item embedding size. Meanwhile the category embedding layer E ∈ R transform category unique identiﬁcations to category embedding e . Note that since c represents the target category, it can also be initialized in the same way as a regular category node. Also for a session with no more than n items, we take advantage of the reversed position embeddings P ∈ R by following GCE-GNN[24], which shows superiority performance because the session length is versatile. Moreover, we conduct a positive-going position embedding in our experiments. Also the category embeddings e are added for each item v to enhance the item representation by concatenation and projection: exp(LeakyReLU(a + a )) (3) exp(LeakyReLU(a + a )) where h ∈ R is the item-source message representation of node v at layer (l + 1) and N (v) stands for the set of neighbor item nodes. α is a scalar representing the attention coeﬃcient. W ∈ R and a , a ∈ R are the shared linear transformation parameters for the source and target node. Graph nodes aggregation. Similar to the item-item message aggregation, we can get other types of messages from the adjacent nodes. Therefore, the ﬁnal representation for an item node at layer (l + 1) can be represented as: (4) = h + h + h where h denotes the messages passed from other item nodes, h represents the messages from its corresponding category node, and h stands for the messages from target category. As for the category nodes, its representation at layer (l + 1) is: (5) = h + h In which h is the messages propagated from adjacent item nodes, and h represents the messages from adjacent category nodes. The same for the target category node c , its (l + 1) layer representation is: (6) = h Since the target category node connects to all the item nodes, only h , the messages aggregated from item nodes are used for its representation. As we employs an L-layer IAGNN, the embeddings for each node before and after the IAGNN can be represented as h and h respectively. In order to fuse the semantics before and after the network and avoid possible overﬁtting issue, we utilize the gate mechanism to get the ﬁnal embeddings for each kind of node: (7) = g  h + (1 − g)  h (8) g = σ(W[h k h ]) where the g is the gate factor to control information contributed from h and . W ∈ R are the transform matrix to get the gate. σ denotes the sigmoid activation function. In a SBR scenario, the last item user interacted contributes a lot to the next item user will interact with. In our case, there are two last items, one is the last item v of the original interaction sequence, the other is the last item v of the in-category sub-sequence. Therefore, after going through the IAGNN, we fuse these two item representations to a session item representation: Accordingly, we fuse the category node embeddings c and c which is related to the sequence last item v and last item v of in-category sub-sequence as the session category representation: After obtaining the item and category session representation h and h , we can also get the embedding of target category node: Then, we combine them into one embedding for the session: = W [h k h k h (12) where W ∈ R is used to project the concatenation result to an embedding of size d . Note that we did not introduce additional attention mechanism for all the items as a readout step, because regarding the target category node, the attention mechanism is equivalently done after message propagation through multi-layer GNN. By multiplying the session representation with all item embeddings, we can get the prediction score as follows: where ˜e is the projected candidate item embeddings through item embedding layer E ∈ R To train our network, a cross-entropy loss function is employed to optimize the model parameters: (14) L( y) = − log( ˆy ) + (1 − y )log( ˆy where y denotes the ground-truth item one-hot encoding vector. <title>5 Experiments</title> We conduct extensive experiments to evaluate our method in comparison with other state-of-the-art methods . The goal in this section is to answer the following research questions: – RQ1: What is the performance diﬀerence between SOTA baselines and ours? – RQ2: Can the category information of the sequence items contribute to the recommendation performance? – RQ3: Will the graph construction beneﬁt the model performance? – RQ4: How does our model perform on the task CSBR with diﬀerent hyperparameters setup? – RQ5: How do the models perform on the session with diﬀerent target category frequencies? Table 1: Statistics of datasets used in experiments. Dataset. We performed the evaluation on three public datasets: Diginetica Yoochoose and Jdata , which are widely used in the session-based recommendation research [4,24,16]. These datasets contain additional category information which can support our work for CSBR. – Diginetica includes user sessions extracted from e-commerce search logs, with desensitized user ids, hashed queries, hashed query terms, hashed product descriptions and meta-data, log-scaled prices, clicks, and purchases. – Yoochoose is the dataset for RecSys Challenge 2015, which contains user clicks and purchases of an online retailer within several months. In our case, we use the fractions 1/4 of Yoochoose data. – Jdata is also a dataset of a challenge hosted by JD.com. The data was ﬁltered by 1 hour duration to extract the session data. To better apply the datasets to our task, we pre-process them before training. At ﬁrst, as described in [12,14,25], we applied a data augmentation by regarding the ith as the label and items before i as the input sequence. Moreover, the category of the label item is considered as the user-speciﬁed target category. Then, since there could be short sessions or infrequent items, we removed all sessions of length ≤ 2 and items which have an occurrence less than 5 times in all datasets. In the end, for the given speciﬁc category in one session, we ﬁltered the candidate items by keeping the category of candidate item the same as the target category. We summarized the preprocessed dataset in Table 1. Table 2: Experimental results (%) of diﬀerent models in terms of P@{10, 20}, and mrr@{10, 20} on three datasets. The * means the best results on baseline methods. Improv. means improvement over the state-of-art methods. The bold number indicates the improvements over the strongest baseline are statistically signiﬁcant (p<0.01) with paired t-tests. Baseline Models. To evaluate the performance of our method, we compare it with several baselines. Note that the candidate items in the experiments are all ﬁltered with the target category, which means we evaluate the precision and rank performance only on the candidate items in the target category for all models. – GRU4Rec[8] captures patterns in user-item interaction sequences by simply utilizing several GRU layers. – NARM [12] combines the global and local representations to generate the session embedding through attention mechanism and RNN model. – SRGNN [25] transforms user interaction sequences into directed graphs and utilizes the GGNN layer[13] to learn the embeddings of sessions and items. – LESSR [4] uses a lossless GRU and a shortcut graph attention layer to capture long-range dependencies and lossless embeddings. – StarGNN [18] employs a additional star graph neural network to model the complex transition in sessions. – DA-GCN [6] uses a domain-aware GNN and two novel attention mechanisms to learn the sequence representation. Here we change the domain concept of the original DA-GCN to category in DA-GCN by employing in-category sub-sequences, along with the target category integrated. Nevertheless, we adopt the target category information to NARM, LESSR, StarGNN by fusing the target category embedding to the query part of their attention mechanism, named NARM , LESSR and StarGNN Evaluation Metrics. We employ two widely used metrics: Precision (P@k) and Mean reciprocal rank (mrr@k) following [25,4], where k = {10, 20}. They respectively represent the correct proportion of the top-k result items and the order of recommendation ranking. Implementation Details. By leveraging the frameworks PyTorch and Deep Graph Library, we implement our method. We ﬁx the embedding size of items and categories to 128. The model parameters are initialized with a Gaussian distribution with µ = 0 and σ = 0.1, where µ and σ are the statistical mean and standard deviation. To help the model converge, We employ the Adam[11] optimizer with the mini-batch size of 256. A grid search for the hyper-parameters is the following: learning rate η in {0.001, 0.005, 0.01, 0.05, 0.1}, learning rate decay step in {2, 3, 4}, number of graph neural network layers L in {1, 2, 3, 4, 5}. Furthermore, we split the dataset to train, test and validation set by ratio 8:1:1. Regarding the baseline methods, we either directly make minimal changes to their original source code for supporting our dataset, or implement by ourselves according to their papers. Table 2 shows the comparison results of IA-GNN over other baselines on the preprocessed datasets Diginetica , Yoochoose and Jdata Comparison of Diﬀerent Baselines. The performances of two RNN-based methods, GRU4Rec and NARM, are not so competitive. Nevertheless, NARM performs much better than GRU4Rec because of its usage of attention mechanism to capture the user interest. And for the GNN-based methods SRGNN, LESSR and StarGNN, they performs signiﬁcantly better than the RNN-based methods, which proved that the GNN has promising advantage for SBR. Moreover, we can discover that LESSR and StarGNN outperform SRGNN in most cases because they use shortcut graph or the star node to capture global dependencies between distant items, showing the eﬀectiveness of explicitly considering long-range dependencies. Signiﬁcance of Target Category. Furthermore, for the methods with target category information adopted, NARM , LESSR and StarGNN generally outperform their original implementation, which indicates that integrating userspeciﬁed target category information can improve the performance signiﬁcantly for CSBR. We can notice that DA-GCN performs better than the other modiﬁed baselines. This means the graph construction method including in-category sub-sequence can beneﬁt our task. Note that for dataset Diginetica , the overall improvements are not obvious because it has too many categories which can be noisy to the category enhanced models. Model Eﬀectiveness. Our model outperforms all the other GNN-based models from Table 2, which shows our model has a better eﬀectiveness. We can elaborate the advantage of our method in three aspects. First, we integrate the user-speciﬁed target category into the graph as a dedicated node, such that the model can be aware of the target category as the context of the session. Second, we inherit the in-category sub-sequence graph construction from the CDR methods, which can model the item transition per category. Third, we introduce the nodes and transitions for categories, and along with the in-category subsequence, we keep the original item sequence which can lead to less information loss. Table 3: Performance comparison for ablation study. Fig. 3: Model comparison w.r.t. diﬀerent depths of GNN. In this section, we performed some ablation studies to demonstrate the eﬀectiveness of our model designs. Category information. In our proposed method, we consider the userspeciﬁed target category as a dedicated node and other category nodes for incategory sub-sequences during the graph construction. Therefore, we compared our model with the version without a target category node (“w/o Target category node”) or sub-sequence category nodes (“w/o Category nodes”) in the graph in order to show the eﬀectiveness of introducing these nodes. On the other hand, to show the importance of introducing user-speciﬁed target category information, we used mean pooling of all item representations as the representation of the target category node instead of the target category (“w/o Target category information”) embedding to diminish the impact of target category for comparison. Moreover, we compared the case when transitions between each category node were removed (“w/o Category transition”). As illustrated in Table 3, the performance dropped on both datasets while detaching category information from the model in diﬀerent mechanisms. This proved the graph construction details aforementioned in section 4 help improving the model performance. Additional model operations. As we know, the item sequence in session has its inherent order relation, and we added the reversed position embedding for every item node to keep the original item transition information. Thus we tried to add the original item transition as directed links for all the item nodes to check if an additional lossless item order can improve the performance. Meanwhile, following [12,25,4], an additional attention mechanism which gets each Fig. 4: Model comparison w.r.t. diﬀerent groups. item contribution was added to our model. Also we want to see if a positive position embedding is better than the negative. Corresponding to above three conditions, we respectively conduct three alternative models: “Add Original item transition”, “Add Attention mechanism” and “Positive position information” for comparison. Following the result in Table 3, we can observe that by adding original item transition links to the method, the performance drops a little. The reason is the model already takes advantage of the negative position embedding and category transition which persist the original item transition order, adding these links will be redundant for the model. Meanwhile, by introducing attention mechanism, the performance was impaired because the target category information is much more signiﬁcant than attention from every item which is in diﬀerent categories. About the position information, albeit positive position embedding improves for P@20 on dataset Yoochoose , overall the performance with this information drops comparing to our method with negative position embedding. GNN depths. We conducted experiments on diﬀerent number of GNN layers for diﬀerent GNN-based methods to check the performance impact. As illustrated in Figure 3, our method keeps beyond the others with diﬀerent GNN layers. Also, we notice that the performance goes up when multi-layer GNN was conducted than that of only one single layer, because more GNN layers are able to capture the high-level and complex semantic information. Furthermore, the metrics of all methods decline approximately after 4 GNN layers, which indicates the over-smoothing is a common issue for GNN-based methods. Without exception, the performance of our method drops after about 3 layers. Nevertheless, as the number of GNN layers goes up, the performance of almost every method increases at the beginning, because GNN is competent for capturing the node embedding transitions, showing it is suitable for our task which involves item and category transitions. We further analyze the capability of diﬀerent models to cope with sessions of diﬀerent target category frequencies. For comparison, we partition sessions of Yoochoose and Jdata into three groups based on occurrence number of the target category in current session, where “None” indicates that a new category never interacted, and “Rare” means that the frequency is less than 3, while each session has more than 3 target categories in “Freq”. The percentages of session belonging to “None”, “Rare” and “Freq” group are {0.28 : 0.42 : 0.30} and {0.29 : 0.44 : 0.27} on the Yoochoose and Jdata , separately. As shown in Figure 4, our model outperforms other competitive baselines on two datasets with diﬀerent target category frequencies. It demonstrates the superior performance of IAGNN. Meanwhile, all models achieve good performance on the “Freq” group, and the performance drops with the frequency decreasing. This is partially because more item interactions in target category will reveal more eﬀective information of the user interest in target category. Especially, this task degenerates into an approximate cold-start problem for the “Rare” group without the item record in target category, and the result is worse. <title>6 Conclusion</title> This paper proposes a novel category-aware session-based recommendation task, which includes the rich category information both resided in the interaction sequence and the user’s intention. Accordingly, a novel model Intention Adaptive Graph Neural Network is introduced to take advantage of these category information, and achieves a more eﬀective performance by explicitly transferring the historical interaction information to the user-speciﬁed category domain. Extensive experiments on three real-world datasets are conducted to show our IAGNN outperforms the state-of-the-art baselines in the new task. As to future work, we prefer to involve other types of attribute information besides category information which would extend the task to an attribute aware session-based recommendation task. <title>References</title>