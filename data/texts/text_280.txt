Beregovskaya Irina applications in many areas, ranging from economics to the Internet of things. This article provides a general overview of modern approaches to recommender system design using clustering as a preliminary step to improve overall performance. Using clustering can address several known issues in recommendation systems, including increasing the diversity, consistency, and reliability of recommendations; the data sparsity of user-preference matrices; and changes in user preferences over time. related fields that are interested in examining the applicability of recommender systems. This review is focused on the analysis of the scientific literature on the topics of recommender systems and clustering models that have appeared in recent years and contains a representative list of the literature for the further exploration of this topic. In the first part, a brief introduction to the so-called classic or traditional recommendation algorithms is given, along with an overview of the clustering problem. learning; collaborative filtering; content-based filtering; user preferences; data sparsity; hybrid recommendation systems; recommendation reliability; recommendation diversity; clustering ensembles recommender systems are widely used as a decision support tool to solve this problem. Although recommender systems are a proven and affordable tool, the need to improve their recommendation ability and effectiveness is high. Among the various mechanisms available for generating similarity-based recommendations, collaborative filtering approaches are widely used. In addition to this approach, content-based filtering algorithms and hybrid filtering algorithms that combine the features of the first two varieties can be found. To improve the process of creating recommendations for various approaches, clustering methods are used with the aim of grouping users and increasing the accuracy of the recommendation system.  With the development of Internet technologies, the flow of data from all areas leads to the problem of information overload. To solve this problem, many major websites and e-commerce sites use various convenient and effective recommendation systems to improve their quality of service and to attract and retain loyal users. For example, Amazon book recommendations, marketplace apps, YouTube videos, and Internet search results.  libraries based on a hybrid recommendation algorithm, and discussed this topic in their article. The article raises the problem that, every year, the number of books in libraries increase, and users need to spend a great deal of time choosing the right book. At the same time, many books are not organized very effectively, which leads to unnecessary costs for libraries. These phenomena are caused by “information overload” and a library needs to rely on an information filtering mechanism to solve this problem. The information filtering mechanism is divided into two types: a search engine and a recommendation engine. The first mechanism uses a keyword to help users quickly find a suitable book and the second automatically recommends books to users. Personal recommendation systems seek to predict preferences based on interests, behavior, or other  Abstract: Recommender systems are one of the most applied methods in machine learning and find  This work will be useful for both beginners in the field of recommender systems and specialists in  Keywords: recommender systems; clustering; biclustering; machine learning; unsupervised  In today's digital world, users suffer from the problem of information overload, and  1. Introduction Recommender systems have become quite common and are used in various fields [56–63].  Tian et al. [1], for example, developed a personalized recommendation system for college information from the user. Personalized recommendations can not only meet a user’s needs, but can also help users to explore and discover new hobbies. The application of recommendation systems in university libraries solves the problem of book selection and increases the utilization of library resources. content-based filtering, and hybrid recommendations. information about the behavior, activities, and preferences of users and the predicting what a user likes based on the similarity of the user to other users. a profile of a user’s preferences. These algorithms try to recommend items that are similar to those that a user has liked in the past. content-based filtering. In some cases, hybrid approaches can be more effective. providing services to users. The essence of this approach is to improve the ability of active users to find accurate and reliable neighbors. However, the collected data are extremely sparse in the custom item ranking matrix, and many of the existing similarity measurement methods used in collaborative filtering are not very efficient, which results in poor performance.  recommends items to a user by analyzing the user’s data; these data can be obtained by tracking browsing history, purchase records, rating records, etc. for similar users based on how users rated items. In a typical CF system, a user-item matrix is created in which a user’s preference for an item is represented as a rating. CF estimates the similarity between a target user and other users, finds a neighborhood by selecting similar users, and then predicts the rating of each unrated item for the target user using the neighborhood ratings. however, also has some disadvantages: items that no one has rated cannot be recommended, and accurate recommendation results are difficult to obtain for users who have rated only a few items. In addition, a profile injection attack against CF (discussed in [21]) is another issue related to this feature. Attacking users or competing companies can insert fake user profiles into the user element matrix to influence predicted ratings, increasing the likelihood that their elements will be recommended or decreasing the likelihood that opponents’ elements will be recommended. filtering algorithms. In memory-based CFRSs, a custom member scoring matrix is built to generate appropriate recommendations, and the algorithm can also be further broken down into collaborative filtering based on users and members. The user-based CF algorithm computes the similarity between a target user and a neighboring user, and then the recommender system generates recommendations based on the interests of a highly-rated similar user. In CF, user-based recommendations are generated based on the assumption that a user with similar qualities to the target user in the present may have similar desires in the future. Likewise, the item-based collaborative filtering algorithm computes a similarity score between different items and provides recommendations to an active user. To make recommendations with CF based on items, item similarity is calculated with the assumption that items that are similar to previously consumed items may be purchased in the future. Model-based CF approaches are widely used to address data reduction and scalability issues through the use of a custom member rating database. user model, finding the closest set of neighbors, and making recommendations. for n items; U denotes a set of m users and I represents a set of n items. The rating data of the rating matrix are sparse, missing, or unknown rating data and are indicated by the symbol “?”.  There are three main categories of recommendation algorithms: collaborative filtering,  1.1. Collaborative Filtering Algorithm Collaborative filtering is the most widely used approach in terms of recommendations for  Collaborative filtering is a successful techniques in recommender systems, which  Collaborative filtering (CF) does not use the content properties of items and can only search  CF has the advantage that recommendations can only be made using ratings. This feature,  CF algorithms are generally divided into memory-based and model-based collaborative  The user-based collaborative filtering (CF) algorithm is divided into three stages: creating a  In recommender systems, the user-member rating matrix (R) contains the ratings of m users denotes the rating of user u for item i. Supposing that there are n users,   expressed by an N * M matrix where N is the number of users and M is the number of categories. The number of items selected by the user from category j is denoted as R centric recommendations using an item-rating matrix, which is usually defined as usr × itm. In an item rating matrix, usr represents an active user with various items of interest, and itm denotes specific items in RS. When the target user wishes to receive an offer from the recommendation system, neighboring users with similar tastes to the target user are determined. Based on the assessment of the previous ratings of the items of neighboring users, an item that might be of interest to the target user is predicted. In other words, a product to be recommended to a customer is rated based on the preferences of neighboring users with similar qualities to the target user’s. active user and available users, plays an important role in the process of predicting the rating of a recommender system.  Pearson’s correlation coefficient (PCC) or Pearson's similarity metric (PSim), given that similar users tend to rate an item with similar rating points. Empirical analysis of different similarity measures relative to the CF recommender system shows that PSim performs better than other existing similarity measures when calculating relationships between users [50]. calculates a kind of average of all neighboring users’ ratings. Based on the calculated forecast, the set of elements with the highest rating is offered to the active user. similarity between users is an important part of this approach. Similarity metrics used mostly include: make an offer to the target user B very large and sparse, which complicates the performance of recommendations. The most active users will only read a small portion of the entire database. The sparseness of the matrix reaches 99.99% [1,12,33]. set of features (profile) to each user and each item. This profile is used to measure the similarity between users and items. These features usually come from a natural description of the object being recommended; for example, a movie profile typically contains information about its genre (action, comedy, etc.), cast, box office popularity, release date, etc. [65].  of an items. To directly compare user and item profiles, CBF heavily relies on similarity metrics— functions that compute how similar or different two feature vectors are. user’s past behavior. They derive desired recommendations from the feature-based representation of the items in the database [66].  , and a set of item categories, , R is  The user-based collaborative filtering recommendations system (UBCFRS) generates user- The computational similarity method, which allows inferring the similarity between an  When ratings are explicitly presented, similarity can be easily determined using the  The ratings are predicted by an average approach using an aggregation function that  A user-based algorithm calculates the similarity between two users. Calculating the  Following the nearest set of neighbors, U, a list of recommendations (B) is produced to  Collaborative filtering often suffers from thinness problems. The user–item matrix can be  1.2. Content-Based Filtering (CBF) Content-based recommendation systems [60,64,67] work in a different way. They assign a  Thus, in order to build a CBF recommendation system we need to describe a set of features  CBF models do not compare users directly; they base their recommendations solely on the defined. In a library system, for example, information about a book may include title, classification number, index number, author, publisher, price, keywords, title, and authors. These features are used in CBF models as item profile features. to the user. Finally, various candidate items are compared with the user’s previously read books, and the most appropriate books are recommended. ratings made by users who are similar to those target users. Therefore, we can expect an increase in forecasting accuracy due to the early grouping of similar users into the same cluster. If attacking user profiles are grouped into one cluster, predictions for other trusted users can be made without being affected by the attacks. On the other hand, if the profiles of the attacking users are similar to those of many trusted users, grouping users can increase the impact of the attacks. The main purpose of the clustering algorithm is to group similar users into one cluster. In clustering-based approaches, neighboring users from a cluster are selected for target users they approach.  similar to each other than they are to those in other clusters [52]. Clustering is often used as an unsupervised machine-learning tool to find a hidden structure in large datasets. It is based on grouping items in a dataset into several groups, or clusters, such as items in the same group being, on average, more similar than they are to items in different groups. In clustering algorithms, each item in the whole dataset is considered as a point in n-dimensional space, where n is the number of features of the item. idea of k-means is to define cluster centroids—a set point in n-dimensional space—so that each point is. The algorithm of the k-means method is described as follows: sum of squares within the cluster. difference, go to Step 2, otherwise go to Step 5. determine neighboring users for a target user. In real-time recommender systems, not all users can rate, are in interested in, or can familiarize themselves with all available items. When there is a relationship or interaction between a user and an item, the user–item rating matrix will be sparse. This critical issue affects the accuracy of rating predictions by the recommendation engine and is known as the sparsity problem. With the increasing need to solve the sparsity problem, but inability to do so, similarity-based models are inadequate for defining an effective list of similar users. In parallel, similarity measures are computationally complex, and using them as the data scale increases will lead to an exponential increase in complexity. To solve problems, such as similaritybased measures when selecting neighboring users, clustering techniques can be used to separate users into different clusters. Typically, clustering can be defined as the process of grouping or organizing users in a database into a cluster while maintaining a higher degree of similarity between them in that cluster. Hence, when a target user is found to be similar to a cluster of users, the user is then added to that cluster, and items of interest to the users of that particular cluster are recommended to the target user. Using clustering techniques in recommendation systems helps to  For the content-based recommender system algorithm, first, the features of items need to be  A user’s preference profile can be expressed as a set of n tuples W: where w denotes the preference of user i and weights v denote the importance of a feature  1.3. Clustering Algorithms CF is a system that predicts what items should be recommended to target users based on  Clustering is the task of grouping a set of objects so that objects in one cluster are more  One of the simplest and still most common clustering algorithms is k-means [53,54,55]. The  Step 1. The set of k-means is determined as m, ...,m. Step 2. Each observation is linked to a specific cluster, the average of which gives the least  Step 3. The new mean of the centroids of the observations in the new clusters is calculated.  Step 4. The new centroids are compared with centroids calculated earlier; if there is a  Step 5. Stop and display the result of the clusters. In recommendation systems, similarity-based measures have traditionally been used to identify groups of users with similar tastes, and this approach greatly improves performance by being immune to sparsity issues. Commonly used clustering techniques include fuzzy, selforganizing maps (SOM), and k-means clustering. different settings, is known as a cluster ensemble (CE). Clustering ensembles can overcome the instability issues of autonomous clustering models. strategies. The first is to conduct separate collaborative and content-based filtering. The second is adding content-based filtering capabilities to collaborative filtering (or vice versa). The third is the combination of the previous two approaches into one model [2]. To reduce the sparseness in data, the authors applied k-means clustering before calculating the similarity.  the problem of sparsity, they replaced books with book categories, thus using a user–category matrix; and then carried out the clustering of users (k = 15). The sparsity of the matrix was calculated as the proportion of zero matrix elements among all matrix elements. The initial matrix sparseness was 99.99% and the authors managed to reduce it to 76.42%. and CBF (described above), the precision metric was chosen: hybrid algorithm for different sizes of training datasets. By increasing the size of the training sample, the accuracy metric gave a greater value for all algorithms, with the hybrid algorithm having much higher values than the rest. combining clustering algorithms. It can also effectively solve cold start problems when a new user or a new book, about which little is known, appears in the system. time model, thus creating a personalized recommendation system for university and college libraries. To some extent, this increases the efficiency of book recommendations and the number of books that users borrow, and reduces the wasteful use of university book resources. predict item ratings. There is no doubt that the accuracy of predictions is an important property of recommender algorithms. Much of the research on recommender systems has focused on improving accuracy (for example, see [69–73]); however, other factors play important roles in satisfying user needs. One such factor that has gained importance of late is the diversity of recommendation lists. For example, a system that offers movies to its users can be very accurate, that is, it can be very good at predicting user ratings by item; however, if a user’s recommendation list consists of films of the same type (for example, only sci-fi films), it may not be very satisfying. A good system should also recommend a diverse set of films (films of different genres) to users.  diversity can only be increased at the expense of accuracy. Nevertheless, this decrease in accuracy may be preferable if user satisfaction increases. This is a well-known issue with recommendation systems [68].  accuracy is not the only property that a successful recommender system must have. For example, McNee et al. (2006) argued that the assessment of recommender systems should go beyond the usual metrics of accuracy [4]. Herlocker et al. (2004) discussed novelty and insight as important  The combination of different clustering algorithms, or the same clustering algorithm with  2. Methods of Using Clustering to Improve the Quality of Recommendation Systems 2.1. Hybrid Filtering Algorithm for Recommendations The authors of [1] considered hybrid recommender systems and highlighted their three main  In their experiments, the authors of [1] used a dataset from a university library. To combat  To compare the hybrid model of recommendations with conventional models, namely, CF where R(u) denotes a recommendation sheet following a training set, and T(u) is a test case. The authors of [1] ran a collaborative filtering algorithm, content-based filtering, and a  The improved collaborative filtering algorithm solved the data sparseness problem by  The authors of [1] then used the Spark big data platform to improve the usability of the real- 2.2. Using Clustering to Increase Recommendation Diversity The success of a recommendation algorithm is usually measured by its ability to accurately  There is, however, a trade-off between accuracy and diversity. That is, in most cases,  It has been some time since recommender system researchers realized that predictive parameters in evaluating recommender systems [5]. The concepts of novelty and insight are closely related to diversity, as increasing the diversity of the recommendation list increases the chances of recommending new and random items to the user. authors have proposed a greedy selection algorithm [6]. In this method, the items are first sorted according to their similarity to the target query, and then the algorithm begins to gradually build the search set (or recommendation list) so that both similarity and diversity are optimized. This is achieved in the following way: in the first iteration, the element that most closely resembles the target request is placed in the retrieval set, in the next iteration, the element that has the maximum combination of similarity with the target query and diversity concerning the retrieval that is already built is selected for the user’s recommendation list. Iterations continue until the desired retrieval set size is reached. As noted in another article [7], this algorithm is highly inefficient, so those authors proposed a limited version of the greedy choice algorithm. In this version, the algorithm first selects the number (b) of elements closest to the target query, and then the greedy selection method is applied to that set of elements instead of the entire set of elements. As b approaches n (the number of elements), the complexity of this restricted version approaches the complexity of the greedy selection method. Zhang and Hurley [8,9] suggested another optimization-based approach based on the trade-off between similarity and diversity as a quadratic programming problem.  increase the diversity of lists of recommendations with a slight decrease in accuracy. The idea was to group items and build a list of recommendations by selecting items from different groups so that the diversity of recommendations is maximized without reducing the accuracy too much. a user. Thus, real-world recommender systems can use ClusDiv without modifying existing prediction algorithms. recommendation lists, the time complexity of the online recommendation algorithm must be very low. The time complexity of an algorithm is a measure of its computational efficiency relative to the growth of the dataset. More efficient algorithms may even take more time to process a certain amount of data, but the time needed increases when the amount of data increases. This makes them more efficient in the long run and far more scalable. ClusDiv has a very low time complexity, which makes it a highly scalable algorithm.  find a diverse set of items. ClusDiv includes a configurable parameter that allows users to customize the diversity level of their recommendation lists. They can adjust this setting independently of other users. Thus, it is up to users to decide how much they want to sacrifice accuracy in favor of diversity. It is still unclear how to implement this configuration in practice and the authors of [3] did not specify this. rating information is enough to diversify recommendation lists. greedy method proposed by Smyth and McClave, since the other method proposed by Hurley and Zhang (2011) had similar levels of diversification efficiency and a slightly worse computational time complexity. As it turns out, ClusDiv was much faster than the restricted greedy method, while still providing a similar diversification efficiency. according to users’ tastes. To do this, researchers grouped items in a user profile and recommended items that fit those individual clusters well rather than the entire user profile [10]. ClusDiv also organizes elements into groups; however, as described in detail below, it groups all the elements in a system, not just the elements in a user profile. That is, the goal of ClusDiv is not to recommend elements that suit users’ tastes, but rather to recommend a diverse set of elements while maintaining the highest possible accuracy. This gives users the ability to encounter random items. to which the similarity within a list was calculated. The authors of [3] proposed a heuristic  Several strategies have been proposed to address the issue of diversity. In earlier studies,  Aytekin and Karakaya [3] described a new method (called ClusDiv) that can be used to  ClusDiv is applied after a prediction algorithm predicts unknown ratings of items offered to  For a recommendation system to allow users to customize the diversity levels of their  It also allows users to experiment with the recommendations provided by a system and to  No content information (such as genre or film director) about objects is required. Product  To show the effectiveness of ClusDiv, the authors of [3] compared it only with the limited  Earlier studies have also used a cluster approach to better diversify featured products  Ziegler et al. [11] defined a similarity metric based on classification taxonomies, according algorithm for diversifying recommendation lists based on this similarity metric. As in other studies [68,69], the proposed method increased diversity but had some negative effects on accuracy. One of the important contributions of this work was to empirically show that overall user satisfaction increases with a variety of lists of recommendations. This result supports the claim that the accuracy of recommendation lists is not the only requirement for user satisfaction. as the average difference of all pairs of items in the user’s recommendation list. If I is the set of all elements, and U is the set of all users, then the diversity of the list of recommendations of a particular user, D (L (u)), can be defined as follows: the dissimilarity of items , which is defined as one minus the similarity of items i and j. appearance. In other words, the diversity value generated using Formula (5) will be dominated by the default values used for the missing estimates and will be misleading. of using the absolute diversity values defined in (5). Formally, the z-diversity of the recommendation list is defined as: elements in L(u) and I, respectively. SD(I) is the standard deviation of the differences of all pairs in I. autonomous phase, in addition to building a model, the authors constructed N (where N is the size of the list of recommendations, L(u)) clusters of elements, C = {C built using the standard k-means clustering algorithm. Items are clustered based on their ratings, which are assigned by users. So the proposed approach is to cluster together items that were rated similarly by a large group of users. The premise is that items found in the same cluster are quite similar to all the users. Information about the contents of the items is not used. However, if information about the content of the items is available, and if the similarities between items based on this information can be determined, then those similarities can also be used when clustering items. with a (u, i)th record,  list of recommendations of user u. Users have their vector  then cluster  of the cluster weights for any user should be equal to N (the size of the list of recommendations). recommendations for u as follows: iterate over the items in the list of recommendations for u from top to bottom and move the item to the list of the first N for u if the weight of the cluster to which this element belongs to is greater than zero and subtract one from this cluster weight. Then, they continued to scan the list of recommendations in this way until all the cluster weights were equal to zero. When all the cluster weights were zero, the final list of recommendations was ready. based, user-based collaborative filtering, and SVD (a variant of CF algorithm based on singular value decomposition of matrices, see [14]). the bounded greedy method (BG), which was designed primarily to optimize the diversity and completeness values in recommendation lists. The significant superiority of ClusDiv appeared when the issue of time complexity was considered. The authors also drew attention to the fact that the maximum level of diversity achieved by the BG method was higher than that of ClusDiv.  One possible metric for measuring the diversity of a user’s recommendation list is calculated where  is a list of user recommendations  and , and  is  Lists of recommendations with diversity values close to 1 will seem to be very diverse in  The authors chose to use z-scores for diversity values, which they called z-diversity, instead where I is the set of all elements in the dataset, and D(L(u)) and D(I) are the diversity of  Like many recommendation algorithms, ClusDiv has autonomous and online phases. In the  The ClusDiv algorithm is based on the construction of cluster weights (CW). CW is a matrix  After the authors generated the cluster weights of user u, they created a list of  In the experiments, authors use three different recommender system algorithms: element- For all three datasets, ClusDiv’s z-diversity and completeness performance were as good as  However, at high levels of diversity, the values of completeness were very low, which meant that the levels of diversity were useless in practice, as the recommendation lists would be very imprecise. clustering user preferences to reduce the impact of data sparsity. User groups were first introduced to differentiate between users with different preferences. Then, given the preferences of an active user, a set of nearest neighbors from the corresponding user group (or groups) was achieved. Additionally, a new similarity measurement method was proposed to calculate the similarity between users. Finally, experimental results on two sets of test data showed that the proposed algorithm was effective at improving the performance of recommender systems. model-based approach and a memory-based approach [13]. The model-driven approach first builds a prediction model based on a custom member rating matrix and then predicts scores of the target members. Unlike the model-based approach, the memory-based approach first calculates the similarity between users/items, selects the top k similar users/items as active neighbors, and then generates predicted results. A memory-based approach can be divided into a user-based or element-based approach. In [12], the authors focused on improving the performance of custom recommender systems to reduce the impact of data sparsity.  modification of the similarity measure and the choice of a user’s neighbor when predicting a rating. Pearson’s correlation coefficient (PCC) and cosine (COS) are often used as measures of similarity in recommender systems. Additionally, Jamali and Ester [15] proposed a modified PCC-based similarity measurement method using a sigmoid function (SPCC), which emphasizes the importance of common ranking elements. Intuitively, if users have more general rating elements, then they are more similar. According to the method of the cosine measure of similarity, the rating scale is not taken into account, and to solve the problem of shortage, an adjusted method of measuring cosine similarity (ACOS) was proposed [16].  proposed many modified approaches for the selection of neighbors. For example, Kaleli [17] proposed an entropy-based optimization to generate a more qualified set of neighbors. It assigned a degree of uncertainty (DU) for each user and required neighbors with minimum differences in DU value and a maximum similarity value with the active user. Boumaza and Brun [18] introduced the concept of global neighbors, which are the neighbors of all active users. Kim and Yang [19] presented a threshold-based neighbor selection approach; in this approach, neighbors were determined in a certain range of choices based on the similarity of preferences. Anand and Bharadwaj [20] presented a recommendation framework combining both local and global similarities to address the problem of data sparsity, which allows to vary the importance given to global user similarity relative to local user similarity. clustering user preferences that differ from those above. On the one hand, user groups are introduced to select more accurate and reliable neighbors for an active user. Users with different preferences have different rating habits. Thus, users can be combined into different user groups.  methods were not suitable to account for user preference factors, and they proposed a new similarity measurement method for calculating the similarity between users in the clustering process. Moreover, extensive experiments showed that the algorithm proposed in [13] can significantly improve performance on sparse-rating data.  neighbors, after which the prediction can be made for the target element. The recommended formula is defined as follows:  2.3. CF with Clustering User Preferences The authors of [12] proposed a powerful new collaborative filtering algorithm based on  Developing recommendation technology can mainly be divided into two categories: a  Modifications and improvements to collaborative filtering are mainly found as two aspects:  In addition to the methods for measuring similarity suggested above, researchers also  The authors of [13] presented an efficient collaborative filtering algorithm based on  (1) An optimistic user group in which users prefer to rate high;  (2) A pessimistic group of users, in which users prefer to give low ratings;  (3) A neutral user group in which users tend to give reasonable ratings for products.  On the other hand, the authors noted that most of the previous similarity measurement  After calculating the similarity, k closest similar users are specified as the active user’s of active user t, |  and  respectively. Meanwhile,  clustering center  characteristics; that is,  depends on the similarity between the user and these clustering centers. Hence, an effective method of measuring similarity is useful for distributing the remaining users into different user groups. To emphasize the importance of user preference, the authors proposed a new similarity measurement method for calculating the similarity between users, as shown below:  user. They first calculated the similarity between users using the method they proposed, and the similarity matrix was denoted as centers with different preferences, respectively. Finally, users were categorized into different user groups based on their similarities. This generated various user groups, which were an optimistic user group  clustering process, the k nearest neighbors for the active user could be determined. follows: analysis was required. The choice of clustering centers required additional time—O (m), where m denotes the number of users, and when the authors calculated the similarity between users of the proposed method, the computational complexity was O (m (m + 2)).  HetRec2011–MovieLens (HRML, [75]). to measure the quality of the predictions, as well as the accuracy and completeness to measure the quality of a set of recommendations. the number of considered neighbors for an active user, the MAE indicator decreased. that the accuracy of COS-CF recommendations was lower than that of modified-COS-CF with an increase in the number of nearest neighbors. Likewise, modified-PCC-CF also clearly outperformed traditional PCC-based collaborative filtering (PCC-CF). algorithms. distinguish between different typical users, the main work in this article is to develop a structure for distributing users into groups of users with different preferences. Hence, neighboring users of the active user can be found to have consistent preferences. Traditional methods of measuring Pearson’s correlation coefficient and cosine similarity have drawbacks. In [13] a new similarity measurement method to look at user preferences from a local and global perspective, respectively, where  denotes the forecast of active user t for target element i,  is the set of neighbors  As discussed above, users can be divided into three different user groups. Suppose ,   represent the optimistic user group, the pessimistic user group, and the neutral user group,  In the process of clustering, the rating information of clustering centers has special  Next, the authors developed an appropriate algorithm to make recommendations to an active  After obtaining a set of neighbors, , for active user t, one can predict the rating () as  To evaluate the performance of the algorithm proposed by the authors, time complexity  In [13], this algorithm was tested on two well-known datasets: MovieLens (ML, [74]) and  To assess the performance of their proposed method, they used the mean square error (MAE)  Over the course of experiments on the two data sets, it was revealed that, with an increase in  When comparing the results of COS-CF and modified-COS-CF, the authors were convinced  All the modified approaches had a higher recommendation accuracy than traditional  This approach is based on the assumption that users have different rating habits. To was proposed. In the course of experiments, the authors evaluated the effectiveness of their proposed algorithm for improving the quality and performance of recommendations, respectively, and experimental results for the two sets of control data demonstrated that the proposed algorithm performed better than some modern recommendation algorithms. In short, the proposed algorithm was effective at improving the performance of recommender systems. based on the ratings of many users. However, this method has several problems, and one of them is the presence of attacks aimed at distorting the predicted ratings of specific elements. The authors of [21] proposed a collaborative filtering technique that reduces the impact of attacks while maintaining or improving prediction accuracy by repeatedly applying clustering to target data and predicting ratings for unrated items within each cluster. In addition to this, the usefulness of the method was investigated using a scoring method that measured the error between actual user ratings and predicted ratings. Additionally, attack resistance was investigated by comparing pre- and post-attack prediction errors. used in recommender systems. CF predicts the ratings of unrated items by assessing the similarity between users and calculating a target item’s rating prediction for a target user based on observed ratings from similar users. results of recommendations. In CF-based recommender systems, the quality of the recommendation can be influenced by the introduction of multiple user profiles for attacks, in which specific items are deliberately rated high or low. Eliminating this defect is important to improve the reliability of recommender systems. those users prefer, it is expected that the prediction accuracy can be improved by pre-clustering similar users. However, you can increase the impact of attacks if the cluster sizes are too small. Thus, [21] proposed a forecasting method that performs clustering. calculates the centroid of the users in each cluster as a representative cluster point, and then clusters again using the representative points to connect the split clusters. The similarity between users in the same cluster is then calculated, and item ratings are predicted using user similarity and ratings suggested by similar users within the cluster. are first divided into clusters using k-means clustering, and then clustering is performed again using the centroid of users belonging to each cluster. Each element  element. clustering. It is necessary to provide a certain number of clusters for the first clustering and to ensure that the cluster size grows for the second clustering. prediction accuracy. CF-based prediction is performed on items that are rated by users, and forecast accuracy is assessed by measuring the errors between the actual user-assigned ratings and the predicted CF-based ratings. In addition, after measuring the errors before and after attacks, the resistance to attacks is analyzed by calculating the difference between the errors, before and after the attacks, which is equal to the change in the predicted CF estimates before and after the attacks. MAE is used as a measure of measurement error. types of attacks have been tested in experiments, due to limitations, only a discussion of an average attack [23] is given in this article. An average attack is carried out through attack user profiles,  2.4. Using Clustering to Improve Recommendation Reliability Collaborative filtering is widely used by online vendors and review sites to recommend items  Collaborative filtering (CF), the subject of this article, is one of the representative techniques  However, CF has a vulnerability to profile injection attacks [22], which intend to distort the  Because CF searches for users that are similar to the target user and recommends items that  The prediction method first divides all users, including attackers, into multiple clusters,  Clustering is used to separate users in a recommendation system into similar groups. Users   can be calculated as follows: where m is the number of users in the cluster, and  is the rating of the i-th user to the j-th  The number of clusters was set to 20–100 for the first clustering and 2 for the second  The goal of [21] is to reduce the impact of attacks while maintaining or improving the  There are several types of attacks against CF-based recommender systems. Although three with ratings of randomly selected items around the average of each selected item and with ratings of targeted items within the highest or lowest rating. target is called a push attack, and an attack aimed at reducing the popularity of a target is called a nuclear attack. The authors of [21] focused on a push attack aimed at increasing the ranking of certain items. When performing a medium push attack by injecting attack user profiles into the source data, targets were randomly fetched and given the highest scores, and the other items, excluding the target items, were randomly selected to average the user ratings of the corresponding item. In the experiments, the number of attack users (attack size) and the number of randomly selected elements, except for the target elements (placeholder size), were changed to check the impact of attacks and the reliability of the CF recommendation in detail.  In the experiments, CF-based prediction was performed for each method—no clustering, single clustering, and double clustering—and the errors between predicted ratings and actual user ratings were measured. The expected result was that prediction accuracy improves as the number of clusters increases. ratings and the actual user ratings is measured. The trend was similar to the results before the attacks; that is, the error based on the one-shot clustering method was the smallest, followed by clustering twice, and then without clustering. at least one of the other two methods, and sometimes, it was the smallest among all three methods for some cases with certain attack sizes and non-target elements. This indicates that by specifying the appropriate number of clusters, the double clustering method can outperform the other two methods in terms of resistance to medium attacks. rating forecasting process twice within clusters. Additionally, a method was proposed for assessing resilience by measuring errors between predicted ratings and actual ratings, before and after attacks, and calculating the difference between errors to investigate the impact of attacks. The experiments in [21] showed that a prediction method that performs clustering twice is effective in mitigating attacks.  Time recommended types of resources and can work with unstructured complex objects [25]. However, with the ever-increasing number of users and resources of an e-commerce website, the traditional collaborative filtering recommendation algorithm is faced with problems of data sparseness, realtime change, extensibility, and so on. Therefore, it is difficult to ensure the required quality of a recommendation system. obtained some achievements. For example, based on the traditional method of measuring similarity [26], an improved method for calculating similarity has been proposed, which increases the recommended accuracy; the data sparseness problem was also effectively solved when matrix factorization methods, such as single value decomposition (SVD, [27]), non-negative matrix factorization (NMF, [28]), etc. They were applied in the joint filtering algorithm, and the real-time system was improved when clustering was introduced into the joint filtering algorithm. In the literature [29], the k-means method is used to cluster users and proposed projects, which reduces the cost of searching for the nearest neighbor. have been assessed in the clustering process, in combination with user ratings and project attributes, user-clustering better reflects user interests and clustering results become more reliable. However, the algorithm does not take into account the situation where the interests of users can change over time, and the clustering of users cannot reflect the changing interests of users very well, and thus the problem of a new project (cold start) cannot be solved.  According to the purpose of the attack, an attack aimed at increasing the popularity of a  For the experiments, the authors of [21] used the well-known Movielens100K dataset [74].  Fake user profiles with a medium attack were then added and the error between the predicted  Focusing on the double clustering method, the average error difference was always less than  Thus, [21] proposed a robust co-filtering method by running the clustering process and the  2.5. Using Clustering in Recommendation Systems to Reflect User Interest Change over  CF algorithm’s advantage is that it does not impose special requirements on the  To solve these problems, many scientists have carried out intensive research and have  The authors of [31] also presented additional attributes of projects proposed for users that multidimensionally, simultaneously with the introduction of the attributes of proposed projects, and presented an improved collaborative filtering algorithm based on user clustering. neighbor search, and acquiring recommended results. The accuracy of the choice of the nearest neighbor, to a certain extent, determines the quality of the recommendation algorithm; that is, the method of measuring the similarity for the joint filtering algorithm is very important. implemented in three ways [32]: vector cosine similarity, corrected cosine similarity, and Pearson correlation similarity.  nearest neighbor rating information: cluster different data, different applications have different clustering algorithms. The k-means clustering algorithm is simple and efficient, is suitable for large datasets, and can be very well implemented into the collaborative filtering algorithm; the authors of [31] chose it as the clustering algorithm in their work. clustering can be divided into two phases: choosing a recommended set of candidates for a project and an online Top-N recommendation. users are located is the set of candidates for the nearest neighbor search. The choice of the set of candidates recommended for the project should be based on the results of clustering the user and the project to make the recommended set of candidates for the project perfect and reliable; the following steps are needed: needs to be constructed. of user  users  attributes of the project need to be built. whether the project includes the  for  the nearest neighbors and is written as  then, one must select projects  project of user u recommended by the set of candidates and written as  The authors of [31] used the temporal fade function to display user interests and change them  Here, the joint filtering algorithm can be divided into three stages: data presentation, nearest  Currently, the similarity measurement method for the joint filtering algorithm is usually  The current user’s rating for unrated projects can be predicted based on the current user’s  Regarding the clustering of users, while there is no general clustering algorithm that can  The steps to implement the authors’ improved collaborative filtering algorithm based on  Step 1. Selecting the recommended set of project candidates Similar users are located in the same cluster by clustering users. The cluster in which the  • Supposing that the cluster in which user u is , for  its vector of interest   • An improved method of calculating the degree of similarity.  where A is a set of project attributes; , respectively, represent the rating weights  by project attribute ; to calculate the similarity for , it is necessary to select  with the highest similarities as the nearest neighbors, and this is written as . • It is necessary to take a rating set of projects from  according to  and u. •  need to be used to find cluster  to which it belongs, for  the vector  • An improved method for calculating the degree of similarity needs to be used. where A is a set of project attributes;  project attribute; , respectively, represent  . It is necessary to select the projects  with the greatest similarity, which will be  • Calculate the union    . • It is necessary to delete projects in  that are rated by user u and compare the similarity;   and obtain a Top-N recommendation. According to the ranking forecast for the recruitment of recommended candidate projects, the N highest-rated projects to be included in the recruitment are selected, thus completing the Top-N recommendation process. experiments. The MAE (mean squared error) was used to assess the rating prediction errors; the authors used the recall rate and precision rate to assess the accuracy of the recommendation sheet.  for different algorithms: the traditional joint filtering algorithm based on the user’s similarity level using Pearson's correlation (P); a collaborative filtering algorithm based on combining user similarity calculation methods (Pearson with Salton) (PS); NMF algorithm; -c error MAE for the authors’ proposed improved collaborative filtering algorithm (ICCFRA). The result showed that, compared to the P, PS, and NMF algorithms, ICCFRA sharply reduced the MAE, which significantly increased the quality of the rating forecast. with recommendation lengths of 30, 40, and 50. collaborative filtering algorithm. The experiment result for the MovieLens dataset shows that the algorithm significantly improved the MAE, as well as the recall rate and precision rate. In addition, the clustering-based collaborative filtering algorithm proposed in this article processes the original score matrix first using the time decreasing function, which solves the problem of the relevance of the original score. sparseness of the rating matrix of historical users and the cold start of new users [34,35]. The sparseness of data indicates that historical users only rate a few items; for example, an audience, on average, and far fewer users leave comments (ratings) and view less than 2% of movies on a movie website. With an increase in historical data, the situation will be even more severe. The scarcity of rating data leads to a serious decrease in accuracy and causes the high computational cost of CF-based methods. A cold start means it is difficult to predict the preferences of new users who have no item records. limitations and improve the performance of the recommendation system. One class of a wide range of solutions is to take advantage of clustering or dimensionality reduction to eliminate the effect of historical sparseness in user ratings. Typical representatives of these methods are bicluster algorithms, singular value decomposition, the factorization of a non-negative matrix, etc. [36, 37, 38], and the key idea of these methods is to use local dense and low-dimensional modules of a rating matrix instead of the original sparse data in user ratings to assess the similarity between new users and historical users; they can then make recommendations using an improved similarity measure. to improve the perception of sparse data and complex information. The traditional measures of similarity in CF, as we have seen in previous sections, are Pearson's correlation or cosine correlation. entropy (CBE-CF) to overcome data sparseness and heterogeneity. Specifically, it takes advantage of biclustering to determine dense modules of a rating matrix and then measure the similarity between a new user and the dense modules based on a measure of information entropy. Finally, a linearly weighted combination of user-based CFs with an improved similarity measure and itembased CFs are used to fulfill the recommendation. measuring user similarity increase dramatically with an increase in the number of past users; consequently, the element-based CF is designed to adapt rapid response requirements to a large- Step 2. Online Top-N recommendation.  To obtain a recommended result for user u, we also need to predict the rating of projects in  Furthermore, the authors of the article in question used the MovieLens dataset in their  After implementing the rating calculation procedure, the authors compared the MAE errors  The accuracy of the ICCFRA algorithm, when generating recommendations, was the highest  Thus, the execution time of the online algorithm was reduced by improving the real-time  2.6. Using Clustering to Deal with Data Sparsity In practice, the effectiveness of CF models, as we have already seen, is limited by the  Researchers have proposed several CF best practices to overcome the above-mentioned  Another strategy for solving constraints in CF is to use some advanced similarity measures  The work of [33] presents a method of joint filtering based on biclustering and information  Although a user-based CF is widely used in various applications, the computational costs of scale product offering data to users. Unlike user-based CF, item-based CF first constructs a measure of item similarity, based on the common users, because the number of items is often much smaller than the number of users in most applications; this strategy can effectively reduce the computational cost of determining the k-nearest neighbors. group elements, the patterns of which can be well described by the consistency of local preferences among both the users (rows) and elements (columns) of a rating matrix, and are often used to address the sparseness of data in a recommendation system. The authors of [33] used biclustering techniques to identify combination patterns consisting of a local dense rating area for identified items with specific users. The general idea of biclustering is to iteratively aggregate the rows and columns of a rating matrix until convergence [39]. Specifically, for rating matrix R, X represents users (rows) and Y represents items (columns), and then I  X and J  Y indicate an indexed subset of users and items in the same cluster. modules, is a measure of the distribution of information of a random variable [33]; a high entropy means a tendency towards a uniform distribution, and conversely, a low entropy indicates a sharp distribution of the random variable. dataset increases. In [33], the authors proposed a new collaborative filtering (CBE-CF) method for extracting local dense rating units to cope with data sparseness and the computational efficiency of traditional recommendation algorithms by introducing information entropy and biclustering in collaborative filtering. Experimental analysis shows the characteristics of the CBE-CF method proposed in [33] and the accuracy and computational costs are higher and lower than modern results on a set of reference data. determine its low-dimensional and dense local modules. Users in each specific cluster have identified item scoring templates, and each template points to a specific cluster. the authors first count the number of elements assigned the same rating in a particular cluster and then estimate the probability that each rating for the identified cluster will be found. The entropy information for each cluster is then calculated, which can be used to measure local similarity between new users and clusters. sort, in ascending order, the differences in information entropy between all clusters  new user  associated with the smallest differences are selected as the nearest neighborhoods for building the recommendation system. This strategy can effectively reduce the computational costs of assessing similarity because it simply focuses on a few predefined clusters instead of real-time similarities between a huge number of new user pairs and historical users. The authors assume that  elements of the new user can be divided into  the first N neighboring cluster. Then the similarity between the new user is determined for  and the cluster  taking the weighted average of N first nearest neighbors. local patterns of historical users and significantly reduces the computational costs for large-scale training data; however, this method does not take into account general patterns of historical data. Hence, the authors present combinatorial collaborative filtering, integrating the advantages of biclustering and information entropy CF and traditional element-based CF linearly; this model also maintains a low computational complexity: phase, where m, n, k are the user number, element number, and cluster number, respectively.  It is worth noting that, in practice, some users often share a common preference for certain  Information entropy, which is used in [33] to measure the similarity of a new user and dense  Collaborative filtering performance can decrease as the number of items in the training  The CBE-CF recommender system method can be described in the following steps: Step 1: Bicluster analysis is performed on the initial “user-element” rating matrix to  Step 2: The informational entropy for each cluster obtained in Step 1 is calculated. In detail,  Step 3: Implementation of a user-based collaborative filtering algorithm. First, the authors  Step 4: Combinatorial collaborative filtration (CBE-CF). CF primarily takes advantage of  In general, the proposed method is CBE-CF and takes O (mn) + O (k) time in the training method and the other compared methods, so each of the two datasets are evenly divided into 10 datasets and, in turn, the contents of the nine datasets were selected as the training dataset and the remaining dataset acted as a test suite. State-of-the-art user-based CF, element-based CFs, were used to assess the advantages and disadvantages of the new CBE-CF method. In addition, the number of nearest neighbors was set to 50 for all CFs based on KNN. evaluated, and the accuracy and computational costs are compared using the HML and NF datasets. The CBE-CF method was run based on optimal parameters. The new method had the highest forecast accuracy and relatively low computational costs compared to all four presented methods. In particular, the performance of the new method was better than that of the probabilistic model (probabilistic latent semantic analysis, PLSA) and the non-negative matrix factorization (NMF) model with a relatively low cost. The obvious observation is that the time to compute the user-based CF increased rapidly with the increase in training data, while the new CBE-CF method was not sensitive to the amount of training data.  NF dataset into 10 datasets of different scales, and then executed CF methods at these different scales. Interestingly, the new CBE-CF method provided improved accuracy using an extended training set, indicating that the new method could overcome the effects of the sparseness of the training data. However, in addition to the new CBE-CF, two other robust methods (NMF and PLSA) showed high computational costs for a large training set. comparison methods. Notably, deep learning-based CF methods also provided excellent predictive capabilities, although they suffered from high computational costs and large training sample sizes [41,42].  research, to generate optimal recommendations, it is still necessary to study the use of clustering methods based on biological factors. The work in [50] introduced a new clustering ensemble based on biological principles by combining swarm intelligence and fuzzy clustering models for collaborative user filtering. These approaches were evaluated on real, large-scale Yelp and TripAdvisor datasets to check the accuracy and consistency of the recommendations using standard rating metrics. guidance, such as k-means, fuzzy C-means, and the SOM method. However, algorithms with biological factors are not widely used for clustering users. In [50], an attempt was made to use a biological-based intelligent clustering approach in custom collaborative filtering. are specifically designed to handle complex real-world applications. Traditional approaches have failed to solve optimization problems, while biological metaheuristic algorithms are known for providing efficiently optimized solutions. For several large-scale applications, biological metaheuristic methods have been recognized as the best solution and have proven to be effective. To solve real-time global optimization problems, the development of hybrid biological methods for solving complex problems is very important. Swarm intelligence provides promising results for optimization problems and analytical data models, inheriting the characteristics of biological systems. Due to their proven effectiveness, intelligent swarm models have been actively studied, and the resulting solutions have opened the way for innovative ideas. have been achieved through greater adaptability. Various fields, such as pattern recognition, big data, and recommender systems, are adapting swarm intelligence-based clustering approaches to improve performance. In [50], a new smart swarm clustering ensemble model was developed for RS to address information overload. stability score is used to compute the consistency of the generated predictions of a target RS  The experiments also used 10-fold cross-validation to evaluate the performance of the new  The performance of the new CBE-CF method and the four other compared methods was  To test the sparse data capability of the new CBE-CF method, the authors randomly split the  The feasibility of this strategy was validated on two sets of benchmarks using four  2.7. Using Clustering Ensemble to Improve Consistency of Recommendations Although many traditional clustering mechanisms are used to group users in modern  There are many clustering approaches available in user-based CFRS to provide user-friendly  The nature-inspired approach works better than traditional models, and their metaheuristics  New clustering models based on swarm intelligence have improved clustering results which  The study in [50] presented stability as an additional metric for evaluating RS algorithms. A algorithm. The authors argued that similarity-based user clustering by leveraging swarm intelligence for the ensemble clustering method improves RS performance and yields better results at the expense of both accuracy and stability. on intelligent swarms, based on biological factors, have been introduced. Since swarm intelligence inherits biological traits and characteristics, it is useful for obtaining quality results for solving global optimization problems. For example, a hybrid clustering model optimizing a swarm of particles using C-means and k-means achieved improved clustering results compared to traditional models [51,52]. In this article, the authors present a hybrid clustering model through ensemble clustering using MWO and particle swarm optimization (PSO) with fuzzy models. The fuzzy clustering model computes the degree of membership in a cluster with other elements, while the hard clustering model maps each element to a specific cluster [50]. optimization), and PSO (particle swarm optimization), have solved many optimization problems [50]. PSO has become a generally accepted metaheuristic algorithm because of its simplicity and versatility, and it has been used as an important technique in various applications. In successful works, various clustering models with PSO have been proposed [50]. Many PSO-based hybrid clustering models have a proven clustering accuracy compared to traditional clustering approaches, such as k-means and fuzzy C-means. However, the PSO-based model requires the setting of parameters before being applied, and it is also relatively slower than the traditional clustering model, which is a noticeable disadvantage. no universal clustering model for obtaining optimal solutions with different types of datasets. To solve the above problem, clustering ensemble (CE) is recognized as an effective approach [50]. The clustering ensemble combines different solutions of clustering algorithms, or combines the results of one clustering algorithm with different parameters to create a new and improved solution, which is usually defined as a consensus solution to a problem. A clustering ensemble can process distributed data and is capable of parallel processing. The main contribution of this article includes an overview of several clustering approaches for generating recommendations. A detailed description of existing clustering algorithms, such as k-means, C-means, PSO, and MWO, is presented to develop new user clustering algorithms. The authors also present a new CE method with swarm intelligence algorithms for clustering users to generate advanced recommendations. was presented. The proposed BICE-based CFRS has three main segments: user clustering, prediction of user interests, and recommendation of generated travel suggestions. biological approaches and obtaining a final clustering result using a statistical ensemble model; the BICE-based CFRS then performs a neighborhood search of the active target user to include it in the appropriate cluster. Then, based on the current neighbors of the active target user in the cluster, ratings are estimated and a list of the first n recommendations is made, which is then presented to the user. The authors used two different approaches to predicting ratings: the average nearest neighbors approach and PSim. same setting has been modified for other combinations of user-clustering-based recommendation approaches. Along with the BICE approach, the authors present three different combinations of hybrid user clustering approaches, HCE1, HCE2, and HCE3. The HCE1 approach is a combination of k-means, C-means, and K-PSO methods used to cluster users. The HCE2 approach corresponds to a combination of k-means, C-means, and FCM-PSO methods. The HCE3 approach is a hybrid combination of the k-means, C-means, and K-MWO methods. recommendations, the resulting proposals turn out to be more accurate than using basic approaches. existing stand-alone approaches. The proposed hybrid approaches perform well, both in terms of  To overcome the limitations of conventional clustering algorithms, clustering models based  Metaheuristic optimization algorithms, such as GA (genetic algorithm), ACO (ant colony  Several clustering models provide different results with the same dataset; as such, there is  In [50] a new recommendation system based on the biointensive cluster ensemble (BICE)  The proposed BICE approach is designed to cluster users of a given dataset by using  The proposed CFRS setting is designed to generate BICE-based recommendations, and the  Even though the BICE model proposed by the authors takes a little longer to generate  The experimental results show that the proposed hybrid approaches are more efficient than assessing accuracy and in terms of stability. The ensemble-clustering model of the BICE approach using K-PSO, FCM-PSO, and K-MWO generated effective user clusters [50]. evolve and become more complicated, as in any field of machine learning. There is a trend for using hybrid approaches, assembling different models of the same type to improve performance and by combining models for different purposes in pipelines. As shown above, clustering can be quite effective as a preemptive stage before recommendation systems. However, the overall effectiveness depends now on both the recommender algorithm and the clustering model. This can lead to difficulties in creating, testing, and implementing these models in practice. As the authors of [1] wrote, “Hybrid approaches, making content-based and collaborative-based predictions separately and combining them could be more effective in books recommender systems. … Obviously, a hybrid algorithm based on the collaborative filtering algorithm and content-based algorithm improved the efficiency and quality of the recommendation algorithm. Meanwhile, it can also solve item cold start issues effectively.” Furthermore, we see increasing usage of deep learning methods to derive inner latent representations of users and item profiles to deal with the massive degree of data sparseness. In addition, the impact of these methods is characterized as “dramatic performance improvements brought by deep learning” [41]. Similar to other fields of machine learning, the more data that are collected, the more complicated and deep models become regarding the use of these data. recommender system. Users and businesses need to not only match their existing preferences, sealing them, and putting users into bubbles, but also to encourage exploration and diversity. This can be also related to the old “cold start” recommendation problem. When we focus on inherent product features, analyzing them more rigorously, we can achieve more desirable results that are not captured by simple accuracy measurements. As was shown using ClassDiv, enabling intellectual data preprocessing can help here significantly, “…it has been recognized that accurate prediction of rating values is not the only requirement for achieving user satisfaction. One other requirement, which has gained importance recently, is the diversity of recommendation lists. Being able to recommend a diverse set of items is important for user satisfaction since it gives the user a richer set of items to choose from and increases the chance of discovering new items.”[3]. We acknowledge there is more to this problem than just clustering. We hope to see more elaborate research on data analysis for better recommendations soon, using, for example, new emerging text understanding tools based on deep language models, such as BERT or GPT. preferences, and effective recommender systems need to consider these issues. Using preemptive clustering to distinguish different groups of users may be promising, as shown in the studies above: “Our approach is based on an assumption that users have different rating habits. For distinguishing different typical users, the primary work in this paper is to design a framework to assign users into user groups with different preferences. Therefore, the neighbor users of the active user can be found with consistent preference. … To solve this problem, we proposed a new similarity measure method to consider user preference from the local and global perspectives respectively. In addition, an example was illustrated in our paper, which has proved that the proposed similarity measure method is more effective and suitable for calculating the similarity between users.” [12]. eliminating the possibility to perform specific attacks on the recommender system by constructing an artificial user profile to manipulate the output of the algorithm. “However, there are several problems with this method, and one of them is the existence of attacks that intend to distort the predicted ratings of specific items.” [21]. This is very relevant to the current trend in machine learning for the exploration of fairness, robustness, and reliability of black-box machine learning methods used for decision-making support [76]. As intelligent systems gain popularity in every aspect of economic and social life, even more attention will and should be devoted to investigating  3. Discussion From this review, we can conclude that, in general, algorithms for recommender systems  Studies have shown that accuracy can no longer remain as the main efficiency metric of a  Another issue is the different rating habits of users. There is always inconsistency in user  As was shown in [21], clustering also can improve recommendation robustness by different ways to ensure their abilities to withstand intentional attacks and inherent biases in training datasets. account constant changes in user preferences and behavior. As was noted in [24], “The traditional collaborative filtering recommendation algorithm based on user rating is very sparse, without because the user changes over time, not a good predictor of user interest, and the nearest neighbor query range is not conducive to a real-time recommendation, for the project problem is not a good solution.”. Traditional recommender systems, both CF and CBF-based, simply do not have any concept of time within them. This may be an issue if users are present in commercial systems long enough to manifest significant changes in behavior. We suppose that this can have a major effect on a timescale of several years on average, though significant changes can appear very quickly in the very beginning of a user’s experience within a certain system due to forming new consumption habits [77]. Thus, these improvements and new results and methods can be useful, not only to those who build long-lasting online services, but potentially everyone who uses recommendation systems to capture dynamic user interests.  Another interesting issue with enterprise recommendation systems is how to take into  1. Tian Y. et al. College library personalized recommendation system based on hybrid recommendation algorithm // Procedia CIRP. - 2019 .-- T. 83 .-- S. 490-494. 2. Zilei Sun, Nianlong Luo. A New User-Based Collaborative Filtering Algorithm Combining Data- Distribution [J]. International Conference of Information Science and Management Engineering, 2010, 2 (8): 19-23 3. Aytekin T., Karakaya M. Ö. Clustering-based diversity improvement in top-N recommendation //  Journal of Intelligent Information Systems. - 2014. - T. 42. - No. 1. - S. 1-18. 4. McNee SM, Riedl J, Konstan JA (2006) Being accurate is not enough: How accuracy metrics have hurt recommender systems. In GM Olson, & R. Jeffries (Eds.), CHI extended abstracts (pp. 10971101). ACM. 5. Herlocker, JL, Konstan, JA, Terveen, LG, Riedl, J. (2004). Evaluating collaborative filtering recommender systems. ACM Transactions on Information Systems, 22 (1), 5-53. 6. Bradley, K., & Smyth, B. (2001). Improving recommendation diversity. In Proceedings of the 12th  Irish conference on artificial intelligence and cognitive science 7. Smyth, B., & McClave, P. (2001). Similarity vs. diversity. In DW Aha, & I. Watson (Eds.),  Proceedings of the 4th international conference on case-based reasoning. Lecture Notes in Computer Science (Vol. 2080, pp. 347-361). Vancouver: Springer. 8. Zhang, M., & Hurley, N. (2008). Avoiding monotony: Improving the diversity of recommendation lists. In Proceedings of the 2nd ACM conference on recommender systems (pp. 123–130).  9. Hurley, N., & Zhang, M. (2011). Novelty and diversity in a top-N recommendation — analysis and evaluation. ACM Transactions on Internet Technology, 10 (4), 14. 10. Zhang, M., & Hurley, N. (2009). Novel item recommendation by user profile partitioning. In  Proceedings of the IEEE / WIC / ACM international conference on web intelligence (pp. 508-515). Milan, Italy. 11. Ziegler, CN, McNee, SM, Konstan, JA, Lausen, G. (2005). Improving recommendation lists through topic diversification. In Proceedings of the 14th international conference on World Wide Web (pp. 22–32). Chiba, Japan. 12. Zhang J. et al. An effective collaborative filtering algorithm based on user preference clustering //  Applied Intelligence. - 2016. - T. 45. - No. 2. - S. 230-240. 13. Shi Y, Larson M, Hanjalic A (2014) Collaborative filtering beyond the user-item matrix: a survey of the state of the art and future challenges. ACM Comput Surv 47 (1): 3: 1–3: 45 14. Vozalis MG, Margaritis KG (2007) Using SVD and demographic data for the enhancement of generalized collaborative filtering. Inf Sci 177 (15): 3017-3037 15. Jamali M, Ester M (2009) TrustWalker: a random walk model for combining trust-based and itembased recommendation. In: Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp 397-406 16. Sarwar B, Karypis G, Konstan J, Riedl J (2001) Item-based collaborative filtering recommendation algorithms. In: Proceedings of the 10th International Conference on World Wide Web, pp 285–295 17. Kaleli C (2014) An entropy-based neighbor selection approach for collaborative filtering. Knowl- Based Syst 56: 273-280 18. Boumaza AM, Brun A (2012) Stochastic search for global neighbors selection in collaborative filtering. In: Proceedings of the 27th Annual ACM Symposium on Applied Computing. ACM, New York, USA, pp 232–237 19. Kim TH, Yang SB (2007) An effective threshold-based neighbor selection in collaborative filtering.  In: Proceedings of the 29th European Conference on IR Research. ECIR'07. Springer, Berlin, Heidelberg, pp 712–715 20. Anand D, Bharadwaj KK (2011) Utilizing various sparsity measures for enhancing accuracy of collaborative recommender systems based on local and global similarities. Expert Syst Appl 38 (5): 5101-5109 21. Zhang J. Robust Collaborative Filtering Based on Multiple Clustering // 2019 IEEE 7th International  Conference on Computer Science and Network Technology (ICCSNT). - IEEE, 2019 .-- S. 174-178. 22. MP O'Mahony, NJ Hurley, GCM Silvestre: Promoting recommendations: an attack on collaborative filtering. DEXA 2002, pp. 494-503, 2002. 23. B. Mobasher, RD Burke, R. Bhaumik, C. Williams: Towards trustworthy recommender systems: an analysis of attack models and algorithm robustness. ACM TOIT, Vol.7, No.4, Article No.23, 2007. 24. Xiaojun L. An improved clustering-based collaborative filtering recommendation algorithm // Cluster  Computing. - 2017. - T. 20. - No. 2. - S. 1281-1288. 