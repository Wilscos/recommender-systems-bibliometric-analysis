Matching markets involve heterogeneous agents (typically from two parties) who are paired for mutual beneﬁt. During the last decade, matching markets have emerged and grown rapidly through the medium of the Internet. They have evolved into a new format, called Online Matching Markets (OMMs), with examples ranging from crowdsourcing markets to online recommendations to rideshare. There are two features distinguishing OMMs from traditional matching markets. The ﬁrst is the dynamic arrivals of a part of the agents in the system, which are referred to as online agents, e.g., keywords in Google Advertising, workers in Amazon Mechanical Turk (AMT), and riders in Uber/Lyft. As opposed to online agents, the other part is oﬄine agents, such as sponsors in Google advertising, tasks in AMT, and drivers in rideshare platforms, whose information is typically known as a priori. The second feature is the instant match-decision requirement. It is highly desirable to match each online agent with one (or multiple) oﬄine agent(s) upon its arrival, due to the low “patience” of online agents. There is a large body of research that studies matching-policy design and/or pricing mechanism in OMMs [1, 2]. The main focus of this paper, instead, is fairness among oﬄine agents in OMMs. Consider the following two motivating examples. Fairness among task requesters in mobile crowdsourcing markets (MCM). In MCMs like Gigwalk and TaskRabbit, each oﬄine task has speciﬁc location information, and online workers have to travel to Abstract. Matching markets involve heterogeneous agents (typically from two parties) who are paired for mutual beneﬁt. During the last decade, matching markets have emerged and grown rapidly through the medium of the Internet. They have evolved into a new format, called Online Matching Markets (OMMs), with examples ranging from crowdsourcing to online recommendations to ridesharing. There are two features distinguishing OMMs from traditional matching markets. One is the dynamic arrival of one side of the market: we refer to these as online agents while the rest are oﬄine agents. Examples of online and oﬄine agents include keywords (online) and sponsors (oﬄine) in Google Advertising; workers (online) and tasks (oﬄine) in Amazon Mechanical Turk (AMT); riders (online) and drivers (oﬄine when restricted to a short time window) in ridesharing. The second distinguishing feature of OMMs is the real-time decision-making element. However, studies have shown that the algorithms making decisions in these OMMs leave disparities in the match rates of oﬄine agents. For example, tasks in neighborhoods of low socioeconomic status rarely get matched to gig workers, and drivers of certain races/genders get discriminated against in matchmaking. In this paper, we propose online matching algorithms which optimize for either individual or group-level fairness among oﬄine agents in OMMs. We present two linear-programming (LP) based sampling algorithms, which achieve online competitive ratios at least 0.725 for individual fairness maximization (IFM) and 0.719 for group fairness maximization (GFM), respectively. There are two key ideas helping us break the barrier of 1 − 1/e. One is boosting, which is to adaptively re-distribute all sampling probabilities only among those oﬄine available neighbors for every arriving online agent. The other is attenuation, which aims to balance the matching probabilities among oﬄine agents with different mass allocated by the benchmark LP. We conduct extensive numerical experiments and results show that our boosted version of sampling algorithms are not only conceptually easy to implement but also highly eﬀective in practical instances of fairness-maximization-related models. that location to complete it (e.g., cleaning one’s house, delivering some package). It has been reported that online workers selectively choose oﬄine tasks based on their biased perceptions. For example, survey results on TaskRabbit in Chicago [3] showed that workers try to avoid tasks that locate in areas with low economic status like the South Side of Chicago. This causes a much lower completion rate for tasks requested by users of low socioeconomic status and as a result, “low socioeconomic-status areas are currently less able to take advantage of the beneﬁt of mobile crowdsourcing markets.” Fairness among drivers in ride-hailing services. There are several reports showing the earning gap among drivers based on their demographic factors such as age, gender and race, see, e.g., [4, 5]. In particular, [6] has reported that “Black Uber and Lyft drivers earned $13.96 an hour compared to the $16.08 average for all other drivers” and “Women drivers reported earning an average of $14.26 per hour, compared to $16.61 for men”. The wage gap among drivers from diﬀerent demographic groups is partially due to the biased perceptions and resulting selective choices from riders who cancel matches with drivers from these groups. In this paper, we study fairness maximization among oﬄine agents in OMMs, on the prototypical online matching model with known, independent, and identical (KIID) arrivals, which is widely used to model the dynamic arrivals of online agents in several real-world OMMs including rideshare and crowdsourcing markets [7–9]. We choose this arrival model instead of the adversarial one, because under the latter it is impossible for an online algorithm to perform well. The online matching model under KIID is as follows. We have a bipartite graph (I, J, E), where I and J represent the types of oﬄine and online agents, respectively, and an edge e = (i, j) indicates the compatibility between the oﬄine agent (of type) i and the online agent (of type) j. All oﬄine agents are static, while online agents arrive dynamically in a certain random way. Specially, we have an online phase consisting of T rounds and during each round t ∈ [T ] with replacement such that Pr[ distribution {r arrival of an online agent j, an immediate and irrevocable decision is required: either reject j or match j with one oﬄine neighbor i with i ∼ j, i.e., (i, j) ∈ E. Throughout this paper, we assume w.l.o.g. that each oﬄine agent has a unit matching capacity. group G is a set of types of oﬄine agents (possibly overlapping) that share some demographic characteristic such as gender, race, or religion. Consider a generic online algorithm ALG, and let Z oﬄine agent i is matched (or served). We deﬁne the following two objectives: Individual Fairness Maximization (IFM): min Group Fairness Maximization (GFM): min Here IFM denotes the minimum expected matching rate over all individual oﬄine agents, while GFM denotes that over all pre-speciﬁed groups of oﬄine agents. Our goal is to design an online-matching policy such that the above two objectives are maximized. Observe that IFM can be cast as a special case of GFM when each group consists of one single oﬄine type. A related model: vertex-weighted online matching under KIID (VOM). VOM under KIID [10, 11] shares almost the same setting as our model except in the objective, where each oﬄine agent i is associated with a non-negative weight w oﬄine agents, i.e., max One could also consider the oblivious variant of VOM where the weights {w and chosen by an adversary. In this variant, an oblivious algorithm cannot do better than maximizing the minimum ex-ante probability x weight to 1 and the other weights to 0. This variant is equivalent to the special case of IFM. Two assumptions on the arrival setting. (a) Integral arrival rates. Observe that for an oﬄine agent j, it will arrive with probability r This can be seen as follows: Suppose there are a large number T of tasks. The ﬁrst arriving worker can perform any of them. Workers 2, . . . , T can each perform a diﬀerent specialized task such that there is one task that can be served only by the ﬁrst arriving worker. The online algorithm has a 1/T chance of correctly allocating the ﬁrst worker to this task. We can always make it by creating multiple copies of an oﬄine agent if has multiple capacities. number of arrivals of j during the online phase and it is called arrival rate of j. In this paper, we consider integral arrival rates for all oﬄine agents, and by following a standard technique of creating r we can further assume w.l.o.g. that all r of online bipartite matching under KIID [10, 12–14], where the objective is typically to maximize a linear function representing the total weight of all matched edges. We emphasize that both of these assumptions are mild in that: the interesting case is T  1 because if T is ﬁxed then the problem, with state space |I|, can be solved to optimality; and under the assumption T  1, the arrival rates are arbitrarily close to integers. Competitive ratio (CR) is a commonly-used metric to evaluate the performance of online algorithms [15]. Consider an online maximization problem like ours. Let ALG(I) = E performance of ALG on an input I, where the expectation is taken over both of the randomness of the arrival sequence S of online agents and that of ALG. Let OPT(I) = E performance of a clairvoyant optimal who has the privilege to optimize decisions after observing the full arrival sequence S. We say ALG achieves an online competitive ratio of ρ ∈ [0, 1] if ALG(I) ≥ ρ OPT(I) for all possible inputs I. Generally, the competitive ratio captures the gap in the performance between an online algorithm subject to the real-time decision-making requirement and a clairvoyant optimal who is exempt from that. It is a common technique to use a linear program (LP) to upper bound the clairvoyant optimal (called benchmark LP), and hence by comparing against the optimal value of the benchmark LP, we can get a valid lower bound on the target competitive ratio. In this paper, we use the benchmark LP as below. For each edge (i, j) ∈ E, let x of times that the edge (i, j) is matched by the clairvoyant optimal. For each i, let N denote the set of oﬄine neighbors of i. Similarly, N convenience, we use i ∼ j and j ∼ i to denote the relation that i is incident to j (i.e., i ∈ N incident to i (i.e., j ∈ N Here we assume the size of |S| is upper bounded by a given constant, say K = 100, which is independent of T  1. Throughout this paper, we use LP (1) to denote the LP with Objective (1) and Constraints (4) to (6). Similarly for LP (2) and LP (3). Note that though Objective (1) is non-linear, we can reduce to a linear one by replacing it with max λ and adding one constraint we can replace it with max λ and add one extra constraint |G| denotes the cardinality of group G. Our LPs are mainly inspired by the work [11]. Note that the critical constraint is (6), in which we have omitted terms of size O(1/T ), which can aﬀect the competitive ratio by at most O(1/T ) [11]. Note that all the the above three LPs can be solved polynomially even after removing the restriction on the size of |S| in Constraint (6). Lemma 1. LP (1), LP (2), and LP (3) are valid benchmarks for IFM, GFM, and VOM, respectively. Proof. Observe that the three objectives (1), (2), and (3) capture metrics of IFM, GFM, and VOM, respectively. Thus, it will suﬃce to justify the feasibility of all constraints for a clairvoyant optimal. Constraint (4) is valid since the total number of matches relevant to an online agent j should be no larger than that of expected arrivals, which is r capacity. Constraint(6) can be justiﬁed as follows. Consider a given i ∈ I and a given S ⊆ NP should be no larger than that of at least one neighbor in S arrives at least once during the online T rounds. Thus, The last equality is due to our assumption that |S| is upper bounded by a given constant independent of T  1. Before describing our technical novelties, we ﬁrst explain the standard LP-based sampling approach, which has been commonly used in algorithm design for various online-matching models under known distributions, either KIID [8] or known adversarial distributions [17] (where arrival distributions are still independent but not necessarily identical). A typical framework is as follows. We ﬁrst propose a benchmark LP to upper bound the performance of a clairvoyant optimal and then solve the LP to get statistics regarding how the clairvoyant optimal matches an online agent with its oﬄine neighbors. After that, we use these statistics to guide online actions and transfer them to a plausible online-matching policy. For example, suppose by solving the LP, we know that the clairvoyant optimal will match each pair of oﬄine-online agents (i, j) with probability x we can then transfer it to a simple non-adaptive matching policy as follows: upon the arrival of online agent j, sample a neighbor i ∈ N 2.3 Overview of our techniques: LP-based sampling, boosting, and attenuation A straight-forward analysis yields that the aforementioned non-adaptive sampling policy achieves 1 − 1/e of the LP optimum, see e.g., [11, 18]. However, such a policy also achieves no better than 1 − 1/e, even when the LP has been tightened by Constraint (6). the following simple and natural idea. Though the LPs may have exponential number of constraints after removing the restriction of a constant size of |S| independent of T , they are all can be solved polynomially since they admit a polynomial-time separation oracle [16]. For presentation convenience, we add that restriction and it is suﬃce for our analysis. To see this, consider a complete bipartite graph with T nodes on each side. Setting x is feasible in the tightened LP that leaves every oﬄine node fractionally matched. However, the corresponding sampling policy would only leave each oﬄine node matched with probability 1 − 1/e. In fact, it can be seen on this example that any non-adaptive sampling policy must leave some oﬄine node matched with probability at most 1 − 1/e. X= 1 denotes the random event that i is matched with one of its neighbors in S, whose probability x= EX= PrX= 1≤ 1 − Pr[none of neighbors in S arrives during the T rounds] = 1 −1 −|S|T= 1 − e+ O(1/T ). Boosting. Suppose we are at (the beginning of) time t and an online agent j arrives. Assume that by solving the benchmark LP, we learn a sampling distribution x from the clairvoyant optimal. Let N non-adaptively sticking on the distribution x a neighbor j from N we promote the chance of each available neighbor of j at t getting matched with j. Also, we can guarantee that the oﬄine neighbor we have sampled is available at the time and dismiss the case that we sample an unavailable neighbor and have to reject j ultimately, which is also a desirable feature to have in practice. This is the key idea in the algorithm we will present for IFM (see Theorem 2). Note that our boosting idea has already been proposed and tested in several practical crowdsourcing applications [8, 20]. Though it proved to be helpful in some scenarios, the boosted version of LP-based sampling is more challenging to analyze since one has to consider the adaptive behavior of the algorithm. We are the ﬁrst to show that it achieves an online competitive ratio of 0.725, exceeding 1 − 1/e, for IFM, which matches the second-best ratio as shown in [10] for VOM. One can contrast this to [12] who studied unweighted online matching under KIID and also introduced a boosting strategy, which is more complex. The main idea there is to generate two negatively correlated sampling distributions from the original one, and sample two candidate neighbors for an online arriving agent. A critical element in our analysis of the simple boosting algorithm for IFM, however, is that an optimal LP solution places identical total mass x optimal LP solution may place higher mass on speciﬁc oﬄine agents, e.g., those belonging in many groups. We show that when there is heterogeneity in the mass placed across oﬄine agents, the boosting algorithm matches high-mass oﬄine agents i with probability no better than (1 − 1/e) · x competitive ratio achieved is no longer better than 1 − 1/e. Uniform vs. Non-uniform Boosting. To break this barrier of 1−1/e for GFM, our idea is to use boosting in a non-uniform fashion. In the simple boosting algorithm above, for an incoming arrival, the probability of sampling unavailable neighbors was re-distributed evenly across its available neighbors. However, our algorithm for GFM is more likely to suﬀer from oﬄine agents i with high total mass x above those agents are more diﬃcult to match relative to its total mass x To accomplish this, we add an attenuation factor to oﬄine agents with small total mass in the LP solution, in an attempt to balance the probability of matching every oﬄine agent i relative to its total mass x. Attenuation techniques have been used previously in several stochastic optimization problems, see, e.g., stochastic knapsack [21], stochastic matching [22, 23], and matching policy design in rideshare [24, 25]. Most similar to ours are the attenuation techniques used in [10, 11] to overcome the barrier of 1 − 1/e for VOM under KIID. However, our attenuation technique is diﬀerent and novel in the following sense. Consider an online agent j that arrives at time t and let x attenuation. The idea in [10, 11] is to carefully design factors α distribution x upon the arrival of j. In this way, they can both promote the performance of an oﬄine agent i with large mass by setting α is to adaptively and randomly update the set of neighbors of j subject to sampling. Recall that the idea of boosting is to sample a neighbor of j only from the set of available neighbors at that time following a boosted version of distribution x of boosting by randomly “muting” some available neighbors of j at time t with small mass (i.e., forcefully labeling them as unavailable) and then apply the boosting idea to the set of all available neighbors that survives the muting procedure. We expect our attenuation can help compress the performance of oﬄine agents with small mass and promote that of oﬄine agents with large mass as a result. In this paper, we propose two generic online-matching based models to study individual and group fairness maximization among oﬄine agents in OMMs. For IFM and GFM, we present an LP-based sampling with boosting (SAMP-B) and another sampling algorithm with boosting and attenuation (SAMP-AB), respectively. Here are our main theoretical results. Theorem 1. For IFM and GFM, both Greedy and Ranking achieve an online competitive ratio of 0. Theorem 2. A simple LP-based sampling algorithm with boosting (SAMP-B) achieves an online competitive ratio at least 0.725 for IFM. Theorem 3. An LP-based sampling algorithm with attenuation and boosting (SAMP-AB) achieves an online competitive ratio at least 0.719 for GFM and VOM. We emphasize that Theorem 1 requires a non-trivial analysis and makes a signiﬁcant statement. Indeed, it is a priori unclear why Greedy (with randomized tiebreaking) or Ranking should be so poor for fairness maximization, when randomization is built into both of them. This contrasts with facts that Greedy achieves a ratio equal to 1 −1/e for vertex-weighted online matching under KIID [26] and Ranking achieves 1− 1/e for unweighted online matching even under adversarial [27]. This shows that IFM and GFM are new, distinct online matching problems in which the baseline algorithms of Greedy and Ranking do not work. On the other hand, the technical contributions in our LP-based algorithms/analysis have already been discussed in Section 2.3. Complementing the guarantees, there is an upper bound of 0.865 due to [12] for unweighted KIID with integral arrival rates, which can be modiﬁed to hold for IFM and GFM. We acknowledge that for VOM under KIID with integral arrival rates, the guarantee of 0.719 implied by our SAMP-AB algorithm does not improve the two state-of-the-art algorithms, which achieve ratios of 0.725 [10] and 0.729 [11], respectively. Nonetheless, we still compare our algorithms against Greedy, Ranking, and these state-of-the-art algorithms in the literature [10–12] in real-data simulations. Our datasets include a public ride-hailing dataset collected from the city of Chicago, using which we construct instances for IFM and GFM, as well as four datasets from the Network Data Repository [28], using which we test the classical problem VOM as well. For IFM and GFM, simulation results show that our SAMP-B algorithm, as well as the algorithm from [12] (after being adapted to our problem), signiﬁcantly outperform others. For VOM, simulation results show that SAMP-B, along with Greedy, signiﬁcantly outperform others. This demonstrates that among algorithms which appear to perform well in practice (boosting, Greedy, [12]), our simple boosting algorithm achieves the best guarantee, and importantly, simultaneously performs well both for fairness maximization and for weight maximization (whereas [12] only performs well for IFM/GFM while Greedy only performs well for VOM). Our simple boosting idea is also much simpler to implement than the cleverly correlated sampling in [12]. As a ﬁnal conceptual result, we show the fairness maximization problems to be no harder than VOM in terms of the optimal competitive ratio. For a given model, let Φ(·) denote the online competitive ratio achieved by an optimal online algorithm, i.e., the best competitive ratio possible. We establish the following, where the ﬁrst inequality is trivial since IFM is a special case of GFM. Theorem 4. Φ(IFM) ≥ Φ(GFM) ≥ Φ(VOM). Of course, this result is on the theoretically optimal online algorithms, which cannot be computed. The fairness maximization problems are computationally distinctive from VOM. Roadmap. In Section 4, we present the algorithm SAMP-B for IFM and prove Theorem 2; in Section 5, we present the algorithm SAMP-AB for IFM and VOM and prove Theorem 3; in Section 6, we prove Theorems 1 and 4, and in Section 7, we present details regarding our real datasets and relevant experimental results. In recent years, online-matching-based models have seen wide applications ranging from blood donation [29] to volunteer crowdsourcing [30] and from kidney exchange [31] to rideshare [25]. Here we brieﬂy discuss a few studies that investigate the fairness issue. Both works of [32] and [33] have studied the income inequality among rideshare drivers. However, they mainly considered a complete oﬄine setting where the information of all agents in the system including drivers and riders is known in advance. They justiﬁed that by focusing a short window and thus, all agents can be assumed oﬄine. There are several other works that considered fairness in matching in an oﬄine setting where all agents’ information is given as part of the input, see, e.g., [34, 35]. Nanda et al. [36] proposed a bi-objective online-matching-based model to study the tradeoﬀ between the system eﬃciency (proﬁt) and the fairness among rideshare riders during high-demand hours. In contrast, Xu and Xu [37] presented a similar model to examine the tradeoﬀ between the system eﬃciency and the income equality among rideshare drivers. Unlike focusing on one single objective of fairness maximization like here, both studies in [36] and [37] seek to balance the objective of fairness maximization with that of proﬁt maximization. Recently, Ma et al. [38] considered a similar problem to us but focus on the fairness among online agents. Manshadi et al. [39] studied fair online rationing such that each arriving agent can receive a fair share of resources proportional to its demand. The fairness issue has been studied in other domains/applications as well, see, e.g., online selection of candidates [40], inﬂuence maximization [41], banditbased online learning [42–44], online resource allocation [45, 46], and classiﬁcation [47]. Let N an optimal solution to LP (1) when the context is clear. Let x that x boosting is formally stated as follows. ALGORITHM 1: Sampling with Boosting (SAMP-B). 4.1 Proof of the main Theorem 2 For an oﬄine agent i ∈ I, let Z show the below theorem. Theorem 5 suggests that each oﬄine agent gets matched in SAMP-B with probability at least 0.725 · τ . Thus, we have min clairvoyant optimal. Therefore, we establish the main Theorem 2. For each oﬄine agent i ∈ I and t ∈ [T ], let 1 t in SAMP-B, and q beginning of) t, i.e., q SAMP-B. Thus, We can always make it by decreasing all {x denote the set of available neighbors of j at t. For the ease of notation, we use {x} to denote.P = τ for all i ∈ I, where τ ∈ [0, 1] is the the optimal value of LP (1).Our LP-based sampling with = {i ∈ N, i is available at t}, i.e., the set of available neighbors of j at t. = ∅ then Proof. The online sampling process in SAMP-B can be interpreted through the following balls-and-bins model: Each oﬄine agent i corresponds to a bin i and each edge e = (ij) corresponds to a ball e; During each round t ∈ [T ], a ball (ij) will arrive with probability 0 if i gets occupied before t, and a ball (ij) will arrive with probability (x for any j and t, we have X Observe that 1 during t that each ball e = (i will shoot i every oﬄine agent i remain unoccupied after t − 1 rounds with probability at most (1 − τ/T ) Proof of Theorem 5. Focus on a given oﬄine agent i i, and use q Now, we try to lower bound the value of q indicate that i is available at t. By the nature of SAMP-B, we see that conditioning on i (1= 1), i that for each j ∼ i Observe that The last inequality above is due to Jensen’s inequality and the convexity of function 1/x. Note that Substituting the above inequality to Inequality (8), we have =x. Here Ncan be viewed as the set of unoccupied bin i at t with i ∼ j. Observe thatPP . Consider a given t< t and a given i6= i. Assume 1= 1 and iis not occupied at t. Then, we see /T since X≤ 1 for all j∼ iand t< t. This implies that the probability that none relevant ballsP during tshould be at most 1 −x/T = 1 − τ /T . Here we invoke our assumption thatP , 1, and Z to denote the corresponding values with respect to i. will be matched during t iﬀ one of its neighbors j ∼ iarrives and (i, j) gets sampled. RecallP The second inequality above is due to the fact that ln(1 − x) ≤ −x for all x ∈ [0, 1). Let g to solve the below minimization program. For the ease of notation, we omit the subscription of i. Note that the ﬁrst constraint is due to our assumption x benchmark LP. By Lemma 3, we have on E[Z] above, we get where S(τ) is an optimal solution to Program (9) as deﬁned in Lemma 3. We can verify that E[Z]/τ gets minimized at τ = 1 and the corresponding ratio is 0.725. Thus, we are done. An optimal solution to the minimization program (9) can be characterized by the following set S(τ ). Let `be the largest integer satisfying that 1 − e Lemma 3. An optimal solution to the minimization program (9) can be characterized by S(τ) = {1 − Proof. Recall that g concave function over x ∈ (0, 1) for all τ ∈ [0, 1]. The main idea in our proof is a local perturbation analysis. In the following, we focus on the special case when τ = 1 and |S| ≤ 2 in Constraint (6). All the rest follows a similar analysis. Assume τ = 1 and let g(x) = ln(1 + x(e − 1)). Suppose have an optimal solution {x WLOG assume that x x< 1 − e and (b) x (x) = ln(1 + x(e− 1)), where τ ∈ [0, 1] is a parameter. To get a lower bound for E[Z], we need − e, · · · , e− e, τ − (1 − e)}. . Then, we can apply a local perturbation as x= x+  and x= x−  with  = min(1 − , x,−), and x= xfor all ` > 2. Now, we try to show that (a) g(x) + g(x) < g(x) + g(x) = {x} is still feasible to Program (9). Thus, we prove Points (a) and (b), which yields a contradiction with our assumption that x Repeating the above analysis, we can show that in the optimal solution, x the case τ = 1 and |S| ≤ 2 in Constraint (6). We ﬁrst give an example showing that SAMP-B can never beat 1 − e Example 1. Consider such a bipartite graph (I, J, E) as follows. Recall that by KIID assumption with all unit arrival rates, we have T = n = |J|. The set of neighbors of j, denoted by N (1) |N disjoint except sharing one single oﬄine agent i (2) i with  = 1/n for all i 6= i for all (ij) ∈ E. Under this solution, we have x Lemma 4. SAMP-B can never beat the ratio of 1 − e term when T → ∞. Proof. Consider i every round t, one j ∼ i i ∈ N let M online arrivals and every arrival will shoot one item in N interpreted as a balls-and-bins model where we have n balls and n bins, and thus, M = max viewed as the largest bin load. From [48], we see that with probability 1 − 1/n, the largest bin load is M = Θ(ln n/ ln ln n) ≤ ln n when n is suﬃciently large. Let SF be the event that M ≤ ln n. Assume SF occurs. We see that for all j ∼ iP have Recall that the optimal LP value is 1 +  i is matched in SAMP-B in the end. Observe that the expected total values obtained by SAMP-B should be at most = 1 and x≤ 1 − efor all j. Note that for any j ≥ 3, | = n, ∀j ∈ J; (2) ∩N= {i}. In other words, each j has a set of n neighbors and they are almost has J as the set of neighbors and every i 6= ihas one single neighbor in J. Let w= 1 and w=  x=  for all i 6= i. The optimal LP value is 1 + (1/− 1/) = 1 + − . . Let N= |N| be the number of available neighbors incident to j surviving in the end, and = n − N, which refers to the number of neighbors of j got shot. Observe that we have T = n x≥ (n − M) = (n − ln n) = 1 − ln n/n. Let Z= 1 indicate that iis matched in the end. We Thus, the ﬁnal competitive ratio of SAMP-B on Example 1 should be at most 5.2 An LP-based sampling algorithm with attenuation and boosting (SAMP-AB) For a given oﬄine agent i, we say i that j ∼ i and j ∼ i neighbors of i have very small values in the optimal solution, the boosting strategy shown in SAMP-B will have little eﬀect on improving the overall matching probability of i. Observe that for each oﬄine vertices i 6= i words, the chance of getting matched for every i 6= i solution. In contrast, the chance that i LP solution. These insights motivate us to add appropriate attenuations to those unsaturated oﬄine vertices such that the boosting strategy can work properly for those saturated ones. Oﬄine-phase simulation-based attenuation. Let us ﬁrst introduce two auxiliary states for oﬄine vertices, called active and inactive, which are slightly diﬀerent from available (not matched) and unavailable (matched) as shown before. In our attenuation framework, we assume all oﬄine vertices are active at the beginning (t = 1). When an active oﬄine agent i is matched, we will label it as inactive. Meanwhile, we need to forcefully mute some active oﬄine agent, label it as inactive, and view it as being virtually matched. Consider the instance on Example 1: In order to make the boosting strategy work for the dominant agent i, we have to intentionally label those active non-dominant vertices i as inactive such that the sampling probability of i being active to inactive is irreversible: Once an active oﬄine agent i is labeled as inactive, it will stay on that state permanently. Here are the details of our simulation-based attenuation. By simulating all online steps of SAMP-AB up to time t, we can get a very sharp estimate of the probability that each i is active at t, say α (1−1/T ) agent i at t as follows: If i is active at t, then label i as inactive with probability 1−(1−1/T ) it active with probability (1 − 1/T ) the target (1− 1/T ) i as active and inactive with respective probabilities β Here are a few notes on the simulation-based attenuation scheme. (1) When computing the attenuation factor β applying all the attenuation factors as proposed during all the rounds before t. (2) During every round, we apply the corresponding attenuation factor to each active oﬄine agent in an independent way. (3) All attenuation factors can be computed in an oﬄine manner, i.e., before the online phase actually starts. 5.3 Proof of the main Theorem 3 Similar to the proof of Theorem 2, we aim to show that each oﬄine agent i will be matched in SAMP-AB with a probability E[Z the total mass allocated to i in the optimal LP solution. This will suﬃce to prove Theorem 3. The argument is as follows. (1) For GFM, we have SAMP-AB = min SAMP-AB and OPT refer to the performance of SAMP-AB and a clairvoyant optimal, respectively. (2) For VOM, we have SAMP-AB = on Example 1, it will be matched with a probability at least E[Z] ≥ 1 − e∼  = x. In other , then no attenuation is needed at t. Otherwise, add an attenuation factor of (1 −1/T )/αto ALGORITHM 2: Sampling with Attenuation and Boosting (SAMP-AB). Phase, we get a sharp estimate of the probability that each oﬄine agent i is active at (the beginning of) t, say α 1 − β neighbors of j at t. For each oﬄine agent i, let 1 attenuation procedure shown in Step 10 prior to the sampling process. Let α Let q q= Pr[1 Observe that α is slightly diﬀerent from before, Lemma 2 of Section 4 still works here. Proof. The proof of Lemma 2 in Section 4 suggests that 1 attenuation. Thus, we have Pr[1 applied independently to all oﬄine vertices. Therefore, Consider a given oﬄine agent i drop the subscription of i i. Here are a few properties of {q = min1, (1 − 1/T )/α. = ∅ then be the probability that i is matched during t conditioning on i is active at t after attenuation, i.e., = 1|1= 1] = β· Pr[1= 1|1= 1] ≤ β· Pr[1= 1] = β· α≤ (1 − 1/T ). Observe that for each given i 6= i irreversibility of the transition from active to inactive of i. Therefore, we claim that {q non-decreasing series. Thus, we prove (P1). From Equation (11), we have The ﬁrst inequality is due to Jensen’s inequality and convexity of the function 1/x. The second one follows from Lemma 5 and the fact of Proof. By (P1), we have q consider t = 2. From Equation 10, we see i we see for each t = 2, 3, . . . , K, α t = K + 1. We see that Therefore, β for all t ≥ K + 1. The above lemma implies that we will keep adding a proper attenuation factor β for all 1 < t ≤ K, and afterwards, we will essentially add no attenuation to i matched in the end in SAMP-AB. Proof. Let Z = Z t ≥ K, respectively. Let K/T = κ + o(1), where κ ∈ [0, 1] is a constant and o(1) is a vanishing term when T → ∞. Let f(p, x) = function over x ∈ [0, 1]. Lower bounding the value of E[Z round of t. Observe that Z before attenuation (i.e., 1 < 1/T and q≥ 1/T . · (1 − q) > 1 − 1/T . Thus, β= (1 − 1/T )/α< 1 and γ= 1 − 1/T . Continuing this analysis, Recall that K/T = κ + o(1). Plugging Inequality (14) to Inequality (13), we have Lower bounding the value of E[Z at (the beginning of) t after attenuation with probability E[1 be no attenuation in essence during all t > K. Thus, assume i apply almost the same analysis as in Section 4 to lower bound E[Z 6.1 Proof of Theorem 1 Let us brieﬂy describe Greedy and Ranking here for IFM and GFM. For Greedy, it will always assign an online arriving agent to an oﬄine available neighbor such that the match can improve the current objective of IFM and GFM most; break the tie in a uniformly way if there is. For Ranking, it will ﬁrst choose a random E[Z] ≥ F (x, κ).=dζ · e· f(e, x) + e1 −exp−dζ · fe, x. permutation π over all oﬄine neighbors and then it will always assign an online arriving agent to an oﬄine available neighbor with the lowest rank in π. Observe that IFM is a special case of GFM when each group consists of one single oﬄine type. Thus, it will suﬃce to show that Greedy and Ranking achieve a ratio of zero for IFM to prove Theorem 1. Example 2. Consider such an instance I of IFM as follows. We have |I| = |J| = T = n oﬄine and online agents. For j = 1, it can serve all oﬄine agents, i.e., N serve one single oﬄine agent i = j. Consider such an oﬄine algorithm ALG (not necessarily a clairvoyant optimal): Try to match each online agent j ∈ J with i = j if agent j arrives at least once. We can verify that in ALG, each oﬄine agent will be matched with probability at least 1 − e the oﬄine optimal, its performance should have OPT ≥ ALG ≥ 1 − e Lemma 8. Greedy achieves an online competitive ratio of zero for IFM Example 2. Proof. Let K j = 1 arrives at t, it will match i = 1 with a probability 1/(K i 6= 1, let Z j ∈ J, let A least once by t. Thus, Bernoulli random variables each with 1/T . By Chernoﬀ bound, we have Pr[A (note that n = T ). Note that Inequality (19) is due to that E Inequality (20) is due to This is in contrast with that OPT ≥ 1 − 1/e. Thus, we claim that Greedy achieves a ratio of zero. PrK≤12· (n − 1) · e= Pr(n − 1) −Z≤12· (n − 1) · e(15) = PrZ≥ n − 1 −12· (n − 1) · e(16) ≤ Pr1+ A≥ n − 1 −12· (n − 1) · e(17) ≤ e+ Pr1+ (n − 1)/(4e) ≥ n − 1 −12· (n − 1) · e(18) E[Z] ≤1Te+ exp−n − 18· e+1· (n − 1) · e+ 1 Lemma 9. Ranking has a competive ratio of zero for IFM on Example 2. Proof. Let S be the (random) set of indices of oﬄine nodes that fall before i = 1 under π. Consider a given S with |S| = K. For each j ∈ J, let A time t ∈ [T ]. For each i ∈ S, let Z Thus, plugging into the above result to Inequality (23), we have Observe that K takes values 0, 1, 2, . . . , n − 1 with a uniform probability 1/n. Thus, This is in contrast with that OPT ≥ 1 − 1/e. Thus, we claim that Ranking achieves a ratio of zero. Prmin(A, 1) + K/e≥ K(24) = Prmin(A, 1) − Emin(A, 1)≥ K − K/e− K ·1 − e(25) = Prmin(A, 1) − Emin(A, 1)≥ K · e− K/e(26) ≤ Prmin(A, 1) − Emin(A, 1)≥ K · e/2(27) ≤ exp− e· K/2 6.2 Proof of Theorem 4 Consider any bipartite graph (I, J, E) and let T denote the length of the time horizon. Let Ψ denote the ﬁnite set of all deterministic online matching policies given the graph and T . For any ψ ∈ Ψ and oﬄine node i ∈ I, let q by the end of the time horizon. Let n = |I| and ﬁx a feasible solution x ∈ [0, 1] LP: where variable z ministic policy ψ. Objective γ is set to the maximum value for which the randomized online algorithm can uniformly guarantee a matching probability of x get: Since Ψ is ﬁnite, by strong LP duality, whenever there exists a x ∈ [0, 1] value of the primal LP is γ = c, there exist feasible weights w with θ = c. That is, the LP for VOM has a feasible solution x with objective value deterministic online policy ψ cannot earn than c (by (29)). Since deterministic online policies are optimal in VOM with known weights, this shows that the competitive ratio for VOM cannot be better than c. To complete the proof, consider any upper bound c on the competitive ratio of GFM. There must exist a x ∈ [0, 1] achieve a competitive ratio of c in GFM). By the preceding argument, such an x would also upper-bound the competitive ratio of VOM by c. Taking an inﬁmum over all valid upper bounds c, we complete the proof that Φ(VOM) ≤ Φ(GFM). In turn, Φ(GFM) ≤ Φ(IFM) since IFM is a special case of GFM. Note that the converse inequality of Φ(VOM) ≥ Φ(GFM) cannot be argued in the same way since the groups may overlap arbitrarily; the converse inequality of Φ(VOM) ≥ Φ(IFM) also cannot be argued since the x ∈ [0, 1] VOM may not satisfy x Preprocessing of a Ride-hailing dataset. We test our algorithms of IFM and GFM on a public ridehailing dataset, which is collected from the city of Chicago https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips/m6dm-c72p such that the primal objective value is no greater than c (otherwise it would be possible to Fig. 1: Experimental results of IFM and GFM on a real ride-hailing dataset in Chicago: The total number of arrivals T takes values from {50, 75, 100, 125, 150} with |I| = |J| = T . a short time window and assume that drivers are oﬄine agents while riders are online agents that arrive dynamically. Our goal is to maximize individual and group fairness among all drivers. The dataset has more than 169 million trips starting from November 2018. Each trip record includes the trip length, the starting and ending time, the pick-up and drop-oﬀ locations for the passenger, and some other information such as the fare and the tip. Note that Chicago is made up of 77 community areas that are well deﬁned and do not overlap. Thus, we can categorize all trips according to the pre-deﬁned community areas. In our case, we deﬁne a driver group for each of the 77 areas and assume each driver belongs to the group identiﬁed as her starting community area. Recall that our metric of group fairness is deﬁned as the minimum matching rates of oﬄine agents over all groups, which aﬀects the minimum average-earning-rate among ride-hailing drivers across diﬀerent community areas in Chicago. Since locations reﬂect the racial- and socioeconomic-disparities in Chicago can help promote racial and social equity as well. We construct the input bipartite graph as follows. We focus on the time window from 18 : 00 to 19 : 00 on September 29, 2020, and subsample T trips from a total of 11, 228 trips. For each trip, we create an individual driver i and rider j, where i has an attribute of a starting community area while j has an attribute of a pair of starting and ending areas. In this way, we have |I| = |J| = T . Note that it is possible for multiple drivers to share the same starting community area. In this case, we assume they belong to the same group identiﬁed by the starting area. For each driver-rider pair, we add an edge if they share the same starting area. Algorithms. For the problems IFM and GFM, we compare our algorithm SAMP-B against the following: (a) GREEDY: Assign each arriving agent to an available neighbor (IFM) or an available neighbor whose group has the lowest matching rate at the time of arrival (GFM); break ties uniformly at random. (b) RANKING: Fix a uniform random permutation of I at the start; assign each arriving agent to the adjacent available oﬄine agent who is earliest in this order. (c) BSSX: the algorithm from [23] but customized to our setting by replacing its benchmark-LP objectives with LP (1) (IFM) and LP (2) (GFM). (d) MGS: similar to our boosting algorithm, but following [12], generating two random candidate neighbors upon the arrival of every online agent instead, and matching it with the ﬁrst available one. Note that here we do not compare against the algorithm in [10], which relies on the special structure of the LP solution that all x structure unfortunately no longer holds when the objective is either LP (1) (IFM) or LP (2) (GFM). Results and discussions. For the real dataset, we vary the number of subsampled trips T in {50, 75, 100, 125, 150}. We ﬁrst construct 100 subsampled instances for each given T , and then run 100 trials on each instance, https://statisticalatlas.com/place/Illinois/Chicago/Race-and-Ethnicity , we believe our objective of maximizing group fairness among drivers across diﬀerent locations reporting the average performance. Note that in the oﬄine phase of SAMP-AB, when it comes to estimation of the attenuation factor β taking the average. Figure 1a shows that for IFM, SAMP-B performs as well as MGS, and both have a signiﬁcant advantage over GREEDY, RANKING, and BSSX. The competitive ratios of SAMP-B always stay above 0.722, which is consistent with our theoretical bound in Theorem 2. Figure 1b shows that for GFM, SAMP-B performs as good as RANKING, BSSX and MGS, and only SAMP-AB and GREEDY fall behind. That being said, unlike GREEDY, SAMP-AB achieves a steady ratio well above 0.7 over diﬀerent choices of T . This is consistent with results in Theorem 3. All results here suggest that SAMP-B and MGS are top two candidates in practice for both IFM and GFM. We emphasize that although our SAMP-B algorithm does not signiﬁcantly outperform the (fairnessadapted) MGS algorithm from the literature, it is both conceptually and implementation-wise much simpler. To our understanding, it is surprising that such a simple adaptive boosting algorithm has not been analyzed and extensively tested before. Construction of input instances. We acknowledge that it is hard to identify real applications that can perfectly ﬁt the model of VOM. [50] has conducted comprehensive experimental studies, which compare the performance of diﬀerent algorithms for unweighted online matching under KIID on a wide variety of synthetic and real datasets. They proposed an idea, called random balanced partition method, to generate a bipartite graph from a practical social network. The details are as follows. Suppose we have a real social network with V being the set of vertices and E being the set of edges. The method partitions V uniformly randomly into two blocks L and R, such that |L| = b|V |/2c and |R| = d|V |/2e. It keeps only those edges that connect two vertices from the two diﬀerent partitions. As indicated by [50], research on how to form a maximum matching on a bipartite graph constructed from a real social network can oﬀer great insights regarding how to boost friendship ties among users active in online social platforms (e.g., Facebook). We follow the idea in [50] and select four datasets from the Network Data Repository [28], namely, socfbCaltech36, socfb-Reed98, econ-because and econ-mbeaﬂw. The former two datasets are Facebook social-network graphs, where vertices are users and edges are friendship ties. The latter two datasets are two economic networks collected from the U.S.A. in 1972, where vertices are commodities/industries and edges are economic transactions. We list detailed statistics of these 4 datasets in Table 1. For each network graph (V, E), we ﬁrst downsample the network size |V | to 200. Since the original graphs are non-bipartite, we ﬁrst partition all nodes uniformly at random into two blocks to construct I and J, such that |I| = b|V |/2c and |J| = d|V |/2e. We keep only the edges that connect two vertices from diﬀerent partitions. We assign the weight for each oﬄine vertex i to be a random value, uniformly selected from [0, 1]. Algorithms. Similar to IFM and GFM, we compare SAMP-B and SAMP-AB against several baselines, including GREEDY, RANKING, BSSX [23], and MGS [12]. Additionally, we test the algorithm presented by [10], denoted by JL. For each of the four instances, we run the above 7 algorithms for 100 times and take the average as the ﬁnal performance. Results and discussion. Figure 2 shows that SAMP-B is second only to GREEDY and is comparable to GREEDY in half of the total instances. The gap between SAMP-B and GREEDY declines as the average Table 1: Network data statistics for graphs from the Network Data Repository [28]. Fig. 2: Experimental results of VOM with on four real datasets from the Network Data Repository [28]. degree of all nodes increases; see econ-because and econ-mbeaﬂw. For all instances, SAMP-B outperforms the other three LP-based algorithms, BSSX, MGS and JL, all of which involve a much more complicated implementation. This establishes the superiority of SAMP-B in practical instances of VOM over the three LP-based baselines. We observe that the competitive ratios of SAMP-AB are always above 0.719, which is consistent with our theoretical bound in Theorem 3. Also, note that SAMP-AB can beat the rest three LP-based baselines in almost all scenarios (except for socfb-Reed98), which suggests that SAMP-AB is a top candidate among all all LP-based algorithms. Preprocessing of a synthetic dataset. We ﬁrst construct the bipartite graph G = (I, J, E), where we always ﬁx |I| = 100 and set |J| = T . For each oﬄine agent i, we randomly choose δ online agents among J as its neighbors, i.e., |N integral arrival rates for all oﬄine agents, thus, we assume w.l.o.g. that all r Algorithms. We compare our algorithm SAMP-B against the following: (a) GREEDY: Assign each arriving agent to an available neighbor at the time of arrival; break ties uniformly at random. (b) RANKING: Fix a uniformly random permutation of I at the start; assign each arriving agent to the adjacent available oﬄine agent who is earliest in this order. (c) BSSX: the algorithm from [23] but customized to our setting by replacing its benchmark-LP objectives with LP (1). Results and discussion. For synthetic dataset, we vary the average degree δ in {2, 3, 4, 5, 6} and the total number of arrivals T in {50, 100, 300, 500, 1000}, respectively. For each instance, we run all algorithms for 100 times and take the average as the ﬁnal performance. Figure 3 and Figure 4 show the results on synthetic dataset. Almost in all cases, SAMP-B is the clear winner and has the best performance. At times two heuristics do well, as shown in Figure 3b. This is due to the fact that the more resources we have (with a larger average degree δ and total number of arrivals T ), the less planning we need. However, when we set |I| = |J| = T , as shown in Figure 3a, SAMP-B outperforms the two heuristics signiﬁcantly. In addition, Figure 4 shows that when T is small, SAMP-B is close to its competitive ratio of 0.722, as given in Theorem 2. This highlights the tightness of our theoretical lower bound. Fig. 3: Experiments on IFM with synthetic dataset: The average degree δ takes values from {2, 3, 4, 5, 6} and the total number of arrivals T takes values from {100, 500} with |I| = 100. Fig. 4: Experiments on IFM with synthetic dataset: The total number of arrivals T takes values from {50, 100, 300, 500, 1000} and the average degree δ takes values from {2, 3} with |I| = 100. Synthetic dataset. Our experimental setup for the synthetic datasets is as follows. We ﬁrst construct the bipartite graph G = (I, J, E), where we always set |I| = |J| = T . For each oﬄine agent i, we randomly choose δ online agents among J as its neighbors, i.e., |N |I| = |J|. We assign the weight for each oﬄine vertex i to be a random value, uniformly selected from [0, 1]. Algorithms. Similar to IFM, we compare SAMP-B and SAMP-AB against several baselines, including Greedy, RANKING, BSSX [23]. Additionally, we test the algorithm presented by [10], denoted by JL. For each instance, we run the above 6 algorithms for 100 times and take the average as the ﬁnal performance. Note that in the oﬄine phase of SAMP-AB, we estimate the attenuation factor β Carlo method for 100 times. For each algorithm, we compute two kinds of competitive ratio as follows: (1) CR1: min (a) Experimental results when varying average de-(b) Experimental results when varying average degree δ, while ﬁxing |I| = 100 and |J| = T = 100.gree δ, while ﬁxing |I| = 100 and |J| = T = 500. (a) Experimental results when varying T , while ﬁx-(b) Experimental results when varying T , while ing |I| = 100 and δ = 2.ﬁxing |I| = 100 and δ = 3. E[Z]/x. (2) CR2:Pw∗ E[Z]. Fig. 5: Experiments on VOM with synthetic dataset: The average degree δ takes values from {2, 3, 4, 5, 6} with |I| = |J| = T = 100. Fig. 6: Experiments on VOM with synthetic dataset: The total number of arrivals T takes values from {70, 80, 90, 100} with the average degree δ = 3. Results and discussion. For synthetic dataset, we run two kinds of experiments by varying the average degree δ in {2, 3, 4, 5, 6} and the total number of arrivals T in {70, 80, 90, 100}, respectively. Overall, the CR1 achieved by each algorithm is strictly dominated by its corresponding CR2. This is expected since CR1 takes the minimum expected matching ratio over all i as the ﬁnal ratio. The higher CR1 an algorithm achieves, the more robust the algorithm will be. As shown in Figure 5 and 6, we highlight that SAMP-B displays remarkable robustness, i.e., the best CR1 achieved, signiﬁcantly outperforming the two heuristics, although SAMP-B has a slightly lower CR2 when compared with GREEDY. Note that in all cases, the CR2 achieved by SAMP-B and SAMP-AB is always above 0.719, which is consistent with our theoretical prediction in Theorem 3. Another observation is that SAMP-B can outperform the other two LP-based algorithms, BSSX and JL, all of which involve a much more complicated implementation. (a) CR1 achieved when varying average degree δ.(b) CR2 achieved when varying average degree δ. (a) CR1 achieved when varying the total number(b) CR2 achieved when varying the total number of arrivals T .of arrivals T . In this paper, we proposed two online-matching based models to study individual and group fairness maximization among oﬄine agents in OMMs. For individual and group fairness maximization, we presented two LP-based sampling algorithms, namely SAMP-B and SAMP-AB, which achieve online competitive ratios at least 0.725 and 0.719, respectively. We conducted extensive numerical experiments and results show that SAMP-B is not only conceptually easy to implement but also highly eﬀective in practical instances of fairness-maximization related models. One interesting future direction is to show some explicit upper bounds for IFM, GFM, and VOM. So far, all existing upper bounds for online matching under KIID are for the unweighted case due to [12]. Can we derive some upper bounds speciﬁcally for IFM, GFM or VOM? We expect the upper bound of IFM should be slightly higher than that of VOM as suggested by Theorem 4. [1] Kostas Bimpikis, Ozan Candogan, and Daniela Saban. Spatial pricing in ride-sharing networks. Oper[2] Hongyao Ma, Fei Fang, and David C Parkes. Spatio-temporal pricing for ridesharing platforms. In [3] Jacob Thebault-Spieker, Loren G Terveen, and Brent Hecht. Avoiding the south side and the sub- [4] Cody Cook, Rebecca Diamond, Jonathan Hall, John A List, and Paul Oyer. The gender earnings gap [5] Alex Rosenblat, Karen Levy, Solon Barocas, and Tim Hwang. Discriminating tastes: Customer ratings [6] Emma Hinchliﬀe. Yes, there’s a wage gap for uber and lyft drivers based on age, gender and race. [7] Boming Zhao, Pan Xu, Yexuan Shi, Yongxin Tong, Zimu Zhou, and Yuxiang Zeng. Preference-aware [8] John P Dickerson, Karthik Abinav Sankararaman, Aravind Srinivasan, and Pan Xu. Assigning tasks [9] Elaheh Fata, Will Ma, and David Simchi-Levi. Multi-stage and multi-customer assortment optimization [10] Patrick Jaillet and Xin Lu. Online stochastic matching: New algorithms with better bounds. Mathe[11] Brian Brubach, Karthik Abinav Sankararaman, Aravind Srinivasan, and Pan Xu. Online stochastic [12] Vahideh H Manshadi, Shayan Oveis Gharan, and Amin Saberi. Online stochastic matching: Online [13] Bernhard Haeupler, Vahab S. Mirrokni, and Morteza Zadimoghaddam. Online stochastic weighted [14] Jon Feldman, Aranyak Mehta, Vahab Mirrokni, and S Muthukrishnan. Online stochastic matching: [15] Aranyak Mehta. Online matching and ad allocation. Foundations and Trends in Theoretical Computer [16] Zhiyi Huang and Xinkai Shu. Online stochastic matching, poisson arrivals, and the natural linear [17] Saeed Alaei, MohammadTaghi Hajiaghayi, and Vahid Liaghat. Online prophet-inequality matching with [18] Bernhard Haeupler, Vahab S. Mirrokni, and Morteza Zadimoghaddam. Online stochastic weighted ations Research, 67(3):744–769, 2019. Proceedings of the 2019 ACM Conference on Economics and Computation, EC ’19, page 583, 2019. urbs: The geography of mobile crowdsourcing markets. In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing, pages 265–275. ACM, 2015. in the gig economy: Evidence from over a million rideshare drivers. Technical report, National Bureau of Economic Research, 2018. as vehicles for bias. Available at SSRN 2858946, 2016. https://mashable.com/2017/01/18/uber-lyft-wage-gap-rideshare/, 2017. Accessed: 2019-12-27. task assignment in on-demand taxi dispatching: An online stable matching approach. In Proceedings of the Thirty-Third Conference on Artiﬁcial Intelligence, AAAI ’19, pages 2245–2252, 2019. to workers based on historical data: Online task assignment with two-sided arrivals. In Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems, pages 318–326. International Foundation for Autonomous Agents and Multiagent Systems, 2018. with inventory constraints. Available at SSRN 3443109, 2019. matics of Operations Research, 39(3):624–646, 2013. matching: New algorithms and bounds. Algorithmica, 82(10):2737–2783, 2020. actions based on oﬄine statistics. Mathematics of Operations Research, 37(4):559–573, 2012. matching: Improved approximation algorithms. In Internet and Network Economics, volume 7090 of Lecture Notes in Computer Science, pages 170–181. Springer Berlin Heidelberg, 2011. ISBN 978-3-642- 25509-0. Beating 1-1/e. In Foundations of Computer Science, 2009. FOCS’09. 50th Annual IEEE Symposium on, pages 117–126. IEEE, 2009. Science, 8(4):265–368, 2013. program. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages 682–693, 2021. applications to ad allocation. In Proceedings of the 13th ACM Conference on Electronic Commerce, pages 18–35, 2012. matching: Improved approximation algorithms. In Internet and Network Economics - 7th International Workshop, WINE ’11, pages 170–181, 2011. [19] John P Dickerson, Karthik Abinav Sankararaman, Aravind Srinivasan, and Pan Xu. Balancing relevance [20] John P Dickerson, Karthik Abinav Sankararaman, Kanthi Kiran Sarpatwar, Aravind Srinivasan, Kun- [21] Will Ma. Improvements and generalizations of stochastic knapsack and multi-armed bandit approx- [22] Marek Adamczyk, Fabrizio Grandoni, and Joydeep Mukherjee. Improved approximation algorithms for [23] Brian Brubach, Karthik Abinav Sankararaman, Aravind Srinivasan, and Pan Xu. Attenuate locally, win [24] Yiding Feng, Rad Niazadeh, and Amin Saberi. Linear programming based online policies for real-time [25] John P. Dickerson, Karthik Abinav Sankararaman, Aravind Srinivasan, and Pan Xu. Allocation prob- [26] Gagan Goel and Aranyak Mehta. Online budgeted matching in random input models with applications [27] Richard M. Karp, Umesh V. Vazirani, and Vijay V. Vazirani. An optimal algorithm for on-line bipartite [28] Ryan A. Rossi and Nesreen K. Ahmed. The network data repository with interactive graph analytics [29] Duncan C. McElfresh, Christian Kroer, Sergey Pupyrev, Eric Sodomka, Karthik Abinav Sankararaman, [30] Vahideh Manshadi and Scott Rodilitz. Online policies for eﬃcient volunteer crowdsourcing. Proceedings [31] Z. Li, Kelsey Lieberman, William Macke, Soﬁa Carrillo, C. Ho, J. Wellen, and Sanmay Das. Incorpo- [32] Tom Sühr, Asia J. Biega, Meike Zehlike, Krishna P. Gummadi, and Abhijnan Chakraborty. Two- [33] Nixie S Lesmana, Xuan Zhang, and Xiaohui Bei. Balancing eﬃciency and fairness in on-demand rides[34] Govind S Sankar, Anand Louis, Meghana Nasre, and Prajakta Nimbhorkar. Matchings with group [35] David García-Soriano and Francesco Bonchi. Fair-by-design matching. Data Mining and Knowledge [36] Vedant Nanda, Pan Xu, Karthik Abhinav Sankararaman, John Dickerson, and Aravind Srinivasan. [37] Yifan Xu and Pan Xu. Trade the system eﬃciency for the income equality of drivers in rideshare. In and diversity in online bipartite matching via submodularity. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 33, pages 1877–1884, 2019. Lung Wu, and Pan Xu. Online resource allocation with matching constraints. In Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems, pages 1681–1689. International Foundation for Autonomous Agents and Multiagent Systems, 2019. imation algorithms. In Proceedings of the Twenty-Fifth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 1154–1163, 2014. stochastic matching. In Algorithms - ESA 2015 - 23rd Annual European Symposium. 2015. globally: An attenuation-based framework for online stochastic matching with timeouts. Algorithmica, 82(1):64–87, 2020. assortment of reusable resources. Available at SSRN 3421227, 2019. lems in ride-sharing platforms: Online matching with oﬄine reusable resources. In Proceedings of the Thirty-Second AAAI Conference on Artiﬁcial Intelligence, AAAI ’18, pages 1007–1014, 2018. to adwords. In Proceedings of the Nineteenth Annual ACM-SIAM Symposium on Discrete Algorithms, volume 8, pages 982–991, 2008. matching. In Proceedings of the 22nd Annual ACM Symposium on Theory of Computing, STOC ’90, pages 352–358, 1990. and visualization. In Blai Bonet and Sven Koenig, editors, Proceedings of the Twenty-Ninth AAAI Conference on Artiﬁcial Intelligence, AAAI’15, pages 4292–4293, 2015. Zack Chauvin, Neil Dexter, and John P. Dickerson. Matching algorithms for blood donation. Proceedings of the 21st ACM Conference on Economics and Computation, 2020. of the 21st ACM Conference on Economics and Computation, 2020. rating compatible pairs in kidney exchange: A dynamic weighted matching model. Proceedings of the 2019 ACM Conference on Economics and Computation, 2019. sided fairness for repeated matchings in two-sided markets: A case study of a ride-hailing platform. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 3082–3092, 2019. ourcing. In Advances in Neural Information Processing Systems, pages 5310–5320, 2019. fairness constraints: Online and oﬄine algorithms. arXiv preprint arXiv:2105.09522, 2021. Discovery, 34(5):1291–1335, 2020. Balancing the tradeoﬀ between proﬁt and fairness in rideshare platforms during high-demand hours. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 34, pages 2210–2217, 2020. Proceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence, pages 4199– 4205, 2020. [38] Will Ma, Pan Xu, and Yifan Xu. Group-level fairness maximization in online bipartite matching. arXiv [39] Vahideh Manshadi, Rad Niazadeh, and Scott Rodilitz. Fair dynamic rationing. Available at SSRN [40] Jad Salem and Swati Gupta. Closing the gap: Group-aware parallelization for online selection of candi[41] Alan Tsang, Bryan Wilder, Eric Rice, Milind Tambe, and Yair Zick. Group-fairness in inﬂuence maxi[42] Vishakha Patil, Ganesh Ghalme, Vineet Nair, and Y Narahari. Achieving fairness in the stochastic multi- [43] Stephen Gillen, Christopher Jung, Michael Kearns, and Aaron Roth. Online learning with an unknown [44] Matthew Joseph, Michael J Kearns, Jamie H Morgenstern, and Aaron Roth. Fairness in learning: [45] Sean R Sinclair, Siddhartha Banerjee, and Christina Lee Yu. Sequential fair allocation: Achieving the [46] Nikhil Bansal, Haotian Jiang, Raghu Meka, Sahil Singla, and Makrand Sinha. Online discrepancy [47] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness through [48] Michael Mitzenmacher and Eli Upfal. Probability and computing: Randomization and probabilistic tech[49] Kumar Joag-Dev and Frank Proschan. Negative association of random variables with applications. The [50] Allan Borodin, Christodoulos Karavasilis, and Denis Pankratov. An experimental study of algorithms preprint arXiv:2011.13908, 2021. 3775895, 2021. dates with biased evaluations. Available at SSRN 3444283, 2019. mization. arXiv preprint arXiv:1903.00967, 2019. armed bandit problem. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 34, pages 5379–5386, 2020. fairness metric. arXiv preprint arXiv:1802.06936, 2018. Classic and contextual bandits. In NIPAdvances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing SystemsS, pages 325–333, 2016. optimal envy-eﬃciency tradeoﬀ curve. arXiv preprint arXiv:2105.05308, 2021. minimization for stochastic arrivals. In Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 2842–2861. SIAM, 2021. awareness. In Proceedings of the 3rd innovations in theoretical computer science conference, pages 214– 226, 2012. niques in algorithms and data analysis. Cambridge university press, 2017. Annals of Statistics, pages 286–295, 1983. for online bipartite matching. Journal of Experimental Algorithmics (JEA), 25:1–37, 2020.