Abstract—Small angle X-ray scattering (SAXS) is extensively used in materials science as a way of examining nanostructures. The analysis of experimental SAXS data involves mapping a rather simple data format to a vast amount of structural models. Despite various scientiﬁc computing tools to assist the model selection, the activity heavily relies on the SAXS analysts’ experience, which is recognized as an efﬁciency bottleneck by the community. To cope with this decision-making problem, we develop and evaluate the open-source, Machine Learning-based tool SCAN (SCattering Ai aNalysis) to provide recommendations on model selection. SCAN exploits multiple machine learning algorithms and uses models and a simulation tool implemented in the SasView package for generating a well deﬁned set of datasets. Our evaluation shows that SCAN delivers an overall accuracy of 95%-97%. The XGBoost Classiﬁer has been identiﬁed as the most accurate method with a good balance between accuracy and training time. With eleven predeﬁned structural models for common nanostructures and an easy draw-drop function to expand the number and types training models, SCAN can accelerate the SAXS data analysis workﬂow. Index Terms—SAXS, scattering, scientiﬁc computing, classiﬁcation, Random Forest, XGBoost The advancing of our society is greatly related to the development of new materials. From the stone age to the silicon era, even till the coming quantum world, new materials lay the groundwork for novel technologies. All materials are built upon controlled arrangement of atoms via either naturally occurring or artiﬁcially imposed design. Such an arrangement is known as materials structure, which usually demonstrates a hierarchical characteristic. From an˚Angstrom, about the size of one atom, to kilometers which represents the largest sizes of man-made objects, materials may be shaped into different structures at different levels to serve its intended functions. Nanotechnology has revolutionized materials science. Since the famous quote ”There’s Plenty of Room at the Bottom” by Dr. Richard Feynman [1], efforts to control materials structure have been focused on the nanoscale – this is now widely known as nanomaterials. Materials with designed nanostructures can demonstrate properties that would never be possible through conventional material design. Advanced characterization methods play a central role in the development of new materials. At research infrastructures such as the Swedish national MAX IV Laboratory, a 4th generation synchrotron radiation facility, X-rays are used to get unique insights into materials in terms of structure and properties [2]. The obtained knowledge paves the way for the development of new materials in various ﬁelds, e.g., medications, microelectronics, energy generation and storage, biodegradable plastics, and novel packaging, etc. [3] In general, the synchrotron radiation based techniques could be classiﬁed into three categories: i) scattering, ii) spectroscopy, and iii) imaging, which provide complimentary information of the material structure and properties [4]. Scattering is powerful in structure determination from submicron down to˚Angstrom. It is a process where incoming X-ray photons are forced to change the travelling direction to a certain angle, known as scattering angle, after an interaction with materials. The intensity of the scattered Xray as a function of scattering angle contains information of the materials structure. Theoretically, the intensity distribution follows the magnitude of Fourier transformation (FT) of the electron density distribution in the materials. This leads to a fact that the size which scattering technique could probe is inversely proportional to the scattering angle. Thus, practically, scattering characterization is performed at two geometries depending on the scattering angle, i.e. small angle X-ray scattering (SAXS) and wide angle X-ray scattering (WAXS). While WAXS is more sensitive to the local atomic structure, SAXS experiments cover the material structures spanning over several orders of magnitude from several hundred nanometer to several nanometer by a single scattering pattern. In applications, SAXS has been used to study various nanostructures’ shapes, which critically relates to material properties. Furthermore, the high photon ﬂux at a synchrotron radiation facility allows SAXS experiments to be performed at tens Hz up to thousand Hz with a single frame of ∼MB size. Abundant SAXS data can even serve as a real-time animation revealing a continous nanostructure development. However, mapping of SAXS data to real nanostructures is not straightforward. SAXS intensity is essentially the magnitude of FT without “phase” information. Experimentalists use SAXS tools to match each single experimental data set with a set of existing models representing the studied nanostructure. As more high data-rate SAXS experiments are foreseen, such traditional analysis approaches could become a bottleneck in the process. The tools offer a large selection, sometimes hundreds, of predeﬁned models to choose from. There is no easy way to know which one to choose, and checking all of them is infeasible. So, effectively, there is a considerable amount of experience necessary to efﬁciently select the correct model or to even narrow the selection to some plausible model candidates. As pointed out in [5], [6], this step can be very intimidating to both new and advanced users. There are some reports (e.g. [5], [6]) that show encouraging results from using supervised learning to facilitate the model selection. As a part of this study, we have produced an opensource scattering analysis tool called SCAN. We used the tool to evaluate a selection of machine learning (ML) models on our scattering data. The results we have obtained are promising. On our data set, our classiﬁcation models outperform previous work reported in the literature and the accuracy ﬁgures we obtain make them highly relevant to users analyzing SAXS data. We envision that supervised learning could be a practical tool to increase the level of automation in the work of SAXS analysts [7], speeding up the characterization. The reminder of the paper is structured as follows. Section II summarizes related work. Section III presents our open source SCAN tool. The evaluation method is presented in Section IV and evaluation results are presented in Sections V. The ﬁndings are discussed and compared to related work in Section VI and Section VII presents the conclusions from our work. ML enters new applications areas almost daily, ranging from character recognition, through product recommendations to self driving cars. A surge of applications of ML in scientiﬁc computing is also evident [8]–[10]. In the ﬁeld of materials characterization, where large volume multidimensional data are available, the application of ML has a great potential and is clearly gaining momentum [11]. Recently, Chen et al [12] has reviewed the latest progress in the area of X-ray scattering characterization. As an important technique, SAXS has already become a test ﬁeld for ML-assisted analytics. One type of application is around the experimental conﬁguration; Wang, et al., use deep learning to classify the experimental conﬁguration-based scattering image [13]. Herck et al, use deep learning to study the structure distribution at grazing incidence geometry [14]. Another type of application is about SAXS for biomarcomolecules, which serves a well deﬁned user community. For example, Franke et al., focused on feature extraction of the scattering pattern and use weighted k Nearest Neighbour (wKNN) and wkNN with Gaussian processes to classify low resolution molecular structure into different shapes [15]. He et al., instead turned to the autoencoder to reconstruct biomacromolecules from bio-SAXS curves [16]. For the general nanostructure analysis, Archibald et al. used KNN to classify general structural models and analyzing SAXS curves [5]. Do et al. instead discovered that the Random Forest is a feasible model with an accuracy of 0.783 for such classiﬁcations [6]. In this work, along the line of pioneer work of Archibald et al. and and Do et al., we aim to offer materials scientists a tool which synergizes different ML algorithms to help SAXS analysts quickly identify a likely model structure for further analysis. To facilitate SAXS analysts’ model selection we have implemented a tool called SCAN (SCattering Ai aNalysis). The tool offers ML model management and classiﬁcation interfaces. The former makes it possible to train, evaluate and maintain any number of ML classiﬁcation models. The latter provides possibility to use the tool for performing classiﬁcation on an experimental data using any of the available classiﬁcation models. The source code and the training data (described in Section IV-A) are hosted on GitHub [17] under an MIT license. SCAN supports nine different ML classiﬁers as well as a possibility to run them in a stacked manner. The classiﬁers included are the following: All but the two XGBoost classiﬁers are implemented using the scikit-learn library [18]. XGBoostClassiﬁer and XGBoostRandomForestClassiﬁer come from the XGBoost library [19]. One notable difference between the two libraries is that, at the time of writing, only XGBoost offered GPU acceleration. All algorithms have been run with default parameters, one of the goals with this evaluation was to check if further hyperparameter tuning would be required. Except from training and maintaining the classiﬁcation models, the management interface offers a possibility to reduce the dimensionality of the input data by using Principal Component Analysis (PCA) and to request a k-fold cross validation. In the classiﬁcation interface the data is provided in the form of a comma-separated values (CSV) ﬁle. The output is another CSV ﬁle, where each input item is annotated with a predicted nanostructure shape and a corresponding probability (conﬁdence) for each selected ML classiﬁer. The interaction with the software is either through a command line or through a web interface. We developed SCAN to meet expectations of a sustainable ML-based tool in scientiﬁc computation. During development, we aligned our work with contemporary discussions on the trending topic of MLOps, i.e., standardization and streamlining of ML life cycle management. In line with work on sustainable MLOps in scientiﬁc computing by Tamburri [20], we supported experiment tracking and explainability by connecting the service Neptune AI [21] to a continuous integration pipeline orchestrated by GitHub Actions. In practice, each pull request (e.g., modifying code, data, or hyperparameters) triggered a reevaluation of model performance and presented the results in an online dashboard. This section ﬁrst presents how we generated representative data using the SASView [22]. Second, we present how we trained and evaluated classiﬁcation models. As aforementioned, ideal scattering intensity is a result of the FT of the electron density distribution inside materials. Thus, SAXS data could be generated via theoretical simulation to meet requirements on large data sets. Here, we use sasmodel module from the SASView software [22], which has been used in previous work [5], [6]. Poisson error distribution has been added onto the generated data to take into account the photon counting event. We have chosen both geometric models and a statistic model to generate the training and test data. For the geometric model, eight common models for nanoobjects in solutions were chosen, including sphere, sphere with fuzzy shell, ellipsoid with different aspect ratios, long and/or hollow cylinder, and ﬂat disk. For statistical models, which are common for systems without deﬁned shapes, three models were selected: Debye-Anderson-Brumberger (DAB) Model [23], Polymer Excluded Volume model [24] and Teubner-Strey model of microemulsions [25]. Furthermore, we added one mixture case consisting of certain sphere and cylinder with arbitrary weighted non-zero contribution to further challenge the classiﬁcation process. In each model, the randomized model parameter, such as radius and length, as well as the polydisperse size and aspect ratio were introduced with the methods available via sasmodels and/or Numpy packages. All the data are generated as (x,y) curves with y as the scattering intensity and x as the scattering vector q (nm), which is deﬁned as q =sin(θ) with θ as half of the scattering angle. The q range is chosen [10nm, 3nm], covering the common SAXS probing range. Selected plots from each model are shown in Fig. 1. For each model, 3,000 curves were generated and both geometric and statistical model were fed into SCAN for training at the same time. All data are publicly available in the GitHub repository. The candidates for evaluation have been selected in the following way: 1) We have trained models for all nine individual classiﬁers supported by the SCAN tool. On top of that we have trained two stacked models 2) For every candidate classiﬁer, we have considered the following inputs In total we evaluate 33 candidate classiﬁcation models. The stacked models are included in the study to investigate if combining multiple classiﬁers yields a better result that any single classiﬁer. PCA is included for two reasons: it should reduce the training time and there are studies (e.g. [26]) that report potential positive impact of PCA on the model accuracy. The evaluation follows the same method as used in [6]. We perform 5-fold cross validation and, for each model, we report the mean accuracy together with the standard deviation. k-fold validation is a common method of evaluating classiﬁcation models, and using the same split parameter as in [6] makes it possible to compare the results. Additionally, to visualize the results, we present confusion matrices for selected models. Table I summarizes the accuracy numbers accompanied by standard deviation. Individually, XGBoost Classiﬁer and Random Forest Classiﬁer outperform other individual candidates. This holds true regardless if PCA has been applied. The stacked models offer even slightly better results, and the model based on the top 5 individual classiﬁers is performing at least as well as the one combining all. To closer inspect the performance of the models we have created confusion matrices for the three most promising models for respective inputs, i.e., i) all inputs (Fig. 2), ii) PCA set to 99%, and iii) PCA set to 95% (Fig. 3 and 4, respectively). In the process we have also clocked the training and evaluation for all the models. Table II presents the timings of the top 3 classiﬁers depicted in Fig. 2-4. We ﬁnd our results encouraging. In (Table I) we can see that our classiﬁcation models can reach the accuracy of over 97% for the stacked models. However, the training of these models is the most time consuming - Table II shows that their training takes roughly order of magnitude longer time compared to the best individual classiﬁers, i.e. RandomForrestClassiﬁer and XGBoostClassiﬁer. These individual classiﬁers do not fall far behind with respect to accuracy, they score almost 96%. As a result of this observation these two individual classiﬁers have been selected as default choice in the SCAN tool, leaving the other ones optional. A close analysis of the confusion matrices reveals that generally lower accuracy predictions are made for sphere, ellipsoidal and sphere-like models – this phenomenon is consistent across classiﬁers. We hoped to tackle this by stacking classiﬁers into an ensemble of diverse models. However, the only marginally better confusion matrices of stacked models conﬁrmed that sphere-like model remains a challenging case. This ﬁnding is consistent with previous work [5], [6]. Somewhat contradictory, sphere-like shapes is probably one of the most recognizable models in the SAXS textbook [27]. One explanation could be that spherical models easily resemble each other upon the common “sphere”-shape envelope proﬁle and polydispersity of its radius. To better distinguish spherelike models could certainly be a future topic in ML-assisted scattering analysis. In addition, as an attempt, we also introduced the “sphere + cylinder” class by summing cylinder models and sphere models in a certain ratio. As a result, the “sphere + cylinder” class obtains better prediction accuracy than the pure sphere-like class. This opens doors to identify the possible shape transition for many soft matter systems during in situ studies [28]. The mixing model is also an efﬁcient method for data augmentation to expand the model selections. We have also experimented with applying PCA. For the best performing classiﬁers, the PCA application consistently leads to slightly worse accuracy across all tested cases, but at the same time it speeds up the training process. Applying PCA does not change the list of most promising classiﬁcation models, and their relative performance remains the same. Therefore, should the training time ever become an issue (e.g. extensive experimentation), one may consider using PCA, at least in the experimentation phase, to ﬁnd the most suitable classiﬁcation models. As we considered the obtained accuracy adequate for the practical needs, we have not attempted any hyperparameter tuning in this study. This is an obvious candidate for further work, as it may possibly yield even better results. The purpose of this study was to investigate the applicability of ML to assist SAXS analysts in the task of model selection. In the course of the study, we have developed an open-source tool called SCAN that made it possible for us to create and evaluate eleven ML classiﬁers trained and evaluated on our scattering data. The tool also provides the classiﬁcation interface that is meant to provide actual model recommendations to practitioners. We have found that on our scattering data multiple ML methods provided satisfactory accuracy for 11 common SAXS models. Random Forest and XGBoost are the most promising classiﬁers, deeming the accuracy from 89% to as high as 95.9%, depending on whether the PCA has been applied. The highest accuracy of 97% has been obtained using stacked classiﬁers but at a cost of signiﬁcantly longer training time. The accuracy achieved in this project should provide adequate support to SAXS analysts. We believe that the tool is useful for both novice and experienced users. With some of the most common models in our training data, the SCAN tool can accelerate the model selection process already now. Furthermore, the training data can easily be expanded by including additional models from sasmodel and/or from labelled experimental data provided by users, making it easily adaptable to speciﬁc needs of individual analysts. At the same time the open source implementation makes it possible for anyone to contribute to the tool. The SCAN tool is created in such a way that it would be even possible to directly connect to an experimental setup to read the data ﬁle in real time. Thus, we conclude that the application of ML classiﬁers to the data generated by SAXS-measurements yields a route towards an accelerated handling of this complex class of data. This initiative received ﬁnancial support through three internal RISE initiatives, i.e., “Machine Learning and Materials Design”, ”SODA - Software & Data Intensive Applications” and “MLOps by RISE.” This work beneﬁted from the use of the SasView application, originally developed under NSF award DMR-0520547. SasView contains code developed with funding from the European Union’s Horizon 2020 research and innovation programme under the SINE2020 project, grant agreement No 654000.