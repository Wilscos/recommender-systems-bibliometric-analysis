<title>Forecasting Daily COVID-19 Related Calls in VA Health Care System: Predictive Model  Development </title> <title>Abstract </title> Background:  COVID-19  has  become  a  challenge  worldwide  and  properly  planning  of  medical  resources  is  the  key  to  combating COVID-19. In the US Veteran Affairs Health Care System (VA), many of the enrollees are susceptible to COVID19. Predicting the COVID-19 to allocate medical resources promptly becomes a critical issue. When the VA enrollees have  COVID-19 symptoms, it is recommended that their first step should be to call the VA Call Center. For confirmed COVID-19  patients, the median time from the first symptom  to hospital admission was seven days. By predicting the number of COVID19 related calls, we could predict imminent surges in healthcare use and plan medical resources ahead.  Objective: The study aims to develop a method to forecast the daily number of COVID-19 related calls for each of the 110  VA medical centers.  Methods: In the proposed method, we pre-trained a model using a cluster of medical centers and fine-tuned it for individual  medical  centers.  At  the  cluster  level,  we  performed  feature  selection  to  select  significant  features  and  automatic  hyperparameter search to select optimal hyper-parameter value combinations for the model.  Results:  The  proposed  method  was  evaluated  for  110  VA  medical  centers  on  the  test  dataset.  The  prediction  error  was  2.13±0.23 in mean square error (MSE) when the configurations of the method (medical center clusters, selected features, and  optimal hyper-parameter value combinations) were determined on the first prediction day and reused in the rest of the days.  We constructed a baseline method where we built one model directly for each medical center. Compared to the baseline method,  the MSE mean of the proposed method decreased by 73.07% and the standard deviation decreased by 68.05%. The proposed  method  also  performed  well  when  the  amount  of  training  data  was  further  reduced.  In  a  more  computational  expensive  experiment where the configurations were determined daily, the proposed method’s MSE standard deviation further decreased  with MSE mean remained similar.  Conclusions: This study proposed an accurate method to forecast the daily number of COVID-19 related calls for VA medical  centers. The proposed method was able to overcome modeling challenges by grouping similar medical centers into clusters to  enlarge the dataset for training models, and using hyper-parameter search to automatically find optimal hyper-parameter value  combinations for models. With the proposed method, surges in health care can be predicted ahead. This allows health care  practitioners to better plan medical resources and combat COVID-19.  <title>Introduction </title> Background   In 2020, the world was hit by the highly contagious COVID-19 disease [1,2]. The spread of COVID-19 could cause severe  social and economic crises. Health care practitioners have been working hard to mitigate the crises. To combat COVID-19, it  is necessary to plan medical resources in real-time. During the pandemic, COVID-19 outbreaks escalated quickly and the ability  to plan  medical resources  becomes critical.  Hospitals  need  to  react  to  the  outbreaks  and  at  the  same  time  maintaining  the  existing patients well. In circumstances where physicians are affected by COVID-19, hospitals also need to take immediate  actions to monitor and reschedule them. Tools that can forecast COVID-19 could help hospitals plan medical resources and  handle such events [3–5].   In the US Department of Veterans Affairs Health Care System (VA), COVID-19 needs to be carefully monitored. The US  Department of Veterans Affairs Health Care System is the largest integrated health care system in the United States. It consists  of over 100 VA medical centers and serves millions of veterans [6,7]. Many veterans in the VA experienced comorbid chronic  conditions [6], increasing their vulnerability to COVID-19 and increasing the likelihood of hospitalization. A sudden outbreak  of COVID-19 can result in a significant surge of medical needs in the VA.   To help planning medical resources in the VA, it is useful to forecast the daily number of COVID-19 related phone calls in  VA. During the pandemic, health care use mainly starts with a phone call that describes the symptoms. For confirmed COVID19 patients, the median time from the first symptom to dyspnea has been estimated as five days, to hospital admission was  seven days, and to acute respiratory distress was eight days [31]. A large number of COVID-19 related calls is likely to indicate  a large number of confirmed COVID-19 patients in the future. Thus, by forecasting the daily number of COVID-19 related  calls, we could predict imminent surges in healthcare use in VA and plan medical resources promptly.  To generate accurate predictions for COVID-19, we employed deep learning models. In the field of COVID-19 forecasting,  deep learning models [3,8,9] were particularly effective because of their efficiency in handling multivariate features and long  time series. However, applying deep learning models to forecast COVID-19 for VA medical centers has two major challenges.  Despite being in the middle of the COVID-19 pandemic, the dataset available for model training is small and deep learning  models usually do not perform well with a small dataset. Additionally, even though deep learning models are effective, their  performance heavily depends on their hyper-parameter settings. To address them, we proposed a novel method. The method  was able to train robust models by enlarging the training dataset. The proposed method grouped similar medical centers into a  cluster, pre-trained a model from the cluster, and fine-tuned the pre-trained model to fit individual medical centers. The method  also alleviated the burden of hyper-parameter tuning by employing an automatic hyper-parameter search method. The proposed  method could help planning medical resources by providing high quality predictive models.  Objectives  To  forecast  the  daily  number  of  COVID-19  related  calls,  this  study  proposed  a  data-efficient  method.  This  study  demonstrated the proposed method on a VA data set and predicted the daily number of COVID-19 related calls for 110 medical  centers.  <title>Methods </title> Study design and ethics approval  VA’s institutional review boards approved this secondary analysis study on clinical data.  Patient cohort  In the processed dataset, 110 out of 140 medical centers were selected for modeling (selection criteria were described in the  data analysis  section).  The  patient cohort contained VA Health Care System enrollees who  called  the VA medical  centers  between January 1st, 2020 and July 27th, 2020.  Prediction target (a.k.a. the dependent variable)  In this study, the prediction target was the daily number of COVID-19 related calls to VA medical centers. On each day and  for each medical center, we measured the total number of calls occurred. Based on the call records, we also inferred the daily  number of calls related to COVID-19 symptoms for each medical center. According to data from Wuhan, the most common  symptoms  at  the  onset  of  illness  were  fever  (98.6%),  fatigue  (69.6%),  dry  cough  (59.4%),  myalgia  (34.8%),  and  dyspnea  (31.2%) [31].  To  find  calls  related  to  COVID-19,  we  searched  these  five  keywords  in  the  call  records  using  the  Veterans  Indexed Search for Analysis tool [30]. A call was considered to be COVID-19 related if a match was found.  Data set  The VA data warehouse supplied textual call data and we processed the data to find the daily number of COVID-19 related  calls for each medical enter. After data preparation, the data set contained 110 medical centers and the time period was between  January 1st, 2020 and July 27th, 2020.  The training and test set split  The last 30 days of the dataset were used for testing. The test set contained data between June 28th, 2020 and July 27th,  2020. When making forecasting for a prediction day, the training set available for medical center clustering, feature selection,  hyper-parameter search and model training consisted of all data prior to the prediction day.  Features (a.k.a. independent variables)  To enhance  the  model’s prediction performance,  we  also  considered  features other  than  the daily  number of  COVID-19  related calls. When identifying the daily number of COVID-19 related calls, we also recorded the daily number of calls in total  and added it to the feature set. We also derived the day of week and week of the year from the  call day and used them as  features.  In  the  COVID-19  Impact  Analysis  Platform  [11],  county-level  COVID-19  related  features  (e.g.  daily  confirmed  COVID-19 cases, daily COVID-19 test positive rate) were available in public and we added them to the feature set. The details  of these features were described in Table 1.  Table 1. The dataset features used in this study. Data analysis  Data preparation  It is common for a medical center to have missing data for the daily number of COVID-19 related calls. When the missingness  is significant, we excluded the medical center from the analysis. For each medical center, we calculated the proportion of days  missing a COVID-19 related calls record. We only kept a medical center when the missingness was lower than 5%.  Additionally, we observed that some medical centers had a small number of calls but the number fluctuated highly over time.  For example, one medical center received 6.76 COVID-19 related calls per day on average but the standard deviation of the  calls per day was 5.45. This indicates that this medical center has a highly fluctuating COVID-19 related call number and it is  difficult to predict its future. Moreover, the forecast results for such medical centers could be less meaningful because they  could be significantly affected by randomness. As a result, we excluded a medical center from the dataset when it fluctuated  significantly. To standardize across medical centers, we measured a medical center's fluctuation by computing the coefficient  of variation, which was the mean of the COVID-19 related calls on all days divided by the standard deviation of the COVID19  calls  on  all  days.  We  excluded  a  medical  center  when  its  coefficient  of  variation  was  less  than  1.  After  filtering  by  missingness and fluctuation, if a remaining medical center still had missing values, we imputed them using forward fill. This  filled a missing value by its nearest backtracked value. A 3-day backward moving average was taken subsequently to smoothen  the data and let the data pattern stand out more clearly. After preprocessing, we managed to keep 110 and exclude 30 medical  centers. In the processed data set, the mean and standard deviation of the COVID-19 related calls was 7.17±6.47. We see that  the  COVID-19  related  call  data  was  still  highly  flutuating  even  after  pre-processing  and  this  could  be  a  challenge  for  forecasting.  Model for forecasting the daily COVID-19 related calls  In the field of COVID-19 forecasting, deep learning models [3,8,9] were particularly effective because of their efficiency in  handling multivariate features and long time series. In this study, the specific deep learning model to consider was the Long  Short-Term Memory network (LSTM) model [27,28]. LSTM is a type of deep learning model that specializes in time series  forecasting and can efficiently handle multivariate features and long time series. LSTM has also been shown to perform well  in forecasting tasks related to COVID-19 [8,9]. This study employed a simple LSTM for the purpose of demonstration. The  simple LSTM contained a recurrent layer followed by a linear layer. The recurrent layer helped to extract significant features  from the time series and the linear layer helped to synthesize the extracted features into a forecast. However, applying deep  learning models to forecast COVID-19 for VA medical centers has two major challenges. Despite being in the middle of the  COVID-19 pandemic, the dataset available for model training is small and deep learning models usually do not perform well  with a small dataset. Additionally, even though deep learning models are effective in time series forecasting, their performance  heavily depends on their hyper-parameter settings. To figure out an optimal hyper-parameter value combination, manual tuning  is usually required by domain experts. In the VA system, there are more than 100 medical centers, each of which serving a  unique population of patients. It is almost infeasible to tune a model for each manually. To solve these problems, we proposed  a novel method.  Overview  Despite being in the middle of the COVID-19 pandemic, the dataset available for model training is small and deep learning  usually does not perform well with a small dataset. To solve this problem, the proposed method applied the idea of model pretraining and fine-tuning [12], a widely used strategy in deep learning for training robust models even with a small dataset. In  computer vision, people addressed the insufficient data problem by pre-training models on large datasets such as ImageNet  [13,14] and  then fine-tuning  them  on downstream tasks.  The  rationale behind this  idea is  that  the early  layers in  the  deep  learning models are able to learn universal rules appliable across tasks and the fine-tuning step can apply these rules locally to  downstream tasks. For example, when building phenotype-specific clinical text encoders, Dligach, Afshar and Miller first pretrained a universal text encoder using data of multiple phenotypes. They then created an encoder for each phenotype by refining  the  pre-trained  model  using  data  from  individual  phenotypes  [15]. Because  pre-trained  models  learned  general  feature  representation from a large dataset and used them for the downstream tasks, this model pre-training strategy can also be viewed  as a regularization for avoiding overfitting on small datasets.  When building models for forecasting the daily number of COVID-19 related calls, the proposed method applied the idea of  pre-training. The proposed method combined multiple medical centers into one dataset, used the dataset to pre-train a general  model and fine-tuned the model to fit individual medical centers.  Nevertheless, in order to utilize pre-training models well, the pre-trained model needs to share similar characteristics with  the downstream tasks. If not, some of the learned rules in the pre-train model would not be appliable to individual medical  centers.  This  created  redundancy  in  the  pre-trained  model  and  made  it  difficult  for  fine-tuning  the  pre-trained  model  to  downstream tasks. Because VA medical centers served different populations, the COVID-19 trend of some medical centers  might be more similar than other medical centers’. Our method took advantage of this to make model training more efficient.  Instead of creating one pre-trained model using datasets from all medical centers, the proposed method grouped medical centers  into clusters and created a pre-trained model for each. When fine-tuning models for individual medical centers, pre-trained  models of their corresponding clusters were used. In this way, the proposed method ensured that the rules learned by the pretrained models were useful for downstream medical centers to the greatest extent. The clustering technique also reduced the  burden of hyper-parameter tuning because we only need to tune one pre-trained model for a cluster of medical centers. In a  study, researchers grouped Chinese provinces into clusters and used the larger dataset to build a model. They directly used the  model to forecast the COVID-19 activity for provinces [16]. Differing from this study, our proposed method took a step further  by refining the cluster-level model to create tailored models for individual medical centers.  When training machine learning models, applying feature selection can enhance the learning algorithm by eliminating the  redundant information from a dataset [17]. However, applying feature selection on a small dataset is dangerous because feature  selection  methods  themselves  are  machine  learning  algorithms  and  suffer  from  the  curse  of  dimensionality;  in  training  a  machine learning algorithm, the amount of data required for getting a meaningful model often grows exponentially with the  number of the dimensions (features) of a dataset [18–20]. To ensure the robustness of feature selection, the proposed method  performed feature selection at the cluster-level dataset instead of the medical center-level.  Although deep learning models can usually produce excellent results, their performance is often sensitive to the selection of  its hyper-parameter values. Traditionally, expert knowledge was required for tuning and selecting the optimal hyper-parameter  value combinations. Recently, automated hyper-parameter search methods were developed for solving this problem. The newly  developed  methods  have  been  shown  to  consistently  outperform  grid  search,  random  search  and  sometimes  even  domain  experts [21–23]. In major tech companies like Google, hyper-parameter search has also often  been  the default solution for  building machine learning models [24]. This study involved building deep learning models repeatedly for each medical center  cluster and each day. To do so with time efficiency and accuracy, we employed hyper-parameter search to automatically find  optimal hyper-parameter value combinations.  The proposed method combined clustering, feature selection, hyper-parameter search, model pre-training and fine-tuning  into  a  single  workflow  to  predict  the  daily  number of  COVID-19  related  calls  for  110  VA  medical  centers.  A  flow  chart  illustrating the method’s execution order on a prediction day was shown in Figure 1. The proposed method first divided VA  medical  centers into clusters  and  performed  feature selection  at the  cluster-level to select significant features;  then,  hyperparameter search was performed to find optimal hyper-parameter value combinations and a pre-trained model was built for  each cluster; in the end, the pre-trained model was fine-tuned to create models for individual medical centers. The fine-tuned  models were used for making forecasts. In a typical scenario, the medical center clusters, selected features and hyper-parameter  value combinations could be determined once and reused in the subsequent days. Nevertheless, when computational resources  were permitted, they could also be determined daily, and this scenario was explored in a separate experiment. The cluster-level  models and fine-tuned models, however, were rebuilt daily as they required neglectable computational resources. The details  of the method’s components were described in the subsections.  Figure 1. The flow diagram when the proposed method was used to forecast the number of COVID-19 related calls for 110  medical centers on a prediction day.  Feature selection  After determining medical center clusters, the method applied feature selection at the cluster level. The method combined  medical  centers in the same  clusters  into one  dataset and performed feature selection on it.  The proposed method used  the  backward feature selection algorithm [26]. The algorithm started by building a linear regression model using all features and  computing the level of significance (p-value) for each feature in the linear regression model; it then dropped a feature if the  feature’s p-value was greater than 0.05 and the feature had the highest p-value. The algorithm continued building the linear  regression model with the remaining features and dropped a feature if the same condition was met. The algorithm terminated  when it could no longer find a feature that satisfied the drop condition.  Hyper-parameter search  Feature selection could remove redundancy in the feature set; however, to make the model use the selected features well, an  optimal hyper-parameter value combination should also be selected. In the proposed method, the selection of hyper-parameter  value combination was carried out by automatic hyper-parameter search. The proposed method used Bayesian Optimization  and Hyperband (BOHB), a robust tool for searching hyper-parameters and has been shown to be successful on a wide range of  machine learning tasks [29]. The hyper-parameter search space provided to BOHB contained three LSTM hyper-parameters.  Their names, value ranges and value distributions were listed in Table 2. For each medical center cluster, BOHB automatically  found an optimal hyper-parameter value combination for building a pre-trained model.  Table 2. Description of hyper-parameter, value range, and distribution. Model pre-training and fine-tuning  The method proceeded by pre-training a general model for each medical center cluster. Using the optimal hyper-parameter  value combinations retrieved from hyper-parameter search, as well as the selected features, the method created a pre-trained  LSTM model for each cluster.  Building on the pre-trained model, the method fine-tuned a tailored model for each medical center. In the pre-trained LSTM  model, there was one recurrent layer and a linear layer, each containing learned parameters. The proposed method performed  fine-tuning by training  the pre-trained  model  again  using  the  specific  medical  center’s  features. In  model pre-training,  the  parameters of both the recurrent layer and the linear layer were learnable; however, in model fine-tuning, the parameters of the  recurrent layer were fixed to be those of the pre-trained model and only parameters of the linear layer was learnable. Following  the pretrain-finetune paradigm [12,15], this ensured that the fine-tuned model  inherited  characteristics  from the pre-trained  model but also contained characteristics specific to the medical center it was tailored for.  Evaluation procedure  We evaluated the proposed method on 110 VA medical centers. Each medical center contained data between January 1st,  2020  and  July  27th,  2020.  We  used  the  last  30  days  of  the  data  for  testing.  To  simulate  typical  usage  of  the  method,  we  determined the medical center clusters, selected features, and optimal hyper-parameter value combinations once on the first  testing day and reused them throughout the rest of the days. This reduced the computational resources as the determination of  the  medical  center  clusters,  selected  features,  and  optimal  hyper-parameter  value  combinations  were  computationally  expensive.  On each testing day, we rebuilt a model for each medical center using the most recent data up to the testing day because the  model pre-training and fine-tuning were less computationally expensive. These models were used to forecast the number of  COVID-19 related calls for the testing day. The forecast results were compared with their true values.  During the evaluation, we used mean squared error (MSE) to measure the forecast error. To control randomness, we repeated  the whole evaluation process 5 times with different random seeds. The mean and standard error of the repetitions were reported.  Baseline method  Aside from the proposed method, a baseline method was also constructed for the purpose of comparison. In the baseline  method, hyper-parameter search was used to create one LSTM model for each medical center directly. The hyper-parameter  search was performed on the first testing day to determine the optimal hyper-parameter value combination for each medical  center and reused on the rest of the days. Other settings of the baseline method were the same as those of the proposed method.  Evaluating the method’s performance with limited training data  In the previous experiment, there were 179 days of data available for the proposed method to make forecasts on the first  testing day. In reality, we would like a forecasting model to work even when the amount of training data was small. This is  especially true at the earlier stage of a pandemic when there were little training data but forecasting was highly beneficial for  allocating medical resources.  To  further  test  the  proposed  method's  performance  under these  cases,  we simulated more  scenarios.  It is  possible that  a  pandemic had an abrupt outburst and only limited disease history was available. Thus, we tested the method's performance  with different amounts of training data. To ensure a fair comparison between the experiments, we also fixed the test dataset.  We performed the comparable experiments by truncating the earlier portion of the data.  In this session, the available training data no longer started from Jan 1st (179 days of training data) as before. Instead, we  performed experiments where the available data for the proposed method started from March 30th, April 29th, and May 29th.  These experiments were equivalent to having 90, 60, 30 days of training data for the proposed method to make forecasts on the  first testing day. The available data still ended on July 27th and we still used the last 30 days of the data for testing.  Evaluating the impact of the frequency of determining the configurations (medical center clusters, selected features, and  optimal hyper-parameter value combinations)  In a more rigorous environment (e.g. sufficient time and abundant energy consumption were permitted), the medical center  clusters, selected features, and optimal hyper-parameter value combinations could be updated every few days. We experimented  with the circumstances where the configurations were determined every 5, 3 and 1 day(s). We sought to analyze if updating  these configurations frequently had an impact on the forecast performance.   <title>Results </title> Comparison between the proposed method and the baseline method  The MSE of the forecast was 2.13±0.23 for the proposed method and 7.91±0.72 for the baseline method. Compared to the  baseline method, the MSE mean of the proposed method decreased by 73.07% (5.78/7.91) and the MSE standard deviation  decreased by 68.05% (0.49/0.72). Most of the time, the medical centers were clustered into 3 groups, despite the fact that the  maximumly allowable clusters were 10. In rare cases, the medical centers were clustered into 4 groups. This indicated that the  VA medical centers had distinctive characteristics in receiving COVID-19 related calls but they were not significantly different.  Evaluating the method’s performance with limited training data  The forecast MSE for 90, 60, 30 days of training data were 2.32±0.16, 3.05±0.29, and 4.66±1.09 respectively. The mean and  standard deviation of the MSE consistently increased with the reducing amount of training data. When the number of training  days reduced from 90 to 60 to 30, the MSE mean increased by 31.47% (0.73/2.32) and 52.79% (1.61/3.05); the MSE standard  deviation increased by 81.25% (0.13/0.16) and 275.86% (0.8/0.29). The performance decrease was the most significant when  the number of training days was reduced from 60 to 30.  Compared to the case where the full COVID-19 history (179 days) was available for the method, the MSE mean increased  by 8.92%  (0.19/2.13), 43.19%  (0.92/2.13)  and  118.78% (2.53/2.13); the  MSE standard increased by -30.43%  (-0.07/0.23),  26.09% (0.06/0.23), 373.91% (0.86/0.23). The performance was similar when the amount of training data was nearly halved to  90 days. The method performed worst when the amount of training data was 30 days. It is worth noticing that even when the  amount  of  training  data  was  30,  the  proposed  method  still  outperformed  the  baseline (MSE  7.91±0.72)  by  a  large  margin  (P<.001). This finding was particularly surprising considering that the baseline method had access to the full COVID-19 history  (179 days). We hypothesized that this was because the proposed method's medical center clustering and model pre-training  effectively remedied the problem of data insufficiency. This showed that the proposed method performed robustly even when  the amount of training data was limited.  Evaluating the impact of the frequency of determining the configurations  When the configurations (medical center clusters, selected features, and optimal hyper-parameter value combinations) of the  proposed method were determined every 5, 3 and 1 day(s), the MSE were 2.20±0.15, 2.18±0.15 and 2.19±0.06, respectively.  In an earlier experiment, the proposed method’s configurations were determined on the first day and reused throughout the rest  of the days. We considered this experiment as a circumstance where the configurations were determined every 30 days because  the test dataset contained 30 days. With this auxiliary experiment added, we concluded that when the frequency of determining  the configurations changed from 30 to 5, 3 and 1, the mean of the MSE remained similar, but the standard deviation of MSE  reduced by 34.78% (0.08/0.23), 34.78% (0.08/0.23) and 73.01% (0.17/0.23) respectively.  <title>Discussion </title> Principal results  In this study, we proposed a method to forecast the daily number of COVID-19 related calls for 110 medical centers; the  prediction error was 2.13±0.23 when the configurations of the method (medical center clusters, selected features, and optimal  hyper-parameter value combinations) were determined on the first prediction day and reused in the rest of the days. Compared  to the baseline method, the MSE mean of the proposed method decreased by 73.07% and the standard deviation decreased by  68.05%. The proposed method also performed well when the amount of training data was limited. In a more computational  expensive experiment where the configurations were determined daily, the proposed method’s MSE standard deviation further  decreased with MSE mean remained similar. The decrease of the MSE standard deviation reached its highest point when the  configurations were determined daily. This showed that updating the configurations frequently increased the stability of the  forecast.  Limitations  This study has 2 limitations that help guide future research.  1)    This study demonstrated the proposed method by predicting the number of COVID-19 related calls for VA medical centers.  In the future, the proposed method can also be applied to more prediction tasks, such as predicting the daily number of COVID19 vaccination walk-ins or appointments; the proposed method can also be applied to a broader scope such as predicting the  daily number of VA emergency department visits.  2)   In this study, the proposed method was evaluated using the VA health care system's dataset. In the future, it would be  helpful to test the proposed method on datasets from other health care systems.  Conclusions  This study developed a method to forecast the daily number of COVID-19 related calls for 110 VA medical centers. The  proposed method overcame modeling challenges by dividing similar medical centers into clusters to enlarge the dataset for  model pre-training. It also used hyper-parameter search to automatically find optimal hyper-parameter value combinations for  building models. Additionally, the method could also produce more stable predictions when its configurations were updated  daily. Besides helping health care practitioners better plan medical resources during the COVID-19 pandemic, the proposed  method is  also  generally applicable for scenarios where prediction tasks are needed to be performed for a large number of  entities but individual entities only have limited data.  Authors' contributions  WZ was the main contributor  to this  study.  RL pulled and  processed  the call  data  from VA.  PH  and GL participated in  proposing the research, gathering the data and editing the article.  Conflicts of interest  None declared. 