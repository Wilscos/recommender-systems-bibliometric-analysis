School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen Graduate School, Shenzhen, China Abstract—Nowadays, E-commerce is increasingly integrated into our daily lives. Meanwhile, shopping process has also changed incrementally from one behavior (purchase) to multiple behaviors (such as view, carting and purchase). Therefore, utilizing interaction data of auxiliary behavior data draws a lot of attention in the E-commerce recommender systems. However, all existing models ignore two kinds of intrinsic heterogeneity which are helpful to capture the difference of user preferences and the difference of item attributes. First (intra-heterogeneity), each user has multiple social identities with otherness, and these different identities can result in quite different interaction preferences. Second (inter-heterogeneity), each item can transfer an item-speciﬁc percentage of score from low-level behavior to high-level behavior for the gradual relationship among multiple behaviors. Thus, the lack of consideration of these heterogeneities damages recommendation rank performance. To model the above heterogeneities, we propose a novel method named intrA- and inteR-heteroGeneity recOmmendation model (ARGO). Speciﬁcally, we embed each user into multiple vectors representing the user’s identities, and the maximum of identity scores indicates the interaction preference. Besides, we regard the item-speciﬁc transition percentage as trainable transition probability between different behaviors. Extensive experiments on two real-world datasets show that ARGO performs much better than the stateof-the-art in multi-behavior scenarios. Index Terms—Recommender Systems, Multi-behavior Recommendation, Collaborative Filtering Recently, recommender systems have been widely utilized in online information systems [1]. Traditional recommender systems only consider the user-item interaction data of one behavior type (i.e., purchase on E-commerce scenarios). Collaborative ﬁltering [2], [3] is the most popular paradigm for building a recommender system, which learns user interest and estimates preference from the collected user behavioral data. However, as the amount and variety of E-commerce data increase, utilizing interaction data of other auxiliary behavior data (such as the click, view, carting and so on) draws much attention. Several studies have utilized these multiple behaviors to provide useful signals of user preferences, which helps to build recommender systems with better performances [4]–[7]. Deep learning has achieved much success in the ﬁeld of computer vision and natural language processing [8]–[10]. There are also some attempts on deep learning in the ﬁeld of recommender systems [11]–[16]. Generalized matrix factorization (GMF) [12] replaces the inner product with embedding layer and fully connected prediction layer, which applies the representation learning on the collaborative ﬁltering with single behavior data. For multi-behavior recommendation, Efﬁcient Heterogeneous Collaborative Filtering (EHCF) [7] is the existing state-of-the-art method. It has shown the superiority than negative sampling (NS) methods, including MC-BPR [5] and Neural Multi-Task Recommendation (NMTR) [6]. However, in previous works, there is a lack of in-depth consideration of heterogeneity in E-commerce, which is shown in Figure 1. When faced with the demands of daily work, study and life, each user has multiple social identities. The heterogeneity between different identities reﬂects the difference of interaction preference of items. Besides, there is a cascading relationship among multiple behaviors in E-commerce scenario (e.g., a user must view an item before purchasing it), and the heterogeneity of items determines that each item transfers a speciﬁc percentage of score from low-level behavior to high-level behavior. Therefore, from the view of latent space, the previous works which neglect the above two kinds of heterogeneity have two limitations. First, in general, item embedding vectors largely diverge in the latent space, and the user embedding vector should be close to the separated vectors of all positive items, which seems to be unreasonable and thus restricts the performance of deep learning with strong representation ability. Second, the modeling of transferring of previous works merely changes the prediction space from auxiliary behaviors to target behavior for all items, and does not capture item discrepancies between different behaviors, which drops the beneﬁts from the auxiliary behavior data. To address the above mentioned limitations, we propose a novel model named intrA- and inteR-heteroGeneity recOmmendation model (ARGO) for multi-behavior recommendation task. To cope with the low representation ability of the existing models, we model the intra-heterogeneity by embedding each user into multiple vectors which represent the user’s identities, and the vector corresponding to the maximum of identity scores indicates the identity that the interaction preference belongs to. In order to capture the inter-heterogeneity, we consider an ordinal relation among different types of behavior, and relate the prediction of each behavior through an item-speciﬁc cascaded manner. To be speciﬁc, the prediction of a (k + 1)-th behavior is obtained from the prediction of the k-th behavior as well as learnable item-speciﬁc transition probability. Through these designs, our model ARGO effectively captures the user preferences and incorporates the behavior semantics. To summarize, the main contributions of this work are as follows: and straightforward neural collaborative ﬁltering model by embedding each user into multiple vectors, which considers the idiosyncrasies of each user. model with trainable transition probabilities, which correlates the prediction of each behavior in an item-speciﬁc probabilistic way to capture the ordinal relation among multiple behaviors. datasets show that ARGO outperforms the state-of-theart models in multi-behavior scenarios by a large margin. Since deep neural networks perform well at representation learning, deep learning methods have been widely explored and have shown promising results in various areas such as computer vision [8]. Note that in vanilla matrix factorization, the mapping between the original representation space and the latent space is assumed to be linear, which can not be always guaranteed. To better learn the complex mapping between these two spaces, deep matrix factorization [17] utilizes a two pathway neural network architecture to replace the linear embedding operation used in vanilla matrix factorization. NeuMF [12] replaces the inner product with a neural architecture that can learn an arbitrary function from data, containing the fusion of GMF and Multi-Layer Perceptron (MLP). DeepCF [14] combines the strengths of representation learning based CF and matching function learning based CF to improve the performance. ConvNCF [18] uses the outer product instead of the dot product to model user-item interaction patterns and then CNNs are applied over the result of the outer product and could capture the high-order correlations among embedding dimensions. Multi-behavior based recommendation aims to leverage the behavior data of other types to improve the recommendation performance on the target behavior [5]. The well-known early model Collective Matrix Factorization model (CMF) [19] simultaneously factorizes multiple user-item interactions with sharing item-side embeddings across matrices and extends to leverage multiple user behaviors for recommender systems [4]. NMTR [6] accounts for the cascading relationship among different types of behaviors and perform a joint optimization based on the multi-task learning framework, where the optimization on a behavior is treated as a task. EHCF [7] models ﬁne-grained user-item relations as well as efﬁciently learn model parameters from positive-only data to further improve the performance. In this section, we ﬁrst formally deﬁne the problem and then feature our ARGO model with two special designs shown in Figure 2: expressed by M embedding vectors corresponding to M identities, and the maximum of M likelihood is considered as the output for the ﬁrst behavior. havior will transfer a certain percentage of score to highlevel behavior for each item. We correlate the predictions of the ordinal behaviors through chain prediction, modeling by probability model with trainable transition probabilities. Suppose the dataset contains users U and items V , R, R, . . . , Rdenote the user-item interaction matrices of size |U | × |V | for all K types of behaviors, in which Rwith each entry having value 1 or 0 comes from users’ implicit feedbacks of the k-th behavior: R=1, if user u has observed interaction with item v0, otherwise. Generally, the K-th behavior is set to be the target behavior to be optimized in the multi-behavior recommendation task. In the E-commerce dataset, a typical target behavior is the purchase behavior, and other behaviors include viewing, clicking and adding to the cart. The task is estimating the likelihood ˆR= f(u, v|Θ) that user u will interact with item v under the target behavior. The items (unobserved under the target behavior) are ranked in the descending order of the likelihood, which provides a Top-N item recommendation list for each user. We share the embedding layer of users and items for the modeling of all behavior types. Different from the former methods, each user corresponds to M different d-dimensional embedding vectors related to different identities in our model, resulting in M user embedding matrices {P}. Formally, where Xand Ydenote the one-hot feature vectors for user u and item v, {P∈ R}and Q ∈ Rare the user embedding matrices and the item embedding matrix, respectively. Note that embeddings in matrix {P}and Q are served as the initialization feature of users’ identities and items, which can be seen as the input feature for each user’s identity and item in our framework. The interaction layer is right behind the embedding layer, which describes the interaction between the user embedding and item embedding. Note that for the user u, each p∈ R represents the speciﬁc identity embedding from the m-th view. The task is to ﬁnd the proper user-embedding from different identities for the item v. We ﬁrst normalize user identity embedding and item embedding: Then for each user-item instance (u, v) of the lowest-level behavior, the likelihood that user u has the m-th interest on item v is estimated by ˆR= ReLU(h(ˆp ˆq)) = ReLU(Xhˆpˆq) Pooling element-wise product in which  denotes the element-wise product of vectors, h ∈ Ris prediction vector. Finally, the likelihood that user u has the interest on item v depends on the maximum value likelihood among the M identities. In formulation, Generally, for a normal purchase behavior of a user, he/she ﬁrst needs to see a certain product, and then adds it to the shopping cart. Therefore, high-level behaviors (e.g., buy) usually depend on low-level behaviors (e.g., view). To take advantage of this regular pattern, we introduce a transition probability model to model it. Speciﬁcally, for any item v, random variable Xis described by the interaction between item v and user u of the k-th behavior. Denote p= P (X= 1|X= 1) and q= P (X= 1|X= 0). For any k < K, pand qcan be simply summarized from the observed data by Note that there is a certain ordinal relation among behavior types in E-commerce, such as a user must view a product (i.e., click the product page) or add a product to cart before he/she purchases it. Therefore, the phenomenon that R= 0 is along with R= 0 always holds for real-world datasets, and we just set q= 0 for simplicity. From the interpretation of ranking, the probability P(X= 1) can be estimated by the likelihoodˆRas. Therefore, according to the law of total probability, we formulate P (X= 1) as It’s worth noting that the transition probability obtained from the data directly may not be accurate due to the unobserved interaction. For all items, we consider pas a learnable parameter tand denote T= (t, · · · , t). As a result, the basic interaction prediction is utilized for the lowest-level behavior, and the likelihood of the high-level behavior is estimated level by level: whereˆR= (ˆR, · · · ,ˆR). With the strong representation of neural networks, the probabilistic transfer vector is reﬁned. Our prediction takes consideration of the effect of behavior-item interaction for each behavior. Note that our model is helpful for predicting the preference of inactive users that have little data on the target behavior because some behaviors (e.g., low-level) are easier to be collected and have a larger volume than the target behavior. Analysis of sparse data will show the effectiveness in experiments. Due to the large space of items, the observed interactions are limited, and unobserved interactions are of a large scale in implicit data. To learn model parameters, a weighted regression with squared loss were introduced [3]: where V, Vare positive and negative (missing) items for user u, wdenotes the weight of entry R. There have been many studies on how to assign proper weights for missing data. Here we adapt a uniform weight w for missing entry [20]: Besides, for m = 1, · · · , M, Prepresents the embedding of the m-th identity of users. To increase the representation ability of our model, we propose a divergence loss function to penalize the solution when Pis almost identical for different m. As a consequence, we expect the cosine distance of each identity embedding vector is large enough (i.e., cos(p, p) ≤ 0). We impose more penalty on the vector pair with closer distance by taking the inﬂation operation on the cosine similarity. L=2|U|M(M − 1)(max(0, cos(p, p))) in which cos(·) means cosine similarity (i.e., the inner product of the two normalized vectors) and the term 2/|U|M(M − 1) is added to calculate the mean. Finally, following the paradigm of Multi-Task Learning (MTL) that performs joint training on the models of different but correlated tasks, we obtain the loss function that is minimized as where λis included to control the inﬂuence of the k-th type of behaviors on the joint training. This is a hyper-parameter to be speciﬁed for different datasets, since the importance of a behavior type may vary for problems of different domains andP scales. We additionally enforce thatλ= 1 to facilitate the tuning of these hyper-parameters. Now, we conduct experiments on two real-world Ecommerce datasets to evaluate our model ARGO, and answer the following four research questions: line models that aim to learn from multi-behavior data? as well as different types of auxiliary behaviors? problem, i.e., few records on the target behavior? ﬁnal performance of ARGO? To evaluate the performance of ARGO, we experiment on two real-world E-commerce datasets: Beibei and Taobao. The statistics of datasets are summarized in Table I. BeiBei [6] This is the dataset obtained from Beibei, the largest infant product E-commerce platform in China. There are 21716 users and 7977 items with three types of behaviors, including purchase, carting, and view collected in this dataset. Taobao [21] This is the dataset obtained from Taobao, the largest E-commerce platform in China. There are 48749 users and 39493 items with three same types of behaviors, comparing to Beibei. To demonstrate the effectiveness of ARGO, we compare it with several state-of-the-art methods. The baselines are classiﬁed into two categories: one-behavior models that only utilize target behavior records, and multi-behavior models that take all kinds of behavior into consideration. One-Behavior Models: BPR [22], a widely used pairwise learning method for item recommendation, which optimizes pairwise loss with the assumption that observed interaction should have higher score than unobserved ones. ExpoMF [23], a whole-data based MF method which treats all missing interactions as negative and Multi-Behavior weighs them by item popularity. NCF [12], a deep learning method which combines MF with MLP for item ranking. Multi-Behavior Models: CMF [4], it decomposes the data matrices of multiple behavior types simultaneously. MC-BPR [5], it adapts the negative sampling rule in BPR and expands BPR for heterogeneous data. NMTR [6], it combines the advances of NCF modeling and utilizes a joint optimization based on the multi-task learning framework. EHCF [7], it models ﬁne-grained user-item relations and efﬁciently learn parameters from positive-only data without negative sampling. Our model is implemented in Pytorch V1.4 and trained on a single NVIDIA GeForce GTX TITAN X GPU. We search for the optimal parameters on validation data and evaluate the model on test data. The embedding size d is ﬁxed to 64 for all models. we use mini-batch Adagrad [24] as the optimizer, having train batch size ﬁxed to 256, and set the learning rate to 0.05. The dropout ratio ρ is set to 0.5 to prevent overﬁtting. Uniform negative entry weight (0.1 for Beibei and 0.01 for Taobao) and the MTL coefﬁcients λ(λ= 1/6, λ= 4/6, λ= 1/6) are all selected as the same with EHCF [7] for fairness. For the baseline, we set the negative sampling ratio to 4 for sampling-based methods, an empirical value showing good performance. We apply the widely used leave-one-out technique [6], [7] and two widely used metrics, Hit Ratio (HR) [25] and Normalized Discounted Cumulative Gain (NDCG) [26] are adopted to evaluate the performance of each model. As a recall-based metric, HR measures whether the testing item is in the Top-N list, while NDCG is sensitive to position, which assigns a higher score to hits at a higher position. It’s noticed that for a user, our evaluation protocol ranks all unobserved Taobao items in the training set and thus the obtained results are more persuasive than ranking a random sampling subset. E. Overall Performance Comparison (RQ1) The results of the comparison of different methods on both two datasets are shown in Table II. We investigate the Top−N performance with N setting to [10, 50, 100, 200]. From the results, the following observations can be made: outperform methods that only make use of purchase behavior, which shows user auxiliary feedbacks improve the models’ performances. The best multi-behavior model among the baselines (EHCF) can outperform the best onebehavior model (NCF) on Beibei by 83.9% on HR@100 and 135.3% on NDCG@100, while 83.4% and 115.0% on Taobao, which demonstrates the beneﬁts of adding multi-behavior data into the model. (ARGO, EHCF) generally perform better than other NS methods (NMTR, MC-BPR), which demonstrates that the sampling method leads to a biased result. For example, NMTR fails to capture enough collaborative ﬁltering signals since it adopts the BPR loss function that limits the performance of the model. mance compared to the best baseline EHCF under all metrics. To be speciﬁc, the average improvement of our model to EHCF is 5.90% and 7.97% for HR and NDCG on Beibei and 7.52% and 8.45% on Taobao, which justiﬁes the superiority of our model. EHCF uses wholedata based learning strategies but ignores both interheterogeneity and intra-heterogeneity while other methods use biased sampling strategies which greatly limit the performances. Our model can fully capture the heterogeneities for target interaction prediction, which helps our Model model outperforms state-of-the-art multi-behavior recommendation models. Case Study. To further study the impact of identity matching design in ARGO, we select the user (ID 20137) from Beibei, which has interaction with the items ”2449, 3484, 3994, 4394, 4666, 5158, 5275” in the training set, and the item ”5403” in the test set. From Figure 3, we ﬁnd that the different identities have relatively large cosine distance, and only one identity embedding has a positive likelihood for each positive interaction. This shows that our identity matching design really captures multiple identities for each user. F. Ablation Study (RQ2) To understand the effectiveness of two novel designs and multiple auxiliary behaviors, we conduct experiments with several variants of ARGO. Particularly, we introduce the following model variants: ARGO-CP. Here we replace the chain prediction with three different prediction layers (h), which are randomly initialized and independent (see [7]). ARGOIM. Here we only use one embedding vector to represent each user (i.e., M = 1). ARGO-C. Here we remove the cart behavior information and use view data as the only auxiliary behavior data. ARGO-V. Here we remove the view behavior information and use cart data as the only auxiliary behavior data. ARGO-CV. Here we remove both the view and the cart behavior information and the model only contains the purchase behavior. The results on Taobao are recorded in Table III and the results on Beibei are similar. We summary the following ﬁndings: ﬁnd that the utilization of chain prediction can improve HR consistently. This is reasonable because the chain prediction arranges more positive items in the top-200 list, beneﬁting from the retention of the likelihood of positive interactions on previous behaviors. consistent with our above analysis that multiple user embeddings can ﬁt better than single user embedding in the latent space. tently outperforms ARGO-V and ARGO-C under all settings, which validates that our model improves purchase forecasting through integrating multi-behavior relations with the MTL framework. ior type, ARGO-C shows better performance on target prediction in terms of HR@100, which demonstrates the higher importance and effectiveness of utilizing viewing feedbacks for purchasing modeling. G. Effectiveness Analysis on Sparse Data (RQ3) Data sparsity is a big challenge for recommender systems based on implicit feedbacks [27], and multi-behavior recommendation is a typical solution to it. Thus, we study how our proposed ARGO alleviates the problem for those users having few records of the target behavior. Speciﬁcally, we collect users with 5∼8 purchase records, and there are 6056 and 11846 users on Beibei and Taobao, respectively. Compared to the best baseline EHCF, we conduct experiments of our proposed techniques. The results are shown in Table IV. From Table IV, we can ﬁnd HR of ARGO outperforms EHCF by a large margin consistently. Since ARGO models heterogeneous behavior relations in a reasonable way, it can achieve good performance for users with sparse interactions. H. Parameter Sensitivity (RQ4) To understand how hyper-parameters inﬂuence the performance of our model, we test the impact of the number ModelsTaobao of identities M , which is related to the representation and generalization ability. We tune M from 1 to 7. The results of HR@100 and running time are plotted in Figure 4. From the ﬁgure, we ﬁnd that larger M leads to a better performance according to the fact that a large M implies an overparameterized model which helps the training process with SGD [28]. However, the training time increases linearly with M and the increasement of HR@100 is scant when M is larger than 4. Therefore, we set M to 4 as default from the trade-off between performance and computational efﬁciency. In this paper, we propose ARGO for recommendation with heterogeneous user feedback. ARGO has two key characteristics: First, it represents each user with multiple vectors encoding the user identities. Second, the prediction of each behavior is correlated by a learnable chain prediction transition probability model. Extensive experiments on two real-world datasets show that ARGO outperforms the state-of-the-art recommendation models. This work further explores the more complex relationship of different behaviors and opens up a new avenue of research by introducing a probabilistic model for the multi-behavior recommendation. Future work includes exploring our model in complex situations such as cold start problem and knowledge-based recommendation problem. We will also try to extend our method to make it applicable in other recommendation tasks such as sequence-based recommendation. This work was partially supported by the National Key Research and Development Program of China under grant 2018AAA0100205.