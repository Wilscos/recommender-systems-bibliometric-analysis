Learning accurate users and news representations is critical for news recommendation. Despite great progress, existing methods seem to have a strong bias towards content representation or just capture collaborative ﬁltering relationship. However, these approaches may suffer from the data sparsity problem (usernews interactive behavior sparsity problem) or maybe affected more by news (or user) with high popularity. In this paper, to address such limitations, we propose content ﬁltering enriched GNN framework for news recommendation, ConFRec in short. It is compatible with existing GNN-based approaches for news recommendation and can capture both collaborative and content ﬁltering information simultaneously. Comprehensive experiments are conducted to demonstrate the effectiveness of ConFRec over the state-of-the-art baseline models for news recommendation on real-world datasets for news recommendation. Recently, news recommendation platforms have sprung up like mushrooms and are growing rapidly, such as Google News, Bing News and Toutiao.com. Massive news information is produced continuously and it is impractical for users to read all these news due to the time limit. Therefore, in online news platforms, it is critical to tackle the information overload and the news recommendation has been playing an increasingly important role to help users ﬁnd their interested contents (Liu et al., 2010). Almost existing news recommendation methods try to construct personalized news ranking by learning accurate and informative user and news representations (noted as representation-based methods). They usually learn news representation from news contents and then construct user representation based on user’s history behavior, e.g, aggregating information from the user’s clicked news. For Figure 1: Collaborative ﬁltering and content ﬁltering. instance, Wang et al. proposed DKN (Wang et al., 2018) to learn news representation from news contents via multi-channel CNN and user’s representation by aggregating her click news with different weights. Furthermore, DAN (Zhu et al., 2019) and NPA (Wu et al., 2019a) utilized an attention network to identify the important clicked news for generating better user representations. Compared with traditional collaborative ﬁltering methods (Koren et al., 2009), which suffer from data sparsity, these methods have been improved by building semantic news representations directly from news contents. However, when the news contents are short and the user historical behavior is sparse, it is difﬁcult to learn reasonable news and user representations (Ge et al., 2020). In addition to these representation-based methods, several graph neural network (GNN) based approaches, such as GNUD (Hu et al., 2020) and GERL (Ge et al., 2020), leveraged user-news interactions to capture high-order relatedness between users and news. However, if we only consider the collaborative ﬁltering relationship, the data sparsity problem still exists. As shown in Figure 1,uhas two 1-hop neighborsnandn. When we construct the representation foruandjust use collaborative ﬁltering relationship, we could taken’s neighborsu,uanduas the 2-hop neighbors of uand ﬁnd nothing fromnsince there is not other neighbors exceptu. Then the representation ofu is built by aggregating the representations of 1-hop and 2-hop neighbors. As a result, the representation ofuobtains more inﬂuence from the popular news nand the impact of nis weakened. To overcome the limitations of representationbased and GNN-based approaches, we propose the content ﬁltering enriched GNN framework for news recommendation (ConFRec). In ConFRec, both collaborative and content ﬁltering information are captured: (1) We use traditional collaborative ﬁltering approaches, such as GNN-based methods, to learn the representations based on the user-news interactions; (2) We proposeNewsExpanding (NE) module as Generator andTargetAwareFiltering &Aggregation (TAFA) module as Discriminator to learn the content ﬁltering representations. Specifically, we utilize the NE to expand neighbors for news and their neighbors generated based on the high-order content-based similarity, and then we leverage the TAFA to identify the importance of the expanded neighbors in different content-views. The plain intuition is that users prefer the news with similar contents. Following the example in Figure 1, we give another example in Figure 2 to introduce the process of building the content ﬁltering representations for u. The useru’s behavior history includesnand n, we can expandu’s neighbor asn, n, n, n through Generator (NE module). After getting the embedding of news through NIE module, we discriminate the importance of these news under different content views through the TAFA module. Finally, the content collaborative representation for useruis aggregated from the representations of news in the expanded list. As the procedure is similar, we omit the construction process of content ﬁltering representations for news due to the space limit. Based on NE and TAFA modules, both user’s and news’ data sparsity problems can be alleviated. The contributions are summarized as follows: •In this paper, we propose ConFRec framework to learn the representations of user and news effectively. The proposed framework improves the recommendation performance by fully considering both collaborative and content ﬁltering information, and is compatible with existing GNN-based approaches for news recommendation. Figure 2: An example of content ﬁltering representation component: Generator and Discriminator. data sparsity problem. Speciﬁcally, the NE module is the generator to generate neighbors for news and the TAFA module is the discriminator to identify important news. •We conduct comprehensive experiments and compare the state-of-the-art baseline models for news recommendation to demonstrate the effectiveness of the proposed method. Moreover, to clarify the contribution from different modules, the ablation study and case study are presented. In this section, we will review relevant research on news recommendation tasks. With the explosion of a gigantic number news articles, to make better personalized news recommendation based on the user’s interests has been widely explored in recent years, and has wide applications (Zheng et al., 2018; Wu et al., 2019b). Early works (Liu et al., 2010; Son et al., 2013) used the manually designed features to obtain meaningful news and user representations. However, The above methods heavily rely on expert knowledge. To capture more informative knowledge with the end-to-end manner, the deep learning based representation approaches (Wang et al., 2018; Wu et al., 2019a,c) are proposed. Wang et al. (Wang et al., 2018) proposed DKN to leverage the knowledge modeled by the knowledge-graph. Wu et al. (Wu et al., 2019a) proposed a news recommendation model with personalized attention mechanism to select important words and news articles based on user preferences to learn more informative news and user representations. Wu et al. (Wu et al., 2019c) proposed a neural news recommendation method which uses multi-head self-attention to learn news representations from the words in news and learn user representations from user’s click history. Recently, graph neural network (GNN) is widely used in recommendation (Velickovic et al., 2017; He et al., 2020; Ying et al., 2018; Sun et al., 2020) because of its powerful representation ability for node features and graph structure. Compared to traditional matrix factorization based approaches, such as MF (Koren et al., 2009), GNNbased approach is able to capture high-order collaborative information. Compared to traditional graph based approaches, such as label propagation (Bengio et al., 2006), GNN-based approach can capture non-linear features. Thus, several GNN-based approaches (Hu et al., 2020; Ge et al., 2020) for news recommendation are proposed as the representation-based approaches. For instance, Hu et al. (Hu et al., 2020) proposed GNUD which uses a GNN to capture high-order collaborative information. However, almost existing news recommendation methods, either representation-based or GNNbased, heavily rely on the collaborative ﬁltering signal, namely the user’s behavior history and usernews interactions respectively. But these methods may achieve sub-optimal performance when the user’s behavior history is short and the interactions are sparse. Assuming the data setDfor training consists of |D|user-news historical interactions[u, n, y], whereuindicates the user id and the related user information,nmeans the target news id and its features. Andy∈ {0, 1}is the associated label indicating user click behavior (y= 1means the useruclicked the target newsn, andy= 0otherwise). To simplify the explanation, we notey asy. The task of news recommendation is to build a prediction modelˆy = M odel(u, n)to estimate the probability of a useruclicking a speciﬁc news According to GNUD (Hu et al., 2020), in this paper, we consider the titleTand proﬁleP(including entitiesEand their corresponding entity typesCfrom the news content) as features for a news articlen. Each news titleT = {t, t, ..., t} is a sequence consists of m words. And each news proﬁlePincludes a sequence of entities E = {ω, ω, ..., ω}and a sequence of entity typesC = {c, c, ..., c}, where p is the number of entities (entity types). We denote the embedding of title, entity, entity type asT = [t, t, ..., t] ∈ R,E = [w, w, ..., w] ∈ R, and C = [c, c, ..., c] ∈ R, respectively. Following (Zhu et al., 2019), we deﬁne the proﬁle embeddingP = [[c; w], [c; w], ..., [c; w]]∈ R. Moreover, we deﬁne the embedding of user id ase∈ R. Note that all above mentioned embeddings are randomly initialized. For the purpose of generating informative representations for user and news, we build user and news representations from collaborative ﬁltering and content ﬁltering. As shown in Figure 3, the proposed ConFRec considers both collaborative and content ﬁltering representations. Speciﬁcally, the model is divided into two parts: the part one is based on traditional approaches (the GNN module in Figure 3), such as GAT and GNUD, and is used to capture the collaborative ﬁltering information; the part two consists of Generator and Discriminator, and is utilized to model content ﬁltering information. The Generator is a News Expanding (NE) module and the Discriminator is Target Aware Filtering & Aggregation (TAFA) module. In this section, we will give a brief description about the News Information Extractor (NIE) and collaborative ﬁltering representation module since they are not the main contributions in this paper, and we will give a detailed introduction of ConFRec. News Information Extractor (NIE) is utilized to obtain a news representationefrom the raw news content, which consists of news titleT, proﬁleP. The raw content based representation would be taken as initial input embedding in the proposed framework. Following (Zhu et al., 2019; Hu et al., 2020), we also use two Parallel Convolutional Neural Network (PCNN) to encode news titleTand proﬁlePinto the title-view and proﬁle-view representations e, erespectively. Finally, we concate- Figure 3: Illustration of the ConFRec framework. The "GNN" module means Graph-based neural network. nateeande, and get the original news representation ethrough a fully connected layer f: 4.2 Collaborative Filtering Representation Based on the original news representationefrom raw content features, we can use graph based approaches, such as GNUD and GAT, to capture collaborative ﬁltering information from user-news interactions and high-order relationships. Due to the space constraints, we do not elaborate on this module. The collaborative ﬁltering representations of user and news are noted as hand h. 4.3 Content Filtering Representation As the example shown in Figure 2, the content ﬁltering component consists of two major modules: (1) Generator: leveraging content ﬁltering to expand the user’s history behavior and connect the news representations through the high-order similarity of news content; (2) Discriminator: utilizing the features under different views of target news to identify the importance of news in user’s behavior. In this section, we will elaborate these modules in detail. 4.3.1 Generator: News Expanding module In NE module, we ﬁrst construct a news-news graph based on the content similarity between news, and then search top-k similar news from the news-news graph and ﬁnally obtain the k-nearest neighbor (kNN) graphG= (A, S), whereAis the adjacency matrix,Sis the similarity matrix, which is calculated by cosine similarity: wherex, xare one-hot vectors of content fori andjnews. Then, based on the similarity, we choose the top-k news pairs as the neighbors for each news and get the adjacency matrix A. Further more, to explore the high-order similarity, based onG, we follow (Perozzi et al., 2014) and use Random-Walk to get theG= (A, S). For each news, taking itself as the starting node, we repeat the walkntimes, set the restart probability and the depth of each walker aspandd, respectively. Then we get the Random-Walk similarity matrix between n items and select top-k similar node pairs for each news as its neighbors, and the adjacency matrixAand similarity matrixSare obtained consequently. Different fromGwhich only relies on the local similarity,Gcontains the global similarity which links more generalized news neighbors for each news. In our framework, based onG, we expand the target news and the user behavior sequence as NandN, respectively. ForN, we just select the top-k similar news for target news. ForN, we ﬁrst search top-k similar items for each news of user clicked history, then de-duplicate all of them as a set, ﬁnally select the top-k similar news as the expanded neighbor set. 4.3.2 Discriminator: Target Aware Filtering & Aggregation module Equipping with NE module can expand user behavior sequence from content-view and boost the performance. However, utilizing NE module is likely to bring noise. Inspired by (Qin et al., 2020), we propose the Target Aware Filtering (TAF) & Aggregation module (TAFA in short) to identify importance of neighbor news. Target Aware Filtering:As introduced in Section 3, there are two kinds of contents, title and proﬁle. To identify the importance of different news under different views before aggregation, we adopt the multi-head attention mechanism to calculate the attention scores of the neighbors and the target news in different views. For a news listN, we use the embeddingeandeof target newsnto calculate the attention scores of the title and proﬁle views, respectively. For instance, thejhead’s attention score ofinews of the neighbors on the target news n in title view (t) is: where theQandVare the parameters inj head of title view,[; ]means concatenation,τindicates the temperature parameter for softmax. Then, based on the attention score, theinews embeddingeis transformed by the title view attention score as: The embedding of newsiis transformed by the proﬁle view ash. Therefore, for the expanded news set of target newsN, we obtain two embedding lists in title and proﬁle views as: For the expanded news set of user clicked history N, we obtain two lists Hand H. Aggregation:We aggregate the transformed embedding list into the content ﬁltering representations of user and news by the other two multi-head attention networks, respectively. Due to the space constraints, we only give the brief description of generating content ﬁltering representations of news in title view: whereβis the attention importance ofinews’ embedding in the listHon the center node embeddingeinjattention head. We can get the ﬁnal aggregation representations in title view:h= [h; h; ...; h]. Note thatβ is calculated by the attention mechanism according to Equation (3), (4) with differentQandV. Similar to the title view, we can obtain content ﬁltering representations of news in proﬁle view ash. For user node, we can get its content ﬁltering representations in title and proﬁle views ashand h, respectively. Based on the graph-based approach and the proposed ConFRec module, we obtain the collaborative ﬁltering representationshandhfor user and news, and the content ﬁltering representations news, respectively. Then we concatenate these embeddings for user and news, and transform it to the ﬁnal user and news representations by a multi-layer perception (MLP) respectively: Same as (Hu et al., 2020), we use the simple inner product to compute the click probability score, which is computed as:ˆy= z· z. We deﬁne the following log-likelihood loss function for training sample (u, n) with the ground truth y: whereˆy= σ(s). Then we apply the l2 regularization to avoid overﬁtting and the overall training loss can be rewritten as: whereλis the regularization coefﬁcient,Θindicates the embedding parameters of user, item contents (title, proﬁle) and PCNN parameters. 5.1 Datasets and Experimental Setting 5.1.1 Datasets Following DAN and GNUD, we conduct experiments on the real-world online news dataset Adressa (Gulla et al., 2017)to evaluate the proposed framework. We use three datasets named Adressa-1week, Adressa-2week and Adressa10week, which are extract 1 week, 2 weeks and 10 weeks logs in chronological order from the dataset, respectively. Following GNUD (Hu et al., 2020; Zhu et al., 2019), we select user-id, news-id, timestamp, the title and proﬁle of news to build our data sets. We remove the stop words and ﬁlter out the words of low-frequency (less than 5). The statistics of datasets are shown in Table 1. We also split all three datasets into three parts in chronological order and according to the ratio of 5:1:1: (1) We use the ﬁrst part to construct the user-news graph and users’ clicked history; (2) The second part is used to build the training samples; (3) We randomly sample 20% instances from the third part as validation set and regard the remaining as test set. Note that, we update the user history in training process same as DAN. 5.1.2 Experimental settings To be fair, according to GNUD, we set the embedding size of user and news as 128, the batch size B = 128, and use the random uniform distribution U(−0.01, 0.01)to initialize the embedding. And then we sample one item (that the corresponding user does not click) from the candidates set for each positive sample. In NE module, through the validation set, we setk = 30, the restart probabilitypand repeated walk numbernfor each node as 0.19 and10, respectively. In TAFA module, we set the number of heads and the output dimension per head as 4 and 32 for attention operator. We apply Adam (Kingma and Ba, 2015) for model optimization. Then we use the validation dataset to tune the regularization coefﬁcientλas 0.001, learning rate as5 × 10respectively. We adopt AUC and F1 (Hu et al., 2020) as the metric and use the F1 value as a reference for early-stop. 5.1.3 Baselines To evaluate the effectiveness of ConFRec, we compare the state-of-the-art methods from three categories for news recommendation: traditional recommendation (LR, DSSM, WideDeep, DeepFM), representation-based (FIM, DAN) and graph-based (GAT, GERL, GNUD). The brief descriptions are introduced as follows: • LR(McMahan et al., 2013): a generalized linear model that takes user-id, user’s clicked news, and candidate news content (title, entity, and groups) as input. • DSSM(Huang et al., 2013): a deep structured semantic model. We model the user clicked news as query, candidate news as documents. • Wide&Deep(Cheng et al., 2016): a widely used deep learning framework, which combines a linear model and a deep model, for recommendation in the industrial scenario. We feed the same feature as LR for linear part and the user’s clicked news, the proﬁle and the title for deep part. • DeepFM(Guo et al., 2017): a general deep recommendation model that combines the factorization machines and deep neural networks. We use the same input features as Wide&Deep. • FIM(Wang et al., 2020): a ﬁne-grained interest matching method, which hierarchically constructs multilevel representations with dilated convolutions for user’s behaviors and target news. We use the same input as DSSM. • DAN(Zhu et al., 2019): an attention-based neural network for news recommendation which uses a dynamic attention mechanism to model user historical behavior sequences. • GAT(Velickovic et al., 2017): a general GNN method with multi-head attention aggregator, using the user-news graph for news recommandation. Speciﬁcally, the initial embeddings of user node and news node are constructed from user id and news contents, respectively. • GERL(Ge et al., 2020): a news recommendation method with high-order user-news relatedness, which uses the transformer to build news semantic representations. We use the proﬁle embedding as the topic embedding. • GNUD(Hu et al., 2020): a deep graph neural model which maps user and news to k kinds of spaces for restriction constraints, and strengthens attention learning through iteration. We use the same inputs feature as GAT. The experimental settings of compared baseline models are consistent with those in the original papers. To ensure fair comparison, we use the same dimension and initialization method to initialize word, entity, and groups embedding. For each experiment, we repeated it more than 5 times independently and reported the average results. The experimental results for news recommendation of different models on 1week, 2week and 10week datasets are shown in Table 2, where we have the following observations: •The deep learning based models achieve better performance, since the deep learning technique is able to capture more non-linear information. The observation is from the fact that LR performs worse than the other models. •Attention mechanism is able to improve the performance. We can observe that DAN achieves better performance than compared traditional methods except DeepFM in terms of F1 on Adressa-2week. However, the performance of FIM is worse than traditional methods, since the dilated convolutions structure to too complicated for the news information extraction since the news contents may short and sparse. •Except GERL on 1week dataset, the graph-based methods achieve better performance than both traditional and representation-based methods due to capturing the high-order relationship between user and news. As shown in Table 2, the performance in terms of AUC and F1 is improved with a large margin. •Considering both collaborative and content ﬁltering relationships, the proposed ConFRec framework is able to enhance the performance of compared graph-based in terms of both AUC and F1. As shown in the Table 2, comparing with GERL, the GERL_ConFRec achieves an improvement of 5.0% to 7.29% in terms of AUC and 6.8% to 16.5% in term of F1, respectively. There are two possible reasons: (1) ConFRec alleviates the data sparsity problem through expanding news with similar contents by NE module. Speciﬁcally, lowdegree news obtains more chance to be trained. As a result, the user and news representations are improved; (2) ConFRec is able to aggregate more reasonable and accurate news information with the target-aware ﬁltering attention mechanism. 5.3 Ablation Studies In this section, we present the several ablation studies on both Adressa-1week and Adressa-2week datasets to explore the effectiveness of different modules. Firstly, we verify the effectiveness of NE and TAFA modules. As Table 3 shows, both NE and TAFA modules in the proposed framework are demonstrated to be effective. The NE module can boost the performance with expanding information for user’s history and strengthen the relationship of news with closer feature similarity. The TAFA module can improve the performance because the importance of items in different views Table 3: The effectiveness of NE and TAF modules. Table 4: The effectiveness of High-order News-News similarity. Figure 4: The effectiveness of ConFRec on data sparsity problem. The value on the horizontal axis represents the degree of node. The left vertical axis represents the gAUC and the right vertical axis indicates the relative improvement of ConFRec over vanilla. are recognized. Combining both modules leads to further improvement, indicating both feature based information expanding and reasonable target-aware ﬁltering are necessary for the news and user representations. To demonstrate the effectiveness of high-order news-news content similarity, we conduct the experiments to compare the performance of kNN similarity (G) and random walk similarity (G), on Adressa-1week and Adressa-2week datasets, respectively. From Table 4, we ﬁnd the walk-based NE achieves better performance than kNN-based NE, which mainly due to random walk can capture the global similarity to link much more high-order news neighbors in feature space. Figure 4 presents the effectiveness of the proposed ConFRec framework on the data sparsity problem. We take gAUC (group and average by user) on the Adressa-2week dataset as metric. In the left (right) of Figure 4, each point indicates the result of the news (user) subset where the degree (number Figure 5: The HeapMap of importance scores calculated by target-aware ﬁltering. The horizontal axis represents news ID, vertical axis indicates two types of views, namely title and proﬁle view, respectively. of user/news neighbors) is smaller than the corresponding value in the horizontal axis. The results demonstrate the proposed framework can improve more for the users with short behavior sequence and the items with low popularity. In other words, the proposed ConFRec framework can effectively alleviate the data sparsity problem. 5.6 Visualization of Target Aware Filtering For the purpose of elaborating the beneﬁts of TAF, we random select two samples as example and visualize these distributions of ﬁltering-based attention scores in user’s Discriminator module. As shown in the Figure 5, each user’s historyNconsists of two parts: original clicked news (in the blue box) and expanded news by NE (in the green box). The impact of embedding from different views are identiﬁed by TAF module. The observations are from the fact that the different views of a same news have different importance. Some of the expanded items have higher impact on target item which means that expanded information is more important. In this paper, we propose the ConFRec framework for news recommendation. ConFRec is able to capture both collaborative and content ﬁltering information and can alleviate the data sparsity problem. Speciﬁcally, we consider a feature-space similarity based News Expanding (NE) module to expand the news information for user history and target news as a generator, and utilize Target-Aware Filtering & Aggregation (TAFA in short) module to identify the important clicked news and aggregate the item information like a discriminator. Comprehensive experiments are conducted on the real-world datasets. The results demonstrate the effectiveness of ConFRec to alleviate the data sparsity problem and improve the news recommendation performance.