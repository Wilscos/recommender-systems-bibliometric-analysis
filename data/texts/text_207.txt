Recent years have witnessed ﬂourishing publications on recommendation, most of which aim at inventing machine learning models to ﬁt users’ historical behavior data [1]. However, the observation data usually exhibits severe popularity bias, i.e., the distribution over items is quite imbalanced and even long-tailed. Such skewed distribution may be caused by the users’ conformity, deviating from reﬂecting users’ true preference. As a crucial factor for user decision-making, conformity describes the tendency that user behaves following groups. In a typical recommender system, a user may click an item simply because he ﬁnds the item clicked by many other users, rather than based on his own judgement. As a result, recommendation model trained on such biased data would yield unexpected results, e.g., capturing skewed user preference and amplifying the long-tail effect. Given the wide existence of popularity bias and its negative impact on recommendation, we cannot emphasize too much the importance of tackling popularity bias. Existing efforts mainly focus on entirely eliminating popularity bias to recover true user preference. However, we argue that not all popularity bias is harmful. Besides conformity effect, the uneven item distribution can also be attributed to the diverse item quality. For example, some items exhibit higher popularity as they have intrinsic better properties, e.g., attractive story, harmonious music and professional actors for a typical movie. Blindly removing the popularity bias would lose such important signal, making the model fail to differentiate superb items that deserve more opportunities for recommendation. Therefore, we arrive at a dilemma: eliminating popularity bias would lose important quality signal, while maintaining popularity bias would suffer undesirable conformity effect. Now a question is raised: is there a solution that enjoys the merit of the popularity bias while circumvents its bad effect? To achieve this goal, it is essential to disentangle the harmful popularity bias caused by the conformity from the benign one caused by the item quality. Although important, this problem has been under explored on the literature. The main challenge is the lack of explicit signals for disentanglement. Since we only have access to item popularity scores, which do not tell what factor causes this result. To deal with this problem, we propose to leverage the temporal information in differentiating the benign and harmful factors, as they exhibit quite different patterns along time: item quality which reveals item intrinsic property is stable and static, while conformity that depends on the number of recent clicks is highly timesensitive. We also conduct empirical analyses on real-world datasets to validate this point, with making the following two interesting observations: (1) The more popular an item is, the larger average rating value the item tends to acquire. This observation reveals the existence of benign popularity bias — items with higher popularity usually suggest better quality and would receive more praise. (2) From the temporal view, for a large proportion of items, the rating value exhibits negative correlation with the item popularity at that time. This observation reveals temporal dynamic of harmful popularity bias — conformity exerts varying negative impact on users’ behaviors with time going by. Based on the above insights, we propose a Time-aware DisEntangled framework (TIDE) for tackling popularity bias. We resort to the causal graph and assume click data is generated from three different components: (1) a timeinvariant module that captures the excellence of the item; (2) a temporal dynamic module that encodes the conformity effect by scrutinizing the number and time of recent clicks on the item; (3) a normal recommendation model that estimates user interest matching on the item. Such disentangled model provides opportunity to make better recommendation — inheriting the benign components while circumventing the harmful ones. Towards this end, during the inference stage, we conduct causal intervention on the conformity module to make the prediction beneﬁcial from the item quality and interest matching score while immune to the harmful conformity effect. Lastly, in terms of leveraging popularity bias in recommendation, the most relevant work is the recently proposed PDA [2]. However, we argue that directly injecting (predicted) item popularity score into prediction is insufﬁcient for satisfactory recommendation as the harmful conformity effect is also injected. Distinct from PDA, our TIDE distills the benign popularity bias in prediction and yields signiﬁcant empirical improvement. In a nutshell, this work makes the following main contributions: to study the problem of disentangling the benign popularity bias caused by item popularity from the harmful popularity bias caused by conformity in recommendation. work TIDE for tackling popularity bias in recommendation. TIDE performs disentangled training by leveraging temporal information while resorts to intervention to block the harmful conformity effect during inference stage. mark datasets demonstrate the superiority of the proposed method over a range of state-of-the-arts. We will release our source code to facilitate future research. The rest of this paper is organized as follows. We formulate the task and empirically explore popularity bias in section 2. We further present our proposed TIDE in section 3. The experimental results are presented in section 4. We brieﬂy review related works in section 5. Finally, we conclude the paper and present some directions for future work in section 6. In this section, we formulate the task and explore popularity bias on real-world datasets. 2.1 Problem Deﬁnition Suppose we have a recommender system with a user set U and an item set I. Let u (or i) denotes a user (or an item) in U (or I). Let D denote the historical user behavior data, which was sequentially collected before the time T and notated as a list of triples i.e., D = {(u, i, t)}, where the triple (u, i, t) denotes the user uhas clicked the item i at the time t. For convenience, we collect users’ feedback on the speciﬁc item i before time t as D= {(u, i, t) ∈ D|i= i, t< t}. Also, we deﬁne the popularity Pof the item i as the number of observed interactions on i, i.e., P= |D|. The task of a recommendation system can be stated as follows: learning a recommendation model from D so that it can capture user preference and make a high-quality recommendation. Popularity Bias, which denotes the uneven (usually longtailed) distribution over the interaction frequency of items, is common in a recommender system. There are two factors resulting in popularity bias: (1) item quality, revealing the inherent excellence of items, which is benign; (2) conformity effect, describing a user tends to behave towards group norms while deviating from his own preference, which is harmful. This paper aims at disentangling the two factors such that the recommendation can beneﬁt from the benign factor while circumvent the harmful one. 2.2 Empirical Analyses of Popularity Bias In this subsection, to reveal the existence of two factors and their properties, we conducted empirical analyses on real-world recommendation datasets including Amazon, Ciao, Doubanand Movielens. Besides click information, these datasets also contain users’ ratings on their clicked items, which provide groud truth label of their preference. A larger rating value suggests a user is more satisﬁed with an item. Two statistical analyses have been conducted: (1) We ﬁrst explore the correlation between item popularity and their ratings. We divide items into 30 groups according to their popularity (where we segment popularity interval uniformly). We then calculate the average ratings of items in each group. The result on a typical dataset DoubanMovie is presented in Figure 1(a). We also report the Pearson Correlation Coefﬁcient [3] between the average rating and popularity in terms of groups on various datasets in Figure 1(b). (2) We then explore the temporal dynamic of popularity bias. For each item, we calculate the Pearson Correlation Coefﬁcient between the rating value and the time-aware instant popularity at that time, where instant popularity of item i and time t is deﬁned as the number of clicks on the item during the past half year (i.e., |D| − |D|, tdenotes a period of half year). The distribution of the calculated coefﬁcients over items on two typical datasets is presented in Figure 2(a),2(b). Here we ﬁlter out not signiﬁcant results with p > 0.2. We also visualize the temporal evolution of the instant popularity for ﬁve randomly-selected items (Figure 2(c)), as well as an example of the relation between the rating value and the instant popularity (Figure 2(d)). Two important observations are concluded from these results. Observation 1. The more popular an item is, the larger average rating value the item tends to have. Figure 1(b) demonstrates item average rating values exhibit positive correlation with item popularity in a large portion of datasets. This result suggests that popularity bias is not always harmful. Some items with higher popularity can be attributed to their better intrinsic quality, which are more likely to be favored by users. Item popularity provides an imporatant signal regarding to item quality, which is proﬁtable to boost recommendation performance. Nevertheless, item popularity can not be directly leveraged into recommendation. Popularity would also be affected by the conformity effect, deviating from the quality. It can be seen from the severe ﬂuctuation of the curve in Figure 1(a). Also, popularity exhibits weakly-positive or even negative correlation with average ratings in a considerable portion of datasets. Thus, we need to disentangle the effects from the two factors such that the recommendation can beneﬁt from such benign knowledge while circumvent the impact of the harmful one. Observation 2. From the temporal view, for a large proportion of items, the rating value exhibits negative correlation with the item temporal popularity at that time. Figure 2(c),2(d) vividly demonstrates the dynamic of item instant popularity that conformity effect depends on. Besides, when the instant popularity becomes larger, when the conformity exerts larger impact on user behavior, we observe to a large extent that user’s behavior deviates from his own preference. Thus we can see the negative correlation between average ratings and instant popularity (Figure 2(a),2(b)). This observation reveals the temporal dynamic of harmful popularity bias and motivates us to leverage temporal information in disentanglement. Based on above analyses, we make the following hypothesis, which lays foundation of our proposed method: Hypothesis 1. Popularity bias is mainly caused by both conformity effect and diverse item quality. Item quality that reveals item intrinsic property is stable and static, while conformity that depends on recent clicks is highly time-sensitive. In this section, we present our time-aware disentangled framework (TIDE) for tackling popularity bias. 3.1 Disentangled Learning TIDE resorts to a causal graph as shown in Figure 3(a) and assumes an observed click is generated from the following three disentangled components: (1) I → Q → Y : This link denotes the effect of item quality on user behavior. An item with higher quality is more likely to be favored by a user. Here we simply use a time-irrelevant item-speciﬁc variable qfor each item i to capture its inherent quality. (2) (I, t) → C → Y : These links represent the timeaware conformity effect on user behavior. As suggested in Hypothesis 1, the impact of conformity not only depends on the time point t of this interaction, but also on the time and the number of past interactions on the item i. As such, we formulate the following parameterized function gto estimate the strength of conformity effect of item i at time t: c= g(t, D) = βexp(−|t − t|τ where a parameter βis introduced for each item i to rescale the effect, as conformity usually exhibits more severe on some items (e.g., soap opera) than others (e.g., science documentary). Here we simply cumulate the stimulations from past interactions while discount their contribution according to the time interval. This setting is coincident with our intuition — the currently popular items would have larger impact on us than the one that was popular in the far past. We also introduce a temperature parameter τ controlling the sensitivity of cto the time. A smaller τ would make the model focus more on recent interactions and immunize the interactions occurred long time ago. (3) (U, I) → M → Y : these links project user and item features (e.g., IDs) into their matching scores m= f(u, i). f(u, i) can be implemented by various recommendation models, such as MF [4], LightGCN [5], DIN [6]and etc. Finally these three components are aggregated into a ﬁnal prediction score for recovering the observed historical interactions: Where tanh(q+ c) can be understood as popularity bias which combines the benign effect from the item quality (Q → Y ) and the harmful effect from the conformity (C → Y ). Tanh(.) is an activation function that project the popularity bias into interval [0,1] while Softplus(.) is an activation to ensure the positivity of the matching score. We can still apply commonly-used BPR [4] recommendation loss over the ﬁnal prediction score to learn the model. Formally, the training loss is given as follow: where σ represents the sigmoid function. We conduct negative sampling to draw a negative instance j from distribution pfor training our model. As recent work [2], here we simply use a uniform sampling strategy for fair comparison. Note that we have omitted the Lregularization terms for clarity.RQ1: Does TIDE outperform SOTA methods for popularity 3.2 Intervention-based InferenceRQ2: Is it beneﬁcial to model both static item quality As shown in Figure 3(a), I inﬂuences Y through three paths: I → Q → Y through item quality, I → C → Y through conformity effect and I → M → Y through user-item matchingRQ3: Do the learned parameters q score. In order to make the recommendation beneﬁt from the useful factors while circumvent the harmful, we perform the causal intervention to cut off the path I → C → Y as shown in Figure3(b) where improper effect from the conformity has been removed. Formally, we directly intervene cwith a ﬁxed value cand make the prediction as: We set cas 0 in experiments for the simplicity of the model. 3.3 Links to Recent Work Recent years have witnessed various debiasing strategies for popularity bias. Among which, causal inference is the most successful and representative strategy [2], [7], [8]. We argue that the inherent nature of this kind of methods is disentanglement — undo the effect of the popularity bias to recover user preference on items. The cause graph of these methods can be simply summarized as Figure 4(a). Although this graph may be different from the causal graph claimed in the original papers, Figure 4(a) is indeed coincident with their models. For example, PDA [2] assumes a click is generated with combining item popularity score and user-item matching score, i.e., ˆy= P× Elu(m); DICE [7] makes a similar assumption except that they model sensitivity of users to item popularity (as marked by the dash line in Figure 4(a)). This work lies on this scheme but we further conduct disentanglement of popularity bias. As Figure 4(b) shows, we split the path regarding to popularity bias (I → P → Y ) into two paths: I → Q → Y the benign effect from item quality and I → C → Y the harmful effect from conformity. Besides, during the inference stage, instead of blindly removing popularity bias as [7], [8] (cutting I → P → Y ) or leveraging complete popularity bias in prediction as [2], we utilize partial popularity bias — leveraging benign part (maintain path I → Q → Y ) while removing harmful part (cutting path I → C → Y ). In this way, our TIDE can distill useful information from popularity to prediction and yields empirical improvement over them. In this section, we conduct experiments to evaluate the performance of our proposed TIDE. Our experiments are intended to address the following research questions: bias? and dynamic conformity effect? Is it beneﬁcial to remove the effect from conformity during the inference stage? 4.1 Experimental Setup Datasets. We choose three well-known datasets Ciao, Amazon-CDs and Douban-Movie for our experiments. These datasets contain users’ rating records in a chronological order. Since it is unreliable to include users with few interactions for evaluation, we conduct 5-core ﬁltering for the datasets Ciao and Amazon-CDs, and 10-core ﬁltering for Douban-Movie. The statistics of the datasets are described in Table 1. We follow the setting of PDA [2] and split the datasets chronologically. Speciﬁcally, we split the datasets into 10 parts according to the interaction time, and each part has the same time interval. The ﬁrst nine parts are used for training, while the last part is left for validation and testing, in which the interactions of half of the users are organized as validation set while others are organized as testing set. We also transform the data into binary implicit feedback for experiments as [2], [9]. That is, as long as there exists a rating, the corresponding implicit feedback is assigned a value of 1, suggesting the item has been interacted (i.e., clicked) by the user. Evaluation Methodology. We train a model with binary training data and evaluate its performance on the following two tasks: casts users’ future clicks. Speciﬁcally, we apply the model to sort the items that have not been interacted, and test whether the top-K items would be clicked by the user in the future (i.e., in test data). For the matrics, we employ Recall@K (called CP-Rec@K in this task), Precision@K (CP-Pre@K) and Normalized Discounted Cumulative Gain@K (CP-NDCG@K) for evaluating model performance in this task. incident with user preference. We further evaluate how a model retrieves relevant items that users are indeed fond of. We resort to the ground truth rating value, and consider the item with a high rating value (e.g., 5) as positive. As we do not know user’s true preference on unrated items, in this task, we just rank the rated items in the test data and evaluate whether the positive items are retrieved within TopK positions. Speciﬁcally, precision@K (marked as PPPre@K) and recall@K (PP-Rec@K) are adopted in this task. Also, considering the number of rated items is usually small, we set a relatively small K (e.g., K=3). Comparison methods. Five type of methods are tested in our experiments: BPR loss. popularity bias by re-weighting each instance according to item popularity. We refer to [12] and apply a max-capping trick on IPS value to reduce variance. data to disentangle user preference and popularity bias into two sets of embeddings. forms deconfounded training while intervenes the popularity bias during model inference. We report two versions of this work: PD that directly uses matching score for recommendation; PDA that leverages predicted item popularity score in recommendation. As PDA demonstrates superior performance over ranking-based methods [13], [14], we do not include these methods as baselines. test two versions of TIDE: TIDE-full, combining all the effect from three components for predicting user future click, i.e., we use ˆyfor ranking; TIDE-int, which performs intervention to cut off the effect from the conformity, i.e., ˆyis utilized. Implementation details. Matrix Factorization (MF) has been selected as a backbone recommendation model for experiments, and it would be straightforward to replace it with more sophisticated models such as Factorization Machine [15], or Neural Network [5], [16]. We also utilize reparameterization trick to ensure the positivity of the learned qand β, i.e., q← Sof tplus(q), β← Sof tplus(β). We optimize our TIDE with Adam. Grid search is used to ﬁnd the best hyper-parameters based on the performance on validation set: The search spaces of learning rate and weight decay of the parameters in MF are {1e-4, 1e-3, 1e-2}; Also, we set the decay of qand βas 0, and search their initialization in [-5,1] with step 1 and learning rate in {3e-4, 1e-3, 3e-3, 1e-2}; τ is set as 1e7, batch-size is set as 8,192. The setting of compared methods is either determined by grid search in our experiments or suggested by their original papers. All experiments are conducted on a server with 2 Intel E5-2620 CPUs, 4 NVIDIA GTX2080 GPUs and 256G RAM. We will share our source code at Github when the paper gets published. 4.2 Performance Comparison (RQ1) Performance on click prediction task. Table 2 presents the performance of the compared methods in the click prediction task in terms of three evaluation metrics. The boldface font denotes the winner in that column. For the sake of clarity, the row ‘Impv’ shows the relative improvement achieved by TIDE over all the baselines. Overall, with few exception, our TIDE outperforms all compared baselines. Especially in the dataset Amazon, the improvements are quite impressive — 23.43%, 16.45% and 19.69% in terms of Precision, Recall and NDCG respectively. This result validates that TIDE can capture more precise popularity bias and thus make a more accurate prediction of users’ future behavior. Performance on preference prediction task. Table 3 presents the performance of the compared methods on preference prediction task. We have the following observations: (1) PDA which consistently outperforms PD in the click prediction task performs worse in this task. This interesting phenomenon reveals the negative impact of popularity bias. Blindly inject popularity bias without ﬁltering its harmful ingredient would deteriorate the model performance. Similar results can be seen from the worse performance of TIDE-full than TIDE-int. (2) Overall, with few exception, our TIDE-int outperforms all compared methods in this task. This result validates the effectiveness of disentangling benign and harmful factors of popularity bias. Without disentanglement, existing methods sink into a dilemma — they either fail to utilize the important signal of the item quality (e.g., TIDE-int outperforms PD, DICE, MF-IPS), or are disturbed by the harmful conformity (e.g., TIDE-int outperforms PDA and MF). 4.3 Ablation Study (RQ2) We conduct ablation study to explore whether it is essential to model both factors and whether it is essential to perform interventional inference. We compare our TIDE-full and TIDE-int with the following special cases: (1) TIDE-noq and TIDE-noc: where item quality or conformity effect is removed in both training and inference stage; (2) TIDE-e: which is trained as same as TIDE-int but uses matching score for recommendation. The characteristics and performance on preference prediction task are presented in Table Effectiveness of modeling both factors. We observe that the method with modeling two factors (TIDE-int) consistently outperforms the cases just considering one aspect (TIDE-noq and TIDE-noc). This result is coincident with our intuition — modeling both factors is beneﬁcial for capturing popularity bias as well as for distilling useful knowledge from it. Effectiveness of interventional inference. From Table 4, we observe TIDE-int is consistently superior over TIDEe and TIDE-full. This result demonstrates the mix nature of popularity bias — containing both benign and harmful signals. The model that roughly maintains or removes both of them would result in undesirable performance. 4.4 Exploratory Analysis (RQ3) To answer the question RQ3, we now explore the learned qfrom two perspective to provide insights into how TIDE captures item quality. Distribution of learned q. Figure 5 visualizes the distribution of the learned qwith their average rating value (simply marked as AR) on a typical dataset Douban-Movie. We can observe the positive correlation between them. Also, comparing with Figure 1(a), the curve in Figure 5 is more stable and exhibits less ﬂuctuation. Ranking correlation comparison. We further validate the stronger correlation of the average rating value with q than with popularity P. We calculate Kendall Tau Ranking Correlation Coefﬁcient (RCC) [17] between the item lists ranked by them. RCC essentially measures the probability of two items being in the same order in the two ranked lists, and would be more robust and rational than Pearson Correlation Coefﬁcient (PCC) especially for a recommendation task. The result is presented in Table 5. We observe RCC between qand ARis larger than RCC between P and AR. Besides, to our surprise, we observe the absolute values of both metrics are relatively small. More seriously, RCC between Pand ARis negative on the datasets Amazon-CDs and Ciao. This result validates the challenging of tackling popularity bias. There exists a gap between the value and ranking — positive correlation in terms of value may not result in positive correlation in ranking. Although popularity exhibits positive correlation with ARin PCC, its ranking result is easily distorted by other factors in popularity and deviates from reﬂecting positive correlation. TIDE ﬁlters conformity effect from popularity bias and relatively capture more stable and precise knowledge of item quality. Effectiveness of learning diverse q. To validate the necessary of learning diverse q, we compare TIDE-int with its special case TIDE-ﬁxq, where qfor all items are ﬁxed as a same value. The results are presented in Figure 6. Generally speaking, TIDE-int performs better than TIDE-ﬁxq. Especially on two large datasets Douban-Movie and AmazonCDs, TIDE-int consistently outperforms TIDE-ﬁxq with a certain margin. This result demonstrates that our model indeed learns some useful information, which is beneﬁcial for recommendation. Also, we observe quite similar performance of TIDE and TIDE-ﬁxq on Ciao. This phenomenon can be explained as follow: It seems that popularity bias on Ciao is mainly caused by conformity. conformity is quite severe and overwhelms the contribution of item quality. it can seen from the weakly-positive correlation of the qand ARpresented in Figure 1(b). In this section, we review the most related works from the following two perspectives. Popularity Bias in recommendation. Popularity bias depicting uneven (usually long-tailed) distribution over the interaction frequency of items, is common in a recommender system. The negative impact of popularity bias has been studied in a large number of recent literatures. For example, some work [7], [18] argues that such skewed distribution may be caused by user conformity, deviating from reﬂecting users’ true preference. As such, recommendation models trained on such biased data would give skewed prediction. Worse still, recommendation model not only inherit the bias, but also ampliﬁes bias, making the popular items dominate the top recommendations [13], [19], [20], [21], [22], [23]. This phenomenon has been empirically veriﬁed by Abdollahpouri [24]. They ﬁnd popular items are recommended to a much greater degree than even what their initial popularity warrants. It would decrease serendipity [25], [26], [27] and fairness [13], [28], [29], [30] of recommendation results, hurting user experience and causing customer churn. Recent work on tackling popularity bias can be mainly classiﬁed into four types: (1) Inverse propensity scoring (IPS) [11], [31] is a classic strategy that directly adjust the data distribution with re-weighting each instance according to item popularity. (2) Ranking adjustment is another type of method [13], [14] that directly re-rank the recommendation list to improve the recommendation opportunity of unpopular items. Although simple and straightforward, this type of methods rely on human heuristical design and usually sacriﬁces recommendation accuracy. (3) Regularization has been introduced by some researchers to push the model towards balanced recommendation [32], [33], [34], [35]. For example, Chen et al. [32] leverage regularization to transfer the knowledge from these well-trained popular items to the long-tail items; Bonner et al. [33] leverage regularization to distill knowledge from the uniform data for addressing popularity bias. (4) Causal inference has been leveraged for addressing popularity bias. These kinds of methods mainly assume the generative process of the data with causal graphs and then disentangle the popularity bias from the user preference accordingly [2], [7], [8]. However, most of existing methods focus on eliminating popularity bias. In fact, popularity bias is not always evil. It may not only result from the users’ conformity to the group, but also from item quality. It would be valuable to leverage such important signal in boosting recommendation performance. To the best of our knowledge, only one work [2] considers to leverage popularity bias into recommendation. However, they directly injecting (predicted) item popularity score into prediction, which is insufﬁcient for satisfactory recommendation as the harmful conformity effect is also injected. Different from these work, we consider the doubleedged nature of popularity bias. We aim at disentangling the benign popularity bias from the harmful one, such that the recommendation can beneﬁt from the merit while circumvent the harmful. Biases in recommendation. Besides popularity bias, recent work has studied other type of biases in recommendation including: Selection bias, which happens as users are free to choose which items to rate, so that the observed ratings are not a representative sample of all ratings [36], [37], [38], [39]; Exposure bias, which happens in implicit feedback data as users are only exposed to a part of speciﬁc items [24], [36], [40], [41]; Position bias, which happens as users tend to interact with items in higher position of the recommendation list [36], [42]; Unfairness [43], [44], which denotes the system systematically and unfairly discriminates against certain individuals or groups of individuals in favor others. Generally, there are substantial work on addressing these biases issues. We encourage the readers refer to the survey [36] for more details. Disentanglement in recommendation. In terms of disentanglement, existing efforts can be classiﬁed into two lines. The ﬁrst type of methods is designed for debiasing. As discussed above, this type of methods aim at disentangling user true preference from the various data biases [7], [8]. Another type of methods lie in disentangled representation learning. This kind of methods aim at learning a ﬁnergranularity representation of users and items, which is beneﬁcial for robust and explainable recommendation. For example, Ma et al. [45] leverage Variational Auto-Encoder [46] to disentangle high-level concepts associated with user intentions as well as low-level factors (e.g., size or color of a shirt). Similarly, Wang et al. [47] learn disentangled user representation with the merits of the interaction graph. This paper studies an important but unexplored problem — how to disentangle the benign popularity bias caused by item quality from the harmful popularity bias caused by conformity. We ﬁrst conduct empirical analyses on realworld datasets and observe quite different patterns of these two factors along time: item quality revealing item inherent property is stable and static while conformity that depends on item recent clicks is highly time-sensitive. We then propose a novel time-aware disentangled framework (TIDE), where a click is generated from three components namely the static item quality, the dynamic conformity effect, as well as the user-item matching score. We further provide an interventional inference strategy such that the recommendation can beneﬁt from the benign popularity bias while circumvent the harmful one. Extensive experiments on three real-world datasets demonstrated the effectiveness of the proposed disentangled models as well as its interventional inference strategy. One interesting direction for future work is to explore a more sophisticate conformity model g, which could capture more complex patterns and potentially achieve better performance than simple sum-exponential structure. Besides, this work demonstrates popularity bias is doubleedged. We believe other biases may also have this nature. It will be valuable to transfer the experience of this work to tackling other biases and to explore their benign and harmful effect on recommendation. This work is supported by the National Natural Science Foundation of China (U19A2079), National Key Research and Development Program of China (2020AAA0106000), USTC Research Funds of the Double First-Class Initiative (WK2100000019), and the Meituan Inc. through Research Cooperation Project.