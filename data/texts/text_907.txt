Multi-touch attribution (MTA), aiming to estimate the contribution of each advertisement touchpoint in conversion journeys, is essential for budget allocation and automatically advertising. Existing methods ﬁrst train a model to predict the conversion probability of the advertisement journeys with historical data and calculate the attribution of each touchpoint using counterfactual predictions. An assumption of these works is the conversion prediction model is unbiased, i.e., it can give accurate predictions on any randomly assigned journey, including both the factual and counterfactual ones. Nevertheless, this assumption does not always hold as the exposed advertisements are recommended according to user preferences. This confounding bias of users would lead to an out-of-distribution (OOD) problem in the counterfactual prediction and cause concept drift in attribution. In this paper, we deﬁne the causal MTA task and propose CAUSALMTA to eliminate the inﬂuence of user preferences. It systemically eliminates the confounding bias from both static and dynamic preferences to learn the conversion prediction model using historical data. We also provide a theoretical analysis to prove CAUSALMTA can learn an unbiased prediction model with sufﬁcient data. Extensive experiments on both public datasets and the impression data in an e-commerce company show that CAUSALMTA not only achieves better prediction performance than the state-of-the-art method but also generates meaningful attribution credits across different advertising channels. Online advertising platforms have been widely deployed to help advertisers launch their advertisements (ads) across multiple marketing channels, such as social media, feed stream, and paid search. During the usage, the ad exposure sequences and conversion feedbacks of all customers are collected. Multi-touch attribution, short for MTA, aims to estimate each ad touchpoint’s relative contribution in user conversion journeys. The attribution results will shed light on the budget allocation and automatically advertising. Nowadays, instead of attributing the ad touchpoints by heuristic rules (Berman 2018), data-driven methods (Shao and Li 2011; Dalessandro et al. 2012; Ji and Wang 2017; Ren and etc. 2018; Arava et al. 2018; Yang, Dyer, and Wang Copyright © 2022, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. Figure 1: The inﬂuence of user preferences for MTA. 2020) which estimate the attribution credits according to the historical data have become the mainstream techniques. These methods learn a conversion prediction model with all observed historical data and then generate the counterfactual ad journeys by removing or replacing some touchpoints. Basing on some criteria, e.g., Shapley value (Shapley 1953), the attribution credits can be estimated by using the prediction results of these counterfactual journeys. One essential assumption of these methods is the conversion prediction model should be unbiased, which means the model can give fair predictions on any randomly assigned journeys, including the factual and counterfactual ones. Unfortunately, this assumption does not hold in online advertising. The ad exposures are recommended according to the user preferences, leading the learned conversion prediction model to be biased. The discrepancy between observed training data and counterfactual data causes an out-of-distribution (OOD) problem in counterfactual prediction, which would harm the fairness of attribution. We deﬁne the attribution of the ad journeys with an unbiased prediction model as causal MTA. Nevertheless, it is no trivial to eliminate the confounding bias of user preferences in MTA. The reasons are two folds: (1) Multiple confounders. The confounders in ad exposure generation consist of the static user attributes, such as genders, ages and education background, and dynamic features, e.g., previously viewed ads and favorite items. Both the static and dynamic features should be taken into account for unbiased causal MTA. Existing works either focus on the static settings (Austin 2011; Johansson, Shalit, and Sontag 2016; Johansson et al. 2018; Zou et al. 2020) using IPW and propensity score matching method for deconfounding, or are dedicated to the dynamic confounders (Lim 2018; Bica et al. 2020) learning an unbiased representation for prediction at each time step. All these works rely on the strong ignorability assumption (Pearl 2009), i.e., no hidden confounders. In their settings, the static and dynamic features are hidden confounders mutually that disable the usage. (2) Delay feedback. The conversion results are observed at the end of the journey. Moreover, there is no explicit feedback available at each touchpoint. Existing sequential deconfounding methods (Xu, Xu, and Saria 2016; Roy, Lum, and Daniels 2017; Lim 2018; Bica et al. 2020) are designed for instant feedbacks, e.g., the blood pressure, which can be observed immediately after taking the hypotensor. CAMTA (Kumar et al. 2020) is the most related method of our work. However, it takes the click action as the ”pseudo” feedback at each touchpoint, which would involve other confounders. Above all, due to the peculiarities of advertising, there are no existed methods that can be used for unbiased causal MTA. In this paper, we propose a novel method, namely CAUSALMTA, to mitigate the effect of user preferencesrelated confoundedness and achieve causal MTA. It learns an unbiased counterfactual prediction model which systemically eliminates the confounding bias from both static user attributes and dynamic features. One fundamental assumption of CAUSALMTA is that the inﬂuence of static user attributes and dynamic features are independent. This assumption is reasonable in online advertising because user attributes usually determine their item interests, and dynamic features determine how likely the users want to buy. As shown in Figure1, twenty years old students tend to be attracted by fancy phones and cosmetics, whereas the middle age guys usually like high cost-performance phones and anti-bald goods. Dynamic features, such as previously visited ads and staying time, reﬂect the purchase intention. The main contributions can be summarized as follows: • We decomposed the confounding bias of user preferences into static user attributes and dynamic features, and deﬁned the causal MTA problem. • We propose the ﬁrst method CAUSALMTA for causal MTA, which is provable for eliminating the confounding bias of user preferences in counterfactual prediction. • Experiments on both opensource datasets and real-world impressing data of mobile phones shops from an ecommerce company show the superior of CAUSALMTA. Data-driven multi-touch attribution. Previously, marketers have applied simple rules, e.g., the last touch, to attribute the inﬂuence of touched ads (Berman 2018), which either ignore the effects of other channels or neglect the channel difference. To overcome these drawbacks, researchers proposed data-driven attribution methods. The data-driven MTA model was ﬁrst proposed in (Shao and Li 2011), and has been combined with survival analysis (Zhang, Wei, and Ren 2014) and hazard rate (Ji and Wang 2017) to reﬂect the inﬂuence of ad exposure. However, the data-driven methods mentioned above neglect the customers’ features and cannot directly allocate personalized attribution. Besides, the temporal dependency and dynamic interaction between channels need to be modeled. Recently, many DNN-based data-driven MTA methods have been proposed to address the issues, such as channel interaction, time dependency, user characteristics. Some literature (Arava et al. 2018; Ren and etc. 2018; Du and etc. 2019; Kumar et al. 2020; Yang, Dyer, and Wang 2020) leverage RNNs to model longitudinal data. DNAMTA (Arava et al. 2018) is an LSTM based deep sequential model which captures the touchpoint contextual dependency via attention mechanism and incorporates user context information and survival timedecay functions. DARNN et al. (Ren and etc. 2018) is a dual attention model that combines post-view and post-click attribution patterns for ﬁnal conversion estimation. Counterfactual Prediction. Positioned as a causal estimation problem by (Dalessandro et al. 2012), the calculation of attribution credits is actually based on counterfactual estimation (Zhang, Wei, and Ren 2014; Du and etc. 2019; Singal and etc. 2019; Shender et al. 2020). A limitation of the models mentioned above is the lack of exogenous variation in user exposure to advertising, which hazards the reliability of the attribution results as the training data of the counterfactual predictor is biased by confounders. Albeit extant papers (Sahni 2015; Barajas et al. 2016; Nair et al. 2017; Zantedeschi, Feit, and Bradlow 2017) mitigate the issue with full or quasi-randomization, the cost and complexity of such randomization restrict the number of users and ad-types. The idea of calibrating the conversion prediction model in MTA by removing confounding bias is inspired by works in counterfactual prediction. There is a large number of methods for counterfactual prediction using observational data in the static setting, involving utilizing propensity score matching (Austin 2011), learning unbiased representation for prediction (Johansson, Shalit, and Sontag 2016; Johansson et al. 2018; Zou et al. 2020), conducting propensity-aware hyperparameter tuning (Alaa and van der Schaar 2017, 2018). For estimating the effects of time-varying treatments in the area such as epidemiology where the treatments have instant feedback, many approaches (Xu, Xu, and Saria 2016; Roy, Lum, and Daniels 2017; Lim 2018; Bica et al. 2020) addressing the longitudinal setting are proposed. Because of the gap between the longitudinal data in epidemiology and ad journeys in MTA, those methods cannot be directly used in our task. Problem Deﬁnition. We consider an ad exposure dataset D which consists of N conversion journeys of U users. Each journey can be formulated as a triplet, i.e., (u, J, y). u stands for the static user attributes, which is unlikely to be changed during the user conversion journey. Jis a sequence of touchpoints, i.e., {p}. Each touchpoint p= (c, f) contains a channel index cand a feature vector z. Specifically, c∈ {c, ..., c, ..., c} indicates the exposed channels, where K is the number of ad channels. The feature vector fincludes the dynamic side information of this touchpoint, e.g., advertising form and staying time. yis a binary indicator that records whether the journey leads to a conversion event or not. The goal of MTA is to model the sequential pattern and assign the attribution credits to all the touchpoints paccording to the whole information in D. Nevertheless, historical data in D often exhibits confounding bias due to user preferences, which could be a fatal challenge for estimating the attribution credits. The choice of the channel at a touch-point is likely to be inﬂuenced by multiple factors like user attributes and previously visited goods. Causal multi-touch attribution aims to estimate trustworthy attribution credits {p}of all touchpoints in J. Method Overview. As shown in Figure 2, CAUSALMTA is a novel model-agnostic framework consisting of two key modules, i.e., journey reweighting and causal conversion prediction, which mitigate the confounding bias of user static attributes and dynamic features respectively. In journey reweighting, we employ the Variational Recurrent Auto-encoders (VRAE) to learn the generation probabilities of pure channels journeys, and conduct user demographic-based density estimation to calculate the likelihoods of the channels being randomly assigned that is used for weights computation. For causal conversion prediction, CAUSALMTA utilizes RNNs to model the dynamic features of journeys. A gradient reverse layer is building upon the outputs of each time step to ensure the model is unable to predict the next ad channel. It derives balancing representation, which removes the association between dynamic features and the ad exposure. Basing on the learned weights of journey reweighting, the last hidden output is trained to estimate the conversion probability. After that, we can obtain an unbiased prediction model. Lastly, with the constructed counterfactual journeys, the attribution credits can be estimated under Shapley value measure. In this section, we ﬁrst specify the journey reweighting and causal conversion prediction respectively. After that, the calculation of attribution credits is detailed. In the end, we provide the theoretical analysis of CAUSALMTA. Journey Reweighting To mitigate the bias of static user attributes, the journey reweighting module takes pure channel sequences in D as the input and estimates the sample weights of the prediction model according to how likely the journey be generated randomly. It consists of two procedures, i.e., generation model for channel sequences and weights estimation of journeys. Generation Model for Channel Sequences. We utilize VRAE (Variational Recurrent Auto-encoders) (Fabius, van Amersfoort, and Kingma 2015) to model the generation of channel sequences. When training data is large enough, the distribution of pure channel sequences tends to be random without considering user preferences. In this setting, the learned VRAE is capable of generating unbiased predictions of observed channel sequences. For each ad journey (u, J, y) in D, we only concern with the channel information in this procedure and extract the pure channel sequence C = {c}. Taking C as the input, CAUSALMTA employs the channel embedding afﬁliated with LSTM as the encoder and utilizes the ﬁnal hidden state to generate the distribution over latent representation: where his the initial hidden state of the encoder. Leveraging the reparametrization trick, we sample a vector z from the distribution to initialize the hidden state of the decoder: where his the initial hidden state of the decoder; Cis the feed previous input which takes the output of previous step as the input; cis the decoded channel sequence. The loss function is composed of two parts: 1) the reconstruction loss which is deﬁned as the cross-entropy between cand c. 2) the KL divergence between the posterior and prior distribution over the latent variable: L= αCE(c, c) + βD(q(z)||p(z)) (1) where p(z) is the prior distribution usually assumed to be a standard normal distribution N(0, I); q(z|c) is the posterior approximation (N(µ, (σ)); α and β are hyperparameters that control the importance each parts. Weights Estimation for Ad Journeys. To eliminate the bias of user static features, we estimate the weights of observed journeys. The journeys approximating to randomly assigned have higher weights in conversion prediction training than those are severely affected by user preferences. Formally, the learned weights W(u, C) should be subject to W(u, C) = p(C)/p(C|u) (Fong et al. 2018; Zou et al. 2020). When we learn a variational distribution q(z|c), the variational sample weights can be computed as follows: where W(u, z) can be viewed as the density ratio estimation to decorrelate u and z for points in space u × Z. The detailed proof can be found in the appendix. In CAUSALMTA, we design a binary domain classiﬁer to help estimate W(u, z). Training data of the classiﬁer is generated cooperating with the encoder of VRAE. We label static user attributes with real latent representation {(u, z)}, z ∼ q(z|c) as positive ones, whereas samples with latent representationt sampled from standard normal distribution {(u, z)}, z ∼ p(z) as negative ones. We ﬁrst embed the user attributes into latent vectors and train a domain classiﬁer to ﬁt these samples: Now that we have p(L = 0) = p(L = 1), the density ratio estimation W(u, z) can be conducted as follows: W(u, z) =p(u, z|L = 0)p(u, z|L = 1)=p(L = 0|u, z)p(L = 1|u, z)(3) Using this formula, we can obtain the weights of all journeys, i.e., {w}. Causal Conversion Prediction After the generation of sample weights, CAUSALMTA utilizes them to train a trustworthy conversion prediction model. Besides the static attributes, the biases of prediction are also caused by dynamic user features. To mitigate them, we borrow the idea from CRN(Bica et al. 2020) and involve a gradient reverse layer to learn balancing representation. Due to the delay feedback problem, we reﬁne the structure of CRN to make it suitable for MTA. Formally, we ﬁrst reorganize the dataset. For each journey (u, J, y), we adopt one step offset on the channel sequence and ﬁll the blank position with a uniﬁed placeholder, i.e., C= {c, c}. CAUSALMTA takes Calong with other dynamic features F = {f}as the input and employs LSTM with the attention mechanism to obtain the trustworthy prediction: where e, e, vare the sequences of latent vectors. Once the output vectors are generated, we adopt them for two parallel processes. One for eliminating the bias of dynamic features, and the other for conversion prediction. {v}= MLP(GRL({out})) {c}= softmax({v}) where GRL is the gradient reverse layer that ensures out can not predict c. The loss function of causal conversion prediction consists of two parts, i.e., reverse channel prediction and conversion prediction: L= γCE(c, c) + δw· CE(v, y) where CE is the cross-entropy loss; γ and δ are hyperparameters; wis the learned journey weights. With the welltrained conversion prediction model, we can calculate the attribution credits of each touchpoint by constructing some counterfactual journeys. Attribution Credits Calculation CAUSALMTA computes Shapley values (Shapley 1953) for ad credits allocation. Based on assessing the marginal contribution of each player in the game, the Shapley value method is a general credit distribution method, and it has been widely used in MTA (Singal and etc. 2019; Yang, Dyer, and Wang 2020) due to its advantage of having an axiomatic foundation and catering to fairness consideration. Formally, let J\{p} denote the counterfactual ad journey by removing touchpoint p. S can be viewed as a subsequence of the counterfactual ad journey J\{p}. If we denote the result of causal conversion prediction for channel sequence Jas p(J), the Shapley values for ad exposure {c} can be deﬁned as SV=P |C|, |S| are the cardinalities of these sets. If SVis negative, we set it zero. Then we normalize all incremental scores for each ad exposure as follows, Algorithm 1: Learning procedure of CAUSALMTA. Input: The ad exposure dataset D, i.e., {(u, J, y)}; Output: Attribution credits {α}for touchpoints {a}. 1: # Generation model for channel sequences 2: for each journey (u, J, y) in D do rameters of VRAE model. 4: end for 5: # Weights estimation for ad journeys 6: for each ad journey (u, J, y) in D do tive samples respectively. 9: end for 10: Conduct density ratio estimation and calculate sample weights waccording to Eq.(2) and Eq.(3). 11: # Causal conversion prediction 12: for each ad journey (u, J, y) in D do rameters of conversion prediction model. 14: end for 15: # Calculation of Attribution Credits 16: for each ad journey (u, J, y) in D do 21: end for 22: return {{a}} where σ(x) = max(0, x) and aare the attribution credits of the corresponding ad exposures. The pseudo-code of CAUSALMTA is shown in Algorithm 1. Theoretical Analysis of CAUSALMTA Under the assumption of independence, we can decompose the overall confounding bias B into the bias introduced by user static attributes Band the bias introduced by dynamic user features B, i.e., B = B+ B. CAUSALMTA aims to obtain an unbiased prediction model and achieve B = 0. We prove that the confounding bias from static user attributes Bcan be mitigated by estimating sample weights wfor ad journeys. Formally, let Edenote the counterfactual prediction error, which is the target to be minimized. Unfortunately, Ecan not be directly measured on the observational dataset. We can derive the upper bound of E, which is given by B= E− E≤ IP M(W(u, C)p(u, C), p(u)p(C)) where Eis the prediction error on the re-weighted data and IP M denotes Integral Probability Metric. When W(u, C) =, the equation E= Ecan be proved. More details of the proof are available in the appendix. In dynamic settings, Bequals zero if we can prove that the learned representation removes the association between dynamic features and the ad exposure. We build Table 1: The overview of the Criteo dataset the representation vinvariant across different ad channels to eliminate biases caused by dynamic user features. We achieve this by minimizing the formula L=PP L= K · JSD(p(v|c), ..., p(v|c)) − K logK where KlogK is a constant, and JSD(·, ..., ·) denotes the multi-distribution Jensen-Shannon Divergence (Li et al. 2018), which is non-negative and 0 if and only if all distributions are equal. To minimize L, we derive p(v|c) = ... = p(v|c), where vis the learned representation invariant across different ad channels. For details, see the appendix. In this section, we evaluate the performance of CAUSALMTA and answer the following questions: • Q1: Does CAUSALMTA perform better than the stateof-the-art MTA methods on conversion prediction? • Q2: What are the capabilities of the journey reweighting module and the causal conversion prediction module? • Q3: Does CAUSALMTA work well on real ad impression dataset? Experimental Settings A conversion prediction task is employed to examine the performance of CAUSALMTA. In this section, we brieﬂy introduce the data description, evaluation metrics, compared baselines, and hyperparameter settings. More details of this part can be found in the appendix. Data Descriptions. The performance of CAUSALMTA is evaluated on two datasets, i.e., Criteo and Ad Impression of an E-commerce company. Criteois a public dataset on ad bidding and be widely used in MTA (Diemert et al. 2017; Ren and etc. 2018; Kumar et al. 2020). Following the same experimental setting of CAMTA(Kumar et al. 2020), we choose top-10 highly exposed channels and journeys containing more than 3 touchpoints. Ad Impression of an E-commerce Company contains the ad impression data of mobile phone shops in 30 days. These touchpoints are categorized into 40 channels, including interact, feed, display, search, live show, etc. Evaluation Metrics. For conversion prediction, we evaluate the performance in terms of log-loss, AUC. For fairness, the log-loss only contains the conversion prediction http://ailab.criteo.com/criteo-attribution-modeling-biddingdataset/ Table 2: Results of conversion prediction on Criteo dataset. SL, DL, CL in the left column indicate the statistical learning-based methods, deep learning-based methods and causal learning-based methods, respectively. Ours part of Equation 4. It can be reckoned as a standard measurement to estimate the classiﬁcation performance. AUC can be a metric reﬂecting the pairwise ranking performance of the estimation between converted and non-converted ad impression sequences. Compared Methods. In our experiments, CAUSALMTA is compared with 8 baseline methods which can be divided into three categories, i.e., statistical learning-based methods, deep learning-based methods, and causal learningbased methods. The statistical learning-based methods consist of three methods, i.e., Logistic Regression (Shao and Li 2011)(LR), Simple Probabilistic (Dalessandro et al. 2012) (SP), and Additive Hazard (Zhang, Wei, and Ren 2014) (AH). Deep learning-based methods contain three methods, i.e., DNAMTA (Arava et al. 2018), DARNN (Ren and etc. 2018), and DeepMTA (Yang, Dyer, and Wang 2020). The causal learning-based methods also have two works, i.e., JDMTA (Du and etc. 2019) and CAMTA (Kumar et al. 2020). Besides, we also compare CAUSALMTA with two ablation methods, i.e., CM-RW and CM-CAUSAL. Detailed descriptions of these methods are available in the appendix. Parameter Settings. For LSTMs in CAUSALMTA, we stack three 3 layer LSTMs as the encoder, decoder, and the predictor respectively. MLP models in CAUSALMTA are composed of 4 fully connected layers with ELU as the activate function. CAUSALMTA has 4 hyperparameters i.e., α, β, γ and δ, we empirically set α = β = 0.5, and γ = δ = 0.5. All the experiments are conducted on a highend server with 2× NVIDIA GTX3090 GPUs. All the compared baselines are trained in 30 epochs and the best model is chosen to report. Performance Comparison The detailed evaluation results on different baselines are presented in Table 2. As shown, CAUSALMTA continuously outperforms all the compared baselines, which proves the validity of eliminating the confounding bias on static user attributes and dynamic features. CAMTA is the strongest baseline but also inferior to CAUSALMTA. It utilizes click labels as the auxiliary information, which probably involves Figure 3: Learning curves and sample weight distribution on Criteo dataset. additional confounding bias. Moreover, CAMTA does not consider the difference between static and dynamic confounders, which would also harm the performance. One interesting phenomenon is CAUSALMTA has a more stable conﬁdence interval compared to other baselines. It indicates that the parameters in CAUSALMTA tend to converge to similar values with different initialization. To a certain extent, CAUSALMTA is more robust than other baselines. Comparing the performance of different categories of methods, we can observe that SL methods are inferior to the other two categories. SL methods either use statistical laws or employ logistic regression to predict the conversion probability, which can not well model the conversion process. DL methods perform better than the SL methods but are also inferior to the CL methods. It proves that the deep learning techniques are more suitable for conversion prediction due to their large parameter space and high ability to model complex tasks. However, these methods have poor performance compared to the CL methods. It is because deep learning methods directly use the observed data to train the prediction models, which are incapable of handling confounding bias and would suffer from the out-of-distribution problem. CL methods outperform other baselines with a large margin, which demonstrates the prediction performance highly increased by eliminating the confounding bias. Ablation Studies To explore the effectiveness of the journey reweighting and causal conversion prediction, we compare CAUSALMTA with two ablation methods, i.e., CM-RW and CM-CAUSAL, which remove the reweighting procedure and the gradient reverse layer respectively. We ﬁrst show the intermediate results of journey reweighting. The reconstruction accuracy of VRAE and the classiﬁcation accuracy of the domain classiﬁer directly inﬂuence the performance of CAUSALMTA. As shown in Figure 3, the reconstruction accuracy is approximate to 98%, and the classiﬁcation accuracy is approximate to 82%, which indicates that the VRAE and domain classiﬁer are well trained, and the results of journey reweighting are signiﬁcant. We also witness the reconstruction accuracy Figure 4: Performance comparison of ablation methods. ﬂuctuates at a high level as KL divergence dominates the training loss when the cross-entropy loss is small enough. We summarize the metrics of ablations in Table 2 and illustrate the training procedure in Figure 5. As shown, the AUCs of CM-RW and CM-CAUSAL are inferior to CAUSALMTA, which proves that both the journey reweighting and causal conversion prediction help improve the performance. By removing the journey reweighting model, the performance of CAUSALMTA decreases from 0.9659 to 0.9539. By removing the gradient reverse layer, the performance of CAUSALMTA decreases from 0.9659 to 0.9617. We can observe the improvement of gradient reverse layer(causal prediction) is more signiﬁcant than journey reweighting, which indicates the confounding bias of dynamic feature are more obvious than the static user attributes. This result is consistent with our cognition. Moreover, as illustrated in Figure 5, the convergence speed of CAUSALMTA is faster than CM-RW and CM-CAUSAL, which shows the superiority of CAUSALMTA in eliminating the confounding bias of user preferences. Empirical Applications in an E-commerce Company We evaluate the performance of CAUSALMTA on real applications in this section. In application, channel attributions of each shop are more meaningful to guide the budget allocation. We train the attribution models in the ﬁrst 15 days and use the last data for testing. We choose all of its converted journeys in the test set for one speciﬁc shop and compute the mean credits of 40 channels. After that, we employ two experiments, i.e., attribution improvement and ofﬂine data replay, to evaluate the performance of CAUSALMTA. Attribution Improvement. We compute the attribution credits of two representative cellphone shops utilizing CAUSALMTA and compare them with the credits calculated by an LSTM-based conversion prediction model. The comparison results are illustrated in Figure 5. As shown, the credits of search channels on both shops are decreased, indicating that the estimated contribution of search ads is reduced after eliminating the confounding bias of user preferences. This is because user tends to search the goods before paying. The attributions of the search channel are usually overestimated, and CAUSALMTA can mitigate this kind of bias. For different shops, the improvements are consistent with its budget allocation. After examining the total budget on each channel, we found Shop 1 spent more money on Live and Shop 2 spent more money on Display, which coincides with our attribution result. Figure 5: The comparison of attribution changes for two cellphone shops. Table 3: Proﬁt comparison of data replay. Ofﬂine Data Replay. In this experiment, we employ the attribution credits to guide the budget allocation. Based on the attribution credits, we ﬁrst compute the return-oninvestment (ROI) of each channel and utilize the normalized weights of ROI as budget proportion (Ren and etc. 2018). Assuming that the total cost of the test set is cost, we set the evaluation budgets as 1/2, 1/4, 1/8, 1/16 of cost and replay the historical data to select journeys satisfying evaluation budgets. Table 3 shows the comparison results of the proﬁt in each evaluation budget. We can observe that the proﬁt CAUSALMTA consistently outperforms the LSTM-based predictor on all evaluation budgets, which indicates that the attribution credits of CAUSALMTA reﬂect the causal relationships in advertising. It can be used to guide budget allocation and achieve better proﬁt. In this paper, we deﬁne the problem of causal MTA, which eliminates the confounding bias introduced by user preferences and assigns the attribution credits fairly over all touchpoints. To this end, we propose CAUSALMTA, which composes the confounding bias of user preferences into two independent parts, i.e., the static user attributes and the dynamic features. CAUSALMTA employs journey reweighting and causal conversion prediction to solve these two kinds of confounding bias respectively. We prove that CAUSALMTA is capable of generating unbiased conversion predictions of ad journey. Extensive experiments on the public dataset and real commercial data from an e-commerce company show that CAUSALMTA outperforms all the compared baselines and works well in the real-world application.