User interactions with recommender systems (RSs) are aected by user selection bias, e.g., users are more likely to rate popular items (popularity bias) or items that they expect to enjoy beforehand (positivity bias). Methods exist for mitigating the eects of selection bias in user ratings on the evaluation and optimization ofRSs. However, these methods treat selection bias as static, despite the fact that the popularity of an item may change drastically over time and the fact that user preferences may also change over time. We focus on the age of an item and its eect on selection bias and user preferences. Our experimental analysis reveals that the rating behavior of users on the MovieLens dataset is better captured by methods that consider eects from the age of item on bias and preferences. We theoretically show that in a dynamic scenario in which both the selection bias and user preferences are dynamic, existing debiasing methods are no longer unbiased. To address this limitation, we introduce DebiAsing in the dyNamiC scEnaRio (DANCER), a novel debiasing method that extends the inverse propensity scoring debiasing method to account for dynamic selection bias and user preferences. Our experimental results indicate thatDANCERimproves rating prediction performance compared to debiasing methods that incorrectly assume that selection bias is static in a dynamic scenario. To the best of our knowledge,DANCERis the rst debiasing method that accounts for dynamic selection bias and user preferences inRSs. • Information systems → Recommender systems; Evaluation of retrieval results. ACM Reference Format: Jin Huang, Harrie Oosterhuis, and Maarten de Rijke. 2022. It Is Dierent When Items Are Older: Debiasing Recommendations When Selection Bias and User Preferences Are Dynamic. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining (WSDM ’22), February 21–25, 2022, Tempe, AZ, USA. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3488560.3498375 User interactions with recommender systems (RSs) are subject to selection bias, as a consequence of the selective behavior of users and of the fact thatRSs actively restrict the items from which a user can choose [32,34,37,41,43]. A typical form of selection bias inRSs is popularity bias: popular items are often overrepresented in interaction logs because users aremorelikely to rate them [7,37,43]. Without correction, bias can aect user preference prediction [22,41,56] and lead to problems of over-specialization [1], lter bubbles [33,36], and unfairness [9]. To correct for selection bias in interaction data fromRSs, the task of debiased recommendation has been proposed. A widelyadopted method for this task makes use of inverse propensity scoring (IPS), a causal inference technique [24], and integrates it in the learning process of rating-prediction for recommendation [10,22,27,41]. It estimates the probability of a rating to be observed in the dataset, and inversely weights ratings according to these probabilities so that in expectation each user-item pair is equally represented. While the existingIPS-based debiasing method improves recommendations over methods that ignore the eect of bias, we identify two signicant limitations. The way thatIPS-based debiasing is being applied for recommendations assumes that (1) the eect of selection bias is static over time, and (2) user preferences remain unchanged as items get older. As we will show in Section 4, currentIPS-based methods are unable to debias recommendations when the selection bias and user preferences are dynamic, i.e., when they change over time. In practice, selection bias is usually dynamic, not static [9,26]. Typically, the popularity of an item changes with item-age [8,26], i.e., the time since its publication. Figure 1 shows the number of ratings items received as they get older in the MovieLens dataset (red line). On average, items receive the most attention during a short initial period of time after being published. Hence, instead of static selection bias, real-world user behavior may be better captured with dynamic selection bias that assumes dierent probabilities of observing user ratings at dierent item-ages. Besides selection bias, user preferences may also change over time [2,25,50]. In this paper, we will focus on the eect of item-age on user preferences, and thus, on capturing the change in user preferences as items become older. From Figure 1, it is clear that the average observed user rating varies with the itemage (blue line), despite the increased variance observed due to a decreasing number of logged interactions. We use the term dynamic scenario to refer to the combination of dynamic selection bias and dynamic user preferences occurring in a recommendation setting. In this paper we rst analyze real-world logged data to verify that the dynamic scenario is real: selection bias and user preferences are dynamic. The dynamic scenario poses a two-fold problem for existingIPS-based debiasing methods forRSs. First, they are not Figure 1: The number of ratings (indicative of popularity) and the average (observed) rating of items for dierent item-ages on the MovieLens-Latest-small dataset. unbiased in dynamic scenarios. Second, existing methods [7,41] for estimating static selection bias cannot be used to estimate dynamic selection bias. Hence, we propose and evaluate a debiasing method to account for dynamic selection bias and dynamic user preferences. All in all, we make a three-fold contribution: (1) an analysis and estimation of dynamic selection bias and dynamic user preferences in the MovieLens dataset; (2)DANCER: a general debiasing method that is adaptable for DebiAsing in the dyNamiC scEnaRio; and (3) time-aware matrix factorization (TMF)-DANCER: to our knowledge it is the rst recommendation method that corrects for dynamic selection bias and models dynamic user preferences. General Recommendation. Early work onRSs typically uses collaborative ltering (CF) to predict user ratings on items or make recommendations to users based on the feedback of similar users with similar behavior. It is customary to divide recommendation tasks into the rating prediction task with explicit feedback (e.g., user ratings) and the top-𝐾ranking task with implicit feedback (e.g., clicks). In this paper, we focus on rating prediction with explicit feedback. The traditional matrix factorization (MF) algorithm directly embeds users and items as vectors and models user-item interactions with an inner product [15,30]. Some recent work has used deep neural networks to improveCF, e.g., by using multi-layer perceptrons [12,19], convolutional neural networks [18], or graph neural networks [17,48]. While they signicantly improve recommendation accuracy [28], they ignore the eect of time. Time-aware Recommendation. Recently, a wide range of algorithms have been proposed that consider temporal information to improve RSs. Such methods are often classied as time-aware or sequenceaware recommendation methods. Sequence-aware recommendation methods focus on the sequential order of interactions and aim to capture a user’s short-term preferences [38]. Various deep learning methods have been applied to this task [38,59] such as recurrent neural networks [21,51,57], graph neural networks [52,54], and networks with attention [11, 23, 45]. We focus on time-aware recommendation methods [6] rather than sequence-aware recommendation methods, by considering changes in user preferences over exact time-periods. One of the best known examples is time-aware matrix factorization (TMF) [29], which takes the eect of time into consideration by adding time-dependent terms to theMFmodel, thus allowing predicted ratings to vary over time. Koren[29]lists and compares various variants ofTMF, in how well they can capture item-related or user-related temporal eects. Xiong et al. [53]propose time-aware tensor factorization (TTF): a factorization based model that uses additional latent factors for each time period based on a probabilistic latent factor model. Lastly, the eect of time is sometimes modelled by utilizing contextual attributes related to time (e.g., day of the week or season of the year) as input features for context-aware RSs [4, 6, 35, 47]. Debiased Recommendation. User selection bias is prevalent in logged data, meaning that many logged user ratings are missing not at random (MNAR) [20,32,41]. Two typical forms of bias inRSs are known as popularity bias and positivity bias. Popularity bias is characterized by a long tail distribution over the number of interactions per item in logged data because users are more likely to interact with more popular items [37,43]. Positivity bias leads to an over-representation of positive feedback because users rate the items they like more often [37]. The eect of these biases is generally dynamic: they can change drastically over time [9,26,58]. For instance, items are rarely popular for very extended periods of time, and therefore, we may expect a dynamic eect between the age of items and popularity bias. Existing debiasing methods for reducing the eect of selection bias addressMNARproblems as follows: (1) the error-imputation-based model (EIB) lls in missing ratings with predicted values, which may introduce bias due to inaccurate predictions [42], (2) inverse propensity scoring (IPS) weights the loss associated with each observed rating inversely to their propensity, i.e., the probability of observing that rating [10,27,41], and (3) the doubly robust (DR) method integrates theEIBandIPSapproaches to overcome the high variance of IPS and the potential bias of EIB [49]. While the impact of dynamic bias has previously been pointed out [26,58], no prior debiasing method considers a scenario in which both selection bias and user preferences change over time. All existing debiased recommendation methods assume a static eect of selection bias regardless of whether they model dynamic user preferences. Hence, there is currently no method that can eectively correct for bias in the dynamic scenario. This is the research gap that we address. We follow the commonRSsetting where items from the setI = {𝑖,...,𝑖}arerecommended to users fromthe setU = {𝑢,...,𝑢}[44]. Users have preferences towards items, generally modelled by a label 𝑦(e.g., a rating𝑦∈ {1,2,3,4,5}) per user𝑢 ∈ Uand item𝑖 ∈ I. Similar to time-aware recommendations [6,29,53], we also consider the eect of time on user preferences: letT = {𝑡,...,𝑡}be a set of𝑇 time periods; we allow the user preference𝑦to vary over dierent periods𝑡 ∈ T. Our goal is to optimize anRSthat best captures the user preferences across all items𝑖and time periods𝑡. We formulate this goal as a loss function: letˆ𝑦be a predicted rating by theRS and𝐿(ˆ𝑦,𝑦)a comparison function between the predicted rating and actual rating. Then our loss is: The function𝐿can be chosen according to commonRSmetrics, for example, the prevalent Mean Squared Error (MSE) metric: The choice forRSs to perform well across all time periods𝑡inTis partially made for practical reasons; arguably, at any particular time one only needsRSs to perform well for the present and future [25]. However, in practice, data is only available about past user preferences, thus making optimization w.r.t. future preferences infeasible. Moreover, we expect that ifRSs’ performance generalizes well across the time periods inT, it likely also generalizes well into the near future. In our setting, logged interaction data is available to provide user ratings that can be used for optimization. However, it is unrealistic for all users to provide ratings for all items. In practice user interaction data is very sparse. We will use an observation indicator matrix O ∈ {0,1}that indicates what ratings are recorded in the logged interaction data and during which time period. We use 𝑜∈ Oto indicate this per rating:𝑜=1 indicates that the rating for user𝑢on item𝑖during time period𝑡has been recorded in the logged data, and𝑜=0 that it is missing. The matrixOis strongly inuenced by selection bias: certain ratings are much more likely to be observed than others. This can be due to self-selection bias: users choosing to rate certain items more often [37,43]; or algorithmic bias: theRSused for logging choosing to show certain items more often [3,14]. Well-known prevalent biases inRSdata include: (1) popularity bias [37,43] – often a small group of popular items receive most interactions; and (2) positivity bias [37] – users are usually more likely to rate items they prefer. We model selection bias using the probability of a rating being recorded:𝑝= 𝑃 (𝑜=1), which we also refer to as the observation probability or propensity. Again, we deviate from the common existing method by explicitly allowing𝑝to vary over dierent time periods𝑡. This enables our method to not only model a bias such as popularity bias but also how that bias changes as items get older and decline in popularity. Before we introduce our recommendation method for dealing with the dynamic scenario in which both selection bias and user preferences are dynamic, we will show that, in a dynamic scenario, the existing recommendation methods that either assume no bias or static bias are not unbiased. The standard estimation of how well the predicted user preferences reect the true user preferences shown in Eq. 1 is the full-information loss (i.e., the loss based on all the ratings), which is impractical since user preferences are only partially known in the logged data. The naive loss ignores the eect of selection bias completely and thus assumes that the observed data represents the true user preferences unbiasedly. Under this assumption, the naive loss can be estimated by a simple average on the observed ratings: And the widely-used debiasing method usesIPSestimation [24,31] to correct for the probability that a user rates an item [41]. It uses static propensities𝑝that are the probability of observing a rating for item 𝑖by user𝑢in any of the time-periods [32,39]. These propensities ignore the dynamic aspect of selection bias, i.e., that these probabilities can vary per time period 𝑡 , resulting in the static IPS estimator: Now that we have described the naive and static IPS-based loss functions for recommendation (that assume no bias and only static bias, respectively), we can consider the eect of dynamic selection bias. Ignoring dynamic selection bias, the recommendation methods that use the naive or static IPS estimation are not unbiased in dynamic scenarios. To illustrate how this may happen, we use a simple exampleXwith one user𝑢, one item𝑖and two time periods𝑡and𝑡. Let 𝑦and𝑦be the user ratings on the item at𝑡and𝑡respectively; 𝑝and𝑝denote the probabilities of observing the ratings at𝑡and 𝑡, respectively. We omit the subscript of𝑢and𝑖if no confusion can arise. Due to dynamic user preferences and dynamic selection bias, the user ratings and observation probabilities are not constant over the dierent time periods:𝑦≠𝑦, 𝑝≠ 𝑝.Remember that in this example the loss we wish to estimate is: The expected naive loss over the observation variables becomes:hi Clearly, it is not proportional to the true lossLwhen selection bias and user preferences are dynamic: if𝑦≠𝑦and𝑝≠ 𝑝, then EL̸∝ L. This happens because the rating with the higher probability of being observed is over-represented in the observations. Then the staticIPS-based debiasing method uses static propensity 𝑝= 𝑝+(1−𝑝)𝑝that is the probability of observing a rating at time 𝑡or 𝑡. If we consider the expected value of this estimator: we see that it is not proportional to the true loss in the dynamic scenario: if𝑦≠𝑦and𝑝≠ 𝑝, thenEL̸∝ L, because the static IPS estimation fails to address the problem that the user’s rating at a time with a higher probability of being observed is more likely to be represented in logged data than at any other time. We note that the above counterexample holds regardless of whether the prediction of user ratings allows for dynamic preferences, i.e., Our example is overly simplistic as it only contains a single user and a single item and two time periods; however, it can trivially be extended to any number of items, users or time periods. Thus, it is a signicant problem forRSs that optimization with the naive or staticIPS is not unbiased if both the user preferences and the selection bias are dynamic; it will lead to biased optimization. Selection bias and user preferencesare practically never static in the real-world; in support of this claim, Sections 7 and 8 provide evidence that the dynamic nature of bias and preferences can be observed in the MovieLens dataset. We introduceDANCER, a method for DebiAsing in the dyNamiC scEnaRio. We applyDANCERto time-aware matrix factorization (TMF), resulting in a novel rating prediction method that corrects for dynamic bias and models dynamic preferences. We introduce a propensity estimation method to estimate the probabilities of ratings being observed per time period. As discussed in Section 4, existing debiasing methods that use the naive or static IPS estimation are unable to debias in the dynamic scenario where selection bias and user preferences are both dynamic. As a solution, we proposeDANCER. With accurate propensities𝑝, dynamic selection bias can be fully corrected by applyingDANCER to inversely weight the evaluation of the predicted ratings: Unlike the naive approachL(Eq. 3) and the static IPS approach with a static estimatorL(Eq. 4), the proposed debiasing method Lis unbiased in the dynamic scenario: BecauseDANCERutilizes propensities that vary per time period𝑡, it can correct for dynamic eects of bias that the existing static IPS estimators cannot. For instance, in our exampleXwith a user, an item and two time periods (see Section 4), the expectedDANCERloss becomes: where we can see thatLis an unbiased estimation of the true lossL. Combined with a time-aware recommendation method, DANCER is able to predict that the user ratings change over time. Because we expect both selection bias and user preferences to change over time in a dynamic scenario, the rating prediction that is optimized byDANCERshould also be able to account for changes in user preferences. WhileDANCERis not model specic, we will apply it to a time-aware matrix factorization (TMF) [29] model that accounts for temporal eects. We refer to this combination ofTMFand debiasing method asTMF-DANCER. Given an observed rating𝑦 from user𝑢on item𝑖at time𝑡,TMFcomputes the predicted rating are embedding vectors of user𝑢and item𝑖, and𝑏∈ R,𝑏∈ R, and 𝑏 ∈ Rare user, item and global osets, respectively. Crucially,𝑏is a time-dependent oset and models the impact of time in rating prediction. Under this model, the proposedTMF-DANCERis optimized by minimizing the following loss: where𝑷,𝑸and𝑩denote the embeddings of all users, all items and all the oset terms, respectively; 𝛿 is the MSE loss function. DANCERrequires accurate propensities𝑝to remove the eect of dynamic selection bias. Because it is the rst method to consider dynamic selection bias inRSs, it thus also needs a novel method to estimate𝑝= 𝑃 (𝑜=1), i.e., the probability that the rating for user𝑢and item𝑖is observed at time𝑡. We propose to apply a Negative Log-Likelihood (NLL) loss to the propensity estimatesˆ𝑝and the observations made in a dataset (indicated by 𝑜): where the function 𝐿is the NLL for each individual propensity: Due to the large number of estimated propensitiesˆ𝑝, we argue that it is best to predict them with a model. Similar to the rating prediction task,TMFandTTF[53] are potential choices to model how the propensities vary over users, items and time periods. Alternatively, one can also make simplifying assumptions in the estimations of dynamic popularity bias. For instance,ˆ𝑝= Pop(𝑖,𝑡):= uses the ratio of ratings received by item𝑖at time𝑡. ThePop(𝑖,𝑡) estimate is easy to compute, but it does assume that there are no dierences between users when it comes to providing ratings. Finally, we note that our proposed propensity estimation method Eq. 12 builds on existing methods for propensity estimation for static selection bias. Saito et al. [40]useMFinstead ofTMForTTF. Similarly, thePop(𝑖):=is a common way to measure (static) popularity bias [7,13,58]. Our propensity estimation method makes these methods applicable to the dynamic scenario, and enables them to provide propensities for the DANCER debiasing method. In our experiments, we focus on the age of an item (item-age) and the dynamic eect it has on selection bias and user preferences. From this point onwards, our notation will use𝑡to denote how long an item has been available in the system, we will refer to this as the age of the item. Because the distribution of ratings is very skewed towards young items, we divide the item-ages into seven bins whose edges are [0,1,3,5,8,11,15,∞]in years. For instance, a rating on an item when it is two-and-a-half years old will be assigned to𝑡 =2, and a rating when it is 15 years old will be assigned𝑡 =7. This can be interpreted as a specic choice for the time periodsTand thus does not change any of the previously stated theory. We rst wish to investigate whether real-world selection bias and user preferences are aected by item-age – and are thus dynamic – and whetherTMF-DANCERis more eective in a dynamic scenario than existing rating prediction methods that do not consider dynamic bias. Our experimental analysis is organized around three researchquestions: (RQ1) Does item-age aect selection bias present in logged data? (RQ2) Does item-age aect real-world user preferences? (RQ3) Does the proposedTMF-DANCERmethod better mitigate the eect of bias in the dynamic scenario than existing debiasing methods designed for static selection bias? To answer these questions, we make use of three dierent tasks based around the MovieLensLatest-small dataset [16]. The following sections will each introduce one of these tasks and answer the corresponding research question. All tasks use embeddings with 32 dimensions, hyperparameter tuning is applied per method and task in the following ranges: learning rate𝜂 ∈ {10,...,0.1}and𝐿regularization weights𝜆 ∈ {0,10,10, ... ,1.0}. Our implementation and hyperparameter choices are available at https://github.com/BetsyHJ/DANCER. To answerRQ1: Does item-age aect selection bias present in realworld logged data?, we will evaluate whether methods that consider item-age can better predict which items will be rated than methods that do not. If item-age has a large eect on selection bias, it should be an essential feature for predicting whether users will rate an item. The goal of our rst task is to predict which ratings will be observed in real-world data, in other words, across users𝑢, items𝑖and itemages𝑡the aim is to predict the observation𝑜variables. Withˆ𝑝 as the predicted probability of observation, the metrics for this task are the NLL (Eq. 13) and Perplexity (PPL): 2. (14) To evaluate whether item-age has a signicant eect on the observation probabilities – and thus the dynamic selection bias in the data –, we compare the performance of observation prediction methods that assume static bias with others that take item-age into account. Our comparison contains three baselines, one static method and four time-aware methods; when specifying the methods, we use𝜎to denote the sigmoid function,𝒑for a learned user embedding,𝒒for an item embedding, 𝒂for an embedding representing an item-age, and 𝑏is a learned parameter that varies per item-age 𝑡. (1) Constant: The fraction of all ratings, this assumes no selection bias is present:ˆ𝑝=. (2) Static Item Popularity (Pop): The fraction of all ratings that have been given to the item; this assumes that selection bias is static over users and time:ˆ𝑝=. (3) Time-aware Item Popularity (T-Pop): The item popularity per item-age; dened as the fraction of all ratings that have been given to item 𝑖 of age 𝑡:ˆ𝑝=. (4) Static matrix factorization (MF): A standardMFmodel that assumes selection bias is static:ˆ𝑝= 𝜎 (𝒑𝒒). (5) Time-aware matrix factorization (TMF)[29]:TMFcaptures the drift in popularity as items get older by adding an agedependent bias term:ˆ𝑝= 𝜎 (𝒑𝒒+𝑏). (6) Time-aware tensor factorization (TTF)[53]:TTFextends MFby modelling the eect of item-age via element-wise multiplication:ˆ𝑝= 𝜎 (𝒑(𝒒×𝒂)). (7) TTF++: We propose a variation onTTFthat models the eect via summation instead:ˆ𝑝= 𝜎 (𝒑(𝒒+𝒂)). (8) Time-aware matrix & tensor factorization (TMTF): Lastly, we propose a novel integration ofTMFwithTTF++:ˆ𝑝= All models are optimized with theNLLloss as described in Section 5.3. We split the dataset into training, validation and test partitions following a ratio of 7:1:2. The MovieLens-Latest-small dataset [16] consists of 100,836 ratings applied to 9,742 movies by 610 users between 1996 and 2018. We apply two splitting strategies to the data: (1) a time-based split that per user places the latest 20% of their ratings into the test set [6]; and (2) a random split that uniformly samples 20% of ratings per user. The time-based split is more realistic but makes the training and test data follow dierent distributions: i.e., there will be more ratings on younger items in the training set than in the test set. Alternatively, the random split ensures both partitions follow the same distribution but is less realistic: i.e., ratings in the test set may have taken place before ratings in the training set. For both settings, the training and validation set are uniformly randomly sampled from the data outside the test set. Since most users have an active lifecycle of less than one year, the time-based split results in a ratio between observed and missing ratings that is four times higher Table 1: RQ1 – Performance in observation prediction. Results are averages of 10 independent runs, the standard deviations are shown in brackets. † indicates a signicant improvement overMF (𝑝 <0.01) according to the paired-samples t-test. TTF++ 0.0632 than the ratio in the test set; to account for this large dierence in distributions we scale the predictedˆ𝑝by 0.25 in this setting. This leads to considerable performance improvements for all methods. Lastly, we ignore ratings outside of the user’s presence in the dataset, i.e., before their rst rating or after their last; this prevents the methods from having to predict when users became active so that they can focus on the eect of item-age. The results for the rst task are presented in Table 1. Clearly, under both splitting strategies, the time-aware methodsTMF,TTF++ and TMTFare signicantly more accurate thanPopandMF, which assume that selection bias is static, whileMFoutperforms Constant, which assumes no bias. Interestingly, T-Pop performs worst among all the methods, probably due to the high variance caused by sparsity. Under the random splitting strategy,TTFandTTF++ outperform TMF, whileTMTFoutperforms all other methods. Thus it appears that modelling item-age via a learned embedding better captures its eect than a single learned parameter, but moreover,TMTFshows us that combining both results in the most accurate method. Under the time-based splitting strategy,TMFperforms slightly better than TTF++ andTMTF, whileTTFperforms worse than them. Also,Pop performs worse than Constant. A plausible reason for this inconsistency is the dierence in distribution between the training and test set caused by the time-based split. The number of ratings per year displayed in Figure 2 displays this dierence. This suggests that TMFis more robust to dierences in distribution and that the other methods are somewhat overtted on the training set. Nevertheless, most time-aware methods still predict the selection bias signicantly better than the static MF. We thus conclude that time-aware methods can better predict selection bias in real-world data than static methods. While the skewed rating distribution in Figure 1 already suggests that item-age has a large inuence, our experimental results strongly show that item-age is an essential factor for accurately capturing the selection bias in users’ rating behavior. Consequently, we answerRQ1armatively: item-age signicantly aects the selection bias present in real-world data. This result strongly implies that the assumption of static bias in previous work is incorrect, at least in recommendation settings similar to that of the MovieLens dataset. To answerRQ2: Does item-age aect real-world user preferences?, we compare rating prediction methods that assume preferences are static with ones that allow for dynamic preferences. If item-age has a signicant eect, the latter group should perform better. The average rating per item-age in Figure 1 does not reveal a clear inuence from the item-age on rating behavior. However, the averages should not be taken at face value because they are subject to selection bias. Users are generally more likely to rate movies they like (i.e., positivity bias [37]), thus it is possible that while the true average rating drops, the observed remains stable due to selection bias. To nd out whether item-age has a substantial eect, we compare methods that assume static preferences with others that allow for dynamic preferences in terms of the Mean Squared Error (MSE), Mean Absolute Error (MAE) and Accuracy (ACC) metrics. We train and evaluate in two settings: (1) in the observed setting the dataset is used without any corrections to mitigate selection bias; and (2) in the debiased setting self-normalized inverse propensity scoring (SNIPS) [46,55] is applied during training and metric calculation to mitigate the eect of selection bias. The advantage of the debiased setting is that – in expectation – it bases evaluation on the true rating distribution; however, it has drawbacks: it requires accurate propensities and can be subject to increased variance. The observed setting will provide biased estimates but does not have these drawbacks. Our evaluation considers both settings so that their advantages can complement each other. The comparison includes two baselines: (1) Static Average Item Rating (Avg): The average observed rating across all item-ages:ˆ𝑦=. (2) Time-aware Average Item Rating (T-Avg): the average observed rating per item-age:ˆ𝑦=. In addition, we also compare with the staticMFand the time-aware TMF,TTF,TTF++ andTMTF. These methods are analogous to those used in Section 7; the main dierence is that for this task the𝜎sigmoid function is not applied. Additionally, we add a global oset 𝑏, a user oset𝑏, and an item oset𝑏toMF,TMFandTMTF. All methods are optimized to minimizeMSE; in the debiased setting optimization is performed withDANCERfollowing Section 5. We use the propensity values estimated for the previous observation prediction task by TMTF under the random-split (see Section 7.1). The dataset is again partitioned into a training, validation and test set according to a ratio of 7:1:2. Unlike for the previous task (Section 7.1), the data for this task only consists of observed ratings, and furthermore, the partitioning is only made via uniform random sampling. As displayed in Figure 2, we nd that a time-based split leads to extremely dierent rating distributions. This makes it infeasible to obtain convincing conclusions from the results of this task. Nevertheless, because a random split is perfectly suitable for evaluating a possible relationship between user preferences and item-age, our results are completely appropriate to answer RQ2. Table 2 displays the evaluation results for the second task; in both settings the time-aware methods outperform the staticMF. There Figure 2: Average rating and number of ratings over item-age inthetime-basedpartitionedtraining(left)andtestset(right). is a single exception:TTFperforms worst in both settings, probably due to over-tting. The dierences between the other time-aware methods and static MF are larger in the debiased setting than in the observed setting. This suggests that selection bias in the data reduces the dynamic eect of item-age on the observed ratings. We speculate that the eect of positivity bias could increase with item-age: users are less likely to try and rate movies that are older unless they already expect to enjoy them. Due to sparsity, T-Avg performs worse than Avg in both settings. Interestingly, Avg performs even better than MFin the debiased setting; this conrms prior observations that Avg is more robust in highly biased scenarios [7]. Regardless, in both settings most time-aware methods signicantly outperform MF and the two baselines, and therefore, we answerRQ2in the armative: item-age has a signicant eect on user preferences. Our conclusions for RQ1 and RQ2 indicate that the dynamic scenario, where selection bias and user preferences change over time, better captures real-world logged data, than a static view. Moreover, Section 4 showed that the existing static IPS approach cannot debias in this scenario. Consequently, our answers to RQ1 and RQ2 reveal a real need for a method that can deal with the dynamic scenario. Section 4 showed that the staticIPS-based debiasing method is biased in a dynamic scenario. Subsequently, in Section 7 and 8 we discovered that selection bias and user preferences in the MovieLens dataset are indeed dynamic. Therefore, we can already conclude that theoreticallyTMF-DANCERis the rst method that is potentially unbiased for the dynamic scenario. Our nal research question considers whether this theoretical advantage translates into improved recommendation performance:RQ3: Does the proposedTMF-DANCER method better mitigate the eect of bias in the dynamic scenario than existing debiasing methods designed for static selection bias? The most common technique for evaluating debiasing methods for recommendation, without actual deployment to real-world users, makes use of unbiased test sets [41,49]. This requires a dataset that has a training set consisting of biased logged ratings and a test set of user ratings on uniformly randomly selected items. Such a test set can be created by randomly sampling items and asking users to provide a rating for them, thus avoiding the selection bias that usually heavily aects what items are rated. However, the publicly available datasets that meet this criterion – Yahoo!R3 [32] and Coat Shopping [41] – lack any form of temporal information.As a result, we cannot apply DANCER or any other form of dynamic debiasing to them. Table 2: RQ2 – Performance comparison of dierent methods in predicting ratings logged in MovieLens-Latest-small. † indicates that the improvement of the models over MF is signicant (𝑝 < 0.01). ↑/↓indicates whether larger or smaller values are better. As an alternative to using real-world datasets, we utilize a semisynthetic simulation based on a real-world dataset for our evaluation. This simulation rst estimates a simulated Ground Truth (sim-GT) based on the actual dataset, and then generates a new biased training set from thissim-GT. Debiasing methods can be applied to the generated training set and evaluated on thesim-GT, since in this setting, the debiased estimates should match thesim-GTas close as possible. The creation of our semi-synthetic simulation has three steps: (1)First, we estimate the complete rating matrix using theTMF method, which simply uses an age-dependent bias term to model the dynamics of user preferences, thus making the simulation understandable and not prone to overtting. This provides us with an estimated rating for each item, user and item-age combination which we will treat as thesim-GT. By optimizingTMF with the real user ratings in the debiased setting, we hope the sim-GT reects the real-world scenario as closely as possible. (2)Second, dynamic selection bias is simulated usingMFto model the interactions between items and item-ages. Following Section 7, we t the following model:𝑝= 𝜎 (𝒒𝒂), to predict if the ratings are observed in the MovieLens dataset. To mimic real-world dynamic popularity bias more closely, we follow the user presence of the original dataset: propensities are zero before a user’s rst rating and after their last rating in the dataset, we also normalize the predicted probabilities so that their mean value is 4%, the same value as the dataset has. (3)Third, to prevent overlap between the training and test set, we utilize both random and time-based splitting: per user, 50% of items are randomly selected for the test set, and a split timestep is chosen at 80% of the user presence. The test set consists of allsim-GTratings on the randomly selected items at the last presence of each user; as a result, the test set reects future preferences on previously unseen items. The training set uses the other 50% of items per user and samples from the ratings before the split timestamp following the estimated propensities𝑝 from the previous step. The result is a training set where due to dynamic selection bias only∼2% of the𝑦ratings are observed. Figure 3 compares the original MovieLens dataset with our semisynthetic simulation. The popularity of items, in terms of how many ratings they receive, is closely approximated by the simulated training set. In terms of average rating, there is some deviation from the simulated training set and MovieLens: the simulated training set rates older items lower than MovieLens. It seems likely that this is the result of positivity bias, which is not part of our simulation. Figure 3: RQ3 – The proportion of ratings and the average rating of items over item-age on MovieLens, the simulated training set (sim-train) and the simulated Ground Truth (sim-GT). Nonetheless, we clearly see that both dynamic selection bias and dynamic user preferences are represented in our simulation. We compare the performance ofTMF-DANCERwith the following baselines: (1) Four methods that ignore bias altogether: Avg, T-Avg,MFandTMF(see Section 8). (2) Two methods optimized with the static IPS estimator:MF-staticIPS [41] andTMF-staticIPS, which use the Static Item Popularity propensities from Section 7. (3) A static preference method with dynamic debiasing:MF-DANCER, which optimizes a (static)MFwhile correcting for the eect of dynamic bias. Finally, to evaluate whetherTMF-DANCERis robust to misspecied propensities, we compare its performance with using TimeAware General Popularity (TG-Pop):ˆ𝑝=, and Time-aware Item Popularity (T-Pop) (see Section 7.1). The main results of our comparison are displayed in Table 3. Based on the displayed results we can make four observations: (1) The average methods (Avg and T-Avg) perform considerably worse than all other methods. Clearly, matrix factorization is preferable over averaging baselines. (2) The time-based methods outperform their static counterparts by substantial margins: TMF≻MF, TMF-StaticIPS≻ MF-StaticIPS, and TMF-DANCER≻MF-DANCER, except T-Avg≺ Avg due to sparsity. This shows that assuming static preferences can substantially hurt the performance of a method when user preferences are actually dynamic. (3) The debiased methods increase performance: MF-DANCER≻MF andTMF-DANCER≻TMF-StaticIPS ≻TMF. There is a single exception:MF ≻ MF-staticIPS under the assumption of static bias. This surprising observation shows that DANCERis more robust to certain dynamic scenarios. (4) Finally, the best performing method is TMF-DANCER, which both models dynamic preferences and is debiased under the assumption of dynamic selection bias. While it is not a surprise that this method Table 3: RQ3 – Performance of TMF-DANCERcompared with dierent methods. † indicates that the improvement of TMFDANCERoverallthebaselinesissignicantatthelevelof0.01. TMF-DANCER 0.1045 Table 4: RQ3 – Performance of TMF-DANCER with estimated propensities and the (simulated) ground truth propensities. Ground Truth 0.1045 (0.0014) 0.2444 (0.0018) 0.6151 (0.0039) performs well in the scenario that it assumes, the dierences with other methods are considerable and statistically signicant. In addition, Table 4 displays the performance of TMF-DANCER using dierent propensities. We see that with estimated propensities the performance of TMF-DANCER is comparable to when it is using the actualsim-GTpropensities. Moreover, TMF-DANCER outperforms the most baselines, exceptTMF-StatisIPS, even when using simple time-aware propensity estimation. To better understand the improvements of TMF-DANCER, Figure 4 shows the average predicted rating from dierent methods across item-ages and the actual average rating. The MF methods are unable to model changes in ratings as items get older; the dierences in the average ratings are purely caused by dierent item distributions: i.e., items that become available later in the dataset will never achieve the oldest item-ages. The TMF methods better capture the overall trend. TMF without debiasing consistently overestimates ratings; TMF-staticIPS reduces overestimation by correcting for static bias; the overestimation becomes worse for older items in both models. Instead, TMF-DANCER approximates the actual average rating at each item-age; its accuracy is quite consistent over time. Lastly, to get more insights into the behavior of TMF-DANCER, Figure 5 shows the propensities and (predicted) ratings per item-age and averaged across users for two handpicked movies. We observe thatTMF-DANCERoutperformsTMF, especially when the popularity of items decreases as items get older. Finally, we can answerRQ3in the armative: theTMF-DANCER method better mitigates the eect of bias in a dynamic scenario than existing debiasing methods designed for static selection bias. This conclusion still holds when propensities are estimated, and the accuracy of TMF-DANCER is consistent across item-ages. In this paper, we considered the dynamic scenario in recommendation where selection bias and user preferences change over time. Our experimental results revealed that in the real-world MovieLens Figure4: RQ3 – Averagerating on items predicted by dierent models over the item-age. Figure5:RQ3–Averagepropensitiesandpredictedaveragerating overitem-age of the very p opular movie “Mad Max (1979)” and the less popular “Kid in King Arthur’s Court (1995)”. dataset: (1) selection bias changes as items get older, and (2) user preferences are also aected by the age of items. Therefore, it appears that the dynamic scenario better captures the real-world situation, and thus, poses a serious problem that existing static IPS-based method cannot correct for dynamic bias in dynamic scenarios. As a solution, we proposed the DANCER debiasing method that takes into account the dynamic aspects of bias and user preferences, the rst method that is unbiased in the dynamic scenario. The results on a semi-synthetic simulation based on the MovieLens dataset showed that TMF-DANCER provides signicant gains in performance that are consistent across item-ages and robust to misspecied propensities. Our ndings about the dynamic scenario have implications for state-of-the-art recommendation methods, as they are strongly aected by dynamic selection bias. With theDANCERdebiasing method, RSs can now be expanded to deal with dynamic scenarios. A limitation of our work is that we only considered the rating prediction task and the eect of item-age on bias and preferences; future work should consider the ranking task and look at other aspects of time, e.g., seasonal eects, weekday, time of day, etc. This research was partially supported by the Netherlands Organisation for Scientic Research (NWO)under project number 024.004.022 and the Google Research Scholar Program. All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors.