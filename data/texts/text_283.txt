Abstract—Item recommendation based on historical user-item interactions is of vital importance for web-based services. However, the data used to train a recommender system (RS) suffers from severe popularity bias. The item frequency distribution is a highly skewed long-tail distribution. Interactions of a small fraction of popular (head) items account for almost the whole training data. Normal training methods from such biased data tend to repetitively generate recommendations from the head items, which further exacerbates the data bias and affects the exploration of potentially interesting items from niche (tail) items. In this paper, we explore the central theme of long-tail recommendation. Through an empirical study, we ﬁnd that head items are very likely to be recommended due to the fact that the gradients coming from head items dominate the overall gradient update process, which further affects the optimization of tail items. To this end, we propose a general framework namely Item Cluster-Wise Multi-Objective Training (ICMT) for longtail recommendation. Firstly, the disentangled representation learning is utilized to identify the popularity impact behind useritem interactions. Then item clusters are adaptively formulated according to the disentangled popularity representation. After that, we consider the learning over the whole training data as a weighted aggregation of multiple (item) cluster-wise objectives, which can be resolved through a Pareto-Efﬁcient solver for a harmonious overall gradient direction. Besides, a contractive loss focusing on model robustness is derived as a regularization term. We instantiate ICMT with three state-of-the-art recommendation models and conduct experiments on three real-world datasets. Experimental results demonstrate that the proposed ICMT signiﬁcantly improves the overall recommendation performance, especially on tail items. Codes will be open-sourced. Recommender systems are emerging as a crucial role in online services and platforms to address the problem of information overload [1]–[3]. A recommender system (RS) is trained using historical user-item interactions with the target of providing the most interesting items given the current user state. However, there is a self-loop in the training of a RS [4]. The exposure mechanism of the RS affects the collection of user-item interactions, which are then circled back as the training data for the RS itself. Such self-loop leads to severe popularity bias in the training data. Speciﬁcally, the item frequency distribution in the training data is an extreme long-tail distribution [5]. A small fraction of popular (head) items accounts for almost the whole training dataset. Normal learning-to-rank methods [6] based on such biased data would lead to a situation that head items are pushed towards much higher ranking scores compared with other items. As a result, popular items are repetitively recommended, which further intensiﬁes the popularity bias and the “rich get richer” Matthew effect [4]. Nevertheless, the recommendation from tail items plays an important role in improving the system performance. From the user’s perspective, he/she could be easily bored with the repetitive popular recommendation. There are potentially relevant items that will lead to larger user satisfaction among tail items [7], [8]. For service providers, the recommendation from tail items can embrace more marginal proﬁt compared with head items [9]. Generally speaking, the recommendation task is a typical exploitation-exploration problem. Long-tail recommendation will beneﬁt both users and service providers with better exploration, which ﬁnally turns into larger proﬁts in the long-run [10]. Existing methods that focus on long-tail recommendation are usually based on metrics like recommendation diversity and novelty [11]–[13]. However, these metrics are infeasible to directly optimize. Recommendations based on promoting such metrics could lead to a huge sacriﬁce of accuracy [14]. Besides, the deﬁnition of diversity or novelty is still an open research problem without a standard benchmark [15]. In this paper, we analyze the popularity bias problem of RS from an optimization perspective. We conduct an empirical study on the Gowalladataset. We train the state-of-the-art LightGCN [16] model on this dataset. Figure 1(a) visualizes the norm (i.e., Lnorm || · ||) of gradients coming from different items. Figure 1(b) shows the gradients from a popular item iand two tail items i, iin the dataset. We can have the following observation: items, indicating that the overall gradient direction is actually dominated by head items. from head items and tail items. That is to say, updating model parameters based on gradients dominated by head items could potentially scarify the learning of tail items. Motivated from the above observation, we propose Item Cluster-Wise Multi-Objective Training (ICMT) for long-tail recommendation to address the popularity bias. Note that ICMT is a general learning framework and can be instantiated with different speciﬁc models, such as Probabilistic Matrix Factorization (PMF) [17], NeuMF [3], etc. More precisely, in the ﬁrst place, a universal popularity embedding is involved in the ranking score prediction. This popularity embedding is then disentangled from user interest embedding for the modeling of popularity impact. Based on the disentangled representations, we split items into different clusters according to their correlation with the popularity embedding. We then consider the learning on each item cluster as an optimization objective. As a result, the learning over the whole training data can be seen as a weighted aggregation of multiple cluster-wise objectives. Then we utilize a Pareto-Efﬁcient (PE) solver to adaptively learn the weight of each objective. Through the PE solver, we can ﬁnd a solution that every cluster-wise objective is optimized without hurting the other one. In other words, the learning of head items would not affect the learning of tail items. Finally, a contractive loss focusing on model robustness is introduced as a regularization term to further prevent the potential overﬁtting of head items. To summarize, this work makes the following contributions: from an item cluster-wise optimization perspective. We show that head items are high likely to be recommended due to the domination of gradients, providing new directions to address the popularity bias of RS. work ICMT which is featured with popularity disentanglement, cluster-wise multi-objective optimization, and robust contractive regularization. mendation models and conduct experiments on three real-world datasets. Experimental results demonstrate that ICMT signiﬁcantly alleviates the popularity bias problem in recommender systems. Due to the popularity bias and the exposure mechanism of RS, tail items usually have much less training data. As a result, generating recommendations from head items is a conservative but effective way to improve recommendation accuracy (e.g., recall) [8]. To get rid of the conformity inﬂuence, some existing methods argue that other metrics like diversity [18]–[20] and novelty [13], [21] should be considered simultaneously as an additional regularization term. For example, [14] proposed a metric based on unpopularity of items. [13], [21], [22] consider diversity as the item difference within one recommendation list while novelty as the difference across lists. However, this kind of metrics is usually infeasible to directly optimize. Also, [23], [24] utilized knowledge transfer from many-shot head items to enhance the quality of tail-item embeddings. Inversepropensity-scoring (IPS) is a practical one for industry product [25]. Since it is relatively easy to reweight training samples and ameliorate the distribution shift problem. Nevertheless, it suffers severely from high variance. Besides, there are also methods based on additional knowledge input such as side-information, user feedback, and niche item clustering to relieve the cold start problem of tail items [26], [27]. However, none of the above work emphasized easing the neglect of tail items during the gradient update process. Despite recommendation accuracy as the main objective of recommendation, some researches have also been done focusing on other objectives such as availability, proﬁtability, and usefulness [28], [29]. Besides, metrics about long-tail recommendation such as diversity and novelty are also considered as objectives [13], [21]. Recently, user-oriented objectives such as user sentiment are considered for better recommendation [30], [31]. For a commercial RS, CTR (Click Through Rate) and GMV (Gross Merchandise Volume) are included in [32], [33] to gain higher proﬁts. The optimization methods for multiple objectives can be categorized into two categories: heuristic search [34] and scalarization [35], [36]. Evolutionary algorithms are popular choices for heuristic search which deal simultaneously with a series of possible solutions in a single run [14]. But these algorithms usually depend heavily on the heuristic experience [34], [37]. Scalarization methods transform multiple objectives into a single one with a weighted sum of all objective functions [36]. Then the overall objective function is optimized to be Pareto-Efﬁcient, where no single objective can be further improved without hurting the others [33]. In this paper, we aim to address the long-tail recommendation task from an optimization perspective. Unlike existing methods which introduce new metrics as the objectives [13], [21], [33], we consider the learning on a cluster of items as an objective. After that, we focus on ﬁnding an optimal solution in which the learning over one item cluster would not affect the learning on the other one. In this section, we describe details of the proposed ICMT framework. Figure 2 illustrates the structure of ICMT, which contains a base recommendation model with the structural disentanglement of popularity, a PE solver to ﬁnd the non-conﬂict gradient directions for multiple item cluster-wise objectives and a hybrid training loss consisting of weighted binary crossentropy (BCE) and robust contractive regularization. A traditional recommender base model mainly consists of user side fand item side f. For each user-item pair (u, i), the core task is to map user u and item i into a user interest embedding v∈ Rand an item embedding v∈ R Fig. 2: An holistic illustration of ICMT. The reasons behind user-item interactions are ﬁrstly disentangled into popularity and interest factors. Then, interest factors are modeled through a base recommendation model (e.g. PMF, NeuMF, LightGCN), in which the user interest embeddings and item embeddings are obtained. Thereafter, items are clustered according to the correlation between item embeddings and the popularity embedding. Then the training objective is formulated as a weighted sum of cluster-wise objectives, which is optimized by a PE solver. Finally, a robust contractive loss is added as regularization. respectively, where D denotes the embedding size. It can be formulated as: In traditional base models, when user and item embeddings are obtained, a scoring function gis utilized to calculate the relevance score for a user and an item(e.g., inner product [2], [16]), which can be formulated as: Recently, many works design novel fand fto extract better features. For example, neural matrix factorization (NeuralMF) [3] adopts MLP as fand fto extract user and item features respectively, LightGCN [16] introduces the graph convolutional mechanism on fand f. However, the engagement of popularity impact is ignored by this approach, where different reasons of an interaction are bundled together as uniﬁed user representations. Therefore, we separate representations for user interest and popularity through assigning each user a unique interest embedding vwhile maintaining a general popularity embedding v∈ R. The latter one represents the public preference that participates with the item embedding vin every interaction, which is denoted as function g. Through aggregation, the prediction function of ICMT can be formulated as: where λis a weighting parameter controlling the ratio of popularity impact. During inference stage, only the interest part gwill be used for ﬁnal recommendation, where the popularity embedding has been disentangled. Without loss of generality, we implement gas matrix factorization in ICMT. In this paper, we consider training the RS from implicit feedback (i.e., observed interactions are considered as positive samples while negative samples are sampled from missing interactions). As for the base model extracting user interest and item representations, we start from the normal training setting, in which each training sample has equal weight (i.e., 1). The total loss function is deﬁned on the whole training data, which is shown asXX minL(θ) =l(θ) +l where Rand Rdenote the set of positive samples and the set of sampled negative samples, correspondingly. lis the speciﬁc loss (i.e., cross-entropy) of (u, i) pair and θ denotes base model parameters. Then we expand the loss on positive where I denotes the whole item set and Ris the set of users who have interacted with item i. Due to the popularity bias in the training data, Ris extremely imbalanced. For head items, Rcontains much more samples than tail items. As a result, when we perform updates according to ∂L/∂θ, the majority of gradients would come from the loss on head items. When there are conﬂicts between gradients coming from head items and gradients coming from tail items, the normal training setting would scarify the learning on tail items to achieve a lower overall loss. That is to say, the overall gradient direction is actually dominated by head items. To address this problem, we propose to consider the learning on each item as an objective and formulate the training over whole (positive) data as a weighted sum of these multiple item-wise objectives:XXX L(θ) can be seen as the initial item-wise optimization objective. wis the weight for objective i. We aim to ﬁnd a set of wso that each item-wise objective can be optimized without hurting the others. In the real-world scenario, there are usually a huge amount of items. As a result, naively consider each L(θ) as an optimization objective could heavily increase the computation complexity of ﬁnding w. To address this problem, we ﬁrst split the whole item set to K clusters and then consider the learning on each cluster of items. Besides, in the total learning space θ, there are some parameters θwhich are shared between objectives and some parameters θwhich are only related to item i. We just need to consider θfor the selection of objective weights, since θwould not affect the learning of other items. It’s worth mentioning that though vis a shared embedding among between all the objectives, its purpose is to evenly capture the popularity preference among all the items. Therefore, ICMT doesn’t apply the re-weighting strategy on vand keeps it in the parameter set θ. Taking all the above factors, we formulate our loss function to train θon positive samples as L(θ) =ωL(θ), where L(θ) =L(θ) s.t.ω= K, ω≥ 0, ∀k = 1, ..., K where ωis the weight for the k-th item cluster and Idenotes the set of items in this cluster. When K = 1, we can recover the normal training weight setting. Lis the learning objective for cluster k. For the training of item-speciﬁc parameters θ, we still use the L(θ) as shown in Eq.(5). In the following, we will ﬁrst describe the item clustering strategy and then describe how to ﬁnd ωfor each cluster objective. 1) Adaptive Item Clustering: We cluster the items according to the observation that items whose embeddings are similar with the popularity embedding should be separated out from items whose embeddings are dissimilar with popular embedding to formulate different item clusters. We implement this idea through operating element-wise product on each v with v. The ﬁnal item clustering embedding vis deﬁned as follows: where  denotes the element-wise product and this product is divided by the inner product (i.e., kvk·kvk) to normalize the scale impact. The clustering embedding mainly correlates with the item’s similarity with the popularity embedding in terms of direction. Then, we perform K-Means clustering algorithm [38] using this item clustering embedding v. 2) Pareto-Efﬁcient Solver: In the following, we will describe how to ﬁnd ωfor each cluster objective. Firstly, we provide a brief introduction to Pareto-Efﬁciency and some related concepts. Given a system that aims to minimize a series of objective functions L, ..., L, Pareto-Efﬁciency is a state when it is impossible to improve one objective without hurting other objectives. Formally, we provide the following deﬁnition: Deﬁnition 1: For a minimization task of multiple objectives, let sand sdenote two solutions as s= (f, ..., f) and s= (f, ..., f), sdominates sif and only if f≤ f, . . . , f≤ f. Then the concept of Pareto-Efﬁciency is deﬁned as: Deﬁnition 2: A solution s = (f, ..., f) is Pareto-Efﬁcient if and only if there is no other solution that dominates s . It is worth mentioning that Pareto-Efﬁcient solutions are not unique and the set of all such solutions is named as ”Pareto Frontier”. In this paper, we aim to ﬁnd ωso that the solution of each cluster-wise objective is Pareto-Efﬁcient, aka Item Cluster-Wise Pareto-Efﬁciency. According to the deﬁnition of Pareto-Efﬁciency, we can use the Karush-Kuhn-Tucker (KKT) conditions [39] to describe the property of ω:P , ..., ω≥ 0 andω= K.P As a result, the task of ﬁnding ωcan be formulated as The optimization problem deﬁned in Eq.(9) is equivalent to ﬁnding a minimum-norm point in the convex hull of the set of input points (i.e., ω), which has been extensively studied [40]. Given the current Lin one training step, we utilize the Frank-Wolfe algorithm [41] to solve the convex optimization problem of Eq.(9). Algorithm 1 shows the detail of this process. Its time complexity is mostly determined by the number of objectives and iterations with a time complexity upper bound of O(K|d|), where |d| is the dimension of parameter space θ. Usually, the number of objectives is limited, therefore the running time of Algorithm 1 is negligible compared to the model training time cost. Algorithm 1 PE-solver Input: θ, K, L Output: ω: [ω, ..., ω] where eis a vector whose elements are 1 at index t and 0 otherwise. With head items dominating the gradient update process, it has been demonstrated that many state-of-the-art recommendation models are actually fragile and vulnerable to small ﬂuctuations and changes from head items [42]. In this section, we propose a simple yet effective penalty term to encourage model robustness and further downgrade the side impact from popularity bias. For a robust recommendation model, the user representation vshould remain a small change when there is a tiny ﬂuctuation of item-speciﬁc parameter θ. Meanwhile, to refrain from the popularity impact, item representation should also be less disturbed by the popularity embedding parameter θ. To this end, we deﬁne the contractive loss as the sum of the squared Jacobian matrix of vwith respect to θand vwith respect This contractive loss is added as a regularization term to encourage more robust model training. In this paper, we use the BCE loss as the basement loss to train the recommendation model. More precisely, the speciﬁc loss lfor a (u, i) pair is formulated as l(θ) = −[Y log(δ(ˆy)) + (1 − Y ) log(1 − δ(ˆy))], where Y is the label for the (u, i) pair (i.e., Y = 1 if there is an interaction between user u and item i, otherwise Y = 0). δ is the sigmoid function. ˆyis calculated according to Eq.(3). Considering the robust contractive regularization, the ﬁnal training function of ICMT regarding the shared parameter θ is formulated asX Input: R,R, recommendation model, K item clusters, learning rate η and all other hyperparameters Output: parameters in the whole learning space θ: {θ, θ} model rithm according to v. where L(θ) is calculated according to Eq.(7), λand λare regularization coefﬁcients. For item-speciﬁc parameter θ, the training function of ICMT is formulated asX where L(θ) is calculated according to Eq.(5). In each training step of ICMT, the popularity impact, unique user interests, and items are ﬁrstly mapped into latent representations v, v, and vby the recommendation model. The items are clustered through the K-Means algorithm according to their clustering embedding in the form of Eq.(8). We then run the PE-solver according to Algorithm 1 to get the weight ωfor item cluster k. Then, we calculate the prediction score according to Eq.(3). For the shared parameter θ, we perform update by minimizing Lwhile for item-speciﬁc parameter θ, we perform update through minimizing L. Algorithm 2 illustrates the overall training and inference procedure of ICMT. In this section, we conduct experiments aiming to answer the following research questions: RQ1: How does the proposed IICMT perform compared with normal training and other long-tail recommendation algorithms? RQ2: How do the components and hyper-parameters of ICMT affect the recommendation performance? RQ3: Can the PE-solver ﬁnd Pareto-Efﬁciency solutions for multiple item cluster-wise objectives? RQ4: How is the interpretability of ICMT? A. Experimental Settings 1) Datasets: We conduct experiments on three public accessible datasets: Last.Fm, Gowalla and Yelp2018. The datasets vary in domains, platforms, and sparsity. Table I summarizes the statistics of the three datasets. Last.Fm: This is a widely used dataset which contains 1 million ratings between users and movies. We binarize the ratings into implicit feedback. Interacted items are considered as positive samples. Due to the sparsity of the dataset, we use the 10-core setting, i.e., retaining users and items which have at least ten interactions. Gowalla: This is the check-in dataset obtained from Gowalla, where users share their locations by checking-in behavior [43]. To ensure the quality of the dataset, we use the 20-core setting. Yelp2018: This dataset is adopted from the 2018 edition of the Yelp challenge. Wherein, the local businesses like restaurants and bars are viewed as the items. Similarly, we use the 20-core setting to ensure that each user and item have at least twenty interactions. 2) Evaluation protocols.: We adopt cross-validation to evaluate the performance. The ratio of training, validation, and test set is 8:1:1. The ranking is performed among the whole item set. Each experiment is repeated 5 times and the average performance is reported. The recommendation quality is measured both in terms of overall accuracy and long-tail performance that reﬂecting the alleviation of popularity bias. The overall accuracy is measured with two metrics: Recall and Normalized Discounted Cumulative Gain (NDCG). Recall@N measures how many ground-truth items are included in the top-N positions of the recommendation list. NDCG is a rank-sensitive metric that assigns higher weights to top positions in the recommendation list [44]. For the evaluation of long-tail performance, we ﬁrst split items into Iand Iaccording to the ratio of 20% \ 80% Pareto Principle. Irepresents the set of head items and I denotes the set of tail items. Here 20% means 20% of total item numbers, other than 20% of interactions. We then adopt the following four metrics. Recall-Tail and NDCG-Tail: Recall-Tail@N measures how many tail items belong to Iare included in the top-N positions of the recommendation list and then interacted by the user. Similarly, NDCG-Tail@N assigns higher weights to top positions. Coverage and APT: Coverage measures how many different items appear in the top-N recommendation list. A more readily interpretable but closely related metric of success we will use for evaluation is the Average Percentage of Tail items (APT) in the recommendation lists. More precisely, Coverage@N and APT@N are deﬁned as: where |U| and |I| are the number of users and items in the test set, list(u) represents the list of top-N recommended items for each user u in test set. 3) Baselines: We instantiate the proposed ICMT with three state-of-the-art recommendation models: conditional probability of latent factors given the observed ratings and includes Gaussian priors as regularization. deep learning-based recommendation model. It combines matrix factorization and multi-layer perceptrons (MLP) to learn high-order interaction signals. learns user and item representations by linearly propagating them on the interaction graph. The user and item embedding is formulated as the aggregation of hidden vectors in all layers. Each model is trained with the following model-agnostic frameworks: with simple BCE loss, as shown in Eq.(1). item popularity. Speciﬁcally, weight for an interaction is set as the inverse of corresponding item popularity value. to ﬁnd Pareto-Efﬁcient solutions for multiple objectives like accuracy, diversity, and novelty. evolutionary algorithm to ﬁnd trade-off solutions between recommending accurate and niche items simultaneously. troduces a ﬂexible regularization-based framework to enhance the long-tail coverage of recommendation lists in a learning-to-rank algorithm. 4) Parameter Settings.: All methods are learned with the Adam optimizer [47] except utilizing RMSprop optimizer in NeuMF based models. The batch size is set as 512. The learning rate is set as 1e. We evaluate on the validation set every 3000 batches of updates. For a fair comparison, the embedding size is set as 64 for all models. For NeuMF and LightGCN, we utilize a three-layer-structure. The nodedropout and message-dropout in LightGCN are set as 0.1 on all datasets. For hyperparameters of ICMT, λ, λ, and λare searched between {1e-4, 1e-3, 2e-3, 5e-3, 1e-2} on all three datasets. We set item cluster number K = 2 without special TABLE II: Top-20 long-tail performance on three datasets. RT, NT, Cov and AT are short for Recall-Tail, NDCG-Tail, Coverage and APT respectively. Boldface denotes the highest score. TABLE III: Top-20 overall performance on three datasets. R and NG are short for Recall and NDCG respectively. Boldface denotes the highest score. mention. Note that model hyperparameters keep exactly the same across all different training frameworks for a fair comparison. B. Performance Comparison (RQ1) Table II and Table III shows the performance of top-N recommendation on Last.Fm, Gowalla and Yelp2018, respectively. We make the following observations from the results: (1). According to Table II, ICMT achieves the best long-tail recommendation performance among all methods. This observation conﬁrms that the proposed ICMT is effective to alleviate the popularity bias and generate better recommendations from tail items. The base model with ICMT achieves the average absolute Recall-Tail@20 / NDCG-Tail@20 / Coverage@20 / APT@20 / gain of 42.45% / 30.11% / 15.45% / 33.23%. (2). As shown in Table III, although ICMT is proposed to tackle the long-tail recommendation task, in all cases, it outperforms normal training and the other long-tail recommendation methods in terms of overall accuracy. It demonstrates that ICMT achieves a better trade-off between longtail recommendation and overall accuracy compared with other frameworks. The performance gain regarding the overall accuracy metrics NDCG@20 / Recall@20 is 4.03 % / 2.98 %. This improvement mainly comes from promoting the highquality niche items while downgrading the irrelevant head items. (3). We conduct one-sample t-tests and the obtained results (i.e., p-value <0.01) indicate that the improvement regarding both long-tail recommendation metrics and overall metrics of ICMT is statistically signiﬁcant. (4). We also analyze the head items and tail items tradeoff in ICMT. Figure 3 visualizes the average recommendation accuracy (i.e., NDCG@20, Recall@20) on head items and tail items on Gowalla dataset with LightGCN as the recommendation model. Generally, the points which fall into the top-right direction indicate better performance with both higher head and tail accuracy. It’s obvious that the proposed ICMT achieves the highest tail accuracy while only scariﬁes a little head accuracy compared with normal training. However, other methods can not achieve such a performance. In most cases, these methods tend to lead to a larger decrease in head accuracy while obtaining a smaller gain on tail accuracy. This result demonstrates that ICMT achieves a better tradeoff between head items and tail items, compared with other methods. The performance gain of ICMT mainly comes from the growth in niche items without the loss across head items. To conclude, the proposed ICMT signiﬁcantly improves the long-tail recommendation performance compared with normal training, and meanwhile, enhances the overall accuracy. Fig. 3: NDCG@20 and Recall@20 Proﬁle of head and tail items on Gowalla Dataset TABLE IV: Ablation study of method components on three datasets. Boldface denotes highest scores. w/o denotes without. ↓ indicates as a severe performance drop (more than 10%). C. Ablation Study and Hyper-parameter Study (RQ2) 1) Ablation Study: In this part, we conduct ablation study to analyze the functionality of the three components of ICMT (i.e.,cluster-wise re-weighting (CR), popularity disentanglement (PD), and contractive loss (CL)). Table IV shows the performance of ICMT and its variants on all three datasets utilizing LightGCN as the base recommendation model. We introduce the variants and analyze their effects respectively: (1). Remove Cluster-wise Re-weighting (w/o CR): The most signiﬁcant long-tail accuracy degradation occurred without the re-weighting strategy, which implies that niche items tend to obtain higher weights because of their weak relationship with popularity embedding. This proves that clustering the items and treating the recommendation target as a multi-objective optimization problem can greatly improve the performance of the model in the long-tail space. (2). Remove Popularity Disentanglement (w/o PD): After taking away the popularity embedding and perform clustering on the item embedding distribution, we ﬁnd that Coverage and APT are signiﬁcantly worse, meaning that the vanilla user embedding is biased by the item popularity. On the other hand, with the participation of popularity embedding, user interest embedding in ICMT alone reﬂects the users’ true preference, which can thus explore more niche items and improve the long-tail performance. (3) Remove Contractive Loss (w/o CL): We can see that the long-tail results downgrade without the contractive regularization, manifesting that the niche items are boosted after regularizing with contractive Jacobi gradients. To sum up, the combination of these three strategies (i.e., ICMT) yields the best performance, proving that all the three components of ICMT are effective and work collaboratively to improve the long-tail recommendation performance and overall accuracy. 2) Hyper-parameter Study: (1). Effect of Item Cluster Number K: In this part, we use LightGCN as the base recommendation model since it has the best overall accuracy performance. Here we choose K ∈ {1, 2, 3, 4} to conduct the experiment. Figure 4 illustrates, NDCG@20, NDCG-Tail@20, and APT@20 under different cluster numbers on Last.Fm and Yelp2018 dataset. The general observation is that overall recommendation accuracy maintains the same level while the long-tail performance shows bellshaped curves. Increasing the cluster number from 1 (i.e., normal training) to 2 leads to the largest long-tail performance improvement. Later on, long-tail performance keeps diminishing along with the increase of cluster number. Such experimental results indicate that adaptively assigning the items into two clusters leads to the most satisfactory performance. However, with more item clusters, the performance of ICMT on long-tail items gets compromised. The reason could be that too many clusters would make ICMT put more focus on the balance between tail clusters rather than the balance between head and tail items. (2). Effect of Popularity Factor Weight λ: To evaluate the impact of popularity factor weight λ, we vary the weight in the range of {0, 1e-4, 1e-3, 2e-3, 5e-3, 1e-2}. The experimental results are summarized in Figure 5. We can observe that the overall NDCG@20 reaches its peak when λ= 2e − 3, thus demonstrating that properly disentangle the popularity factor closely reﬂects the true user interest. Meanwhile, with the incremental of λ, the long-tail performance keeps rising swiftly. This implies that more niche items are excavated when we put more emphasis on decomposing the popularity factor. To sum up, for a higher overall accuracy, we choose λ= 2e − 3 as our default setting. (3). Effect of Contractive Loss Weight λ: From Figure 6, we can observe that a small value of λpromotes the accuracy, especially in the long-tail space according to its ability of balancing the gradients from all items and suppressing the popularity embedding dominance. However, despite keep promoting the APT, a larger portion of robust regularization does not necessarily lead to better accuracy due to the issue of losing information from the gradients. Therefore, we set λas (1e-3, 1e-3, 2e-3) corresponding to Last.Fm, Gowalla, Yelp2018 to achieve the best overall performance. Fig. 5: Effect of Popularity Factor Weight λ. Fig. 6: Effect of Contractive Loss Weight λ. D. PE-Solver Investigation (RQ3) In this part, we conduct experiments to show whether the PE-solver generates reasonable Pareto-Efﬁcient solutions. 1) Pareto Frontier and the Searched PE Point: On the Gowalla dataset with all the three recommendation models, we ﬁrst generate the Pareto Frontiers of head and tail losses by running the Pareto MTL algorithm [33] with different trade-off preference vectors, shown in Figure 7(a). It can be observed that the obtained Pareto Frontiers under different constraints follow Pareto-Efﬁciency, i.e., no point achieves both lower short-head and long-tail losses than other points. When the model focuses more on head items, the short-head loss is lower while the long-tail loss increases, and vice versa. When it comes to the searched point of the PE solver, we can see that on all recommendations models, those points mainly lie in the middle part of the Pareto Frontiers. This observation indicates that the PE-solver coincides with our aim of balancing the trade-off between head items and tail items. 2) The Learning of Weights: To be clear of the training process and reveal the attention of long-tail items, we further plot the learning curves of the average weights assigned to long-tail items, as shown in Figure 7(b). We use LightGCN as the recommendation model and visualize the trend on all three datasets. We can observe that the obtained weights from PEsolver tend to focus on tail items. After variating at the early training stage, the weight for tail items becomes ﬂattened and then converges to a value around [1.04, 1.16]. On the other hand, the normal training methods neglect these PE weights and treat all items in the same way, leading to the overﬁtting on head items. Hence, the proposed ICMT can effectively eliminate the popularity bias of RS by assigning adaptive weights to head and tail cluster-wise objectives. E. Case Study (RQ4) To show the interpretability of ICMT, in the Last.Fm dataset, we randomly select a user uand retrieve his Fig. 8: Case study of a single user. The upper part is the recommendation list from LightGCN-Normal and the lower part is the recommendation list of LightGCN-ICMT. H denotes the movie is a head item while T denotes the movie is a tail item. ω denotes the average weight assigned to each item. The blue check mark denotes that the recommended item belongs to the ground-truth items in the test set. The arrow indicates that there are some relations between the two items (e.g., same tag). two top-5 recommendation lists from LightGCN-Normal and LightGCN-ICMT given the same interaction history. Figure 8 illustrates the recommendation detail. We observed that the recommendation list derived from LightGCN-Normal contains popular ground-truth items but does not contain any tail items. LightGCN-ICMT contains two tail (unpopular) items, Farben Lehre and Plavi Orkestar thanks to the higher average weights assigned to tail items in his interaction history. One of the two recommended tail items belongs to the ground-truth test set, which improves the long-tail and overall performance. Note that the two recommendation lists have several items in common (e.g. Erasure), which indicates that LightGCNICMT can also catch the preference on popular items. In this paper, we propose to tackle the long-tail recommendation task from a multi-objective optimization perspective. We ﬁnd that head items are repetitively recommended due to the fact that head items tend to have larger gradient norms and thus dominate the gradient updates. Learning parameters based on such gradients could scarify the performance of long-tail items. To alleviate such a phenomenon, we propose a general learning framework namely ICMT which is featured with popularity disentanglement, cluster-wise multi-objective reweighting, and robust contractive regularization. We instantiate ICMT with three state-of-the-art recommendation models and conduct extensive experiments on three real-world datasets. The results demonstrate the effectiveness of ICMT. Future work includes generalizing ICMT for other tasks such as multi-class classiﬁcation and long-tail document retrieval.