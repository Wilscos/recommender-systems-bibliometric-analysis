Universidade Tecnol´ogica Federal do Paran´a (UTFPR), Computer Science Department, Alberto Carazzai, 1640, 86300-000, Corn´elio Proc´opio, PR, Brazil Universidade Tecnol´ogica Federal do Paran´a (UTFPR), Mathematics Department, Alberto Carazzai, 1640, 86300-000, Corn´elio Proc´opio, PR, Brazil Corresponding Author: Fabr´ıcio Martins Lopes Universidade Tecnol´ogica Federal do Paran´a (UTFPR), Computer Science Department, Alberto Carazzai, 1640, 86300-000, Corn´elio Proc´opio, PR, Brazil Tel: +55 (43) 3133-3872 Email: fabricio@utfpr.edu.br Matheus Henrique Pimenta-Zanon(matheus.pimenta@outlook.com), Glaucia Maria Bressan(glauciabressan@utfpr.edu.br), Fabr´ıcio Martins Musical genre’s classiﬁcation has been a relevant research topic. The association between music and genres is fundamental for the media industry, which manages musical recommendation systems, and for music streaming services, which may appear classiﬁed by genres. In this context, this work presents a feature extraction method for the automatic classiﬁcation of musical genres, based on complex networks and their topological measurements. The proposed method initially converts the musics into sequences of musical notes and then maps the sequences as complex networks. Topological measurements are extracted to characterize the network topology, which composes a feature vector that applies to the classiﬁcation of musical genres. The method was evaluated in the classiﬁcation of 10 musical genres by adopting the GTZAN dataset and 8 musical genres by adopting the FMA dataset. The results were compared with methods in the literature. The proposed method outperformed all compared methods by presenting high accuracy and low standard deviation, showing its suitability for the musical genre’s classiﬁcation, which contributes to the media industry in the automatic classiﬁcation with assertiveness and robustness. The proposed method is implemented in an open source in the Python language and Matheus Henrique Pimenta-Zanon, Glaucia Maria Bressan, Fabr´ıcio freely available at https://github.com/omatheuspimenta/examinner. Keywords: Musical genres classiﬁcation, expert music systems, feature extraction, pattern recognition, machine learning 1. Introduction media industry. The correct association between genres and musics is very important for several applications, for example, musical recommendation systems. The Music Information Retrieval (MIR) is a research topic regarding the music audience and consumption mainly from online sources containing millions of songs (Oramas et al., 2016). Providing properly selected music contents is fundamental for the media industry, which manages huge music catalogues stored on distributed databases (Fern´andez & Ch´avez, 2012). The automatic classiﬁcation of musical genres is one of the most popular tasks in MIR research (Tzanetakis & Cook, 2002), which addresses the development of techniques to analyze, organize, synthesize or extract musical information (Ra´s & Wieczorkowska, 2010). properties and features. This classiﬁcation task has motivated studies specially because of the improvement of digital technologies and computational power available. Therefore, automatic classiﬁcation of music genres plays an essential role in music indexing and retrieval, allowing Web sites and expert music indexing systems to manage and label music content (Correa & Rodrigues, 2016). As more music is made available, the need for eﬃcient methods to query and retrieve information from these musical databases increases (Dannenberg et al., 2001). ery considering its genre are based on learning strategies involving the feature extraction, which composes a feature vector (Duda et al., 2001). The feature extraction is a decisive step for the success of the classiﬁcation, since it deals with the reduction of data dimensionality, i.e. it aims to represent the origi- Musical genres classiﬁcation has become a relevant topic, especially for the The classiﬁcation in genres aims to group music styles according to common According to current literature, research works dedicated to the music recovnal data in a smaller vector trying to avoid the loss of information. Therefore, the feature vectors are applied in classiﬁcation methods and, as a result, an automatic classiﬁcation system for musical genres. siﬁcation (Sturm, 2014; Scaringella et al., 2006; Fu et al., 2011), no general solution is available, mainly because of the imprecise deﬁnition of musical genres and merges among borders (Bressan et al., 2018; Fern´andez & Ch´avez, 2012). In this scenario, this work presents a feature extraction method based on complex networks for the automatic classiﬁcation of musical genres, called EXAMINNER (EXtrAction of MusIcal Notes from complex NEtwoRks). Competitor methods are adopted in order to compare the proposed approach by considering accuracy, robustness, and methodological complexity. For that, the GTZAN (Tzanetakis & Cook, 2002) and FMA (Deﬀerrard et al., 2017) datasets were adopted, since they are commonly used in the literature and then the performances could be compared with other feature extraction methods. networks for musical genres identiﬁcation by considering the sequence of musical notes from each considered music. The proposed method diﬀers from those found in the literature, which use Wavelet, Fourier, Cossine, spectral and other transform, which increase the methodological complexity of the feature extraction (Nanni et al., 2017; Panagakis et al., 2008; Silla et al., 2009). In addition, some methods produce results in an embedded form that do not allow for an interpretation of how their results were generated (interpretability), such as the deep learning based methods (Sigtia & Dixon, 2014; Choi et al., 2017; Bisharad & Laskar, 2019). The proposed method considers only the sequences of musical notes, an information that can be retrieved directly from the music itself, with no additional information. Furthermore, the EXAMINNER is a feature extraction method that can be used independently of the classiﬁcation algorithm, i.e. it is not embedded with the classiﬁcation method, leading to a more general and non classiﬁer-dependent solution, unlike other methodologies that are embedded with the classiﬁcation algorithm (Turnbull & Elkan, 2005; Iloga et al., Although many techniques have already been proposed for music genre clas- The novelty of this work is a feature extraction method based on complex 2014; Oramas et al., 2018; Bisharad & Laskar, 2019). traction method based on complex networks measurements, the high accuracy presented by the classiﬁcation results, interpretability of its results, relative simpliﬁcation (using only two parameters) with lower methodological complexity and higher robustness, when compared with competitor methods. In addition, the proposed approach can help the media industry in the musical genres classiﬁcation task, oﬀering automation services with robustness and conﬁdence in its results. approaches proposed in the literature. Section 3 presents the material and methods, detailing the proposed approach and the adopted datasets. The results and discussion are presented in Section 4, as well as the evaluation of the proposed approach and literature methods. Finally, the conclusion is presented in Section 5. 2. Related Works been proposed in the literature. In particular, the survey by Sturm (2014) presents the musical genre recognition and analyzes three major aspects: experimental designs, datasets and ﬁgures of merit. An overview of most important approaches that deal with music genre classiﬁcation is also presented in the survey by Correa & Rodrigues (2016), which considers the symbolic representation of music data, presenting the current issues inherent to the music format and the main algorithms used to model the music feature space. classiﬁcation model is presented in Kim et al. (2018). Artist labels are adopted as side information, allowing a model to learn the mapping between audio and artists, while capturing patterns that might as well be useful for genre prediction. Authors show that music representations learned from raw artist labels can The contributions that can be highlighted in this work are: new feature ex- The paper is organized as follows. Section 2 described the related recent Considering the context of music genre classiﬁcation, some approaches have A multi-task transfer framework for using artist labels to improve a genre transfer to other music-related tasks. and extending feature vector by parameters related to the speciﬁc musical instruments that are characteristic for the given musical genre allows for eﬃcient automatic musical genre classiﬁcation. Authors have showed that the feature vector and the SVM with Co-training mechanism are applicable to a large dataset, which was a subset of audio excerpts extracted from the Synat dataset. tory level of performance only on a particular dataset, however not on other datasets. In their study, authors proposed a music genre recognition using a convolutional recurrent neural network architecture (CRNN), which is trained on mel spectrogram, which is a simpler, lower level acoustic representation of audio signals (Shen et al., 2018). Then, it is extracted audio clips of 3 seconds from the mel spectrogram and a convolutional network is trained to perform artist recognition, genre recognition and key detection (Dieleman et al., 2011) by training a convolutional deep belief network on all data, and then use the learned parameters to initialize a convolutional multilayer perceptron with the same architecture. In addition, Choi et al. (2017) concatenated feature vectors using the activations of feature maps of multiple layers in a trained convolutional network. On the other hand, Sigtia & Dixon (2014) examines ways to improve feature learning for audio data using stochastic gradient descent and deep neural networks. The methods provide improvements in training time and music features. gakis et al., 2008), in which a multiscale spectro-temporal modulation features are extracted. Then, the classiﬁcation is performed by a Support Vector Machine and a stratiﬁed cross-validation method. More recently, Panagakis et al. (2009a) proposed a music genre classiﬁcation framework that combines the rich, psycho-physiologically grounded properties of auditory cortical representations of music recordings and the power of sparse representation-based classiﬁers. In Rosner & Kostek (2018), authors investigated if separating music tracks According to Bisharad & Laskar (2019), some features provide a satisfac- Music genre classiﬁcation is also addressed in a multilinear perspective (Pana- Panagakis et al. (2009b) proposed a music genre classiﬁcation framework that combines the rich, psycho-physiologically grounded properties of slow temporal modulations of music recordings and the power of sparse representation-based classiﬁers. It is worth mentioning that (Sturm, 2012b) presents a rigorous analysis of these systems, questioning their performance. fuzzy system for the automatic classiﬁcation of Latin music genres, considering the imprecise deﬁnition and merges among borders of musical genres. For this, it adopted the selected features by Silla et al. (2009). res classiﬁcation by Iloga et al. (2014). The aim of this approach is to capture the inner transitions from one genre to another in order to perform the classiﬁcation. More speciﬁcally, the use of one MM per genre model statistically captures the transitions between genres through its state’s transition matrix. is based on the fusion of acoustic and visual features, considering an ensemble of SVM classiﬁers. Also, combining visual and acoustic features for automated audio classiﬁcation, Nanni et al. (2017) use the input signal represented by its spectrogram and an ensemble of SVM classiﬁers. Existing music transcription methods normally perform pitch estimation. A method based on deep neural networks for audio-to-score music transcription of monophonic excerpts is proposed by Rom´an et al. (2020), which outputs a notation-level music score, using an audio ﬁle as input, modeled as a sequence of frames. adopt the librosa library (Brian McFee et al., 2015) as the feature extraction method. The librosa is a python package for audio and music signal processing, currently in version 0.8 (McFee et al., 2020). The following features have been extracted using the librosa library and adopted in the literature: Chroma (Goto (2006); M¨uller & Ewert (2011)), Mel-frequency cepstral coeﬃcients (MFCCs) (Rabiner et al. (1993)), root-mean-square (RMS) value for each music frame, spectral measures (Klapuri & Davy (2007); Dubnov (2004)), coeﬃcients to a For the classiﬁcation task, Bressan et al. (2018) present the construction of a The Markov models (MM) were adopted as classiﬁers to perform music gen- The approach for music genre classiﬁcation presented by Nanni et al. (2016) In the literature, several works that address musical genres classiﬁcation nth-order polynomial to the columns of a spectrogram, tonal centroid features (Harte et al. (2006)), tempogram (Grosche et al. (2010)) and zero-crossing rate of a music time series. These features are adopted in musical genres classiﬁcation in Deﬀerrard et al. (2017) in order to generate a lower-bound to this task and show the task’s diﬃculty to classify the musical genres in the FMA dataset. Rolloﬀ, Spectral Flux, and Zero Crossing features in order to classify musical genres, showing that the combination of low-level features with high-level features is eﬀective. Therefore, the librosa library is applied by methods of identifying musical genres. tion and music genre classiﬁcation. Complex networks have been successfully applied to analyze, represent and understand complex systems in many application areas (Watts & Strogatz, 1998; Newman, 2003; Vazquez et al., 2004; Boccaletti et al., 2006; Costa et al., 2007; Backes et al., 2009, 2010; Barab´asi et al., 2011; da Rocha Vicente & Lopes, 2014; Lopes et al., 2014; de Lima et al., 2015; Ito et al., 2018; de Lima et al., 2019; Breve & Lopes, 2020), contributing as a multidisciplinary methodology. 3.1. Material dataset, contains 1, 000 music clips distributed across 10 classes of musical genres. A rigorous analysis about GTZAN dataset is presented in Sturm (2012a), which shows that GTZAN has rhythms overlapping and repetition of musics. More speciﬁcally, it is reported that about 7% of the overlapping of GTZAN come from the same recording (including 5% being exact duplicates). Despite these issues inherent to the database, it is an important contribution for the literature, since many works adopt it in the assessments and the performance comparisons. Thus, this challenge is assumed in this work, which makes the In Arabi & Lu (2009), authors adopt MFCC, Spectral Centroid, Spectral- This work presents a complex-network based approach for feature extrac- The dataset presented by Tzanetakis & Cook (2002), known as GTZAN assessment of the proposed method more realistic to this type of classiﬁcation problem. the GTZAN dataset (Tzanetakis & Cook, 2002) was adopted in this work. More speciﬁcally, the 1, 000 music clips are classiﬁed into ten music genres, namely: blues, classical, country, disco, hip hop, jazz, metal, pop, reggae, and rock. Each musical genre contains 100 samples with approximately 30 seconds in duration of each one. Music Archive (FMA) dataset (Deﬀerrard et al., 2017). The FMA dataset is mainly used to classify musical genre and data analysis. Thus, in order to evaluate the EXAMINNER feature extraction approach, the FMA small subset (Deﬀerrard et al., 2017), which is used for single label classiﬁcation, was adopted in this work. This subset contains 8, 000 music ﬁles sorted in 8 musical genres, namely: electronic, experimental, folk, hip hop, instrumental, international, pop and rock. For each musical genre, 1, 000 balanced music ﬁles with 30 seconds in duration each one composes this dataset. genre with high accuracy only by listening 3 seconds of each music. This approach was successfully adopted in CRNN (Bisharad & Laskar, 2019). Thus, in this work was adopted 10 segments of 3 seconds for each music. 3 seconds in duration are got for each music. For each one of these segments, the fundamental frequency and musical notes are extracted. All the computational implementations are developed using the Python language. For the pre-processing stage, the librosa 0.8 (McFee et al., 2020) library was adopted. 3.2. Methods deals with the feature extraction for the classiﬁcation of distinct classes of RNA sequences in bioinformatics research. It is discussed that the structure of nu- Thus, in order to evaluate the EXAMINNER feature extraction approach, The second dataset adopted to evaluate the proposed method is the Free According to Gjerdingen & Perrott (2008), humans can identify a musical As the result of the pre-processing stage, approximately 10 segments with The EXAMINNER method is inspired on BASiNET (Ito et al., 2018), which cleotides organization in the RNA sequence is an important factor in deﬁning the classes of the sequences. More speciﬁcally, the neighborhood organization between the words of size 3 (k-mers, k=3) recovers the structural organization in the biological sequence, which is mapped in a complex network and its topological measurements are extracted to compose a feature vector, one for each sequence and, as a result, its classiﬁcation with signiﬁcant results. cal notes and that the structure formed by the order in which the musical notes occur are relevant factors for its classiﬁcation as a music genre, the EXAMINNER feature extraction is proposed, considering three main steps: mapping, feature extraction and output features. Figure 1 presents an overview of the EXAMINNER feature extraction approach. music, the fundamental frequency is extracted adopting the method proposed by de Cheveign´e & Kawahara (2002) with the parameters of minimum frequency and maximum frequency equal to 65Hz and 2093Hz respectively, as recommend (Brian McFee et al., 2015; McFee et al., 2020). After obtaining the fundamental frequency, the sequence of musical notes is obtained. Then, the musical notes of the chromatic scale are considered. For those notes the symbol # was not considered, generating musical notes represented by two symbols. network, with the objective of mapping the structural neighborhood relations of the musical notes in the music. Two parameters are considered for traversing the sequence: the word size (W S) and the step size (ST ). In order to maintain coherence, this work adopts W S = 2 and ST = 2. More speciﬁcally, these values represent that the sequence of musical notes is traversed considering the immediate neighborhood and each note in the music is considered once. Figure 2 illustrates how these parameters are applied and the network is generated. borhood relations between notes as edges. As a result, a complex network with undirected weighted edges is generated, in which its edges have an associated Therefore, considering that musics can be represented by sequences of musi- The EXAMINNER starts by considering each music individually. For each Then, each sequence of musical notes is traversed and mapped into a complex Therefore, the network is composed of musical notes as nodes, and the neighweight (numerical value) that represents the frequency of repetitions between the musical notes adjacency. measurements (Costa et al., 2007; Boccaletti et al., 2006) are extracted in order to characterize the organizational structure of musical notes in each music, and, as a result generating a feature vector as shown in Figure 3. More speciﬁcally, the initial network was considered with all the edges identiﬁed in mapping step and it is performed the topological feature extraction. Thus, 10 topological measurements commonly used in the literature were adopted in order to characterize the topological patterns of the network: assortativity (ASS), average degree (DEG), maximum degree (MAX), minimum degree (MIN), average betweenness centrality (BET), clustering coeﬃcient (CC), average short path The second main step is the feature extraction, in which complex network length (ASPL), average standard deviation (SD), frequency of motifs with size 3 (MT3) and frequency of motifs with size 4 (MT4). quency of neighborhood between musical notes. Then the proposed approach iteratively applies a threshold to remove the “weaker” edges at each iteration. Removing edges will change the topology of the network and initially remove possible noise (less frequent edges) while keeping the most frequent (representative) edges, leading to a dynamic in the topological variation of the network. Topological measurements are extracted at each iteration, i.e. diﬀerent frequency scales of the network edges. Therefore, the goal is to extract topological measurements at these diﬀerent scales of connectivity between the nodes to compose a feature vector for each sequence of musical notes. Then, thresholds are applied as long as there are edges left in the network (default) or until a T value is reached, as an optional stopping condition. The number of thresholds T is an optional parameter for the proposed method. inappropriate inﬂuence of the extracted features on the classiﬁcation methods, i.e. diﬀerent numerical scales of each feature, a Min-Max rescale is adopted. Thus, each feature vector ~µ = µ Where µ topological measurement adopted. As a result, all the topological measurements However, the initial network has edges with diﬀerent weights, i.e. the fre- The third main step is the output of the feature vector. In order to avoid an to µin the range [0, 1] deﬁned as µ= (µ− µ)/(µ− µ). are deﬁned into the interval [0, 1]. AMINNER feature extraction method, which can be applied by diﬀerent classiﬁcation algorithms (Duda et al., 2001). 4. Results and Discussion the GTZAN and the FMA datasets were adopted. As described in Sec. 3.1, 10 segments of 3 seconds were extracted for each music from GTZAN and FMA datasets in order to evaluate the proposed method and to compare with results from literature. Thus, considering the same input datasets, both EXAMINNER (Sec. 3.2) and librosa (Brian McFee et al., 2015) were applied for feature extraction. Regarding librosa, all features available by the library were considered and extracted. comparison of the proposed method with the librosa; comparison of the results of music genre classiﬁcation using EXAMINNER compared to methods in the literature; and the analysis and interpretation of the features extracted from EXAMINNER and their use in music genre classiﬁcation. 4.1. Comparing EXAMINNER with librosa feature extractor library (Brian McFee et al., 2015) was adopted to extract the musical features from the GTZAN and FMA datasets. For each music, all the available features have been extracted from the librosa library feature extraction, as cited in Sec. 2: Chroma, Mel-frequency cepstral coeﬃcients (MFCCs), root-meansquare (RMS) value for each music frame, spectral measures, coeﬃcients to a nth-order polynomial to the columns of a spectrogram, tonal centroid features, tempogram and zero-crossing rate of a music time series. same ﬁles, i.e. 3 sec segments. Regarding the librosa, for each feature it was Therefore, the normalized feature vector represents the output of the EX- Regarding the assessment of the EXAMINNER feature extraction method, In this context, the results section was organized in three parts: the results In order to evaluate the proposed feature extraction approach, the librosa The EXAMINNER and librosa features were extracted by considering the also considered the mean and the standard deviation by using the numpy python library (Harris et al., 2020). This procedure was adopted for GTZAN and for FMA datasets. extraction method, several values of thresholds T were adopted in the Feature Extraction step (see Fig. 1). In the ﬁrst iteration, no threshold (T 0) is considered, which produces a feature matrix with 10 columns (features) from the initial network, i.e. considering all the edges of the mapping step. In the next iteration, one threshold (T 1) is considered and 10 more features are obtained, resulting in 20 features aggregated in the feature matrix, i.e. features T 0 + T 1. This procedure was repeated iteratively, adding one by one threshold, until the tenth threshold (T 10). After that, the next adopted thresholds were T 15, T 20, T 25 and the last considered threshold was T 30. the extracted features, such as Classiﬁcation via Regression (Regression), Bayes Network (BN), Random Forest (RF), support vector machine (SVM) and Multi Layer Perceptron (MLP) from Weka data mining software (Hall et al., 2009; Lang et al., 2019) by adopting their default parameters, providing equality in the comparison of results. The 10-fold cross validation method was adopted (Aggarwal, 2015). for EXAMINNER feature extraction method. Table 2 shows the average accuracy of cross validation for each classiﬁer and adopted threshold by considering GTZAN dataset and Table 3 shows the same considering FMA dataset. It is possible to notice that EXAMINNER produce higher accuracy rates, even adopting just 10 features (T 0) from both GTZAN and FMA datasets. As new thresholds are applied and more features are included in the feature matrix, all the results of the classiﬁer algorithms increase their accuracy for GTZAN dataset. A similar behavior occurs for FMA dataset, however with Random Forest, MLP and Regression classiﬁers showing a saturation and a slight loss of accuracy when considering the increasing number of features. As expected, the In order to assess and to analyze the behavior of the EXAMINNER feature In addition, diﬀerent classiﬁcation algorithms were adopted in order to assess Tables 2 and 3 show the results by considering diﬀerent threshold values SVM classiﬁer performs better at higher dimensional feature space (Cortes & Vapnik, 1995) for both datasets. Accuracy (%) obtained by the EXAMINNER and the librosa feature extraction. Accuracy (%) obtained by the EXAMINNER and the librosa feature extraction. Figure 4 shows the highest average accuracy values obtained for each classiﬁer from EXAMINNER features comparing with librosa features, by considering diﬀerent classiﬁers, respectively to (a) GTZAN dataset and to (b) FMA dataset. the behavior of all classiﬁers using EXAMINNER features was relatively homogeneous with lower variation, achieving higher accuracies for all classiﬁers algorithms than those achieved with the librosa features. The higher average accuracy was obtained by the Bayes Network classiﬁer with 30 features from the EXAMINNER (threshold T 2). Regarding the FMA dataset (Figure 4(b)), it is possible to notice that Bayes Net, Random Forest and Regression classiﬁers had better performance when compared with Multi-Layer Perception (MLP), Random Forest (RF) and Support Vector Machine (SVM) classiﬁers using the EXAMINNER features and the higher average accuracy was achieved by the Bayes Network classiﬁer with 20 features from the EXAMINNER (threshold T 1). It can be noted that all the classiﬁers produced higher average accuracy from the EXAMINNER features than the librosa, which considers 28 features. Considering the results achieved by classiﬁers from librosa features, all of them present relatively lower accuracies when compared to the EXAMINNER, even considering the initial thresholds with less quantity of features than the librosa. work, SVM classiﬁer presents the highest accuracy variation, thus the extracted features from librosa and EXAMINNER was also assessed by the SVM with a polynomial kernel (second degree). This evaluation shows, as expected, that the customization of the classiﬁer improves the results already obtained. the confusion matrix is an important indicator for evaluating the results in each music genre, since it contains the number of elements that have been correctly or incorrectly classiﬁed for each class. The main diagonal presents the number of samples that have been correctly classiﬁed for each class. The oﬀ-diagonal elements present the number of samples that have been incorrectly classiﬁed (Duda et al., 2001). Regarding the GTZAN dataset (Figure 4(a)), it is possible to observe that Although the tuning of the classiﬁcation algorithms is not the goal of this In order to better understand the behavior of the classiﬁcation algorithms, Figure 5 shows, for each one of the adopted datasets, the Confusion Matrix of the Random Forest classiﬁer by considering the EXAMINNER and the librosa features. The Random forest classiﬁer was chosen because it was the classiﬁer that presented the best accuracy for the librosa features. Therefore, the aim is to compare the results by considering the best classiﬁcation of the competitor method to evaluate the EXAMINNER. experimental genres, which was noticed in all classiﬁcation algorithms, showing the proximity of these musical genres and the diﬃculty in separating them. Regarding the GTZAN dataset, there is a homogeneous classiﬁcation, i.e. none of the musical genres with a discrepant classiﬁcation, showing the suitability of the It is possible to observe that there is a confusion between electronic and extracted features in the classiﬁcation process. The relatively slight variation between the errors in the musical genres is expected, given that some genres are composed of similar types of instruments with similar rhythmic patterns (Bagcı & Erzin, 2007). The heatmaps for all adopted classiﬁers produced a similar behavior, which are available at https://github.com/omatheuspimenta/ examinner. 4.2. Comparing the performance of the proposed approach with literature apwith the methods of classiﬁcation of musical genres available in the literature, a review was performed on the methods that adopted the GTZAN dataset. Table 1 presents the comparison of the EXAMINNER feature extraction method and some of the more recent state-of-the-art musical genres classiﬁcation. It was observed that several methods applied in GTZAN adopt the SVM classiﬁer. Although EXAMINNER presents more assertive results with other classiﬁers, as described in the previous section, its results with the SVM classiﬁer were considered, using the linear and polynomial kernels. The aim is to make the results comparable in terms of the features extracted and considered for the same classiﬁer as a basis. This way, the eﬃciency of the feature extraction method based on the same classiﬁer of the competing methods becomes clearer. average accuracy among competitor methods. The Panagakis et al. (2009a) present accuracy of 92.4%, however the authors have stated that this result was inﬂated, since this performance is less than that reported (Sturm, 2012b; Nanni et al., 2017). In addition, it is important to note that Chang et al. (2010) and Fu et al. (2010) reported accuracy of 92.7% and 90.9%, respectively. However, their methods are based on manual feature engineering, which are biased by choice of features and might provide higher accuracy (Bisharad & Laskar, 2019). classiﬁcation methods, the proposed method was more accurate than competitor proaches In order to a broaden comparison of the results by the proposed approach It is possible to highlight that the proposed method achieves the higher Although there are some discussions in the literature about the musical genre methods regarding the GTZAN dataset. The results can be explained by the fact that the proposed methodology considers the relationships between “pieces” of music, represented by musical notes. This relationship of the parts of the music may not be directly identiﬁable by other feature extraction techniques. The results indicate that the extracted features possibly maps the pattern of adjacency and frequency of musical notes that distinguish the respective musical genres. (2017) show that several classiﬁers are evaluated in order to compare their performances. Using the same features set and six statistical measures, the accuracy of the SVM classiﬁer ranged from 39% to 63%, while other classiﬁers presented lower accuracy. As can be seen in Figure 4 (a) and (b), the EXAMINNER presents higher accuracy rates for all applied classiﬁcation algorithms. 4.3. Analyzing the features extracted by EXAMINNER relevant, the frequency that each topological measurement was recovered for the musical genre classiﬁcation. For this analysis, a random forest classiﬁer with 500 trees was adopted, since this number of trees are more robust in relation to 100 trees (default) and the tree structure allows to analyze the features considered in the classiﬁcation process. Figure 6 shows the relative frequency of the use of each measurement (feature) in the musical genres classiﬁcation process. highest frequency are ASP L and DEG, which represent respectively the Average Shortest Path Length and the node degree. The shortest path is the minimum path connecting the node i to the node j, that is, the smallest number of edges connecting the node i to the node j. An Average Shortest Path Length (ASPL) is deﬁned in (1). Regarding the comparison of results using the FMA dataset, Deﬀerrard et al. In order to analyze which topological measures of complex networks are most The two topological measures of the complex networks that presented the where d graph nodes. High ASP L values indicate that there is a high distance between musical notes. For example, if the minimum distance between the A3 note and the D2 note is 7, it means that there are another 6 musical notes between the notes; while low values for ASP L represent a sequence of closer musical notes. The Average Shortest Path Length represents this network structure in a general way, indicating the distance between musical notes. The node degree i, given by k Matrix (a) of an undirected graph, the node degree is given by (2) (Costa et al., 2007; Boccaletti et al., 2006). a hub behavior, being musical notes that concentrate high connectivity in the is the distance between node i and node j, and N is the total number of , represents the number of edges connected to it. In terms of Adjacency And the average degree is given by (3). Musical notes (nodes) with a high number of edges connected to it, represent 21.5721.38 network. The average standard deviation of the node degrees (SD) is the third most used topological measure in the classiﬁcation of genres and, according to (Costa et al., 2007), this measure can also be used to characterize networks or phenomena. After that, there are the maximum (MAX) and the minimum (MIN) values, respectively, represented as (4) and (5). These two values also are related to node degree. The (ASS), frequency of motifs with size 3 (MT3), average betweenness centrality (BET), frequency of motifs with size 4 (MT4) and clustering coeﬃcient (CC) were relevant, however they were selected with lower frequency than the previously described measurements by the classiﬁcation algorithm. The ASS quantiﬁes the tendency of nodes to connect to nodes that are similar in some way, such as node’s degree. The BET quantiﬁes the relevance of a vertex in relation to all the paths of the network, i.e. the more paths pass through a vertex, the greater will be your betweenness. Graph motifs are small connected subgraphs, MT3 and MT4 quantiﬁes the number of motifs with size 3 and 4, respectively in the network. The CC is also known as transitivity, characterize the frequency of loops of order three in the network Boccaletti et al. (2006); Costa et al. (2007). tance are associated with connectivity between network nodes, such as ASPL, DEG, SD, MAX and MIN. More speciﬁcally, these measurements are directly associated with the connectivity (degree) and the distance (ASPL) between network nodes (musical notes). On the other hand, the measurements associated with the presence of substructures, such as loops and motifs, or as connection of similar nodes (ASS) and centrality (BET) were selected by the classiﬁcation algorithm with lower frequency. Thus, the sequence of musical notes and their structural organization in terms of neighborhood were better characterized by In addition, the other adopted complex network measurements: assortativity In this context, the complex networks measurements with the greatest importopological measurements related to the connection between the musical notes in the network. their frequencies and builds an undirected weighted graph. That is, it maps how many times diﬀerent adjacent musical notes are repeated and their frequencies. However, instead of mapping one type of repetition at a time, the complex network represents a global map of all frequencies of all adjacent musical notes throughout the music, producing a topological organization of the graph. To summarize and quantify this mapping, measurements of complex networks are extracted from the graph. To identify adjacent patterns at diﬀerent frequency scales, a threshold is applied. Thus, the method can extract the topological organization generated by musical notes globally and in diﬀerent scales from the music and these features can distinguish musical genres. In addition, the classiﬁcation method is able to classify the music in its respective musical genres with high accuracy. 5. Conclusions sive amount of new data produced in an unstructured way, which stands out as a matter of interest in Music Information Retrieval. In addition, some musical genres are composed of similar types of instruments with similar rhythmic patterns, increasing the challenge. siﬁcation of musical genres based on complex networks and their topological measurements. More speciﬁcally, the music is mapped and represented through a complex network. Besides the representation, the method does the characterization by adopting topological measurements of the network. The topological measurements form a feature vector, which is used to classify its musical genre through the analysis of the topological structure formed by the musical notes. In addition, EXAMINNER produces features independently, i.e. not embedded Therefore, the EXAMINNER identiﬁes the adjacent musical notes, counts The classiﬁcation among musical genres is challenging in face of the exten- This work presents the EXAMINNER feature extraction method for claswith a classiﬁcation method, allowing the application of diﬀerent classiﬁcation algorithms. contains 1, 000 music clips distributed across 10 classes of musical genres and the FMA dataset, which contains 8, 000 musics ﬁles distributed across 8 musical genres. The results of the proposed method were compared with the principal methods available in the literature, using the range of thresholds from 0 to 30 to analyze the results. The accuracy results of the comparison with other methods, when applied to the GTZAN and FMA datasets, showed that the proposed method was more assertive than all other methods. Furthermore, the results show that the representation of music as complex networks can extract features more suitable to its classiﬁcation than those adopted by the other methods. with high accuracy using complex network measurements, which represents a relevant contribution of feature extraction and dimensionality reduction in pattern recognition research, allowing expert music systems to manage and label music content. other parametrization for the word size (W S) and the step size (SS), that could be more suitable for each type of musical genre, which could lead to a more adequate learning of parameters for each musical genre and as a result, improve the classiﬁcation. language). The program, the features matrix, ﬁgures and the heatmaps (which represent the confusion matrix), as well as all the material necessary for the replication of this work, are available at https://github.com/omatheuspimenta/ examinner The proposed method was evaluated by adopting the GTZAN dataset, which Furthermore, the proposed method was suitable for classifying music genres As a future work it is suggested an optimization method in order to analyze Finally, the EXAMINNER method was implemented in open source (Python N´ıvel Superior (CAPES), Conselho Nacional de Desenvolvimento Cient´ıﬁco e Tecnol´ogico (CNPq) (Grant number 406099-2016) and the Funda¸c˜ao Arauc´aria e do Governo do Estado do Paran´a/SETI (Grant number 035-2019). This work was funded by Coordena¸c˜ao de Aperfei¸coamento de Pessoal de