Institute for Articial Intelligence, Tsinghua University (THUAI), State Key Lab of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Department of Automation, Selection bias is prevalent in the data for training and evaluating recommendation systems with explicit feedback. For example, users tend to rate items they like. However, when rating an item concerning a specic user, most of the recommendation algorithms tend to rely too much on his/her rating (feedback) history. This introduces implicit bias on the recommendation system, which is referred to as user feedback-loop bias in this paper. We propose a systematic and dynamic way to correct such bias and to obtain more diverse and objective recommendations by utilizing temporal rating information. Specically, our method includes a deep-learning component to learn each user’s dynamic rating history embedding for the estimation of the probability distribution of the items that the user rates sequentially. These estimated dynamic exposure probabilities are then used as propensity scores to train an inverse-propensity-scoring (IPS) rating predictor. We empirically validated the existence of such user feedback-loop bias in real world recommendation systems and compared the performance of our method with the baseline models that are either without de-biasing or with propensity scores estimated by other methods. The results show the superiority of our approach. recommendation, debiasing learning , user-feedback loop Recommendation has been a fundamental problem for many realworld applications ranging from e-commerce to healthcare. Many recommendation algorithms have been proposed in the last decade. Most of them tried to directly model explicit user feedback, such as the existing user-item ratings or user/item features. However, the implicit information hidden in recommendation systems can cause selection bias in the data and make the recommendation algorithms trained on such data not reliable. For example, on Netix a specic user will only rate a movie if he/she has been exposed to that movie. Because of the large number of movies and the integration of recommendation systems, it is unlikely that each user has an equal opportunity to be exposed to every movie. If we construct a user-item rating matrix, this selection bias makes the missing values in the matrix not at random, which is referred to as the Missing-Not-At-Random (MNAR) problem [11]. This makes the recommendation problem challenging. To adjust for such selection bias, researchers have proposed different strategies in recent years to make the recommendations more reliable. For example, Schnabel et al. [16] proposed to estimate the quality of a recommendation system by propensity-weighting type of approaches [7] and derived a matrix factorization approach to perform recommendation under the empirical risk minimization framework. Liang et al. [10] proposed to explicitly model user exposure as a latent variable in the probabilistic matrix factorization framework [12] and developed an exposure matrix factorization algorithm for making recommendations. Bonner and Vasile [2] proposed a domain adaptation approach to derive the causal embeddings of both users and items and estimate preference scores with them. All of the research we mentioned above focused on static recommendation settings, i.e., no temporal rating information has been considered. In reality, many recommendation algorithms tend to rate the item for a specic user according to his/her rating history. It means the dynamics of the user ratings play an important role in the recommendation system and will introduce implicit bias, which we refer to such induced bias as user feedback-loop bias. In this paper, we propose to systematically study the eect of user feedback-loop bias in recommendation systems and how to correct it in predicting item ratings. In particular, we design a novel probabilistic graphical model structure to estimate the dynamic/sequential item exposure probability distributions with respect to individual users. The estimated sequential exposure probabilities are then leveraged as propensity scores to adjust the user feedback-loop bias when we perform rating prediction for each specic item at each specic timestamp. We validate the existence of such user feedback-loop bias on the Movielens 20M and Goodreads dataset. We also demonstrate that better rating prediction performances and more diverse recommendation results can be achieved with the proposed dynamical de-biasing technique. In this section, we briey review the existing research that is related to this work. 2.0.1 Causal Recommendation. Dierent strategies have been proposed from the causal analysis perspective to make the recommendations more reliable. For example, researchers in [10,24,25] proposed to rst estimate exposures for each user and then use them to de-bias click prediction, which has led to promising results. Other works include [16] and [2] as mentioned above. These works focus on selection bias statically, while our paper studies selection bias as a dynamic process of how users rate the items over time. 2.0.2 User Feedback-Loop in Recommendation Systems. There are also recent studies on user feedback-loop and its inuences on recommendation systems [3,13,15,17,18]. With simulations, Chaney et al. [3] demonstrated that the data generated from recommendation systems are confounded by the underlying recommendation algorithm, and with the continuous utilization of such system the algorithm tends to recommend homogeneous items to each user again and again at the end, which signicantly decreased the users’ satisfaction of the system. Schmit et al. [15] developed a model for analyzing user feedback-loop in recommendation systems and showed by simulation that that estimators which ignore the feedback-loop will deviate from the ideal recommendations. Other works are studying the eects of this bias by training collaborative ltering algorithms and sampling new data with the trained algorithm iteratively [18]. And Sun et al. [21] develop an active learning method to debiasing the human-recommender system feedback loop. These works mainly illustrated via simulation the existence of user feedback-loop bias and its potential impacts in recommendation systems, however, such bias has not been validated in real-world data yet. In this paper, we empirically showed the existence of user feedback-loop bias in real recommendation systems and the correction of this bias would improve the quality of rate prediction, as evaluated by reduced prediction error and more diverse recommendation results. 2.0.3 Sequential Recommendation. Recently plenty of works have been proposed to model the sequential dependency of user behaviors. Some of them [6,14] model the item sequence with Recurrent Neural Network (RNN) and predict the next item a user will click, while some [22,26] use Convolutional Neural Network (CNN) for sequence embedding. All these works are proposed to solve the implicit recommendation problem where the input is a sequence of items that a user has interacted before, and as such their models are not suitable to model user rating sequence, which is an essential component in our proposal. First, we use the framework in [16] to illustrate how to correct selection bias for rating prediction with a static exposure model. Then we introduce user feedback-loop bias and extend the framework to a sequential setting. Suppose there are𝑁users and𝑀items; let𝑌 ∈ Rbe the rating matrix, where𝑌is user𝑖’s rating on item𝑗. Let𝑂 ∈ {0,1} indicate which items are rated by the users, that is,𝑂=1 if𝑌 is observed. Let 𝑃= P(𝑂= 1). For the task of rating prediction, a rating estimator will be trained and produce the predicted ratings asˆ𝑌. Standard criterion to measure the performance of the estimator is as follows: where𝛿can have dierent forms such as Mean Squared Error (MSE):𝛿 (𝑌,ˆ𝑌) = (𝑌−ˆ𝑌)and Mean Absolute Error (MAE): 𝛿 (𝑌,ˆ𝑌) = |𝑌−ˆ𝑌|. Since𝑌is not fully observed, in practice we can only measure 𝑅(ˆ𝑌 ) on observed data: However, because of the existence of selection bias,ˆ𝑅(ˆ𝑌 )is no longer an unbiased estimation of𝑅(ˆ𝑌 )[16,19], which means that E[ˆ𝑅(ˆ𝑌 )] ≠ 𝑅(ˆ𝑌 )(Eis the expectation over the observed set 𝑂). To make the estimation unbiased, Schnabel used the InversePropensity-Scoring (IPS) estimator [7] to de-bias the learning process of recommendation systems by minimizing the following cost: The eectiveness of IPS estimator depends on a good estimation of𝑃. Most of existing work build static exposure model to estimate𝑃[10,16] by considering dierent factors of selection bias. However, in real life, users rate items sequentially, and the system will change the recommendations according to users’ rating history, making these models incapable of correcting such user feed-back loop bias. As we stated above, recommendation systems rate the items and recommend customized items to the users according to the users’ rating history in reality. Items have dierent probability to be rated since users typically rate items they like and rarely rate items they dislike. After each rating, the probability distribution of the items recommended by recommendation systems has changed because of the growing rating history. In other words, the dynamics of the user’s rating history aect the work of recommendation systems and the sequential bias which the rating history leads to has to be considered. For further explanation, take an example in movie recommendation systems, users tend to rate movies with the styles they liked or popular recently, which are also the movies more likely to be exposed to the users.𝑀𝑜𝑣𝑖𝑒𝑙𝑒𝑛𝑠 −20𝑀is a real-world data collecting ratings for movies by users (detailed description is in the section 6.4.1). In which we select a part of the users’ rating history. The mean ratings of the selected users are as Figure 1. In addition to the notations introduced above, the items rated by user𝑖is represented as a sequence𝑆= {𝑠, ..., 𝑠}where the index𝑘for𝑠denotes the item order. The observed ratings for user𝑖are𝑌|𝑆= {𝑌, ..., 𝑌}.𝑂∈ Ris a one-hot exposure indication vector that𝑂=1 if𝑗 = 𝑠and𝑂=0 otherwise. Figure 1: Average of each rating. The rst 15 are the rates on items given by the recommendation system randomly respectively, and the rest are the rates on the movies recommended by the recommendation system according to the user’s rating history When user𝑖rates𝑠, the corresponding rating history before such event is dened as𝐻= {(𝑠, 𝑌), ..., (𝑠, 𝑌)}.𝑃is the probability that user 𝑖 rates item 𝑗 at order 𝑘. Keep in mind that on Movielens website the recommendation system asks a new user to rate 15 items rstly, then the system will select customized movies based on the previous rating history. The rst 15 rates can be regarded as unbiased rates respectively as they are not aected by any rates and all movies are likely to be recommended, while the other rates are aected by the previous rating history. As illustrated in Figure 1, the distribution of the rst 15 rates is far dierent from the distribution of the rest rates. The rst 15 rates are relatively low while the 16th rate increased a lot compared to the previous ratings. It means𝑃is extraordinary dierent from𝑃. Since the recommendation system gets the information about the user’s preference after 15 rates, it tends to recommend the movies that the user likes. After the rst 15 rates, the rates are getting lower and lower. Because classic movies are the minority, we guess the system prefer recommending movies with higher ratings rst. For the order𝑘 >15, the observed probability𝑃 doesn’t equals to𝑃. Assuredly, the movies recommended after 15 movies are aected by dynamic user feedback-loop bias caused by the previous rating history. Compared to existing research for adjusting the static selection bias, temporal user feedback-loop bias is dynamic as it is from the growing rating history. Our main objective is to build a model to estimate𝑃, which can be utilized to get an unbiased estimation of𝑅(ˆ𝑌 ). Here we assume the system conducts an algorithm to recommend items to a user based on rating history regularly. Specically, with the sequential exposure probabilities, we propose the corresponding IPS estimator as (we use SIPS to indicate Sequential IPS): which is an unbiased estimation of 𝑅(ˆ𝑌 ) because: In fact, the selection bias comes from dierent sources. Though we focus on user feedback-loop bias, we also take into account other factors to get a more precise estimation of𝑃. According to previous research [1], other common bias factors include user activity, item popularity and self-selection bias (i.e., users are more likely to rate the items they like). User activity and item popularity will be included in our model. The user’s self-selection bias is not considered. Based on the analysis above, we propose a novel dynamic exposure model to correct the sequential bias. Figure. 2 provides an overview of our dynamical/sequential exposure model. We assume the exposure probability of each user is determined by two kinds of latent variables: the rst one is the static 𝐷-dimensional latent factor𝑣sampled from a standard Gaussian prior. This variable is to represent the personal behavior/habit for a user to see and rate particular genres of items, which does not change along time: Figure 2: Dynamic exposure model. White nodes are variables which can be observed and collected, while the gray nodes are latent variables. The second one is a dynamic𝐷-dimensional latent process indexed by𝑘as𝑢. It represents how the system recommend items to a user based on rating history 𝐻: 𝑝 (𝑢|𝐻) : 𝑢∼ 𝑁 (𝜇(𝐻), Σ(𝐻)), where 𝜇and Σare functions of 𝐻. The𝑘item rated by user𝑖is sampled from a categorical distribution determined by 𝑣and 𝑢: where 𝜋 (𝑣, 𝑢) is a 𝑀-dimensional probability vector. Given the generative model, the posterior distribution of𝑣, 𝑢 is factorized as: We directly mimic the structure of the posterior with the following factorization of the variational approximation: We can get the variational lower bound oflog 𝑝 (𝑆|𝑌)as our loss function L to be optimized: log 𝑝 (𝑆|𝑌) = E− 𝐾𝐿(𝑞(𝑣|𝑆, 𝑌)||𝑝 (𝑣))+ log 𝑝 (𝑠|𝑣, 𝑢)), where𝑞(𝑣, u)is short for𝑞(𝑣, 𝑢|𝑆, 𝑌)and𝐾𝐿represents KL-divergence. We now detail how we construct the generative model and variational approximation by neural networks. The information of rating history𝐻is represented with a GRU (a kind of Recurrent Neural Network (RNN)), whose hidden stateℎis updated by whose hidden stateℎis updated with input of 𝑠and 𝑌: where𝑊and𝑊are embedding matrices for one-hot item vector𝑠and its rate𝑌,ℎis the𝐷-dimensional hidden state of GRU shared between generative and inference models. 4.1.1 Generative Network. For the generative process of𝑝 (𝑢|𝐻): where𝑊∈ R. The superscript𝑝means𝑊is the parameter of generative process and the subscript𝜇means𝑊is the mean parameter of variable𝑢.𝜇andΣare short for𝜇(𝐻) andΣ(𝐻). Similar rules apply to other parameters and functios dened below. The exposure distribution 𝜋 (𝑣, 𝑢) is calculated by: where 𝑊∈ R. 4.1.2 Inference Network. For the posterior distribution𝑞(𝑣|𝑆, 𝑌), we use a normal distribution to approximate it, whose mean and variance are calculated as functions of 𝑆and 𝑌: Σ= 𝑑𝑖𝑎𝑔(exp(1|𝑆|𝑊[𝑠, 𝑌] + 𝑏)). For the posterior distribution𝑞(𝑢|𝐻, 𝑠, 𝑣), we also use a normal distribution to approximate it, whose mean and variance are calculated as functions of𝐻, 𝑠, 𝑣. Note that inference function of𝑢shares parameters with the corresponding generative model by using the same hidden state of GRUℎto calculate the posterior mean and variance as follows: With the sequential exposure model, we use a two-step pipeline for de-biasing the rating prediction. Firstly, we train a dynamic exposure model as in Algorithm 1 where we use𝜃indicates all parameters of GRU, generative and inference networks and calculate the propensityˆ𝑃for each observed rating𝑌. We then useˆ𝑃as propensity scores to optimize for the evaluation function in equation (2) with MSE as loss function. We use Generalized Matrix Factorization (GMF) as rating prediction model, which is a generalized version of matrix factorization and achieve better performance on the validation set: where𝛼∈ Ris the user-specic vector,𝛽∈ Ris the itemspecic vector, and ℎ ∈ Rand 𝑎is the activation function. For each method, the grid search is applied to nd the optimal settings of hyperparameters using the validation set. For both tasks, hyperparameters include all related dimensions𝐷,𝐷and𝐷 Algorithm 1:Train the dynamic exposure model and estimate the exposure probability Input: 𝑆and 𝑌for all users Output:ˆ𝑃for all users and their rated items Initialize 𝜃 while not converged do forall user i do end end forall user i do Returnˆ𝑃for all users and their rated items from{16,32,64}, l2-normed regularization hyperparameter𝜆for exposure model and𝜆for rating model, learning rate𝑙𝑟from {10, ...,10}, batch size for rating model𝐵from{64,128,256,512}. We nd the performance of rating prediction is sensitive to𝜆, so we rst search it from{10, ...,10}and then from a ner range. For simulation data, the selected parameter sets are{𝐷, 𝐷, 𝜆, 𝑙𝑟 } = {32,32,0.0001,0.001}for exposure model and for rating prediction {𝐷, 𝜆, 𝑙𝑟, 𝐵} = {64,0.01,0.01,256}. For real-world data, the selected parameter sets are{𝐷, 𝐷, 𝜆, 𝑙𝑟 } = {32,32,0.0001,0.001} for exposure model and{𝐷, 𝜆, 𝑙𝑟, 𝐵} = {32,0.004,0.01,256}for rating model. In our GMF rating prediction model, we choose identity mapping as activation function by performance on validation set. In Movielens and Goodreads data, the increased variance problem for IPS estimator is very severe. So we also adjust propensity scores from our model into a reasonable range. We also use the technique of propensity clipping [20] to clip propensity scores which is too high or too low for all kinds of de-biasing methods including Pop and PF. These procedures and clipping thresholds are decided by performance on validation set. Since the ideal test set for evaluation of de-biased rating prediction is a set where users rate randomly selected items and there is no real-world dataset that contains both a random test set and sequential information at our best knowledge, existing research mainly generate a skewed test set by adjusting user activity and item popularity [2,9], but a simulated skewed test set still suers user feedback-loop bias. In our experiments, compared with previous work that focused on simulated data, we evaluate our model with all baselines both on simulated data and real-world data,𝑀𝑜𝑣𝑖𝑒𝑙𝑒𝑛𝑠and𝐺𝑜𝑜𝑑𝑟𝑒𝑎𝑑𝑠 in which a test set without user feedback-loop bias can be extracted. In the procedure of de-biasing rate prediction, exposure probability prediction and de-biased rate prediction share the same training and validation set, while one test set from biased observational data is used to evaluate the task exposure probability prediction and the other unbiased test set for the task de-biased rate prediction. We compare our dynamic exposure model with two baseline models in previous work[9]: popularity model (Pop) and Poisson factorization model (PF). In the popularity model, the exposure probability is the portion of the users who have been exposed to the item. In the Poisson factorization model, the exposure probability follows Poisson distribution whose parameter is determined by latent embeddings of user and item[4]. To evaluate the performance of de-biased learning, we use GMF as the model predictor and trained with evaluation functions without de-biasing (Naive) and with propensity scores estimated by Pop, PF and our model. 6.2.1 Exposure Prediction. For the task of exposure probability prediction, we evaluate its performance by the following matrix on the test set for exposure: Negative Log-Likelihood of the estimated exposure probability (NLL, smaller NLL means more accurate exposure probability). Recall@50 and NDCG@50 (bigger Recall@50 and NDCG@50 means more reasonable estimators) are rankingbased evaluation metrics of recommendation and their detailed denitions can be found in [9, 10]. 6.2.2 De-biased Rate Prediction. For this task, we evaluate its performance by measuring the distance between the predicted rating matrixˆ𝑌and the true rating matrix𝑌. In particular, we evaluate de-biased rate prediction with Mean Squared Error (MSE) and Mean Absolute Error (MAE) on an unbiased test set. where N is the number of users and M is the number of items, 𝑌means the rate on the i users for the j items. 6.2.3 Recommendation Diversity. Besides the evaluation of the accuracy of the predicted ratings, for the experiments on realworld data𝑀𝑜𝑣𝑖𝑒𝑙𝑒𝑛𝑠and𝐺𝑜𝑜𝑑𝑟𝑒𝑎𝑑𝑠, we want to measure the quality of the recommendation another way. To this eect, we evaluate the diversity of recommendations provided by the trained rating prediction model. With the trained model, we will generate a list of highest-rated items (The length of the list is 10 in Movielens and 20 in Goodreads). Then we calculate the Gini coecient and average dissimilarity [8]. The Gini coecient measures the inequality among the frequency distribution of items recommended to all users, let𝑃, 𝑗 =1, ..., 𝑀be the popularity of each item with recommendation and sort them in non-decreasing order as 𝑃(𝑃≤ 𝑃), the Gini coecient is calculated as follows: Average dissimilarity measures the dissimilarity within the recommendation list of each user, which is dened as follows: where𝑐is a vector represents the characteristic of item𝑗and 𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦is a similarity measurement. We use the vector of genres in Movielens dataset as𝑐and use cosine similarity. Based on the denitions, when Gini coecient is smaller and the average dissimilarity is bigger, the recommendation result is more diverse. 6.3.1 Simulated dataset. For simulation, we create a community that consists of 3000 users and 1000 items. The rating matrix is generated with the same forms of functions used in previous related paper [3]. And we tune the parameters to make the distribution of data closer to real data. The dimension of the latent variables (𝛼and𝛽) is 10.𝜇∼ 𝐷𝑖𝑟𝑖𝑐ℎ𝑙𝑒𝑡 (20)and𝛼∼ 𝐷𝑖𝑟𝑖𝑐ℎ𝑙𝑒𝑡 (𝜇)for each user. Similarly,𝜇∼ 𝐷𝑖𝑟𝑖𝑐ℎ𝑙𝑒𝑡 (100)and𝛽∼ 𝐷𝑖𝑟𝑖𝑐ℎ𝑙𝑒𝑡 (𝜇) for each item. We rst sample a value from Beta distribution with mean as𝛼𝛽and variance as 0.01. Then we times the value with 10 to getting the rating𝑌make. All ratings range in[0,10]. The true similarity matrix of items is dened as 𝑆 and 𝑆= 𝛽𝛽. We use the following procedure to simulate the user feedbackloop: a xed similarity matrixˆ𝑆is generated in advance to simulate the system have a pre-trained but not perfect recommendation algorithm: eachˆ𝑆is sampled from a beta distribution with a mean of true similarity𝑆and variance of 0.01. The system will combine a user’s rating history andˆ𝑆to determine recommendation ranking with item-based collaborative ltering algorithms. The exposure distribution is aected by recommendation ranking: the exposure probability of top-100 ranked items will be 10 times as the others. For each user, the process will iterate for 30 times to generate the biased observational data. We choose the 1-20,21-25 and 26-30 items of each user as training, validation and test set for exposure probability prediction. We sample an extra 20 items randomly to construct the unbiased test data for rating prediction. The simulation will be repeated with ten random seeds. For each simulation "world", we will train each exposure model for once and report the averaged performance over the ten worlds. For de-biased rating prediction, we will repeat experiment 10 times for each world and report the result all averaged over the 10 × 10 experiments. 6.3.2 Performance on Simulation Dataset. The results of simulation experiments is summarized in Table 1 and 2. As is illustrated in Table 1, for exposure prediction, our model outperforms the baseline methods Pop and PF obviously in the indicator of NLL, RECALL@50 and NDCG50. In Table 2, the result shows that Pop and PF have a slight performance improvement over Naive method on the simulation dataset, while our model surpasses all baselines for the task of de-biased estimator. Table 1: Exposure prediction performance on simualtion data. Ours 6.813 ± 0.019 0.1351 ± 0.021 0.056 ± 0.008 Table 2: Rating prediction performance on simualtion data. Table 3: Summary of each periods of Movielens data. Table 4: Summary of each periods of Goodreads data. In this section, we will introduce our experiments on𝑀𝑜𝑣𝑖𝑒𝑙𝑒𝑛𝑠 dataset and𝐺𝑜𝑜𝑑𝑟𝑒𝑎𝑑𝑠dataset. In each experiment, we will demonstrate the dataset pre-processing, the experiment settings, the results, and our analysis. 6.4.1 Movielens Dataset. Movielens-20M is a benchmark dataset for movie rating prediction. The data ranging from 1996 to 2015 when the interface and recommendation algorithms used in Movielens website change [5]. We study the range from 2005 to 2011 when Movielens system remains the same interface and recommendation algorithm. We further divide the data into three overlapped periods [01/01/2005,31/12/2008], [01/01/2006,31/12/2010] [01/01/2007,31/12/2011] (called𝑃,𝑃and𝑃respectively) with similar amount of data to show our method can achieve consistent advantage over baselines. For each period, we select the users who registered in this period. And we only keep the users who rate at least 65 items and use the rst 65 items for training and evaluation. We decide the split of the dataset based on the system’s rule: a new user is asked to rate 15 items before the system recommends movies to him/her. So the rst 15 items rated by a user will not be aected by user feedback-loop bias. So we select the rst 15 items as a test set of rating prediction. We used the 16-45 and the 46-55 items for training and validation. The 56-65 items are used as the test set of exposure prediction. We only keep the items Figure 3: MSE of items with dierent popularities in Movielens data. with popularity more than 100. To avoid leakage of information, We do not include the rst 15 items when training the sequential exposure model. After pre-processing, the statistics of each period are summarized in Table 3. For each period, we repeat the rate prediction experiments 10 times to ensure the results are reliable. 6.4.2 Performance on Movielens Dataset. Table 5 shows the performance of exposure prediction in Movielens dataset. The performance of rating prediction and diversity of recommendation results are shown in Table 6 and 7. As we treat the selection bias sequentially, our model gets more accurate exposure probability and outperforms all baselines in the three periods in the tasks of exposure prediction. For the task of rating prediction, our model gets a better performance compared with the baselines. In the table 7, our model achieves more diverse recommendations. We also separate test data of rate prediction in half by items’ popularity in training data, then compare MSE in high-popularity items (H-items) and low-popularity ones (L-items) in Figure 3. We can see the rating prediction on low-popularity items can benet from our debiasing method. 6.4.3 Goodreads Dataset. Goodreads is a large-scale dataset from the book review website𝐺𝑜𝑜𝑑𝑅𝑒𝑎𝑑𝑠which contains 229,154,523 records and they are organized from 876,145 users’ bookshelves and covers 2,360,650 books [23]. In which we select the data collected after 15th September 2011 since then the𝐺𝑜𝑜𝑑𝑅𝑒𝑎𝑑𝑠recommendation system changed the recommendation algorithm. Similar to the Movielens recommendation system, the𝐺𝑜𝑜𝑑𝑅𝑒𝑎𝑑𝑠asks a new user who registered after 15th September 2011 to rate 20 books rstly before the system recommends customized books. We decide the rst 20 books as test set of rating prediction on account of the rst 20 items rated by a user will not be aected by user feedback-loop bias. We choose the 21-50 items for training, 51-60 for validation and 61-70 for test. To avoid information leakage, the training dataset doesn’t contain the rst 20 items when we train the sequential exposure model. For all records, we only select 3000 the most popular books. As the records range from 2011 to 2017, we divide the data into 3 disjoint periods[16/09/2011,31/12/2012], [01/01/2013,31/12/2014] and [01/01/2015,31/12/2017](called𝑃,𝑃,𝑃respectively) with similar amount of records. For each period, we select the users who registered in this period. Considering too much time-consuming in each experiment if we use all records, we select 10000 records randomly each period in all the experiments. After pre-processing, the statistics of each period are summarized in Table 4. For each period, we repeat the rate prediction experiments 10 times as the Movielens experiment does. 6.4.4 Performance on Goodreads Dataset. The results of the experiments on Goodreads Dataset are shown in Table 8, 9 and 10. In which the exposure prediction performance is in Table 8, our model surpasses all baseline in each period. As for the accuracy of rating predictions, Table 9 illustrates that all the methods perform almost the same. As there may exist bias-variance trade-o in de-biasing methods [16], more accurate exposure probability predictions may mean higher variance of propensity scores. The high variance of propensity is much severe in real-world data and it can hurt the performance of the debiased method. Since the category of one book is indistinct, the book may belong to the category of romance, fantasy and story. In our task of measuring dissimilarity, we regard the most relevant category of the book as its genre and the results are shown in Table 10. We can see that our method provides the most diverse recommendation results. Based on the experiments on simulated data and real-world data, we make the following observations: (1)Our sequential exposure model substantially and signicantly outperforms the static models. In the real-world datasets, our model achieves the best performance on the task of exposure probability prediction. In the task of rating prediction, we surpass existing de-biasing methods in simulated dataset. This suggests there exists user feedback-loop bias in realworld data and models with the dynamic mechanism can improve the performance of exposure prediction. (2)In simulation and Movielens data, the rating prediction with de-biasing mechanism is better than the naive estimator, while our method achieves the best results. We can also see recommendation performance is more stable across popularities of items from Figure 3. In Goodreads dataset, the performance between naive estimator and debiased estimators are quite similar due to the negative impact of high variance counterbalances the postive impact of less biased estimation. (3)Our dynamic model improves the recommendation quality. With de-biasing learning, the recommendation results are more diverse with the measurement of both Gini coecient and average dissimilarity. In the Movielens and Goodreads experiments, our method outperforms baselines by Gini coefcient in all periods and achieves close average dissimilarity compared to baselines. By propensity score re-weighting, more diverse items are recommended when we get better results on rating prediction. We propose to systematically correct user-feedback loop bias for training and evaluating explicit-rating recommendation algorithms. We design a novel probabilistic graphical model structure to estimate the dynamic item exposure probability distributions with respect to individual users. The estimated probabilities are used as propensity scores to adjust the user feedback-loop bias in sequential rating prediction. We show the superiority of our method over other models with statically estimated exposure probabilities. Experiments on simulated data demonstrate the existence of user feedback bias and our method can achieve better performance on exposure probability prediction and de-biasing rating prediction. By adjusting the bias sequentially, more diverse items are recommended with more reasonable exposure probability. More importantly, we get expected results on exposure predictions and de-biasing rating predictions on the two real-world datasets.