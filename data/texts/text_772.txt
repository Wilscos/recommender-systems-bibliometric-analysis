 the structure of individual diﬀerences in cognitive tasks. In brief, the method relies on To answer the question of “Does everybody. . . ?” in the context of performance on cognitive tasks, Haaf and Rouder (2017) developed a class of hierarchical Bayesian mixed models with varying levels of constraint on the individual eﬀects. The models are then compared via Bayes factors, telling us which model best predicts the observed data. One common criticism of their method is that the observed data are assumed to be drawn from a normal distribution. However, for most cognitive tasks, the primary measure of performance is a response time, the distribution of which is well known to not be normal. In this technical note, I investigate the assumption of normality for two datasets in numerical cognition. Speciﬁcally, I show that using a shifted lognormal model for the response times does not change the overall pattern of inference. Further, since the model-estimated eﬀects are now on a logarithmic scale, the interpretation of the modeling becomes more diﬃcult, particularly because the estimated eﬀect is now multiplicative rather than additive. As a result, I recommend that even though response times are not normally distributed in general, the simpliﬁcation aﬀorded by the Haaf and Rouder (2017) approach provides a pragmatic approach to modeling individual diﬀerences in cognitive tasks. Keywords: individual diﬀerences, hierarchical Bayesian model, lognormal distribution, response times Recently, Haaf & Rouder (2017) provided a methodological innovation for investigating assuming that the resultant behavioral measures (e.g., response times) are drawn from a normal distribution whose mean is represented as a linear combination of a variable intercept and slope (eﬀect). In turn, each of these parameters is further drawn from normal distributions centered at 0 and scaled according to overall variability. Diﬀerent models of individual diﬀerence structure are instantiated by placing varying levels of constraint on the slope/eﬀect parameter. Critical to the Haaf & Rouder (2017) method is a Bayesian comparison of these models, which uses a combination of the well-known analysis of variance approach developed by Rouder, Morey, Speckman, & Province (2012) and the encompassing prior approach Faulkenberry (2019). The approach has been used successfully to investigate the structure of individual diﬀerences in many cognitive phenomena, including Stroop and Simon eﬀects (Haaf & Rouder, 2018), the truth eﬀect (Schnuerch, Nadarevic, & Rouder, 2020), numerical distance eﬀects (Vogel, Faulkenberry, & Grabner, 2021), and the numerical size congruity eﬀect (Faulkenberry & Bowman, 2020). performance measures are drawn from a normal distribution. This criticism is particularly salient when the primary measure is response time, as response times are well known to exhibit a distinct positive skew. While there are many methods for modeling response times using skewed distributions (i.e., ex-Gaussian, inverse Gaussian / Wald, etc.), the implementation of such distributions into the Haaf & Rouder (2017) framework is quite diﬃcult. One simple approach that might prove attractive is to assume that the observed response times follow a (shifted) lognormal distribution; then, the analyst may simply transform the observed response times by ﬁrst shifting by a ﬁxed amount (e.g., 200 milliseconds is a common recommendation) and then taking the (natural) logarithm. The resulting distribution of (log) response times is then approximately normal and may be “fed into” the Haaf & Rouder (2017) method with little diﬃculty. (2017), particularly as applied to cognitive tasks where the primary observed data are response times. Before going into the details, I will reiterate that the main aim of this approach is to build a (hypothetical) generative process for each observed response time in a cognitive task. That is, there is no aggregation of trials at the individual or group level that needs to occur. One criticism of the Haaf & Rouder (2017) method is the assumption that raw The purpose of this brief paper is to investigate this approach and to argue two points. the inferences obtained from the shifted lognormal model are exactly the same as those obtained from the original model with the normality assumption; and interpreting the estimated model parameters from the shifted lognormal model is nontrivial and potentially inappropriate in the context of these cognitive tasks. First, I will describe the Bayesian mixed model approach developed by Haaf & Rouder Each observed response time is assumed to be the sum of four components: (1) a grand mean gives a “random” intercept for each subject); (3) a subject-speciﬁc eﬀect term noise term is drawn from some to-be-deﬁned probability distribution. Of particular interest is the distribution that generates each subject’s eﬀect term – this distribution is the one on which we build our competing models of individual diﬀerence structure. experimental condition (usually two conditions, so that eﬀects linear model on the vector of response times Y Here, for subject each trial. For example, suppose we are interested in modeling a congruity eﬀect, where response times on incongruent trials generally increase compared to those of congruent trials. In this case, for congruent trials (condition incongruent trials (condition then represents the (random) congruity eﬀect for subject sampling variance of the observed response times. (i.e., the distribution from which each subject’s size-congruity eﬀect We deﬁne four possible populations for these of four possible theoretical positions about the distribution of eﬀects. The unconstrained model type/quality (i.e., positive or negative) as well as magnitude. As such, with place no constraint on the individual eﬀects δ where eﬀects δ The positive-eﬀects model quantity (i.e., they are always positive, but possibly diﬀer in magnitude between subjects). Mis a constrained model in the sense that it speciﬁes the assumption that all individual eﬀects δ where Normal µ; (2) a subject-speciﬁc adjustmentαto the grand mean (i.e., so thatµ+α ε. The hierarchical model is then built by assuming each of these components We letYdenote the response time for thekreplicate of theisubject in thej µdenotes the grand mean intercept andαrepresents the speciﬁc intercept adjustment i. The termxis a binary variable which codes the experimental condition for The next step is to propose a structure for the parent distribution of random eﬀectsδ The unconstrained model, denotedM, allows the eﬀectsδto vary both in νandηrepresent the mean and variance, respectively, of the distribution of individual The positive-eﬀects model, denotedM, hypothesizes that eﬀectsδonly vary in are positive. That is, The common-eﬀect and null models in studies on individual structure, the common-eﬀect and null models are deﬁned to provide a critical check of experimental design. The common-eﬀect model places even more constraint on the distribution of eﬀects by assuming that each individual has the same eﬀect. That is, Such a model serves to probe the following question: if the common-eﬀect model was the best predictor of the observed data, one would be forced to question the eﬃciency of the experimental design as a test to elicit individual diﬀerences in the eﬀect. As one might expect, the null model is the most constrained of the four, as it speciﬁes that each subject’s size-congruity eﬀect is zero: It is used for a similar reason: if the null model was the best predictor of the observed data, then one must question the eﬃciency of the experimental design to elicit eﬀects of any sort. “default” prior speciﬁcations. The critical parameters I’ll describe here are The default procedure is to use the which re-expresses these parameters as a standardized eﬀect size. To see how this works, consider the collection of individual eﬀect parameters hyperparameter that casts the variability of sampling variability σ Similarly, we may scale the mean size-congruity eﬀect get a new hyperparameter priors as well. The default speciﬁcation (Zellner, 1986) is to use with one degree of freedom and scale r parameters in terms of sampling variability specifying priors on variability of our eﬀects relative to the expected overall variability of the observed response times. Like Haaf & Rouder (2017), I will use the variability of observed response times. mean size-congruity eﬀect. With the Whereas the unconstrained and positive-eﬀects models are usually the primary players Generally, most applications of the Haaf & Rouder (2017) method follow similar To be clear, theg-prior setup is quite clever, as it completely describes these critical Now we can actually ﬁnish setting our priors. First we considerg, theg-prior on the where the relative magnitude of our expected eﬀects. For the types of eﬀects we often see in numerical cognition (and certainly the types of tasks we will describe in this paper), I usually expect such eﬀects to be, on average, around 50 milliseconds, or 1/6 of the expected overall trial-by-trial variability (σ = 300 milliseconds). Thus, we set r the mean eﬀect. With the & Rouder (2017), we set the eﬀect across individuals should be about 1/10 of milliseconds. Model comparison eﬀects we observe in our cognitive task, our problem is ﬁrst and foremost one of model comparison. That is, we ask which of the four competing models deﬁned above is the most adequate as a predictor of our observed data? To answer this question, we use Bayes factors (Jeﬀreys, 1961; Kass & Raftery, 1995), which index the relative predictive adequacy of two models by comparing the marginal likelihood of observed data under one model to another (Faulkenberry, Ly, & Wagenmakers, 2020). For example, a Bayes factor of 10 indicates that the observed data are 10 times more likely under one model compared to another. Techniques for computing Bayes factors among three of the four models above the BayesFactor (Morey & Rouder, 2018) package in R (R Core Team, 2020). The Bayes factor between the constrained positive eﬀects model Mis computed by the encompassing prior method (Faulkenberry, 2019; Klugkist et al., 2005), which is based on counting the number of posterior samples of constraint placed by the same constraint. (2017) method, assumes that the observed response times are drawn from a normal distribution, to a modiﬁed approach where the observed response times are drawn from a lognormal distribution. To do this, I will perform two case studies where I analyze two datasets that have already appeared in the literature. In case study 1, I will model the latent structure of individual diﬀerences in the size congruity eﬀect (Henik & Tzelgov, 1982), a classic phenomenon in numerical cognition in which people are slower to choose the larger of two presented numbers when the numbers are presented in a physical size that is incongruent with their relative numerical magnitude (e.g., a large numeral 2 displayed alongside a small numeral 8). The data for case study 1 (19499 response times from g∼ Inverse-χ(r). The scale parameterrshould reﬂect our prior belief about Second, we considerg, which describes the variability of individual eﬀects around Since our goal is to capture the latent structure of individual diﬀerences in the M,M) were previously developed by Rouder et al. (2012) and are implemented in My goal in this paper is to compare the inferences from the default Haaf & Rouder originally reported in Bowman & Faulkenberry (2020). In case study 2, I will model the latent structure of individual diﬀerences in the unit decade compatibility eﬀect, another classic phenomenon in numerical cognition (Nuerk, Weger, & Willmes, 2001). The data for case study 2 (11600 response times from part of a collaborative pregistration project by Cipora et al. (2021). Figure 1 . Individual eﬀect estimates (left column) and Bayes factor model comparisons (right column) for Case Study 1 under a normal distribution assumption. Posterior means and 95% credible intervals for + symbols represent the observed size-congruity eﬀect for each subject. The red dashed-line represents the estimated mean size-congruity eﬀect box denotes the winning model, and Bayes factors are displayed beside each arrow. places a normal distribution on the observed response times. The individual eﬀect estimates from the unconstrained model are displayed in the left column of Figure 1. We can see that the observed eﬀects for each subject (denoted by black crosses) span from -14.59 ms to 142.10 ms. In this context, we compute observed eﬀects by subtracting each subject’s mean response time for congruent trials from the mean response time for incongruent trials. With the exception of one subject, the observed size-congruity eﬀects are all constrained to be positive. Estimates from the hierarchical Bayesian model are displayed as blue dots with shaded 95% credible intervals. These estimates are computed as means of the posterior samples for each posterior samples (i.e., ranging between the 2.5% and 97.5% quantiles of the samples). The The ﬁrst analysis I will describe is the default Haaf & Rouder (2017) method, which red dashed line represents an (posterior) estimated mean eﬀect of ν = 60 ms. we observe a fair amount of shrinkage in our estimates. Notice that the estimated eﬀects (the blue dots) extend over a smaller range (8.84 ms to 115.73 ms) than the observed eﬀects (the black crosses; -14.59 ms to 142.10 ms). This shrinkage reﬂects how the hierarchical model accounts for sampling variability at all levels. can see, the observed data were 7.19 times more likely under the positive-eﬀects model Mthan under the unconstrained model which is equivalent to a posterior probability of overhelmingly preferred over the common-eﬀect model was more likely to have predicted the observed data by factors of 10 respectively. on the observed response times. To do this, we transform the observed response times by ﬁrst subtracting a constant amount from each response time (here, I chose a shift of 200 milliseconds), then taking the (natural) logarithm of the result. As we can see in Figure 2, the transformed distribution appears approximately normal, indicating that the lognormal model is appropriate for us here. The resulting transformed data can be directly modeled as above, the results of which I will now describe. Figure 2 . Distributions of observed response times in the size congruity task (Case study 1). The left panel displays the original observed response times, whereas the right panel displays the log-transformed response times. similar patterns of observed eﬀects, estimated eﬀects, and shrinkage. For the log transformed data, we see a posterior estimated common eﬀect (red dashed line) As is usually seen with this type of modeling (and hierarchical modeling in general), The right column of Figure 1) shows the Bayes factor model comparisons. As we , this means that our posterior odds in favor ofMhave increased to 7.19-to-1, Next, we perform the same procedure while assuming a shifted lognormal distribution The overall similarity of these results with the ﬁrst analysis is striking. We see very Figure 3 . Individual eﬀect estimates (left column) and Bayes factor model comparisons (right column) for Case Study 1 under a lognormal distribution assumption. Posterior means and 95% credible intervals for + symbols represent the observed size-congruity eﬀect for each subject. The red dashed-line represents the estimated mean size-congruity eﬀect box denotes the winning model, and Bayes factors are displayed beside each arrow. transform this back to the original response time scale, we get an estimated common eﬀect of 1.16. Because the data are on a logarithmic scale, this eﬀect is multiplicative, so an estimated eﬀect of 1.16 is a 16% increase in response times. For these data, this is roughly equivalent to a response time increase of 86 ms. Figure 3) we can see the observed data were 6.21 times more likely under the positive-eﬀects model overhelmingly preferred over the common-eﬀect model M obtain from using a shifted lognormal model on observed response times is very similar to that when we use the default normal speciﬁcations recommended by Haaf & Rouder (2017). In both cases, the positive eﬀects model is preferred over the unconstrained model. (2017) method with a normal distribution on the observed response times. The individual eﬀect estimates from the unconstrained model are displayed in the left column of Figure 4. The observed eﬀects for each subject (denoted by black crosses) span from -5.37 ms to 137.52 The similarity persists with the Bayes factor comparisons. In the right column of Mthan under the unconstrained modelM. Further, these models were again In all, it seems that with the exception of the raw eﬀect estimate, the inferences we As above, I will ﬁrst report the results of modeling using the default Haaf & Rouder Figure 4 . Individual eﬀect estimates (left column) and Bayes factor model comparisons (right column) for Case Study 2 under a normal distribution assumption. Posterior means and 95% credible intervals for + symbols represent the observed size-congruity eﬀect for each subject. The red dashed-line represents the estimated mean size-congruity eﬀect box denotes the winning model, and Bayes factors are displayed beside each arrow. ms. Similar to Case Study 1, the observed numerical distance eﬀects were mostly positive. Estimates from the hierarchical Bayesian model are displayed as blue dots with shaded 95% credible interval. The red dashed line represents an (posterior) estimated mean eﬀect of ν= 43 ms. Note that we again observe shrinkage in our estimates, as the estimated eﬀects extend from 15.04 ms to 92.80 ms), a smaller range that that of the observed estimates. case, the observed data were 4.17 times more likely under the positive-eﬀects model than under the unconstrained model this means that our posterior odds in favor of equivalent to a posterior probability of models were strongly preferred over the common-eﬀect model M on the observed response times. As before, we transform the observed response times by ﬁrst subtracting a constant amount from each response time (here, I chose a shift of 200 milliseconds), then taking the (natural) logarithm of the result. As we can see in Figure 5, the transformed distribution appears approximately normal, indicating that the lognormal model is appropriate for us in this case study. The right column of Figure 4) shows the Bayes factor model comparisons. In this Next, we run the analysis again, but this time assuming a shifted lognormal distribution Figure 5 . Distributions of observed response times in the numerical comparison task (Case study 1). The left panel displays the original observed response times, whereas the right panel displays the log-transformed response times. Figure 6 . Individual eﬀect estimates (left column) and Bayes factor model comparisons (right column) for Case Study 2 under a lognormal distribution assumption. Posterior means and 95% credible intervals for + symbols represent the observed size-congruity eﬀect for each subject. The red dashed-line represents the estimated mean size-congruity eﬀect box denotes the winning model, and Bayes factors are displayed beside each arrow. eﬀects, and shrinkage in Figure 4. For the log transformed data, we see a posterior estimated common eﬀect (red dashed line) equivalent to an estimated (multiplicative) common eﬀect of 1.09, a 9% increase in response times. For these data, this is roughly equivalent to a response time increase of 57 ms. Figure 6) we can see the observed data were 8.40 times more likely under the positive-eﬀects model preferred over the common-eﬀect model from using a shifted lognormal model on observed response times is very similar to that when we use the default normal speciﬁcations recommended by Haaf & Rouder (2017). In both cases, the positive eﬀects model is preferred over the unconstrained model. times exhibit positive skew, the inference we obtain from applying the default Haaf & Rouder (2017) method (which assumes a normal distribution on response times) is the same as when we apply a shifted lognormal model on response times. In both cases, applying a shift and then taking the natural logarithm of the observed response times does indeed transform the distribution of observed data into one which is approximately normal. Certainly, the Haaf & Rouder (2017) method works well for this transformed data, but the penalty is in the interpretation. When the observed data is tranformed to the log scale, the “eﬀects” we see in the data (i.e., diﬀerences between the observed data that occur as a function of the experimental manipulation) are now diﬀerences in the log scale. Diﬀerences in the log scale become multiplicative diﬀerences (i.e., quotients) when we transform back to the original scale of the response times. While multiplicative eﬀects can make sense in many contexts, such eﬀects are not typical in the context of cognitive eﬀects on response time. Indeed, most typical response time models assume that total response time is the sum of its constituent subprocesses. As such, it is not clear how one of these cognitive eﬀects could reasonably interpreted in a multiplicative context. of estimated eﬀects becomes less clear, there is no compelling reason to reject the normal assumption on response times when applying the Haaf & Rouder (2017) method for investigating individual diﬀerence structures in cognitive tasks. As with Case Study 1, we see very similar patterns of observed eﬀects, estimated The Bayes factor comparisons also present the same message. In the right column of Mthan under the unconstrained modelM. Further, these models were again Both case studies lead to a common conclusion. Even though the observed response Given that (1) the pattern of inference does not change, and (2) the interpretation