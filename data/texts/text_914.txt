Sungkyunkwan UniversityNaver Corp. Session-based recommendation (SR) predicts the next items from a sequence of previous items consumed by an anonymous user. Most existing SR models focus only on modeling intra-session characteristics but pay less attention to inter-session relationships of items, which has the potential to improve accuracy. Another critical aspect of recommender systems is computational eciency and scalability, considering practical feasibility in commercial applications. To account for both accuracy and scalability, we propose a novel session-based recommendation with a random walk, namely SWalk. Precisely, S-Walk eectively captures intra- and inter-session correlations by handling high-order relationships among items using random walks with restart (RWR). By adopting linear models with closed-form solutions for transition and teleportation matrices that constitute RWR, S-Walk is highly ecient and scalable. Extensive experiments demonstrate that S-Walk achieves comparable or state-of-the-art performance in various metrics on four benchmark datasets. Moreover, the model learned by S-Walk can be highly compressed without sacricing accuracy, conducting two or more orders of magnitude faster inference than existing DNN-based models, making it suitable for large-scale commercial systems. • Information systems → Recommender systems;Collaborative ltering; Expert systems. Collaborative ltering; Session-based recommendation; Random walks; Closed-form solution ACM Reference Format: Minjin Choi, Jinhong Kim, Joonseok Lee, Hyunjung Shim, and Jongwuk Lee. 2022. S-Walk: Accurate and Scalable Session-based Recommendation with Random Walks. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining (WSDM ’22), February 21–25, 2022, Tempe, AZ, USA. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3488560. 3498464 Modern recommender systems (RS) are indispensable for addressing the enormous information overload in various real-world applications, such as e-commerce platforms and online multimedia platforms, e.g., Amazon and Alibaba, YouTube, Netix, and Spotify. Classical recommender systems [12,15,19,44] usually assume that user accounts and users’ long-term interactions are available. However, this assumption rarely holds. The user may not login, or multiple users share the user account, e.g., family members. The user may also exhibit dierent behaviors depending on the context. Thus, it is necessary to provide personalized recommendations without explicit user information. Recently, session-based recommendation (SR) [3,9,22,42,51] has gained considerable attention for predicting the next items from the sequential behavior consumed by an anonymous user. Unlike conventional RS, SR relies only on the users’ actions in an ongoing session. This setting of SR is well-suited for real-world scenarios but inherently results in a severe data sparsity problem. To address this issue, it is essential to understand the unique characteristics of sessions, that is, intra-session properties. First, the items within a session are coherent with the user’s hidden intent, e.g., a list of products in the same category, referred to as item consistency (or long-term dependency). Second, some items are strictly consumed in chronological order, namely sequential dependency (or short-term dependency), e.g., consecutive episodes of a TV series. Lastly, the user can repeatedly consume the same items, called repeated item consumption, e.g., user’s favorite tracks. Most SR models utilize deep neural networks (DNNs) to learn intra-session relationships. Recurrent neural networks (RNNs) [16– 18] and attention mechanisms [31,32] have been used to model the sequential dependency of items. Recently, graph neural networks (GNNs) [1,13,40,41,50,53,54] have been used to eectively Figure 1: Illustration of intra- and inter-session relationships. The red shoes and the gray shoes (in blue box) do not appear within a single session, but they are correlated because both are related to the orange shirt (in red boxes). represent both item consistency and sequential dependency. Unfortunately, they suer from performance degradation when dealing with complex and long sessions, where it is dicult to understand user intent. For this, inter-session relationships among items are valuable clues. Figure 1 describes intra-session and inter-session relationships; some items do not occur within a single session but share their neighboring items for multiple sessions, implying potential item correlations. Several studies [36,50,52] have attempted to consider inter-session relationships using neighboring sessions or global item graphs. However, they incur substantial computational costs and are infeasible for large-scale commercial systems. High-capacity DNN models have achieved state-of-the-art performances but usually require heavy computational overhead for runtime speed and memory consumption. Although competing for the best performance is a reasonable mission for most research problems, computational eciency and scalability are also critical factors for dealing with practical restrictions in commercial recommender systems. [11,33] suggested neighborhood-based models for session-based recommendations. Owing to their simplicity, they are highly scalable. Moreover, [34,35] reported that the neighborhoodbased models achieved comparable performances to DNN-based models on several benchmark datasets. Our primary objective is to design an SR model that accounts for both accuracy and scalability. To this end, we propose a novel session-based recommendation with a random walk, namely S-Walk, (i) exploiting intra- and inter-session relationships among items to improve accuracy, and (ii) supporting cost-eective, real-time performance at scale. (i) Whereas the basic SR learns hidden patterns between items only within a session, S-walk additionally introduces global item graphs, modeling item-item relationships across all sessions. By applying random walks with restart (RWR) on this graph, a random surfer can jump from one item to another adjacent item by traversing the item graph or restart from an arbitrary item in the current session. Therefore, S-Walk can capture high-order correlations among items using multi-hop connections on an item graph. S-Walk can exploit the local patterns within a session and global patterns involving the same items from other sessions. (ii) Recently, linear item-item models [23,45–47] have shown competitive performance in conventional RS. Motivated by their success, we devise linear item models to build two probability matrices, item transition and item teleportation matrices, to formulate the stochastic process of RWR. The item transition matrix captures the sequential dependency of items, generalizing a Markov chain model on items. The item teleportation matrix reects the restart probability, allowing various items to participate in the model training depending on the ongoing session. Instead of having arbitrary items for restart, we utilize the co-occurrence relationship among items. The items that co-occurred with the current session items are used for restart. Notably, training our linear models is highly efcient and scalable because they have closed-form solutions whose computational complexity is determined by the number of items, independent of the number of sessions or user actions. To summarize, the key advantages of S-Walk are as follows: (i) It can eectively capture inter- and intra-session relationships via RWR. (ii) Without complicated model tuning, it is highly ecient and scalable owing to the closed-form solution of linear models. (iii) It achieves competitive or state-of-the-art performance in various metrics (i.e., HR, MRR, recall, and MAP) on four benchmark datasets (i.e., YouChoose, Diginetica, RetailRocket, and NowPlaying). (iv) The model learned by S-Walk can be highly compressed without sacricing accuracy, supporting fast inference time. Notations.Given a set of sessionsS = {𝑠, . . . , 𝑠}over a set of itemsI = {𝑖, . . . , 𝑖}, an arbitrary session𝑠 ∈ Sis represented by a sequence of items𝑠 = (𝑠, 𝑠, . . . , 𝑠)with a length|𝑠|. Here,𝑠∈ I is the𝑗-th consumed item, e.g., clicked, watched, or purchased. For simplicity,𝑠 ∈ Sis represented by a binary vectorx ∈ {0,1}, wherex=1 if𝑖is consumed, andx=0 otherwise. By stacking 𝑚sessions, letX ∈ Rdenote a session-item interaction matrix, where𝑚is the number of sessions. As a straightforward variant, the binary value inxcan be converted to real values to quantify the importance of items within a session. Problem statement.Given a sequence of items previously consumed by an anonymous user in a session, session-based recommendations predict the next items that the user is most likely to consume. Formally, a session-based recommender model takes a session𝑠 = (𝑠, . . . , 𝑠)as input and returns a ranked list of top-𝑁 candidate items as the recommended next items(𝑠, . . . 𝑠). Note that this is more generalized (and challenging) than predicting the next single item𝑠, which has been used in existing work. (See Section 4 for the generalized evaluation metrics for this setting.) Random walk models.The key concept behind random walk models is to reect the direct and transitive relations among items. Conventional recommender models using random walks [6–8,20, 37,38,55] are based on a user-item bipartite graphG= (U ∪ I, E), whereUandIare a set of users and items. Each edge𝑒 ∈ E represents the relationship between a user and an item. Thus, the core part of the random walk model is to determine a transition probability matrix to compute proximity scores for items. In general, there are two possible solutions for computing the proximity scores of items. First, we can utilize the𝑘-step landing probability distribution of a random walker. Starting from a source user𝑢, the proximity scores for all items can be computed asuR, whereuis the user vector, andRis the𝑘-step transition probability matrix. Although it is simple yet eective, existing studies [6,7] are vulnerable to popularity bias; popular items tend to have high proximity scores as𝑘increases (e.g.,𝑘 ≥3), thereby degrading the recommendation quality. As an alternative, we can compute the stationary distribution of random walks with restart (RWR), which is well-known as personalized PageRank [26]. It is eective for capturing high-order relationships among vertices. Because RWR leverages restart in addition to sequential transition, it can alleviate the problem of popularity bias, concentrating on the central node in the𝑘-step. For this reason, we adopt RWR for session-based recommendations. (See Section 5 for empirical comparisons between the two methods, 𝑘-step and RWR.) Adopting the random walk in session-based recommendations has the following advantages: (i) The random walk model utilizes high-order item correlations across sessions. Because sessions are usually sparse by nature, it is useful for alleviating the data sparsity problem by capturing profound relationships among items. (ii) Compared to GNN-based SR models [13,40,41,53,54], it is ecient without requiring complicated hyper-parameter tuning. Linear item-item models.Given the session-item matrixX, the goal of linear models [39,46] is to estimate the item-item similarity matrixB ∈ R. As a pioneering work, SLIM [39] formulated a linear model subject to the constraint that all entries inBare non-negative and zero diagonal. where∥ · ∥and∥ · ∥are the entry-wiseℓ-norm and the matrix Frobenius norm, respectively,𝜆and𝜆are the regularization coecients, anddiag(B) ∈ Rdenotes the vector with the diagonal elements ofB. Although SLIM [39] shows competitive accuracy, it suers from high computational training cost. Recently, EASE[46] and its variants [45,47] only consider the zero-diagonal constraint by removing the non-negativity ofBand ℓ-norm constraints from Eq. (1): argmin∥X − X · B∥+ 𝜆 · ∥B∥ Owing to this simpler formulation, EASEis solved by the closedform equation via Lagrange multipliers: whereˆP = (XX + 𝜆I). Here,1 ∈ Ris the vector of ones, and⊘denotes the element-wise division. LetdiagMat(x)denote the diagonal matrix expanded from the vectorx. (See [46] for the detailed derivation of the closed-form solution.) Although inverting the regularized Gram matrixXXis the computational bottleneck for large-scale datasets (i.e., the time complexity isO(|I|)with the Coppersmith-Winograd algorithm), the closed-form solution is advantageous in terms of efciency. The training complexity of EASE[46] is proportional to the number of items, which is usually much smaller than the number of sessions (𝑛 ≪ 𝑚). Besides, the linear model is benecial to accelerate the inference because computing top-N recommended items is simply done by single matrix multiplication. Most recently, SLIST [5] reported competitive accuracy with linear models for the session-based recommendation. Although SLIST [5] tackled various characteristics of session data, it did not consider inter-session relationships. In contrast, we devise linear models with random walks, taking both intra- and inter-session correlations into account. In this section, we propose a novel session-based recommendation with a random walk, namely S-Walk. While existing random-walkbased recommender models [6–8,20,37,38,55] are based on a useritem bipartite graph, it is non-trivial to adopt them for session-based recommendations. Since user information is unavailable, we rely only on item information to learn underlying patterns. Furthermore, the session-item matrix is extremely sparse. To address these issues, we rst present the overall architecture of S-Walk using global item graphs (Section 3.1). Intuitively, walking on a global item graph can describe inter-session relationships among items because the walker can move from an item of the current session to the items of other sessions. Then, we develop two linear models to build a transition matrix and a teleportation matrix, used in S-Walk (Sections 3.2–3.3). Note that these linear models can be replaced by others as long as they are ecient and scalable. Notably, our linear models satisfy the desirable condition for eciency and scalability. Finally, we explain model training and inference of S-Walk (Section 3.4). Figure 2 overviews the S-Walk model. Given a session-item interaction matrixX, we rst design two models for item transition and teleportation to capture dierent characteristics of sessions (the blue and orange box in Figure 2, respectively). We then constitute a nal global item graph using random walk with restart (RWR). Specically, each model produces its own relevance matrix over the transition graphG= (I, E)and the teleportation graph G= (I, E), where each node corresponds to an item and an edge indicates the relevance between a pair of items. The transition matrixRis the adjacency matrix ofGwhich encodes sequential dependency and repeated item consumption in a session. On the other hand, the teleportation matrixTis the adjacency matrix of G, which captures item consistency in the session. Introducing the two matrices captures dierent intra-session relationships among items, but they do not address the inter-session relationship. By adopting the RWR using the two graphs, where a random walker jumps from one node to another or restarts on an arbitrary node regardless of her current position, we intend to consider the inter-session relationship, capturing high-order relationships among items, i.e., multi-hop connections on the item graphs. Conceptually, the RWR on the two item graphs,GandG, can be thought of as tossing a biased coin that yields the head with probability 𝛼: (1)If the coin is head (with a probability of𝛼), the walker moves to one of the items adjacent to the current item through the transition matrix R ∈ R. (2)If the coin is tail (with a probability of 1− 𝛼), the walker restarts on one of the items adjacent to the start item through the teleportation matrix T ∈ R. Figure 2: The overall architecture of S-Walk. Given a session-item matrix, two dierent linear mo dels build the transition graph and the teleportation graph by adjacency matrices R and T, using Eq. (7) and Eq. (10), respectively. Then, in Eq. (12), the random walk with restart is used to build the nal graph with adjacency matrix M, capturing high-order relationships. The random walk using these two matrices is a stochastic process, which can also be seen as a Markov chain on items over a homogeneous discrete time. Formally, we formulate the RWR as follows: x= 𝛼xR + (1 − 𝛼)xT, where 𝑘 = 0, . . . , ∞. (4) Here,𝛼is the damping factor that controls the proportion of the random walk and the restart.x∈ Ris the initial item vector andx∈ Ris the updated proximity score for items after the 𝑘-th step. As the𝑘increases,xconverges to limited distribution. Through the RWR, we obtain stationary probabilities that the random walker lands on each node, expressed as the green graph in Figure 2. Finally, we generate the recommendation list using the nal graph G= (I, E). In this process, we devise linear models for the two models, taking the following advantages: (i) they achieve comparable performance without complicated tuning, and (ii) training and inference are much faster than DNN-based session recommender models [13, 16–18, 31, 32, 40, 41, 53, 54]. Fist, we develop a linear transition model to build the item transition matrixR. As a natural way of representing the transition of item sequences, we introduce partial session representations. A session 𝑠is divided into two sub-sessions, past and future, according to each time step𝑡 =1, ..., |𝑠 |. The past partial session consists of items consumed before the𝑡-th item, i.e.,s= {𝑠, . . . , 𝑠}. The future partial session consists of items consumed at or after the𝑡-th item, i.e.,s= {𝑠, . . . , 𝑠}. For each time𝑡 =2, ..., |𝑠 |, we produce|𝑠| −1 past and future partial session pairs. By stacking |𝑠| −1 pairs for all𝑠 ∈ S, we build two matrices, the past session matrixY ∈ Rand future session matrixZ ∈ R, whereÍ 𝑚is the number of all partial sessions, i.e.,𝑚=(|𝑠| − 1). Finally, the item transition matrixRis learned with two matricesY and Z according to the partial session representation. To represent the temporal proximity of items, we adjust the weights of items inYandZ. As adopted in [5,11], we consider the position gap between two items as the weight of items within a session. where𝛿is the hyper-parameter that controls the position decay in partial sessions, and𝑝 (𝑖, 𝑠)is the position of item𝑖in the session 𝑠. In this way, we decay the relevance between items𝑖and𝑗as they get farther away. Formally, the item transition model is formulated as whereBis the item-item relevance matrix learned from the sequential dependency betweenYandZ. AsY ≠ Z, we can naturally avoid the trivial solutionB= I. Unlike Eq.(2), we can remove the zero-diagonal constraint inB. The closed-form solution is given by whereˆP= (YY + 𝜆I)∈ R. The computational complexity is independent of the number of users, as shown in Eq.(3). (See Appendix A for a detailed derivation of our solution in the supplementary material.) To utilize the item transition matrix in random walks, each element should be the transition probability from one node to another. That is, every element is non-negative and sums to 1. However,ˆB is not normally a probability matrix. To satisfy the non-negative constraint, we rst replace all negative values inˆBwith zero, denotingˆB. We then normalizeˆBas follows: Here,Ris the item transition probability matrix, where each row is normalized, and 1 is a column vector of length 𝑛 lled with one. The item teleportation matrix is designed to capture the item consistency within a session. For this reason, we focus on modeling co-occurrence between items. A session is treated as a set of items s = {𝑠, 𝑠, . . . , 𝑠}, ignoring the order of items. By stacking𝑚 sessions, we build a binary session-item matrixX. Note that the repeated items in the session are treated as a single item. Given the matrixX, we devise a linear teleportation model. It is formulated with the same input and output matrix as used in the existing linear models [39,46]. Meanwhile, we relax the zerodiagonal constraint forBto handle repeated item consumption, as discussed in [5]. When the diagonal element ofBis loosely penalized, it allows us to predict the same items as the next item repeatedly. argmin(X − X · B)+ 𝜆∥B∥, s.t. diag(B) ≤ 𝜉, (9) whereBis the item-item relevance matrix for item consistency, and𝜉is the hyper-parameter to control diagonal constraints. When 𝜉 =0, it is equivalent to the zero-diagonal constraint forB. When𝜉 = ∞, there is no constraint on the diagonal elements of B. Note that the objective function of EASE[46] is a special case of Eq. (9), where Bwith 𝜉 = 0. We can obtain the closed-form solution of Bas follows: ˆB= I −ˆP · diagMat(𝛾), 𝛾=≤ 𝜉,(10) whereˆP = (XX + 𝜆I), and𝛾 ∈ Ris the vector used to check the diagonal constraint ofB. Because of the inequality condition for the diagonal elements inB,𝛾is determined by(1− 𝜆𝑃). The closed-form solution may depend on𝜉. If𝜉 =0,𝛾is equal to 1/𝑃, corresponding to(1⊘ diag(ˆP)). If𝜉 = ∞, the solution becomesˆB= I − 𝜆ˆP. Similar toˆB, the solutionˆBdoes not satisfy the nonnegativity and normalization conditions to be a probability matrix. We compute the item teleportation probability matrixTby replacing the negative values with zero and normalizingˆB: where𝛽is a hyper-parameter that controls the importance of the self-loop to guarantee the convergence of random walks. (See Appendix C for detailed analysis in the supplementary material.) Training.To compute the stationary distribution of S-Walk, we utilize the power method [26]. Each proximity score corresponds to the limiting distribution using Eq. (4): Here,M =Í𝛼(1 − 𝛼)TRis the trained item-item matrix by SWalk. (Appendix B provides the detailed pseudo-code for computing the proximity score using the power method.) Inference.Given a new session𝑠, we represent a session vector xand compute the proximity score usingM. The proximity score for predicting the next item is nally given byxM. In this process, we decay the importance of items inxto rely more on recent consumption, similar to Eq. (5): where𝛿is the hyper-parameter used to control the item weight decay, and |𝑠| is the length of the session 𝑠. Benchmark datasets. We use four public datasets collected from e-commerce and music streaming services: YooChoose(YC), Diginetica(DIGI), RetailRocket(RR), and NowPlaying(NOWP). Following existing studies [16,31,32,53], we use single training-test split (single-split) datasets (i.e., YC-1/4, DIGI1). To minimize the risk of random eects, we also split the datasets (i.e., YC5, DIGI5, RR, NOWP) into ve folds (ve-split) which are contiguous in time, as used in recent extensive evaluation [33–35]. Following the convention [33–35], we discard the sessions with only one interaction and items that occur less than ve times. Also, we split the training and test datasets chronologically and use a portion of the training set for validation, such that the validation set size is equal to that of the test dataset. (See Appendix D for detailed statistics of all benchmark datasets.) Competing models. We compare our model to nine competing models. Among the non-neural models, we compare to AR [2], SR [25], STAN [11], and SLIST [5]. AR [2] is a simple model using association rules, and SR [25] is a Markov chain model together with association rules. STAN [11] is an improved model of SKNN [21], a session-based kNN algorithm. SLIST [5] is a linear model designed for SR. Among the neural models, we compare to NARM [31], STAMP [32], SR-GNN [53], NISER+ [13], and GCE-GNN [52]. Notably, SR-GNN [53] employs GNNs to consider complex sequential dependency of items. To overcome overtting and popularity bias, NISER+ [13] uses normalized items and session embeddings on top of SR-GNN. Lastly, GCE-GNN [52] considers inter-session relationships by modeling item transitions over all sessions. (See Appendix E for the implementation details of baselines.) All source codes are available at https://github.com/jin530/SWalk. Evaluation protocol and metrics. As in the common protocol [18, 31,53], we use the iterative revealing scheme, which iteratively exposes an item from a session to the model, to reect sequential user behavior throughout the entire session. We adopt several metrics to handle two scenarios: (i) To evaluate the next single item, we use Hit Rate (HR) and Mean Reciprocal Rank (MRR), which have been widely used in existing studies [17,32,53]. HR and MRR measure the next item’s existence and rank in the recommendation list, respectively. (ii) To evaluate all subsequent items predicted, we use two common IR measures, Recall (R@k) and Mean Average Precision (MAP@k), which measure the subsequent items’ existence and rank in the recommendation list, respectively. We use𝑘 = {5,10,20,50,100}, where 𝑘 = 20 is the default. We evaluate the accuracy and eciency of S-Walk by comparing it with competing models. Based on thorough and extensive evaluations, we make the following conclusions. •S-Walk exhibitsstate-of-the-art performanceon multiple datasets. For R@20, MAP@20, and HR@20, S-Walk consistently outperforms the other models, up to 3.16%, 4.11%, and 3.65%, respectively (Section 5.1). •The inference of S-Walk is up to8.9 times fasterthan other DNN-based models. Surprisingly, S-Walk can becompressed (sparsied by zeroing-out entries via thresholding),without sacricing its accuracy (Section 5.2). •Forlong sessions, where user intent is more dicult to capture, S-Walk signicantly outperforms existing models. (Section 5.3). •S-Walkconverges within 3–5 stepsand is superior to the k-step method because it utilizes the teleportation model for restarts (Section 5.4). Table 1 reports the accuracy of S-Walk and other competitors. It is found that no single model shows the best performance over all the datasets, as reported in existing studies [33–35]. Remarkably, the existing models have dierent tendencies for single-split and ve-split datasets; while most neural models surpass non-neural models on the single-split datasets, their performances are degraded on the ve-split datasets. We conjecture that the parameters of the neural models reported in existing studies are mostly biased for optimizing the single-split datasets. For ve-split datasets, it is also observed that the variance in the neural models is larger than that of non-neural models. Based on these observations, it is challenging for one model to consistently achieve outstanding performance on all the datasets. Nevertheless, S-Walk shows competitive or state-of-the-art performances. Notably, the gain of S-Walk is up to 4.08% and 8.15% in R@20 and MAP@20 over the best competing model. For all vesplit datasets, S-Walk consistently surpasses the existing models for HR@20, R@20, and MAP@20. These empirical results indicate that S-Walk captures various intra- and inter-correlation among items without being biased to specic datasets. Compared to the other metrics, S-walk is slightly lower on MRR@20, particularly on YC and NOWP datasets. Based on the gap between SR [25] and STAN [11], we observe that the MRR@20 scores on these datasets are mostly aected by intra-session relationships. Thus, we address this by taking fewer random walks on these datasets; e.g., S-Walkconsiders mostly intra-session relationships, conrming superior performance in MRR@20 as well. Table 2 compares the inference time between S-Walk and the other best models on several datasets. Whereas the computational cost of Figure 3: R@20 and MAP@20 of S-Walk over various compression ratios. S-Walk is proportional only to the number of items, that of neural models also depends on the number of layers and their dimensions. Although S-Walk runs on CPU and other models run on GPU, S-Walk shows about ve times faster inference time owing to its simpler structure, even with better accuracy. This property is highly desirable for deploying S-Walk for real-world applications. We also attempt model pruning for S-Walk. As a simple strategy, we adopt magnitude pruning [10], i.e., the model is globally sparsied by zeroing out parameter values with the smallest magnitude. For instance, 100×compression means that we retain only 1% non-zero entries inMwith the highest magnitude while zeroing out the remaining 99%. Surprisingly, S-Walk preserves the accuracy with highly extreme (100×) compression ratios, as depicted in Figure 3. Random pruning is a simple baseline, i.e., the parameters are randomly removed under the given compression ratio. This result indicates that the learned relationship between items is disentangled with the locality, as observed in existing studies [4,27–30]. Owing to this valuable property, the compressed S-Walk is memory-ecient, suitable for low-resource devices, e.g., mobile and embedded applications. To further investigate the accuracy gains of S-Walk we carefully design case studies and examine the eects of session length and retrieval size. (See Appendix F for the eect of the data size on S-Walk and competing models.) To observe how the session length aects the performance, we compare it with other best models (i.e., STAN [11], SR-GNN [53] and NISER+ [13]) by categorizing the entire sessions into two groups: short (≤5 items) and long sessions (>5 items). Note that the ratio of short sessions is 77.2% (DIGI5) and 79.2% (RR), respectively. Figure 4 indicates that long sessions are much more challenging to predict users’ hidden intents eectively. Nonetheless, S-Walk signicantly outperforms NISER+ [13] in long sessions by 6.2%–20.2% and 5.8%– 21.0% on R@20 and MAP@20, respectively. Based on this result, we Table 1: Accuracy comparison of S-Walk and competing models, following experimental setup in [34, 35]. Gains indicate how much better the best proposed model is than the best baseline model. S-Walk rst step M. The best model is marked in bold and the second best model is underlined. DIGI5 DIGI1 YC-1/4 Table 2: The number of oating point operations and runtime (in seconds) for inference of S-Walk and DNN-based models. Gain indicate how fast S-Walk is compared to GCEGNN [52]. Runtime for DNN models was measured on GPU, while that for S-Walk on CPU. ModelsGFLOPs Time GFLOPs Time GFLOPs Time conrm that S-Walk eectively captures complicated item patterns, further improving the accuracy of longer sessions. Figure 5 depicts the comparison results between S-Walk and the competitive models for various numbers of recommended items. For all cut-o sizes, we observe that S-Walk consistently surpasses NISER+ by 5.2%–16.9% and 5.4%–17.2% gains on Recall and MAP, respectively. In this sense, S-Walk can expand item coverage by increasing the number of steps through the random walk process in the item graph. We analyze the eect of each component, i.e., the transition model and the teleportation model, in S-Walk. As shown in Table 3, the Figure 4: R@20 and MAP@20 of S-Walk and competitor models over dierent session lengths (Short ≤ 5, Long > 5). complete S-Walk shows the best performance, compared to using SR [25] for the transition model. For the teleportation model, AR [2] shows worse accuracy than the identity matrix in the YC-1/4 dataset, where AR [2] shows the worst performance. This implies that incorrect teleportation may hinder random walks. Figure 6 depicts the eect of the damping factor𝛼in S-Walk, controlling the ratio of walks and restarts. With𝛼 =0.7, S-Walk Figure 5: R@N and MAP@N of S-Walk and state-of-the-art models over the various cut-os on DIGI5 and RR. Table 3: R@20 and MAP@20 of S-Walk with various transition and teleportation models. SR [25] and AR [2] are simple Markov- and co-occurence-based models. I denotes the identity matrix. 𝑡𝑟𝑎𝑛 and 𝑡𝑒𝑙𝑒 denote the transition and teleportation model, respectively. 𝑡𝑟𝑎𝑛 𝑡𝑒𝑙𝑒 Ours 0.5171 0.0400 0.3930 0.0270 0.4950 0.0301 Ours 0.5205 0.0403 0.3936 0.0271 0.4979 0.0303 Figure 6: R@20 and MAP@20 of S-Walk over varied damping factor 𝛼. shows the best performance, implying that the transition model is more dominant than the teleportation model. Finally, with various numbers of random walk steps, we compare S-walk with the𝑘step method, which uses the𝑘-step landing probability on the transition graph. (i) Without restart using the teleportation graph, performance signicantly degrades, and (ii) when𝑘 ≥2 in𝑘-step, the accuracy continues to decrease. (iii) S-Walk usually converges within 3–5 steps, achieving the best performance on both datasets. Figure 7: R@20 of S-Walk using random walk with restart (RWR) and a k-step landing probability. Random walk-based models. With the success of PageRank [26], the idea of the random walk has been widely adopted to address the data sparsity problem in recommender systems [55]. TrustWalker [20] addressed cold-start user/item problems using trust information between users. Starting from a target user vertex, [6,7] estimated the proximity score using the transition probabilities after short random walks on the user-item bipartite network. Besides, random-walk-based models have been successfully deployed in the large-scale industrial systems [8]. Recently, RecWalk [37,38] leveraged spectral properties of nearly decoupled Markov chains and combined the item model with random walks. Session-based recommendation (SR). SR models are categorized into three groups, i.e., Markov chain models, neighborhood-based models, and DNN-based models. For more details, please refer to recent survey papers [3,22]. Firstly, Markov chains (MC) are useful for modeling consecutive item dependency. FPMC [43] proposed the tensor factorization using MF, and FOSSIL [14] combined FISM [24] with factorized MC. SR [25] proposed an improved MC model by combining association rules. Although they are eective for addressing the short-term item dependency, it does not utilize various patterns among items. Secondly, Jannach and Ludewig[21] adopted the K-nearest neighbor (KNN) for SR, and STAN [11] improved SKNN using various weight schemes to further reect item dependency. Recently, [33–35] reported that the KNN-based models have shown competitive performance on various datasets. However, they are generally limited in representing high-order dependency among items. Lastly, various DNN-based models have been used for SR. GRU4Rec [16,17] employed gated recurrent units (GRU) for SR. Later, NARM [31] and STAMP [32] utilized attention mechanisms to distinguish short- and long-term item dependency. To further analyze complex item transitions, SR-GNN [53] recently exploited gated graph neural networks (GGNN). However, SR-GNN [53] is often vulnerable to overtting [13] owing to extreme data sparsity. In this work, we propose a session-based recommendation using item random walks, S-Walk. To complement the drawback of existing models, we utilize the random walk with restart to fully capture intra- and inter-correlations of sessions. We incorporate ecient linear item models, i.e., the transition model and the teleportation model, into the item random walks process. Our extensive evaluation shows that S-Walk achieves comparable or state-of-the-art accuracies, high scalability, and fast inference speed over various benchmark datasets. This work was supported by the National Research Foundation of Korea (NRF) (NRF-2018R1A5A1060031, NRF-2021R1F1A1063843, and NRF-2021H1D3A2A03038607). Also, this work was supported by Institute of Information & communications Technology Planning & evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2019-0-00421, AI Graduate School Support Program).