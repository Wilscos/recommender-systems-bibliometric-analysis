Recently there has been a surge of interest in the design of personalized recommender systems (RS) that adapt to user’s taste based on their implicit feedback, mostly in the form of clicks. The ﬁrst works on RS assume that users provide an explicit feedback (as scores) each time an item is shown to them. However providing a score is usually time consuming; and in many practical situations users may provide no feedback when they are not interested in some items that are shown to them, or, they may click on items that are likely to be of their interest. nature of user/item interactions in the learning process [5]. These approaches are mainly focused in the design of sequential neural networks as RNN or LSTM for predicting, in the form of posterior probabilities, the user’s preference given the items [14]. Models from the feedback history of a given user his next positive feedback [4]. All these strategies consider In this paper, we study the eﬀect of long memory in the learnability of a sequential recommender system including users implicit feedback. We propose an online algorithm, where model parameters are updated user per user over blocks of items constituted by a sequence of unclicked items followed by a clicked one. We illustrate through thorough empirical evaluations that ﬁltering users with respect to the degree of long memory contained in their interactions with the system allows to substantially gain in performance with respect to MAP and NDCG especially in the context of training large-scale Recommender Systems. In the last few years, most works were interested in taking into account the sequential only the sequence of positive feedback i.e. viewed items that are clicked or purchased; and rely on the underlying assumption that user/item interactions are homogeneous and persistent in time, motivating the design of RS based on stationary neural networks with nice memory properties. feedback along with positive ones in the learning of models parameters, and, (b) the impact of long-range dependent user/items interactions for prediction. Thereafter, we turn this preliminary study into a novel and successful strategy combining sequential learning per blocks of interactions and removing user with non–homogeneous and non persistent behavior from the training. Even if simple, our approach proves to be surprisingly eﬀective, with respect to state-of-art approaches, especially when dealing with large scale datasets. mathematical framework, used to model persistence in RS data. Thereafter, we present our novel strategy combining the eﬃciency of sequential learning per block of interactions and the knowledge of the memory behavior of each user in Section 2.2. We then illustrate that memory is intrinsically present in RS user/items interactions in Section 3 and prove through extensive experiments the eﬀectiveness of our approach. Our claim is that all user/items interactions are not equally relevant in the learning process. We prove in the sequel that we can improve the learning process, considering only the subset of users whose interactions with the system possess two main characteristics : homogeneity in time and persistency. The user feedback is homogeneous in time if it is statistically the same, whatever the time period is. Moreover, the behavior of a given user has to be persistent through time, that is the current choices are dependent on the whole interaction history of the individual. We propose to model these two natural characteristics of user feedbacks, using two mathematical notions introduced for sequential data analysis : stationarity and long memory. We recall that a time series X = {X to be (wide-sense) stationary (see Section 2.4 in [1]) if its two ﬁrst orders moments are homogeneous with time: Under such assumptions the autocovariance of a stationary process only depends on the diﬀerence between the terms of the series h = k − l. We set γ(h) = Cov(X The concept of long-range dependence arouses in time series analysis to model memory that can be inherently present in sequential data. We shall apply this concept to study the persistent nature of sequential interactions with the RS of each given user. In this paper, we put in evidence (a) the eﬀectiveness of taking into account negative The remainder of the paper is organized as follows. In Section 2.1, we present the The parameter d is called the memory parameter of X and provides a quantitative measure of the persistence of information related to the history of the time series in the long-run. In the perspective of the inference of the memory parameter d, we shall use the alternative deﬁnition based on the so-called spectral density. The spectral density is the discrete Fourier transform of the autocovariance function: and reﬂects the energy contains at each frequency λ if the times series. Under suitable conditions, a stationary time series X admits memory parameter d ∈ (0, 1/2) iﬀ its spectral density satisﬁes : the memory parameter, the GPH estimator introduced in [6]. It consists of a least square regression of the log-periodogram of X. One ﬁrst deﬁnes a biased estimator of the spectral density function, the periodogram I(λ) and evaluate it on the Fourier frequencies λ where N is the length of the sample : We now present our learning scheme. Here, the aim is to take into account the sequence of negative feedback along with positive ones for learning, and select users characteristics as stationarity and long memory. In the following, we ﬁrst present our Sequential learning with Negative And Positive fEedback approach (called SNAPE) and then detail the explicit inclusion of memory in the algorithm (that we refer to as MOSAIC). to the user. A user may prefer (or not) two items independently one from another, but within a given set of shown items, he or she may completely have a diﬀerent preference A weakly time series is said to be long-range dependent if for some d ∈ (0, 1/2): In order to infer this memory parameter, we use one of the most classical estimators of The estimator of the memory parameter is therefore as follow : where Y= −2 log |1−e|,¯Y = (Y)/m and m is the number of used frequencies. User preference over items depend mostly on the context where these items are shown Figure 1: The horizontal axis represents the sequence of interactions over items ordered by time. Each update of weights ω negative interactions, N over these items. By randomly sampling triplets constituted by a user and corresponding clicked and unclicked items selected over the whole set of shown items to the user, this eﬀect of local preference is not taken into account. Furthermore, triplets corresponding to diﬀerent users are non uniformly distributed, as interactions vary from one user to another user, and for parameter updates; triplets corresponding to low interactions have a small chance to be chosen. In order to tackle these points; we propose to update the parameters sequentially over the blocks of non-preferred items followed by preferred ones for each user u. The constitution of B + 1 sequences of non-preferred and preferred blocks of items for two users u and u + 1 is shown in Figure 1. dimensional vectors U of the sequential part of our algorithm is to learn a relevant representation of the couples users/items ω = (U, V ) where U = (U ranking loss corresponding to this block : where ` the logistic one with y include stationarity and long-memory in the pipeline (called MOSAIC). In the ﬁrst step we train SNAPE on the full dataset. Thereafter we remove non stationary embeddings, then test long-range dependence on the remainder and remove non-long range dependent embeddings. Finally we train SNAPE on the ﬁltered dataset. In this case, at each time a block B= Nt Πis formed for user u. In a classical way [9], each user u and each item i are represented respectively by low = 1 if the user u prefers item i over item i, y= −1 otherwise. We now describe the inclusion of the Memory-Aware step of our algorithm, allowing to following. Algorithm 1 MemOry-aware Sequential leArning for Implicit feedbaCk (MOSAIC) Input: A sequence (user and items) {(u, (i interactions with the system ; Preprocessing: Train the Sequential Learning approach (SNAPE) on the full dataset. Memory-Aware Step: Test stationarity for each user. Remove non stationary embedding. Test long-range dependence on the remaining dataset Remove non long-range dependent embeddings Postprocessing: Train SNAPE on the ﬁltered dataset. Return: The last updated weights; In this section, we provide an empirical evaluation of our approach on some popular benchmarks proposed for evaluating RS. All subsequently discussed components were implemented in Python3 using the TensorFlow library. We ﬁrst proceed with a presentation of the general experimental setup, including a description of the datasets and the baseline models. Description of the datasets. We have considered the three following publicly available datasets, for the task of personalized Top–N recommendation: collection. The pseudo-code of our Memory-Aware Sequential Learning approach is shown in the • ML–1M [7] consists of user-movie ratings, on a scale of one to ﬁve, collected from a movie recommendation service. We consider ratings greater or equal to 4 as positive feedback, and negative feedback otherwise. • Kasandr dataset [12] contains 15,844,717 interactions of more than 2 million users in Germany using Kelkoo’s online advertising platform (https://www.kelkoogroup. com/). • Pandor [11] is another publicly available dataset for online recommendation provided by Purch (http://www.purch.com/). The dataset records 2,073,379 clicks generated by 177,366 users of one of the Purch’s high-tech website over 9,077 ads they have been shown during one month. Tables 1 presents some detailed statistics about the datasets and the blocks for each Table 1: Statistics on the # of users and items; as well as the sparsity and the average number of + (preferred) and − (non-preferred) items on ML-1M, Kassandr and Pandor collections. of users after ﬁltering based on memory in embeddings, |MEM numbers of positive (clicks) and negative feedback (viewed but not clicked). Table 2: Number of interactions used for train and test on each dataset, and the percentage of positive feedback among these interactions. oldest interactions of users and the aim is to predict the 20% most recent user interactions. Table 2, presents the number of interactions in train and test as well as the percentage of clicks (positive feedback) in these two sets. taining only users with stationary and persistent behavior. Filtering with respect to these two criteria users will allow us to select an interesting subset of the training set, with better generalization properties as shown in next section. keep those whose embeddings components are both LRD. The output subset obtained is much more small for Kassandr and Pandor that the full dataset. Table 3: Statistics on the number of total, stationary, stationary and LRD sequences of embeddings. tionary components is given for ML-1M and Kasandr just below. We see clearly that all the components of the embeddings have the same distribution, meaning that all components Among these, we report the number of users, |U|, and items, |I|, the remaining number We keep the same set of users in both train and test sets. For training, we use the 80% Identifying stationary and LRD users. We now describe our ﬁltered subset con- We keep only users whose embeddings have four stationary components, and thereafter The histogram of the memory parameter of sequences of embeddings having four staare equivalent. In addition, we recover that the distribution of user with memory interactions is very diﬀerent in these two datasets, with a median memory parameter around 0.2 for ML-1M and 0.0 for Kasandr. The eﬀect of the Memory-Aware step is then expected to be very diﬀerent in these two cases. Figure 2: Distribution of memory parameter for sequence of embeddings with respect to frequency for ML-1M (left) and Kasandr (right). We consider the following classical metrics for the comparison of the models. The Mean Average Precision at rank K (MAP@K) over all users deﬁned as MAP @K = where AP ones. The Normalized Discounted Cumulative Gain at rank K that computes the ratio of the obtained ranking to the ideal case and allow to consider not only binary relevance as in Mean Average Precision, NDCG@K = Table 4: Comparison of diﬀerent models in terms of MAP@5 and MAP@10(top), and NDCG@5 and NDCG@10(down). To validate our approach described in the previous sections, we compared SNAPE and MOSAIC sampling of training triplets, for ﬁnding the model parameters ω = (U, V ) by minimizing the ranking loss over all the set of triplets simultaneously (without considering the sequence of interactions). Although a few extensions of BPR are available [3, 2], BPR remains the golden standard in this area. GRU4Rec [8] is an extended version of GRU for session-based recommendation. The approach considers the session as the sequence of clicks of the user and learns model parameters by optimizing a regularized approximation of the relative rank of the relevant item. Caser [13] is a CNN based model that embeds a sequence of clicked items into a temporal image and latent spaces and ﬁnd local characteristics of the temporal image using convolution ﬁlters. representation of users and items; as well as the regularisation parameter over the norms of the embeddings for all approaches were found by cross-validation. the logistic ranking loss. These results suggest that sequential learning with both positive and negative feedback as it is considered in SNAPE is eﬀective compared to BPR which does not model the sequence of interactions, and Caser and GRU4Rec which only consider the positive feedback. with the following approaches. BPR [10] corresponds to a stochastic gradient-descent algorithm, based on bootstrap Hyper-parameters of diﬀerent models and the dimension of the embedded space for the Table 4 presents the comparison of BPR, Caser and Sequential Learning approaches over Table 5: Comparison of SNAPE and MOSAIC in terms of MAP@5 and MAP@10(top), and NDCG@5 and NDCG@10(down). We compare now SNAPE and its enhanced version, adding the Memory-Aware step (MOSAIC). approaches over the test sets of the diﬀerent collections. We put in boldface for each dataset the best model. To be able to compare the two approaches, the test set is always the same for SNAPE and the memory-aware one (MOSAIC). and Pandor, whereas for ML-1M the performance are similar. is correlated with the removal of nearly 99% of the users for Kasandr and Pandor in the ﬁltering step. It shows that for large scale datasets the ﬁltered subset has better generalisation ability than the full dataset and that memory helps in the learning process. The consistency of the behavior of stationary and LRD users makes the sequence of their interactions much predictable than those of generic users, who may be erratic in their feedback and add noise in the dataset. We proposed a way to take into account implicit feedback in recommender systems. In addition, we introduce a strategy to ﬁlter the dataset with respect to homogeneity and persistency of the behavior in the users when interacting with the system. Surprisingly, when training from this much smaller ﬁltered dataset, the performance of the RS highly improves with respect to several classical metrics showing that we selected users with highly generalisable prediction properties. Table 5 presents MAP@5 and MAP@10 (top), and NDCG@5 and NDCG@10 (down) of the On both metrics, MOSAIC outperforms SNAPE on the two large scale datasets, Kasandr What is noticeable, is that the increasing of performance for Kasandr and Pandor,