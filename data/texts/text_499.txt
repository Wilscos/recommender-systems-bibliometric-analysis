Abstract—There has been many studies on improving the efﬁciency of shared learning in Multi-Task Learning(MTL). Previous work focused on the “micro” sharing perspective for a small number of tasks, while in Recommender Systems(RS) and other AI applications, there are often demands to model a large number of tasks with multi-dimensional task relations. For example, when using MTL to model various user behaviors in RS, if we differentiate new users and new items from old ones, there will be a cartesian product style increase of tasks with multi-dimensional relations. This work studies the “macro” perspective of shared learning network design and proposes a Multi-Faceted Hierarchical MTL model(MFH). MFH exploits the multi-dimension task relations with a nested hierarchical tree structure which maximizes the shared learning. We evaluate MFH and SOTA models in a large industry video platform of 10 billion samples and results show that MFH outperforms SOTA MTL models signiﬁcantly in both ofﬂine and online evaluations across all user groups, especially remarkable for new users with an online increase of 9.1% in app time per user and 1.85% in next-day retention rate. MFH now has been deployed in a large scale online video recommender system. MFH is especially beneﬁcial to the cold-start problems in RS where new users and new items often suffer from a “local overﬁtting” phenomenon. However, the idea is actually generic and widely applicable to other MTL scenarios. Recommender systems (RS) are widely applied in online applications. To better model user preference and increase satisfaction, there has been an increasing trend of using Multi-Task Learning (MTL) to simultaneously predict various user feedbacks. With the forthcoming era of immersive short videos such as TikTok, Reels, Triller etc., this trend has been accelerated as in full screen mode there are more implicit parallel user feedbacks of more balanced importance v.s. in the list page era there is a dominant impression-click behavior thread. The mainstream RS ranking scheme is to apply MTL to predict various speciﬁc user behaviors and predeﬁned task labels as accurate as possible, followed by a fusion model that aims to characterize the overall user satisfaction based on the speciﬁc output values of the MTL model, e.g. likelihood of thumbup, favoriting, sharing, completion ratio etc. Compared to Single Task Learning(STL), MTL is a general learning framework that learns multiple task simultaneously in one single model v.s. one model per task, it has not only been used in RS, but also widely applied in Natural Lan- , Xinjian Liand Xu Wang guage Processing(NLP), Computer Vision(CV) etc. learning problems of various domains. MTL has the beneﬁt of transfer learning and improves model generalization through induction bias. MTL also faces challenges such as negative transfer and seesaw phenomena[1] induced by the complex correlation between tasks. Essentially, deep MTL networks needs to jointly accomplish representation learning and information routing between tasks[1]. There has been many research that focus on improving the shared learning efﬁciency between 2 tasks or small task groups. From the simplest hard sharing to MMOE[2] and PLE[1], with innovative shared learning structures, these works try to improve the shared learning efﬁciency and better address the conﬂiction between tasks. The focus is on the micro scale task cooperation for small task groups. On the other hand, there are often much more tasks beneﬁcial to model together in real world applications. For example in immersive short-video applications, users generate richer and more subtle feedbacks such as time spent, likes, subscription, comments, sharing etc., and many predeﬁned labels such as 3s skip (swipe away within 3 seconds), 80% completion ratio etc. Joint learning these tasks with MTL has the beneﬁt of better representation learning and more shared learning among tasks. Furthermore, in RS and many other applications, it is frequent to have different value ranges of certain properties exhibiting very different correlation patterns with the predicted label. Normally these property values are simply treated as sample features to the model, however, this often results in overﬁtting in certain feature regions especially when we have imbalanced and insufﬁcient data samples. Despite that these feature regions may lack data samples, it is often important to improve the model’s accuracy there as they can be regions of higher business value, or regions important for the long term value of growth, content ecosystem etc., e.g. new users, new content facing the cold start situation. Another approach is to split the different user/item/context regions into independent tasks, then there will be a cartesian product style increase in the number of tasks as these are orthogonal dimensions that independently divide the samples. The increasing scale of task numbers in MTL poses new research challenges. Current MTL technologies do not scale well with the task number increase and still lack sufﬁcient exploration in this area. This explains why we observe the common industrial practice of employing 2 or even 3 MTL models in the ranking service to handle total of 10-20 tasks where each MTL model normally handles 2-6 tasks. However, this practical approach is essentially a compromise between MTL and STL. Addressing large number of tasks in MTL is challenging. These tasks could have complex relations and are highly imbalanced as a large fraction of these tasks could have little data. The MTL learning structures in previous works such as MMOE, PLE handle well with two or small number of tasks. With a large number of tasks, we will show later that simply plugging in all tasks with ﬂat sharing using these structures can hardly yield signiﬁcant gains compared to not adding these tasks. We need new MTL models that exploit the semantic correlation structures among the tasks. Thus, designing an efﬁcient MTL structure that can support efﬁcient shared learning with large number of correlated tasks has becoming a critical aspect for MTL recommender system. Meanwhile, advancing MTL’s scalability also has great value for the generality of MTL as a universal learning framework. In this work, we propose a noval Multi-Faceted Hierarchical multi-task learning model(MFH) that aims at providing a more efﬁcient multi-task learning for a large number of tasks through scalable efﬁcient cooperative learning designs. The main contribution of the paper is summarized as follows: cooperative learning in MTL are brought to attention for better understanding of the previous efforts on MTL model design and what is demanded for better scalability. Also a local overﬁtting phenomenon is described and clariﬁed. These concepts are important notions to understand the core issues of scalable MTL. the challenge of scalable efﬁcient multi-task learning with three major characteristics: Multi-Faceted, Hierarchical and Heterogeneous. The multi-faceted and hierarchical design combined together introduces multidimensional implicit induction biases and results in a much more efﬁcient and sufﬁcient representation learning, thus greatly relieves the local overﬁtting and the data scarcity issue with smaller tasks. In addition, MFH network is more heterogeneity-friendly and provides great ﬂexibility for the model to better customize the tasks and generate further improvement. MFH in both a large-scale industrial short video app and a public benchmark dataset. Ofﬂine evaluation shows that MFH outperforms the baseline of a ﬂat 9-task model by 0.46% in MSE. Online A/B test results in WeSee APP also demonstrate the signiﬁcant improvement of MFH over SOTA MTL models in real-world applications, with 2.14% increase in app-time per user, 0.19% increase in retention rate. The improvement is much more signiﬁcant on new users as 9.10% in app-time per user and 1.85% in retention rate. MFH has been successfully deployed in our recommender system now and generates signiﬁcant business values, especially for the cold-start recommendation. MFH has a greater value of serving as a component of a universal ranking that unify the ranking for heterogeneous candidates in a broader context, e.g. mixed ranking with organic video content,ads and live broadcast etc. Multi-Task Learning[3], [4] is a general learning framework that improves the model generalization through cooperative learning between tasks. It explores the commonalities and differences between different tasks to facilitate the joint learning. MTL has been successfully applied to a wide range of applications, from RS[5], [1], [6], [7] to NLP[8], [9] and CV[10], [11], [12] etc. There are many studies on improving the shared learning efﬁciency in MTL. Shared-bottom[3] is the ﬁrst simple structure for task sharing which has its limit on task conﬂict. CrossStitch Network[13] and Sluice Network[14] both learn static weights of linear combinations to fuse representations for different tasks selectively. Then several approaches apply the gate structure and attention mechanisms to model the sample dependent correlation between tasks. MOE[15] ﬁrst introduces expert modules and uses gating network to fuse the expert outputs for upper task towers. MMOE[2] extends MOE to utilize task-speciﬁc gates to provide customized fusion for each task. M3oE[16] extends the customized gates in MMOE with multi-head gates. PLE[1] further improves the shared learning efﬁciency by differentiating task-speciﬁc experts and shared experts, and adopting a progressive routing mechanism. On top of PLE, MSSM [17] trains a ﬁeld-level sparse connection to provide more ﬂexible feature combination for different tasks, and replace the gates with a matrix multiplied by a mask vector. All of the works mentioned above focus on tasks of small groups, and are often evaluated with 2 tasks as an example. There still lacks research studying the structures of the task relation graph for a large number of tasks. Recently, ESMM[18] constructs joint loss of CTCVR based on CTR and CVR’s task relation. [19] generalizes ESMM to model the task relations with a Bayesian graph and construct joint losses as in ESMM along the paths in the graph, it also introduces more tasks. These works exploit task relation structures in loss design, instead of the network structure design for shared learning. To the best of our knowledge, this work is the ﬁrst to address this for MTL in RS. Besides, another thread of research has been applying neural architecture search(NAS)[20] and other AutoML methods to learn efﬁcient MTL architectures automatically. Prior works such as [21], SNR[22],MTNAS[23] etc. are all efforts in this direction. However, this is still in early stage as the search range of network structures is often based on certain simpliﬁed assumptions and the learning cost is expensive. Overﬁtting is one of the most common problems in machine learning. Usually, it is manifested as a large performance gap between the training and testing set, with a much worse performance on the testing set. However, as mentioned in [24], overﬁtting can vary signiﬁcantly throughout the input space. [25] ﬁrst mentioned a term of partial overﬁtting and pointed out certain data distributions are prone to lead to partial overﬁtting. [26] also mentioned local overﬁtting on different image patches. Despite these mentions, local overﬁtting has not been ofﬁcially introduced to the best of our knowledge. The traditional methods to address overﬁtting normally do not apply well with local overﬁtting as it is often caused by drastic feature-label pattern change combined with highly imbalanced training samples across the feature regions. Thus how to alleviate local overﬁtting effectively is a challenging issue worthy of study. In this work, we formally introduce local overﬁtting and propose MFH to address it. First of all, we brieﬂy introduce a real-world recommender system in WeSee, a short-video playing APP of Tencent, which serves tens of millions of users every day for immersive video watching experience. For a user request, the recommender system works to generate a recommended list of videos from a ten-million-scale candidate pool, then present the recommendations on the user’s mobile screen one video at a time. Each recommended video will start autoplay and the user may take various actions such as keep watching, swipe, like, comment, share, etc. In particular, if the user swipe up the current video, the system will show the next video from the recommended list. Upon all videos of the recommended list are presented, a new request will be triggered to generate another list. The goal of the system is to recommend favorable videos that maximize the user satisfaction which is normally quantiﬁed by total app time. As in most industrial recommender systems [27], our recommender system adopts a two-stage design that contains two core processes, candidate recall and ranking. In this paper, we focus on the ranking part, which aims to rank thousands of recalled candidate videos and select the top ones for presentation. As the widely adopted RS ranking framework shown in [1], our ranking system is composed of two parts: an deep MTL model and a Evolution Strategy(ES)/ Reinforcement Learning(RS) fusion model. The MTL model jointly outputs the likelihood of various user behaviors and its goal is to predict those concrete signals as accurate as possible. Based on user and context state features, the ES/RL fusion model outputs hyper parameters for a proxy function which calculates the ﬁnal fusion score to rank the candidate videos, the proxy function takes the MTL model’s outputs as its input. The goal of the fusion model is to synthetically characterize the user satisfaction score based on the concrete signal that the MTL model predicts. In our practice, there are two MTL models each deals with a different group of tasks. We will ﬁrst use the play task group as an example. 1) Play Task Group MTL: In the play task group MTL, we focus on three important tasks that are highly related to the video watch time, i.e., Play Completion Ratio prediction, Play Finish Rate prediction, and Play Skip Rate prediction. For simplicity, we will denote the three tasks by Cmpl, Finish and Skip respectively in the rest of this paper. Speciﬁcally, Cmpl task is a regression task that predicts the completion ratio of a video view. The label is deﬁned as: The watch time of a video view may often exceed the video length due to re-watch and the auto-replay nature of immersive short-video play APPs, thus y∈ [0, ∞). To handle exception cases, we truncate yto ensure its maximum value is below a certain threshold. Finish task is a binary classiﬁcation task that predicts the probability of watching a video to the end. y=1, if watch time ≥ video length0, otherwise(2) Skip task is a binary classiﬁcation task that predicts the probability of quick skipping a video within a short time. where c is a small constant number. The three tasks model users’ watching behaviors from slightly different perspectives. The Cmpl task reﬂects a user’s commitment to a video continuously, while the Finish and Skip tasks focus on modeling users’ positive and negative viewing experience, respectively. In our system, the three tasks are jointly learned with one MTL model. In our practice a local overﬁtting phenomenon is observed. By local overﬁtting, we mean that the model is overﬁtted in part of the input space or the degree of overﬁtting in parts of the input space is much more serious than other regions. For example, there are three different groups of users in our App: new users, low-activity users and highactivity users, activity level is determined according to total video watch time of the user. Naturally there are far less data samples for new/low-activity users than for high-activity users. In our MTL ranking, all of the baseline models exhibit overﬁtting on all tasks for new/low-activity users, in contrast to high-activity users. Intuitively, this is because the training samples of new/low-activity users are much fewer than that of high-activity users and the model parameters trained with such imbalanced data is dominated by the data pattern of high-activity users. Thus the predictions on new/low-activity users are negatively affected by high-activity users, leading to unsatisfactory recommendation results and user experience. However, cold-start - addressing the recommendation for new users or new items, is a problem of great business value for retention and growth. Models are often developed separately for cold-start in industrial practice. This is far from an ideal approach as the new user model still suffers from few data samples, additional training/serving cost, and more importantly the common patterns shared between different user groups can not be transferred to beneﬁt the minority groups. Furthermore, this local overﬁtting phenomenon is not only restricted to cold start problem of new users. It is actually quite common to encounter. New items, new users, minority context, ... , in general any feature value regions that exhibit different pattern from the main regions and have much less data samples may suffer from local overﬁtting. A natural idea to address local overﬁtting is to split original task’s feature regions into independent tasks with the overﬁtting regions as separated tasks. For example, we can split the Cmpl task into three new tasks: New&Cmpl, Low&Cmpl, High&Cmpl, representing Cmpl for new users, Cmpl for lowactivity users and Cmpl for high-activity users respectively. This will give the overﬁtting regions more customized care and hopefully relief the overﬁtting. However, this also introduces new challenges as the number of tasks increases from 3 tasks to 9 tasks in a cartesian product fashion. With a large number of unbalanced tasks that have multi-aspects of correlations, is the traditional MTL structure well prepared to scale efﬁciently? This is a natural question to ask. We will demonstrate later in Table 1 of the Experiments Section that addressing many more tasks with ﬂat sharing can hardly bring any substantial gains. Next, before showing our solution with the design of the Multi-Faceted hierarchical MTL model in the next Section, we will ﬁrst explain the perspectives of micro and macro shared learning structures in MTL and introduce the baseline models from these perspectives. C. Micro and Macro perspective of cooperative learning in MTL 1) Micro level cooperative learning structure - MTL Switcher: To illustrate the micro level coordinated learning structures in MTL, we introduce a concept called switcher in deep learning models. As depicted in Fig. 1, a switcher is a neural architecture that takes one input and branching out multiple (≥ 2) latent outputs. The input of the switcher can be any types of features, embeddings or intermediate latent representations in the network, and its outputs are some latent representations that will be fed into upper-level networks such as any hidden layers in the network or particularly speciﬁc task towers in deep MTL models. As discussed in [1], MTL needs to jointly address representation learning and information routing. Abstractly, switchers can be used to deal with the micro level cooperative learning of diverting one input to multiple intermediate latent outputs. As we see in Fig. 1, MTL structures such as shared-bottom, MMOE, PLE are just switchers of different types.Previous MTL research has been focusing on switcher innovations improving the micro level cooperative learning efﬁciency, partially because we were not dealing MTLs with a large number of tasks. 2) Macro level cooperative learning structure: As discussed earlier the number of tasks can easily increases to a large number. This raises the importance of the macro level cooperative learning structure for MTL models. The macro learning structure concerns with the macro scale information sharing among tasks. One straightforward macro learning structure will be a ﬂat branching structure as shown in ﬁg. 2, an opposite alternative can be a chain structure like the asymmetric sharing described in [1], other possibilities can also be a tree etc. For the same macro level structure, any micro level switchers can be used for the local diverting, we will examinate different combinations of micro switchers for each macro structure candidate and use the performance of the best switcher choice to represent the macro structure. And in general we ﬁnd that it is normally better to use the SOTA switchers everywhere for a macro structure given sufﬁcient training data. We choose the straightforward macro structure of ﬂat sharing for the baseline models and there are a few extended variations. 1) Baseline 3-task Model: Figure 2a illustrates a baseline ﬂat 3-task model with one switcher and three towers that corresponds to the three tasks Skip, Cmpl, and Finish, respectively. Note that the baseline 3-task model may have different versions, depending on the speciﬁc switcher architecture it adopts. In our case when the switcher upgrades from simple to more complex SOTA ones, i.e., Shared-bottom → MMOE → PLE, corresponding performance improvements are observed. However, in spite of different switchers, the baseline 3-task model cannot well address the new user cold-start problem mentioned earlier which shows local overﬁtting is beyond the scope of micro level switchers. 2) Flat 5-task and 9-task Models: To alleviate the new user issue, we attempt to further divide a prediction task into three sub tasks according to the division of user groups, i.e., prediction on new users, prediction on low-activity users, and prediction on high-activity users. The idea is to improve the predictions on new/low-activity users by allowing them more independent optimization without loss of accuracy on highactivity users. To validate this idea, we implement a partlydivided baseline ﬂat 5-task model (Fig. 2b) by dividing only the Cmpl task into three sub tasks New&Cmpl, Low&Cmpl and High&Cmpl, and a fully-divided baseline ﬂat 9-task model (Fig. 2c) by dividing all tasks in the same way. Here, the notation New&Cmpl denotes the prediction task of Cmpl on New users, and other notations have similar meanings accordingly. Later, ofﬂine evaluation results of Table 1 in the Experiments Section show that the ﬂat 5-task and 9task models make limited improvement compared to baseline 3-task model in terms of prediction accuracy on new/lowactivity users, and the local overﬁtting is still signiﬁcant. Next, we illustrate the MFH model which is essentially designed with a nested multi-hierarchical tree structure for solving this problem. In this section we ﬁrst introduce the concept of facet for tasks, then for sake of readability, we employ the aforementioned 9-task problem as an example to describe our proposed models. Last, we generalize our models to a general N -faceted multi-task problem setting. We introduce a concept of facet for tasks, facets are orthogonal dimensions that every task has. There are several partitions for each facet that can divide tasks into groups. For example in the 9-task problem setup, each task simultaneously has two facets, i.e., user behavior facet = {Cmpl, Finish, Skip} and user group facet = {New, Low-activity, High-activity}, where each facet contains three partitions. The combination of any two partitions from the two facets deﬁnes a speciﬁc task. Facets provide prior structures for the correlation between tasks, there are correlations along each facet’s aspect and tasks share common facet partitions have stronger correlations. In the 9-task MTL, each task correlates more with two tasks sharing the same partition on one facet and other two tasks on another facet. For example, Task New&Cmpl shares the common user group of new users with New&Finish and New&Skip, and shares the common user behaviour of complete watching with Low&Cmpl and High&Cmpl, at the same time. In general, the number of facets could be three or even more, e.g., the popularity of the video or the video length can each be another new facet. The number of tasks increases very quickly in a Cartesian Product fashion as more facets are introduced. This type of multi-facet multi-task problem is actually very common in industrial practice. In spite of its universality, few research has studied the problem of macro level cooperative learning strategies, partially because the community has been focused on innovating micro level structures such as MMOE, CGC and PLE. With the switcher modules sharpened, it is a good time to address the challenges on how to scale the cooperative learning in the multi-facet MTL setup from the macro perspective. In this subsection, we introduce a Hierarchical MTL (HMTL) model for the 9-task problem. As depicted in Fig. 3, H-MTL utilizes a two-level tree architecture to model the task relationships in both facets and share the facet latent representations between tasks in a hierarchical fashion. At level 0, a switcher is adopted to learn the task relationship in the user behavior facet based on the input features, which connects to three MLPs(Multilayer Perceptrons) at level 1 that correspond to three partitions of the user behavior facet: Skip, Cmpl and Finish, respectively. Each MLP outputs a hidden representation to feed a MTL switcher which learns the task relationship in the user group facet conditioned on a particular partition of the user behavior facet, and connects to three task tower networks that corresponds to the combination of this user behavior and one of the three user groups (i.e., new, low-activity and high-activity). Each task tower network concentrates on the corresponding task, and predicts the ﬁnal score for that task. Formally, the output of a speciﬁc task, e.g., Task New&Skip, can be abstractly formulated as: Output= T ower(Switcher( MLP(Switcher where Switcherindicates the corresponding output of Switcherfor (hidden) Task Y , and in general the MLP can downgrade to zero layers in which case the lower level switcher will feed directly to the upper level switchers. From the macro cooperative learning perspective, H-MTL avoids to branch out directly from the input to all tasks as the baseline ﬂat 9-task model does. Instead, it adopts a hierarchical structure for a multi-level tree sharing among tasks. At each level, switchers are used to branch out semantic representations for the upper level sub-trees. In general, the tree starts from level 0 to level k ≤ N − 1 when we have N facets. Different permutations of the facets form different trees. For example, we can divide by user groups ﬁrst then further divide by user behaviours. C. Multi-Faceted Hierarchical MTL (MFH) Although the H-MTL model captures the hierarchical task relationships with multi-facets, we have to choose one particular tree corresponding to one speciﬁc permutation of the facets. However, the facets are normally important explicit dimensions along which the tasks lie strong correlation, they are orthogonal aspects of parallel importance. To further improve the efﬁciency of information sharing and cooperative learning among the tasks, we propose a more comprehensive model, named Multi-Faceted Hierarchical MTL (MFH). MFH is essentially composed of multiple H-MTL trees that are nested together. With the 9 task problem as an example, as shown in Fig. 4, at level 0, the switcher network learns the inter-facet task relationship between two facets, and branches out to the two facets’ MLPs at level 1. The upper-level structures of MFH can be simply regarded as the combination of two variants of the H-MTL model. In particular, each tower network linearly combines the hidden outputs from two different paths connected to the input, and outputs the predicted score for a speciﬁc task. For example, the output of Task New&Skip can be abstractly formulated as: Output= T ower( Switcher(MLP(Switcher( MLP(Switcher(Input))))) + Switcher(MLP(Switcher( MLP(Switcher where Switcherindicates the corresponding output of Switcherfor (hidden) Task Y , and + denotes the operation of linear combination. Compared to previous H-MTL model, MFH further improves the learning efﬁciency in the following aspects. First, it models three-fold task relationship by extending to three levels of MTL switchers, i.e., the inter-facet relationship, the ﬁrst-order intra-facet relationship, and the second-order intrafacet relationship in the context of a particular partition of another facet. Second, it enables each task to share semantic information simultaneously with multiple sets of strong correlated tasks according to the shared facet partitions. With MFH, we can expand to any number of orthogonal trees of different facet permutations and nest the intermediate and leaf nodes as they cross. This maximizes the representation learning through multi-dimensional intersecting paths that support more shared learning. In this subsection, we generalize the MFH model to a generic N -faceted multi-task problem setup. Let Fdenote the i-th facet, and Fdenote the j-th partition of facet F, facet Fcontains M> 1 partitions. For simplicity of presentation we assume all facets have equal M partitions, and it is easy to extend the following description to the general case. Then, there would be in total s ≤ Mtasks in this multi-task setting. Each task is associated with one element of the Cartesian product of the N facets, denoted by a N -tuple, (F, ..., F), where j, ..., j∈ {1, ..., M}. Given these deﬁnitions, we illustrate the generalized version of MFH model in Fig. 6. Speciﬁcally, the level 0 switcher (i.e., the root node) expands the N facets MLPs FMLP i from 1 to N. The level 1 switchers expand each facet to its M partition MLPs. In general, for any k < N − 1, level k contains C∗ M switchers and they expand to C∗ MMLPs and switchers at level k + 1. Each MLP at level k + 1 has a unique code formed by a combination of k unique facets each with a speciﬁc partition. Upper MLPs and lower MLPs are connected through the lower level switchers if the upper level MLP’s code contains the lower level MLP’s code as a subcode. In general, we can choose to expand the multi-facet network to any level of k, 1 < k < N − 1, then connecting directly to the s ≤ M towers for output tasks. We can have at most Mtasks but do not necessarily need to split all the tasks if there is not high business value or special pattern for the considered input regions. Fig. 5 shows a 3-facets MFH of 18 tasks for the Play Task Group with an additional facet of video popularity, differentiating new items and old ones. This jointly models the complete cold-start problem for both new users and new items. MFH is more heterogeneity-friendly than ﬂat MTL. In Fig. 6, MFH’s task towers and MLPs can all be designed heterogeneously. The size of the task towers can be customized to better ﬁt the special task. For example, we can use smaller size MLP layers for task towers with less training samples. And we can do this for the intermediate MLPs that corresponds to tasks of less data samples as well. MFH is more ﬂexible on heterogeneity as the common shared root is thinner and there are various granularities of sharing that can be customized to be heterogeneous. In addition to the structure, different tasks can also have customized input features only available for themselves. Paired up with a generic fusion algorithm, MFH’s heterogeneity has a greater value of serving as a component of a universal ranking that unify the ranking for heterogeneous candidates in a broader context, e.g. mixed ranking with organic contents, ads and live broadcast etc. In this section, ofﬂine and online experiments are performed on both a large-scale industrial recommender system and a public benchmark dataset to evaluate the effectiveness of the proposed models. A. Evaluation on an industrial Video Recommender System In this subsection, the proposed models are evaluated with a large-scale online video recommender system. 1) Dataset: We collect an industrial dataset through sampling user logs from Tencent’s short video APP WeSee during a few consecutive days. There are 10 billion samples in the dataset. In addition to labels PCR(Play Completion Ratio), PFR(PLAY Finish Rate), PSR(Play Skip Rate) as mentioned before, there are also explicit user feedback labels LR(Like Rate), FR(Follow Rate), CMR(Comment Rate), SR(Share Rate), RCR(Read Comment Rate), RHR(Read Homepage Rate). We divide the users into three groups: new users group, low activity users group and high activity users group. Low activity users group are users with less than 60 min video watch time. 2) Learning Tasks: There are two MTL learning models to serve the online ranking. A play tasks MTL that jointly predicts PCR, PFR and PSR, 3 tasks that are mostly related to the video playing process. Another interactive tasks MTL that jointly predicts LR, FR, CMR, SR, RCR and RHR, the explicit user feedback behaviours. 3) MTL Models: For the play tasks MTL, we evaluate the baseline 3-task MTL(Fig. 2a), ﬂat 5-task MTL(Fig. 2b), ﬂat 9-task MTL(Fig. 2c), H-MTL 9-task(Fig. 3) and MFH 9task MTL(Fig. 4). For the interactive tasks MTL, we evaluate baseline 6-task, H-MTL 12-task and MFH 12-task models. To avoid a sudden performance gap for new users or low activity users when they change group memberships, we include new user samples in all groups’ task training and low activity user samples in high activity user tasks training while in serving only do inference through the corresponding user group tasks, this way the performance is smoother as user upgrade groups. As new users and low activity users are far less than high activity users, the larger user groups’ training is not negatively affected. Since the focus in this work is the macro level task coordinate learning structures, for each MTL model, we tried different MTL switchers for the micro level shared learning such as hard sharing, MMOE, CGC[1] and PLE and uses the performance of the best switcher choice to represent the macro level MTL structure. As a result, we adopt shared-bottom for level 0 switcher, PLE for level 1 switchers, CGC for level 2 switchers in H-MTL and MFH, and adopt PLE for switchers in rest of the models. 4) Experiment Setup: In the experiment, PCR prediction is a regression task trained with MSE loss and evaluated with MSE, tasks modeling other actions are all binary classiﬁcation tasks trained with cross-entropy loss and evaluated with AUC. Samples in the ﬁrst 14 days are used for training and the rest samples for testing. We adopt a two-layer MLP network with RELU activation and hidden layer size of [128,64] for each task’s tower part in all MTL models. The experts in the switcher is implemented with a single-layer network and tune the following model-speciﬁc hyper-parameters: number of shared layers, number of experts. 5) Ofﬂine Evaluation with Play Task Models: Table I illustrates the experiment results and we mark best performance in bold. It is shown that H-MTL signiﬁcantly outperform all ﬂat task models, baseline 3-task, ﬂat 5-task and ﬂat 9task in all tasks and all user divisions. With the ﬂat task shared learning structure, introducing more tasks produces slight improvement, but much insufﬁcient compared to the improvement H-MTL and MFH generate. H-MTL and MFH introduce new shared learning structures to better address the difference and imbalance between different user divisions. MFH further signiﬁcantly outperform H-MTL in all tasks and user divisions. Of the improvement H-MTL and MFH generates, it is much more on the new users than on the active users. We can also compare the performance between MFH 9task and ﬂat 9-task in Table I, as both models have the same 9 tasks and the only difference is MFH vs. ﬂat on macro shared learning structure. MFH 9-task outperforms ﬂat 9-task on all tasks: -0.46% MSE on New&Cmpl, -0.42% MSE on Low&Cmpl, -0.22% MSE on High&Cmpl; +0.18% AUC on New&Finish, +0.2% AUC on Low&Finish, +0.22% AUC on High&Finish; +0.48% AUC on New&Skip, +0.24% AUC on Low&Skip, +0.32% AUC on High&Skip. This shows MFH manifest signiﬁcant performance improvement over baseline ﬂat sharing. Because MFH’s macro structure handles large numbers of tasks much better, combined with tasks increase it generates big improvement over the ﬂat 3-task model, better releasing the potential of large number tasks MTL. 6) Ofﬂine Evaluation with Interactive Task Models: The interactive tasks include LR(Like Rate), FR(Follow Rate), CR (Comment Rate), SR (Share Rate), RCR(Read Comment Rate) and RHR(Read Homepage Rate) 6 tasks. For interactive task MTL, we merge the new user group and the low activity user group into one group, thus a Cartesian Product of user group and interactive behaviour types produces 12 tasks. As shown in Table II, H-MTL and MFH achieve signiﬁcant improvement over the baseline model on all tasks of all user groups. 7) Ofﬂine evaluation on 3-facets MFH: We conduct ofﬂine experiment to evaluate the 3-facets MFH model as shown in Fig. 5 . As new items are normally not served to new users and low activity users for a double blind cold start in practice with concerns on user experience, we only serve new cold start items to high activity users but not to low activity and new users. Thus instead of a MFH 18-task as shown in Fig 4. of the main body, we have a MFH 12-task of 3 facets, with the high activity user group’s 3 tasks divided into 6 tasks, 3 for cold start content items and 3 for non cold start items. Same dataset as above is used to evaluate the ofﬂine performance of MFH 12-task vs. the 2 facets MFH 9 tasks. As a result, 3 facets MFH 12-task model achieves similar performance on new user and low activity users compared to 2 facets MFH 9-task model and at the same time achieves signiﬁcant improvement on high activity users group where the 3rd facet is applied. As shown in Table III, the 3 facets MF 12-task model outperforms the 2 facets MFH 9-task model on all tasks for the high activity users, for both the non cold start items and the cold start items. A great reduction of 1.01% on Cmpl task’s MSE loss are observed for cold start new items, which is a remarkably signiﬁcant improvement for content cold start as normally a 0.1% increase of AUC or MSE already generates online metrics improvement signiﬁcant enough to be observed in A/B testing. 8) Mitigation of local overﬁtting: Through multidimensional shared learning between the tasks, MFH maximizes the shared representation learning and mitigates the local overﬁtting phenomenon. Here we use the Share Rate task in the interactive task group as an example to show the mitigation of local overﬁtting with MFH. As in Fig. 7, we compared MFH 12-task MTL and the baseline ﬂat 12-task MTL on training and testing errors on new users. train impr denotes the training error relative improvement from MFH 12-task to ﬂat 12-task on Share Rate prediction, and test impr denotes the testing error relative improvement accordingly. As the training time proceeds shown in Fig. 7, the test error is reduced much more than the training error, which is about 2.5 times higher. Thus, compared to the ﬂat MTL models, MFH mitigates the local overﬁtting phenomenon by reducing the gap between training and testing errors. 9) Online Evaluation: Online experiments are also conducted. The baseline uses ﬂat 3-task model for the play tasks MTL and ﬂat 6-task model for the interactive tasks MTL, the experiment group adopts a MFH 9-task model and a MFH 12-task model accordingly. Both the experiment and the control group have the same RL fusion model adapted to the corresponding MTL ranking models. Table IV shows the signiﬁcant improvement of MFH and it is worth noting MFH shows remarkable increase of +9.1% apptime per user on new users. In this subsection, experiments are conducted on public benchmark datasets to evaluate MFH in more application scenarios. 1) Dataset: Ali-CCP(Alibaba Click and Conversion Prediction) Dataset is a public dataset extracted from Taobao’s Recommender System. The dataset includes 84 million data samples equally divided into training set and testing set, which contain 3.4 million clicks and 18 thousand conversions. CTR(Click Through Rate) and CVR (Conversion Rate) are two tasks modeling user actions of click and purchase in the dataset. 2) Experiment Setup: For users in the dataset, we deﬁne Purchasing Power = CVR / CTR to characterize the user tendencies of purchasement. Combined with the User Consumption Level Type I and II ﬁelds provided in the dataset, users are clustered into three groups, low, medium and high purchasing power user groups, containing 40%, 35% and 25% users respectively. Since there are a CTR task and a CVR task for every group, we have a total of 6 tasks. In our experiment, a ﬂat 2-task and ﬂat 6-task Model(PLE as switcher) are used as the baseline models, compared with a MFH 6-task Model. For each task in both models, we adopt a two-layer MLP network with hidden layer size of [64, 32]. 3) Experiment Results: As shown in Table V, compared to the baseline 2-task and baseline 6-task Models, MFH signiﬁcantly improves the AUC of all six tasks. And the baseline 6-task model performs slightly better than the baseline 2-task model. Biasnet[28], [29] is a natural alternative to address the user group differences with a side shallow bias tower that outputs a bias logit to be combined with the main tower. Viewing the neural network as a network learning a nonlinear mapping from the input feature space to the labels, the MTL approach provides a more general mapping than the biasnet approach as the task speciﬁc towers provide greater ﬂexibility in ﬁtting the label. Biasnet uses a stronger induction bias which may be beneﬁcial for cases where the bias difference can be modeled with a few layers of simple neural mappings and the biased feature value is continuous. Thus, the MTL approach is a more general framework, it can actually include the biasnet structure as part of the MTL network. Ofﬂine evaluation is also conducted to compare MFH’s performance with biasnet. As shown Fig. 8, we replace the user group facet with a bias tower that takes the user group feature as its input, and the bias output is added to the logits of task towers. The bias tower is composed of two-layer MLP with RELU activation and hidden layer size of [128,64]. As Table VI shows, the 2 facets MFH 9-task MTL outperforms Biasnet on the Cmpl task’s PCR(Predicted Completion Ratio) MSE loss for all user groups, and also outperforms Biasnet in all tasks for new users, slightly underperforms Biasnet on PFR(Predicted Finish Rate) and PSR(Predicted Skip Rate) on partial user groups. As the PCR task and new user group are more important, overall MFH performs better than biasnet. In this paper we propose a novel MTL model called MultiFaceted Hierarchical multi-task learning model(MFH), which uses a multi-faceted hierarchical tree structure to improve the MTL efﬁciency and scalability from the macro perspective of task sharing. Ofﬂine and online experiment results on the industrial and public datasets show signiﬁcant and consistent improvements of MFH over baseline SOTA models. Researching the possibilities of applying Meta Learning on the MFH tree structures will be the focus of future work.