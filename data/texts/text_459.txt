Ayman Moawad, Zhijian Li, Ines Pancorbo, Krishna Murthy Gurumurthy, Vincent Freyermuth, Ehsan Islam, Abstract—This paper presents a neural network recommender system algorithm for assigning vehicles to routes based on energy and cost criteria. In this work, we applied this new approach to efﬁciently identify the most cost-effective medium and heavy duty truck (MDHDT) powertrain technology, from a total cost of ownership (TCO) perspective, for given trips. We employ a machine learning based approach to efﬁciently estimate the energy consumption of various candidate vehicles over given routes, deﬁned as sequences of links (road segments), with little information known about internal dynamics, i.e using high level macroscopic route information. A complete recommendation logic is then developed to allow for real-time optimum assignment for each route, subject to the operational constraints of the ﬂeet. We show how this framework can be used to (1) efﬁciently provide a single trip recommendation with a top-k vehicles star ranking system, and (2) engage in more general assignment problems where n vehicles need to be deployed over m ≤ n trips. This new assignment system has been deployed and integrated into the POLARISTransportation System Simulation Tool for use in research conducted by the Department of Energy’s Systems and Modeling for Accelerated Research in Transportation (SMART) Mobility Consortium [1]. Index Terms—Neural recommender systems, machine learning, MDHD, trucks, vehicle assignment, energy consumption, cost, TCO. REIGHT companies are facing increasing pressure to decarbonize their ﬂeets. The large number of technology options, the diversity in vehicle usage and economic uncertainties are major hurdles slowing down new vehicle technology adoptions. Transportation decarbonization across the freight industry is a major challenge for multiple reasons: (1) the large number of vehicle applications, powertrain and component technologies makes it difﬁcult for ﬂeets to decide which vehicles to invest in, and (2) the diverse vehicle usage, both current and future, raises questions as to which technology should be assigned to a particular route. Understanding the techno-economic impact of technologies is an active ﬁeld of research. Traditionally, energy consumption and economic impacts have been evaluated using standard drive cycles as a baseline for regulatory purposes [2], [3], [4], [5], [6]. While they are a good standardization for energy beneﬁt studies, regulatory cycles fail to represent real driving conditions, trafﬁc variability and other effects such as future infrastructure and connectivity changes, population density changes, trafﬁc behavior changes, etc. As a result, the freight industry has been operating under a high level of uncertainty both for longer term technology adoptions and investment as well as day-to-day operations of their current vehicle ﬂeet. Since the industry is heavily driven by cost, we choose to study the optimal assignment problem from a TCO standpoint, assuming that the lowest-cost powertrain option captures driving conditions and number of miles driven over the lifetime of the vehicle under that metric. To represent diverse vehicle usage as well as the impact of multiple vehicle technologies on energy consumption and cost, both current and future, we leverage an agent-based transportation tools to model truck routes across the city of Chicago and its suburbs under various scenarios, combined a high-ﬁdelity vehicle system simulation tool, to estimate individual truck energy consumption and cost. The results generated serve as a very large backbone dataset of vehicleroute energy outcomes that capture variability in vehicle classes, powertrain ﬂeet distribution, vehicle technology, automation and connectivity levels, population, driving modes, ride-sharing extent, e-commerce impact, etc. All of these affect trafﬁc and driving behavior: For example, connected and automated vehicle (CAV) technologies are likely to have signiﬁcant effects not only on how vehicles operate in the transportation system but on how individuals behave and use their vehicles. In Section III-A we provide high-level details about the data generation process and a brief overview of the data content. For more details about the design of the experiment, the tools involved, and their capabilities, refer to [7] and [8]. The rest of this article describes the development of a machine learning based vehicle-route assignment recommender system for MDHDT to efﬁciently identify cost effective technologies for different routes, cargo requirements, goods, energy cost, etc. from a total cost of ownership (TCO) perspective (Figure 1) with very limited known internal road dynamics (i.e using high level route information). With deployment goals in mind, the system needs to be lightweight, computationally efﬁcient, accurate, and scalable for later integration into subsequent tools, allowing real-time querying. The objective of the paper is to provide and end-to-end deployable tool to support ﬂeet decision making related to investments and technology usage. Fig. 1: Summary view of the recommender system with the required inputs, assumptions and constraints to output a topk ranking of recommended vehicles. For a given trip or set of trips and a ﬂexible list of candidate vehicles, the system outputs a recommendation based on a fast energy consumption prediction that accounts for cost, time and other ﬂeet constraints. Examples of such constraints are operational costs, charging/refueling time delays, delivery window requirements, and truck payload needs. Recommender systems—algorithms that predict users’ preferences among a large set of items based on their feedback—are widely used in many businesses today [9], [10], [11]. A recommender system learns the systematic relationship between users and items based on past behavior as well as the item attributes involved. These systems are used to establish personalized systems that recommend items to the users likeliest to use or buy them. Table I shows a direct similarity to our problem: We want to recommend vehicles for routes. Typically, recommender systems are built to deal with a large matrix of user–item pairs, while our system operates similarly in a very large matrix of vehicle–route possibilities. This approach also works well in a sparse setting, in which there is a large number of users and a big catalogue of items, but not all users interact with all items. In our case, the vehicle–route design matrix is large, but not all vehicles use all routes. Our goal is to predict a rating, in our case TCO, to rate each vehicle–route pairs. TABLE I: Typical product recommendation compared to a vehicle recommendation Recommender systems can be built with variety of techniques and complexities. Collaborative ﬁltering is one of the most popular and powerful traditional algorithms for a recommendation system. It uses a sparse data matrix R ∈ Rin which each row represents a route and each column stands for a vehicle. A nonzero entry rof R is the explicit feedback, i.e., rating, for the combination of route u and vehicle i. Collaborative ﬁltering leverages a method called low-rank matrix factorization, which computes the two low-rank matrices V ∈ Rand P ∈ R, k << n and k << m, that contain the latent information on route–vehicle interaction. The loss function of collaborative ﬁltering to minimize is formulated as follows: L =(r− vp)+ λ||V ||+ λ||U|| where vis the u-th row of V , pis i-th column of P, Ω is the indices of nonzero entries of R, and λ ≥ 0 is a regularizer parameter. To generate more precise personalized recommendations, we can use a deep neural network to input rich external features of both routes and vehicles, such as vehicle characteristics or road structures, into the algorithms. Deep neural networks have been widely used in recommendation systems to learn the complex interactions of features from users and items. He et al. [12] designed a neural-network version of collaborative ﬁltering. They used an embedding layer to learn the latent factors vand p, and they replaced the inner product with a more sophisticated fully connected neural network to learn the interaction of latent factors. Cheng et al. [13] proposed a neural recommendation system they called the Wide & Deep model that processes both raw and transformed features. It captures both linear and nonlinear interactions between features to learn and generalize users’ preference for items by jointly training a wide single-layer neural network and a deep multi-layer neural network. With a raw input vector x ∈ R, the model computes its predictions ˆy as follows: where σ(·) is the sigmoid function, a= f (Wa+ b) is the output of l-th layer with abeing the compressed dense embedding of x, and [x, φ(x)] is the concatenation of x and its cross-product transformation φ(x). Based on the Wide & Deep model, Guo et al. [14] proposed DeepFM, which replaces the wide model of Wide & Deep with a more efﬁcient factorization machine model. The factorization machine measures the interaction of feature i and feature j by the inner product of latent vectors Vand Vwith a given dimension k. Hence, the output of the factorization machine is the following: and DeepFM’s outputs are the following: DeepFM improves the Wide & Deep model as it directly takes raw input x without the need for transformation. Wide & Deep is essentially the ensemble of a linear model and a highorder nonlinear model, and DeepFM captures the additional order-2 interactions. To learn users’ preference for items, it is popular to integrate a model that learns linear and order2 interactions of features with a deep high-order nonlinear model. Researchers have proposed several approaches to generating the order-2 interactions and having models learn them. Adding to the work of Guo et al., [14], Lian et al. [15] introduced a convolutional neural network (CNN) approach called compressed interaction neural network (CIN) to learn these interactions, which they call extreme deep factorization machine (xDeepFM). xDeepFM encodes each feature in a vector of length D. Each raw datum is embedded as X∈ R, where m is the number of features. It then computes the k matrices of feature interactions through k layers and outputs X∈ R. Each row of Xis computed recursively as follows: Based on each level of interaction, xDeepFM outputs the following: where p= X1for 1 ≤ l ≤ k, and 1 is the vector of all ls of length H. xDeepFM integrates CIN with a linear model and a deep neural network. It can be formulated as follows: Finally, here we introduce an additional approach to computing the interactions called “cross layer” designed by Wang et al. [16]. Given a input vector x∈ R, it computes its interaction with level k recursively as shown: where W∈ Rand b∈ Rare trainable weights and bias respectively. Here, we denote the cross layer operation as ψ(·), so the k-th order interactions generated by the cross layer are x= ψ(x). In order to determine the energy consumption of a vehicle in a large metropolitan area under varying conditions and scenarios, it is necessary to model the entire transportation system, including people and goods movement. Activity demand is generated to become the basis for the generation of trips. Trips generate trafﬁc ﬂow, which in turn affects average trip speed. Trip information can then be used along with powertrain information to inform energy consumption. Argonne National Laboratory has developed a complete workﬂow to study this complex and multi-dimensional system by combining several TABLE II: Table of mathematical notations in this work simulation tools [7], [8]: Autonomie,SVTrip [17], and POLARIS [18]. The workﬂow is shown in Figure 2. POLARIS uses population and vehicle synthesis as well as activity demand generation and trafﬁc ﬂow. The freight transportation systems model is based on regional truck trip data [19] with an e-commerce MDT module [20]. The freight model is being updated to a fully agent-based freight model (named CRISTAL) with business ﬁrms and ﬁrm-speciﬁc delivery ﬂeets [21], [22]. The route information is fed into SVTrip, which predicts the 1 Hz speed proﬁle for each trip, which in turn is simulated with Autonomie to estimate the energy consumption of the transportation network for different vehicle technologies. This workﬂow operates ofﬂine as a data generator. A model is trained leveraging the data, deployed as a standalone model and integrated into the POLARIS Transportation System to make on-demand truck recommendations for new simulated ﬂeets. It is worth emphasizing that generated trips contain only basic information (expected average speed over link sequence) about the inner trafﬁc dynamics. The goal is to learn energy consumption based on that incomplete summary-level dynamics information. Typically, high-resolution speed behavior is a key variable in estimating the energy proﬁle, but in our setting the learning occurs without it: Our system learns the high-level route structure and vehicle–feature interactions and how they correlate to the energy consumed. As a result, in the process shown in Figure 2, the high-ﬁdelity time series of vehicle speed dynamics is masked. The data used to train the energy model are vehicle parameters and high-level aggregated route information only. This approach means that future scenarios of this form could be constructed using readily available information such as that in HERE or Google Maps, this is consistent with information ﬂeets have at their disposal in real world situations. POLARIS provides corresponding Fig. 2: Data generation and training process (grey box). After training, the model is deployed as a standalone model and integrated into the POLARIS Transportation System to make on-demand truck recommendations for new simulated ﬂeets (light blue box). aggregated link level activities: Generated trips are on the level of detail of expected link average speed, link length, speed limits, and so on. Although all internal dynamics that affect energy consumption are masked, we show that it is possible to learn aggregated-level energy consumption values quite accurately with a deep learning approach. When large-scale data is available, and with some tailored feature engineering, such a model is able to overcome latent information. The generated data contains over 3.5 million trips over 30,000 Chicago links. It accommodates a wide range of vehicle classes: class 3, 4, 6, and 8 trucks of different types, such as pickups&delivery trucks, walk-ins, vans, boxes, longhauls, etc. In addition, several powertrains were simulated with varying levels of electriﬁcation, component sizes, and technologies: from conventional to integrated starter generator (ISG) start-stop systems, hybrid electric vehicles (HEVs), plug-in hybrid electric vehicles (PHEVs), and pure battery electric vehicles (BEVs). Different fuel types (gasoline, diesel, etc.) and automation levels (no automation, partial automation, full automation) are also included. Let X = {(X, y)}and ∀i, X∈ Rbe the dataset of trips with Tmany links so that X= (x, · · · , x), where x= [u, v] ∈ Ris a link. We deﬁne v∈ Rand u∈ Ras the vehicle features and link features, respectively, with D+ D= D dimensional features. The labels y∈ Rhave two dimensions: the electricity consumption and fuel consumption of vehicles on each link. The entire sample space can be partitioned in many ways based on classes of a certain feature. We are mostly interested in two partitions: powertrain type and number of links. Because the number of links in a trip is an arbitrary positive integer, by the number of links in a trip, we can naturally partition our sample space TABLE III: Statistics of the training set at the trip level into countably many disjoint subspaces: Xis the collection of all possible trips that contains exactly l links. Then again, the sample space can be partitioned by the powertrain type: where the subscript stands for one of the ﬁve powertrain types, i.e., {0 : BEV, 1 : Conv, 2 : ISG, 3 : HEV, 4 : PHEV}. In this work, we will focus on how our model performs on each powertrain, as our goal is to make powertrain selection recommendations for given trips. As shown in Figure 3, the distribution of trips against the number of links is heavily skewed to the right. Most trips have fewer than 50 links. Table III shows key distribution statistics over the energy consumption of diverse powertrains. Fuel consumption mass values are converted to gasoline equivalent values in grams for a uniform comparison of the different fuel types, while electric consumption is in Wh. Note that the mean is signiﬁcantly higher than the median, which indicates a large variance in consumption values. Therefore, we will analyze the errors against the number of links in trips to see whether the model is biased toward short trips. Fig. 3: Distribution of trips against the number of links in training data. In our dataset, we have D= 20 the dimensionality of the vehicle features and D= 60 the dimensionality of the link features, so that D = 80. Dincludes vehicle data such as vehicle class, weight, battery size, frontal area, engine power, etc. Among the D= 60 only 7 are direct use of raw route features from macroscopic level data, the rest are carefully engineered/derived from them. Examples of raw data are: link ID, the link entering time of the vehicle, the link length, the expected duration of stop on link, the expected duration of travel on link, the expected average speed on link and the speed limit on link. Those are direct output of POLARIS. Examples of manually engineered features are: delta link average speed of surrounding links, calculated proxies of congestion by comparing speeds to speed limits, length of previous and subsequent links, difference in speed between links over travel time as proxy to global acceleration, etc. Such calculated macroscopic level dynamics are aftereffect of more granular microscopic changes. Designed features that capture link sequence dependencies will explicitly guide and inform the model training to learn microscopic latent behavior. We note that the vehicle features used in the model are limited to major vehicle attributes that are in general considered available and known, or can be collected as shown in [23]. Trips have different lengths, and zero padding is a common way to equalize trip data points to the same shape. However, in our case, the trip length varies from 1 to 283, and padding jeopardizes the accuracy of the model. To better train our models, we experimented with different ways of batching the link sequence data, which varied by trip length. First, we grouped the data by similar trip length (with shufﬂing at the end of each epoch to introduce noise) to minimize padding within a batch. After grouping by similar trip length, we further experimented with quantile bucketing and binning of different sizes. That is, if T = maxT, we discretize the range of trip length into levels 0 = L< L< · · · < L= T . Based on this discretization, we partitioned the dataset into disjoint groupsF X =G, where X∈ Gif T∈ (L, L]. Then, for each group G, we mapped all data points in Ginto R by padding with zeros. Next, at the expense of less noise during training, we also grouped the sequence data by exactly the same trip length to avoid padding completely. This approach yielded the best result. As explained earlier, if we treat each vehicle as an item and each link as a user, we turn our recommendation problem into a classic item–user recommendation. We recommend vehicles based on a trip, which is a sequence of links. In this setting, we want to recommend a vehicle to maximize the expected feedback given a ordered sequence of links. Our task is more challenging than evaluating each item–user pair. We need to model beyond the similarity of users and items, as the energy of each link will have an impact on the following link. The key to building a recommender system for our task is being able to accurately estimate the energy consumption of a large vehicle given varying roads, trips, and driving styles. Although we have features that seem to directly affect energy consumption, such as the trip length, average speed, vehicle weight, etc., there are signiﬁcant difﬁculties in modeling the energy consumption explicitly because it is hard to capture the interactions between links. For example, since the fuel consumption for acceleration and slowing down are very different, even with the same average speed a vehicle’s energy consumption on a link varies depending on how it enters and leaves the link. A neural network can learn such latent information from a sufﬁciently large and rich dataset. Inspired by the neural recommender systems mentioned above, we designed a novel way to learn a vehicle’s expected energy consumption on a given trip: We use the idea of an ensemble model and integrate models with their distinct functions to accurately predict energy consumption. As mentioned in the previous section, the energy consumption of a vehicle on a link depends on the preceding and following links. For that portion of the model, we leverage a recurrent neural network with long short term memory (LSTM) cells [24] of hidden size 128, stacked with a fully connected neural network to learn the sequential dependencies of link consumption. Given a input trip X with length˜T , the output is formulated as follows: where H ∈ R, w∈ R, and the output ˜y∈ R. g(·) is the rectiﬁed linear activation function. While the LSTM captures the interaction between links, we built two models that learn how the characteristics of the vehicle and route itself affect the energy consumption. First, we have a linear model that learns from direct features and the order-2 interaction of features. There are known feature relationships that directly and unambiguously correlate with energy (e.g., link length), which we want to explicitly capture to inform the model during training. To compute order-2 interactions, we use the cross layer from [16] mentioned in Section II-B. Its advantage is its high efﬁciency in computation and memory. If we directly generate a ﬂat vector of order-2 interactions of all features for a link, this brute-force approach will give a vector of length+D (cross terms plus squared terms), which makes computation very expensive. The cross layer operator outputs a vector of length D that contains all the cross terms and squared terms with trainable weights. It allows our model to capture the order-2 interactions with low cost. For each trip, the cross layer operator is applied link- wise, i.e., ψ(X) =ψ(x), · · · , ψ(x). Our linear model is formulated as follows: where w, w, b∈ R. Finally, we integrate a personalization component to learn the preference for each vehicle on each link. We have a deep model that resembles neural collaborative ﬁltering. Based on [12], we used two embedding layers to map vehicle ID and link ID into two latent vectors, vand p, of dimension 32. Then, we concatenate the latent vectors and pass the result to a multi-layer network to train. For this deep model, we have the following: with link-wise concatenated embedding a= [v, p] ∈ R for 1 ≤ t ≤˜T . For each layer, we have the following: a= f(Wa+b) = (f(Wa+b), · · · , f (Wa+b)) where W∈ Rwith H= 32 and H= 1. As we have one dense layer (W∈ R) in the end, we may deﬁne w= W∈ Rand formulate the output aas follows: We integrate three models to predict the link-level consump- The key to this modeling is that, because vehicles don’t enter or exit links the same way, similar (or even identical) links don’t necessarily yield similar energy proﬁles. In a given trip, a route is composed of a sequence of links, and the energy consumed depends on previous and subsequent links structures and characteristics. Modeling the entire sequence informs linklevel latent internal dynamics, provided a large dataset of trips (i.e. sequences) is available. In other words, such model is able to retrieve microscopic latent behavior. Our ﬁnal goal is to recommend the vehicle with the lowest potential energy consumption given a new trip X. Our recommendation will be based on the estimated consumption of theP entire trip, ˆy=ˆy. This new trip can be a random combination of existing (adjacent) links and unknown to our model. Therefore, we require our model to be accurate in both link-level and trip-level consumption, so the model can learn both interactions of vehicles and routes and the impact of the sequential effect of links. To further improve the generalization ability of our model, we impose an additional cumulative link loss that requires the model to be precise on partial trips up to each link. The loss is formulated as follows: We search for the optimal solution: through back-propagation gradient descent. C=P performance on the partial trip up to the l-th link. We sum Cover all l to ﬁnd the cumulative link loss,P C=C, which evaluates the model’s predictions on partial trips up to each link. The trip level lossP evaluates the model’s prediction of the ﬁnal consumption for the entire trip, and C=Py− f(Θ, x) measures the model’s performance on each link. As we mentioned in the previous section, we group trips based on their length without padding. Trips in the same batch share a common T, so objective function (5) is precise in training. For training and tuning purposes, we leveraged multiple graphics processing units (GPUs) spread across multiple machines via MultiWorkerMirroredStrategy, which implements synchronous distributed training across multiple workers, each with potentially multiple GPUs. With the help of roughly 30 machines, each with at least one GPU, we were able to decrease the model training and tuning time for a dataset of this scale. Our hyperparameter search space contained different hyperparameters spanning different areas of model development, including the different pre-processing approaches discussed in Section III-C, model selection and design, but also training strategies to include/exclude or freeze the weights of the different sub-component models in the ensemble at different times during the training phase. In the remaining sections, we present the results of the best trained model. We introduce several metrics to evaluate model performance. The most direct measurement for a regression problem is the mean absolute error (MAE), formulated as follows: And Root mean square error (RMSE): Both MAE and RMSE average the size of errors, while RMSE is sensitive to the variance of errors. Let e= |y− ˆy| and X be the discrete uniform random variable on set {e}. One can easily show that That is, the difference between RMSE and MAE measures the variance of the errors. We use RMSE and MAE to evaluate the performance of our models in terms of both size and variance of errors. On the other hand, RMSE and MAE have their ﬂaws. There are some long trips in our dataset where energy consumption can reach tens of thousands of grams or kWh. In that case, a 1% error in prediction will lead to a large RMSE and MAE. Therefore, we also evaluate our model with two additional metrics: mean absolute percentage error (MAPE) and its variant mean arc-tangent absolute percentage error (MAAPE). MAPE is deﬁned as shown: which is the mean of absolute percentage error (APE), i.e., . In other words, it expresses the error of the prediction in terms of a percentage. MAPE’s drawback is that it is extremely sensitive to outliers, especially when yis small. One outlier can make MAPE very large, and it is impossible to tell the model’s performance on the entire dataset from this large number. In order to ﬁx this issue, Kim and Kim [25] introduced MAAPE, formulated as follows: MAAPE averages the arc-tangent absolute error (AAPE), arctan. Each absolute percentage error is bounded byin MAAPE, so the value of MAAPE will not be signiﬁcantly affected by a small number of outliers when the sample size is large. AAPE also approximates absolute percentage error well for small errors. From the Taylor series of arctan x, we see that | arctan x−x| = O() for x ∈ [0, ]. As a result, MAAPE can give us a better idea of the overall performance of the model when there are outliers in errors. The validation set was generated by a random 20% split of the entire data. An import feature we focus on is the number of links in each trip. Since the model predicts the consumption on each link and outputs the summation as the prediction for a trip, the number of links in a trip can potentially play a role in the model’s accuracy. As shown in Figure 3, the distribution is heavily skewed to the right; most trips have fewer than 50 links, and there are few trips with more than 100 links. The large number of links does not necessarily mean that the trip is long, as the length of a link varies across a wide range. However, we ﬁnd that the number of links is strongly positively correlated to the trip length. The correlation coefﬁcient of the two features is 0.83, which means a trip with high number of links is very likely to be long. We identiﬁed only a few trips that are exceptionally long and have high energy consumption. We ﬁrst measured error by size, as shown in Table V. As the validation data can be partitioned based on powertrain type, we also computed the error on each vehicle type, as shown. The model has fairly low MAE and RMSE on both fuel and electric consumption when compared to the range of the true values from the validation set statistics shown in Table IV. TABLE V: Mean absolute error (MAE) and root mean squared error (RMSE) of trip energy consumption The large difference between MAE and RMSE estimates indicates that the variance of the errors is large. This behavior suggests that the distribution of errors is skewed and extreme outliers might appear. Since the dataset is seriously imbalanced in terms of the number of links as well as the energy consumption values, we investigated the error size by the number of links. The RMSE and MAE over all trips with l many links are computed as follows: RMSE and MAE by number of links are shown in Figure 4. It is clear that RMSEand MAEincrease as l increases. However, it does not necessarily mean that the model performs worse on long trips. For example, Figure 5 shows the model’s prediction for a Class 3 hybrid truck’s trip. This trip has 121 links and is over 170 kilometers long. We see that the model predicts the consumption on each link quite precisely. The truck consumes 27.27 kg of fuel on the entire trip, while the model predicts the consumption to be 26.21. The model underestimates the consumption by only 4%, but this trip contributes an error of over 1 kg (1000 g) to MAE and MAE, which can appear to be a large number in absolute. To further investigate the model’s performance on trips with different numbers of links, we computed the MAPE and MAAPE. However, the MAPE and MAAPE are not deﬁned for sets in which the corresponding consumption is zero (e.g., fuel consumption for a BEV is zero). Therefore, we computed MAAPEfor each powertrain type separately. Deﬁning G= {(X, y) ∈ G|y6= 0}, we compute the following: We have c ∈ {1, 2, 3, 4} for fuel consumption and c ∈ {0, 4} for electric consumption. We present the result in Figure 6 in a plot of MAAPE against the number of links for each powertrain. For electric consumption, we note that the BEV is not sensitive to the number of links, while MAAPE(PHEV) increases slightly as l increases. For fuel consumption, the Fig. 4: MAE and RMSE of trips by the number of links in the trip. The left-hand section shows plots of all trips of varying number of links. The right-hand side section shows trips with fewer than 100 links. Fig. 5: Link level prediction and cumulative prediction of a trip. errors of conventionals and HEVs are not very sensitive to the number of links either. MAAPEincreases as the l increases. TABLE VI: AAPE percentiles of fuel consumption by nonelectric vehicles and APE percentiles of electric consumption by BEVs and PHEVs We computed the AAPE of fuel consumption over all tripsF inGand the AAPE of electricity consumption overF all trips in GG. We list the percentiles of those errors in Table VI. For more than half of the trips, the predictions of our model are off by less than 0.6% and 0.4% for fuel and electric consumption, respectively. The predictions on more than 90% of the trips deviate from the ground truth by less than 5.7% and 1.5% for fuel and electric consumption, respectively. Figure 7 shows the fractional histogram of AAPE. For conventional, HEV, and ISG powertrains, our model has relative errors less than 10% for all but a negligible portion of trips. Our model also predicts most trips with APE errors less than 10%, but it struggles on a small portion of trips. The lower sub-ﬁgure of Figure 7 shows that our model predicts all but a few trips with relative errors less than 5%, which can also be seen in Table VI. In Figure 8, we see that a fully charged PHEV truck consumes electric energy at the beginning of a trip, as part of a charge depleting phase, and transitions to fuel consumption later in charge sustaining mode. The battery charge is depleted, and the model has some trouble anticipating an exact engine turn-on point. In other cases, due to the complexity of the PHEV engine controls, sporadic engine turn-on events are difﬁcult to predict by this model. The indicator of such transitions or engine turn-on events is not completely contained in the features. As a result, the prediction of PHEVs is somewhat the least accurate. The relationship between macroscopic level vehicle speed and energy is, as expected, complex for PHEVs. This phenomenon is well studied in [26]. We summarize in Table VII the percentage error of the model broken down by powertrain. Overall, we conclude that the model does not show evidence of major bias towards short trips or towards speciﬁc powertrains and is adequate for subsequent tasks. Our recommender system is based on the energy model trained in the previous section. It is assumed that a ﬂeet usually comprises a limited number of trucks, perhaps less than two hundred. As a result, instead of using an approximate nearest neighbour search [27] to narrow down potential candidates into a small subset, we explicitly compute the estimated consumption of all vehicles for a given trip to give the best possible output. This brute force approach is more accurate and does not impose a computational burden given our setting. Let V ⊂ Rdenote the collection of all vehicles. Given a trip U ∈ R, we replicate v to match the length of the trip for each vehicle, concatenate the replicated tensor with route features to form input data point X for our model, and compute the estimated consumption for this vehicle, leveraging our model. The procedures of our recommendation system are shown in algorithm 1. Fig. 8: The energy consumption values of a PHEV on a trip. The model has trouble anticipating engine turn-on events at the charge depleting/charge sustaining transition. TABLE VII: Percentage prediction error broken down by vehicle type The next module extracts TCO values for the different candidates. The TCO is expressed in terms of $/mile and is made up of two parts. First, a manufacturer’s suggested retail price (MSRP) is calculated using a bottom up approach in which each component cost is determined based on technology and timeframe [2], [3]. MSRP is determined by summing up all component costs and multiplying by a retail price equivalent (RPE) factor of 1.2. It has been shown recently that such a rigid adjustment factor is not appropriate for all component technologies [23] due to the large differences in pricing strategies between manufacturers, vehicle classes, market segments, etc. In the future we plan to leverage top-down component cost estimates as presented in [23] to improve MSRP estimation, the key to accurate TCO computation. The second part of the TCO calculation accounts for operational expenses. An energy cost is calculated based on the cost of electricity, gasoline, or diesel fuels using the Annual Energy Outlook from the U.S Energy Information Administration (EIA) predictions [28]. The energy cost is calculated over an expected period of ownership years and various vehicle miles traveled distributions that depend on the vehicle/application use. Other TCO components such as discount rates (inﬂation and risk premium), depreciation, and resale value are also considered in the calculation. Maintenance and insurance costs are not taken into account. Based on TCO results, we designed a formula to rank the candidates on a scale of 1 to 5. Let ˜y ∈ Rbe the estimated TCOs of n candidates for a given trip. We rank each candidate by the following: In equation 6, we map, the relative distance of TCOs to a target value α, to set {1, 2, 3, 4, 5}. If we have some previous observations of energy consumption on the trip, we set α to be the expected optimal consumption, and let α = min{α, min˜y}. If the expected optimal value is unknown, we set α = min˜y. Figure 9 shows an example of ﬁve candidate vehicles recommended for a given trip. In addition to computing TCO and performing single trip recommendations, we have extended the recommender system to optimize for a more general assignment problem. In this setting, given n vehicles and m trips (n ≥ m), the goal is to select the best m vehicles to minimize the total TCO of all m Algorithm 1: Recommend vehicles from V input : A new trip U ∈ R, a set of candidate output: Recommendation vand consumption table. Table = {}; for v ∈ V do [u, v], · · · , [u, v]← X; f(X) ← y Estimate consumption; ˜y ← y Compute TCO; end v= argmin ˜y Fig. 9: Recommendation of ﬁve candidate vehicles evaluated for a single given trip. We call this framework VRecSysOne. Fig. 10: A weighted bipartite graph that represents candidates and trips. Each edge is weighted by TCO. trips. In other words, we would like to minimizes total TCO of the ﬂeet in its entirety by optimally distributing/deploying trucks over various trips. As shown in Figure 10, this problem is equivalent to ﬁnding the minimum perfect matching of a complete weighted bipartite graph G = (V t U, E). The algorithm that yields the optimal solution of this problem is the Kuhn-Munkres algorithm [29], which solves this problem via a primal-dual approach. The primal linear programming (LP) is formulated as Thanks to the fundamental theorem of linear programming, the optimal solution of this problem will be found at a corner point over the feasible polytope. It guarantees the optimal solution is an 0-1 vector, i.e., x∈ {0, 1}, ∀i, j. Hence, this LP is equivalent to our assignment problem. By solving the dual of the LP:X the K-M algorithm is guaranteed to obtain the optimal solution with complexity O(|V |·|U|). The recommender system takes a n by m matrix consisting of TCOs and outputs a vector of length m encoded IDs of optimal vehicles. Figure 11 shows an example of assignment input and output for the case of n = m = 3. In this example, we note that the electric truck is not assigned to the ﬁrst trip (best option) but instead assigned to the third trip (highest TCO). The full hybrid truck is deployed to the ﬁrst trip, to beneﬁt the total cost of the entire ﬂeet. Fig. 11: Example of a general assignment problem in which n = m = 3, i.e., three trucks are to be optimally deployed over three trips such that ﬂeet level TCO is minimized. The recommendation system developed here is applied within a large-scale agent-based travel demand simulator called POLARIS [18]. Applying such a model on hundreds of thousands of trips within a forecasting tool helps identify the possible spatial and temporal impacts of random and optimal vehicle type assignments for commercial trips. A brief overview of POLARIS and its components is next, along with details on integration, and highlights of use case plans. 1) POLARIS: POLARIS is an agent-based activity-based travel demand forecasting tool that simulates all personal and freight travel for a given region across a 24-hour travel day. Residents in the region are synthesized based on underlying demographics to match all cross-tabulations of age, gender, household income, household size, and other key metrics from the U.S. Census Bureau’s Public Use Microdata Sample (PUMS) [30]. On the personal travel side, activities are then planned and scheduled for traveler agents [31] from this synthetic population, and several econometric choice frameworks are applied to choose the destination for the activity, start time, and travel mode to travel to the chosen activity location. Currently, on the freight side, commercial trips both inside and external to the region (i.e., trips originating or terminating outside the region) are modeled through a top-down framework that decomposes aggregate data into individualized trips so that congestion patterns can be calibrated for a region [19]. A full agent-based freight model was ﬁrst implemented in [32] including an e-commerce MDT module[20], and is being extended with data-driven processes and a robust framework named CRISTAL (Collaborative, Informed Strategic Trade Agents with Logistics) as proposed in [22]. The CRISTAL framework creates a synthetic population of ﬁrm agents and their member establishments using data from the US Census County Business Patterns and other sources. Fleets for each ﬁrm are modeled using a Seemingly Unrelated Regression with Latent Tobit Variables (SURTLV) approach [33] that includes variables for customer service and logistics sophistication strategies of ﬁrms [34] using data from the CoStar real estate database, the US Securities and Exchange Commission, and other sources. The SURTLV model predicts the number of MDT and HDT owned by each ﬁrm. The CRISTAL framework is being integrated with POLARIS to create a fully agent-based passenger and freight model that supports several travel modes ranging from household vehicles (single or high-occupancy trip), non-motorized travel (walk or bike), use of a ride-hailing ﬂeet [35], and medium and heavy-duty freight trips. With all travel demand in place, a time-dependent Arouter provides trajectories taking into account travelers’ expected user equilibrium path through information mixing from historical information [36]. Vehicles move on the network abiding by trafﬁc ﬂow principles [37] with powertrain-speciﬁc decisionmaking available such as electric vehicle battery consumption and charging. 2) Model Integration and plans: POLARIS is a powerful large-scale travel demand model encompassing several travel behaviors for a realistic forecast. Integrating the recommendation system into POLARIS was done through the Lite interface of the large-scale machine-learning estimation and prediction tool TensorFlow [38]. TensorFlow Lite provides a lightweight interface for machine-learning model prediction and is typically used to deploy models on micro devices, such as phones and tablets. With its low latency and low memory framework, the recommendation system can be used within POLARIS with minimal impact on memory or computational footprint while still leveraging robust results. The next steps will be ﬁrst to integrate the recommendation system with each ﬂeet, then to deploy the integrated system in studies involving alternative powertrains for MD/HD freight, with powertrain options including diesel, gasoline, electric and hydrogen. The system will be implemented at the operational level, where routes are generated for each vehicle that is conducting pickup and delivery tours. Information on these operational demands (the routes and their characteristics such as length) will be used with a feedback loop to the recommender system to evaluate the optimal powertrain mix for the ﬂeet. The resulting route and powertrain outputs will be combined to evaluate energy and emissions for each ﬂeet, which can be aggregated up to study regional freight system impacts. This work shows how an end-to-end vehicle–route recommender system framework can be designed by leveraging large-scale trip/route data and deep learning models. In our setup, the trip, route, vehicle and energy data are generated by a suite of transportation system and vehicle modeling tools using a wide range of representative mobility scenarios across an entire metropolitan area in varying conditions. We presented a latent energy learning model that attempts to correlate energy outcomes at the link (road segment) level with road and high-level trip information only, i.e., with masked high-resolution speed proﬁles. On the basis of highly accurate energy models, subsequent blocks of the algorithm perform single trip recommendations for a list of vehicle candidates by considering TCO metrics. In its more general form, we have implemented a general assignment functionality for which the recommender system can be leveraged to optimally deploy several trucks over several deﬁned trips. For ﬂeets, this can support investment decisions (e.g., which combination of vehicle technologies would allow to minimize TCO) as well as match individual vehicles to routes on any particular day. It represents real world situations in which routing can be known up to a certain level of trafﬁc ﬁdelity. With a given truck inventory and/or availability speciﬁc to the ﬂeet, the recommender model facilitates cost-effective deployment of trucks to routes. Finally, we’ve deployed and integrated the model into the POLARIS agent-based transportation system tool for online and real-time truck recommendations within the modeled ﬂeets. Route selection has a big impact on the vehicle technology choice. Different powertrain choices, and investment decisions are made on the basis of cost, energy, time or other psychological aspects. For example, [39] investigates this optimum routing assignment for electric vehicles (in comparison to conventional vehicles) via speciﬁc energy modeling and microscopic simulation (i.e with known speed proﬁle). [40] and [41] studied eco-routing comparisons between various vehicle technologies while retaining micro information. [42], among others [43], analyze thoroughly conditions for energy efﬁcient assignment, leveraging data and simulation, and point out that macroscopic tools lack of ﬁdelity for an accurate energy estimation. In fact, [44] discusses the complexity involved. In our work, we overcome the need to depend on microscopic level information, this was tackled in earlier studies via different approaches [45], [46], [47], [48], [49], and [50] developed a sophisticated eco-routing framework on that basis. We proposed here a deep learning perspective to predict accurate energy consumption values in a macroscopic setting, that learns latent (microscopic) information via careful model design and feature engineering. Under the umbrella of a recommender system, we applied the framework to routing, and technology dependent cost-efﬁcient assignment problems as attempted previously by [51]. This new framework is very relevant, for example, to freight companies. The work described was sponsored by the U.S. Department of Energy (DOE) Vehicle Technologies Ofﬁce (VTO) under the Systems and Modeling for Accelerated Research in Transportation (SMART) Mobility Laboratory Consortium, an initiative of the Energy Efﬁcient Mobility Systems (EEMS) Program. The following DOE Ofﬁce of Energy Efﬁciency and Renewable Energy (EERE) managers played important roles in establishing the project concept, advancing implementation, and providing ongoing guidance: Erin Boyd and Danielle Chou (Ofﬁce of Energy Policy and Systems Analysis, U.S. Department of Energy). The submitted manuscript has been created by UChicago Argonne, LLC, Operator of Argonne National Laboratory (Argonne). Argonne, a U.S. Department of Energy Ofﬁce of Science laboratory, is operated under Contract No. DE- AC02-06CH11357. The U.S. Government retains for itself, and others acting on its behalf, a paid-up nonexclusive, irrevocable worldwide license in said article to reproduce, prepare derivative works, distribute copies to the public, and perform publicly and display publicly, by or on behalf of the Government.