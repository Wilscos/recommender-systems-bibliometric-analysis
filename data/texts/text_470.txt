Federated learning (FL) exploits the computation power of edge devices, typically mobile phones, while addressing privacy by letting data stay where it is produced. FL has been used by major service providers to improve item recommendations, virtual keyboards and text auto-completion services. While appealing, FL performance is hampered by multiple factors: (i) differing capabilities of participating clients (e.g., computing power, memory and network connectivity); (ii) strict training constraints where devices must be idle, plugged-in and connected to an unmetered WiFi; and (iii) data heterogeneity (a.k.a non-IIDness). Together, these lead to uneven participation, straggling, dropout and consequently slow down convergence, challenging the practicality of FL for many applications. In this paper, we present GEL, the Guess and Learn algorithm, that signiﬁcantly speeds up convergence by guessing model updates for each client. The power of GEL is to effectively perform “free” learning steps without any additional gradient computations. GEL provides these guesses through clever use of moments in the ADAM optimizer in combination with the last computed gradient on clients. Our extensive experimental study involving ﬁve standard FL benchmarks shows that GEL speeds up the convergence up to 1.64× in heterogeneous systems in the presence of data non-IIDness, saving tens of thousands of gradient computations. Federated Learning (FL) (McMahan et al., 2017) has recently gained popularity to address on the one hand, the crucial need for scalability due to an exponential volume of training data, and a growing concern for privacy on the other. FL leverages the computational power available at the edge of the network, typically end-users devices to collaboratively train a global model. Yet, the users’ data stays where it has been produced, preventing raw data to travel on the network, thus ensuring some level of privacy. More speciﬁcally in FL, a central server broadcasts a global model to participating clients (edge-devices). Clients perform a number of training iterations on their local data and send the updated local model to the server. The server is in charge of aggregating local models to form the new global model and send it back to a new set of clients. This process repeats for several rounds until a desired accuracy is reached. The increasing computing power at the edge coupled with privacy guarantees has made FL an attractive alternative for training machine learning models in the last half decade, gaining increased attention from both academia and industry (Bonawitz et al., 2019; Yang et al., EPFL - Swiss Federal Institute of Technology, Lau- <akash.dhasade@epﬂ.ch>. Technical report. Under review. 2018; Federated, 2019; Yang et al., 2021; Caldas et al., 2018). Despite its attractive properties, FL’s performance can be impacted by several factors that signiﬁcantly slow down the convergence. It is indeed a well-known fact that a typical federated training task is expected to take a few days (Bonawitz et al., 2019), making it impractical for timecritical applications. Firstly, FL training is affected by systems heterogeneity, which refers to system constraints of participating client devices on the learning process, such as the differences in computing power, memory and limitations on network bandwidth. For instance, devices may drop off in the middle of training depending upon the network availability. In a study using large-scale data from 136k smartphones, (Yang et al., 2021) found that heterogeneity leads to 2.32× longer training time, 9.2% accuracy drop and undermines fairness. Secondly, federated training should ideally take place when devices are plugged-in, idle, and connected to an unmetered Wi-Fi (Bonawitz et al., 2019). Referred to as behavioral heterogeneity, this imposes an even stronger constraint on the client computation resulting in uneven participation and unpredictable dropouts. (Abdelmoniem et al., 2021) measure that device and behavioral heterogeneity together lead to a 2.2× and 4.6× degradation in fairness and average accuracy respectively. Thirdly, FL suffers from statistical heterogeneity, which refers to the fact that the individual data produced and stored on a client device might signiﬁcantly differ from another client’s dataset and more generally from the global dataset. This may happen along two dimensions a) the distribution from which the data is drawn might vary from one device to another (IID vs non-IID); and b) the amount of data on users’ devices might be very different for different users (balanced vs unbalanced). The impact of such statistical heterogeneity is that during training, client models may signiﬁcantly evolve towards their own local optima, thus slowing down the global convergence. Boosting FL for free Motivated by these challenges, we design GEL, our Guess and Learn algorithm to boost convergence at no additional computational cost. In contrast to previous approaches that largely focused on the machine learning aspect of federated training, GEL takes a purely computational view of the learning process, focusing on the system-induced constraints. Under these constraints, we assume that clients are limited in their capacity to contribute to the learning process. We regard this capacity as the computational budget of the client which dictates the number of local model update steps the client can perform when participating in a training round. The challenging FL characteristics induce low-budgeted clients than ideal for training, yielding slower convergence. The main goal of GEL is to offer clients a way of increasing the number of model update steps they can locally perform at no additional cost through a novel guessing mechanism. By doing so, GEL strives to maximize progress towards global model convergence under limited budget constraints. Typically, an ML training step can be seen as moving the model weights in a speciﬁc direction determined by the negative gradient. The core idea of GEL is to guess the direction of the next model update taking the odds that an actual gradient computation would have led the model towards that direction. To achieve this, GEL makes clever use of accumulated moments in the ADAM optimiser (Kingma & Ba, 2014), along with using the last computed gradient on the client as a proxy for upcoming uncomputed gradient. The power of GEL is that these guesses come for free, i.e., without any additional gradient computations. For the rest of the paper, we use u to refer to the computational budget of clients and g to refer to the number of guesses. A subscript k is used when referring to a speciﬁc client k. Therefore, a client k performs (u+ g) model update steps with uactual computations and g guessed updates. We evaluate GEL on 5 standard FL benchmarks (Caldas et al., 2018). Our experiments show that in homogeneous low-budget settings (same u for all clients), GEL not only boosts convergence but achieves2 convergence rates equivalent to (u + g) total model update steps, by performing only u actual updates and guessing g steps. For example, GEL on Shakespeare dataset with (u = 20, g = 5) converges 1.34× faster than no guessing (u = 20, g = 0), impressively taking about the same number of communication rounds as (u = 25, g = 0) to achieve the same target accuracy. Our experiments also demonstrate that while achieving such a performance boost, GEL also saves tens of thousands of gradient computations, approximately 50 k in the above example. Finally, in the more realistic heterogeneous budget setting, GEL boosts convergence up to 1.64× for free. Contributions In this paper, we make the following contributions: • We revisit the FL limitations through a computational budgets lens, taking a fully computational view of the FL process. • We present the design of a novel algorithm to improve the performance of FL for free and propose GEL, our guess and learn algorithm, that boosts convergence under computational budget constraints. • We present an extensive evaluation of GEL on a widerange of datasets and models and demonstrate that GEL is able to signiﬁcantly speed up the convergence for free in non-IID contexts under both homogeneous and heterogeneous budget settings. The remainder of this paper is organized as follows. Section 2 presents a brief background on deep learning optimisation and federated training that sets the context for GEL. We then present our core algorithm GEL in Section 3. The experimental results for GEL are presented and discussed in Section 4. Finally, we review related work in Section 5 before concluding in Section 6. GEL relies on effective use of momentum in the state-ofthe-art ADAM optimiser (Kingma & Ba, 2014). We ﬁrst present a brief summary on the evolution of different deep learning optimizers that paved the way to ADAM. Then we discuss key components of ADAM that enable guessing in GEL. Finally, we present a quick outline of steps involved in a typical federated training process along with minor modiﬁcations required for GEL. Deep Learning Optimisation Neural network objective functions are generally non-convex, thus the goal of deep We encourage reproducible research and will be sharing all artifacts. The source code link is currently omitted due to doubleblind review. learning (DL) optimisation is to reduce the loss function as much and as fast as possible, over aiming for global minimum. First order gradient-based methods remain the most widely used techniques to optimise non-convex DL objectives. The default among them is the stochastic gradient descent (SGD) algorithm, which updates weights in negative direction of the gradient computed by sampling a minibatch of data b. The update rule goes as follows, where  is the step size: Improvements to SGD rely on the use of momentum. The momentum v is simply an exponentially decaying moving average of all past gradients given as v ← αv − ∇`(w; b) where α is the decay rate. Such overtime accumulation alleviates the impact of noisy gradients and therefore accelerates training. The update rule for SGD with momentum algorithm is the following: Further advanced algorithms in DL optimisation fall under the group of adaptive learning rate techniques. The basic idea is that the loss function curves differently in different dimensions, hence using the same learning rate  for all dimensions is not optimal. To address this, a running moment of squared gradients v← βv+ (1 − β)grad  grad is accumulated where β is the decay rate hyper-parameter and grad = ∇`(w; b). The popular algorithm RMSPROP (Hinton, 2012) then applies the following update rule: where δ (usually 10) is a small positive constant for numerical stability and the update is applied element-wise. RMSPROP thus makes gentle progress in the parameter space by scaling down large partial derivatives and scaling up small partial derivatives inversely proportional to square root of accumulated squared gradients. RMSPROP is a dependable algorithm for many deep learning tasks. The optimiser ADAM goes one step further and maintains an exponentially weighted moving average of both ﬁrst order vand second order vmoments of gradients. Precisely, where α and β are again the decay rate hyper-parameters. Seen as the best combination of both adaptive learning rate methods and momentum, the update rule in ADAM appears as follows:v The actual update rule further contains some bias correction terms which we omit for simplicity. ADAM is generally regarded to be fairly robust in spite of the hyperparameters, which makes it a preferred choice of many DL practitioners (Goodfellow et al., 2016). For ADAM, α = 0.9 and β = 0.999 are the typical values of decay rate hyper-parameters and often tend to work well in practice. With these defaults, a closer look at the two accumulated momentums offers an interesting insight: the new computed gradient contributes only 10 % and 0.1 % to the new values of vand vrespectively. Precisely, v← 0.9 × v+ 0.1 × grad v← 0.999 × v+ 0.001 × (grad  grad) Since the accumulated moment is the major contributor to the update (90 % and 99.9 %), using a gradient proxy instead of the actual gradient should still produce a good update. GEL leverages this facet of ADAM’s machinery to guess future model updates. The guessing in GEL consists of reusing the last computed gradient as a proxy for the upcoming one. This represents the core of our guess and learn algorithm, which we describe further in Section 3. Federated Training We list next the several steps involved in a typical federated training process. These steps provide a general template for most FL algorithms including GEL. We then brieﬂy describe FEDAVG (McMahan et al., 2017), the most popular algorithm for federated training, and contrast the steps in GEL with it. The federated training takes place in rounds of communication orchestrated by a central server. Each such round constitutes of the following steps (Kairouz et al., 2019): C check-in with the server. The server then selects a subset K << C clients to perform federated training. 2. Broadcast: The server broadcasts the global model along with the training conﬁguration to the selected clients (learning rate, optimizer, no. of epochs etc.). 3. Client computation: Clients train on their local data based on the training conﬁguration received from the server. Upon completion of training, clients push the updated model parameters to the server for aggregation. 4. Aggregation: The server aggregates client model updates using a simple or a weighted average of client models. 5. Model update: The server updates the state of global model using the computed aggregate. In practice, the client computation and aggregation steps involve further actions to ensure privacy, e.g., clients encrypt model updates using encryption (Phong et al., 2018) or secret sharing (Bonawitz et al., 2017) techniques before sending it to the server which then performs secure aggregation. The FEDAVG algorithm uses SGD as the local optimizer for clients. As training conﬁguration, it broadcasts the learning rate, number of epochs and the local minibatch size to each client. Finally, it uses a weighted averaging scheme based on the number of samples on client devices to perform the aggregation. In comparison, clients in GEL use the ADAM optimiser and the server broadcasts number of guesses instead of number of epochs to each client. Note than in GEL, the number of model update steps (analogous to epochs) are predetermined by computational budget constraints. Finally, GEL uses a plain averaging of client models to produce the global model. Thus, the overall structure of GEL remains similar to FEDAVG with trivial modiﬁcations to the server design. As motivated in Section 1, the participating clients are limited in their capacity to contribute to the training process by budget u. The budget dictates the number of model update steps the client can perform when participating in a training round. Given the computational budget constraints of clients [u, u, . . . , u] participating in a training round, the goal of GEL is to maximize the amount of progress made towards the optimal global model. GEL achieves this by guessing future model update steps for every client, the number of which is given by [g, g, . . . , g]. Thus, each client virtually performs [u+ g, u+ g, . . . , u+ g] total learning steps, thereby boosting convergence. These guesses do not require any extra gradient computation but only comprise of a model update step, a much faster computation than a forward and backward pass through the deep model. Also, we do not make any temporal assumptions regarding budgets of clients that participate again in future rounds, hence budget constraints in a given round are considered fully independent of all previous rounds. We detail next the exact steps in GEL. Similar to FEDAVG, the training begins when a few online clients check-in with the federated server. The server then randomly selects K clients to perform a round of training. At this point, the server decides the number of guesses to be performed by each client. These guesses could either be a ﬁxed number or a ﬁxed percentage of actual computations performed by the client. Note that the server may determine the number of guesses even without knowing the budget constraints of the clients. Finally, the server broadcasts the global model w and gto each client k for local training (Algorithm 1, lines 4-8). The clients begin training by instantiating the ADAM optimizer (Algorithm 1, line 11). This sets the default values for decay hyper-parameters and initializes the moments to zero. Algorithm 2 presents the complete ADAM algorithm (Section 2) adapted in context of GEL. To simplify understanding GEL, one can think of ADAM as a blackbox optimizer that produces a model update (denoted ∆w) when fed with the gradient (denoted grad) at step i i.e., ∆w= Adam(grad, i) (Algorithm 1, line 16). Next, the clients sample a random batch of data, compute the gradient, fetch the model update from ADAM and ﬁnally perform the update altogether for usteps (Algorithm 1, lines 13-17). These steps constitute an actual gradient computation involving forward and backward pass through the deep model. At this point, when the clients have exhausted their budgets u, GEL’s guessing mechanism steps in. Notice that the ADAM optimizer accumulates moments v and vduring the umodel update steps. Now, to perform the model update at step u+ 1, GEL simply uses the last computed gradient, i.e., the gradient computed at step uas a proxy for the uncomputed gradient, resulting in ∆w= Adam(grad, u+ 1). To obtain an intuition behind this, one can picture an optimization landscape where certain of its regions have more or less the same slope. It thus makes sense to use the previous gradient as a proxy for the next one. As explained in Section 2, ∆wacts as a good guess of the real update since the accumulated moments share a major portion of the update. Note however that the update resulting from ∆wand ∆wtogether is not a step size adjusted update of ∆w, i.e., ∆w+ ∆w6= ∆wfor some  because of the exponentially decaying machinery of Adam. Clients continue to guess using gradas a proxy for all next gguesses before ﬁnally returning the updated model to the server (Algorithm 1, lines 18-22). The server then aggregates the received models using a simple averaging and updates the state of global model (Algorithm 1, line 9). The complete GEL is presented in Algorithm 1. Some of GEL beneﬁts partially come from the averaging performed by the FL server. Fundamental to FL, the averaging performs surprisingly well on both independent and identically distributed (IID) and non-IID data. For instance, a model combined as the average of two models independently trained on disjoint subsets of the MNIST dataset achieves a lower loss on the entire training set than either model taken alone (McMahan et al., 2017). In other contexts, averaging is often used to reduce the impact of noise, like the mean ﬁlter in computer vision applications (Gonzalez & Woods, 2006). In this sense, averaging allows the design of algorithms where client updates can be somewhat inexact and yet produce a good general model. Figure 1. Illustrative example demonstrating the beneﬁts of guessing together with averaging. We see the loss contours for two clients, their model update steps and the optimal path for the global model. The average global model produced with guessing ∆wis better than the one without guessing ∆w because the former makes more progress on the optimal path. In this example, u= u= 3 and g= g= 2. An illustrative example for this situation is shown in Figure 1 for federated training with two clients. The clients take update steps towards their local minima identiﬁed by loss contours, producing model updates ∆wand ∆w. Upon guessing using accumulated moments, they produce model updates ∆wand ∆w. Although the guessed updates are not exact for each client, the average global model produced with guessing ∆w(dashed arrow) is still better than the one without guessing ∆w (dotted arrow) – making more progress towards the global optimum. Finally, we note that clients in GEL are stateless. This is crucial for practical applicability of any FL algorithm since the probability of any particular client participating in more than one round of training is very low (Kairouz et al., 2019). Clients in GEL instantiate a new ADAM when commencing the training. Thus, the accumulated moments are local to the current training and do not carry over from previous rounds in case the client participated before. Lastly, since the overall procedure of GEL remains very similar to FEDAVG, any additional algorithms applied on top of FEDAVG like model compression, differential privacy or secure aggregation can be directly applied to GEL without special amendments. We seek to quantify the beneﬁts of GEL in homogeneous as well as heterogeneous budget settings and measure the extent of possible guessing, i.e., the number of guesses that can be made until they negatively start affecting convergence. We consider as baseline for GEL, the setting with g= 0 ∀k ∈ {1, 2, . . . K}, i.e., GEL with no guessing for all selected clients K. The performance is measured as the number of communication rounds required to achieve a5 Algorithm 1: GEL. The K clients are indexed by k; uand gare the computational budget and number of guesses for client k, and B is the local mini-batch size. Algorithm 2: ADAM. vand vaccumulate ﬁrst and second order momentums respectively, α and β are decay rates,  is the learning rate and the function gradientStep executes one step of ADAM. = 0, v= 0 desired target accuracy. Datasets We evaluate GEL on ﬁve different FL benchmarks from LEAF (Caldas et al., 2018) used in several previous works (Li et al., 2018; 2019; Abdelmoniem & Canini, 2021; Abdelmoniem et al., 2021; Yang et al., 2021). Table 1 summarizes the learning task, dataset, models and other statistics for each benchmark. The data partitioning for all datasets is non-IID unless noted otherwise. Further, unlike SGD, Adam is generally regarded to be fairly robust to the choice of hyperparameters (Goodfellow et al., 2016). We thus stick to recommended defaults for all hyperparameters in Adam (α = 0.9, β = 0.999,  = 0.001, δ = 10) with the momentums initialized to zero. The number of selected clients per round is ﬁxed to 20 for all benchmarks. We use a batch size of 20 for FEMNIST and Shakespeare, 10 for Sent140 and 5 for CelebA and Synthetic. Lastly, we set the accuracy targets similar to ones used in previous works (Abdelmoniem & Canini, 2021; McMahan et al., 2017; Caldas et al., 2018). These are also included in Table 1. Fairness of comparison The training in FL proceeds in rounds of communication where the server selects clients before each round. This selection is simulated by a uniformly random sampling of clients from the set of total clients available for each benchmark. The client budgets are also uniformly randomly sampled for heterogeneous budget experiments. We perform at least ﬁve runs of each distinct experiment where these runs differ in their client sampling, budget sampling and in model initialization. We observe high variance in rounds of convergence introduced by this stochasticity, speciﬁcally for experiments with heterogeneous budgets. To establish fair comparison between GEL and the baseline, the client and budget sampling is kept ﬁxed for any two comparable runs. We further ensure that GEL uses the same random initial model as the baseline in any two comparable runs, thereby eliminating any effect of model initialisation on the measured speedup. This is crucial since the convergence of deep models is very sensitive to the choice of initialisation (Goodfellow et al., 2016). Implementation We implement GEL in TensorFlow Federated (TFF) framework (Federated, 2019), the opensource framework by Google for machine learning on decentralized data. The experiments ran in the simulation environment provided by TFF. We now present the results in the homogeneous budget setting where all clients have the same computational budget, which also remains constant across communication rounds. Although not the most realistic setting, it helps us to clearly observe and understand the effects of guessing in GEL. As before, let u and g denote the computational budget and number of guessed update steps respectively for every client. Like homogeneous u, note that we apply the same number of guesses g on every client. Figure 2 depicts convergence curves in three cases for all ﬁve benchmarks: 3. Target: u = u+ g, g = 0. The goal of these cases is both to know if GEL boosts convergence (comparing with Baseline) and to observe if the boost can imitate the case with equivalent real computations and no guesses (the Target). Surprisingly, GEL boosts convergence such that the curves for GEL and Target almost overlap. We observe this pattern consistently for low budgeted clients (u≤ 10). Although the pattern does not perfectly continue all the way to high budgets, it is impressive that GEL attains such a convergence without computing a number of gradients. We quantify the exact saved computation for plots in Figure 2 in Table 2. As we observe, GEL saves a few thousand gradient computations for most datasets and about 180k for synthetic. Lastly, for an IID data partitioning, GEL also achieves similar performance beneﬁts as depicted in Figure 3. We study next the performance of GEL across a range of values of u from low budget to high budget, while measuring the beneﬁts of guessing in this spectrum. Figure 2. Convergence boost achieved by GEL in homogeneous budget setting with non-IID data partitioning. GEL outperforms baseline and overlaps with target. Figure 3. Convergence boost achieved by GEL in homogeneous budget setting with IID data partitioning. GEL outperforms baseline and overlaps with target. 4.2 How much can we guess? A consequent natural question to ask is the extent of guessing in GEL, i.e., how much can we guess until it starts negatively affecting convergence. A good way to establish this extent is to parameterize the number of guesses as a function of computed gradients. Thus, for a given u, we consider the number of guesses as percentage of uwhere x% guesses refer to g=u. With this, we would like to answer the following questions: • For given u, to what extent can we guess (g) as percentage of usuch that GEL meets Target? • Does this vary for different values of ufrom low budget to high budget?7 • How many gradient computations does GEL save in each case? To answer the ﬁrst question, we experiment with different guessing percentages selected from the list [10%, 25%, 50%, 75%, 100%, 125%]. This list covers a broad range of values including the case where the number of guessed steps are beyond that of gradient computations (125%). To answer the second question, we must vary uover a range of values [a, b] deﬁned for every dataset. We select these ranges as follows: for every dataset, consider the number of steps (u) performed by the median client in one epoch. Thus, u= de where nis the number of samples on median client and B is the batch size for the dataset. The values of nfor all datasets are included in Table 1. We then set a = uand b = 5 × uwhich roughly corresponds to 1-5 epochs. We follow this scheme for all but the Shakespeare dataset, for which the number of samples per client is two orders of magnitude larger than all other datasets. To focus on low computational budges, for the Shakespeare dataset we adopt a much lower range of values than estimated by this scheme. The selected ranges for each dataset are presented in Table 3. We present the results for FEMNIST dataset in Figure 4. The ﬁrst row depicts the number of communication rounds until convergence for different values of uand gwhile the second row depicts the corresponding total number of gradient computations in all three cases: Baseline, GEL and Target (as deﬁned in the previous section). For the sake of computational feasibility, we experiment with a ﬁxed few values of uchosen from [8, 40]. These values are stated on the title of each chart column in Figure 4. We omit though the results for u> 24 as they offer no interesting trends. We observe in all plots that GEL consistently and signiﬁcantly outperforms Baseline in terms of number of Table 2. Number of saved gradient computations when using GEL in homogeneous budgets case. This is computed as Savings = (CR× (u+ g) − CR× u) × no. of clients where CR refer to the number of communication rounds until convergence for the Target and GEL respectively and no. of clients = 20 in our experiments. Figure 4. Performance of GEL for FEMNIST dataset across a spectrum of budgets and guessing percentages. GEL always outperforms baseline and meets Target when guessing up to 25% for all three values of uwhile needing less total gradient computations than either of them (row-2). communication rounds, demonstrating the impact of GEL to boost performance. Results also show that GEL exactly meets Target when guessing up to 25% (where Target performs u= 10 steps and GEL performs u= 8 steps plus 2 guesses) and is very close for 50% (where Target performs u= 12 steps and GEL performs u= 8 steps plus 4 guesses). After this point, guessing starts to be detrimental. This pattern is consistent for all three values of u. We also observe the decreasing trend in number of rounds of convergence from the left plot to the right plot in the ﬁrst row for all three cases. As expected, the more computations per client the less the number of rounds until convergence. This however begins to plateau towards the right plot, indicating signiﬁcant decrease on the beneﬁts of increasing local work. In the context of guessing, this suggests that performing guesses is effective when clients are low in their budget as illustrated by the decreasing gap between Baseline and GEL moving from the u= 8 to u= 24.8 Finally, we observe in the second row of charts that the total gradient computations performed by GEL is consistently less than Target in all cases. Note that this does not necessarily imply reduction in communication costs since GEL may require slightly more rounds to converge than the Target. However, in cases where both GEL and Target take the same number of rounds to converge, GEL brings considerable savings in terms of gradient computations when compared to Target for equivalent costs in terms of communication. On the other hand, when compared to the baseline, GEL signiﬁcantly beneﬁts both in communication and computation costs. We present similar charts for the Synthetic and CelebA datasets in Figures 5 and 6. For the Synthetic dataset, guesses up to 125% provide an improvement across the whole spectrum of uas the blue curve overlaps the red one for all experiments. Like with the FEMNIST dataset, we observe similar trends of boost over the Baseline, the decreasing gap between GEL and Baseline with increasing uand consistent savings on gradient computations for both the Synthetic and CelebA datasets. Distinctively, for CelebA, the Target plot plateaus very quickly with increasing uand, different runs of same experiment show high variance in rounds of convergence. Nevertheless, on average, GEL always outperforms Baseline and meets Target in most cases. For reasons of both computational feasibility and limited space, we exclude Shakespeare and Sent140 in this section. Revisiting the questions at the beginning of this section, we summarize the answers below: • The extent to which guessing is beneﬁcial varies with datasets. We observed positive results for 25% guessing in FEMNIST and 125% for Synthetic. Accounting for high variance in runs of CelebA, beneﬁts were observed for most values in 25%-125%. • The results were observed to be consistent across the budget spectrum. Notably, GEL achieves maximum performance beneﬁts when clients are low-budgeted, which is the norm in FL. • GEL always performs less gradient computations in total than both Baseline and the Target. This ranges anywhere from a few hundred to tens of thousands of computations observed in the second row of charts in Figures 4 to 6. In a broader perspective, these results suggest that one can apply a ﬁxed number or a ﬁxed percentage of guesses (for instance, 25%) across a signiﬁcant spectrum of u. This enables the federated server to determine the number of guesses without knowing the computational budgets of the clients, thus greatly simplifying server design. We present next the results in heterogeneous budget setting. In this setting, clients have unequal computational budgets representing the most realistic scenario. We follow the same approach as in (Li et al., 2018) to simulate the heterogeneous budgets case by uniformly randomly sampling client budgets from the range [a, b] for every dataset (see Table 3). The values of a and b are chosen as described in the previous section. We ﬁx the number of guesses in GEL to 5 i.e setting g= 5 ∀k ∈ {1, 2, . . . , K}. To quantify speedups achieved in both low budget vs high budget cases, we split the range into two halves, measuring beneﬁts for each separately. The speedups achieved for all 5 benchmarks are given in Table 4. We observed long stretches of rounds where the models struggled to achieve the target accuracy when already within 2% of the target. This made it difﬁcult to infer and analyze the speedup accurately with high variance in such long tails. To address this, we instead measure speedups at slightly lower (by at most 2%) accuracy targets for some datasets. The new targets are stated alongside the datasets in Table 4. Using only 5 guesses speeds up the convergence of Synthetic dataset by 1.64× and Shakespeare by 1.56× in Range − 1. The speedups for remaining datasets are more modest but still signiﬁcant given the expected training time to last a few days. Further, the speedups for Range − 1 are relatively higher than Range − 2. This conﬁrms that settings with low budget clients beneﬁt more from GEL. The only slowdown in this table observed for the CelebA dataset in Range − 2 can be explained by the fact that in Range − 2, the results obtained without any guesses are already very good. Thus performing further update steps (both with or without guessing) will not provide any beneﬁts similar to rightmost plots in the ﬁrst row of Figures 4 to 6.9 Figure 5. Performance of GEL for Synthetic dataset across a spectrum of budgets and guessing percentages. GEL always outperforms Baseline and meets Target when guessing up to 125% for all three values of uwhile needing less total gradient computations than either of them (row-2). Federated Learning Federated learning has emerged as a privacy-preserving technique to learn efﬁcient models from sensitive user data. It has been deployed by major service providers (Bonawitz et al., 2019; WeBank AI Group, 2018) recognizably by Google to improve search suggestions on Google keyboard (Yang et al., 2018). The resurged interest in FL by both academia and industry is evident through several comprehensive surveys (Kairouz et al., 2019; Wang et al., 2021; Li et al., 2020; Bonawitz et al., 2019) put together by large collective effort. (Li et al., 2020) lists expensive communication, statistical heterogeneity and systems heterogeneity amongst the core challenges for FL. The need for new techniques which reduce the number of communication rounds, are robust to low client participation and heterogeneous hardware, and perform well in the presence of non-IID data is largely realized. By providing convergence boost, we see GEL as tackling some of these challenges. Federated Optimization (McMahan et al., 2017) adapted the classical SGD to federated learning, introducing FEDSGD and FEDAVG. Being the ﬁrst of FL algorithms, FEDAVG was not particularly designed to address heterogeneity. (Li et al., 2018) then proposed FEDPROX, which modiﬁes the client objective function to include a proximal term that prevents them from drifting away to their local minima. FEDPROX was shown to provide more stable and accurate convergence than FEDAVG in heterogeneous settings. On similar lines, (Li et al., 2019) propose an optimization objective aimed at providing fairness called q-FFL. However, through their extensive experimentation based on real-world phone traces to simulate device and be- Table 4. Performance boost achieved by GEL in heterogeneous (low and high) budget setting. WOG refers to without guessing case. Figure 6. Performance of GEL for CelebA dataset across a spectrum of budgets and guessing percentages. GEL always outperforms baseline and meets Target in most cases between 25%125% for all three values of uwhile needing less total gradient computations than either of them (row-2). havioral heterogeneity, (Abdelmoniem et al., 2021) show that FEDPROX and q-FFL are not quite effective in practice. The authors also suggest that mitigating such heterogeneity may require adaptive system design over algorithmic innovations since the heterogeneity is induced by system aspects than algorithmic hyper-parameters. In line with this suggestion and in contrast to all previous approaches, GEL takes a computational view of the learning process focusing on system induced constraints. Different from the family of algorithms that modify objective functions, the SCAFFOLD algorithm (Karimireddy et al., 2020), uses the idea of control variates to achieve variance reduction of gradients from participating clients. Notably, SCAFFOLD was shown to converge under any adverse conditions of statistical heterogeneity but with the downside that it requires stateful clients – a constraint that is difﬁcult to meet in practice. With renewed interest in federated optimization (Wang et al., 2021) and relatively immature convergence theory, newer works to accelerate federated learning (Yuan & Ma, 2020; Pathak & Wainwright, 2020) focus on development of methods in convex settings. GEL is the ﬁrst of such algorithms to boost convergence in general non-convex settings and to empirically achieve good results. In the very ﬁrst of any hardware-based solutions to mitigate device heterogeneity, (Abdelmoniem & Canini, 2021) propose adapting quantization levels (bitwidths) used to represent models on client devices. Specifically, since models with lower quantization level run faster on the same hardware, the FL server makes a per-client decision of quantization level such that all clients return updates within time. However, such an approach requires proﬁling of clients with a complex server design to accurately predict quantization level. In contrast, GEL requires trivial modiﬁcation to FL server and no client proﬁling since it can determine number of guesses without knowing computational budgets of clients. In this work, we proposed GEL, our Guess and Learn algorithm to tackle slow convergence of challenging FL settings. The novelty of GEL lies in guessing model updates without computing gradients, thus speeding up convergence at no cost. Our empirical evaluations on a suite of ﬁve standard FL benchmarks demonstrate that GEL significantly boosts convergence in realistic heterogeneous budget settings with non-IID data. Notably, we showed that the characteristic low-budget settings of FL beneﬁt the most from GEL achieving speedups up to 1.64×. In the highbudget settings, GEL achieves modest boosts but saves tens of thousands of gradient computations. While GEL uses terminal guessing, i.e., guessing after exhausting budgets, interesting directions for future work include interleaving guessing with real computations, decayguessing across communication rounds or a combination of the two. A successful application of guessing in centralised machine learning settings, like data-center training, promises huge resource savings (computational, energy and ﬁnancial) presenting another interesting avenue.