Abstract—We propose a general framework (CEV Framework) for recommending and verifying technical solutions in central bank digital currency(CBDC) system, in which we build two subframeworks: an evaluation sub-framework that analyzes current problems about CBDC and provides solutions in terms of consensus algorithms and operating models, and a veriﬁcation sub-framework that proves the feasibility of recommended solutions. Our framework provides a workﬂow and can be used as a reference to design CBDC systems based on related national economic and regulatory conditions. The working procedure to generate customized solutions is to split consensus algorithms into different components and analyze their impact on CBDC systems. Furthermore, we propose two operating models to cover operational aspects. Then we build a veriﬁcation subframework to verify potential solutions through empirical experiments and formal logic proof. By iterating with our framework, CBDC designers can ﬁnd a balanced point in designing a CBDC system. To the best of our knowledge, we are the ﬁrst to propose a framework to recommend and verify CBDC related technical solutions. Index Terms—Central Bank Digital Currency, Evaluation Subframework, Consensus Algorithm, Operating Model, Veriﬁcation Sub-Framework The recent development in cryptography and distributed ledger technology (DLT) has seen a new form of currency known as Central Bank Digital Currency (CBDC) [1]. CBDC is a digital representation of legal currency regulated by nations’ monetary authority or central bank. There are many differences between jurisdictions in terms of national conditions and the focuses of regulators. So CBDC designers across different jurisdictions have varying approaches in designing a CBDC system. Based on previous research, we conclude several CBDC dimensions to measure a CBDC system and propose an evaluation sub-framework that provides holistic CBDC solutions covering these dimensions. Moreover, we build a veriﬁcation sub-framework to verify the feasibility and rationality of proposed solutions and see if they match initial expectations. Finally, we integrate both sub-frameworks into one framework, called CEV Framework. Consensus algorithms are vital components in a CBDC system. They directly impact many dimensions, including performance and privacy. Therefore, it is essential to evaluate consensus algorithms and undertake the related calibration properly. We analyze diverse consensus algorithms and build a theoretical framework, the evaluation subframework, that splits consensus algorithms into different components, such that the impacts of each of them on CBDC dimensions can be derived. We also propose two operating models to cover operational aspects in which business secrecy is one of the critical criteria for CBDC systems. Most CBDC pilots have shown a tiered architecture, bringing many potential problems, especially business secrecy issues. Current technical solutions to keep business secrecy, such as homomorphic encryption [39], could not satisfy non-functional requirements, especially performance. Therefore, we propose new operating architectures to cover these aspects in our evaluation subframework, like helping institutions retain their business secrecy. After proposing CBDC solutions, we then propose a veriﬁcation sub-framework to guide CBDC designers to verify proposed solutions. The sub-framework needs CBDC designers to build a mathematical model for its choice and verify if it can meet initial expectations on diverse CBDC dimensions, like performance, security, privacy. By leveraging this framework, they can judge whether proposed consensus algorithms and operating models are consistent with their preferable evaluation dimensions. In summary, our CEV framework includes an evaluation sub-framework to provide CBDC solutions and a veriﬁcation sub-framework to prove the feasibility of proposed solutions. Depending on different national economic and regulatory conditions, CBDC designers can create various consensus algorithms to address speciﬁc CBDC needs. The remainder of this paper is organized as follows. In Section II, we present the background of our research. Section III introduces our CBDC framework, including an evaluation sub-framework and a veriﬁcation sub-framework. We mainly discuss the evaluation sub-framework in Section III and the veriﬁcation sub-framework in Section IV. Section IV also gives an example of leveraging our framework to develop a solution and verify it. Finally, we conclude the paper in Section V. According to the research of the Bank for International Settlements (BIS) [4], more than 85% of central banks worldwide have already started research on CBDC. Since there are many differences regarding national economic and regulatory conditions between them, such as population and internet penetration, CBDC designers have diverse focuses to design their CBDC systems. For example, a country with a large population would pay more attention to the performance of its CBDC system. These different background conditions and the focus areas of regulators will lead to different CBDC designs. Based on previous research [4]–[16], [38], we conclude following dimensions to cover most of CBDC-related considerations for CBDC designers and regulators. Note that there may be different deﬁnitions of the following categories, so we use speciﬁc sub-categories to deﬁne them. 1) Performance: In a country, millions, even billions of customers, may use CBDC in future. Therefore, performance is an essential criterion to handle millions of requests. In current CBDC projects around the world, blockchain has shown many beneﬁts [27], [31]. In crossborder business, peer-to-peer payment could save liquidity and improve efﬁciency [33]. However, blockchain has been widely used in the wholesale CBDC rather than retail CBDC [40]. One key factor is that its weak scalability cannot meet the need for high performance in the CBDC system. Therefore, we conclude that we should consider the following features to measure performance. 1) User Scalability: the cost of adding a new customer to a CBDC system. 2) Network Scalability: the capability to handle larger transaction volumes per second(TPS), which is related to the time complexity of consensus algorithms. 3) Latency: the time to complete one transaction. 2) Security: Security in a distributed system involves various aspects, including cryptography, secure channels, key management, prevention of double-spending attacks, and so on [18]. Among them, the prevention of doublespending is one of the basic requirements in a CBDC system. Therefore, we would use double-spending prevention as an example in the veriﬁcation sub-framework. 3) Privacy: Privacy is related to the user’s identity and transaction information [32]. We divide it into two aspects, customer privacy and business secrecy. For customer privacy, it is related to the anonymity of transactions. For business secrecy, it is related to preventing data leakage to competitors, which is one of the essential design principles of CBDC. In BIS’s report [43], it presents a two-tier CBDC model. This model will work if participating institutions are not commercial competitors with each other. If not, tier-two institutions would be worried about data leakage to tier-one institutions and may even give up CBDC services to protect business secrecy. In the CBDC system, we deﬁne business secrecy as safeguarding data of tier-two institutions from tier-one institutions. 4) Others: Other dimensions do not conﬂict with these CBDC dimensions, or there are already mature solutions in these areas. Examples include resilience, governance [19], functionality, interoperability and ofﬂine payments. For example, resilience can be related to many problems [32], such as hardware issues, power or network outages, or cloud service interruption. We consider the following features for resilience. 1) Fault-tolerance: the capability of tolerating accidents in a CBDc system, such as single-point failure. 2) Availability: the time or percentage that a CBDC system will operate satisfactorily in an ideal environment. We believe these requirements can be met in the current ﬁnancial system, or they can be solved independently, so we do not discuss them in any detail. In future, there could be more dimensions involved in our CEV framework if needed. With blockchain development, new research topics appear one after another, especially in the performance part. The performance of blockchain, especially bitcoin [20], cannot meet today’s commercial needs. To solve this problem, many blockchain platforms spring up one after another [22]–[25]. Besides performance, other dimensions, like resilience, security and privacy, are also undergoing research. Consensus algorithms play a key role in many dimensions. Fabric [22] once used Practical Byzantine Fault Tolerance (PBFT) [21] which provides fault tolerance while sacriﬁcing part of performance. Corda blockchain protocol aims to satisfy ﬁnance and regulatory requirements [23]. Transactions in the Corda platform are recorded only by participants rather than the entire network, which provides high performance and protects privacy to some extent. To fully consider consensus algorithms, we use our evaluation sub-framework to analyze most of the current consensus algorithms. BIS’s paper [13] mentions a tiered CBDC model. Until now, a tiered CBDC model has been selected in most CBDC projects, including China’s E-CNY [30], Sweden’s E-Krona [?], [41], [42]. There are several strong reasons to follow a tiered model in CBDC designs. Firstly, a tiered model can maintain the system stability of the current banking system. After many years of operation, the tiered model shows ﬁnancial stability and has advantages in functionality and facilities. Furthermore, a tiered model can accelerate market competition and improve banking and payment services. The CEV framework includes two sub-frameworks: an evaluation sub-framework that provides consensus algorithms and operating models and a veriﬁcation subframework that proves the feasibility and rationality of recommended solutions. We will discuss the evaluation subframework in detail in this section. Figure 1 shows the working procedures of the CEV framework. First, CBDC designers can determine preferable CBDC dimensions based on their economic and regulatory conditions. Then they can determine consensus algorithms and operating models according to the evaluation subframework. After that, CBDC designers can build a theoretical model for their choices and carry out experiments and proofs to verify original CBDC dimensions. Finally, if they are not satisﬁed with the veriﬁed result, they can go back to adjust their expectations on CBDC dimensions, leverage the evaluation sub-framework to update their solutions, and verify proposed solutions again. We mainly discuss the evaluation sub-framework in Section III. The evaluation sub-framework includes two parts: consensus algorithm part which splits consensus algorithms into different components and analyses their impacts on CBDC systems, operating model part which provides two options to overcome business secrecy issues. 1) Consensus algorithm: Consensus algorithms play a signiﬁcant role in CBDC systems. It has direct impacts on many dimensions mentioned in Section II. We split them into different components to better analyze consensus algorithms and their impacts on CBDC systems. Then we can estimate the impacts of individuals. By combining different components into one algorithm and analyzing its effect on CBDC dimensions, we can better propose CBDCrelated consensus algorithms to adapt national economic and regulatory conditions. ﬁgure 2 introduces components of consensus algorithms. In a CBDC consensus network, a client will send a request to the system, and the system will process it until reaching an agreement inside the network. The following steps describe details about this process: 1) Leader Election / Proposer: a network requires one representative to lead the bookkeeping process before a client sends a transaction request. a) Voting: a leader is elected via a voting mechanism. There are many extensive options for the voting mechanism, such as deﬁning the percentage of votes needed to become a leader. RAFT [26] adopts a voting mechanism with election timeout to determine the network’s leader. b) Predetermination: a leader is predetermined in this network. For example, leaders would be the notary node in Corda blockchain platform [23], which is determined before network deployment. c) Round-robin: a leader is chosen by an arrangement in a group equally in some rational order. PBFT [21] uses this approach to choose the primary (leader). d) Proposer: There could be no leader in the network. For example, in some public blockchain systems, a proposer collects transactions from users and proposes them to the network via Proof of Work [20], Proof of Stake [35], etc. 2) Client - Request: a client would submit its payment request to the network in a transaction. a) To one: a client sends the request to one node. A node is a connection point in a communication network. In some algorithms, like RAFT, if no response from the leader is received, the client sends the request to another node in the network. We classify this situation as the "To one" option. Furthermore, we consider node sharding [28], [29] to improve system performance. Sharding means multiple nodes process transactions in parallel and interact with each other in a speciﬁc manner. This may improve the system’s capability to handle high concurrent transactions. b) To all: a client sends the request to all nodes in the network to ensure the request is accepted in time. 3) Leader / Proposer - Pre-prepare: the leader node or proposer would process the request locally after receiving it. a) Proof of X: if "proposer" is chosen in the ﬁrst step, the proposer would leverage one of Proof of X, such as Proof of Work [20], to publish transactions. b) Veriﬁcation: A leader would verify proposed transactions and send them to other nodes. c) Inter-communication & Veriﬁcation: a leader would ﬁrst communicate with other nodes and ﬁlter transactions into the next phase. Filtration can potentially reduce the number of illegal transactions in the early phase, which can help increase the system’s security. 4) Fixed / Dynamic Validators: validators are other nodes than the leader node. In this step, some consensus algorithms require all nodes to carry out some operations while others just need selected or random dynamic nodes. For example, traditional RAFT [26] and PBFT [21] need all nodes to participate data backup, while IBFT [34] adopts a dynamic set of validators to deal with transactions. A dynamic set of validators can provide a higher performance due to a more ﬂexible number of participants. In contrast, a ﬁxed set of validators would be easier to implement and more secure. 5) Validators - Prepare: validators can vote and communicate with others to verify the request from the leader node. a) Voting: validators would vote for the request. b) Inter-communication & Voting: validators would vote for the request after inter-communication between each other. PBFT [21] adopts intercommunication between nodes to prevent malicious behaviors. c) No action: No action is taken in this step. For example, validators (called followers) in RAFT [26] would not vote or communicate. 6) Validators - Commit: commit means how validators record transactions in their database. They could directly undertake data backup, like RAFT [26], or communicate with other nodes, like PBFT [21] and then determine whether to record the proposed request. a) Data backup: validators would make a backup in its local database without other operations. b) Inter-communication & Data backup: validators would communicate with each other before backup. 7) Leader / Proposer - Decision Mechanism: decision mechanism describes the conditions of a success notice sent to the client that the transaction has ﬁnalized. a) x% backup replies: the transaction would be ﬁnalized if the leader node receives more than x% backup replies. For example, in RAFT [26], the leader node needs to receive 50% replies before responding to its client. b) x% vote replies: the transaction would be ﬁnalized if the leader node receives more than x% vote replies. If there is no action in the "commit" step, there could be possible that the validator node only collects votes. c) Self-decision: a leader node decides the transaction by itself. For example, the notary node in Corda [23] veriﬁes proposed transactions by itself. 8) Encryption: encryption can be applied in every step to secure transmitted information. It is independent of previous options. In most algorithms, consensus algorithms are more related to achieving consistency in a network and do not cover encryption. However, our consideration of consensus algorithms is more relevant to CBDC, where encryption plays an important role, so we include encryption in this part. Note that each component has many possibilities and extensions. Our evaluation framework would be more like a guide to CBDC designers to consider related factors. Besides, there are also some constraints between different components. For example, based on our knowledge, choosing "proof of X" in the third step must choose "proposer" in the ﬁrst step. Therefore, we need to verify to ensure that proposed consensus algorithms are valid, which will be done in the veriﬁcation sub-framework. We have referenced PBFT and RAFT several times. Here we describe two consensus algorithms by our Consensus Process Map. RAFT [26] (ﬁgure 3) starts from voting and election timeout mechanism in the leader election. Then a client sends a request to the leader in the network. After the leader’s Veriﬁcation, validators would make a backup and respond to the leader node. After receiving more than half of the notices, this transaction would be regarded as valid. PBFT [21] (ﬁgure 4) selects a leader in a roundrobin manner. Suppose a client sends a request to all nodes in the network, the leader node would undertake simple Veriﬁcation and publish the request. Then validators would communicate to ensure more than 67% of nodes pass Veriﬁcation. Then a new round of communication between them would ensure more than 67% of them undertake a data backup. Finally, the client waits for 33% replies from validators to ensure no malicious behaviours. Due to diverse national economic and regulatory conditions, CBDC designers have different requirements for their CBDC systems. Therefore, to make the CEV framework widely applicable, we further analyze connections between consensus algorithm components and CBDC dimensions. We now conclude a table according to our experience on industrial CBDC research and work. Table I shows the impact of the above components on mentioned dimensions. We measure the impact through categories of High, Medium and Low. High means the module is helpful to the dimension. Medium means the module has no impact or relative medium impact on the dimension. Low means the module has a relatively bad inﬂuence on the dimension. TBA indicates that the impact needs to be further analyzed. For example, the "To one" option can provide higher user scalability and network scalability due to the sharding method. CBDC designers can better choose consensus components according to their national requirements by this table. This table needs further reﬁnement in the future via the CEV framework workﬂow. Our objective, for now, is to build a framework for future research. Based on this framework, CBDC designers could choose different components individually according to their focus areas and analyze different combinations until they ﬁnd a suitable consensus algorithm. 2) Operating Model: We propose several operating models to cover operational aspects, especially business secrecy, that can not currently be solved from a technical standpoint alone. According to the BIS’s paper [43], a two-tier CBDC model is proposed where tier-one institutions are directly connected to the central bank (tier-one), and the tier-two part includes household and business. If tier-two institutions and tier-one institutions are not competitors, this model can mitigate business secrecy-related concerns. For example, if all tier-one institutions are banks, other banks in tier-two would be worried that tier-one banks monopolize their customer data. However, it is nearly impossible in a tiered model to let all commercial institutions become tier-one ones and responsible for CBDC distribution and circulation because of a potential single point (central bank) failure and performance bottleneck. Distribution means that an institution connected to the central bank helps issue CBDC and manages CBDC authentication work. Tier-one institutions take the responsibility of distribution in a two-tier CBDC model. Circulation means that an institution provides CBDCrelated transfer services. General commercial institutions can carry out circulation in order to improve service coverage. However, if tier-two institutions provide CBDC services, they have to connect to tier-one institutions and ask them to provide authentication services. Tier-two institutions are mostly competitors with tier-one institutions, and they are reluctant to provide transaction and customer information to their competitors, making two-tier architecture hard to implement in a CBDC system. Overall, we found that two problems in the current twotier CBDC model: 1) It is not possible that every institution is a tier-one institution. 2) If tier-two institutions want to provide CBDC related services to their customers, they would have to connect to tier-one institutions. However, they are commercial competitors in most cases, and tier-two institutions would be worried about customer data leakage. A three-tier CBDC model (ﬁgure 5) can better describe these two problems in which commercial institutions would be divided into two tiers. We regard higher-tier institutions as privileged institutions and lower-tier institutions as nonprivileged ones. The tier-one institutions in the two-tier model are privileged in the three-tier model. The threetier model describes how non-privileged institutions provide CBDC services to their customers. Due to privileged institutions operating the ledgers, non-privileged institutions must provide transaction information to privileged ones for bookkeeping, which means transactions from nonprivileged institutions’ customers are regarded as valid only when recorded in privileged institutions’ ledgers. Nonprivileged institutions are particularly reluctant to provide their customer data to privileged ones because they are competitors with interest conﬂict. Therefore, their customer data should not be shared with their competitors (privileged institutions). For commercial institutions, they can give up providing CBDC-related services or become non-privileged institutions and connect to privileged ones in which they are worried about business secrecy issues. To safeguard non-privileged institutions from data monopoly, we propose several operating models: 1) Use dynamic virtual addresses to keep the identities of participants secret from privileged institutions; 2) Set up an independent operating organization that has no conﬂict of interest; For option one (ﬁgure 6), non-privileged institutions would create virtual addresses for their customers in the ledger of privileged ones who would not know identity information. Note that privacy includes identity and transaction information. Virtual addresses ensure that privileged institutions do not know the payee and payer of each transaction. In this model, non-privileged institutions would provide a mapping table between virtual addresses and real identities to regulators. Only regulators and non-privileged institutions can know the mapping relation of virtual addresses to real identities. One beneﬁt of this option is that non-privileged institutions only need to inform the central bank of the identity mapping relationship, then the central bank could get all transaction information by combining identity mapping and ledger transaction information. However, privileged institutions can infer virtual addresses by analyzing token ﬂow even though they only know transaction information. To further protect the business secrecy of non-privileged institutions, we can make virtual addresses dynamic, which means new virtual addresses are created to collect changes in transactions. This technical solution can prevent privileged institutions from further accessing non-privileged institutions’ critical customer data. For option two (ﬁgure 7), the operating organization could be operated by a third-party institution to ensure no competition with other tier-one and tier-two. In this model, an operating organization could know the transaction data of other operating institutions without business secrecy issues. However, the business model of operating organizations needs to be further created to ensure its stable operation. For example, all participating institutions could invest and organize the operating organizations, protecting their interests and supporting rational CBDC operation. Both options can be applied in a CBDC system to ensure business secrecy and a fair market. CBDC designers can choose either of them based on their preference. By the evaluation sub-framework, CBDC designers can develop a customized solution. Then the veriﬁcation subframework works to ensure the proposed solution’s feasibility and rationality. Figure 8 shows how CBDC designers can verify proposed solutions. The procedures to apply veriﬁcation sub-framework: 1) Build a model based on proposed solutions, including state machine, ledger, transaction. A theoretical model is essential for further Veriﬁcation. The consensus algorithm and operating model have been developed in the evaluation sub-framework, so we need to further build related state machines and ledger to describe the proposed solution. 2) Translate this model into mathematical languages, including notations, deﬁnitions. Math is a perfect tool to provide further rational Veriﬁcation. 3) Empirical experiments are used to verify dimensions that need a real test, like performance. 4) Formal proofs are used to prove the rationality of proposed solutions, like preventing double-spending. We would follow the rules built in previous steps and prove related theories with formal logic proof. Next, we will use the veriﬁcation sub-framework to analyze potential solutions proposed from the evaluation framework and build related models for Veriﬁcation. The choice of operating models would inﬂuence the design of consensus algorithms. So we ﬁrst discuss the overall operating architecture. Figure 9 shows potential consensus networks in our proposed operating model (option one). We would follow this model to verify CBDC dimensions. There are wholesale consensus networks and retail consensus networks in the ﬁgure. The wholesale consensus network involves central banks and privileged institutions responsible for transactions involving different privileged institutions. For this kind of transaction, there would be interactions between the wholesale consensus network and retail consensus networks. On the other hand, retail consensus networks involve retail clients and service providers. Transactions between clients in the same privileged institutions would be ﬁnished inside retail consensus networks. In the wholesale consensus network, there could be many possible implementations. For example, if the central bank does not want to record retail transactions, it can control the wholesale balance of issued CBDC to different privileged institutions. The central bank is only responsible for issuance and redemption transactions by this method. If any issue exists in retail transfer transactions, corresponding privileged institutions should be accountable. On the other side, if the central bank wants to regulate every retail transaction, privileged institutions can provide detailed transaction information asynchronously in this model. Asynchronously means transactions do not need the central bank to participant in the process of consensus in real-time, and this transaction information can be provided to the central bank after transactions are ﬁnished. On the other hand, there could be different consensus algorithms in retail consensus networks. Consensus algorithms in the retail consensus network one and two work to protect retail users at different levels. For example, privileged institutions can involve other corporations to form a blockchain network to ensure each transaction recorded in the ledger is veriﬁed by each participant in the network. However, this method would inﬂuence performance a lot. Alternatively, privileged institutions can determine every transaction by themselves, ensuring high performance, but it may bring potential security issues. Therefore, the implemented consensus algorithms in different consensus networks could be different. Next, we provide an example by leveraging the framework. Assume a country with a large population and well-developed technology and communication. The CBDC designers focus on privacy and performance, especially network scalability, latency, business secrecy. Assume they choose operating model option one and build consensus algorithms based on it. There would be different consensus algorithms in operating model option one in different consensus networks. For wholesale consensus network, we propose a new consensus algorithm in ﬁgure 10. For retail consensus networks one and two, we propose a new consensus algorithm in ﬁgure 11. The recommended consensus algorithm in wholesale consensus network (consensus algorithm one) works as following procedures: 1) Leader nodes are predetermined in the algorithm that the central bank would run. 2) Clients send cross-shard transactions (deﬁned later) to its sharded leader node, which would resend it to the leader node (central bank) in the wholesale network. 3) The leader node would verify the transaction and ﬁnish the related issuance and redemption transactions for different sub-networks. The recommended consensus algorithm in retail consensus networks (consensus algorithm two) works as following procedures: 1) Leader nodes are predetermined in this algorithm that privileged institutions run. 2) Clients send transactions to its sharded leader node. 3) The leader node encrypts transactions before sending to validators in the network (possible competitors). 4) Dynamic set of validators would be chosen to make an encrypted data backup. 5) The Leader node would send a success notice to the client after receiving 50 per cent of notices from dynamic validators. Finally, we would leverage the veriﬁcation sub-framework to show how we can verify the proposed solution’s performance, security, and privacy. We build a theoretical model to describe the proposed solution above, including state machine, ledger and transaction types in a token-based CBDC system. Furthermore, we use ’regulated cryptocurrency’ to replace ’CBDC’ in some parts because regulated cryptocurrency includes CBDC and stablecoin, which means the CEV framework can also be used to design a stablecoin system. Different components in the consensus process map can be used ﬂexibly. For example, recommended consensus algorithm two in ﬁgure 11 chooses "To one / Sharding" in the "client-request" step. This choice brings many possibilities to system design and implementation. There are two types of transactions in the CBDC system: cross-shard transaction, which describes a transaction with two ledgers involved, single-shard transaction, which describes a transaction within one ledger. Figure 12 shows a cross-shard transaction on the left side. We discussed threetier operating models in Section III, in which privileged institutions can also directly provide services to end-users. Therefore, we only show two-tier in this ﬁgure. In a CBDC system, cross-shard transactions would inﬂuence the system’s performance compared to single-shard transactions because cross-shard transaction needs the currency issuer (Central Bank) to redeem a token in one ledger and issue a new token in another ledger. Moreover, with the increasing number of operating institutions, it would be frequent that cross-shard transactions happen in an account-based sharding system. Sharding is a method used to improve performance. The account-based sharding method divides users by accounts. Traditionally, privileged institutions have different wallets and divide users by their accounts. Speciﬁcally, PI (privileged institution) A’s customers will come to PI A when using CBDC because it created its account from PI A. If the customer transfers its money to PI B’s customers, a crossshard transaction happens. On the contrary, we may divide users by tokens. If PI A issues a token to one retail customer, the customer will come to PI to initiate CBDC related services because of the token he used rather than its account. Figure 13 shows token data structure, in which a string of the operator could be used to determine its service provider. In a tokenbased sharding, users must contact their token service provider. Therefore, users can transfer the token to everyone without a cross-shard transaction. However, token-based sharding needs the central bank with operating institutions to provide a uniform interface to distribute transactions based on tokens. Because if a customer use PI A’s token, he needs to come to PI A to transfer the token. If he comes to PI B’s interface, he should be distributed to PI A based on the uniform interface. Another important thing is that the central bank should provide uniform wallet standards to privileged institutions. For example, if the transaction receiver is not PI A’s customer before, there should be a wallet address to record the token from it. In this case, if PI B provides KYC and onboarding services to its customers, it does not expect to see data leakage of its customers to PI A. So virtual addresses could help design wallet addresses. Figure 13 shows that a virtual address for its holder or wallet. Note that tokenbased sharding is only a new direction to explore. It may be not an excellent solution to solve all related pain points. Overall, we try to leverage a token-based sharding system to reduce the number of cross-shard transactions and verify related features. Besides, in consensus algorithm two, encryption in the third step is used to protect business secrecy from validators, including non-privileged institutions. Therefore, validators in the algorithm would only make a backup of encrypted data, which will be used for tampering with proof. Next, we build a theoretical model for the recommended algorithm and operating model. Figure 14 shows ledger state machine. The central bank and privileged institutions would operate the state machine together. This model provides a formal description of ﬁnite state machine M = (S, V, t). The state machine can describe any state s ∈ S for every moment. It can read input token τ ∈ V and proceed to the next state by different transitions t(s, τ). There are two types of transactions. Single-shard transactions will only need consensus in the retail consensus network, while cross-shard transactions need the central bank participant. Leaders are privileged institutions in the retail consensus network. The central bank is the leader node in the wholesale consensus network. Assuming an initial machine state s, a token-based sharding system would distribute transactions to different leaders. The central bank institutions could provide a uniform system interface to the public to handle transactions and process them based on token-based sharding. In a single-shard transaction, the shard leader checks transaction signatures and input tokens τ. After verifying the signature, the tokens become locked. If involved tokens have not previously been locked, the output becomes τand the machine moves to the locked state s. Otherwise, it will exit ( a rolled-back transaction to the initial state). Next, the leader veriﬁes τavailable in its ledger. If τ are available, the output token will be τ, and the machine moves to the veriﬁed state s. Otherwise, it will exit. Finally, the leader writes the transaction with inputs and outputs. If successful, the output will be τ, and the machine moves into the state s. Otherwise, it will exit. These steps ensure the token is recorded on the ledger before noticing clients. Note that we do not cover validators’ operations here, like data backup. We will discuss it in Section C. Figure 15 shows data model of leaders’ ledgers. Transaction records are subject to the leader’s ledger. Once a leader updates its ledger, the transaction becomes legal and immutable. If traders want to revert the transaction, they must initiate a new transaction to return the token. Deﬁnition 1. (Ledger State) The ledger state of the regulated cryptocurrency is deﬁned as a directed graph D=<V(D), E(D), ϕ> that the elements of V(D) are vertices (tokens) and the elements of E(D) are edges (token ﬂow) in the model. ϕ is ordered mapping from token set V to token ﬂow set E. Deﬁnition 2. (UTXO) U T XO = {τ|τ ∈ V (D) ∧ d(τ) = 0}. UTXO is an unspent transaction token set. In the model, an unspent token means there is no edge coming from it (the out-degree of it is 0). Deﬁnition 3. (Transaction Graph) A transaction graph is a directed graph TD=<V(TD), E(TD), ϕ>. In a transaction graph, the in-degree of an input token is 0 and the outdegree of an output token is 0. Leader’s ledger will be updated when a transaction is ﬁnished by the state machine (∀x. ∀ τ.(Tx(τ,x) ⇒ D = D + TD)). Figure 16 shows all types of transaction graph. The Initial Issuance Transaction can only be initiated by the currency issuer (Central Bank), who can generate a new token from the genesis point. The Final Redemption Transaction has to be checked by the central bank (transaction receiver). Besides, our model needs the central bank to carry out realtime Initial Issuance Transactions and Final Redemption Transactions. Other types of transactions can be regulated in a deferred manner for central banks, which reduces the central bank’s performance stress. A valid transaction in in ﬁgure 16 would produce new tokens. We can use the following mathematical expressions to show token ﬂow. Here we add an assumption that the leader nodes are non-faulty (H) and would follow the model procedures. Faulty nodes may behave arbitrarily and be vulnerable to inside and outside attacks. With non-faulty nodes, we can ensure tokens are recorded in the ledger by every transaction: 1) ∀τ.(H∧p(τ) ⇒ p(r (τ))∧p(c(τ))) 2) ∀τ.(H∧p(τ) ⇒ p(f (τ))) The state machine ensures that every transaction is valid. ∀τ.(H∧p(τ) ⇒ p(r (τ)) means that if input τ has been recorded in the ledger, a valid transaction graph using τ as inputs and received token r (τ) and change token c(τ) as outputs will be added to the ledger by a non-faulty leader(H). If the change is 0, then c(τ) = null and p(c(τ)) means no token recorded. Note that the expressions above show the token ﬂow rather than the transaction. ∀τ.(H∧p(τ) ⇒ p(f (τ))) means non-faulty leaders(H) would ensure that output tokens in a cross-shard transaction would be recorded in another shard’s ledger. Crossshard transactions would not happen in our model if we split one transaction into several concurrent subtransactions. However, cross-shard transactions would match some business scenarios more. For example, CBDC users may pay tokens in different ledgers and achieve an atomic transaction. Alternatively, CBDC designers want to control the number of tokens and consolidate tokens from different ledgers to one new token. Figure 17 shows a client has different tokens allocated in three different shards and uses them to initiate a transaction. The transaction ﬁrst turns the input tokens to the endpoint via the Final Redemption Transaction and issues new tokens in the new shard via the Initial Issuance Transaction. In a CBDC system, the central bank is responsible for issuing and redeeming tokens, regulating both transactions and ensuring that output tokens are recorded in the new shard. For performance veriﬁcation, we need to test its user scalability, network scalability and latency. These dimensions can be tested by empirical experiments, like a stress test. To ensure experiments are valid, we could choose speciﬁc scenarios and operations which should be as close to reality as possible. In our experiments, we initiate random transactions by random users, and we also consider different payment methods, like face-to-face transfer, collecting, etc. In the recommended algorithm (ﬁgure 11), we use sharding in the retail consensus networks to improve network scalability and user scalability. Commercial institutions, including privileged and non-privileged ones, could take the role of leader nodes or validator nodes in the retail consensus networks and undertake customer due diligence. To improve performance, CBDC designers could leverage sharding to increase their capability of handling transactions. Sharding provides horizontal scalability to a CBDC network. However, traditional account-based sharding may bring extra cross-shard transactions due to interactions between multiple operating institutions. Therefore, we use token-based sharding to reduce the number of cross-shard transactions. We leverage AWS EC2 and Corda node to carry out a series of experiments. In our experiments, privileged institutions would take the role of leader nodes when processing their single-shard transactions. The result in ﬁgure 18 shows a linearly increasing TPS, which presents excellent user scalability and network scalability. Furthermore, sharding has little impact on latency shown on the right side in the ﬁgure. Unfortunately, since the Corda open-source version has limitations on performance, we could not demonstrate an extremely large TPS in the experiment due to cost control. However, by our experiment, we can see that our method improves the performance of a CBDC system a lot. If CBDC is a non-fungible token, Token-based sharding can map every non-fungible token to one leader node since the token’s creation. Then tokens can be circulated in different ledgers in parallel, increasing the performance and achieving efﬁcient token circulation. However, CBDC is more like a fungible token. Due to changes produced by transactions, the account user might use several tokens in a transaction which causes additional concurrent volume. Moreover, if a CBDC user wants to use two tokens circulating in different ledgers simultaneously, the cross-shard transaction may happen to ensure no double-spending. In our recommended consensus algorithms, sharding improves performance by parallel running ledgers. This is because cross-shard transactions are relatively less frequent in the token-based sharding method than the accountbased one. However, if we consider the performance in the wholesale consensus network, say that each transaction in the retail consensus network needs Veriﬁcation from all parties in the wholesale networks, more shards may cause worse performance. Overall, we prove that the proposed algorithms can increase the system’s TPS while not sacriﬁcing latency. There are many other kinds of performance tests, in which we use two of them as an example. We provide two options as operating models to protect business secrecy. For option two, we designate one operating organization to distribute CBDC because it is not a competitor with other operating institutions such that they would not be worried about their data being monopolized. For option one, we use dynamic virtual addresses to prevent privileged institutions from knowing customer data of non-privileged ones. The method is similar to the bitcoin schema. In the bitcoin [20] system, there are some essential facts: 1) new addresses are used to collect change in transactions, 2) users could have many addresses. Bitcoin uses this method to protect customer privacy from data leakage to the public, while our model protects non-privileged institutions’ data from privileged institutions. However, in the current model, similar to the bitcoin schema, privileged institutions can still obtain secret information, depending on different transaction types. Besides SISO transactions, SIDO, MIDO, MISO transactions may expose relationships between inputs and outputs. For example, ﬁgure 19 shows a SIDO transaction, in which one of the addresses in vand vwould be the address for the change. The relationship between payees and payers could be inferred when collecting enough extra data, like goods, transaction places. However, in a SISO transaction, the payee and payer are not the same people in most of the cases. If we only have SISO transactions in the network, privileged institutions would not know the relationship between payees and payers. However, in a MISO transaction, tokens coming from different virtual addresses are usually paid from one same client. Similarly, in a SIDO transaction, one of the output tokens should be the change token back to the payer. Moreover, in a MIDO transaction, payers would be the same person in most cases. Therefore, we conclude that only SISO transactions can protect privacy. This problem is not solved in the bitcoin system, which has been proved that bitcoin can not protect user privacy completely [37]. Nevertheless, in our CBDC operating model, transaction data would be processed by nonprivileged institutions before they are sent to privileged institutions. Non-privileged institutions can add virtual entities with virtual addresses to the network and use these virtual entities to create SISO transactions for customers. For example, in a SIDO transaction, non-privileged institutions can use virtual entities as the receiver to avoid the connection between payer and payee and then send it to the actual receiver via a SISO transaction. This can also be applied in other transactions. With enough virtual entities by operators, non-privileged institutions can hide the direct relationship between the inputs and outputs. Here we discuss double-spending as a security example, where we try to prove no double-spending in singleshard and cross-shard transactions separately. Note that the premises below come from lemmas or deﬁnitions in the model. Lemma 1. When a non-issuance transaction is ﬁnished, the out-degrees of the input tokens in the ledger state become non-zero. ∀x.∀τ.(T x(τ, x) ⇒ ∀y.(xR y ⇒ d(τ, y)! = 0). Proof. For a non-issuance transaction in deﬁnition 3, the out-degrees of input tokens become non-zero after the transaction is ﬁnished. Since (∀x. ∀ τ.(Tx(τ,x) ⇒ D = D + TD)), a new transaction graph is added into the ledger where the out-degrees of input tokens would not change. Lemma 2. ∀x. ∀ τ.(Tx(τ,x) ⇒ ∀y.(xRy ⇒ H(τ, y))) Proof. According to lemma 1, we get ∀x. ∀ τ.(Tx(τ,x) ⇒ ∀y.(xRy ⇒ d(τ, y)! = 0). The temporal logic proofs of Lemma 3, 4, 5 and 6 are shown in appendix A. The logic proofs (temporal logic [36]) have been checked by a proof-editor from Stanford University [44]. Lemma 3. ∀x.∀ τ.(Tx(τ,x)) ⇒ ∀ z.(zRx ⇒ F(τ, z))) Lemma 4. ∀x.∀ τ.(F(τ,x) ⇔ ¬H(τ,x)) Lemma 5. A recorded token can not be spent twice in different transactions in the network. Lemma 6. If leaders are non-faulty(H), there is no doublespending in single-shard transactions. Lemma 7. If leaders are non-faulty(H), there is no doublespending in cross-shard transactions. Proof. According to the model, a non-faulty leader with the central bank ensures a cross-shard token is recorded in the ledger. According to lemma 5, we prove a recorded token without double-spending problems. Since the tokens are recorded in the ledger, there can be no double spending in a cross-shard transaction. To be mentioned, there are different operating architectures mentioned in BIS’s report [43], in which the central bank can record wholesale balance or retail balance. If the currency issuer (Central Bank) secures the Initial Issuance Transaction and the Final Redemption Transaction, there would be no double-spending in cross-shard transactions, no matter central bank records wholesale balance or retail records. However, recording balance can help the central bank in many other ways, like controlling the volume of circulating CBDC in different ledgers. Lemma 8. If leaders are non-faulty(H), there is no doublespending in all transactions. Proof. There are two kinds of transactions in the network: transactions in one shard and transactions between two shards. Lemma 6 and 7 prove no double-spending with non-faulty leaders in these two kinds of transactions. Therefore, we conclude no double-spending problem in the network if leaders are non-faulty. We have shown that with a non-faulty leader, we can prevent double-spending. However, the assumption is the weakest point in our system. We can believe that the central bank would not perform malicious behaviour. Then in a cross-shard transaction, the central bank can ensure no fault in the wholesale consensus network. However, in the retail consensus network, privileged institutions are responsible for their ledger and decide each transaction on its own without validation. There is no mechanism to ensure them non-fault. As a result, double-spending may happen in single-shard transactions. We leverage mathematical tools to ﬁnd the weakest point in the system. Math would be a perfect tool for describing a complex system and ﬁnding problems inside it. We sacriﬁce part of security to increase performance in this example. As we discussed before, the design of CBDC is a trade-off between different dimensions, including performance, security and privacy. For example, leveraging a single institution responsible for all transactions could ensure high performance but bring security issues. Although we can not avoid double-spending in real-time in our recommended consensus algorithm, we can increase the cost of malicious behaviours. The recommended consensus algorithm in the retail consensus network leverages data-backup from validators to ensure that the leader node would be non-faulty. A leader would send encrypted transactions to validators in the network after Veriﬁcation. By encryption, customer data would not be shared with validators. Encryption also ensures business secrecy in the CBDC system. Validators would undertake data backup. Once the leader node changes the original Data, encrypted data from validators can be used to check data consistency. This can help mitigate malicious behaviours from the leader node. If the leader node performs malicious behaviour, they would be punished. Moreover, since the central bank controls issuance and redemption transactions, it will know the balance of money on each ledger so that no extra money would come from retail networks. By data backup, all transactions become immutable in real-time. By checking data consistency, malicious behaviours would be found. On the other side, we can ensure latency is not being overly inﬂuenced because validators in the network would be randomly selected so that not all validators in the network need to join the process of a transaction. Therefore, leader nodes in our model are motivated to be non-faulty. If validators are competitors, these data should be encrypted to ensure business secrecy. In other cases, validators could be run by third-party auditors. In this scenario, it is not necessary to encrypt the data. Besides, we use 50 per cent as the threshold to make encrypted data backup. Since most validators could be competitors or auditors of the leader node, they should be motivated to keep the encrypted data recorded. To avoid the leader node from being set up by its competitors, there should be at least two validators in this process. If CBDC designers want a real-time check for fault, we can add auditors in the consensus process and let them vote for each transaction. Then there would be no doublespending even though the leader node is faulty. Figure 20 shows how we can iterate in this example. CBDC design involves many trade-offs between different dimensions. In our example, we start from a country with a large population, focusing on performance and privacy. Then we use the evaluation sub-framework to propose solutions. Finally, we come back to the original dimensions in our veriﬁcation framework, like performance, privacy, and security. We try to verify these dimensions in diverse ways. As shown above, the proposed solution presents an excellent performance and privacy, but when we try to prove there is no double-spending, we ﬁnd that it is possible. Our veriﬁcation sub-framework can ﬁnd the weakest link in the model. We only discuss three dimensions in this example. If CBDC designers have other speciﬁc focuses, this framework could have more dimensions. After Veriﬁcation, if CBDC designers want to improve system security, they can come back to CBDC dimensions to determine what they expect again. If they need a more secure system, they could continually use the evaluation sub-framework to propose new solutions and use the veriﬁcation framework to verify diverse dimensions. In our example, the CBDC designer can leverage the evaluation subframework to choose another component in the consensus process and form a Byzantine fault-tolerant algorithm. The newly proposed solution can involve more participants to vote for single-shard transactions, which is helpful to ensure no fault in the retail consensus networks. However, it may potentially inﬂuence the system’s performance. Afterwards, the CBDC designer can return to CBDC dimensions again to adjust its expectations on different dimensions until ﬁnding a balance point. Our framework presents potential trade-offs in CBDC designs and helps CBDC designers see what they expect with iterations. Finally, after many times of iterations, there would be a balance point for the CBDC designers. Our paper proposes a CBDC framework (CEV Framework), including an evaluation sub-framework and a veriﬁcation sub-framework to design central bank digital currency. This work is of signiﬁcant importance to the evolution of CBDC and proposes an original approach. We provide a holistic solution for CBDC designers who can have a method to analyze potential solutions according to the economic and regulatory conditions of their jurisdictions. To the best of our knowledge, we are the ﬁrst to propose a framework to analyze CBDC related technical solutions by splitting consensus algorithms into different components and proposing operating models to solve CBDC related issues. Most importantly, we build a veriﬁcation sub-framework to prove the feasibility of the recommended algorithms and operating models with rigorous and professional mathematical proofs. Besides, our framework would not bring any new issues. Our framework could be continuously updated and improved by iterating with the workﬂow. In addition, there are diverse central bank digital currency projects worldwide. These projects can leverage our framework to design the consensus algorithms better and adopt reasonable operating models. To handle the future need for regulated cryptocurrency design, our framework needs further reﬁnement in practice. We have listed all considerations in CBDC in the CEV framework. The main future work is to include more dimensions and solutions into the framework and simplify the process of using this framework. The authors gratefully acknowledge the help of Bo Tong Xu on fruitful discussions on some aspects of the present work. This paper is partially based on our work in Global CBDC Challenge [3], in which we were shortlisted into ﬁnalists. Based on our framework in this paper, we built an evaluation and recommendation platform, which advocates consensus algorithms for different CBDC designers based on national economic and regulatory conditions. The authors wish to acknowledge the other two teammates, Mark Liu and Bing Qu. This paper is reviewed by Dr Philip Installura. The authors wish to express great appreciation for his valuable input. Here are temporal logic proofs. Please see notations in section III. A. Lemma 3 Proof. A token τ keeps unspent status when it has not been used in any transaction. For any τ ∈ V, F (τ, y) ⇔ (τ ∈ UTXO at time y) ⇔ d(τ, y) = 0. From our deﬁnition in transaction, we get ∀x. ∀ τ.(Tx(τ,x) ⇒ ∀y.(yRx ⇒ d(τ, y) = 0). B. Lemma 4 Proof. ¬H(τ,x) means τ has not been spent before x. Therefore, F(τ,x) ⇔ d(τ, x)! = 0 ⇔ ¬H(τ, x). C. Lemma 5 ∀x.∀y.(T x(τ, x) ∧ T x(τ, y) ∧ xR y ⇒ τ6= τ) Proof. Time is continuous that given any two timestamps, there is one timestamp between them. we assume a double spending transaction possible as one premise to ﬁnd a contradiction. With proof by contradiction, we get that a recorded token in the validator’s ledger can not be spent twice in different transactions. D. Lemma 6 Assume a leader is non-faulty(H), there is no doublespending in its shard. Proof. In a token chain, tokens (a) with in-degree 0 are created and issued by an issuer. For a valid payment transaction, a non-faulty leader would ensure the received token and change token is recorded, after which the transaction will be announced as valid.