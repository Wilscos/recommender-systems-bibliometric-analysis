Developing artiﬁcial intelligence systems that, mildly at least, understand the structure of knowledge is foundational to building an eﬀective recommendation system for education [4, 15], as well as for many other applications [18, 30] related to knowledge management and tracing. Through this work, we propose Semantic TrueLearn, a novel and transparent learner model that incorporates automatic entity linking and Wikipedia (a publicly available, humanly-intuitive, domain-agnostic and ever-evolving) knowledge graph, as a ﬁrst step towards building an educational recommender that automatically labels materials and embeds the structure of universal knowledge using Wikipedia. Semantic TrueLearn is Sahan Bulathwela, Mar´ıa P´erez-Ortiz, Emine Yilmaz, John Shawe-Taylor In informational recommenders, many challenges arise from the need to handle the semantic and hierarchical structure between knowledge areas. This work aims to advance towards building a state-aware educational recommendation system that incorporates semantic relatedness between knowledge topics, propagating latent information across semantically related topics. We introduce a novel learner model that exploits this semantic relatedness between knowledge components in learning resources using the Wikipedia link graph, with the aim to better predict learner engagement and latent knowledge in a lifelong learning scenario. In this sense, Semantic TrueLearn builds a humanly intuitive knowledge representation while leveraging Bayesian machine learning to improve the predictive performance of educational engagement. Our experiments with a large dataset demonstrate that this new semantic version of TrueLearn algorithm achieves statistically signiﬁcant improvements in terms of predictive performance with a simple extension that adds semantic awareness to the model. a probabilistic graphical model that maintains a symbolic representation of learners’ knowledge that allows explanations, rationalisations and scrutinisation. We i) propose a novel approach for modelling semantic relatedness, ii) propose a novel sub-symbolic Bayesian learner model, iii) identify several research questions relating to validating the improvement of this proposed model and iv) evaluate the performance of the proposed model in a large dataset of learners engagement with educational resources. Knowledge Tracing (KT) [31] is one of the most popular methods for user modelling in educational recommendation contexts. Incorporation of Semantic Relatedness in KT systems has been attempted before in prerequisite modelling [11, 12], exercise similarity [20, 14, 19] and other tasks [4, 29]. However, KT often relies on expert labelling of the Knowledge Components (KCs) [27] (sometimes also for knowledge hierarchies [4]), which is not scalable to large-scale lifelong learning applications in practice. Wikiﬁcation, a form of entity linking [5] that expands this idea, has shown substantial progress and great promise for automatically capturing the KCs covered in an educational resource. Educational Recommenders using Wikiﬁcation, such as TrueLearn [8], has shown promise in building probabilistic graphical models, although one of the assumptions of this model is that Wikipedia concepts are independent and thus unrelated. Using Wikpedia as an ontology or knowledge graph to understand documents is not a new idea. While Wikipedia itself has been used as an ontology using page link and category links to describe ”relates to” and ”is type of” relationships respectively [28, 16], other works have pushed further and used the wealth of information in Wikipedia to build downstream knowledge bases and ontologies [1], as well as ontology-driven information retrieval systems [13]. From the early days of Wikipedia, exploiting diﬀerent aspects of its contents (such as text, link structure, etc.) to model Semantic Relatedness (SR) that represents ”relates to” links has been attempted. These SR metrics have evolved over time into recent proposals that are diverse and sophisticated metrics highly predictive of concept relatedness [25]. However, the utility in these proposals with graphical models is yet to be explored and is addressed thorugh this work. Representations from Graphs The core technical contribution of this work is proposing a method to infer the latent value of an unobserved skill parameter using observed ones via information sharing based on a semantic relatedness graph. Several works have proposed novel ways to use a relationship graph to recover a latent representation for an unknown node using a set of known nodes. Recent Graph Convolutional Neural Networks [17] infer hidden node embeddings (H of its neighbours using adjacency matrix A and diagonal D (H The popularising attention mechanism [2] uses alignment, which is a weighted sum of embeddings. This work puts the foundations to applying these approaches in a educational recommender using 1) a probabilistic graphical model and 2) SR values extracted from Wikipedia. Problem Formulation Consider a learning environment in which a learner ` interacts with a set of educational resources S steps, Q being the total of resources in the system. Each resource r the top KCs or topics covered K the system) and the depth of coverage d time t as a multivariate Gaussian distribution θ of knowledge and Σ covariance matrix in all cases and thus knowledge topics are completely independent from each other. The work in this paper builds towards considering a full covariance matrix, assuming that ρ i and j when i 6= j. The key idea behind TrueLearn [8] is to model the probability of engagement e {1, −1} between learner ` and resource r knowledge θ learner joins the recommender system, TrueLearn sets µ a hyperparameter of the system, and Σ an educational video fragment, TrueLearn updates the learner model/skills accordingly. Every skill that is not updated is set to the value from the last step, meaning at time t there might be many unobserved skills, specially given the amount of topics considered by the system (equal to the number of Wikipedia pages). Thus, TrueLearn assumes that the skill for topics in K related ones. Extending the TrueLearn model [8, 7], the proposed Semantic TrueLearn, is a learner model that infers the knowledge state of learners in an online fashion. Semantic TrueLearn exploits its current knowledge of observed concepts and their SR to a novel concept to make a better prior estimation as per Figure 1. Incorporating Semantic Relatedness Between Topics The main assumption for Semantic TrueLearn, the proposal, is that knowledge can be shared across semantically related topics. By taking inspiration from graph convolutions [17], we formally assume a relationship as per equation 1. where Ω most semantically related seen topics), where i 6= j. The mixing factors γ to semantic relatedness ρ observed topics are used). In the TrueLearn [8] model, which we extend, θ is a Gaussian variable. We use equation 2 to calculate unknown parameter θ represents the set of topics used to infer the representation of topic i (e.g. Figure 1: Inferring the knowledge for unseen topic (white circle) based on semantically Semantic Relatedness Metric (SR Metric) As mentioned in section 2, diﬀerent measures of SR for Wikipedia concepts exist [25]. We empirically evaluate if the predictive performance of an educational recommender can be improved by incorporating 7 diﬀerent SR Metrics to substitute ρ Embeddings (W2V), Point-wise Mutual Information (PMI), Language Model based (LM), Jaccard Similarity (Jaccard), Conditional Probability (CP) and Barabasi and Albert (BA) SR Metrics, where SR values are pre-computed and publicly available [23]. We have four main research questions we verify in this preliminary experiment. • RQ1: Which SR Metric is most suitable? • RQ2: How many related topics should be considered? • RQ3: Does Semantic TrueLearn outperform TrueLearn? • RQ4: Does semantic information contribute to the gains? In which cases? related and seen ones (grey circles) by transferring knowledge (dotted lines). Topics are: ML (Machine Learning), RL (Reinforcement Learning), Prob (Probability), CV (Computer Vision), NLP (Natural Language Processing) and W2V (Word2Vec). We use the PEEK dataset [10], a dataset of more than 20,000 learners consuming video lectures in VideoLectures.Net diﬀerent users consumed fragments of videos over time [9]. This dataset uses entity linking [5] to associate most related Wikipedia concepts to documents. TagMe WAT API [24] To keep the computational complexity lower, a smaller dataset of 20 most active users is used for RQ1 and RQ2. However, the full dataset of 20,000 users is used to validate RQ3 and RQ4, which are our primary research questions. A sequential prediction design where engagement at time t is predicted using events 1 to t − 1. A training set of 70% of the learners is used for hyperparameter tuning and the remainder is used for testing and reporting. Being a binary classiﬁcation task, precision, recall and F1-measure are evaluated whereas F1-measure is used for overall model selection [10]. The evaluation metrics are computed for each learner separately and the weighted average of the scores based on the number of learner’s events is reported. To verify statistical signiﬁcance of the improvement in RQ3, we use a learner-wise one-tailed paired t-test. 4.2.1 Impact of Semantic Relatedness (RQ4) We use the topics encountered in user sessions to build a topic relatedness graph and extract a few attributes linked to graph connectedness for each user. Spearman’s Rank Order Correlation Coeﬃcient (SROCC) statistic is then used to evaluate the correlation between the extracted features and the predictive performance. User’s number of events, number of unique topics, topic sparsity rate [8], positive label rate, Avg. Connectedness, i.e. average of the degree distribution of the topics, and Min. Cut Set Size, i.e. the minimum number of topics that need to be removed to break the graph into more sub-graphs, are analysed. The correlation with the recall score is investigated as the improvement in recall attributes to the performance gains of the proposed model (see Table 1). To validate if semantic relatedness is speciﬁcally inﬂuential in earlier parts of the user session, we plot the mean recall score of all users at event n, for diﬀerent number of events (n). We run experiments to answer the research questions outlined above. To identify the most suitable SR metric (RQ1), we evaluate Semantic TrueLearn model using 7 SR Metrics proposed in section 3.1. The results are outlined in Table 1. To understand the Eﬀect of Ω provides the required SR annotations. , the Number of Semantically Related Topics (RQ2), we use the identiﬁed SR Table 1: Predictive performance of adding Semantic Relatedness (SR) to TrueLearn Metric to experiment with diﬀerent numbers of semantically related topics. The results of this experiment are reported in Table 2. Finally, we use the full PEEK dataset to validate if the use of SR data improves baseline TrueLearn model (RQ3). The results obtained in this experiment are presented in Table 3. Figure 2 presents the results obtained in investigating the impact of semantic relatedness (RQ4) where (left) the correlation investigation between topic connectivity of users and recall score, and (right) the performance of the model based on diﬀerent number of events is reported. Table 2: The performance of Semantic TrueLearn model with W2V SR metric is reported It is evident from Table 1 that incorporating semantic relatedness leads to improvements in overall F1 score in majority of the SR metrics beating the baseline TrueLearn algorithm. Four Semantic TrueLearn models (ones that use M&W, W2V, PMI and BA ) tend Novel algorithm. The diﬀerent conﬁgurations (SR Metric) of Semantic TrueLearn Novel algorithm (our proposal) are evaluated using Precision (Prec.), Recall (Rec.) and F1 Score (F1). The most performant value and the next best value are highlighted in bold and italic faces respectively. The Semantic TrueLearn algorithms that outperform baseline model in terms of F1 score are underlined. in terms of Precision (Prec.), Recall (Rec.) and F1 Score (F1). The performance of the model is reported when diﬀerent Ωtop semantically related topics are utilised in equation 1. The most performant value and the next best value are highlighted in bold and italic faces respectively. Table 3: Predictive performance of Semantic TrueLearn model (our proposal) using Preto outperform the baseline TrueLearn Novel model in terms of precision and F1. The remainder seem to lead in recall. Entity embedding-based SR metric (W2V) leads to the best performing model. This is expected as neural-based semantic relatedness measures often outperform their graph-based counterparts [25]. Our empirical results in Table 2 also showed that using all semantically related topics gives best results contrary to restricting to some of them. Finally, Table 3 shows the superiority of Semantic TrueLearn in comparison to the baseline model that does not exploit SR information from Wikipedia. This is a clear indication that a knowledge base such as Wikipedia can be critical to improving the assumptions used for a learner, modelled using a probabilistic graphical models in the education context. Semantic relatedness can be truly valuable in early stages of the user session when the interaction data about the user is limited, thus addressing the cold-start problem. The correlation evaluation presented in Figure 2 (left) shows the lack of correlation between Positive Label Rate and recall score across both TrueLearn models. Although it Figure 2: (Left) Relationship between diﬀerent behavioural characteristics of user procision (Prec.), Recall (Rec.) and F1 Score (F1). The most performant value is highlighted in bold face. The Semantic TrueLearn Model that outperform baseline model (p < 0.01 in a one-tailed paired t-test) are marked with ·. ﬁles and model recall performance presented using SROCC. The numbers and the intensity of each cell corresponds to the Spearman R coeﬃcient where signiﬁcant correlation is present (p < 0.01). Empty cells represent lack of signiﬁcant correlation.(Right) The average recall performance of the two models for the learner population at diﬀerent number of events. has been demonstrated by the original authors that TrueLearn algorithm capitalises on recall, there is no information in the work regarding the positive label rate in the datasets. This observation conﬁrms that TrueLearn family of algorithms ﬁnd true patterns in learner data rather than merely capitalising on the positive labels to boost performance. Multiple observations in Figure 2 (left) give evidence of the superiority of Semantic TrueLearn exploiting the semantic relatedness between topics to boost recall. The main two observations are the new model’s stronger Spearman’s rank correlation with learner Avg. Connectedness and Min. Cut Set Size. This is a strong indication that the Semantic TruLearn model is exploiting the topic correlations. The correlation between the number of events, number of unique topics and topic connectedness cause the higher correlation between these features and Semantic TrueLearn model. The Figure 2 (right) clearly shows how the recall score of predictions is much larger in Semantic TrueLearn algorithm regardless in early or latter stage of the learner session. Linking this to results in Table 1 shows that this impressive gain of recall score is achieved with a much smaller sacriﬁce of precision score. Limitations Amid the signiﬁcant gains, we observe that most KCs encountered by the model in a session are highly correlated to each other. This leads to overlapping information being propagated repeatedly when using equation 1 which may lead to overestimation of knowledge of unseen KCs. Equation 1 only acknowledges the existence of correlations between seen and unseen topics (dotted lines in Figure 1) not the correlation within seen topics (solid lines in Figure 1) which is an issue. As the proposed method primarily infers unobserved skills, its use diminishes over time when the user session matures (as new topics are encountered less often). Mechanisms to keep using semantic awareness to reﬁne representations is a much needed improvement to the proposed method. Leveraging semantic relatedness between Wikipedia topics has demonstrated promise to improving the predictive performance of informational recommenders such as TrueLearn that are built on Wikipedia ontology and probabilistic graphical models. In addition, we identify that restricting the number of related topics leads to degraded performance, suggesting the use of all available knowledge components extracted from Wikiﬁcation. Our analysis also shows that topic connectedness within learner sessions is positively correlated with the performance gains of Semantic TrueLearn, giving clearer evidence of the positive impact of incorporating this aspect when modelling learners and their journey within an education setting. The proposed model is a stepping stone to accounting for semantic relatedness. However, it still disregards the correlation among the observed topics. To address this, we propose the following research avenues: 1) using algorithms such as PageRank [6] to derive uncorrelated skill parameters, 2) accounting for inter-skill correlation in equation 2 and 3) building a hierarchical representation of knowledge [21] consisting of mutually exclusive (uncorrelated) Wikipedia concepts. It may also be fruitful to consider richer ontologies [1] that contain more ﬁne-grained relationships, entity deﬁnitions/categorisations and constrains in the place of raw Wikipedia graph to incorporate ﬁner grain semantic-awareness to the learner model. Mechanisms to continuously utilise SR information should be identiﬁed and investigated in future work. Moreover, semantic relatedness measures are not usually built and validated with educational datasets or topics, which is a limitation. In the future, we also aim to validate the SR metrics with education and informational recommender focused datasets. As Semantic TrueLearn builds a sub-symbolic representation that is humanly-intuitive, it is possible to create narratives and intelligent user interfaces (e.g. [9, 22]) used to interpret and rationalise [26] the learnings of the model leading towards more humanin-the-loop artiﬁcial intelligence that allows veriﬁcation and scrutinisation of the models [3]. This research is conducted as part of the X5GON project (www.x5gon.org) funded from the EU’s Horizon 2020 research and innovation programme grant No 761758. We gratefully acknowledge support and funding from the U.S. Army Research Laboratory and the U. S. Army Research Oﬃce, and by the U.K. Ministry of Defence and the U.K. Engineering and Physical Sciences Research Council (EPSRC) under grant number EP/R013616/1. This work is also partially supported by the European Commission funded project ”Humane AI: Toward AI Systems That Augment and Empower Humans by Understanding Us, our Society and the World Around Us” (grant 820437) and the EPSRC Fellowship titled ”Task Based Information Retrieval” (grant EP/P024289/1). [1] S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, [2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine transla- [3] Krisztian Balog, Filip Radlinski, and Shushan Arakelyan. Transparent, scrutable [4] Konstantin Bauman and Alexander Tuzhilin. Recommending remedial learning and Zachary Ives. Dbpedia: A nucleus for a web of open data. In The semantic web. Springer, 2007. tion by jointly learning to align and translate. In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. and explainable user models for personalized recommendation. In Proc. of the 42nd Int. ACM SIGIR Conf. on Research and Development in Information Retrieval (SIGIR ’19), 2019. materials to students by ﬁlling their knowledge gaps. MIS Quarterly, 42(1):313– 332, 2018. [5] Janez Brank, Gregor Leban, and Marko Grobelnik. Annotating documents with [6] Sergey Brin and Lawrence Page. The anatomy of a large-scale hypertextual web [7] S. Bulathwela, M. Perez-Ortiz, E. Yilmaz, and J. Shawe-Taylor. Towards an in- [8] S. Bulathwela, M. Perez-Ortiz, E. Yilmaz, and J. Shawe-Taylor. Truelearn: A family [9] Sahan Bulathwela, Stefan Kreitmayer, and Mar´ıa P´erez-Ortiz. What’s in it for [10] Sahan Bulathwela, Maria Perez-Ortiz, Erik Novak, Emine Yilmaz, and John Shawe[11] C. Carmona, E. Mill´an, J. L. P´erez-de-la Cruz, M. Trella, and R. Conejo. Intro- [12] Penghe Chen, Yu Lu, Vincent W Zheng, and Yang Pian. Prerequisite-driven deep [13] Gregory Grefenstette and Karima Rafes. Transforming wikipedia into an ontology- [14] Zhenya Huang, Yu Yin, Enhong Chen, Hui Xiong, Yu Su, Guoping Hu, et al. [15] Weijie Jiang, Zachary A. Pardos, and Qiang Wei. Goal-based course recommenda- [16] Tokio Kawakami, Takeshi Morita, and Takahira Yamaguchi. Building wikipedia relevant wikipedia concepts. In Proc. of Slovenian KDD Conf. on Data Mining and Data Warehouses (SiKDD), 2017. search engine. In Proc. of Int. Conf. on World Wide Web, 1998. tegrative educational recommender for lifelong learners. In AAAI Conference on Artiﬁcial Intelligence, 2020. of bayesian algorithms to match lifelong learners to open educational resources. In AAAI Conference on Artiﬁcial Intelligence, 2020. me? augmenting recommended learning resources with navigable annotations. In Proc. of Int. Conf. on Intelligent User Interfaces Companion, IUI ’20, page 114–115, 2020. Taylor. Peek: A large dataset of learner engagement with educational videos, 2021. ducing prerequisite relations in a multi-layered bayesian student model. In Proc. of the Int. Conf. on User Modeling, UM’05, page 347–356, 2005. knowledge tracing. In 2018 IEEE Int. Conf. on Data Mining (ICDM), pages 39–48. IEEE, 2018. based information retrieval search engine for local experts using a third-party taxonomy. arXiv preprint arXiv:1511.01259, 2015. Ekt: Exercise-aware knowledge tracing for student performance prediction. IEEE Transactions on Knowledge and Data Engineering, 2019. tion. In Proceedings of International Conference on Learning Analytics & Knowledge, 2019. ontology with more semi-structured information resources. In Semantic Technology - 7th Joint International Conference, JIST 2017, Proceedings. Springer Verlag, 2017. [17] Thomas N. Kipf and Max Welling. Semi-supervised classiﬁcation with graph con- [18] Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir [19] Hiromi Nakagawa, Yusuke Iwasawa, and Yutaka Matsuo. Graph-based knowl- [20] Shalini Pandey and Jaideep Srivastava. Rkt: Relation-aware self-attention for [21] Radek Pel´anek. Managing items and knowledge components: domain modeling in [22] Mar´ıa P´erez-Ortiz, Claire Dormann, Yvonne Rogers, Sahan Bulathwela, Stefan [23] Francesco Piccinno. Algorithms and data structures for big labeled graphs. PhD [24] Francesco Piccinno and Paolo Ferragina. From tagme to wat: A new entity annota- [25] Marco Ponza, Paolo Ferragina, and Soumen Chakrabarti. On computing entity [26] Mark Owen Riedl and Vadim Bulitko. Interactive narrative: An intelligent systems [27] Douglas Selent, Thanaporn Patikorn, and Neil Heﬀernan. Assistments dataset from [28] Zareen Syed, Tim Finin, and Anupam Joshi. Wikipedia as an ontology for describing [29] Khushboo Thaker, Lei Zhang, Daqing He, and Peter Brusilovsky. Recommending volutional networks. In International Conference on Learning Representations (ICLR), 2017. Karpukhin, Naman Goyal, Heinrich K¨uttler, Mike Lewis, Wen-tau Yih, Tim Rockt¨aschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. arXiv preprint arXiv:2005.11401, 2020. IEEE/WIC/ACM International Conference on Web Intelligence, WI ’19, 2019. knowledge tracing. arXiv preprint arXiv:2008.12736, 2020. practice. Educational Technology Research and Development, 68(1):529–550, 2020. Kreitmayer, Emine Yilmaz, Richard Noss, and John Shawe-Taylor. X5learn: A personalised learning companion at the intersection of ai and hci. In 26th International Conference on Intelligent User Interfaces, pages 70–74, 2021. thesis, Universita´de Pisa, 2017. tor. In Proc. of the First Int. Workshop on Entity Recognition & Disambiguation, ERD ’14, 2014. relatedness in wikipedia, with applications. Knowledge-Based Systems, 188, 2020. approach. Ai Magazine, 34(1):67–67, 2013. multiple randomized controlled experiments. In Proc. of the Conf. on Learning @ Scale, 2016. documents. In Proc. of Int. Conf. on Weblogs and Social Media. AAAI Press, March 2008. remedial readings using student knowledge state. In Proc. of Int. Conf. on EDM, 2020. [30] Tae Yano and Moonyoung Kang. Taking advantage of wikipedia in natural language [31] Michael V. Yudelson, Kenneth R. Koedinger, and Geoﬀrey J. Gordon. Individuprocessing. Technical report, Carnegie Mellon University Language Technologies Institute, 2016. alized bayesian knowledge tracing models. In H. Chad Lane, Kalina Yacef, Jack Mostow, and Philip Pavlik, editors, Proc. of Artiﬁcial Intelligence in Education, 2013.