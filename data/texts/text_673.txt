Finding an optimal individualized treatment regimen is considered one of the most challenging precision medicine problems. Various patient characteristics inﬂuence the response to the treatment, and hence, there is no one-size-ﬁts-all regimen. Moreover, the administration of even a single unsafe dose during the treatment can have catastrophic consequences on patients’ health. Therefore, an individualized treatment model must ensure patient safety while efﬁciently optimizing the course of therapy. In this work, we study a prevalent and essential medical problem setting where the treatment aims to keep a physiological variable in a range, preferably close to a target level. Such a task is relevant in numerous other domains as well. We propose ESCADA, a generic algorithm for this problem structure, to make individualized and context-aware optimal dose recommendations while assuring patient safety. We derive high probability upper bounds on the regret of ESCADA along with safety guarantees. Finally, we make extensive simulations on the bolus insulin dose allocation problem in type 1 diabetes mellitus disease and compare ESCADA’s performance against Thompson sampling’s, rule-based dose allocators’, and clinicians’. Precision medicine aims to provide the best possible treatment on an individual level by considering patient characteristics’ variability (Mirnezami et al., 2012; Ashley, 2016). Many healthcare problems require keeping a physiological variable (e.g., blood glucose level) in a safe range. One such example is electrolyte disorders, which are common among intensive care unit patients. When the blood sodium level falls below 135 milliequivalents per liter (mEq/L) or goes beyond 145 mEq/L, the patient experiences hypo-/hyper-natremia with adverse effects on health (Kraft et al., 2005). Therefore, correct dosing of electrolytes is crucial to ensure patient safety, and there is no consensus on how to assess the correct dosage for different patient characteristics. Another critical problem is blood pressure disorder. These are hypo-/hyper-tension events where the blood pressure deviates from its standard value and needs to be corrected. Patient characteristics play an essential role in determining the blood pressure response to the therapeutic agent, and they should be taken into account in the dosing process (Nerenberg et al., 2018; Materson et al., 1993). Related Work and Background A fair amount of research is dedicated to adaptive clinical trials which aim to identify a drug’s effectiveness within a group, often including a tradeoff between the efﬁcacy and the toxicity (Shen et al., 2020; Atan et al., 2019; Lee et al., 2020; Villar and Rosenberger, 2018; Lee et al., 2021). However, the algorithms proposed in these works are not applicable for the problem structure considered here for two main reasons. First, the therapeutic agent (e.g., drug) is not necessarily toxic, and the aim is not to maximize the patient response to the agent but to keep it close to a target level. Therefore, classical upper conﬁdence bound (UCB) based algorithms such as UCB1 (Auer et al., 2002) or GP-UCB (Srinivas et al., 2010) are not applicable for our Preprint. Under review. objective. This is simply because the UCB-based algorithms leverage the optimism in the face of uncertainty principle and pick the arms that yield the highest estimated outcomes, whereas in our case optimism implies selecting the arm with the closest estimated outcome to the target level. This fundamental difference in our task necessitates radical changes in acquisition strategy. Secondly, our objective is to provide optimal dose recommendations on an individual level rather than for a group of patients. To that end, we approach the safe dose allocation problem from a contextual multiarmed bandit (MAB) (Lu et al., 2010) perspective with additional safety constraints. We propose a novel acquisition function tailored for this problem structure in §3. To render our acquisition method safe, we propose a safe exploration strategy. There is a surge of interest in safe exploration for different frameworks such as Bayesian optimization (BO), Markov decision processes, and reinforcement learning (Moldovan and Abbeel, 2012; Wachi et al., 2018; Gelbart et al., 2014; Hernandez-Lobato et al., 2016). We operate in a BO framework where we model the objective function as a sample from a Gaussian process (GP). Gelbart et al. (2014); HernandezLobato et al. (2016) consider BO with safety constraints. However, they aim to ﬁnd optimal safe solutions and allow unsafe evaluations throughout exploration. Amani et al. (2020) propose a safe variant of GP-UCB, which employs a pure exploration phase at the beginning, and provide upper bounds on its cumulative regret. SafeOPT and StageOPT algorithms provide guarantees on the safety of the exploration process (Sui et al., 2015, 2018). However, they model the exploration of the safe set as a proxy objective which leads to unnecessary suboptimal evaluations at the boundaries of the safe set (Turchetta et al., 2019). Moreover, despite the convergence guarantees, they do not provide formal upper bounds on the cumulative regret. On the other hand, Goal-oriented Safe Expansion (GoOSE) algorithm works with any acquisition function as a plug-in safety mechanism and encourages the expansion of the safe set only when necessary (Turchetta et al., 2019). When the query is not guaranteed to be safe, only then GoOSE tries to expand the safe set by iteratively evaluating the function at safe points to learn more about the initial query’s safety, which preserves the performance of the original acquisition strategy within safety constraints. However, such reevaluations is not possible within the framework of dynamic treatment regimes since this setup does not allow the administration of multiple different doses. Moreover, all the works above consider a one-sided safety constraint (f(x) ≥ c), whereas we consider a two-sided safety constraint since the aim is to keep f in a range (c≤ f(x) ≤ c previous works and propose a safe-exploration strategy for our problem structure in §3. Finally, we make extensive in silico simulations on type 1 diabetes mellitus (T1DM) disease in §5. T1DM is characterized by insulin deﬁciency due to pancreatic β-cell loss and can have serious adverse effects due to hypo-/hyper-glycemia (low and high blood glucose levels), which might result in immediate hospitalization and even death (Bastaki et al., 2005). Therefore, T1DM patients must regulate their blood glucose levels by administering bolus insulin doses before meals. We try to optimize the dose recommendation process via safely and efﬁciently learning to recommend better doses. Our key contributions are as follows. Key Contributions • We study a prevalent and essential problem structure in medicine and relevant in numerous domains, which is rather overlooked. • We formalize this problem through the lens of MABs via a suitable deﬁnition of regret as the proxy performance metric in §2. • Since the objective is not to maximize the outcomes but to keep them close to a target level as opposed to the classical MAB setting, we propose a novel acquisition strategy in §3. • We design a safe exploration scheme to render our acquisition function safe in §3 and provide high probability upper bounds on its regret along with safety guarantees in §4. We denote by [N ] the set {1, . . . , N}, z ∈ Z a context, and d ∈ D a dose, where both Z and D are compact and convex, and D = [0, D]. Here, D ∈ R f : Z × D → Ω be the (unknown) function that maps (z, d) pairs to the physiological variable of ). We utilize intuitive safe set expansion rules from interest, where Ω = [0, T ]. At round n ∈ [N], the learner observes a context, z a dose, d, to obtain a noisy evaluation of f at (z νare zero-mean i.i.d. Gaussian with known variance σ physiological variable, f, within a safe range and preferably close to the target level. We formalize this objective as a contextual MAB problem with safety constraints as, where Tand Tdenote the lower and upper safe values for f, respectively, and T ∈ (T+ α, T− α) is the target value, where α > 0. We assume ∀z ∈ Z, there exists d∈ D s.t. f(z, d) = T . Regularity Assumptions Our safe exploration strategy relies on expanding around an initial safe set, S⊂ D, by exploiting the smoothness properties of the objective function f. Without an initial safe set, and some regularity assumptions on f , it is not possible to make inferences on the safety of the prospective recommendations (Sui et al., 2015). Let X = Z × D denote the space of all context-dose pairs. Let k(·, ·) be a positive deﬁnite kernel function on X . We assume that f is a function from the Reproducing Kernel Hilbert Space (RKHS) corresponding to k(·, ·). In addition, we assume that f has bounded norm in this particular RKHS, i.e., kfk 2002). This mild assumption makes f smooth enough to be efﬁciently learnable. More precisely, f is L-Lipschitz continuous w.r.t. kernel metric q(x, x L = B(Steinwart and Christmann, 2008). Also, we denote by q this point, we deﬁne a discretization of D for every z ∈ Z as where d= 0, d> dfor i > j, q(d, d discretization parameter. We assume that an initial safe set of discretized doses S for each context z ∈ Z. These assumptions allow us to use tools from Gaussian processes (GP) to design our algorithm, and analyze its regret and safety guarantees (Rasmussen, 2004). A GP is a distribution over functions, and it is fully characterized by its mean, µ(·), and covariance, k(·, ·), functions. Moreover, if we assume a GP prior over f, then, after observing a set of noisy evaluations y= [y. . . y]at points A= {x, . . . , x with the following mean and covariance functions, where k(x) = [k(x, x), . . . , k(x, x)] [k(x, x)]. We propose ESCADA: Efﬁcient Safe and Context Aware Dose Allocation algorithm. ESCADA consists of two blocks: (i) an acquisition function, which we call TACO: TArget-based COnﬁdentacquisition, (ii) a safety mechanism to render TACO safe. Algorithm 1 and Figure 1 summarize ESCADA’s design. Acquisition Strategy We propose TACO, a novel acquisition method speciﬁcally tailored for the problem structure described in Section 2. At each round n, TACO uses the conﬁdence bounds of doses d ∈ D for zderived from the GP prior as l u(z, d) = µ(z, d) + βσ(z, d). We deﬁne β conﬁdence intervals contain the true value of f with high probability (see Lemma 1). Then, using Lipschitz continuity of f, we form the ﬁnal lower and upper conﬁdence bounds for every d ∈ D as, }, the posterior over f is a GP distribution again, and Kis the positive deﬁnite kernel matrix , d), l(z, d) − Lq(d, d)} , d), u(z, d) + Lq(d, d)}, Figure 1: ESCADA Algorithm Description (left). Upon observing a context z forms the set C(z) ⊆ S(z) after eliminating the doses that are suboptimal with high probability. If C(z) 6= ∅, it recommends the dose whose mean response is closest to the target T . If C ∅, it recommends the dose with the widest conﬁdence interval in S A simple interpretation of the dose allocation process intended for domain experts. where d= argminq(d, d). We denote by C ﬁdence interval of a dose d ∈ D in round n, and by C set of all conﬁdence intervals. Finally, we form the conﬁdence widths for each dose d ∈ D as w(z, d) = ¯u(z, d) −¯l(z, d). 1: Inputs: X = Z×D; GP prior (µ, k, σ); 9: Subroutine: TACO 10: Inputs: C(z); D 11: C= {d ∈ D| T ∈ C(z, d)} 12: if C6= ∅ then Safety Awareness Having proposed an acquisition function tailored for our problem structure, the next step is to render it safe. We propose a safe exploration scheme inspired from the previous works (Sui et al., 2015, 2018). We denote the safe set at round n for a given context z Letˆl(z, d, d):=¯l(z, d) − Lq(d, d), and ˆu implement the following safe expansion rule to derive S At each round n, TACO recommends a dose from D for which f resides in the target interval almost certainly (see Theorem 1). We also deﬁne the reachability operator Rand -reachable safe set for z ∈ Z, the uncertainty in measurements) as in (Sui et al., 2015), TACO queries a recommendation from a dose set Dat each round n upon observing the context z in three steps: (i): Identify the dose set C⊆ D whose elements’ conﬁdence intervals contain the target value, T (ii) If C6= ∅ recommend the dose in Cwith closest posterior mean to the target value T (iii) If C= ∅, recommend the dose in D∩¯D with the widest conﬁdence interval. In the ﬁrst step, TACO eliminates the doses which are suboptimal with high probability. This step includes elements of both exploration and exploitation. A dose whose mean response is close to the target value can be selected (i.e., exploitation). On the other hand, if a dose is under-explored, it will have a wider conﬁdence interval which may contain the target, and it stands a chance to be selected (i.e., exploration). In the third step, TACO focuses on exploration in spirit of identifying the doses that may be optimal. TACO is efﬁcient in the sense that it treats exploration as a proxy objective –in third step– only when all the feasible doses are suboptimal with high probability. (z, d, d) ≥ T∧ ˆu(z, d, d) ≤ T}, (3) , always includes at least one discretized dose in¯D. and¯R(S(z)):= limR(S(z)). Rdenotes the n-time reachability operator, which calls Rn times using the previous step’s output. identiﬁed as safe for the context z by observing f up to a statistical certainty restricted by . ESCADA for Healthcare Although the problem ESCADA attempts to solve is quite general and it may emerge in almost every domain, it exhibits certain qualities which make it suitable for healthcare in particular. ESCADA employs a deterministic acquisition function, TACO, which favors it in the clinical setting where inherent randomness in an algorithm (e.g., Thompson sampling) may result in inexplicable variations in treatment and reduce the quality of care (Tomson and Van Der Veer, 2013). Moreover, ESCADA’s recommendation process can be interpreted to domain experts via the simple ﬂowchart in Figure 1 as opposed to black-box models (Zhang et al., 2018). Consider a ﬁxed sequence of patient contexts the space of all context-admissible recommendation pairs, where X the admissible dose space for z. For a given sequence of context-recommendation set A, let y denote the |A|-dimensional vector containing corresponding noisy evaluations of f. The quantity governing our regret bounds after N rounds in this scenario is a volatility-adapted maximum information gain term, γ= maxI(yyy;f mutual information between f and observations at points in A. In the general setting where there is not a ﬁxed context sequence, we have γ= max we have γ≤ γ. Explicit bounds on γdepending on N are available in the literature (Srinivas et al., 2010; Vakili et al., 2020). In this section, we ﬁrst derive a high probability upper bound on the cumulative regret of TACO for a ﬁxed context sequence without safety constraints. Then, we bound the regret of ESCADA in a single context scenario with safety constraints. For the former, we have¯z= [z. . . z], and D= D, and we denote the upper bound on the information gain term (see Lemma 2) by γ. For the latter, we have upper bound on the information gain term by γ ESCADA is safe with high probability. Detailed proofs are provided in appendix for each result. First, we mention two standard results used in the analysis. Lemma 1 shows that f is contained in the GP-induced conﬁdence intervals with high probability. Lemma 1. (Theorem 1 in Krause and Ong (2011)) Pick δ ∈ (0, 1), and deﬁne β 2L+ 300γlog(n/δ), where L is the Lipschitz constant. Let E = {|µ βσ(xxx), ∀n ∈ N, ∀xxx ∈ X }. We have PE The next lemma expresses the information gain in terms of predictive variances. Lemma 2. (Lemma 5.3 in Srinivas et al. (2010)) The information gain for the points selected can be expressed in terms of the predictive variances. If f The following theorem gives a safety guarantee on ESCADA under the high probability event E in Lemma 1. The proof depends on an inductive argument on the safe sets constructed by ESCADA. Theorem 1. All doses recommended by ESCADA are safe with at least 1 − δ probability. We proposed a novel acquisition function in §3, TACO, for the generic problem structure described in §1 and §2. Theorem 2 provides an upper-bound on the regret of TACO, without any safety constraints in place. Theorem 2. Deﬁne βas in Lemma 1 and let C for a ﬁxed context sequence is upper-bounded as follows, Next, we introduce a new concept, safe path. Flowchart assumes that GP-induced conﬁdence intervals are correct, i.e., the event E in Lemma 1 holds. ¯z = [z. . . z]. Let X= X× . . . Xdenote ff), where fff= [f(xxx)]and I(yyy;fff) is the ¯z= [z . . . z], D= S(z), and we denote the . We also prove that every dose recommended by ≥ 1 − δ. = (f(x)), I(y; f) =Plog(1 + := 8/ log(1 + σ). Cumulative regret of TACO γ≥ 1 − δ . Deﬁnition 1. (Safe Path) For a ﬁxed context z ∈ Z, we say that there exists a safe path between two doses d, d∈ D if the following is satisﬁed, η(d, d) = minminT−  − f(z, d) Deﬁnition 1 simply states that if there exists a safe path between two doses d there is no dose violating or exactly at the safety constraints between them. That is, f(d) ∈ (T+  + η(d, d), T−  − η(d gret bound for ESCADA, which uses TACO as the acquisition function, and employs the safety mechanism in §3. We assume a ﬁxed context scenario and show that the safety constraints result in at most a constant addition to the regret. Theorem 3. If there exists a safe path between at least one dose d ∈ S q(d, d) = K(|d− d|) for some monotonically increasing mapping K : R all d, d∈ D, then the cumulative regret of ESCADA in a safety constrained single context (z) scenario can be upper-bounded by setting the discretization parameter λ <  as follows, where N∈ N is a constant independent of N. Note that since we have f(z, d) = T and T ∈ (T for the possibility of a safe path to exist between some d ∈ S The assumption q(d, d) = K(|d− d|) for a monotonically increasing mapping K : R holds in our case where the response to insulin dose is characterized by patients’ carbohydrate factor (CF). That is, if we let L  CF, then we have f(z, d That is, q(d, d) = K(|d− d|) = |d− d Moreover, we would like to emphasize that this is the case for a variety of widely used kernel induced distance metrics. Consider the squared exponential kernel k(α, β) = exp where σ > 0. Then, we have (see §2), Similarly, one can also consider the Laplacian kernel (also from the radial-basis functions family) k(α, β) = exp (− kα − βk /σ), which induces the metric, where both (6) and (7) are monotonically increasing w.r.t. |d the non-incremental parts in our analysis as they provide explicit regret guarantees for a novel problem structure and acquisition strategy, both with and without safety constraints for a compact and convex decision (i.e., dose) set D. The bound in Theorem 3 can be generalized to mixed context scenarios by imposing further assumptions on the regularity of context arrivals over time. We provide experimental results on mixed context scenarios in §5. Online experimentation with real patients in the clinical setting is hazardous, and it faces various ethical challenges (Chen et al., 2020; Vayena et al., 2018; Price and Nicholson, 2017; Price, 2018). Previous works on dose-ﬁnding clinical trials validate their methods either through experiments in synthetic environments or use external algorithms to ﬁt a dose-response model to real-world data when the patient group is homogeneous (Aziz et al., 2021; Shen et al., 2020; Lee et al., 2020). Such algorithms are not applicable in our case as they assume a shared dose-response model among patients, whereas we aim to learn individualized representations. We make in silico experiments via University of Virginia (UVa)/PADOVA T1DM simulator (Kovatchev et al., 2009; Xie, 2018). It , minf(z, d) − T−  , d)) for all d ∈ [d, d]. Next, we give the reγ+ T N≥ 1 − δ, + α, T− α), one must ensure that α >  ) − f(z, d) ≤ L|d− d| for d, d∈ D. comes with 30 virtual patients, each having different individual characteristics: 10 adults, 10 adolescents, and 10 children. The simulator calculates the postprandial blood glucose (PPBG) response of a patient for (meal event, bolus insulin dose) pairs via a complex model using differential equations and patient characteristics (Kovatchev et al., 2009). It is recognized by the United States Food and Drug Administration (U.S. FDA) as a reliable closed-loop hormone controller design framework for in silico experiments, and it is the most frequently used framework in blood glucose control studies (Daskalaki et al., 2013; Zhu et al., 2020a,b; Tejedor et al., 2020). We experiment with all 30 virtual patients that come with the simulator. We use separate models for each patient, and model the different meal events as contexts (i.e., z ∈ Z in §2). In our best effort to evaluate the success and potential of ESCADA as a supplementary tool in the clinical setting and to provide external validation, we also compare its performance against clinicians for ﬁve virtual adult patients. Throughout the experiments, we use a ﬁxed value of β= 10 for all n ∈ [N]. Performance Metrics When the PPBG level of the patient drops below 70 mg/dl (or exceeds 180 mg/dl), hypoglycemia (hyperglycemia) events occur. Both events may lead to life-threatening conditions (Bastaki et al., 2005). We set the target blood glucose (BG) level to (70+180)/2 = 125 mg/dl (Maahs et al., 2016). Our primary objective is to recommend insulin doses to minimize the cumulative regret while ensuring safety. Minimizing the cumulative regret translates to recommending doses that keep the patients’ PPBG level close to the target BG level (see (1)). Ensuring safety means not recommending any insulin dose that triggers hypoglycemia or hyperglycemia events (see (2)). To that end, we gauge an algorithm’s performance by combining its regret, hypoglycemia and hyperglycemia frequencies (error frequencies), and glycemic risk indices. Glycemic risk indices are low blood glycemic index (LBGI), high blood glycemic index (HBGI), and risk index (RI + HBGI). LBGI (HBGI) characterizes the risk of hypoglycemia (hyperglycemia) events for a patient in the long term (Kovatchev et al., 2003). A well-rounded algorithm should have a low cumulative regret together with small risk index values by safely and efﬁciently learning to recommend insulin doses for arbitrary contexts (meal events). Besides, we discuss the competing algorithms’ consistency since inexplicable variations in medical therapy are undesirable (Tomson and Van Der Veer, 2013). Precisely speaking, for a given history, a consistent algorithm should recommend the same insulin doses to a patient for the same meal events. A meal event is a two-element tuple: (carbohydrate intake, fasting blood glucose). We create different meal events via uniform sampling to create an ensemble of different scenarios. We sample carbohydrate intake for each meal event from [20, 80] g, and fasting blood glucose from [100, 150] mg/dl. Single Meal Event (SME) Scenario In this part, we recommend insulin doses to a patient for the same meal event assuming the patient takes the insulin dose directly before the meal. Simulating this setup is helpful for two reasons: (i) it tests the performance of algorithms in the classical noncontextual MAB setting, (ii) it provides a simple benchmark to understand the performance metrics and to compare them with the contextual setup later. After recommending a dose, we observe the patient’s PPBG level and update the algorithms’ parameters before the next recommendation. Our objective is to optimize the PPBG 150 minutes after the meal. We make 15 consecutive dose recommendations for a meal event in a single run. We repeat this experiment for 30 patients and with 30 different meal events for each patient. Finally, we average the results from all (30 × 30 = 900) runs. Multiple Meal Events (MME) Scenario In this part, we recommend insulin doses to a single patient for a sequence of different meal events. This scenario showcases how learning from previous meal events with different contexts helps adjust recommendations for the current meal event. We use the same 30 meal events created in the SME scenario and run simulations for all 30 patients. We make consecutive recommendations for different meal events in a round-robin fashion and recommend a total of 15 doses for each meal event. Precisely speaking, after making a dose recommendation for a meal event, we make recommendations for the other 29 meal events and observe the PPBGs before making the next recommendation for the ﬁrst meal event. We then average the results from all 30 runs (one per patient). The difference in this part from the SME scenario is that we make insulin dose recommendations to a patient for different meal events in a single run (i.e., the setting here is contextual), whereas, in the SME scenario, we recommend doses to patients for the same meal event in a single run (i.e., non-contextual). This setup illustrates that the information gained from a context can assist in making decisions for different contexts. This contextual knowledge transfer enables our algorithm to adapt to intra- and inter-daily variability in meal events. Table 1: Performance metrics averaged over all dose recommendations for each (patient, meal event) tuple. “-I” sufﬁx indicates that initial data was used, and “-TC” sufﬁx indicates that the tuned calculator was used. The target PPBG level is 125 mg/dl. TACO and TS (i.e., unsafe algorithms) yield higher hypo- and hyper-glycemia frequencies, risk indices, and higher standard deviations in the PPBG distribution than ESCADA and STS. When the tuned calculator is used, ESCADA and STS satisfy the safety requirements perfectly and yield the lowest risk indices. Also, the presence of initial data provides notable performance improvements. Finally, we mark dramatic advancements in every performance metric in the MME scenario compared to the SME scenario, suggesting that the information gained from a meal event improves the recommendations for other meal events. Algorithms We simulate ESCADA and TACO (i.e., without the safety mechanism). Besides, we propose a Thompson sampling (TS)-based algorithm along with its safe version (STS) which operate as follows: TS samples a PPBG function from the posterior GP in each round and recommends the dose that achieves the PPBG closest to the target BG, whereas STS implements the safe exploration strategy in §3, and uses TS as the acquisition function. Moreover, we use two versions of rule-based dose allocators (calculators) as baseline benchmarks, whose details are given below. Dose Calculators Dose calculators are commonly used in diabetes care, as they are transparent and interpretable (Walsh et al., 2011). We use them to initialize the safe dose set for patient and meal event pairs. A calculator recommends an insulin dose via a simple equation, including carbohydrate intake, fasting blood glucose, and patient-speciﬁc parameters. They must be ﬁne-tuned to ensure safety which may be challenging. Even in such case, they may not include some patient characteristics which can affect PPBG in the calculation rule. Correction doses constitute 9% of the patients’ daily insulin dose intake due to the calculator’s failure (Walsh et al., 2011). Details about bolus calculators are available in the appendix. We consider two setups. In the ﬁrst one, we use a calculator setting that occasionally fails to provide safe dose recommendations and sacriﬁce the assumption that an initial safe set, S, is always available. In the second setup, we use tuned calculators for each patient and ensure that S Initial Data While ESCADA can safely optimize the course of treatment without requiring initial training data, having access to a small amount of initial data is not uncommon in practice. For instance, we might have access to training data obtained from patients’ past treatments. To assess the effect of initial data on performance, we simulate both setups where it is available and not. Safety Ensuring patient safety is of utmost importance. Theorem 1 shows that ESCADA always recommends safe doses with high probability when an initial safe dose is available. However, in reality, the initially provided dose may not be safe. As described in §5.1, we simulate two scenarios and probe the safety statistics of ESCADA both when an initial safe dose is available and not. For the latter, we observe from Figure 2 and Table 1 that the hypo- and hyper-glycemia frequencies (error frequencies) of ESCADA are not zero. We expect that error since the calculator fails to provide safe doses in the beginning consistently. However, ESCADA yields signiﬁcantly lower is always available. Figure 2: Comparison of PPBG distributions in the SME Scenario. “-I” sufﬁx indicates that initial data was used, and “-TC” sufﬁx indicates that the tuned calculator was used. risk index values, error frequencies, and standard deviations than the calculator. This improvement stems from ESCADA’s ability to gradually identify and recommend safe doses, even when initially misdirected. We plot consecutive dose recommendations by ESCADA in SME scenario for four different meal events in Figure 4. For each of these meal events, rule-based calculator fails to provide safe doses in the beginning. Notwithstanding, ESCADA efﬁciently expands its safe set in the right direction and eventually recommends safe doses. Figure 2 and Table 1 conﬁrm the safety mechanism’s effectiveness. ESCADA and STS yield signiﬁcantly better safety metrics and lower standard deviations in the PPBG distributions compared unsafe algorithms, TACO and TS. We also study the effect of initial data on performance. We assume that ten (meal event, insulin dose, PPBG) observations are available for each patient, which can be easily collected in a week. Figure 2 and Table 1 show that the availability of such data improves the safety metrics for both ESCADA and STS, even when the initial safe set, S, is incorrectly speciﬁed. Next, we study the case where we always have access to a safe dose in the beginning. We achieve this via tuned calculators for each patient as described in §5.1. We can observe from Figure 2 and Table 1 that both ESCADA and STS satisfy the safety requirements perfectly in this case. Regret Our optimization objective is to minimize the cumulative regret while satisfying the safety constraint. By (1), this is equivalent to recommending doses that lead to PPBG values close to the target BG level. We observe from Figure 2 and Table 1 that ESCADA and STS signiﬁcantly outperforms the rule-based calculator. Figure 5 shows that TACO and TS yield lower cumulative regrets than ESCADA and STS. That is a natural trade-off between safety and regret. The safety mechanism restricts the allocation of a dose before it is identiﬁed as safe. Therefore, a safe algorithm can yield a higher cumulative regret when the initial safe dose is far from the optimal dose. Inter-contextual Information Transfer We investigate the efﬁciency of GP-induced smoothness in transferring information between different contexts. We mark an evident advancement in PPBG distributions and safety metrics in MME scenario compared to SME in Table 1. Examining Figure 3, we observe that ESCADA expands the safe dose set and identiﬁes the optimal dose faster in MME scenario. Notice that ESCADA recommends doses for different meal events between two consecutive recommendations for the same meal event in MME scenario. These observations suggest that information gained from a context helps improve the performance for other contexts. Besides, we Figure 3: Consecutive doseFigure 4: Consecutive dose recommendations for threerecommendations for four meal events (ME) in SMEmeal events (ME) when S and MME scenarios.is unsafe in SME scenario. observe signiﬁcant advances in the safety metrics of TACO and TS in MME scenario. However, they still incur notably worse error frequencies and risk indices compared to ESCADA and STS. Consistency Figures 2 and 5, and Table 1 reveal that ESCADA and STS yield similar results. Both algorithms employ GPs and have the same time complexity. However, random recommendations do not receive a warm reception in healthcare (Tomson and Van Der Veer, 2013). ESCADA is a deterministic and fairly interpretable recommendation model, whereas STS is inherently random. Comparison Against Clinicians We compare ESCADA’s performance against clinicians’ for ﬁve virtual patients in the simulator. For each patient, we provide the clinicians with 20 samples in the form of (meal event, insulin dose, PPBG measurement), and ask them to make dose recommendations for 20 unseen meal events. We provide ESCADA with the same 20 samples for each patient as training data and query recommendations for the same 20 test meal events. In Figure 6, we observe that the clinicians perform slightly worse than the dose calculator and ESCADA outperforms both signiﬁcantly. These results suggest that it is not trivial to make inferences about a patient’s dose-response and ESCADA is promising as a supplementary tool in the clinical setting. Moreover, ESCADA can provide clinicians with various useful statistics regarding dose responses, such as the conﬁdence region of the response, hypo-/hyper-glycemia probabilities, or probability of response residing in a speciﬁc interval for a given patient, meal event, and insulin dose. We studied a prevalent problem in medicine and proposed TACO, a novel acquisition function tailored for this problem structure. As safety is crucial in healthcare, we proposed a safe exploration strategy to render TACO safe. Combining these two blocks, we proposed ESCADA, a safe and efﬁcient learning algorithm, and provided safety guarantees and upper bounds on its cumulative regret. We discussed ESCADA’s performance and working mechanism and provided benchmarks highlighting its effectiveness over baselines to minimize the regret and meet the safety requirements. We conducted in silico experiments to compare ESCADA’s performance against clinicians’ to provide external validation and discussed its potential as a complementary instrument in clinical settings. ESCADA can also be used in other safety-critical decision-making problems where the goal is to achieve precise control of a target variable within a safe region. This study was supported in part by the Scientiﬁc and Technological Research Council of Turkey under Grant 215E342. Ilker Demirel is supported by Vodafone within the framework of 5G and Beyond Joint Graduate Support Programme coordinated by Information and Communication Technologies Authority.