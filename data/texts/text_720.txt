人工智能（AI）技术正在造福人类，但是，目 前许多 AI 系统的研发主要遵循“以技术为中心”的 理念。研究表明不恰当的 AI 技术开发导致了许 多伤害人类的事故，AI 事故数据库已经收集了 1000 多起事故，这些事故包括自动驾驶汽车撞死行人， 交易算法错误导致市场“闪崩”，面部识别系统导致 无辜者被捕等。美 国工程院院士、计 算机教授 Shneiderman将围绕“以技术为中心”还是“以人 为中心”理念开发 AI 系统的争议形象化地描述为 “AI 哥白尼革命”，提出 AI 开发应该将人类放在中 心,而不是算法和 AI 技术。 近几年来，围绕“以人为中心 AI”理念、如何 避免 AI 伤害人类以及产生社会负面影响等方面的 研究引起越来越多的重视,目前国内外还没 有形成系统化的跨学科工作框架来有效应对这些 新挑战及促进这方面工作的开展。中国国家自然科 学基金委员会在 2020 年成立了交叉学科部，在交 叉科学高端学术论坛上，受邀的 AI、人机交互 （human-computer interaction）、人因工程（human factors engineering）等专家一致认为，学科交叉 是未来科学发展的必然趋势。  在这样的基于跨学科合作理念的背景下，本文 回答以下三个问题： 与传统计算技术相比, AI 技 术带来了什么新挑战？应该如何促进“以人为中心 AI”理念在 AI 研发中的应用？从跨学科合作角度 我们应该采取什么策略？本文将进一步阐述我们 在 2019 年提出的“以人为中心 AI”（human-centered AI，HCAI）理念，系统地提出人-人工智能交互 （human-AI interaction，HAII）这一新兴跨学科 领域。希望通过倡导 HCAI 理念和 HAII 领域，促进 AI 研发造福于人类，避免潜在的负面影响。  AI 界一般认为 AI 技术主要经历了三次浪潮。 前两次浪潮集中在科学探索,局限于“以技术为中 心”的视野，呈现出“学术主导”的特征。深度机 器学习、算力、大数据等技术推动了第三次浪潮的 兴起。在第三次浪潮中，人们开始重视 AI 技术的应 用落地场景，开发对人类有用的前端应用和人机交 互技术，考虑 AI 伦理等问题。同时，AI 界开始提 倡将人与 AI 视为一个人机系统，引入人的作用。  可见，第三次浪潮开始围绕“人的因素”来开 发 AI，促使人们更多地考虑“以人为中心 AI”的理 念。因此，第三次浪潮呈现出“技术提升 + 应用开 发 + 以人为中心”的特征，意味着 AI 开发不仅 是一个技术方案，还是跨学科合作的系统工程。  2.2 智能时代的新型人机关系    AI 可以开发成具有自主化（autonomy）特征的 智能体。取决于自主化程度，AI 系统可以拥有一定 程度上的类似于人的认知、学习、自适应、独立执 行操作等能力，在特定的场景下可以自主地完成一 些特定任务，可以在一些设计未预期的场景中自主 地完成以往自动化技术所不能完成的任务。 这种智能自主化特征赋予人机系统中机器新 的角色。在非智能时代，人类操作基于计算技术， 机器充当辅助工具角色。人与 AI 系统的交互本质 上是人与自主智能体的交互。随着 AI 技术提升,自 主智能体有可能从一种支持人类操作的辅助工具 的角色发展成为与人类操作员共同合作的队友，扮 演“辅助工具 + 人机合作队友”的双重新角色。 因此，智能时代的人机关系正在演变成为团队 队友关系，形成一种“人机组队”（human-machine teaming）式合作。 智能时代的这种人机关系 区别于 PC 时代的人机交互，对 AI 研发是挑战和机 遇,研发者需要在 AI 研发中要利用这种人机合作， 保证人类能够有效控制 AI 系统，避免伤害人类。 2.3 人-非AI系统交互与人-AI系统交互的比较 人机交互是 PC 时代形成的跨学科领域,它研 究人-非 AI 计算系统之间的交互。表 1 比较了人非 AI 系统交互与人-AI 系统交互之间的一些特 征。人-AI 系统交互所具备的特征是基于 AI 系统 具有较高的智能自主化程度,有些特征目前还没实 现。从表 1 可见，与人-非智能系统交互相比，人 -智能系统交互带来了许多新特征和新问题,也给 人-智能系统交互的研究和应用带来了新机遇。 在人-非智能系统交互中，作为一种支持人类 操作的辅助工具，机器依赖于事先设计的规则和算 法。尽管人机之间也存在一定程度上的人机合作， 但是作为辅助工具的机器是被动的，只有人可以主 动地启动这种有限的合作。  AI 系统智能体具备的自主化特征使得智能体 与人类之间可以实现一定程度上类似于人-人团队 之间的“合作式交互”。在特定的操作环境中，这 种交互可以是由两者之间双向主动的、分享的、互 补的、可替换的、自适应的、目标驱动的以及可预 测的等特征所决定的（见表 1）。随着 AI 技术的发 展，未来 AI 系统将更多点地具备这些特征。 由此可见，智能时代人-AI 系统交互的新特征 以及研究的问题等已经远超出了目前人机交互研 究和应用的范围，需要一种新思维来考虑如何更加 有效地开展多学科合作来应对人-AI 系统交互以及 AI 系统研发中面临的一系列新特征和新挑战。  国外针对人-AI 系统交互的研究和应用已经展 开。例如：人-智能体交互，人-自主化交互 (human-autonomy interaction)，人 -AI 交互。 尽管这些工作各有侧重点，但是都是研究人与智能 “机器”（智能体、智能代理等）之间的交互。所以， 这 种 交 互 本 质 上 就 是 人 -AI 交互 （ human-AI interaction，简称 HAII）。目前还没有一个系统的 有关 HAII 领域的工作框架，有必要正式提倡将 HAII 作为一个新的多学科交叉领域来推动。 3.1 HAII领域的理念：以人为中心AI 近几年,当“以技术为中心”方法影响着 AI 研 发的同时，研究者也在探索基于“以人为中心”的 AI 开发方法，例如，以人为中心的算法,AI 人文设 计，包容性设计，基于社会责任的 AI。 斯坦福大学在 2019 年成立了“以人为中心 AI”   (Human-Centered AI,以下简称 HCAI) 研究中心， 目的是通过技术提升与伦理化设计手段，开发出合 乎人类道德伦理和惠及人类的 AI 系统。  许为在 2019 年提出了一个“以人为中心 AI”(HCAI)的系统概念框架，该框架包括人、伦理、 技术三个方面。Shneiderman在 2020 年提出了一 个为开发可靠、安全和可信赖的 AI 系统的指导框 架。HCAI 就是指导 HAII 新领域的理念。我们以下 进一步阐述 HCAI 理念的三个方面: 技术、人、伦 理(见图 1)。其中,图 1 概括了各方面工作的主要途 径（见图 1 中围绕三个周边圆形部分的蓝色字体）， 例如，人的需求，AI 应用场景；图 1 也概括了这些 工作要达到的 HCAI 设计目标（见图 1 中围绕“以 人为中心 AI”中心圆形部分的黑色字体）， 例如， 可用的 AI,有用的 AI。 （1）“ 技术”方面：强调 3 个部份的有机结合。 （a）机器智能: 利用算法、大数据、算力等技术来 开发机器智能;（b）人类智能：利用智能增强技术, 借助心理学、脑神经技术等方法推动人类智能的增 强（见 4.1）; (c)人机混合增强智能：AI 界已经认 识到单独发展 AI 技术的路径遇到了瓶颈效应，在 高级人类认知方 面 难 以 达 到 人 类 的 智 能 水 平 。 因此,HCAI 理念强调将人的作用融入人机 系统,通过人机智能的互补,开发人机混合增强智 能、AI 与人类智能增强技术的整合（见 4.1、4.2）。 目的是开发出可持续发展、强大、人类可控的 AI； AI 开发的目的是提升人的能力, 而不是取代人类。  （2）“人”方面：强调在 AI 系统研发中从人的 需求出发，落实有效的应用场景, 开发人类认知模 型，在 AI 研发中实施基于“以人为中心”的人机交 互设计和方法(建模、设计、测试等)。目的是开发 出有用的（满足人的需求、有使用价值）、可用的（易 用、易学）、 人类拥有最终决控权的 AI 系统。 （3）“伦理”方面：结合跨学科方法、有效开 发实践、标准和治理等工作，通过工程设计手段（如 “有意义的人类控制”， 详见 4.7），保证 AI 开发遵 循公平、人的隐私、伦理道德、人的决策权等方面 的权益。目的是开发出伦理化、负责任的 AI。  HCAI 理念强调在 AI 开发中保持人的中心地位， 贯彻技术、人、伦理三方面相互依承的系统化 AI 开 发思维，主张 AI 开发是一个跨学科协作的系统工 程， 开发出可靠的、安全的、可信赖的 AI 系统。  3.2 HAII领域的工作框架 针对 HAII 这一新兴领域,我们作出以下初步    的定义。图 2 示意了人-人工智能交互（HAII）的 领 域框架，其中，蓝色圆圈部份代表跨学科的主要合 作学科，白色长形部份代表本文所讨论的 HAII 研 究和应用的主要问题（详见 4.1 至 4.7）。 • HAII 领域理念：以人为中心 AI（HCAI）。 • HAII 领域目的：作为一个跨学科交叉领域， HAII 利用 AI、计算机科学、人机交互、人因工程、 心理学等学科技术和方法，致力于合作研发 AI 系 统，优化人与 AI 系统之间的交互，注重机器与人类 智能的优势互补，全方位考虑 AI 伦理道德,强调人 对 AI 系统的最终决控权，通过提供一个跨学科的 合作平台, 在 AI 系统开发中实现 HCAI 开发理念， 为人类提供安全、可靠、可信赖的 AI。 • HAII 研究和应用范围：狭义地说，HAII 涉及 到人与 AI 系统交互的研究和应用；广义地说，任何 涉及到由人来使用、影响人的 AI 研究发都属于 HAII 的范畴，包括与人产生交互的 AI 系统的研究和应 用领域，如智能手机应用 APP，智能人机交互技术， 智能决策系统，智能物联网等。如图 2 所示，HAII 从人-机-环境系统的角度来考虑各种因素对人与 AI 交互的影响，全面了解这些影响有助于发挥 AI 技术的优势，避免负面影响。 • HAII 领域方法：作为一个跨学科领域，通过 多学科方法（建模、算法、设计、工程、测试等） 和合作的流程来开发 AI 系统。这些方法来自这些 相关学科，例如计算模型、工程设计方法、行为科 学研究方法、人机交互设计等。 • HAII 领域人员：从事 HAII 研究和应用的人 员包括来自 AI、计算机、数据科学、人机交互、心 理学、认知神经科学、社会科学等专业人员。广义 地来说，大多数从事 AI 系统研发的人员都属于这 个范畴，他们研发的 AI 系统或多或少都与人交互， 都是为了开发出有利于人类的 AI 系统。 3.3 为什么需要 HAII新领域 首先，HAII 领域为各学科提供了一个合作平 台。HAII 有助于在一个领域名称（HAII）下，联合 参与 AI 系统研发的跨学科、跨行业专业人员，避免 易混淆的名称，这种跨学科合作有助于有效地开发 以人为中心的 AI 系统。 其次，HAII 领域强调其研究和应用的对象是 AI，不是传统的非 AI 系统，有助于提醒人们注重 AI 与非 AI 系统之间的特征差异，促使人们重视 AI 技术带来的新挑战和新问题，采用有效的方法来解 决 AI 系统开发中的独特问题。  最后，HAII 领域有助于推动 HCAI 理念在 AI 研 发中的落实。HAII 强调 AI 研发中将人的中心作用 整合到系统设计中，避免潜在安全风险问题。 历史上，新技术促进了新领域的产生。 进入 PC 时代， 传统“ 人 机 交 互 ” （ human-machine interaction）领域过渡到新版的“人机交互”（人 -计算机交互），但是此“机”非彼“机”。智能 时代的机器过渡到 AI 系统, AI 的新特征促使 HAII 新领域的产生, 因此，HAII 的出现也是必然的。 我们并不建议将 HAII 设置为一门独立的新学 科,强调 HAII 是一个新型跨学科领域，希望通过该 领域的跨学科、跨行业协同合作来落实 HCAI 理念。 例如，HAII 工作需要人机交互人员的参与，他们必 须采用新思维开展针对人与 AI 交互的研究和应用。 3.4 实现HCAI理念面临的挑战和HAII解决方案  相关学科已经开展了一些工作。为进一步阐述 HAII 领域，基于文献综述和分析，表 2 概括了当前 HAII 研究和应用的重点、实现 HCAI 理念的挑战、HAII 领域可能的解决方案、期望的 HCAI 设计目标。表 2 也引用一些实例，详细内容在本文第 4 部分讨论。 从表 2 可知, 首先,为实现基于 HCAI 理念的设 计目标，HAII 研究和应用有许多挑战期待解决。不 解决这些挑战我们就无法实现 HCAI 理念，无法开 发出安全、可靠、可信赖的 AI。 其次，表 2 轮廓出 HAII 研究和应用的范围。 目前来自 AI 和其他学科的专业人员在开展这方面 的工作，这些挑战不是单一学科可以解决的，这正 说明了 HCAI 和 HAII 工作需要跨学科的协同合作。 最后，HAII 领域采用跨学科的方法。HAII 研究 和应用的挑战、可能的解决方案以及实例都依赖于 跨学科方法（建模，工程设计，行为科学方法等）， 单一学科的方法无法有效地解决这些问题。  40 多年前，当 PC 新技术刚兴起时，开发者基 本遵循 “以技术为中心”的理念。 随着 PC 的普 及，许多用户体验问题随之出现，人们开始意识到 “以人为中心设计”理念的重要性，来自计算机科 学、人因工程、心理学的专业人员协同推动了人机 交互学科的形成和发展。多年的实践，用户体验的 理念已经在社会和计算技术界形成共识。 今天，随着 AI 技术的引进，我们又目睹了类似 情景，但是这一次忽略“以人为中心”理念的代价 对人类和社会的影响将更为严重。因此，各学科 必须再一次协同合作，推动智能时代的“以人为中 心设计”版本(即 HCAI 理念)和 HAII 领域的工作， 更加有效地利用 AI 技术，扬长避短，为人类服务。 另外，HCAI 理念和 HAII 领域定义的是 AI 开发 中应该遵循的理念、目标及途径等，并非是一个具 体模型或算法。我们强调跨学科合作，一旦明确了 这些理念、目标及途径等，AI 人员就能更加有效地 开发出实现 HCAI 理念、设计目标的模型、算法以及 技术。  依据 HCAI 理念，针对目前 AI 带来的新挑战， 我们从以下几方面分析目前 HAII 研究和应用的进 展，提出今后的重点方向。目前一些 AI 人员也在开 展这方面工作，希望 HCAI 理念和 HAII 领域的提出 能够强化这些人员的 HCAI 理念以及跨学科的合作， 也希望非 AI 人员积极参与到 HAII 研究和应用中。  4.1 人类智能增强 自 1956 年 AI 概念被提出后，研究者已经开始 致力于另一条 路径 : 智能增强 (Intelligence Augmentation，IA)。智能增强致力于增强人类智 能。研究人员利用新技术（如心理学、脑机接 口、虚拟现实），借助 AI 技术来推动智能增强的研 究和应用。 从 HCAI 理念看，HAII 领域与智能增 强具有相同目标：利用 AI 技术来增强人的能力。  AI 领域与智能增强领域之间长期存在竞争。 一些 AI 人员认为 AI 可以取代人类，而智能增强人 员认为 AI 仅仅为智能增强技术提供了新的手段。 从 HCAI 理念分析，AI 和智能增强会采用类似的技 术，追循的应该都是扩展人类智能，应该是“以人 为中心”的伙伴关系，许多智能方案其实是两种技术 的集合，HAII 可以为两者的合作起到桥梁的作用。 智能增强研究中有许多问题今后需要 HAII 领 域的贡献。首先，机器智能无法模仿人类智能的某 些维度，HAII 提倡从跨学科角度来探索哪种类型的 人类智能增强以及技术可以提供有效手段来弥补 AI 的弱点，这需要智能增强人员主动寻求来自 AI、心理学、认知神经科学、人因工程学科的支持。 其次，开发 AI 与智能增强技术最佳组合的应 用解决方案将有效促进两种技术之间的合作，从而 达到“1 + 1 > 2“的效果。HAII 领域可以起到一 个中间桥梁的作用，从人机交互、心理学等学科角 度，从人机交互方式、多模态交互兼容性、人类认 知加工水平、AI 系统自主化程度等多种维度来开发 能够支持人与智能系统有效交互的解决方案。 第三，依据 HCAI 理念，智能增强专业人员要将 人类置于系统方案的中心。 HAII 领域提倡心理学、 认知神经科学等人员积极参与研究。 例如，基于可 塑性机制, 构建认知负荷可控、及时生理反馈、体 脑双向交互的新型人机交互研究。这些研究将有效 支持在许多应用领域中训练和增强人类智能。 最后，在生物神经层面上寻找 AI 技术与智能 增强技术的整合解决方案。这是当前关注的研究方 向之一,例如，脑机融合。HAII 提倡 AI、认知神 经科学、脑成像技术、人机交互等人员合作，优化 脑机界面解决方案，通过在生物神经层面上整合 AI 与智能增强技术来探索有效的人-AI 交互手段。 4.2 人机混合增强智能  将人类的作用和人类智能引入 AI 系统将形成 人类智能与机器智能的优势互补，从而开发出更强 大、可持续发展的人机混合增强智能。  目前，针对混合增强智能的研究基本可分为两 类。 第一类是在系统层面上的“人在环路”式混合 增强智能。这种思路符合 HCAI 理念，即将人的作 用引入 AI 系统中，形成以人为中心、融于人机关系 的混合智能。例如，在“人在环路”范式中，人始终 是 AI 系统的一部分，当系统输出置信度低时，人主 动介入调整参数给出合理正确的问题求解，构成提升 智能水平的反馈回路。另一种方案是在生物学层 面上开发“脑在环路”式混增强智能，以生物智能 和机器智能深度融合为目标，通过神经连接通道，可 以形成对某个功能体的增强、替代和补偿。 第二类混合增强智能是将人类认知模型嵌入 AI 系统中，形成基于认知计算的混合增强智能。从 HCAI 理念分析，这类混合增强智能并不是真正意义 上的人机混合增强智能，因为这种系统并非能够保证 以人机系统为载体来实现人在人机系统中的中心作 用和最终决控权。当然，把人类认知模型引入到机器 智能中，对于发展机器智能是非常重要的。  HAII 领域工作将对人机混合增强智能研究和应 用发挥重要作用。首先，HAII 领域提倡心理学、认知 工程等学科专业人员的合作支持，加速现有心理学等 学科成果的转换来支持认知计算的研究，提供有效的 认知计算体系架构, 例如，为提高对非结构化视听 觉感知信息的理解能力和海量异构信息的处理效率， HAII 领域需要支持 AI 界在“感知特征的提取、表达 及整合”和“模态信息协同计算”等方面的视听觉 信息认知计算研究 法与“人在环路”方法（系统、生物学层面）整合的 工作思路。基于 HCAI 理念，这种思路有助于开发出 更强大、可持续发展的、人类可控的 AI。 第二，开展基于 HCAI 理念的人机混合智能控制 研究。针对人机混合智能系统控制，目前主要有两种 方案：“人在回路控制”和“人机协同控制”。AI 系统在应急状态时人机之间的高效切换是目前重要 研究课题。例如，自主武器系统发射后的追踪控制， 自主驾驶车应急状态下的高效人机切换。HCAI 理念 要求人拥有最终控制权，这需要 AI、人机交互等专 业人员的合作，寻找有效解决方案。 第三，开展人机混合增强智能系统的人机交互研 究。“人在环路”混合智能系统需要与用户交互的交 互设计。不同于传统人机交互，用户交互的对象是 AI 模型，用户界面难以理解，用户与 AI 交互中存在 用户意图的不确定性。HAII 研究要求 AI 专业人员 与人机交互、人因工程等专业合作，从智能系统、用 户、人机交互设计三方面优化系统设计。例如，开 发自然式交互设计，选择有效的心理模型。 最后,开展人类高级认知层面上的人机混合增 强智能研究。HAII 研究需要 AI、认知神经科学、计 算机科学、心理学等专业人员的合作。例如，进一 步探索人机融合、脑机融合等方面的研究，今后要 在更高的认知层次上为脑机智能的叠加（如学习、 记忆）建立更有效的模型和算法； 探索如何将人 的决策和经验与机器智能在逻辑推理、演绎推理等 方面的优势结合，使人机合作具有高效率。从长 远看，人机混合增强智能未来可能形成有效的人机 共生，通过个体和群体智能融合等途径，最终在 系统和生物学层面上实现人机共生和融合。 4.3 人-AI合作 智能技术带来了一种新型人机关系：人-AI 合 作，人-AI 系统作为一个组合体比单个实体的工作 更加有效。人-AI 合作的研究目前在国外是一 个热点。HAII 研究需要 AI、心理学和人因工程等学 科的合作，从感知、认知、执行三个层面上开展。  在感知层面，为了有效的人-AI 合作，AI 系统 需要人的模型来支持系统对人类状态的监控（生 理、行为、情绪、愿图、能力等）；AI 系统的人机 界面要足够透明，帮助人类了解当前系统状态。 例 如，人机之间情景意识（态势感知）分享是人-AI 合 作研究的基本问题之一。研究需要了解如何有效实 现人-AI 之间基于情景意识模型的的双向沟通, 目前还缺少针对人-AI 合作的情景意识模型和测试 方法。 今后的 HAII 工作需要丰富情景意识理论， 为人-AI 合作建模、认知架构、绩效测评提供支持。  能满足智能时代的复杂交互场景。HAII 需要构建符 合人-AI 合作的认知和计算模型。人与 AI 之间的 互信影响人-AI 合作的绩效，HAII 需要研究信任测 量、建模、修复、校正等方面的工作，以及如何量 化不同操作场景中人机之间动态化功能交换时所 需的信任。不同于传统人机交互，人与 AI 均需要彼 此感知并识别交方的意图与情感，今后研究要进一 步探索心理模型、意图识别、情感交互等模型，以 及在系统设计中如何实现和验证这些模型。  务、功能、系统等层面上实现决控权在人与 AI 代 理之间的分享。决控权的转移取决于人机双向信 任、情景意识共享、合作程度等因素。例如，在自 动驾驶车领域，HAII 工作需要研究人机控制分享范 式、人机共驾所需的情景意识分享、人机互信、风险 评估等，保证车辆控制权在人机之间的快速有效切 换，确保人拥有最终控制权（包括远程控制等）。 HAII 研究需要了解在什么条件下人机之间如何完成 有效切换，是否可以借助人-AI 合作的思路，通过有 效人机交互，提供有效的人机控制权转移。  HAII 今后的工作还应该在以下几方面开展。 首先，HAII 需要为人-AI 合作的研究开发新理论、 模型以及评估和预测人-AI 合作团队绩效的方法，这 些都是传统人机交互中没有遇到的新问题。HAII 领 域的工作要支持 AI 建模以及对建模数据的需求（例 如，情景意识，行为，意图，信任），合作开发人 -AI 合作在各种应用领域的解决方案。   层面上来研究人-AI 合作。要研究社会因素（社会责 任，道德等）对人-AI 合作的影响，研究如何让 AI 代 理担当团队角色并且与人类队友合作； 研究如何 从系统设计角度，通过合适的人机交互方式来发展良 好的人机关系（信任，情感等）； 研究如何有效支 持长期人-AI 合作（如医用机器人）。   机交互建模。与 AI 人员合作研究对人-AI 合作中人 机交互建模构成挑战的理论问题，例如，分布式认知 理论，基于上下文的知识表征和知识图谱，人-AI 合作中情感交互、社交互动等方面的认知建模。  究人-AI 合作。例如，实验室研究表明，与简单机 器人的交互可以增强人的协调性，并且机器人可以直 接与人合作；人-AI 合作中 AI 与人的认知风格、 人格特性等特性相适应时，可增强人机互信与可靠性。 今后要在真实社会环境中验证这些人-AI 社会互动， 这将有助于优化人-AI 合作的设计。 4.4 可解释AI 深度学习等方法会产生 AI“黑匣子”效应，导致 用户对 AI 系统的决策产生疑问，该效应可在各类使 用中发生，包括 AI 在金融股票、医疗诊断、安全检 测、法律判决等领域，导致系统决策效率降低、伦理 道德等问题，影响公众对 AI 的信任度。  寻求可解释 AI（eXplainable AI, XAI)已成为 AI 界的一个研究热点，具有代表性的是 DARPA在 2016 年启动的项目。该项目集中在：（1）开发或改进 ML 技术来获取可解释算法模型；（2）借助于先进的 人机交互技术，开发可解释 AI 的用户界面模型；（3） 评估心理学解释理论来协助何解释 AI 的研发。  可解释 AI 研究中的重要性。Miller的调查表 明，大多数可解释 AI 项目仅在 AI 学科内展开。 许 多 AI 人员采用“以算法为中心”的方法，加剧了算 法的不透明。一些 AI 人员没有遵循 HCAI 理念， 通常为自己而不是用户构建可解释 AI。研究还 表明，如果采用行为科学方法，侧重于用户而不是 技术，针对可解释 AI 的研究将更有效。 今后 HAII 领域的工作主要有以下几方面。首 先，研究和开发“以人为中心的可解释 AI”解决方 案。HAII 领域要从人机交互、心理学、人因工程等 方面来寻找解决方案。以往许多研究是基于静态和 单向信息传达式的解释，今后 HAII 工作要研究探 索式、自然式、交互式解释来设计可解释界面。 第二，HAII 领域提倡可解释 AI 研究要进一步 挖掘心理学等模型。尽管这些理论和模型通常是基 于实验室研究产生，可解释 AI 研究应该善于利用 这些模型，同时验证它们的可行性。HAII 的工作 可以利用本身交叉学科的特点起到一个中间桥梁 作用，加快理论转换，构建有效的界面或计算模型。 最后，HAII 领域要开展可理解 AI 的研究和应 用。可解释 AI 也应该是可理解的，可解释性是必 要条件，但 不是充分条件。从 HCAI 理念考虑，可理 解 AI 方案应满足终端用户的需求（例如知识水平）。 这方面的研究需要行为科学方法的支持以及实验 4.5 人类可控自主化 智能自主化技术正在走进人们的工作和生活， 但是已有人开始混淆自动化与自主化的概念，这可 能导致对技术不恰当的期望和误用。自动化技术 按照固定算法、逻辑和规则而产生确定的机器行为。 智能系统会拥有不同程度的类似于人的智能（自适 应、自我执行等能力），系统输出具不确定性，有 可能出现偏差的机器行为。AI 的自主化特征对安全 和大众心理等负面影响还没有引起足够的重视。 从 HCAI 理念出发，我们提倡基于“人类可控 AI”设计目标的人类可控自主化设计，即智能自 主化系统需要人类的监控，人类操作员具有最终 的决控权（通过直接或远程操控等方式）。 人因工程界已经对一些复杂领域（航空、航天 等）中的自动化系统开展了广泛的研究，已达成共 识。许多复杂自动化系统存在脆弱性，在设计 所规定的操作场景中运行良好，但是在遇到意外事 件时，可能导致操作员的“自动化惊讶”现象： 操作员无法理解自动化正在做什么，为什么这样做。  统自主化程度的提高，各单项功能的“自动化”水平 也相应提高，这可能会导致操作员对这些功能的关注 度降低，在应急状态下出现“人在环外”的现象。对 近几年发生的多起自动驾驶车致命事故调查表明，界 面模式混淆、“人在环外”、过度信任等问题正是以 往自动化系统中出现的典型问题。 智能技术中潜在的自主操作性等特征也会造成 人们对该技术产生类似于对自动化的过度信任。具有 学习能力的自主化系统意味着其操作结果的不确定 性可能以意想不到的方式发展，有可能给操作员带来 比自动化更强烈的“自动化惊讶”体验。  今后 HAII 领域的工作可从以下几方面考虑： 首先，HAII 领域要针对一些自主化的基本问题 展开研究。从人机交互角度充分理解 AI 自主化特性 对人机交互设计的影响, 研究自主化对操作员期望、 角色等的影响, 研究自主化对操作员情绪应激、认知 能力、人格特质和沟通属性的影响。 其次，HAII 领域要在自主系统开发中实现 HCAI 理念的“人类可控 AI”设计目标。目前，尽管人机交 互等专业人员参与了自主化系统（如自动驾驶汽车） 的研发，但是频频发生的事故提醒我们评估目前的方 法。SAE认为 L4-L5 等级的自动驾驶车不需要人 类监控和干预，我们质疑 SAE 忽略了自动化和自主化 之间的本质差异，可能对设计、安全、标准化和认 证等产生不利影响。高等级自动驾驶汽车是一个“移 动式”自主化系统，不是传统的自动化系统。基于 HCAI 理念，要从人-AI 合作、人机互信、态势感知共 享、自主化共享等角度探索自主化设计，实现有效的 人机共驾及交接，任何等级的自动驾驶车都需要确 保人是系统的最终决控者（包括远程控制方式）。 最后，实现针对自主化系统的“有意义的人类控 制”（meaningful human control）设计目标。 HAII 工作要落实该目标的实现：（1）通过“人在环 路”、人机交互设计，保证应急状态下人类可接管或 中断系统运行；（2）在重要的自主化系统中安装“故 障追踪系统”来实现设计改善和人机故障问责制， 推动 HCAI 理念中“人类可控 AI”设计目标的实现。 4.6 智能人机交互 智能化人机交互为 HAII 领域带来了挑战和机 遇。AI 系统丰富的应用场景和用户需求需要有效的 人机交互范式。现有人机交互方式（如 WIMP）局限 于有限的感知通道、交互带宽不足、输入/输出带宽 不平衡、交互方式不自然等问题,已有研究提出了 Post-WIMP 的范式，这些范式需要 HAII 工作的验 证。多模态融合及并行交互范式是今后 HAII 的重要 研究内容，这方面研究目前主要在 AI、计算技术界 展开，HAII 应该提供跨学科支持。HAI 还要在情境 感知、意图理解等方面取得更大突破。 人-AI 合作的新型人机关系对人机界面设计提 出了新要求。传统人机界面主要基于“刺激-反应” 理念的“指令顺序”式交互，针对智能人机交互（情 感、意图识别、上下文检测等）的多模态余度式交 互，HAII 要设计有效的人机界面来支持人-AI 合作 所需的情景意识分享、人机互信、人机控制分享等。  HAII 领域要开发针对 AI 系统的人机交互设计 标准。现有的标准主要是针对非 AI 系统，国际标准 化组织正在起草人-AI 系统交互的设计标准（ISO 9241-810），已有一些针对 AI 系统的人机交互设 计指南，但是还需要 HAII 领域的贡献。 4.7 伦理化AI设计  HCAI 理念推崇的伦理化 AI 设计目标是 AI 界 目前普遍关心的重要问题。研究表明，AI 人员在职 业培训中通常缺乏应用伦理规范进行设计的培训， AI 界已经认识到伦理化 AI 设计需要多学科的合作 。专业组织和企业已发布了多套 AI 伦理准则，但 是研究表明在 AI 系统开发中如何有效落实这些规 范有待进一步努力，一些专业人员是在开发后期而 不是过程中考虑伦理化设计。因此，HAII 领域的 一项重要工作是将伦理化 AI 设计落实在开发过程 中。 首先，HAII 领域要开展针对 AI 机器行为的研 究。2019 年 MIT 等大学的多名学者在《自然》上发 文建议开展 AI 机器行为的研究。目前从事机器行 为研究主要是 AI 人员, 没有受过行为科学的训练。 AI 机器行为的非确定性，需要从算法、数据、培训、 测试等方面来研究影响因素，避免算法偏差。目前， 已有基于 HCAI 理念的机器行为研究，例如，“以人 为中心的机器学习”、交互式机器学习等方法。 这些方法有助于在开发中解决 AI 系统极端行为、 公平性等问题。 第二，HAII 领域可采用跨学科的方法论来支持 伦理化 AI 设计，将人机交互所倡导的迭代式设计 和测评方法应用在模型算法训练中，收集算法培训 数据，定义用户预期结果并且转化成有效的输入数 据，利用早期原型开展用户体验测评，通过迭代式 设计和测试来减小算法偏差。 第三，采用“有意义的人类控制”方法将伦理 化 AI 落实在系统设计中。系统设计要保证： （1）操作员能够对所使用的自主化技术做出知情 且有意识的决策；（2）操作员有足够的信息来确保 采取合法的行动。另外，在系统设计、测试、专业人 员培训等方面采取措施来确保人类对系统的有效控 制。“有意义的人类控制”与 HCAI 理念一致，有利于 在设计中实现伦理化 AI 的目标。 最后，HAII 领域要优化 AI 的开发实践来支持伦 理化 AI 设计。研究表明，目前 AI 界缺乏有效的伦理 化 AI 设计方法论、指导设计选项的技术细节或详细 示例。HAII 领域可从“人在环路”AI、人-AI 合作 等设计思路方面提供帮助。如何将伦理化 AI 原则嵌 入到开发流程、如何提高伦理化 AI 准则对 AI 工程 师行为的影响、如何提升 AI 工程师的伦理化设计技 能等方面的问题都需要 HAII 的多学科方案。  作为一个新兴领域，在实现 HCAI 理念的实践中， HAII 研究和应用必定面对挑战。 第一, AI 人员缺乏对 HCAI 理念的理解。许多 AI 人员在开发中基本按照“以技术为中心”的理念，一 些人员认为人机交互无法解决的问题目前已被 AI 技 术解决（如语音输入）,人机界面不必考虑用户体验； 而人机交互等专业人员往往在 AI 项目产品需求定义 后才参与项目，限制了他们对 AI 系统设计的影响， 并且导致一些 AI 项目的失败。 第二，AI 系统研发中缺乏有效的跨学科合作。 AI 人员与非 AI 人员之间缺乏有效的沟通语言，非 AI 人士缺乏必要的 AI 知识，而 AI 人士缺乏对其他学 科的了解。目前，已有研究提出了基于 HCAI 理念 的 AI 与人机交互专业人员的“配对式 AI 合作开发 流程”以及提升的人机交互方法。 第三，跨学科合作缺乏有效的方法。一些人机交 互人员在 AI 系统开发中仍然采用传统针对非 AI 系 统的方法；许多 AI 人员不易接受其他学科的方法。 目前，人们已经提出了一些方法，例如，“ AI 优先” 方法、“ AI 作为设计材料”。 为有效实现 HCAI 理念和开展 HAII 工作，我们从 以下 3 个层面提出建议（如图 3 所示）。 首先，在 AI 研发团队层面，建立多学科团队和 采用跨学科方法。AI 带来的新问题只有采用多学科 合作才能找到有效方案。基于 HCAI 理念来优化现有 的 AI 研发流程，例如，在开发初期制定 HCAI 设计目 标，优化在各个开发流程节点上协同合作。 其次，在 AI 研发企业组织层面，培育基于 HCAI 理念的组织文化，制定基于 HCAI 的开发标准指南， 提供 HCAI 研发资源（跨学科人力资源、HAII 项目、 跨学科研究设备等），建立高效的 AI 研发团队。  最后，在 AI 研发社会层面，培养具备 HCAI 理 念的跨学科复合型人才。例如，在 高校开设 “AI 主 修 + 辅修”、“主修 + AI 辅修”本科专业，培养针 对 HAII 关键问题的硕博生；制定 AI 发展策略、法 规等；开展跨行业、跨学科攻关项目，提倡学术界 和工业界之间的协作；设立政府专项基金来支持 HAII 项目； 建立完善的产学研相结合的科研体系， 在一些关键行业开展 HAII 研究和应用。  一、当前的智能时代呈现出“技术提升 + 应用 开发 + 以人为中心”的阶段特征。拥有一定程度 的学习、自适应、独立执行等能力是智能技术的独 特自主化特征，赋予了机器在人机系统中新的角 色，带来了新型人机关系：人-AI 合作。与人-计算 机交互相比，人-AI 交互带来了许多新特征和新问 题，给 AI 系统研发带来了新挑战,促使我们重新评 估目前所采用的、基于非 AI 系统的研发策略。 二、为有效解决 AI 系统研发中的新挑战，本文 阐述了 HCAI 的理念，它强调三方面工作的有机结 合。（1）“技术”：提倡 AI 技术的发展策略应该注重 人类与机器智能的优势互补，将人的作用引入 AI 系 统中，从而产生更强大、可持续发展的人机混合增 强智能。AI 的目的是提升人的能力，不是取代人； (2)“人”：强调从人的需求出发，为人类提供有用、 可用、人类拥有最终决控权的 AI 系统；(3)“伦理”: 从人类伦理出发, AI 系统研发要避免产生伦理道 德等问题，目的是开发出伦理化、负责任的 AI。 三、为实现 HCAI 理念在 AI 研发中的落实，本 文系统提出 HAII 这一跨学科新领域。 HAII 领域可 以为各学科提供一个有效的合作平台，注重 AI 技 术的新挑战和新问题，有助于推动 HCAI 理念在 AI 研发中的落实，开发出安全、可靠、可信赖的 AI 系 统。 四、 针对 AI 带来的新问题，我们提出今后HAII 研究和应用的重点方向，它们包括人类智能增强技 术、人机混合增强智能、人-AI 合作、可解释 AI、 人类可控自主化、智能人机交互、伦理化 AI 设计。  五、针对今后 HAII 实践面对的挑战，从研发团 队、研发组织、研发社会环境 3 个层面上，我们建议： 设立多学科研发团队，采用跨学科方法，优化现有 AI 研发流程；培育 HCAI 理念的组织文化，开发 HCAI 标 准指南和研发资源；培养跨学科复合型 AI 人才，政 府出台相关政策和法规，积极开展跨学科、跨行业以 及关键行业领域的 HAII 研究和应用。我们展望只要 各学科和各行业一起努力，一个基于“以人为中心 AI”理念的智能社会时代将会到来。 