Villigen, Switzerland, Forschungsstrasse 111, 5232 Villigen, Switzerland, Forschungsstrasse 111, 5232 KeywordsDynamic neutron imaging (SNR) · Bubble ﬂow · Liquid metal · Two-phase ﬂow · Magnetohydrodynamics (MHD) ·Image processing·Denoising·Segmentation·Low signal-to-noise ratio Gas bubble ﬂow in liquid metal is encountered in a variety of industrial processes. Examples include liquid metal stirring, puriﬁcation and continuous casting in metallurgy, liquid metal-based chemical reactors, and more. Controlling the output of these processes is essential and it was proposed that this can be (and in some cases already is) achieved via applied magnetic ﬁeld (MF) [1–8]. Single-bubble ﬂow with and without applied MF has been systematically studied using ultrasound Doppler velocimetry (UDV) [9–12], ultrasound transit time technique [13, 14], X-ray imaging [14] and numerical simulations [15–22]. The most important features and physical mechanisms involved in single-bubble ﬂow are presently rather well known [23–28], but many aspects of bubble collective dynamics, especially in presence of MF, are not fully understood or have not been studied in-depth [29–32]. Clearly, this is a problem from the process engineering and optimization perspective, and also from the point of view of computational ﬂuid dynamics (CFD) where it is of interest to improve effective models for bubble ﬂow (Euler-Euler and Lagrangian) [2, 33–36]. Through recent efforts and the advent of dynamic x-ray and neutron radiography of two-phase liquid metal ﬂow [37–43], fundamental investigation of bubble chain systems mimicking industrially relevant ﬂow conditions is underway [1, 8, 15, 29, 30, 37, 44–47]. In bubble chain ﬂow, bubbles are released into a liquid metal system one-by-one with a uniform time delay between each, at a certain gas ﬂow rate, and ascend to the free surface of liquid metal. Such systems are usually rectangular vessels ﬁlled with gallium [1, 8, 44] or an eutectic gallium-indium-tin alloy [29, 30, 37, 45, 47] where bubbles are introduced via horizontal [8, 44] or vertical [1, 29, 30, 45, 47] nozzles at the bottom of the vessel, or top-submerged vertical [37] nozzles. Bubble chains ﬂow systems are the next logical step from single-bubble ﬂow investigations, since single-bubble ﬂow, while very informative of the bubble wake ﬂow dynamics and characteristic trajectories without and with applied MF, is not representative of the actual ﬂow conditions typical for the above mentioned industrial processes where one has columns and swarms with a high number density of deformable bubbles [48–51]. Bubble chains are still simple enough to enable experimentation with compact systems [1, 8, 44, 46, 47] and contain computationally manageable numbers of bubbles within the liquid metal volume [8, 15, 44, 46]. Meanwhile, they already exhibit collective dynamics between leading and trailing bubbles [8, 15, 44–46] and, depending on the system geometry and ﬂow rate, bubble agglomeration, coalescence and breakup can occur [29, 30, 37]. Therefore these systems are a crucial milestone in a transition from studying single-bubble ﬂow to investigations of many-bubble systems that are very close to their actual industrial counterparts. However, despite the relative simplicity, dynamics exhibited by bubble chain ﬂow in liquid metal without or with applied MF are still very complex. Depending on the gas ﬂow rate, bubbles produce unstable elongated wake ﬂow regions where periodic vortex detachment occurs and turbulent pulsations are generated – shed vortices and turbulent wakes of leading bubbles strongly affect the trailing bubbles, leading to bubble pair coupling across the ascending chain [8, 15, 44, 46, 52–55]. There exists a feedback loop involving combined perturbations of bubble shapes and within the bubble chain, surrounding liquid metal ﬂow, and the inﬂuence of the free surface at the top of the metal vessels with instabilities and oscillations in the bubble chain shape [8, 15, 44, 46, 55]. Recently, dynamic mode decomposition (DMD) has been applied to the output of the MHD bubble chain ﬂow simulation to study both large-scale ﬂow structures and bubble wake ﬂow in the bubble reference frame [56]. It was demonstrated that DMD is a viable tool for an in-depth analysis of the complex dynamics mentioned above, and it was shown that there exists a very complex interplay of bubble wake ﬂow and large-scale ﬂow modes with a wide range of spatial and temporal scales. It has become clear that specialized and rather advanced image processing methods and tools are required to extract physically meaningful data from data sets acquired via dynamic neutron and/or X-ray imaging [1, 8, 44]. This is mainly due to the low signal-to-noise ratio (SNR) associated with imaging thick ( rates& 100frames per second (FPS) and the need to resolve many often closely packed interacting objects. High frame rates are a requirement to enable capturing fast bubbles, drops and particles ﬂowing in liquid metal and to avoid motion blur [1, 8, 44]. Meanwhile, neutron ﬂux that can be used in experiments is limited by both the utilized neutron source and the rapid activation of model liquid metals such as gallium. Here we describe and demonstrate our new image processing methodology developed over the course of our dynamic neutron imaging experiments with bubble ﬂow in liquid metal. We show that the implemented code is robust and can operate reliably at very low SNR in presence of image artefacts. It is also shown that this version clearly outperforms our previous solution by resolving/avoiding known issues. In addition to demonstrating performance for dynamic neutron imaging data sets from our measurements with a rectangular gallium vessel with bubble chain ﬂow, we have also performed direct experimental validation of the code by imaging a reference spherical body, both stationary and in motion, and have quantiﬁed the shape detection errors. Bubble ﬂow imaging with and without applied magnetic ﬁeld was conducted at the thermal neutron imaging beamline NEUTRA (SINQ, PSI,20 mmaperture, medium spatial resolution set-up (MIDI) [57]. Experiments were performed with both horizontally and vertically oriented inlet nozzles. The setup with the horizontal inlet is described in [8, 44], whereas a modiﬁed version of that model gallium/argon system was designed for the new experiments with the vertical inlet – the latter will be described in a follow-up publication. A thin-walled ( glass (boron-free) vessel ﬁlled with liquid gallium up to the to the30-mmdimension of the vessel. A square ﬁeld of view (FOV, was imaged at 100 FPS. The distance between the liquid metal layer and the scintillator varied depending on the setup (magnetic ﬁeld system used, if any) and was scintillator (200 µm thickLiF/ZnS screen). Reference experiments were performed at the cold neutron beamline ICON (SINQ, PSI, NEUTRA ﬂux) to validate the developed image processing methodology [58]. A brass reference body (stationary and moving) with a central spherical cavity ( within a120.06 mmsquare FOV (a sCMOS ORCA Flash 4.0 V2 camera with a reproduce the imaging conditions for argon bubbles in liquid gallium. The reference body was imaged with neutron ﬂux directed along its shorter or longer axes. In addition, the distance between the scintillator and the body was either 0- (static body) /2 mm(moving body) or either with an extra meant to determine how the reference shape acquisition error depends on SNR which these conditions modify. For each image sequence recording at NEUTRA and ICON camera dark current signal and neutron beam proﬁle signals were recorded to be used for subsequent image normalization during pre-processing. The acquired images are 16-bit 1-channel TIFFs with a frames) with a0.11-0.12 mmpixel size ( in strong Poisson (multiplicative) noise from neutrons and converted photons, and salt-and-pepper noise of varying density is present due to overexposed (gamma ray noise) or "dead" camera pixels. The neutron beam ﬂux over the FOV is non-uniform with a fall-off near the edges of the acquired images. Figure 1a is an example of an acquired raw image. Here gas ﬂow rate was minute) and static vertical magnetic ﬁeld of following captured in a full FOV image: the liquid gallium volume within the glass container (delimited by the interior orange lines and the light blue line), the container walls (orange lines), the free surface of liquid metal (the light blue line), the surrounding air (regions outside the walls and above the metal free surface) and the neutron ﬂux shielding (the red line) for the magnetic ﬁeld system. However, not all of the FOV is of interest – Figure 1b shows the FOV cropped to the liquid metal volume in false color after pre-processing (Section 3.2). Note also the bubble regions highlighted in Figures 1a and b – these are the objects of interest that must be segmented and their properties such as centroids, projection areas, tilt angles, aspect ratios, etc. measured. Note that the same color scheme and normalized luminance scale as in Figure 1b are used in all other ﬁgures beyond this point unless stated otherwise. To illustrate the image processing challenge, Figures 2 and 3 show examples of image noise and neutron ﬂux transmission signal for bubbles after pre-processing (Section 3.2). Figure 2 shows a typical luminance distribution about a bubble region: note that here moving averages (window width in the scan direction is equal to one pixel) over (a) horizontal and (b) vertical image patches are shown, since plots over any given single pixel line would be unintelligible. Estimates from a control set of bubble regions for different frames indicate many of the images have SNR are cases with SNR as low as∼ 1.2 of the cropped FOV are shown in Figure 3. While visible in (a), it is especially evident in (b) that despite the compensation for neutron ﬂux non-uniformity over the FOV, the background "mean" is still not uniform/ﬂat. One also has rather densely packed noise peaks with luminance values comparable to the values associated with the bubbles. 4 mm) rectangular150 mm×90 mm (95 mm)×30 mm(interior dimensions) 0.12 mmfor the reference experiments). Short exposure times (10 ms) result . Similar plots for (a) horizontal and (b) vertical patches for the entire width/length Figure 1: (a) Original captured FOV after outlier removal and luminance normalization with marked container walls (orange dashed lines), the mean gallium free surface level (light blue), the neutron ﬂux shielding and bubble locations within the FOV (white). Note the scale bar in the bottom-left corner. (b) FOV in false color (color bar on the right) after cropping to the container walls and the metal free surface, dark current and ﬂat ﬁeld corrections, and normalization. Figure 2: Bubble neighborhood analysis: width mean of luminance (gray) over the length of (a) horizontal and (b) vertical patches roughly ﬁtted to the bubble region within the FOV. Normalized luminance versus pixel coordinates is shown in both cases. Note the pixel-toscale and are normalized as in Figure 1. Scan directions are indicated by the dashed blue arrows and the red curve is the total variation ﬁltered (Gaussian, regularization parameter equal to 1 [59]) gray curve. Figure 3: Bubble signal analysis for the cropped FOV: width mean of luminance (gray) over the length of (a) horizontal and (b) vertical patches roughly ﬁtted to the bubble dimensions, spanning the FOV. Note the scale bar in (a). Resolving gas bubbles ascending in liquid metal mmscale bar in (b). Bubble neighborhood patches shown in (a,b) are not to Estimates indicate that Eötvös number is Re ∈ [10; 10]. This corresponds to a ﬂow regime wherein bubbles have oscillating elliptic shapes [8, 24, 44, 60]. Bubbles have equivalent diameters of range [44]. Such velocities and dynamic phase boundaries dictate the high acquisition frame rate required for physical analysis. 100 FPS was considered the optimal trade-off frame rate for the experiments covered herein in that one already avoids signiﬁcant motion blur about the bubbles while still maintaining manageable image SNR. Bubbles ascend in vertical chains from the bottom of the gallium vessel to the free surface where they exit the liquid metal volume. Bubbles generally exhibit non-uniformly accelerated motion depending on the applied magnetic ﬁeld and ﬂow rate. Bubble trajectories are mostly planar zigzags (plane parallel to the largest container face) with slight out-of-plane perturbations that intensify with gas ﬂow rate. Bubble collisions, coalescence or breakup do not occur for image sequences considered in this paper, but rather chains with closely packed bubbles manifest for higher ﬂow rates. In the future, the methodology developed herein will also be applied for even higher ﬂow rate cases where bubble collisions do take place. The results obtained via the previous version of our image processing code [8, 44] determined the objectives that must be met here: 1. Improved bubble edge detection stability – more reliable detection, less artefacts and false positives 2. Greater bubble shape detection precision 3. Increased bubble detection rates at the bottom of the FOV The following assumptions regarding the bubbles are in effect: • Bubbles have perturbed elliptic/circular shapes, i.e. not necessarily convex. •Bubble phase boundaries do not exhibit local curvature radii less that a pre-deﬁned fraction of their mean • No coalescence or breakup of bubbles is expected at ﬂow rates < 500 sccm considered herein. In addition, the development of the methodology outlined herein was subject to the following considerations: •Given the image properties/quality as described in Section 2.2, we do not attempt to perform ﬁltering & •Since the 100 FPS frame rate is the lower limit for prevention of considerable motion blur, we do not employ •Furthermore, given the above and to make our methods more general, we treat image sequence frames To achieve the above goals, it was decided to separate the bubble segmentation into two stages: global and local ﬁltering/segmentation. That is, one starts by obtaining ﬁrst estimates for bubble segments within images (the entire cropped FOV), and then uses a separate routine for local ﬁltering/segmentation about the preliminary segments to improve shape detection precision at local scales (i.e. lower-wavelength corrections to ﬁrst shape estimates) and to resolve false positives. The global ﬁltering/segmentation routine, which is essentially a completely overhauled version of our previous image processing approach [8, 44], was designed and adjusted to maximize bubble detection rates at the cost of reduced shape detection precision and higher false positive rates. Further, to improve edge detection stability, we have opted for implicit edge detection. Global noise ﬁltering is performed in multiple stages, each targeting a certain noise type and/or wavelength range. As for the local ﬁltering/segmentation routine, a recursive multi-scale analysis algorithm was implemented that is shown to perform well even for images with especially low SNR and recovers bubble shapes in cases where the ﬁrst segment estimation outright fails to capture initial bubbles shapes within an acceptable margin of error. The overall structure of the proposed image processing solution is outlined in Algorithm 1. Resolving gas bubbles ascending in liquid metal d∈ [6; 8] mmand travel with varying velocities usually in the[20; 40] cm/s Algorithm 1: Overall structure of the new image processing pipeline Input: Raw image sequence Output: Centroids and shape parameters for bubbles detected in each image Image pre-processing is performed in ImageJ as shown in Algorithm 2). Algorithm 2: Pre-processing for raw images Input: Raw image sequence: 16-bit 1-channel TIFFs, 1024 × 1024 pixels Output: Dark current and ﬂat-ﬁeld corrected normalized images Images as cropped as indicated in Figures 1a and b. Dark current compensation is performed by subtracting the mean projection of 5K-10K recorded dark current noise images from all images in the raw image sequence (typically 3K-9K images). Then the dark current-compensated ﬂat ﬁeld is computed from the mean projection of 5K-10K neutron beam ﬂux distribution images. Afterwards the dark current-compensated FOV images are normalized with respect to the ﬂat ﬁeld compensated for the dark current. These corrections for the cropped raw FOV images can be expressed as whereIare the luminance maps of the corrected images, the dark current and neutron beam ﬂux images. This correction results in the spatial dependence of the SNR as a consequence of less neutrons detected behind the sample compared to the open beam. Afterwards, bright outliers are removed using median thresholding with a 1- to 2-pixel radius. The threshold is chosen such that outlier removal modiﬁes only the pixels where luminance by far exceeds the local median (within the designated radius). Pixels with luminance above the threshold are then assigned the local median values. Finally, the images are normalized and saved, then passed to Wolfram Mathematica for further processing. First segment estimates are obtained using an algorithm referred to in this article as the global ﬁlter, which is outlined in Algorithm 3. Segment estimation is performed in three stages – noise ﬁltering & background removal, implicit edge detection and segment ﬁlling & cleanup. Noise ﬁltering is done as follows. First, Perona-Malik (PM) ﬁltering is performed on an input image whereby the following non-linear diffusion partial differential equation (PDE) is solved over the image luminance map time t with Neumann boundary conditions (BCs) [61]: whereI = I(~r, t),f(I, α)is the diffusion coefﬁcient and image.f(I, α)prescribes anisotropic diffusion by restricting luminance diffusion across sharp edges. The number of PM iterations,αand the gradient Gaussian regularization width Algorithm 3: Global ﬁrst segment estimator for pre-processed FOV images Input: Normalized pre-processed images (Algorithm 2) Noise ﬁltering & background removal Output: • Image mask with ﬁrst segment estimates • Memoized SSCF-ﬁltered image for later use in Algorithm 4 • Memoized SCTMM-ﬁltered image for later use in Algorithm 6 chosen such that the PM process only acts on very small-scale noise structures – Equation (2) is edge-preserving – and it is mainly aimed at removing the remainder of the salt and pepper noise due to bright and dark outliers that survived pre-processing (Algorithm 2). Note that where Kis a Gaussian kernel with its standard deviation σ. In the case of our images, we found that is productive to set α to the 0.5 quantile of |∇I| in I Next, the total variation (TV) ﬁlter is applied assuming Poisson noise (typical for low-SNR underexposed images as in this case) by solving the following PDE with Neumann BCs [64]: where the regularization parameter and input/output similarity preservation. Solving (4) over virtual time a stationary (with respect tot) ﬁltered image. The TV ﬁlter is set up such that it eliminates noise structures up to a fraction of the length scale of bubbles on the order of bubbles while avoiding overly distorting the luminance map. In our case, we ﬁnd that setting β ∈ [0.8, 1] and limiting the number of TV iterations to 100 [65] yields better results. The third stage is the application of the self-snakes curvature ﬂow (SSCF) ﬁlter. Here the following PDE is solved with Neumann BCs [66]: whereg(I, γ)is the curvature diffusion coefﬁcient and diffuses local luminance curvature, not luminance itself. It is also edge-preserving. The number of SSCF iterations and γare set such that the SSCF ﬁlter eliminates any remaining sharply localized luminance maxima about the bubbles since there the luminance curvature is the greatest; at the same time, ﬁltering must preserve bubble region contrast with respect to background. For our images we ﬁnd that in some cases one may set γ → ∞, which simpliﬁes (5) to (~r), and to set σ = 1 and the number of PM iterations to 5 [62, 63]. βdetermines the balance between noise ﬁltering (pixel value variation minimization) which is the mean curvature ﬂow PDE. However, other cases require anistropic curvature diffusion and then we set the 0.5 quantile of |∇I| in I(~r) as with the PM ﬁltering. The number of performed SSCF iterations is set to 7 [67]. The next stage is the soft color tone map (CTM) masking (SCTMM) which is a non-linear ﬁlter designed to clean up the image background by removing large-scale artefacts left over after denoising and to further separate background from bubbles while avoiding excessive erosion of the bubble regions. The large-scale structures in the background were actually one of the sources of the edge detection instability in the previous approach, especially for low-CNR images with higher bubble number density where bubble detection was often outright impossible due formed edge artefacts that could not be reliably removed. Given a normalized original image x, the SCTMM background correction generates a new image y: whereCTM(x, c)is the CTM operation and (in this case the gray-scale values) of the image using gamma compression with a global compression factor idea behind SCTMM (7) is as follows. A pure distances between the nearest luminance values (input would be much more distant from the mid-range luminance values, which are affected the most. If one masks or lowers the values of certain pixels within one of the images to a "hard" binary mask) that would shift the pixels with reduced values in luminance range, ideally making them background. Soft masking is preferred here because masking using binarization and then replacing the removed background using luminance interpolation or other methods will generally produce artiﬁcial and potentially very pronounced edges and/or reduce the contrast of actual edges. Here it is required here thatxis such that background and post-ﬁltering artefacts are removed, and bubble contrast is enhanced while bubble features are eroded as little as possible. It was decided to opt for additive masking of the form x(x) = x − mask. An invertedCTM(x, c) have high luminance for background and denoising artefacts since values. This wayx= x − (1 − CTM(x, c)) The resulting product (7) then has the desired properties and emphasizes the bubbles while reducing the impact of image artefacts. For the images considered here c = 0.5 generated better results. Another major change is the substitution of explicit segmentation and edge detection with an implicit procedure. The SCTMM output is normalized and passed to the gradient ﬁlter (luminance gradient magnitude map of a Gaussian kernel convolution (3) for an image; the Bessel derivative kernel is used) which estimates bubble edge regions (halos) in the image. The halos are segmented using double-threshold hysteresis binarization (pixel corner connections enabled) [69] and then the edge estimates are obtained using the thinning transform [69] (exploiting the edge gradient symmetry). Optionally, morphological erosion [70] can be applied to the halo segments before thinning, which is suggested if thinning outputs jagged edges. Finally, bubble shape masks are generated by applying the ﬁlling transform [69] followed by a small-radius mean ﬁltering. The advantage of this procedure is that it is more stable and does not require edge/area repairs for bubble edges/masks. Afterwards, small-radius (2-3 pixels) mean ﬁltering step followed by Otsu binarization [71] ensures that the edge dendrites that are occasionally left over at the ﬁlled bubble shape boundary are pruned – this is much computationally cheaper than morphological pruning, which would also generally require multiple iterations to converge to edges that are Jordan curves immune to the pruning transform. The gradient ﬁlter regularization kernel scale is set to roughly match the bubble scale (Section 2.3). The primary threshold for the hysteresis binarization of edge halos is by default 0.35, though it had to be reduced to secondary threshold is computed using the Otsu method. In our case we perform morphological erosion using disk structural elements with a 5-pixel radius. Finally, we remove segments that are in contact with image boundaries – this is because only bubbles that are fully within the FOV are of interest. Resolving gas bubbles ascending in liquid metal y = x ∗x − (1 − CTM(x, c))(7) was chosen as mask because, if the rightcvalue is set,1 − CTM(x, c)will 0.25in some cases where the image quality was especially problematic. The 3.4 Multi-scale recursive interrogation ﬁlter (MRIF) The ﬁltering methods utilized in Algorithm 3 are rather aggressive. Testing revealed that, while bubble detection rates are indeed signiﬁcantly higher than before and bubbles are detected everywhere within the FOV, it comes at the cost of decreased shape resolution precision and a higher false positive rate. The former is very important for a more in-depth analysis of the effects of varying ﬂow rate and MF on the behavior of bubble chains. It was decided to ﬁne-tune the global ﬁlter such that the bubble detection rates are maximized and good ﬁrst estimates of bubble shapes/sizes are obtained, and complement it with a routine that would use the ﬁrst estimates to generate more precise bubble shapes and efﬁciently ﬁlter out false positives. To this end, we have developed an algorithm for iterative segmentation reﬁnement – the multi-scale recursive interrogation ﬁlter (MRIF) outlined in Algorithm 4 and schematically illustrated in Figure 4. Algorithm 4: Multi-scale recursive interrogation ﬁlter (MRIF) Input: • An image mask with ﬁrst segment estimates (Algorithm 3, Step 12) • The global SSCF ﬁlter output (Algorithm 3, Step 3) while L/L < ε, ε > 1 (user-deﬁned) do Map the global SSCF ﬁlter output onto the segment IW Perform local ﬁltering (Algorithm 5) if updated segments were found then Deﬁne new IWs (side length L Redeﬁne preceding IW scales as L else Output: • Updated bubble shape masks for the FOV • Converged IWs for later use in Algorithm 6 The key idea is to deﬁne interrogation windows (IWs) about the initially detected bubbles to exclude irrelevant parts of the image and its intensity histogram from the analysis. This also helps to reduce the inﬂuence of any remaining ) for the updated segments based on their areas and centroids (8,9) artefacts left over from the global ﬁltering. Especially for images with lower SNR and with closely packed bubbles, it may be the case that the initial segmentation is poor, i.e. two or more bubbles have been segmented as one due to the surrounding artefacts, or a bubble was connected to large-scale artifact structures, forming a large segment that obscures the true object. This means that an appropriate local ﬁltering algorithm must be devised for IWs. However, a single local ﬁltering pass may not be enough for various reasons, e.g. what might appear visually as a poorly segmented bubble at the scale of the current IW might actually turn out to be, after local ﬁltering, multiple bubbles – these would then each require another pass at a ﬁner scale. This means that in general a series of consecutive interrogation passes could take place. Thus, MRIF performs object ﬁltering at different scales, effectively checking that the segments have been properly resolved by the global ﬁlter and/or in the preceding local ﬁltering iterations. A stopping criterion based on the IW size similarity between iterations makes sure that MRIF recognizes that it only makes sense to re-ﬁlter an image patch if the object is signiﬁcantly smaller than the previous IW, since in this case the ﬁner shape features may have been under-resolved. MRIF consists of several components: an IW generator that centers the IW at the segment location and adjusts its size according to the segment size; a local ﬁlter that is responsible for ﬁltering within IWs; a recursive routine that performs a "scale descent" and converges to the "true" segment scale starting from the ﬁrst estimates; a procedure that collects the ﬁnal, updates segments and maps them onto the original bubble segment mask, substituting the ﬁrst estimates. The criterion is the stopping factor that controls recursion depth, i.e. the lower IW scale threshold. In our case good results. The MRIF core components are described in detail in Sections 3.4.2, 3.4.3 and 3.4.4. 3.4.2 Interrogation windows (IWs) IWs are square windows with side length L which is determined for segments as follows: whereSis the segment area in pixels and segments. Given L and the segment centroid ~r = (x, y), an IW is deﬁned by pixel coordinate intervals: SinceLfor the entire image is required for the ﬁrst iteration of MRIF and one should always perform local ﬁltering at least once for every initial segment, here one can set (Algrithm 3, Step 3) ands≥ 1is an arbitrary scaling factor such that iteration. Note that in general an IW may be out of the image bounds – for this reason, two IWs are generated for a segment at every MRIF iteration: a virtual IW deﬁned by (9), and a real IW given by soIWis not necessarily square. To reiterate: the current ﬁltering scale is deﬁned by the IW scale output is mapped ontoIW. For simplicity, stated otherwise later. We observed that for our images s ∈ [2; 2.5] yielded better results. The local ﬁlter used for recursive ﬁltering in MRIF (Algorithm 4, Step 3) has elements similar to the global ﬁlter, but with important distinctions. It was designed to be less aggressive because MRIF ensures that only the crucial background context from the image is retained within an IW, e.g. the somewhat destructive SCTMM is not required. The local ﬁlter operates on an IW as described in Algorithm 5. Here the mean ﬁltering radius is a fraction of the expected bubble scale – this is to avoid averaging out the ﬁner shape features. The ﬁltering radius is set based on the expected lower threshold for bubble surface perturbation wavelength. The gradient ﬁlter regularization kernel (3) scale was set equal to the mean ﬁltering radius. Chan-Vese binarization is a variational method for object segmentation in images that does not explicitly utilize edges. It is generally more robust than edge- and histogram-based methods (e.g. Otsu, Canny [71, 72]) but is more computationally expensive [73]. However, this can be afforded relatively easily in the case of IWs that are only a Resolving gas bubbles ascending in liquid metal sis a user-deﬁned scale factor, i.e.Lscales with the equivalent radii of bxe −2; bxe +2,bye −2; bye +2(9) Algorithm 5: Local segment reﬁnement for IWs Input: Global SSCF ﬁlter output (Algorithm 3) mapped onto an IW Output: Updated local shape estimate fraction of the original images. Chan-Vese two-level segmentation works by assigning the following functional to an image (in this case single-channel) and minimizing it iteratively [73]: with respect toC, whereCis the set of segment contours, ν,λandλare the control parameters. The Chan-Vese process is typically initialized by deﬁning image area is covered with a checkerboard of small circular contours of adjustable size, preferably very ﬁne [73]. Two regions within an image are deﬁned: areas within Minimizing (11) has several effects on discrepancy between the region luminance values and the region averages (terms 3 & 4) are reduced – the relative prevalence of these effects is dictated by [73]. Optimization is performed for a certain number of iterations, generally resulting in the uniﬁcation/dissolution of the initial disjointCcomponents until, ideally, process also guarantees that C is a set of Jordan curves. Minimization of (11) can be performed by solving the following PDE with respect to the level set function with the BC deﬁned for ∂D : D = D∪ D. Here ϕ = ϕ(~r, t) with |ϕ| = 1, ~n is the outward boundary normal, and δ(, ϕ) is the level set regularization function ϕ(~r, t) is initialized as whereλdetermines the wavelength of the initialized checkerboard pattern. Equation (12) with (13) and (15) is then solved iteratively by alternating between updates for hIi In our caseµ = 0.03,ν = 0,λ= λ strategy leading to fast convergence, but we have observed that + λI(~r) − hIidS+ λI(~r) − hIidS; C = ∂D(11) C: their combined length (term 1), area ofD(term 2), as well as the total µ,ν,λandλ.Cis deﬁned as the zero crossing of a special level set function µ · ∇|∇ϕ|− ν − λI − hIi+ λI − hIi(12) ϕ(~r, 0) = sinπxλ· sinπyλ(15) = 1and = 1. As indicated in [73], (15) withλ= 5is a good initialization quality degradation in our cases. The reason Chan-Vese instead of Otsu or hysteresis binarization is used is that the former exhibits much stabler edge halo detection in IWs and is not explicitly tied to image histograms (i.e. does not only minimize inter-class and maximize intra-class variance for the level sets like the Otsu method) which can be very different across IWs. Once binarization is complete, one performs the same sequence of operations as with the global ﬁlter (Algorithm 3, Steps 7-12). For local ﬁltering, erosion for segments is performed with 1- to 5-pixel radius disk elements and the mean ﬁltering (cleanup) radius is 1-3 pixels. Centroids are mapped from converged IWs onto original images (full FOV) using the following transformation: where~ris the updated centroid location in the FOV, coordinate system,~ris the location of the virtual IW center in the FOV, coordinate system and~Λ(L, ~r)is the IW crop correction for and IW’ both always contain the segment (if any detected) and their centers are always within the FOV, for an IW fully within the bounds of the FOV one simply extends a radius vector and then from that to the bubble centroid via of bounds, then the actualIW(Figure 5b) has a different center coordinate when the IW is cropped (10). The crop correction given an image z is as follows: as a separate step because the IW coordinate system origin is not necessarily within the FOV. Figure 5: Coordinate mapping from IWs onto the full FOV for objects detected in IWs: (a) transformation from the IW coordinate system to the image coordinate system and (b) crop correction for the IW center coordinates within the FOV. In (a) the circle represents the object detected in the IW (dark gray square). In (b) the yellow area indicates the out-of-bounds part of the virtual IW. The MRIF procedure, in addition to its intrinsic false positive ﬁltering capacity stemming from the recursive multi-scale analysis, is supplemented by a dedicated false positive identiﬁcation algorithm that processes the segments output by MRIF. The procedure is outlined in Algorithm 6. Algorithm 6: Luminance map-based false positive ﬁltering for MRIF output Input: • Updated bubble shape masks for the FOV (Algorithm 4) • Global SCTMM ﬁlter output (Algorithm 3, Step 4) • Converged IWs (Algorithm 4) if hIi · max(I) < η; η ∈ [0; 1] (user-deﬁned) then Output: FOV bubble shape masks without detected false positives Algorithm 6 exploits the observation that SCTMM applied locally to the global SSCF ﬁlter output mapped onto converged IWs should produce very strong intensity maxima and an overall higher intensity in the segment region in the case of a true bubble while the opposite should hold for false positives. The product of mean and maximum intensity is used so that neither of the two criteria alone are enough to pass the ﬁlter, since it might be the case that a region with an otherwise background level intensity might exhibit a tightly localized intensity maximum; similarly, mean intensity ﬁltering alone is not enough since a bubble should have a strong maximum of transmission intensity about its centroid, which in itself is not as strongly correlated to the mean intensity. Another way to interpret this is that, if the maximum and mean thresholding have certain probabilities of accepting a false positive, then the max/mean product thresholding has a false positive acceptance probability at least lower than the greater of the two components. Note that Algorithm 6 uses a luminance compression factor minimizing true positive elimination) when η ∈ [0.1; 0.125]. After ﬁltering the MRIF output using Algorithm 6, all properties of interest are measured for all remaining bubble segments and logical ﬁlters can be applied for further false positive elimination. In our case logical ﬁlters check for implausible bubble coordinates, sizes and aspect ratios and remove the outliers from the dataset of measured bubble shapes. Finally, the resulting data can be post-processed and interpreted. Figure 6 shows the effect of subsequent operations that the global ﬁltering routine (Algorithm 3) performs for a preprocessed image. The difference between Figures 6a and 6b is that the noise with low wavelengths (sharply localized luminance maxima and minima left over from pre-processing) have been eliminated. Next, the TV ﬁlter (Figure 6c) consolidates the high luminance values within the bubble regions (white dashed circles), increasing the SNR for the bubbles. Also, noise is signiﬁcantly damped and the wavelength of its features is increased even more. However, the TV ﬁlter does not remove the sparse larger-scale luminance maxima still seen in Figure 6c in the background between the bubbles as efﬁciently as it is desired without degrading the CNR for the bubbles. This function is performed by SSCF (Figure 6c) which speciﬁcally diffuses the leftover intensity maxima, increasing bubble SNR (and CNR due to reduced noise in the background) further. In the case of Figure 6 one has neighborhood’s transformations is shown in Figure 7 where one can visually notice that bubble CNR is increased by SSCF (d) and that intensity maxima are indeed eliminated from the background. A more detailed analysis of how how noise ﬁltering stages affect the image and the bubbles can be seen in Figure 8 where a vertical strip containing both bubbles is taken from the images in Figure 6 and their relief plots (a) and mean luminance proﬁles (b and c) are shown. Resolving gas bubbles ascending in liquid metal c = 0.5for SCTMM. We found that false positives are efﬁciently ﬁltered (i.e. also Figure 6: First segment estimation stages (Algorithm 3): (a) original pre-processed (Algorithm 2) image; (b) PM-ﬁltered image; (c) Poisson TV-ﬁltered image; (d) SSCF-ﬁltered image; (e) SCTMM output; (f) gradient ﬁlter output (edge halos); (g) hysteresis-segmented edge halos (prior to erosion); (h) bubble masks obtained after erosion, thinning, ﬁlling, small-radius mean ﬁltering, Otsu binarization and border component removal. The color scheme is as in Figure 1. Figure 7: Effects of global ﬁltering (Algorithm 3) on the luminance map of the neighborhood of the lowermost bubble in Figure 7 indicated by a white dashed circle: (a) neighborhood projection of the original pre-processed image; (b) PM-ﬁltered; (c) Poisson TV-ﬁltered; (d) SSCF-ﬁltered; (e) SCTMM output; (f) gradient ﬁlter output (edge halos). With SNR increased by the sequence of PM, TV and SSCF ﬁlters, SCTMM is now applied to increase the CNR – this is especially clearly seen in Figure 8c where one can see that SCTMM signiﬁcantly ﬂattens the background while preserving bubble signal intensity, as intended. This enables the gradient ﬁlter to produce bubble edge halos with an even greater CNR (note the high depth of the halo "wells" in Figure 8a-6, which extend well below the binarization threshold, down to background luminance levels), enabling clean segmentation, as seen in Figure 6g. Figure 8: The effect of ﬁltering stages on bubble signal versus noise and background: (a) pseudo-3D shaded relief plots of strips taken from Figures 6a-f (sub-ﬁgures 1-6, respectively) containing bubbles and background in between; (b) mean luminance proﬁles over image strips (1-4) in the direction indicated by a blue dashed arrow in (a) for pre-processed, PM-, TV- and SSCF-ﬁltered images; (c) mean luminance proﬁles for SSCF-, SCTMM- and gradient-ﬁltered strips (4-6). Note that all luminance proﬁles in (b) and (c) have been normalized for direct comparison. The ﬁrst segment estimator could have been enough for bubble shape extraction, when tuned appropriately, if not for the fact that the image considered in Figures 6-8 is one of the better examples in terms of noise and artefacts present, i.e. a considerable portion of the images captured in our experiments are of a much poorer quality. Not only are the obtained shapes often imprecise or deformed, they can at times be decidedly non-physical – one such example is show in Figure 9 where in (a) a segment is shown that looks like two bubbles that are in the process of merging. Figure 9: Updating a ﬁrst segment estimate using the local ﬁlter (Algorithm 5): (a) ﬁrst estimate in an IW; (b) original pre-processed image projected onto the IW; (c) SSCF output projection onto the IW (Algorithm 3); (d) mean-ﬁltered SSCF output; (e) gradient ﬁlter output; (f) Chan-Vese segmentation output; (g) edges extracted via erosion and thinning; (h) updated local segment for the IW. Segment ﬁlling and cleanup are similar to what is done in Algorithm 3. Such events are not expected at the ﬂow rate for which this image was acquired, therefore Figure 9a shows an obvious artefact. The bottom-right corner of (b) contains closely packed high-luminance spots which likely have been combined and merged with the bubble region in the upper-left corner. However, once MRIF targets the segment and the local ﬁlter Resolving gas bubbles ascending in liquid metal is applied to the SSCF output projected onto the segment IW (c) in stages (d-h), the artefact is no longer present and a single bubble is correctly resolved. In addition to such artefacts, since the global ﬁlter was tuned to maximize the odds of detecting bubbles in the FOV, there are cases where detected segments are false positives. Two instances of such segments interrogated by MRIF are shown in Figure 10. In (a) one can see that the local ﬁlter has revealed that there is indeed no segment contained within the IW. Figure 10: Instances of false positives revealed by MRIF with (a) no local segments found and (b) an artefact (purple outline) that will be eliminated later by Algorithm 6 based on the segment luminance map. Sub-ﬁgures (1-9) in (a) and (b) are: (1) is the original image projected onto an IW; (2-7) are the respective local ﬁltering stages (Figure 9c-h); (8) is (1) with detected edge overlays; (9) is SCTMM applied to (2). However, interrogating the false positives in an IW might on occasion produce segments yet again, as in (b), where the gradient ﬁlter stage (b4) generated a structure that resembles a bubble edge halo. It was then segmented and, through edge cleanup, transformed into a segment that seems eligible – but simply overlaying it over the original image projected onto the IW, one can see that this is not the case. However, MRIF effectively performs a two-factor false-positive check, and in such cases the luminance map-based ﬁlter (Algorithm 6) serves as a backup. Once the global SCTMM output is projected onto the IW and SCTMM is applied to the resulting image (b9), one can see that the segment overlay contains only background, and thus this false positive will be eliminated since it has hIi · max(I) < η. An example containing several instances of false positives, under-resolved shapes and bubble regions merged with noise patterns is shown in Figure 11. Notice that the image quality, even visually, is much worse than in Figures 6-8. The artefacts in the upper part of the image stem from lower CNR in (b), whereas one of the bottom artefacts comes from a noise structure in the background that resembles a bubble. However, as seen in (d) and (e), MRIF successfully removes all false-positives and artefacts while improving the shape estimates. An even more difﬁcult case is seen in Figure 12 where very large segments appear. The largest one in the upper part of (c) has occluded two of the four bubbles visible in (a-b). This is also an instance where the crop correction (17) is signiﬁcant for remapping the updated segments onto the FOV (16). MRIF successfully resolves bubbles from the ﬁrst estimates, as seen in (d-f). Notice the segment in the bottom-left part of (e) and (f) – its luminance map contains background only, so it will be later eliminated by Algorithm 6. To see how MRIF iteratively resolves cases like the above two examples, consider Figure 13 where the updates for the ﬁrst segment estimates are shown for MRIF iterations. One can see in (e3) that the SNR and CNR are even worse than in the cases shown in Figures 11 and 12. The largest segment seen in (e1) and (a1) is ﬁrst resolved into two bubbles (b1) and then each bubble is interrogated once more, obtaining more precise shapes. The bottom-most segment in (e1) requires the most MRIF iterations – the ﬁrst two, (b3) and (c3), remove portions of the artefact that had obscured the bubble, and the last iteration (d) updates the resolved shape. The resulting bubble shapes are then mapped onto the FOV as indicated in (b-e). Figure 11: An example of segmentation improvement by MRIF: (a) horizontally cropped pre-processed image – note the very low CNR in the upper half of the image; (b) global SCTMM ﬁltering result; (c) ﬁrst segment estimates; (d) updated segments output by MRIF; (e) output segment overlays for (a). Note that the top- and bottom-most segments from (c) are not present in (d) and (e) – this is the correct behaviour, since one can visually see in (a) and (b) that the corresponding bubbles are partially outside of the FOV, and thus are not eligible for analysis. Figure 12: Another example of MRIF resolving initially occluded and incorrectly detected segments. Sub-ﬁgures (a-d) and (f) correspond to Figures 11a-e, respectively, and (e) shows the MRIF output overlays for the global ﬁlter output. The false positive in the bottom-left corner of (d-f) that survived MRIF interrogation will be eliminated by Algorithm 6, since it corresponds to background (e). Here it is important to reiterate that the performance of MRIF strongly depends on the user-deﬁned IW scaling factor s(8) and the critical IW length scale ratio theχ = s/εratio is of interest – we suggest same for all image sequences acquired under similar conditions, enables MRIF to efﬁciently "strip" the ﬁrst segment estimates of artefacts and perform one ﬁnal update for the resolved bubbles, as in Figures 13a-3 - 13d. Here for examples shown in Figures 11-13, with determine thesvalue which gives the best performance for the local ﬁlter, also adjusting the settings for the latter – this will determine a starting value for  before further optimization. Figure 13: An illustration of the iterative interrogation process for an image with one of the worst overall SNR values, whereRis the MRIF recursion depth. Sub-ﬁgures (a-d) show depth. Sub-ﬁgure (e) displays (1) the initial segments, (2) MRIF output and (3) output overlays for the original image. Converged segments are ﬂagged with green ticked boxes. Colored frames in (e2) correspond to (b2), (c1-2) and (d) via respective colors. Orange frames in (e1) indicate the IWs at virtual counterpart is signiﬁcantly out-of-bounds and therefore considerable crop correction (17) is assigned to properly map (c1-2) onto the FOV. Aside from the examples shown in Sections 4.1 and 4.2, it is also of interest how the developed approach performs for entire image sequences in terms of bubble detection density in the FOV and the physicality of obtained results, i.e. bubble trajectory and shape properties. Figures 14-16 demonstrate the differences in performance for the preceding image processing pipeline [8, 44] and the methodology presented here. One can clearly see in Figure 14 that the new version of the image processing code outperforms the previous version by completely avoiding the blind zones in the lower part of the FOV for both image sequences. Notice also that bubble tracks visible in (b) are much more coherent than in (a). Figure 15, in turn, shows that with the new methods one can now clearly resolve the classical S-shaped mean trajectory cluster formed by zigzag trajectories, as seen in (c) and (d), as opposed to (a) and (b) where a signiﬁcant portion of the events is missing. The deﬂection bias in the in (c) and (d) is determined by the horizontal inlet releasing gas in that direction. Another point of interest are the tilt angle dynamics resolved in [8] versus the current results – this is showcased in Figure 16. Three things are important to note here: ﬁrst, as a consequence of the blind zone elimination, the new curves extend all the way through the FOV; second, the average trends yielded by both approaches indicate that the previously used code indeed resolved the dynamics without unacceptable inaccuracy; third, the error bands are considerably narrower about the averaged curves for the present results. The latter is especially true for the case with applied MF Resolving gas bubbles ascending in liquid metal εfor the latest and the (potential) next recursion iterations. Speciﬁcally, s = 2.5andε = 2. Before adjustingχ, we would recommend that the user Figure 14: The locations of bubbles detected in the FOV for a sequence of 3000 images (30 seconds) at a ﬂow rate for the model system from [8, 44] (Section 2.1, horizontal inlet): no applied MF, (a) previous and (b) current image processing code; applied∼ 265 mT locations are marked with dots color-coded in the chronological order of appearance. Note the color legend in (d): imaging starts at 0 and ends at 1. The red-tinted areas indicate the blind zones of the previously used image processing code. All sub-ﬁgures are to scale. Figure 15: Normalized bubble detection density histograms with counts: (a-b) the case in Figure 14a with (a) all bins and (b) bins with 3+ detections shown; (c-d) the case in Figure 14b with (c) all bins and (d) bins with 4+ detections shown. Note the color legend to the right of (d). shown in (b) where the SNR was much lower then in the image sequence corresponding to (a). This indicates that the new approach indeed yields signiﬁcant improvement not just in bubble detection, but also in shape boundary resolution. The experimentally obtained results in [8] were in a rather good agreement with performed simulations, meaning one thus has indirect validation of the presented approach. The developed approach was also applied to the newly acquired data to ensure consistency in the code output across different experimental campaigns – one instance of the new results is shown in Figure 17. Again, the bubbles are resolved over the entire FOV for all three cases shown. An in-depth physical analysis of the bubble dynamics is beyond the scope of this paper and is reserved for a follow-up article. Resolving gas bubbles ascending in liquid metal horizontal MF, (c) previous and (d) current image processing code. Bubble Figure 16: Bubble tilt angle versus elevation (averaged curves and error bands) over the FOV bottom for (a) the case with no applied MF (Figures 14a and b) and (b) applied horizontal 100 sccmﬂow rate. Orange indicates the previous paper [8] and the current results are shown in gray. The tilt angle deﬁnition is shown in the bottom-right corner of (a). Figure 17: The locations of bubbles detected in the FOV for a sequence of 3000 images (30 seconds) at a ﬂow rate for the new model system (Section 2.1, vertical inlet): (a) an example of detected bubbles: white contours are shapes, orange dots are the current positions and white dots are the preceding detections; (b-d) all detected bubble positions with (b) no applied MF, (c) horizontal (b-d) are marked as in Figure 14. All sub-ﬁgures are to scale. An important note on Figure 16: the averaged curves and the error bands were computed from the image processing code output as outlined in Algorithm 7. The quantile spline envelopes (QSEs) were computed following [74] and using the code (Wolfram Mathematica package) available on GitHub: Anton Antonov (antononcube): MathematicaForPrediction/QuantileRegression.m. For all the datasets represented in Figure 16, we used andb2.5% · Nespline knots for QSEs where δ= b0.5% · Ne(point density-adaptive physical bin size); the TV regularization parameters [59] were 0.25 for the binned data. Finally, even though one cannot check how many bubbles the image processing code actually failed to detect without manual inspection (not feasible), one can evaluate the amount of detection events that are ruled out as false positives at the various stages of code execution for a sequence of images. The results for the ﬁve image sequences considered above (Figures 14 and 17) are presented in Table 1. Algorithm 7: Post-processing for the output of the image processing code. Input: Tilt angle (or any other bubble property) values over elevation (or any other independent variable) Designate the data points above the upper and below the lower lower QSEs as outliers and remove from the dataset Table 1: False positive elimination rates ( and the object property ﬁlter (with respect to the input that each ﬁlter received), and the percentage of detection events input to MRIF that were eliminated in total. Notice that in the most difﬁcult case of the ﬁve (Figure 14d) most of the work is done by the luminance map-based ﬁlter and the object property ﬁlter. However, the intrinsic ﬁltering capacity of MRIF is signiﬁcant because it ﬁlters out the detection events that very likely would have passed both of the two following stages. The developed image processing algorithm is ﬁrst validated by applying it to the images of a stationary reference body described in Section 2.1. Three imaging cases are considered here: neutron ﬂux transmission through the shorter body axis, the longer axis, and the latter with an extra distance from the body to the scintillator. Thus, the SNR of the neutron-transparent spherical cavity within the body progressively decreases for these cases. This is illustrated in Figure 18. Figure 18: Static reference body: (a) an example radiograph; (b-c) normalized images cropped as in (a) for neutron ﬂux transmission through the shorter axis, the longer axis, and the latter with an extra distance to the scintillator, respectively; (e-g) normalized mean luminance maps for the respective image sequences. Note the color bar to the right. A neutron radiography image of the reference body (slightly inclined) is shown in (a) where one can see the rectangular brass frame (darker) and a circular projection of the spherical void (brighter), as well as the surrounding background due to air. Neutron transmission in the case of (a) is along the shorter of the body axes. In all three imaging cases %) over three stages – MRIF, the luminance map-based ﬁlter (Algorithm 6) the images are cropped as indicated in (a). Examples of cropped images of the spherical void within the body with exposure very similar (∼ 1.3×) to that for the bubble images (100 FPS, the three cases listed above, respectively. The corresponding mean luminance maps shown in (e-g) were obtained by averaging over∼ 5.8K,∼ 12K and are used to obtain reference shapes. The shapes detected by the image processing code in images like (b-d) are then compared to the reference shapes to compute shape detection error metrics. Note that all images seen in Figure 18 and used for validation are obtained from raw images by pre-processing via Algorithm 2, as with bubble ﬂow images. Note that the images shown in Figure 18 have the image side length to sphere diameter ratios that are very similar to what one has for MRIF IWs. To compare the reference body images to the bubble images in terms of image quality, consider Figures 19-21 versus Figure 2. Figure 19: Neighborhood analysis for the reference spherical void, transmission along the shorter axis: normalized width mean of luminance (gray) over the length of (a) horizontal and (b) vertical patches roughly ﬁt to the sphere dimensions, spanning the cropped body images. Note the pixel-toindicated by the dashed blue arrows. The image patches are not to scale and their luminance maps are normalized as in Figure 18. The red curve is the total variation ﬁltered (Gaussian, regularization parameter equal to 1 [59]) gray curve. Figure 20: Neighborhood analysis for the reference spherical void, transmission along the longer axis: normalized width mean of luminance (gray) over the length of (a) horizontal and (b) vertical patches roughly ﬁt to the sphere dimensions, spanning the cropped body images. Notice that the case shown in Figure 21 is very similar to the bubble neighborhood case in Figure 2. In fact, Figure 21 exhibits arguably even worse CNR and SNR, meaning that, despite different materials (gallium and argon versus brass and air) and slightly different neutron ﬂux, the reference measurements are representative of the ﬂow imaging conditions and can be used for direct validation of the new image processing code. To obtain the reference shapes from the images in Figure 18e-g, one ﬁrst applies the Gaussian TV ﬁlter [59] ∼ 9.5K images (entire recorded sequences), respectively – these averaged images Figure 21: Neighborhood analysis for the reference spherical void, transmission along the longer axis with a extra distance to the scintillator: normalized width mean of luminance (gray) over the length of (a) horizontal and (b) vertical patches roughly ﬁt to the sphere dimensions, spanning the cropped body images. where the notation is as in (4) (note that the left-most term is different), TV iterations are performed [65]. Afterwards, double-Otsu hysteresis binarization is performed followed by image border component removal and mean ﬁltering (5-pixel radius). To ensure fair veriﬁcation, we apply both the global (Algorithm 3) and the local (Algorithm 5) ﬁlters to the reference void images with parameters identical to those used for bubble images – these are provided in Sections 3.3 and 3.4.3. Once all images are processed and masks given by the global and the local ﬁlter are obtained, we compute the following shape detection error metrics for both ﬁlters: • S– the area of the difference between the detected and the reference masks • δS – the absolute difference in the areas of the detected and the reference masks • δr – the absolute difference of the detected and the reference mask effective radii • δc– the absolute difference in the circularity (the ratio of the equivalent disk circumference to the shape • (δx, δy) – the absolute difference in centroid coordinates between the detected and the reference masks where all metrics are normalized to the respective properties of the reference masks, except the reference radius. Here theδcandδrmetrics serve primarily as "red ﬂags" against gross inaccuracies in the detection of the circular void projection shapes. Under normal circumstances, one should have that ofδS. The other three metrics are used directly for shape detection error quantiﬁcation where the most important one is S. The principles behind imaging a moving reference body are as above, except the body is now attached to a pendulum (Figure 22) that periodically oscillates, and thus the body travels back and forth through the FOV. The motion is mostly horizontal and is initially strongly damped until the pendulum amplitude reaches a state where its oscillations exhibit a very slow decay. This enables us to determine the dynamics of the error metrics outlined in Section 5.1 and assess the effects of motion blur as the body and the void within it decelerate. Here, before the global and local ﬁlters can be applied to the cropped reference body images, one must ﬁrst segment the body within the FOV (Figure 22), crop the masked image to an IW about the mask centroid, repair the IW images as necessary, and then apply the ﬁlters. This procedure is somewhat more involved that the one in Section 5.1 and is outlined in Algorithm 8. The Poisson TV ﬁlter (4) reduces the noise in the image and the image luminance map inversion makes the darker body area foreground and the surrounding air (brighter) background. The SCTMM ﬁlter (7) then increases the body CNR and the body is segmented using the Chan-Vese process (11). Morphological opening (disk structural elements, 15-pixel radius) and erosion (disk structural elements, 5-pixel radius) help separate the body from the clamps (Figure 22), as well as to remove artefacts, if any. Border component removal is done because only body segments fully within the FOV are eligible for analysis. Note that here we use c = 0.5 for SCTMM and β = 1 for the TV ﬁlter. Figure 22: Neutron radiography image of the pendulum used for the reference experiments with the moving reference body: neutron ﬂux transmission along the (a) longer and (b) shorter axes. The red dotted arrows indicate the direction of motion and the white dotted circles highlight the locations of the spherical void. The pendulum arm is a standard lab holder and the reference body is held by clamps (dashed orange lines). Note the motion blur visible at the body boundaries and the holder arms above the clamps. Algorithm 8: Void region (IW) extraction and repair from the pendulum images. Input: A normalized pre-processed (Algorithm 2) image as in Figure 22 Image ﬁltering Output: A repaired IW containing the spherical void surrounded by the body background After area thresholding removes mask components that have abnormally small areas (usually left over clamp segment fragments), an IW is deﬁned about the body centroid via (8) and (9) with non-segment pixels is projected onto the IW. An example is illustrated in Figure 23. Note that (a), which shows the detected segments, contains a small artefact to the bottom left of the body segment – such segments are removed by area thresholding. An IW is then deﬁned about the centroid of the remaining body segment and a void region is extracted, which is shown in (b). Note, however, that the IW contains a portions of the masked background from (a), which can interfere with the global and local ﬁlters. It is therefore necessary to extrapolate the body background about the void into such regions. These regions are detected by inverting the IW luminance map and running histogram-based segmentation with a single threshold of 0.999. The masked regions are then segmented from the IW, as shown in (c). Texture synthesis-based inpainting is then performed with a maximum N= 300 sampling instances for texture ﬁtting [75]. N= 150neighboring pixels used for texture comparison and a maximum of Figure 23: (a) Detected reference body segments (red contours) with an IW (white dashed frame) centered about the body position after segment area thresholding; (b) original image projected onto the IW; (c) image regions designated for inpainting (red borders); (d) restored void region. In rather rare cases inpainting introduces pixels with strongly outlying luminance values, which are eliminated as follows. An Otsu thresholdIis computed for the input image, and then the image is binarized using the threshold, wherekis the threshold scaling factor. With the right more than a certain luminance value from the bulk of the histogram. The segmented pixels are then masked in the input image. We found thatk= 4does not affect the images without signiﬁcant outliers (ones that strongly affect global and local ﬁlter output) while effectively cleaning up severe outliers without modifying the bulk image histogram. An example output of Algorithm 8 is shown in Figure 23d. Afterwards, the resulting repaired void regions are used as input for the global and local ﬁlters. The settings for the global and local ﬁlters are the same as in the cases with stationary reference bodies. In the cases where neutron ﬂux transmission was along the longer body axis (Figure 22a) it was more difﬁcult to segment the body without the pendulum clamps with Algorithm 8 as outlined above. Therefore, minor adjustments were made: • Otsu binarization was used instead of the Chan-Vese process • Morphological opening disk element radius was increased to 50 (Step 6) • Morphological dilation using disk structural elements with a 5-pixel radius was performed after Step 7 • Body masks were oriented to minimize the area of masked background in the IW before performing Step 11 and other Steps and parameters of Algorithm 8 remained unchanged. This procedure was necessary because clamp removal from the body segments using larger-scale morphological opening resulted in body segments smaller then the body by a considerable margin, which was compensated for by morphological dilation to recover the eroded area. Body reorientation was required because the masked image margins to be ﬁlled using texture synthesis often constituted a signiﬁcant fraction of the IW area, resulting in artefacts. Body orientation was detected by ﬁtting a minimum area oriented bounding box and determining its angle masked body image was then rotated by cases we had to use lower values, high-luminance synthetic background. In addition, another issue exists: ﬁltering is performed for IWs with slightly different sizes and void positions. Therefore, one cannot directly overlay detected void shapes over a reference mask. One also cannot obtain a reference mask by averaging the images from the recorded sequence as with a stationary body. As a solution, we use the reference void segment detected from Figure 18e (best SNR and CNR) to generate a reference circle that the detected shapes will be compared against. Using the radius determined for the reference void segment, optimal circles detected segments: where~rare the segment boundary pixel positions, radius measured from Figure 18f. This approach to reference mask placement works well only if the global and local ﬁlters are known not to systematically produce shapes with signiﬁcant errors in centroid position with respect to the true void position, which has been veriﬁed using the image sequences with stationary bodies. −φradians and the body region was obtained and repaired as usual. In two N= 50andN= 200, to avoid sampling the void regions and producing Given this, it is expected that (19) affects centroid determination error is considerably diminished, but this is an acceptable trade-off. In fact, with (19) becomes a measure of circularity correlated to moving reference body (δx, δy) can also be used to quantify shape detection errors induced by motion blur. With the images from the reference experiments processed and the error metrics calculated, one can now assess the performance of the developed code more strictly than in Section 4.3. Starting with the imaging for a static reference body, the results are presented in Figures 24-26. One can see in the error distribution peaks and means are shifted towards higher shorter (a) to longer (b) axis, and value dispersion is also increased with considerably more instances of When the body is moved1 cmaway from the scintillator (c), the global ﬁlter peak is shifted further towards higher values but the dispersion does not change signiﬁcantly. The maximum values (not shown) are higher as well with respect to (b). Similar tendencies can be observed for the local ﬁlter errors, but the overall error values are considerably decreased and distribution peaks are shifted back to lower diminished across the board. Thus, while not radical, the improvements due to local ﬁltering are still very clear. Figure 24: Static reference body: smooth normalized (20 mm) axis, (b) larger (30 mm) axis and (c) larger axis with an extra body (0 mmby default). Note the color legends in the upper right corners of (a-c) indicating results for the global and local ﬁlters. Hereρis the normalized event density. Histogram bins were determined using the Scott method and 2-order interpolation was applied to bin density values. TheδSdistributions shown in Figure 25 are different in that there are many more instances of while in (a) where there are relatively less results signiﬁcantly – dispersion is minimized and the distribution mean is shifted below to what is seen in (b,c): in (b), the roughly the same position. However, again, the local ﬁlter drastically minimized why one observes relatively lessδS < 5% well the ﬁrst three stages of the global ﬁlter improve SNR and CNR. That is to say, most of the instances with are converted to values about the peaks of the local ﬁlter error distribution because the local ﬁlter in most cases cannot achieve improvement to below than (b). As withS(Figure 24), one can see that the local ﬁlter performs progressively worse from (a) to (c), as expected. Sto a degree, andδS,δrandδcare unaffected by deﬁnition. However, the δS < 5%values than in (b,c) for the global ﬁlter, the local ﬁlter improves the δSpeak is shifted towards larger values by the local ﬁlter, and in (c) it stays at values in (b,c) than in (a) is that the local ﬁlter performance depends on how δS . 3%. Therefore it stands to reason that less such values are seen in (c) than in Figure 25: Static reference body: smooth normalized axis, (b) larger axis and (c) larger axis with an extra 1 cm distance between the scintillator and the body. Figure 26: Static reference body: smooth normalized smaller axis, (b) larger axis and (c) larger axis with an extra that here δx ≈ δy for all instances, which is why they are not plotted individually. In the static body case one would expect Figure 26 therefore shows the norm of the position error vector. Notice that here the local ﬁlter improves the error distributions only sightly, reducing the relative amount of higher out thatδrdistributions conform to across the board. The error values seen in Figures 24-26 are within acceptable ranges. Moving on to the moving reference body imaging, the results of these tests are shown in Figures 27-32. Figure 27 shows the pendulum (and reference void) velocity dynamics over consecutive frames for all imaging series. The range of expected bubble velocities (Section 2.3) is covered by the performed measurements, as seen in (a) and (a1). Importantly, in addition to shorter and longer axis transmission tests, we also used purposefully inappropriate texture synthesis and outlier removal settings in Algorithm 8 to generate three sets of data with synthetic image edge artefacts (luminance similar to the void regions) and single pixels with luminance exceeding the image maximum by an order Resolving gas bubbles ascending in liquid metal δx ≈ δy, which is indeed the case, since there is no bias due to motion blur. δSplots and theδrmetric values are lower by a factor of 2, whileδcis negligible of magnitude (greatly reduced image CNR) to see how the ﬁlters perform. Consider Figure 28 where distributions are shown for the three test groups. Figure 27: Frame pair velocimetry (magnitude) for the moving body (Figure 22): (a) velocity over sequential frames for all recorded image sequences with oscillations ﬁltered out for visual clarity; (b) velocity for one of the image sequences with oscillations shown. (a1) shows the ﬁrst 500 frames in (a). Gaussian TV ﬁltering was used for (a) and (b) with the regularization parameters set to 5 (150 iterations) and 0.5, respectively. Figure 28: Smooth normalizedS neutron ﬂux transmission along the (a,b) smaller axis, (c-d) larger axis and (e-f) the latter with the addition of synthetic image artefacts. Note the legend in the upper-right corner of (a) indicating the results for the global and local ﬁltering. Colors indicate different imaging instances. S (a,c,e) andδS(b,d,f) histograms for the cases with a moving body (pendulum): As before, the global ﬁlter performance in terms of both length is increased and then image artefacts are introduced to the data from the longer axis transmission measurements. Notice that theSandδSvalues in Figure 28 are in all cases greater than in the static body cases (Figures 24-26). This is clear enough to be seen visually, as histogram peaks in (a,b) are just under while only being just under. 8% ﬁlter makes a radical difference – observe in Figures 28a, c and e that the dispersion, maxima, minima and means of Sare greatly reduced. Similarly good performance is seen in (b,d,f) in terms of local ﬁlter error distributions as image quality gets worse from (a,b) to (e,f) are consistent with what is seen for static body imaging in Figures 24 and 25. Another important point here is that two of the shorter axis transmission instances (Figures 28a and b) and one from the longer axis groups (Figures 28c and d) are with an extra distance (2 mmby default) – however, in this case the differences are not signiﬁcant enough to warrant attention. This likely stems from the fact a large fraction of errors is due to motion blur, especially during the pendulum deceleration stage, which is within the ﬁrst 300-500 imaging frames (Figure 27). It is also very clear from Figures 28e and f that introducing additional image artefacts considerably degrades the global ﬁlter performance. The local ﬁlter, again, greatly improves the quality of detected shapes, but, of course, also produces greater errors as opposed to what is seen in (c) and (d). Figure 29: Smooth normalizedδx transmission along the (a,b) smaller axis, (c-d) larger axis and (e-f) the latter with the addition of synthetic image artefacts. One must remember thatSis reduced by (19). To estimate the reduction, consider that if the centers of two circles with equal radii are displaced by a factor S(k) = 1 − (2/π) arccos(k/2) + (k/π) "improves" the position of the detected shape by the peak comes out toS∼ 5%. To verify this, we also observe how detected (rarely) for stationary body images when ground truth masks (Figures 18e-f) are replaced with ﬁts using (19) – Resolving gas bubbles ascending in liquid metal in the worst case forSin Figure 24c. However, this is exactly where the local (a,c,e) andδy(b,d,f) histograms for the cases with the moving body: neutron ﬂux this is in agreement with the above idealized estimate rather well, yielding is applied to Figures 28a, c and e, the observations are consistent with the results for the stationary reference body, and the local ﬁlterSvalues come out to about of the cases in Figure 28e (light green curves). To reiterate, Here theδrdistributions again conform to that the asphericity of the detected shapes in within acceptable bounds. Turning to Figure 29 and recalling that with (19) that the errors are anisotropic in all cases. The greater component Importantly, this anisotropy is also observed when inspecting the shape/reference difference masks for the local and global ﬁlters, where the largest contributions to pendulum (Figure 22) oscillation directions. SinceSandδSmaxima for the global ﬁlters were not included in Figure 28 to maintain visual clarity, and it is hard to quantify dispersion visually, Figures 30 and 31 show these quantities explicitly for all three test groups and for both global and local ﬁlters. While shape detections with 31b are very rare, it is important that the local ﬁlter can signiﬁcantly improve the quality of detected shapes even in these instances. Figure 30: (a) Mean and (b) maximum and local ﬁltering are represented with matte and glossy bars, respectively. The standard deviations for the mean values in (a) are indicated by the red (global) and black (local) error bars. Note the color legend in the upper-left corner of (a) indicating the three different test groups considered in Figures 28 and 29. Figure 31: (a) Mean and (b) maximum and local ﬁltering are represented with matte and glossy bars, respectively. The effects of motion blur can be assessed more quantitatively and directly – consider Figure 32 where as a time series for two of the processed image sequences. One can see that higher body motion velocity indeed corresponds to greater errors, which decline over time as the body decelerates. Note that, between Figures 32a and b, it is evident that the intrinsic error signal due to the global ﬁlter quickly obscures the error contribution due to motion blur. Resolving gas bubbles ascending in liquid metal δS.δcis negligible for all cases and, as seen in Figure 29,kδx, δykis such Svalues for the cases with a moving reference body. The results for the global δSvalues for the cases with a moving reference body. The results for the global However, it also seems that the global ﬁlter is affected by the motion blur more than the local ﬁlter – as seen in (b), theSrather quickly relaxes to a quasi-stationary value at about N ∼ 500. Similar dynamics can be observed in (c) and (d) as well. Figure 32: An illustration of the effect of body motion on the shape detection errors: examples from two image sequences. Neutron transmission along (a-b) the shorter and (c-d) longer axis of the reference body. (a,c) show the Sdynamics over consecutive frames for the global ﬁlter and (b,d) show the results for the local ﬁlter. (a,b) show the ﬁrst 1000 frames for visual clarity. Note that 3000 images were analyzed in total for both shown cases. The error time series show here are obtained from raw data by removing the outliers above and below the Gaussian TV-ﬁltered (regularization parameter 1)q = 0.9 ﬁlter (regularization parameter 2) to the remaining data points. The velocity curves are as in Figure 27a. We assess the reference void detection failure rates in the image sequences used for the code validation – the results are summarized in Table 2. Table 2: Reference void failure rates ( transmission along the shorter axis (SA) of the body, the longer axis (LA), and the latter with an extra distance to the scintillator. For moving body imaging, tests with an extra body-to-scintillator distance are (3-4) for SA and (4) for LA. Tests with LA and synthetic artefacts are based on data from LA runs (2) and (4). There are no detection failures for static body imaging and for a moving body with neutron ﬂux transmission along the shorter axis, and very small percentages are found for the longer axis case. The cases with synthetic artefacts have signiﬁcantly higher failure rates for the global ﬁlter. However, all cases exhibit values performance. Finally, Table 3 indicates peak errors induced by motion blur at near the maximum pendulum velocity for the local ﬁlter for all the imaging instances, including S QSEs (3-rd order splines,b90% · Nespline knots) and applying the Gaussian TV %) for the validation experiments. Static: tests (1-3) are with neutron ﬂux ∼ 5%. Note that the peak errors are within added to images. While the demonstrated image processing performance is satisfactory for the problems that the code was developed for, its degree of parallelization could still be increased, especially for MRIF, and we expect that signiﬁcant speedup can be attained for several components. The developed code has been tested using the following hardware: 1. Intel Core i7-7700 (4 cores/8 threads) with 64 Gb 2400 MHz DDR4 RAM 2. Intel Core i7-8700 (6 cores/12 threads) with 64 Gb 2400 MHz DDR4 RAM 3. Intel Core i9-9900K (8 cores/16 threads) with 64 Gb 2666 MHz DDR4 RAM 4. Intel Xeon W-2255 (10 cores/20 threads) with 192 Gb 2933 MHz DDR4 ECC RAM 5. Intel Core i9-10980XE (18 cores/36 threads) with 256 Gb 2933 MHz DDR4 RAM and we found that memory utilization for parallel execution of Algorithm 3 using hyperthreading (all images are processed independently) and all available threads for a sequence of 3000 images (properties given in Section 2.2) requires almost all of the memory for the ﬁrst and the last two machines, while the second and third machines ran out of memory and the image batch size had to be decreased. While this is not a critical issue, the mean execution time per 1000 images reduces signiﬁcantly between machines as the thread count increases, so we expect the reduction in memory utilization to be worthwhile. For context, the ﬁrst machine fully processes 3K images and outputs results in ∼ 2hours, while the fourth machine ﬁnishes in follow-up publication for a greater number of processed image sequences. It is also planned to implement a feedback loop that will enable coupling with our recently developed object tracking algorithm MHT-X [76] for iterative reinforced object detection and tracking. Finally, we will also apply the developed methods to image sequences with even smaller bubble-bubble distances where bubble collisions also occur. To summarize, we have demonstrated the new version of our image processing methodology for resolving gas bubbles travelling through liquid metal imaged using dynamic neutron radiography. The showcased components of our code, such as the multi-scale recursive interrogation ﬁlter (MRIF) and the underlying global and local image ﬁlters, as well as soft color tone map masking, proved effective for detecting bubbles and extracting their dynamic shapes from images with low SNR and CNR. Output quality was further improved by the implemented luminance map-based false positive ﬁlter that bolstered the MRIF’s intrinsic false positive ﬁltering function. It as shown by direct comparison that the new image processing code clearly outperforms the previous version used in [8, 44], while the outputs of both are still consistent. In addition, we have validated the new methods experimentally by imaging a reference body, both stationary and in motion, with a precisely machined spherical cavity. Results indicate that that local ﬁltering performed by MRIF largely limits the shape detection errors: relative shape mismatch area and shape area difference with respect to reference shapes are within acceptable bounds of ∼ 14% (∼ 20% with synthetic artefacts) and∼ 10%(∼ 14%with synthetic artefacts), respectively (accounting for motion blur and the worst-case underestimation correction), while the asphericity of the detected shapes is rather negligible. As such, we ﬁnd that applying the current methodology to the neutron radiography images obtained for our model systems with bubble chain ﬂow is safe in that physically meaningful results with manageable errors can be expected. Note that we have also used the present image processing code to benchmark our object tracking code MHT-X [76]. In follow-up articles, we are going to process the data acquired in the previous and latest neutron imaging campaigns using the methods presented in this paper and our MHT-X code, and showcase the effects of applied horizontal and vertical magnetic ﬁeld with different strengths on bubble chain ﬂow in a rectangular liquid gallium vessel. Bubble S) for the local ﬁlter at near maximum body velocity for all validation experiments. 14%for tests without synthetic artefacts, and within20%for instances with artefacts trajectories (length, curvature, oscillation frequencies, envelopes, etc.), velocity (both overall spectra and dynamics, including acceleration) and shapes (aspect ratio, tilt angle, etc., and dynamics thereof) will be assessed and compared for different ﬂow conditions – in addition to magnetic ﬁeld conﬁgurations, a range of gas ﬂow rates will be considered. We will also attempt to perform dynamic mode decomposition for the bubble shapes extracted from neutron radiography images and compare the dynamics against simulations – this will be done using the methods recently developed in [56]. Finally, we expect that the developed image processing pipeline and/or separate elements thereof should be applicable beyond the current application and context, which we also plan to demonstrate in follow-up papers. In the meantime, the image processing code is available on GitHub: Mihails-Birjukovs/Low_C-SNR_Bubble_Detection. The code will be improved as outlined in Section 6. The authors acknowledge the support due to the ERDF project ”Development of numerical modelling approaches to study complex multiphysical interactions in electromagnetic liquid metal technologies” (No. 5 1.1.1.1/18/A/108). The work is also supported by the Paul Scherrer Institut (PSI) and a DAAD Short-Term Grant (2021, 57552336). The authors would also like to express gratitude to Jevgenijs Telicko (UL) and Peteris Zvejnieks (UL) for assistance with the experiments, as well as to Imants Bucenieks (UL) who assembled the designed magnetic ﬁeld systems.