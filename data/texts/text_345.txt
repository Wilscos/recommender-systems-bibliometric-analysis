We present a case that the newly emerging Ô¨Åeld of synthetic d ata in the area of recommender systems should prioritize ‚Äòdoing data right‚Äô. We consider this catchphrase to have two aspects: First, we should not repeat the mistakes of the past, and, second, we should explore the full scope of opportunities presented by synthetic data as we move into the future. We argue that explicit attention to dataset design and description will help to avoid past mistakes with dataset bias and evaluation. In order to fully exploit the opportunities of synthetic data, we point out that researchers can investigate new areas such as using data synthesize to support reproducibility by making data open, as well as FAIR, and to push forward our understanding of data minimization. Additional Key Words and Phrases: datasets, data synthes is, data bias, evaluation, data minimization, FAIR principles, responsible AI 1 INTRODUCTION The era of big data has seen impressive examples of how knowledge and value can be created using data. It has also seen sobering reminders of how easy it is to ‚Äòdo data wrong‚Äô, causing unintended outcomes and often outright harm to the people [17]. In this position paper, we point out that we are at the beginning of a new era of synthetic data and that we should take this beginning as an opportu nity to ‚Äòdo data right‚Äô. Synthetic data is data that is created to serve in the place of original data, which is directly collected or captured. Synthetic data makes it possible to carry out analyses or develop new algorithms on data that would be otherwise too sensitive to retain, share, or release. Synthetic data can also be u sed to augment an existing dataset to improve the performance of algorithms. Data that is only partially synthesized is referred t o as semi- sy nthetic data. The goal of this paper is remind researchers that we must not repeat mistakes that have been made in the past and must also ensure that as our research moves forward, we take advantage of the full scope of the opportunities presented by synthetic data. Our focus is on recommender system data, w hich takes the form of a user-item matrix R with ùëà = {1, .., ùëÅ } users and ùêº = {1, .., ùëÄ } items. If a user has interacted with an item, the corresponding matr ix cell contains a 1. Interactions can include clicks, views and purchases, which implicitly express a preference of a user. Today, recommender system research focuses on such implicit data, since explicit data, which consists of ratings explicitly expressing user preferences, is harder to co me by. Recommender system data diÔ¨Äers from many datasets of t he big data era in that it is highly sparse and characterized by long-tail distributions. SpeciÔ¨Åcally, we have act ive users who watch/consume/click many items and non-active users (including cold start users) who attempt to watch/consume/click very few items. Similarly for items, we have popu lar items that are consumed by many users and non popu lar items are consumed by few users. The special characteristics of recommender system datasets make them challenging t o synthesize, and research has just begun in this direction. This means that the time is right to avoid the pitfalls already encountered with conventional data. Further motivation past failure in ‚Äòdoing data right‚Äô with regards t o user privacy, which is still fresh in the minds of recommender system researchers. Memorably, in 2010 , NetFlix Prize competition was discontinued after it was demonstrated that the data that was released to allow the competitors to develop recommender systems could be deanonymized, revealing the identity of individual users [27]. Flashing forward, the NetFlix Prize debacle has inspired research on synthetic data. Via the experience of ou r own research we see two directions emerging. First, research on using synthetic or semi-synthetic data to replace captured data in competitions [32]. Second, research on ensuring that synthetic or semi-synthetic data that is derived from data originally collected from users does not leak sensitive information on those users [31]. The paper is structured as follows. First, we look at two areas, going beyond privacy, where past research in recommender systems arguably failed in ‚Äòdoing data right‚Äô when working with conventional: bias and evaluation. We discuss how research in synthetic d ata can grab the chance of not repeating past mistakes. Then, we discuss two opportunities that are opened by synthetic data, which are not oÔ¨Äered by conventional data: open data and data minimization. We present remarks on how the recommender system community can build on these opportunities. Our paper clo ses with a short summary and an outlook. 2 ADDRESSING PAST MISTAKES The era of big data has been driven by the idea that more data will automatically give rise to more reliable analysis and better systems. In recent years, however, machine learning researchers have initiated a more systematic approach to data in which the quality, not just quantity, of data is central. These eÔ¨Äorts are well represented by the initiative of datasheets for datasets [13]. In a nutshell, this initiative proposes that every dataset is described by a d atasheet with a standardized format that documents: the mo tivation (why a dataset is created), creation (how the dataset is created), composition (what information it contains), intended uses (what tasks it should (not) be used for), data distribution (what are the properties of the dataset). In this sectio n, we look at past cases of ‚Äòdoing data wrong‚Äô related to d ata bias and to evaluation. We comment on how understanding, docu menting, as well as explicitly designing, the characteristics of data is currently oÔ¨Äering course correction for research practices and also on how work on synthetic data can be steered so that the same problems t hat we have confronted while working with conventional data do not arise anew. 2.1 Bias Mitigation In its early days, the recommender systems community did not considered issues of bias and fairness. Thankfully, recent work has start ed to illuminate these issues. Here, we provide a brief summary. Discrimination and unfairness in recommender systems can originate from diÔ¨Äerent sources: First, input bias [25, 34] that users exhibit in the input data. In [25], the authors studied how diÔ¨Äerent collaborative Ô¨Åltering algorithms propagate bias existing in the input data and its impact o n users. In [10], the authors evaluated the ability of recommender system algorithms to produce equal utility for users of d iÔ¨Äerent demographic groups. A set of results showed a statistically signiÔ¨Åcant diÔ¨Äerences in eÔ¨Äectiveness between users‚Äô gender and age groups. Second, algorit hmic bias [26, 34] examines the eÔ¨Äectiveness of recommendation algorithms in capturing diÔ¨Äerent users‚Äô interests across item cat egories. For example, popularity bias, where the recommender gives higher accuracy scores to algorithms that favor popular items irrespective of their ability to meet user needs. In [9], the authors proposed FaiRecSys, an algorithm that mitigates algorithmic bias by post-processing the recommendation matrix with minimum impact on the accuracy of recommendations provided to the end-users. Third, evaluation metric error and bias [33] simulates the recommender data generation and evaluation processes to quantify how erroneous current evaluation practices are. In [35], the authors proposed a simulation framework for measuring the impact of a recommender system under diÔ¨Äerent types of user behavior. The framework goes beyond one-step recommendation and incorporates the interaction between user preferences and system eÔ¨Äects, to better understand recommender system biases over time. Biased data, biased algorithm and a biase d metric wil l have an impact on all users wit h diÔ¨Äerent degrees, which leads to discrimination, unfairness and harm. Data synthesis is an important ap proach to mit igate b ias. Synthesized data can potentially support recommender systems‚Äô experimentation, tuning, validation and performance predictio n. When synthesizing data, there are some points that we attempt to achieve or test. For instance, the (semi-)synthesized data can be used to mitigate bias [15, 20], improve consumer-provider fairness [6, 24], data augmentation [2]. We argue that althou gh data synthesis is helpful to address bias, alone it is not enough. It is critical that the design decisions that were made when creating a synthesized dataset are well motivated, and made explicit, and also that they are well documented. In this way, future researchers can understand how b ias was handled and assure themselves that new forms of bias were not introduced dur ing the synthesis process. With explicit design and careful documentation, we can learn, understand, and explain where things have gone wrong and ideally be able to work toward redressing problem i.e., harms and preventing fu rther problems. The goal of datasheets for datasets is to provide mo re transparency, accountability and co ntrol in the machine learning and recommender system communities. Moving forward it is crucial that datasheets are also crated for synthetic data. 2.2 Reliable Evaluation In its early days, the recommender systems community did not fully appreciate the importance of systematic evaluation. Arguably, it was [30] that awakened researchers to the importance of completely controlling the dimensions of an evaluation in order to achieve a fair comparison. The Ô¨Årst dimension mentioned by [30] is data. In recent years, the community has made strides in evaluation practices and reproducibility, see [3], which contains a section documenting the eÔ¨Äort. We point out that a datasheets approach to synthetic data, will ensure that synthetic data will be used appropriately for evaluation from the start and invalid comparisons between datasets will be avoided. Another dimension mentioned by [30] is evaluation strategies. Here, we dive deeper to discuss w hy careful attention must be paid to evaluation st rategies for synthetic or semi-synthetic data. In the machine learning literature, the quality of synthetic data is often evaluated using machine learning performance. Such an evaluation involves comparing the performance metrics of predictive models trained on synthetic and on real data (called as model compatibility). This performance of a machine learning models trained and tested on real and or synthetic data is compared based on diÔ¨Äerent scenarios [12, 14, 18]: Train on Real and Test on Synthetic data (T RT S) Train on Synthetic and Test on Real (T ST R), Train on Real, Test on Real (T RT R) and Train on Synthetic, Test on Synthetic (T ST S), and lastly trained and tested o n a mixt ure of real and synthetic data (T MT M). In principle, these scenarios are transferable to the evaluation of synthetic data in recommender systems. However, it is important to consider whether T RT S and T ST R actually yield meaningful information about how useful synthetic data is for recommendation. The reason is that, if the synthetic d ata provides synthetic users, then users in the training set (or test set) are diÔ¨Äerent from those in the test set (respectively training set). It is critical to develop evaluation frameworks that are suitable for use in evaluating synthetic data in the context of recommender systems. In other words, evaluation itself must be an object of research. Here, we cite two directions that could serve as a starting point. First, relative ranking of a set of algorithms, rather than absolute sco res could serve as an important tool. The relative performance of a set of algorithms trained and tested on the synthetic dataset should be the same as their relative performance when trained and tested on the original dataset [7, 18, 19, 32]. For example, if (semi-)synthetic data is released for use in a data science challenge, this relative ranking would be more important that the absolute scores achieved by the algorithms. This direction of research is not yet well explored by researchers in recommender system community. Second, special attention must be paid to ensure that the test set remains comparable when diÔ¨Äerent types of (semi-)synthetic data are compared. We have proposed on way to address this issue for semi-synthetic d ata [31]. We close t his section on evaluation by mentioning the importance of studying data characteristics. There is an interaction between the exact nature of the data, and the types or recommender system algorithms that perform well on that d ata. These aspects have traditionally been understudied by the community, also the situation is hopefully changing in the wake of [1, 8]. Because it is straightforward to control the properties of synthetic data, the study of synthetic data opens a w ho le new world of possibilities for use to understand which algorithms works well with which type of data, and why. Again, we see that the proper documentation of synthetic data in datasheets is critical fo r such research to be reproducible and thereby useful. 3 PAVING THE WAY FOR FUTURE RESEARCH Synthetic data is generally intended to take the place of original data. However, in order to take advantage of the full potential of synthetic data, which must also invest research eÔ¨Äort in developing the potential of synthetic data to transcend conventional data, and be used for purposes for which conventional data is not suited. 3.1 FAIR and Beyond FAIR is the combination of diÔ¨Äerent small practices that make the data easier to Ô¨Ånd, easier t o understand, less likely to be lost, and more l ikely to be usable during the project time and years later [16]. FAIR principles [11] are guidelines for data management and stewardship that are valid for both machines and humans: Findable: (meta)data should be discoverable, identiÔ¨Åable and searchable via the assignment of metadata and unique identiÔ¨Åers. Accessible: (meta)data should be available and retrievable with access via authentication and authorisation procedures. Interoperable: (meta)data should be semantically understandable, allowing the broadest possible data exchange i.e., exchange and reuse between researchers, institutions, organisations or countries. Reusable: (meta)data should b e suÔ¨Éciently described, well documented, and shared with the least restrictive licenses, allowing the widest reuse possible. The FAIR principles can drive forward progress in recommender system research because t hey can support reproducibility. However, the FAIR principles do not dictate that the d ata has to be shared openly [28], which is a hindrance to reproducibility. For instance, the data can be FAIR but not open: it is FAIR within the company but it does not open to researchers, scientists and users outside the company. Data synthesis oÔ¨Äers a possibility to make data FAIRly open without the need to release the original data. The (semi-)synthetic data could be designed to protect user‚Äôs sensitive information while still maintaining its value for training recommender systems, which is needed for reproducibility. We have suggested one approach in [31], but this work represents only a beginning. The (semi-)synthetic data could also be designed to protect information that is important for companies‚Äô competitiveness while at the same time preserving the information that is necessary for the data to contain in order for third-parties to be able to have oversight over how companies collect and use the data of users. 3.2 Data Minimization Finally, we discuss the issue of d ata minimization. Article 5(1)(c) of t he Eu ropean Union‚Äôs General Data Protection Regulation (GDPR) req uires that personal data should be limited to only what is necessary to the purposes for which the data is processed [29]. Linking back to the discussion of FAIR, we note that in [5, 16], authors suggested that FAIR data and metadata can facilitat e compliance with data minimization principle since FAIR principles allow for an assessment of which data to reuse. Here, we zero in speciÔ¨Åcally on data minimization for recommender systems. In [23], the autho rs prop osed to adopt training data requirements analysis to analyze and evaluate the trade-oÔ¨Ä between the amount o f data that the system requires, and the performance of the system. In [21], t he authors proposed to extend the data minimzation principles advocated in GDPR and studied their eÔ¨Äect o n recommender systems. They investigated the eÔ¨Äects of reducing the amount of data used to model a recommender system and showed that a substantial amount of data can be dropped without a large impact on the performance. In [4], authors pointed to the lack of an homogeneous interpretation of the data minimization principle. They argued that personalization-based systems do not necessarily need to collect user data, but that they do so to improve the quality of the results. They found that the performance decrease incurred by data minimization might not be substantial but that it might disparately impact diÔ¨Äerent users. To support minimization, [4 ] suggested that we need to design new protocols for user-system interaction, a system that does not only focus on providing inÔ¨Ånite recommendations while collecting inÔ¨Ånite data about its users‚Äô. In other words, we need to propo se new learning mechanisms that select necessary data that respect speciÔ¨Åc minimization requirements while maintaining a good personalized -based recommendation performance. Synthetic data presents a promising opportunity to understand what data minimizing means for recommender systems. M inimized datasets can be synthesized with d iÔ¨Äerent characteristics and the impact of these characteristics could be studied. We believe that cold start user proÔ¨Åles could be a good starting point to understand and Ô¨Å nd the minimal necessary data in a user proÔ¨Åle. Then, recommender system research need to look at how much data is really necessary to accomplish a given recommender system task. We expect the study of data minimization to move forward the state of the art in recommender systems, but also to make it possible to gain understanding of how the GDPR must be enforced for recommender system data. Using synthetic data to stu dy data minimization is potentially relevant to oversight beyond the GDPR as well. Currently, there is growing concern about the manipulative impact of hypertargeting, which infringes on privacy and consumer rights. Previously, we have proposed the concept of hypotargeting [22], i.e., imposing a constraint on the number of unique recommendation lists that a recommender system can present to its users in a given time window. Because the number of unique lists remains Ô¨Ånite, it beco mes feasible to audit the experience that a recommender system is oÔ¨Äering to its users. Such oversight can watch for bias, Ô¨Ålter bubbles, and unfair targeting. 4 SUMMARY AND OUTLOOK In this position paper, we have described mistakes that have occurred over the history of recommender system research, speciÔ¨Åcally, neglecting the issue of bias and overlooking the imp ortance of evaluation framework. We have argued that we must ensure that these mistakes are not repeated as we develop ap proaches to craete synethetic data for evaluation. We have also pointed to areas where synthetic data has a special contribution to make in the future, speciÔ¨Åcally, extending FAIR principles to make data open and also moving forward our understanding of data minimization for recommender systems and how t o minimize data appropriately and eÔ¨Äectively. Throughout we have emphasized the importance of explicitly designing and documenting synthetic datasets, following the idea of datasheets for datasets [13]. Future research will need to embrace the development of best practices for design, documentation, and evaluation of synthetic data as research areas in their own right. Recommender system research must also create bridges across disciplines. As pointed out by [13], the risk datasets causing harm can be exacerbated when developers are not domain experts. Moving forward it is essential to include experts from speciÔ¨Åc domains, such as health, psychology, and communication science, in synthetic data research. Further, interdisciplinary collaboration is also necessary with legal experts to understand how synthetic data can best protect privacy, and support d ata minimization and regulatory oversight.