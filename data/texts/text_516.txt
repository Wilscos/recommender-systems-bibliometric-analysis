Abstract—Just as user preferences change with time, item reviews also reﬂect those same preference changes. In a nutshell, if one is to sequentially incorporate review content knowledge into recommender systems, one is naturally led to dynamical models of text. In the present work we leverage the known power of reviews to enhance rating predictions in a way that (i) respects the causality of review generation and (ii) includes, in a bidirectional fashion, the ability of ratings to inform language review models and vice-versa, language representations that help predict ratings end-to-end. Moreover, our representations are time-interval aware and thus yield a continuous-time representation of the dynamics. We provide experiments on real-world datasets and show that our methodology is able to outperform several stateof-the-art models. Source code for all models can be found at [1]. Index Terms—recurrent recommender networks, dynamic language model, attention for recommendation Following the deep learning agenda, the success of modern recommender systems heavily relies on their ability to leverage meaningful representations that allow for the accurate prediction of a purchase or a rating. Fundamentally one must dwell into interest modeling, as an effective recommendation is such that it uncovers, for a given user, a hidden interest in an unknown item. It is natural to study the change of user interest with time and, in the present work, we seek to incorporate these dynamical notions with those of text reviews. Reviews are effectively a form of recommendation, and one that is directly provided by the user. The challenge however, stems from the unstructured and ambiguous nature of reviews (and natural language itself). A user might, for example, simultaneously highlight positive and negative aspects of the different items she reviews. Following current trends in natural language processing, we leverage review content through neural models of text and attention mechanisms, and guarantee the information content of those representations via reproduction quality. We encourage the dynamical aspect of text recommendations by learning representations which help predict both when is the next review arriving and what does it say. One is then led naturally to dynamical language models, since enforcing good text predictions ensures its dynamical representation quality. There is a large body of research invested in recommender systems (RS), a big part of which has lately been devoted to capture the temporal dynamics of both users and items. One of the ﬁrst temporal models for recommendation is the TimeSVD++ [2], which extends the SVD++ matrix factorization algorithm by introducing time-dependent latent factors. From the neural network perspective, many models for RS have been developed [3]–[5], and Recurrent Neural Networks (RNNs) have been used to capture time-ordered user activity. For example, session-based item recommendation use RNNs to infers user preferences from sessions of user behaviour [6]– [9]. Another example, closer to our work, is the Recurrent Recommender Networks (RRN) which uses two independent RNNs to model user and item dynamics separately [10]. Just as with user (and item) temporal representations, including review content representations has also been shown to signiﬁcantly improve rating prediction and item recommendation [11]–[14]. However, some of these models break causality, in the sense that they either use the review of the item whose rate one is predicting, or use item reviews that have not been received by the time the item of interested was rated. Finally, a model that combines RRN (a dynamical RS) with character-based autoregressive language models for reviews has recently been develop [15]. This work however, does not leverage the review content for rating prediction. In contrast to all these works, we combine dynamical recommender systems with a dynamical language model that captures review content evolution, and use the review representations together with the user-item temporal representations in a causal fashion, to predict the rating of the next review. III. DYNAMIC REVIEW-BASED RECOMMENDERS (DRR) The interests and preferences of users vary as they age, or change their social status or lifestyle. Exogenous factors like trends or seasons also affect user preferences. For example, users tend to look for different clothe types in winter than those they look for in summer. Users also tend to change their music tastes as they age. Such preference changes are naturally encoded in the collections of reviews and ratings given by these users over time. Our goal is to learn representations capturing them. We therefore develop a model that explicitly Fig. 1: Dynamic Review-based Recommender. The model consists of three interacting components: (i) a temporal model composed of two RNNs, one for users and the other for items, which we called Dynamic Model of Review Sequences; (ii) a neural language model which leverages the temporal representations of both user and items, and which we called Dynamic Model of Review Content; and (iii) a Rating Model which combines the user and item temporal representations with the review content representations to predict ratings. Note that when q = t in the language model component, the Dynamic Review-based Recommender is causal. The model is non-causal when q = t + 1. uses the text content and ratings of past reviews together with the history of when those reviews were written to better predict user interest in unknown items. Consider a dataset D with a number of V items (as e.g. businesses or services, movies, products, etc.) and a number of U users. An element e ∈ D consists of a sequence of N reviews r= {(x, τ, δ, y)}, where the t-th review is composed of its text x, creation time τ, inter-review time δ≡ τ− τand rating vector y. Such review sequences reffectively deﬁne time series, and each of these can either be associate with a user u (in which case we set e = u), or an item v (in which case e = v). Thus the rating vector for user u is such that y∈ R, with y= p if user u rated item v with rating p. Conversely, the rating vector for item v is such that y∈ R. Note that both of these vectors are large and sparse. To process them efﬁciently we perform dimensionality reduction via hashing, following [16]. Our main idea is to model the user and item review sequences separately, via two independent RNNs which output temporal representations encoding the nonlinear relations between timing and rating of past reviews. We then feed these temporal representations to neural models of text, thereby yielding instantaneous review content models, while simultaneously use them to predict when are new reviews going to arrive and what are their ratings. The model thus consists of tree interacting components: a temporal model composed of two RNNs, one for users and the other for items, which we called Dynamic Model of Review Sequences, a neural language model which leverages the temporal representations of both user and items, and which we called Dynamic Model of Review Content, and a Rating Model which combines the user and item temporal representations with the review content representations to predict ratings. In what follows we dwell into the details of these building blocks. Figure 1 summarizes the Dynamic Review-based Recommender (DRR) model. Given a sequence of reviews r, we process each of its elements recursively via a RNN with hidden state h∈ R. At each timestep t, we ﬁrst compute the hidden representation where W, W, Wand bare learnable parameters and z∈ R. We then update the RNN’s hidden state thus where fis implemented by a LSTM network [17]. Note that the superindex e is used here to emphasize that we have two sets of functions namely, one for the user (e = u) and one for the item (e = v) reviews. The temporal representation hthus deﬁned not only encodes the history of ratings, but also the time lag between past reviews, thereby yielding a continuous-time representation of the dynamics. To enforce encoding quality, we ﬁrst use hto predict the arrival time of new reviews via a simple Review Creation Model, which we shall now introduce. Later we will explicitly use hand hto predict ratings through a Rating Model. 1) Review Creation Model: The inter-review times δcan be modeled as following an exponential distribution whose rate parameter λ(h) is a function of the temporal representation h[18], [19]. In practice we approximate the function λ: R→ Rwith a multi-layer perceptron. The log-likelihood of the Review Creation Model is then log p(δ) =log p(δ|h) Note that predicting the arrival times of new reviews can be done by either sampling the exponential distribution, or using the mean of the distribution directly. In our experiments we use the mean of the distribution. Consider the t-th review in the sequence r, whose text content is given by x= (w, w, . . . , w), where w and Llabel the j-th word and the number of words in that review, respectively. To capture how the review content changes within r, we deﬁne the probability of observing the word sequence xat the t-th review as the conditional probability p(x|h). Here we deﬁne the global temporal representation hencoding the nonlinear relations between timing and ratings of past reviews as h≡ concat([h, h]), with hdeﬁned in Eq. 2. Note that when processing the dataset D, the modeling of review content does not need to differentiate between user and item. We therefore drop the superindex e in what follows. Below we present two models for p(x|h), one based on a Bag-of-Words (BoW) representation, and another on an autoregressive language model. Both models will be trained by maximising log p(x|h). These language models will ultimately allow us to deﬁne a vector representation¯s, summarizing the content of the t-th review, which we will later use as input to our Rating Model. 1) Bag-of-Words Neural Review Model: We assume the words in xare generated independently, conditioned on h,Q that is p(x|h) =p(w|h), where we follow [20] and write the probability over words as with R ∈ Rand b ∈ Rtrainable parameters, h= concat([h, h]) and wthe one-hot representation of the jth word in x. We deﬁne the summary representation for xas the Bagof-Words (BoW) representation¯s∈ R, where V is the vocabulary size [21]. 2) Autoregressive Review Model: In contrast to the BoW model above, autoregressive language models approximate the probability over the word sequence xas [22] where wlabels all words previous to w. The conditional probability above depends on both wand the global temporal representation h. To model it we take an approach akin to that of the variational autoencoders of text [23]. That is, we ﬁrst concatenate hwith all word embeddings in x, i.e. we deﬁne˜w= concat[w, h], and then process the new vector sequence with a RNN with hidden state s∈ R, whose update equation reads s= g(˜w, s). Here g is implemented by a LSTM network, with equations similar to those below Eq. (2). The distribution pis then deﬁned as a categorical distribution over a vocabulary of size V , whose class probabilities are given by π= softmax(W s), where W ∈ Ris a learnable matrix. We now deﬁne the summary representation for xas aP weighted sum over word representations¯s=αs where the j-th weight αis calculated with the gated attention mechanism proposed in [24] α=softmax(kq),(6) k= tanh(Ms+ b)  σ(Ms+ b), where M, M∈ Rand b, b∈ Rare learnable parameters, q ∈ Rcan be interpreted as a learnable global query,  denotes element-wise multiplication and σ(·) denotes the sigmoid function. This type of attention is introduced to solve the problem of the limited expressiveness of the tanh(·) to capture complex relations, due to the fact of approximate linearity in the region [−1, 1]. As we shall see below, this attentive summary representation allows us to track the most relevant words affecting the rating of a given item as time evolves. Given the temporal representations for user and item reviews (i.e. h, h), and the summary representation for review content¯s, we want to predict the rating ˆy∈ R that user u gives to item v. There is, however, still the question of how to combine hand hwith¯s. After exploring different possibilities we found two optimal solutions namely, 1) DRR-BoW: For the Bow Neural Review Model we augment Eq. (1) and deﬁne˜z= z+W¯s, where W∈ R is an additional learnable weight, to get˜h= f(˜z,˜h), where fremains the same as in Eq. (2). The new representation˜hnow encodes the nonlinear interaction between timing, rating and text of past reviews. 2) DRR-LM: For the Autoregressive Review Model we instead deﬁne with W∈ R, b∈ Rlearnable. The resulting representation˜halso encodes the interaction between timing, rating and text, albeit through a different route. We have now all ingredient to predict the rating ˆy∈ R that user u gives to item v. We compute ˆywith a factorization machine (FM) [25], here deﬁned as where h ∈ R≡ concat([˜h,˜h]), w∈ R, w ∈ Rand V ∈ Rare learnable parameters, K is set to 10 and h·, ·i denotes dot product. We choose the loss function of the Rating Model to be the mean square error function between ˆyand our prediction ˆy(h). The complete loss function of the DRR model has therefore three components: the loss of the Rating Model, the loss of the Dynamic Model of Review Sequences, which is the negative log-likelihood of an exponential, and the loss of the Dynamical Model of Review Content, which is the negative log-likelihood of our word sequence model. Explicitly we write −λlog p(δ|h) − λlog p(x|h), where λ, λ∈ Rare hyperparameters. By construction, both DRR-BoW and DRR-LM models above preserve causality — the models do not use any information from the future to predict ratings. As mentioned in the introduction, however, most recommender system models that leverage review content use the review x, written by user u, to predict the rating ygiven by this same user to the item v. In order to fairly compare our methodology with such models, we use the degrees of freedom available within the deﬁnition of the DRR-LM model and redeﬁne This new representations encodes¯s, the summary representation of the review whose rating it predicts, and breaks causality. Below we refer to the model using the causal representation Eq. (7) as DRR-LM-C, whereas we denote the model using the non-causal expression Eq. (10) as DRR-LMNC. Naturally, the causal model is to be preferred as we normally do not have review content about the item whose rating we want to predict. Nevertheless, we shall see that the non-causal model lends itself when one is interested in tracking the words which most affect the rating of a given item as time evolves. Data set To test our model we choose the Amazon dataset [26]. We pick four 5-core subcategory datasets namely, Automotive (A), Digital Music (DM), Tools and Home (TH) and Pet Supplies (PS). The review creation time is deﬁned as the difference in days between the original timestamp and the timestamp of the ﬁrst review in the dataset. Next we group reviews by day, since the granularity of the timestamps is day based. All users or items with less than 5 days (i.e. time series with less than 5 points) are removed from the dataset. The autoregressive language models use the review raw text, changed into lower case. Preprocessing scripts can be found at [1]. Statistics of the preprocessed data is summarized in Table Training Our model predicts ratings through the user and item dynamic representations, which come from two independent RNNs. Simply applying backpropagation through both sequences is computationally forbidden. In order to overcome this problem, we train the user and item RNNs alternately. We ﬁrst freeze the parameters of e.g. the items’ RNN, and only update those of the users’ RNN, while back-propagating the gradients of all ratings for a user batch. The items’ dynamic representations are taken to be ﬁxed. We then repeat these operations but now with the user parameters and user representations frozen. Model Conﬁguration We split each dataset along the time dimension into three parts: training set (80%), validation set (10%) and test set (10%). We use grid search on the validation set for hyperparameter tuning. We set the hidden dimension H of the temporal representation hto 32, and the embedding dimension E of zto 100. Regarding the review content models, we set the vocabulary size V to 2000 for DRR-BoW and to 5000 for DRR-LM. In the latter case we also use GloVe word embeddings [27] (these corresponds to the win Eq. (5)) with dimension 300. For DRR-LM we also set the attention dimension A to 64 and the embedding dimension Hof the (concatenation of the) temporal and summary representations to 64. We use Adam [28] with learning rate 0.0002 and β= 0.9 and limit the review length to 150 tokens. All methods are implemented using PyTorch v1.3. Source code for all models can be found at [1]. Results Given an user and item of interest, the DRR model predicts the arrival time, rating and the probability over the word sequence of the next review, and we optimize the model to give the best performance on the rating prediction task. Our methodology incorporates modeling the dynamic aspects of user-item interaction with neural models of review content. To test the importance of each of these components for the problem of rating prediction, we test our models against (i) the Probabilistic Matrix Factorization (PMF) [29], which is a static recommender system which does not model review content; (ii) the RRN [10], a causal model which learns dynamic user/item representations (albeit non-continous), but does not model review content; and (iii) three static models which do leverage review content, namely DeepCoNN [14], D-ATT [13] and AHN [12]. These last three models are noncasual since they either use the review of the item whose rate they predict, or use item reviews that have not been received by the time the item of interest was rated. Table II shows results for all models on the chosen datasets. We use boldface to highlight best results in both causal and non-causal cases. Let us start by focusing on the causal models. First we note that both DRR-BoW and DRR-LM-C outperform the RRN model, which conﬁrms the known fact that review content helps in rating prediction tasks. We remark however that in this case the models in questions are dynamic, and it is the content of past reviews what is successfully being used. Interestingly, DRR-BoW beats DRR-LM-C which may hint at the fact that TABLE I: Datasets statistics. The mean and the standard deviation of the number of reviews, sentences and words per review with respect to the user and item. Fig. 2: Upper Left: Dynamic attention on the words ’COUNTRY A’ and ’smell’ for an item in ’Pet Supplies’ dataset. Upper Middle: Review sample from the beginning of the time series. Upper Right: Review sample from the end of the time series. **The real names of the countries are replaced with masks ’COUNTRY A’ and ’COUNTRY B’ for fairness. Lower Left: Dynamic attention on the words ’comfortable’ and ’ear’ for an item in the ’Tools and Home’ dataset. Lower Middle: Review sample from the beginning of the time series. Lower Right: Review sample from the end of the time series. The darker the highlight color for a word, the higher its attention value. it is enough to know that certain key words are present in the review, as opposite to e.g. word order, to better predict the rating. Regarding the non-causal models, DRR-LM-NC outperforms all other models in almost all datasets, which shows that one indeed needs to not only account for review content, but also for its dynamic character. Remarkably, both causal models DRR-BoW and DRR-LM-C perform better than all their non-causal competitors in two of the datasets (see the Digital Music and Pet Suplies rows in the table), and comparable to them in the others. We can conclude that our models successfully learn both temporal user/item representations and review content representation which together are useful for rating prediction. Let us now consider the dynamic attention mechanism of the DRR-LM-NC, which allows us to e.g. follow in time the weights α(deﬁned in Eq. 6) of the words in the reviews for the item whose rate we aim at predicting. The higher the weight of a word, the stronger its relevance to the rating prediction. Figure 2 Upper Left shows the attention weights on the words ‘COUNTRY A’ and ‘smell’ as time evolves for a given product in the ‘Pet Supplies’ dataset. One can see that although at the start of the time series the word ‘smell’ was important for determining the rating, its relevance decreases as the weight on the word ‘COUNTRY A’ increases. After a closer look at the reviews we learn that at the start of the time series most reviews were related to the smell of the product (e.g. whether the dogs were liking the product’s smell). Later on, however, the manufacturing company moved the product production to COUNTRY A, and this event was successfully captured by our attention model. Figure 2 Upper Middle shows an example review for the item in question, from the start of the time series. Words with darker highlights mean here words with higher attention weight. One can see that the word ‘smell’ is highlighted as important. In contrast, Figure 2 Upper Right displays a review sampled from the end of the time series, in which one sees the word ‘COUNTRY A’ has more relevance than the word ‘smell’. Similarly, the Lower row of Figure 2 shows the attention weights on the words ‘comfortable’ and ‘ear’ as time evolves for a given product in the ‘Tools and Home’ dataset. In this work we proposed a recommender system model which accounts for the dynamic aspects of user preferences, as reﬂected in their history of reviews and ratings. We explicitly learn continuous-time representations for both users and items, and use these to deﬁne dynamic language models for review content. The latter provided us with review content representations which, when combined with the temporal user/item representations, proved to be useful in predicting the hidden interest of users in unknown items. Indeed, our results outperformed several state-of-the-art recommender system models in rating prediction tasks, in different datasets. We also introduced a new dynamic attention mechanism which allowed us to track the most relevant words for a given rating of an item of interest at a given instant of time. Future directions of work include developing attention mechanisms between reviews with different timestamps, and learning more generic dynamic representations able to characterize hidden dynamics global to all users. The authors of this work were supported by the Competence Center for Machine Learning Rhine Ruhr (ML2R) which is funded by the Federal Ministry of Education and Research of Germany (grant no. 01—S18038A). We gratefully acknowledge this support.