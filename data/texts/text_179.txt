The ongoing COVID-19 has been devasting in many ways. As of April cases was fallout and recession. Along with the spread of the virus, misinformation about it has also spread virally. As the Director-General of the World Health Organization (WHO) said, fake news spreads faster and more easily than this virus. This paper has been accepted for publication in ASONAM 2021. Stevens Institute of TechnologyStevens Institute of Technology mchen20@stevens.eduxchu2@stevens.edu The outbreak of COVID-19 has resulted in an “infodemic" that has encouraged the propagation of misinformation about COVID-19 and cure methods which, in turn, could negatively affect the adoption of recommended public health measures in the larger population. In this paper, we provide a new multimodal (consisting of images, text and temporal information) labeled dataset containing news articles and tweets on the COVID-19 vaccine. We collected 2,593 news articles from 80 publishers for one year between Feb162020 to May82021 and 24184 Twitter posts (collected between April 172021 to May82021). We combine ratings from two news media ranking sites: Medias Bias Chart and Media Bias/Fact Check (MBFC) to classify the news dataset into two levels of credibility: reliable and unreliable. The combination of two ﬁlters allows for higher precision of labeling. We also propose a stance detection mechanism to annotate tweets into three levels of credibility: reliable, unreliable and inconclusive. We provide several statistics as well as other analytics like, publisher distribution, publication date distribution, topic analysis, etc. We also provide a novel architecture that classiﬁes the news data into misinformation or truth to provide a baseline performance for this dataset. We ﬁnd that the proposed architecture has an F-Score of0.919and accuracy of0.882for fake news detection. Furthermore, we provide benchmark performance for misinformation detection on tweet dataset. This new multimodal dataset can be used in research on COVID-19 vaccine, including misinformation detection, inﬂuence of fake COVID-19 vaccine information, etc. COVID-19 Vaccine·Multimodal Data Repository·Misinformation·Fake News Detection·Explainable 132, 485, 386; including2, 875, 672conﬁrmed deaths [1]. This has caused panic about the possible economic WHO deﬁned the term, infodemics, as an excessive amount of information, including misinformation, disinformation and rumors that make it difﬁcult to identify a solution, hampers effective public health response and creates confusion and distrust among people [2]. Therefore, it’s necessary to track and analyze misinformation about this virus and the vaccines that have been developed for it. For e.g, a news item that claimed that the COVID-19 vaccine can alter DNA was circulated on the web [3]. Furthermore, the propagation of misinformation about vaccines affects the vaccination rates negatively, potentially leading to a worsening of the public health crisis. A study showed the number of Americans and Britons who would “deﬁnitely” get vaccinated dropped by 2.4 percent and 6.4 percent, respectively, after receiving misinformation about the COVID-19 vaccines [4]. This paper proposes a new Multimodal COVID-19 Vaccine Focused Data Repository (MMCoVaR) that includes 2,593 news articles and 24,184 related tweets with visual, textual and temporal information. Our work is inspired by [5] but with some differences which we will elaborate on later. The main contributions of our work are: • An architecture for data collection from news sources and Twitter • Annotation schemes for the • Several benchmark performances for misinformation detection for news and tweet data in this dataset With the explosion of COVID-19, a lot of datasets have been released to support big data and deep learning based analyses of the disease and its effects. One of the earliest COVID related datasets was the CORD-19 dataset [8] which is a resource of over 500,000 scholarly articles on COVID-19, SARS-CoV-2, and related coronaviruses. This dataset includes over 200,000 articles with full text. Researchers have also mined social media to create COVID-19 related datasets. Chakraborty et al [9] released two types of Twitter-based datasets; one gathered from Dec 2019 to May 2020 and the other from Jan 2020 to Mar 2020. They provide the sentiment analysis for this tweet dataset. The dataset in [10] collects 23,830,322 tweets from Mar to Apr9 (UMAP) to analyze topics distribution. The COV19Tweets [11] is a Twitter-based dataset with more than 310 million COVID-19 speciﬁc English language tweets from Mar geographical distribution of the tweets during the COVID-19 crisis and proposes a sentiment scoring system. The CoronaVis [12] is also a Twitter dataset containing tweets gathered from US-based users from Mar 22020. It focuses on sentiment and topic analysis. They also build a web application for topic trend analysis. The GeoCoV19 [13] is a large-scale Twitter dataset containing more than 524 million multilingual tweets posted for 90 days from Feb topics by countries and cities. The CoVaxxy [14] dataset is a Twitter dataset gathered between Jan 212021, focusing on geographical, topic and vaccine-related analysis. It provides a web information dashboard to track trending topics. Among these datasets, only CoVaxxy provides COVID-19 vaccine-related analysis. While the above datasets focused on mainly topic, sentiment and other geographic properties of the tweets; several researchers have also started to work on COVID-19 misinformation related datasets. We discuss these in the following subsection. The CMU-MisCov19 dataset [15] contains 4,573 manually labeled tweets with 17 categories: “Irrelevant", “Conspiracy", “True Treatment", “True Prevention", “Fake Cure", “Fake Treatment", “False Fact or Prevention", “Correction/Calling out", “Sarcasm/Satire", “True Public Health Response", “False Public Health Response", “Politics", “Ambiguous/Difﬁcult to Classify", “Commercial Activity or Promotion", “Emergency Response", “News" and “Panic Buying". The analysis in this work draws the conclusion that misinformed communities are denser and more organized 1.news articles using two news media reliability ranking websites: (i) Medias Bias Chart [6] and (ii) Media Bias/Fact Check (MBFC) [7], which allows for better accuracy of the annotation process; 2. Twitter data, using similarity based stance detection Statistical and topic analysis for fake news articles and true news articles and a summary of the differences of topic distributions between them A novel attention based architecture for fake news classiﬁcation which achieves an F-Score of 0.919 and accuracy of 0.882 2020 and utilizes Latent Dirichlet Allocation (LDA) and Uniform Manifold Approximation and Projection 12020. GeoCoV19 focuses on geographical and topic distribution analysis and provides the distribution of than informed communities, a large majority of misinformed users may be anti-vaxxers and that informed users tend to use more narratives than misinformed users when making up their minds. The Constraint@AAAI2021 dataset [16] extracts 10,700 social media posts from Facebook, Twitter, Fact Checking, etc. It is also a manually labeled dataset with two categories: real and fake. It provides benchmark performances using four baseline models: (1) Decision Tree, (2) Logistic Regression, (3) Gradient Boost and (4) Support Vector Machine (SVM). The best performance is 93.46% on the F1-score using SVM. The COVIDLIES dataset [17] identiﬁes 86 common misconceptions using Wikipedia articles on COVID-19 related misconceptions. The dataset contains 6,761 tweets, identiﬁed and human annotated by researchers. The dataset creates misconception-tweet pairs with three labels: “Agree", “Disagree" and “No Stance" which describes whether the tweet agrees or disagrees with the misconception or has no stance with respect to the misconception. The authors use BERTScore [18] to compute a similarity metric on tweet-misconception pairs and use that for stance detection. ReCoVery [5] collects 2,029 COVID-19 related news articles and 140,820 tweets containing textual, visual, temporal, and network information from Jan to annotate the news articles into two categories: reliable news and unreliable news. They also include the performance of four baseline models for fake reliable/unreliable news detection as benchmarks: (1) LIWC+DT, (2) RST+DT, (3) Text-CNN and (4) SAFE a neural network based method. Although CMU-MisCov19 [15], Constraint@AAAI2021 [16], COVIDLIES [17] and ReCoVery [5] provide labeled datasets, our dataset adds some additional value. We list the key differences below: • Finally, our dataset is focused speciﬁcally on misinformation in the realm of COVID-19 vaccination. We will elaborate more on the differences between these datasets and the proposed dataset in Section 3.3. In short, we provide a Multimodal COVID-19 Vaccine Focused Data Repository (MMCoVaR). We annotate the news dataset using two news website source checking ﬁlters and the tweets dataset based on stance detection. We also provide benchmark performances on news and tweets datasets for further comparison. As mentioned earlier, our goal is to provide a labeled dataset that comprises of news articles as well as social media posts (tweets) to support research in COVID-19 vaccine related misinformation. We detail how we collect and annotate the news data in Section 3.1 and social media data in Section 3.2. Our dataset is compared with other datasets in Section 3.3. We also provide some statistics and topic analysis in Section 3.4 and Section 3.5. Figure 1 shows a schematic overview of the proposed data collection and annotation process, for both news articles and social media. Media Bias Chart Checking [6] provides 120 websites and Media Bias/Fact Check (MBFC) [7] provides around 3700 websites with their ratings. Of these, 80 websites are common between Media Bias Chart Checking and Media Bias/Fact Check (MBFC). As shown in Fig 1, we classify these 80 websites into two groups according to our ranking system described below. The CMU-MisCov19 with 17 categories doesn’t provide any benchmark performance for misinformation detection, is a manually labeled dataset and contains fewer tweets than our dataset. The CMU-MisCov19, Constraint@AAAI2021 and the COVIDLIES datasets only provide labeled tweets dataset and not the relevant news articles. These datasets essentially do not concern themselves with the news article-tweet pairing. The ReCoVery dataset is comprehensive, consisting of news articles and relevant tweets. However, the tweets are annotated as misinformation or true by simply inheriting the label of the relevant news articles. That is, there is no stance detection involved, which might mean that a tweet that refers to a fake news article but calls it fake can be tagged as a fake tweet and vice versa. This paper also does not provide fake tweet detection benchmarks. The COVIDLIES dataset uses BERTScore to compute a similarity metric on tweet-misconception pairs and uses this as a stance detection mechanism. They do not use news articles. We propose a method to detect the stance of a tweet with respect to the news article and then use that to label the tweet. More details on our stance detection approach can be found in Sec. 3.2. Figure 1: Data collection process including news dataset and tweet dataset. The news dataset is validated using two sources of credibility. The tweets mentioning URLs of news articles are checked for stance and then labeled as reliable, unreliable or inconclusive. Media Bias Chart is a website reliability visualization tool to display fact checking information and political bias information of news sites, which are annotated by their analyzers. The reliability score from Media Bias Chart is between categorizes data into six levels of reliability using manual fact checking by their analyzers. These levels are: “Very High", “High", “Most Factual", “Mixed", “Low" and “Very Low". For our purposes, to improve the precision, we discarded the websites whose reliability levels from Media Bias/Fact Check (MBFC) are labeled “Most Factual" or “Mixed". We use the following criteria to label the remaining news articles: Then we use newspaper library [19], a news articles extraction tool, to crawl COVID-19 vaccine related news articles using the following nine keywords: “vaccine", “vaccinated", “COVID-19 Pﬁzer", “COVID-19 Moderna", “COVID-19 Janssen", “Moderna vaccines", “Janssen vaccines", “Johnson & Johnson’s vaccines", “Biontech vaccine". For the news dataset, we provide the following information: “News ID", “URL Link", “Publisher", “Publish Date", “Author Title", “Image", “Body Text", “Label". In total, the dataset contains 2,593 annotated news articles consisting of 958 unreliable news articles and 1,635 reliable news articles as shown in Table 1. We also provide the following statistics for the news articles: (i) news publisher distribution, (ii) authors distribution (number of articles written by a single author and multiple authors), (iii) news words distribution, etc. in the Section 3.4 and topic analysis in the Section 3.5. Using the Twitter developer API [20], we crawl all tweets that mention the URL of the news articles in the news dataset that we just created. Tweets were gathered from Apr of the URL of an unreliable news article does not automatically mean that the tweet is also fake. A user could be agreeing or disagreeing with the content of the news in the URL. Hence, we need to determine the stance that the tweet takes with respect to the news article mentioned in the URL. The proposed stance detection process is illustrated in the Fig 2. Recently it was shown that lexical features and readability features can be highly indicative of the stance of a written text [21]. This work used type-token-ratio (TTR), the measure of textual lexical diversity (MTLD), automated readability index (ARI), Flesch-Kincaid grade (FKG) and Flesch reading ease (FRE) and some LSTM algorithms to detect stance. 0to64;0indicates lowest credibility, and64indicates highest credibility. Media Bias/Fact Check (MBFC) If MBFC ranking is “ High" or “Very High" AND Media bias chart score is greater than 42 If MBFC factual ranking is “ Low" or “Very Low" AND Media bias chart score is below 24. In our approach, we use all of the above features, and add root type-token ratio (RTTR), corrected type-token ratio (CTTR) and Dale Chall readability score (DCR) [22] to create a handcrafted feature vector: where the is created for each news article and the tweet that mentions it. Then, we compute the similarity, the two handcrafted feature vectors using cosine similarity metric [23]. We then compute the summary of the article. We use the summary of the article instead of the entire article in order to be closer to the tweet length which is only characters long. We create a BoW vector for the summary of each news article and every tweet. Then, we estimate the similarity, BoW vectors for each of these. The average of stance of the tweet with respect to the news article. least similarity and [0.6, 1], “refute" when the score is in range Then we annotate each tweet based on the credibility of the news articles and the stance of social media as follows: “Refute" Based on the Twitter development API agreement and policy [24], we can only provide the tweet ID of the Twitter data. Additional information about the tweet can be obtained by twarc [25] or hydrator [26]. The dataset can be downloaded at [27]. In total, we extracted 24,184 tweets, including 3,092 unreliable tweets, 17,234 inconclusive tweets and 3,858 reliable tweets. The detail information of annotated news articles and related tweets is shown in Table 1. Our collection relies upon publicly available data and is registered as IRB exempt by Stevens Institute of Technology IRB (approved protocol 2021-035(N)). We release the data set with the stipulation that those who use it must comply with Twitter’s Terms and Conditions. HCF= [TTR, RTTR, CTTR, MTLD, ARI, FKG, FRE, DCR]. One handcrafted feature vector Similarity, between every tweet and news article pair by computing the cosine similarity between the If the relevant news is reliable and stance is “Support"ORthe relevant news is unreliable and stance is If the relevant news is reliable and stance is “Not Enough Information"ORthe relevant news is unreliable and stance is “Not Enough Information" If the relevant news is reliable and stance is “Refute"ORthe relevant news is unreliable and stance is “Support" Table 2: Comparison of collection process among different misinformation focused datasets. The dataset used the corresponding approach and not, respectively. In this table, MB Chart represents Media Bias Chart, MBFC represents Media Bias/Fact Check and Manually represents manual annotation. Stance Detection column captures whether the Twitter dataset uses stance detection to label tweets that mention news article URLs: only COVIDLIES and MMCoVaR use stance detection for tweet annotation. We compare the collection process and properties of our dataset with other recent COVID-19 related misinformation datasets in Table 2 and Table 3. The comparison of data collection process is shown in Table 2. As mentioned in Section 2, only CMU-MisCov19, Constraint@AAAI2021, COVIDLIES and ReCoVery datasets provide misinformation-annotated data, the rest of the datasets are not focused on misinformation and hence do not label for misinformation or truth. CMU-MisCov19 [15] and Constraint@AAAI2021 [16] use manual annotation without any web site reliability checking. ReCoVery [5] utilizes two news quality rating websites to label for misinformation after the news data and tweets have been gathered. Our proposed dataset, MMCoVaR, merges the MB Chart and MBFC to check for news site reliability. Among all the datasets, only COVIDLIES and our proposed MMCoVaR use stance detection for annotating tweets. While COVIDLIES uses BERTScore to compute similarity between a tweet and misconception pair; we use stance detection to check whether the tweet agrees with the news article or not. The properties of the different datasets is shown in Table 3. All datasets provide social media information; however, only the ReCoVery [5] and the proposed MMCoVaR dataset provide the relevant news articles information. Also, only CoVaxxy [14] and MMCoVaR provide COVID-19 vaccine related data. However, the CoVaxxy focuses on the topic analysis, geographical distribution, etc. Therefore, they do not label this dataset for misinformation. Furthermore, the time span of the dataset presented in this paper MMCoVaR is the longest one among all datasets. Table 3: Comparison of the properties of different misinformation focused datasets. The contains the speciﬁc information or not. In this subsection, we provide some additional statistics about our dataset, which may add some insight into misinformation surrounding COVID-19 vaccinations. Publication Date Distribution: the there is a steep uptick in the news articles about COVID-19 vaccines since Nov 2020. This timeline correlates with the fact that the COVID-19 vaccine became available in November and Pﬁzer COVID-19 vaccine was approved in the UK in Dec 2 News Publisher Distribution: dataset. Fig 4 (a) shows the distribution of reliable publishers which is dominated by “Business Insider" and “Chicago Sun-Times". Fig 4 (b) shows the distribution of articles by unreliable publishers and is dominated by the“Daily Mail" which contributed 463 articles, accounting for 48.3% of the unreliable news. News Author Distribution: note that the number of authors for most news articles is fewer than 5; however, reliable news articles are dominated by single author articles, whereas unreliable news articles are dominated by two author articles. Word Distribution for News Articles: unreliable news in Fig 6. The mean, median and mode of word number for both cases are: 911, 708 and 645, respectively for reliable news; 1169, 812 and 744, respectively for unreliable news. The similarity of the distribution of word count [28]. for reliable and unreliable news may indicate that the length of these articles may not be a useful feature to distinguish between real and fake news. Topic analysis is a useful tool to gather insights into the kinds of topics that are discussed in social media in all three categories of tweets (unreliable, reliable and inconclusive). In this section, we utilize Latent Dirichlet Allocation (LDA) [29] to analyze the distribution of topics in our data repository, since it is an unsupervised method and more suitable for our dataset. We extract 20 different topics using LDA analysis. Each topic was described using the 30 most relevant words for that topic. A visual representation of these 20 topics is shown in Fig 7. Each topic is represented by a circle and the size of the circle is proportionate to the number of news articles in the dataset that covers that topic. We ﬁnd that distribution of topics under the reliable news category is more dispersed than that under unreliable news category. We propose an attention based architecture that uses Longformer [30] to embed the news articles. The Longformer can capture the long-range dependencies in text to create a ﬁxed dimension embedding of the sentence/article. We preprocess the data by removing the website links, stop words and non-alphanumeric characters from the text. Then we add special tokens like [CLS] and [SEP] between sentences. Let news dataset. Let Subsequently, we feed this matrix by an attention layer, a dense layer and a softmax layer to get the ﬁnal classiﬁcation. The architecture is depicted in Fig 8 and is inspired by our earlier work on interpretable fake tweet detection [32]. nbe the language embedding of theipreprocessed news article,N, obtained using Longformer. -dimension vector. The resulting vectors,n, are used to construct the matrixM = {n, n, . . . , n}. We implement all the models in Pytorch and train them to minimize the cross-entropy loss function of predicting the class label of tweets in the training set. For all models with attention architecture in our experiments, we use a 6-layer multi-head attention (MHA) module and the stochastic gradient descent (SGD) [33] as the optimizer for training. Moreover, we split the dataset in the over-ﬁtting the model. Before we discuss the models for misinformation detection, we ﬁrst describe the handcrafted features that we use in some of these models. Handcrafted features can play an important role in misinformation detection as demonstrated in [32]. We extract the following handcrafted features: using NLTK [34], four psycho-linguistic features (‘FamiliarityScore’, ‘ConcretenessScore’, ‘ImagabilityScore’ and ‘AgeofAcquisitionScore’), four vocabulary richness features (Honore’s Statistic (HS), Sichel Measure (SICH), Brunet’s Measure (BM) and Text-Type Ratio (TTR)) and two readability features (Automated ReadabilityIndex (ARI) and Flesch-Kincaid readability (FKR) scores) [35]. Examples of some of these PoS tags are shown in Table 6. We provide the performance (in terms of accuracy, F1 score, precision and recall) of several benchmark architectures on our dataset. The comparisons are shown in Table 4 and Table 5. The benchmark architectures are described below. • Logistic Regression [36]: • Gradient Boost [37]: Gradient Boost is an additive model in a forward stage-wise fashion for classiﬁcation. • Decision Tree [38]: Decision tree is a non-parametric supervised learning method used for classiﬁcation. • Handcrafted Features+Attention (HCF+Att) [32]: • Handcrafted Features+LSTM (HCF+LSTM): Figure 8: The architecture with latent features using Longformer based sentence embedding. possible outcomes. features (HCF) for fake news detection. It can also provide explanations in a classiﬁcation task. features (HCF) for the fake news detection task. Longformer based Sentence Embedding+Attention (LFLSE+Att):LFLSE+Att is the attention based architecture we propose in this work and described in Section 4. The classiﬁcation results on news dataset are shown in Table 4. We can see that the latent features extracted using Longformer based Sentence Embedding-Attention (LFLSE-Att) performs best compared with the other architectures on the MMCoVaR news dataset using the same experiment setup with an accuracy and F-Score of 0.882 and 0.919, respectively. The performance of LFLSE-Att in terms of recall is 0.970, which is close to the best score (0.979). This points to the fact that features extracted from the Longformer are potentially more useful compared to handcrafted features for classifying news into fake or real. In addition, the performance of Handcrafted Features-Attention (HCF-Att) in terms of recall is better than the other models, while Logistic Regression performs best in terms of precision. The baseline performances of the classiﬁcation we provided here can be used for comparison with other models in the future. Furthermore, more classes of features including visual information and social media information can be added into our architecture, if desired, to construct a composite classiﬁer engine. The classiﬁcation results on tweets are shown in Table 5. Here, logistic regression outperforms other methods in terms of F-Score and Recall. The “infodemic” caused by the COVID-19 has sparked the spreading of misinformation about COVID-19 and vaccines. We provide a new Multimodal COVID-19 Vaccine Focused Data Repository (MMCoVaR) consisting of images, text, and temporal information. We combine two news media ranking websites, which allows for better accuracy of the annotation process for the news dataset. A hybrid stance detection mechanism is proposed for the tweet dataset annotation. We also provide several statistics and topic analyses on the news dataset and tweet dataset. We propose a novel baseline modular architecture for fake news classiﬁcation using the Longformer. In addition, several benchmark performances of misinformation detection on news and tweet datasets are provided. We expect to continue to add to this data repository by including: (1) more COVID-19 vaccine-related news articles; (2) social media data from more platforms like Sina Weibo (China) and Reddit (U.S.)