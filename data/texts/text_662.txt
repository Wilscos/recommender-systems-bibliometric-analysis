Reasoning with paths over user-item associated Knowledge Graphs (KGs) has been becoming a popular means for explainable recommendations [1], [2], [3]. The path-based recommendation systems have successfully achieved promising recommendation performance, as well as appealing explanations via searching the connectivity information between users and items across KGs. One category of existing works on path-based explainable recommendations seeks auxiliary meta-paths (pre-deﬁned higher-order relational compositions between various types of entities in KGs) as similarity measures and evidence for possible explanations between users and items. However, most of existing path-based methods for explainable recommendation simply treat the underlying KGs as static graphs, ignoring the dynamic and evolving nature of user-item interactions in real-world recommendation scenarios. The dynamics and evolutions of users’ interactions with items play a pivotal role in both recommendation precision and explanations for a users’ real intent. Take the scenario in Figure 1 as an example, Alice purchased a phone case and a phone ﬁlm after a recent buy of a new phone. If we ignore the sequential information between each purchase (in Fig 1a) and treat the whole information as a static graph (in Fig 1b), the system probably gives an explanation of buying the phone case is because a similar customer also bought this phone case by exploring co-purchasing relationships. Whilst the explanation, in this case, might be valid and the underlying reasoning mechanism (collaborative ﬁltering signal) can be used for recommendation, it is still sub-optimal as a more appealing motivation of buying a phone case is due to the recent purchase of a new phone. For this reason, in this example, it is important for a system to be capable of considering temporal and sequential user-item interactions and disentangling the importance of various reasons when generating possible explanations. Although some prior works have considered some extent of the sequential information for knowledge-aware path-based explainable recommendation problem, they still fail to explicitly model the dynamics of users’ activities. To allow effective reasoning on paths to infer the underlying rationale of a user-item interaction, the method proposed in [2] takes the advantages of path connectivity and leverages the sequential dependencies of entities and sophisticated relations of a path connecting a user-item pair. Nevertheless, the methods only consider the sequential information within speciﬁc paths and did not consider the importance of the user’ historical sequences on reﬂecting the user’s dynamic interactions with items. To improve, the KARN model [4] fuses the user’s clicked history sequence and path connectivity between users and items in KGs for recommen- Fig. 1: Existing Sequential modelling and static knowledgegraph based modelling. dation. However, the method models the user’s sequential behaviours and user-item interactions separately and in a coarse-grained manner (treating a user’s click history as a whole), which may restrict the expressiveness of users’ temporal dynamics on recommendation explainability. In light of this, in this paper, we challenge the problem of exploring users’ temporal sequential dynamics in the context of path-based knowledge-aware recommendation. Different from existing works that either only consider the sequential information within a path or treat the user’s sequential interactions as a whole and separately, we aim to 1) explicitly model and integrate the dynamic user-item interactions over time into the path-based knowledge-aware recommendation, and 2) leverage the captured dynamics of user-item interactions to improve the performance and explainability of the recommendation. It is worth noting that modelling users’ temporal sequential behaviour with path-based knowledge-aware explainable recommendation is a non-trial and challenging task. First, path-based knowledge-aware recommender systems are built upon the well-constructed KGs, and its expected accuracy and explainability are highly related to the underlying KGs and distilled paths. If temporal information between users and items is considered, the original underlying static KGs will be cast into multiple snapshots w.r.t. the timestamps. Comparing with the static KGs that consist of all users’ full timelines, each snapshot at a certain timestamp only has partial observations of the global knowledge, which will result in inferior recommendation performance. To deal with the issue, we devise a general framework for temporal knowledge aware reinforcement path-based explainable recommender systems, namely Temporal Metapath Guided Explainable Recommendation leveraging Reinforcement Learning (TMER-RL). TMER-RL provides a solution that can explicitly depict users’ sequential behaviour while being able to be aware of global knowledge of the entire underlying KGs. Speciﬁcally, to model the temporal dynamics between users and items, TMER-RL naturally models the task as a sequential recommendation problem and takes as input users and their corresponding sequential purchase history. To learn the sequential dependencies between consecutive items purchased by a user, TMER-RL novelly explores item-item paths between consecutive items and embed the paths as context with elaborated designed attention mechanisms to model the dynamics between user and items. Compared to existing path-based explainable recommendation systems that only consider user-item paths as evidence and support for the recommendation decision, TMER-RL contributes another creamy layer on the top of existing works, which makes use of the powerful expressiveness of temporal information between users and items. In addition, when taking paths into consideration for the above purpose, another challenge lies in the existence of a large number of possible paths. It is time-consuming for a model to select several paths that are meaningful, expressive, and have positive impacts on both recommendation performance and explainability. To this end, inspired by prior work [5], our previous work TMER [6] leverages the concept of meta-path [7] and explore diverse meta-path schemas to characterize the context of dynamic interactions between users and items. However, it has to pre-deﬁne meta-paths and randomly sample path instances from all generated ones, which involves human and random factor in the following recommendation module. To explore paths effectively, we utilize reinforcement learning with our designed useful score function for paths to mine diverse metapath instances. With resort to the powerful transformer model for sequential modelling, we also elaborate itemitem path attention and user-item path attention units to learn combinational features of multiple paths to further characterize users’ temporal purchasing motivations and their general shopping tastes, respectively. The rationale for developing such path-based attention units is that a user’s motivation towards buying a certain product is complex and consists of multiple factors. For example, when buying a new phone, a customer may consider several factors including a phone’s intrinsic features such as functionality, display, camera, etc., as well as other external factors such as the choices of their close friends, and their previous purchase of certain related electronics using the same operating system. With help of the designed path-based attention units, the proposed TMER-RL framework is able to learn different weights for various possible paths which will be then used as explanations for recommendations (we show the effectiveness of using the proposed path-based attention units for the explainable recommendation in the experiments by running case studies). Another shining point of our work is that the introduced item-item path modelling also serves as the core of the simple yet effective sequential modelling architecture of TMER-RL. The combinational meta-path enriched features learned by the item-item path attention units are aggregated with features of previous purchased item will serve as the prediction signals for the next item. The intuition behind is that the item-item paths connect two consecutive items purchased by a user, and represent various reasons and factors that may lead to the next purchased item, which intrinsically provides strong sequential dependencies between items. Compared to existing works on the sequential recommendations that rely on Recurrent Neural Nets such as (RNNs [8], GRUs [9], LSTM [2], [4]), the proposed methods in this paper is light, simple but effective. The main contributions of this paper are summarized as follows: item interactions over time can signiﬁcantly beneﬁt the recommendation performance and explainability. We introduce, to the best of our knowledge, the ﬁrst study to model users’ temporal sequential behaviour with path-based knowledge-aware explainable recommendation. considers users’ dynamic behaviours on top of the global knowledge graph for sequential-aware recommendation and explores both user-item and item-item meta-path paths with well-designed reinforcement framework and attention mechanisms for explainable recommendation. mark datasets have been conducted, and the experimental results demonstrate the superiority, effectiveness and temporal explainability of the proposed TMER-RL model. In this section, we ﬁrst give some essential deﬁnitions and deﬁne the problem. Deﬁnition 1. Information Networks. An information network is a simple graph G = (V, E). Each edge e ∈ E represents a particular relation r ∈ R of two entities(v, v) linked by edge e. Each entity v ∈ V belongs to a particular type T . (v, r, v) is a triplet means head entity vto tail entity vis with relation r. In general, relation r and its reverse ris not the same unless the relation is symmetrical. Deﬁnition 2. Heterogeneous Information Network. A heterogeneous information network (HIN) is a special type of information network. In heterogeneous information network H, edges E and entities V are in different types, that is, |R| > 1, |T | > 1. Example 1. As shown in Figure 2, A product recommendation network Gis a HIN, in which entities V could be many types, including items, users, categories, colors, brands, etc. E could represent different relations. Edges between users and items denote the buy relation, edges between items and brands denote the is brand of relation, etc. Deﬁnition 3. Meta-path. A meta-path [7] P in a network from entity vto v, is denoted as v−→ v−→ v−→ ...−→ v, where composite relation from vto vis Fig. 2: An example of a heterogeneous information network: product recommendation network r = r◦ r◦ r◦ ... ◦ r. ◦ represents the composition operator on relations. Gin Figure 2, there are many meta-paths; one of the meta-paths is UIBI, which means user → item → brand → item. In the paper, we use the meta-path instances instead of metapaths. A meta-path instance is a speciﬁc path, like u→ AirP ods → Apple → Beats Solo is a meta-path instance of meta-path U IBI. Problem 1. Sequential knowledge-aware explainable recommendation. For a user u∈ U , given the item set I, the user transaction sequence πand the item associated information network G, the target of knowledge-aware explainable recommendation is to predict top k items that uwill interact with, as well as the possible reasoning of recommended items. In this section, we introduce the proposed model Reinforcement Learning based Temporal Meta-path Instances Guided Explainable Recommendation (TMER-RL). In the remaining of the paper, we use the notation summarized in Table 1 to refer to the variables and parameters used throughout the paper. 3.1 Overview of TMER-RL Architecture The overall architecture of the proposed TMER-RL model is shown in Figure 3. It mainly consists of ﬁve components. First, to initialize users and items, we use DeepWalk [10] to embed user and item entities. Secondly, instead of pre-deﬁned meta-paths and randomly generating metapaths instances [6], we utilize a reinforcement learning with a Markov Decision Process (MDP) environment to explore useful and meaningful sequential (temporal) and non-sequential paths to improve the recommendation performance and personalization. In this step, we obtain itemitem instance paths between consecutive items using reinforcement learning framework. In the third step, after embedding instances, we use the multi-head attention to learn the weights of instances as the weights of reasoning paths for the speciﬁc user. Next, for the item updating, we employ a two-layer attention to make items contain reasoning information. This step also models the users’ sequential Fig. 3: It is the architecture of Reinforcement Learning based Temporal Meta-path Instances Guided Explainable Recommendation (TMER-RL). Here shows an example: User Alice bought iPhone 11 pro, Phone case and Phone ﬁlm in a sequential order and the training process for Alice. The number in each network block is the step order of the model. Details are in Section 3.1. TABLE 1: Description of major notations used in this paper purchased information, feeding the previous item’s feature to the next one. Finally, we feed item embeddings, user embeddings, and instances to the recommendation network to do recommendation. The speciﬁc steps are elaborated in the following subsections. 3.2 Initialize User and Item Representations We ﬁrstly learn latent representations for involved users and items by treating random truncated random walks in a user-item bipartite network as an equivalent of sentences in DeepWalk [10], which optimizes the co-occurrence probability among the entities in a walk by using skipgram based on word2vec [11]. Other recent advanced graph-based embedding initialization methods can be also applied, like GraphSage [12], GAT [13], and so on. These recent works usually can even outperform than DeepWalk. However, through extensive comparison with these methods, DeepWalk is the best choice, the possible reason behind this is because DeepWalk pays more attention to the embedding of nodes in a path, while GCNs, such as GraphSage, GAT, etc., learn embedding of each entity with the aggregated feature information from its local neighborhood. That is, these approaches pay more attention to local relationships. However, if only considering the recommendation task itself, although the local relationships are signiﬁcant, the global higher-order relationships learned by walks on a graph also play a notable role. For example, the transitivity of copurchasing relationships between friends and the substitute relationship of items can be discovered by modelling higherorder relations in a bipartite user-item graph. 3.3 Incorporating Meta-path based Context In recommendation tasks, external features related to users and items, such as product attributes, user social network, and user demographic information are usually considered as additional auxiliary information to complement traditional collaborative ﬁltering methods. However, how to utilize the heterogenous additional information efﬁciently is an open problem. Some prior works [14], [15], [16] attempted to consider social relations as the user-side information to boost the recommendation performance. To seek help from injecting more complex additional information, recent works [17], [18] introduced meta-paths into recommendation methods to describe relational compositions between various types of entities in heterogeneous information networks. In [17], the authors proposed to diffuse user preferences along different meta-paths in information networks to generate latent features of users and items. Related work [18] ﬁrstly extracts different-aspect features with meta-paths from a HIN, and then fuse aspect-level latent factors to the recommendation systems. However, these methods largely rely on the latent factors obtained from constructed metapath based similarity matrix, which are too general and only can reﬂect mutual interaction between different types of entities in a graph but cannot capture the speciﬁc information along particular path instances. Therefore, inspired by existing work [5], our prior work TMER and the proposed model TMER-RL explore to improve both recommendation performance and explainability by modelling more speciﬁc meta-path instances. Different from existing works, we differentiate metapath instances into two different categories based on the involved entities in a recommendation scenario (i.e., useritem and item-item meta-path instances). Through modelling these path instances, we learn a more detailed metapath based context to further characterize the motivations, reasons as well as leading factors between each pair of useritem interaction. While previous works such as [5] mainly focuses on modelling meta-path instances between a user and an item, this paper highlights the item-item meta-path instances, which we think is beneﬁcial in multiple aspects to sequential explainable recommender systems. Firstly, only considering user-item paths is restrictive for recommendation explainability as user-item paths only represent a user’s general shopping interests. In comparison, item-item paths are more expressive and can reﬂect devise reasons by exploring higher-order relations among items, such as complementary products (e.g., phone and a phone case), substitutable items of known items (e.g., iPhone - phone ﬁlm - Huawei Phone), co-purchased products with other people, etc. In addition, item-item paths sometimes also serve as sequential modelling signals that naturally capture the temporal dependencies between each consecutive item purchased by users, which will be of great impact for sequential explainable recommendations. Despite the powerful expressiveness of meta-paths in exploring HIN based knowledge-aware recommendation, it is still challenging mainly because the number of metapaths is too large to handle (i.e., the amount of edges is cubic to the number of entities). Taking the electric product recommendation situation for an example, for IUIBI meta-path schema, if we ﬁx the starting node - iPhone11 pro, there are many instances: iP hone11 pro → Alice → iP ad → Apple → AirP ods, iP hone11 pro → Amy → P hone case → Miracase → P hone film, and so on. Therefore, it is necessary to explore useful path instances while limiting the total amount to simplify later calculations. The path instances exploration is introduced in the next subsection. 3.4 Reinforcement Learning for Paths Exploration Our previous work [6] pre-deﬁnes use-item and item-item meta-paths on the recommendation knowledge graph, and randomly selects meta-path instances from all existing ones. The hand-crafted meta-paths not only need human efforts, but also are difﬁcult to be determined when dealing with large recommendation knowledge graphs. Therefore, we propose a reinforcement learning module to explore potential useful meta-path instances on the recommendation knowledge graph. The deﬁnition of usefulness in our work is to have contribution to the recommendation module learning. The process of meta-path instances exploration can be deﬁned as a Markov Decision Process (MDP) [19], and we use reinforcement learning to train the exploration policy. is deﬁned as S. At step t, the state Sis (e, his), where e∈ (U ∪ I ∪ B ∪ C) is the current visiting entity and his= {e, e, ..., e} is the history visited entities including the current one. Inspired by [1], [20], [21], [22], we add self-loop and inverse edges on knowledge graph G to facilitate graph traversal. entities to go. We deﬁne A= N(e) ∪ e, which means the the candidate entities are the neighbours of the current visiting entity eand itself. Moreover, we allocate each action a weight to present the probability of choosing each action. The score function of each action at step t is as follows. where hand hmean the presentation of current visiting entity and one of the actions, respectively. We believe cosine function could indicate the similarity of two entities and it is more likely to choose similar entities to form a path on the knowledge graph. However, on the knowledge graph, some entities have dense structure, leading to large action set. Thus, pruning unimportant candidate entities is necessary to improve efﬁcient. We rank each actions score descendingly and obtain top k as new action set. an action e∈ A, the transition probability to the next state S= (e, his) is to ﬁnd user-item meta-path instances and item-item meta-path instances, so the target entity is known for each user. Therefore, if get to the target entity before pre-deﬁned maximum step T , the reward is 1, otherwise 0, mathematically, R =1, if get to the target entity bef ore step T,0, otherwise ule maximizes the ﬁnal reward to learn policy π to ﬁnd useful user-item and item-item meta-path instances, mathematically, where eis the initial entity. We use REINFORCE [23] algorithm to train the objective function. According to the above MDP framework, we can get candidate user-item and item-item meta-path instances. Taking user-item meta-path instances from uto ifor an example, there should be p candidate paths. We use a score function to calculate each path’s score, mathematically, where sis each step’s action score. The rationale to choose average step’s score as the path’s score is that we do not want the length of path to inﬂuence the path’s score. We rank the score of paths descendingly and get top q candidate paths. 3.5 Parameterizing Combinational Features of Metapaths as Recommendation Context 3.5.1 Learning combinational path-based features with Self-Attention After obtaining candidate user-item meta-path instances and item-item meta-path instances, we ﬁrst regard paths as sentences, nodes as tokens in sentences, using Word2Vec [11] method and M ean(·) operations to learn path embedding. Then, we employ multi-head self-attention units to learn the meta-path based context (the User-Item and ItemItem Path Attention modules shown in Figure 3). The rationale of deploying such self-attention units here is that because, after sampling, there are still multiple paths between each pair of item-item (or user-item) representing particular distinct reasons (reasoning paths); and we observe that the reasons for buying consecutive two items are not simply unique; rather, the reasons are more complex and likely a mixture of multiple different reasons. For example, the reasons for a customer to buy a phone case right after his/her previous purchase of a new phone are probably a mixture of 1) his/her friends who own a similar phone and bought this particular phone case, 2) the phone case is the most popular match for the purchased new phone, 3) the color of the phone case matches the customer’s preference. The potential reasons can be more than the listed, and again they can be represented by using various meta-paths. Based on this observation, self-attentive properties of the Transformer model [24], we aim to learn the combinational features from multiple path instances to better characterize the complex reasons between each connected pair of entities in the KG. Attention(Q, K, V) = f(√d)V, MultiHead(Q, K, V) = Concat(head, ..., head)W, where headis Attention(WQ, WK, WV). f (.) is a softmax function. Query Q, key K and value V are selfattention variables associated with path φ, and W is the weight. dis the dimensionality (here d= 100). Concat(.) is the concatenation operation. 3.5.2 Modelling temporal dependencies with item-item meta-path instances To learn the temporal dynamics of each user, the proposed TMER-RL framework artfully resorts on the abovementioned item-item meta-path instances together with the well-designed architecture to capture the sequential dependencies between two consecutive items. Compared with most existing works on sequential recommendation [2], [4], [25] that utilize recurrent neural networks to encode the temporal effects between items in a user’s interacted sequence, the proposed TMER-RL bypasses the de-facto default deployment of RNNs or LSTMs that sometimes make the model even heavier. Speciﬁcally, the proposed framework novelly model the temporal dependencies between two items by capturing 1) the information passed from the previous item though an item-attention unit, 2) itemitem connectivity trough a speciﬁc candidate path instance. Notably, the information passed from the previous item is an attentive aggregation of previous item-item connectivity information. For example, in Figure 3, whether Alice will buy the phone ﬁlm is modelled by considering 1) the information passed from the phone case (which includes the connectivity between iphone11 pro and the phone case), and 2) the paths between the phone case to the phone ﬁlm. As a result, the long-range and short-term ”memory” in a sequence can be captured, and the extent of the goodness of the long and short term memory can be inﬂuenced by the length of the modelled sequence in different scenarios with different datasets. 3.5.3 Updating item representations After updating representations of user-item meta-path instances and item-item meta-path instances according to a multi-head self-attention mechanism, we employ a different kind of attention mechanism to update item representations. It is obvious that the current item is mostly related to the last one, which means it is better to add the last item’s information to the current one to contain temporal information. Besides, the current item is also related to the instances that arrived at this item. Therefore, we perform a twolayer attention mechanism to update item representations. Mathematically, where hand hmean the ﬁrst and second layer output of the item attention module, respectively. his the last item’s latent representation. φis the instance from the (i − 1)item to the iitem. W and b with different superscripts denote different variables’ weights and bias. g(.) is ReLU function. However, until now, here is a problem with the calculation of the ﬁrst item, because there is no item before it. To solve this problem, we involve the useritem instance from user u to the ﬁrst item into the update of the ﬁrst item, as Eq. 9 shows. Actually, the instance from u to the ﬁrst item is really important in the recommendation, because it is the ﬁrst item user has bought and most of the other bought items have a sequential relation with the ﬁrst item to some extent. That is why we embed it into the ﬁrst item. where φrepresents the path from user u to the ﬁrst item. 3.6 The Complete Recommendation Model Finally, we concatenate user, item and instances information (calculated in 3.5.2) to a vector according to Eq. 10, and get user-item prediction scores through Multilayer Perceptron (MLP) with explainability instances. where [; ] means vector concatenation. Here hdenotes the explicit mutual vector of the user, item, and implicit mutual of user-item meta-path instances and item-item meta-path instances. For the ﬁrst item, the concatenation operation is different because of the dimension problem, and therefore, for the ﬁrst item related to each user, the vector fed in MLP involves user-item instance, mathematically, After that, ﬁnal user-item rating calculates as follows. where the MLP contains a two-hidden-layer neural network with ReLU as the activation function and sigmoid function as the output layer. According to [5], [26], neural network models can learn more abstractive features of data via using a small number of hidden units for higher layers, we employ a tower structure for the MLP component, halving the layer size for each successive higher layer. We use implicit feedback loss with negative sampling [27], [28] as the whole loss function: where models the negative feedback drawn from the noise distribution P, which is a uniform distribution following [5]. 3.7 Discussion of Explanation for Recommendation with Attention Mechanism Attention Model [29], [30] was ﬁrst introduced in machine translation task and the attention weights were later widely used in natural language processing tasks as explanations in neural networks [31], [32]. Other than Natural Language Processing (NLP) tasks, the attention mechanism is also a near-ubiquitous method in recommendation tasks used as explanations in some works. [33], [34], [35], [36] However, there are different opinions on whether attention mechanism could be used as a way to explain data [37], [38], [39]. In our proposed method TMER-RL, the item-item metapath instances with attention weights learned by Item-Item Path Attention module in Figure. 3 are used as explanations. To be speciﬁc, for all existing item-item meta-path instances, we use reinforcement learning to explore some useful paths, because it is difﬁcult to process all paths whose number is large. After obtaining the candidate item-item meta-path instances, we consider these paths as the explanations for purchasing the target item. For example, in Figure. 3, user Alice has bought iPhone 11 pro, Phone case and Phone ﬁlm in a sequential order. For paths from Phone case to Phone ﬁlm, the paths includes P hone case → P hone accessories → P hone film, P hone case → M iracase → P hone f ilm and P hone case → Abby → P hone f ilm. In this situation, the explanations for buying Phone ﬁlm are that Alice has bought other Phone accessories, Alice has bought other Miracase product, and that Abby has bought the Phone case and the Phone ﬁlm together. Based on them, we use a self-attention module as Item-Item Path Attention module to learn a distribution of these paths (explanations) to further explain the recommendation. The learned weights are considered as the explainable weighted scores for the candidate item-item instances. Detailed case study is in subsection 4.8. In this section, we present our experimental settings and give analysis on the evaluation results. 4.1 Experiment Settings 4.1.1 Datasets We use two public data collections to conduct experiments, Amazon datasets[40] and Goodreads dataset[41], [42]. The Amazon dataset contains 29 categories, from which we choose musical instruments dataset, automotive dataset, and toys and games dataset. Each dataset includes brand and category as the metadata. The Goodreads dataset is a public book online rating and review collection. We select mystery thriller crime genre books and choose authors and publishers as the metadata of books. More details are shown in Table 2. We select the latest twelve items for each user and order these items by timestamps, and then we choose the ﬁrst two items as bridge items, the next four items as training items and the rest as test items. We create the Heterogeneous Information Networks using user, item, category and brand in Amazon datasets, and using user, book, author, publisher in Goodreads dataset, respectively. Last, user-item meta-path instances and item-item meta-path instances are explored according to section 3.4. 4.1.2 Evaluations We leverage Top K Hit Ratio (HR@K) and Top K Normalized Discounted Cumulative Gain (NDCG@K) as our metrics. For each positive test instance (u, i), we mix the ground truth item iwith N random negative items, then rank all these N + 1 items and compute the HR@K and NDCG@K scores. We set N = 500 and K = 1, 5, 10, 20 for evaluations. To alleviate the high-bias and low-variance of sampled metrics, we use corrected evaluation metrics introduced in [43]. For evaluation of the explainability of the recommendation, we use case studies to show the explanations in detail. 4.1.3 Baselines ommendation method using GRU. For each user, we treat the training items as a session. anism to build an explainability recommendation system. with the co-attention mechanism to learn rich metapath based context information for recommendations. torization Machines (FM) and nonlinear neural networks for prediction under sparse settings. items and corresponding temporal dynamics to model the recommendation data in a knowledgeaware and time-aware way. The enhanced item representations improve the performance. tion to employ self-supervised learning tasks to learn data representations for sequential recommendation enhancement. 4.2 Implementation Details For GRU4Rec, we use ReChorus package [47] to implement the algorithm. For others, we directly run the provided code by each paper. To fairly compare the evaluation results, we modify the each baseline’s evaluation code as the same as TMER-RL. Especially, NARRE is a rating prediction model, we turn it into a link prediction model by rating 1 positive item and 500 negative items and ranking them. 4.3 Parameter Settings We choose the ﬁrst and second items for each user as the bridge items, the training or testing process, the last 6 items for each user as the testing positive items, and the remaining 4 are training items. The hyperparameters are carefully tuned to achieve optimal results in all experiments. We implement GRU4Rec, NARRE and NFM based on the paper by pytorch package. The meta-paths and settings in MCRec are the same as the original paper. The meta-paths in FMG are User-Item(UI), User-Item-Brand-Item(UIBI) and User-Item-Category-Item(UICI). In terms of the TMER compared in the following experiments, which removes the path generation via reinforcement learning module, we use UIBI, UICI, UIBICI and UICIBI as user-item meta-paths and ICIBI, IBICI, ICICI, IBIBI, IUIUI, ICIUI and IBIUI as item-item meta-paths, where U, I, B and C denote user, item, brand and category, respectively. For our proposed TMER-RL, the learning rate for Amazon Musical Instruments dataset is 1e − 5, for the Amazon Automotive dataset is 5e −5 and for Amazon Toys and Games is 1e −4. The parameters for other baselines are searched for their best results. We set the maximum length of path instance exploration as 6 because we set 6 as the max length of meta-path in our previous work [6] and it is convenient to compare the performance. 4.4 Effectiveness Analysis on Recommendation Results We compare TMER-RL with 6 other popular and recent baselines, including four sequential recommendations (GRU4Rec, Chorus, SRec and our former proposed TMER), an explainable recommendation (NARRE),a path-based recommendation (MCRec) and a factorization machines-based recommendation (NFM) on 4 datasets with 500 negative sampling. As shown in Table 3, our proposed TMER-RL achieves the best results and in the most situations, TMER-RL could always give the correct items among 500 negative items, especially in Amazon Automotive dataset. The advantages also hold on other datasets. These results demonstrate that our framework can achieve obvious advantages through explicitly modelling each user’s sequential purchased information with the temporal paths, while NARRE and NFM ignore the sequential information for each user. MCRec ignores the item-item intrinsic relations and just utilizes useritem interactions to train the recommendation. GRU4Rec utilizes RNNs to model session-based recommendation. Chorus focuses on the way to better learning items’ representations by combining the complement and substitute relations among items on the temporal items. SRec uses different ways to pre-train embeddings to improve recommendation. However, the above three sequential recommendations all overlook the relation along paths and only focus on the temporal historical sequence, leading to worse results. 4.5 Effectiveness Analysis on Modules of TMER-RL To study the impact of the modules of TMER-RL for the recommendation performance, including the reinforcement learning path generation module, user-item and item-item instances modules, we future compare our model (TMERRL) with three variants, namely TMER, ¬UI and ¬ II. TMER removes the reinforcement learning module and generates user-item and item-item instances according to pre-deﬁned meta-paths as mentioned in 4.3. ¬ UI means we do not consider user-item instance and remove the corresponding selfattention module. ¬ II means we remove the self-attention module for item-item instances. We report the compared results with 100 negative sampling in Table 4. TMER-RL achieves the best performance on all evaluation methods, especially on Amazon Automotive dataset. We can see that the user-item and item-item instances self-attention modules signiﬁcantly boost the recommendation method, adaptively adjust the importance of different instance paths. The self-learned user-item and item-item instance paths contribute to improving the performance of recommendation ﬁnally. Especially, using the item-item meta-path instances self-attention module helps TMER-RL improve 5.87% and 6.85% on HR@1 on Musical Instruments dataset and Automotive dataset, respectively. 4.6 Variable Sensitivity To test how the recommendation perform when variable changes, we conduct variable sensitivity test on Amazon Musical Instruments dataset and Amazon Automotive dataset. Figure 4 shows the inﬂuence of learning rate of recommendation for HR@1. The x-axis represents the learning rate of recommendation, which ranges among {1e-3, 5e-4, 1e-4, 5e-5, 1e-5}, and the y-axis means the HR@1 value. From Figure 4, we could see that the HR@1 ﬂuctuation of TMER-RL is smaller than TMER so we could get the conclusion that the performance of TMER-RL is more stable than TMER. Moreover, our proposed TMER-RL could always outperform TMER with different learning rates on these two datasets. This further proves the effectiveness of TMERRL. Especially, on the larger dataset (Amazon Automotive), TMER-RL is more effective than TMER, which means our TABLE 4: Impact of User-Item and Item-Item Instances SelfAttention Mechanisms. H@K and N@K mean HR@K and NDCG@K, respectively. reinforcement learning path generation module could show superiority on a larger dataset, which is also required in the real scenario. 4.7 Impact of the Amounts of Training Data To test whether our proposed method TMER-RL could show superiority on sparse dataset, we conduct the TMER-RL and TMER on different training proportion of the full Amazon Automotive dataset. We select {0.2, 0.4, 0.6, 0.8} as the training proportion (x-axis in Figure 5) and compare the HR@1 (Figure 5a) and HR@20 (Figure 5b) of TMER-RL and TMER. (a) HR@1 w.r.t. Learning rate(b) HR@1 w.r.t. Learning rate on Amazon Musical Instru-on Amazon Automotive ments (a) HR@1 w.r.t. Training Pro-(b) HR@20 w.r.t. Training Proportion on Amazon Automo-portion on Amazon Automotivetive. Fig. 5: HR@1 and HR@20 w.r.t Training Proportion on Amazon Automotive. The x-axis represents the training proportion of the full Amazon Automotive dataset. As we can see, the more training proportion of the full dataset, the better performance of TMER and TMERRL. This is in line with the common sense because lower training proportion means sparser data, which leads to less paths generation and captures less information among users and items. This will result in lower performance of recommendation. However, in another perspective, when dealing with the least training proportion data (0.2) in Figure 5a and Figure 5b, the gap of TMER-RL and TMER is the most and the proposed TMER-RL always keep the better performance. This result could get the result that the TMERRL is more suitable for sparse dataset, which means it could explore paths in a sparse data environment and do better recommendation. Besides, the TMER-RL could always outperform TMER on HR@1 and HR@20 when the training proportion varies, which further proves the effectiveness of TMER-RL. 4.8 Case Study: Generating Explanation for Recommendation One of this work’s contributions is to give explanations on instances paths while recommending preferable items. This is because our method generates multiple item-item instance paths according to user purchase history, and then it utilizes attention mechanism to learn the weight of each item-item instance path and aggregate multiple item-item instance paths for each item-item pair. To demonstrate this, we show a random example drawn from TMER on Amazon Musical Instruments dataset. We randomly select a user, whose id is u273, and track his item-item instance paths’ parameters. In the training dataset, u273’s purchase history is i2954, i2280, i4514 and i11158. We shows several sampled item-item instance paths with high attention parameters in Figure 6 and demonstrates our explanations. for purchasing i2280. The most probable reason with the highest attention weight is that u273 has bought the last musical instrument category i2954 and i2237 with the attention weight 0.18. For the next item i4514, the reason for purchasing it is that the user u273 has bought i2280 who has the same brand and category with item i4514. There is also only one item-item instance path between some items because the item-brand and item-category data are sparse. Therefore, our method can model the reason through item-item instance paths with different weights. tion according to user purchase history thanks to item-item instance paths. These item-item instance paths learn the reason path from the current item to the next item. In the whole model, these reason paths will feed to the item attention module. Therefore, our model can recommend with learned sequential information. 4.9 Case Study: Generating Paths via Reinforcement Learning Compared with randomly generating paths according to pre-deﬁned meta-paths in our previous work [6], we design and implement a reinforcement learning framework to learn and mine instances in this work. Also, instead of randomly choosing paths among large amount of instances, we design a rank method to sort the scores of generated paths and get top k paths to feed into the following modules. We provide a case study for paths generation by reinforcement learning framework on Amazon Musical Instruments dataset. Details are shown in Figure 7. To be consistent with 4.8, we also choose u273 as the example. i2954 (Microphone Pop ﬁlter) and i2280 (Right Angle Instrument Cable) are the ﬁrst and the second items for u273. We summarize the generated 10 paths to schemes in Figure 7. The generated paths schemes contain, IIBICI, IICICI, ICICI and IICI. Although the number of summarized schemes is less than that of pre-deﬁned meta-paths, the generated paths via reinforcement learning contributes to recommendation more than randomly generation, which could be proved in the above experiments. To be speciﬁc, when randomly generating, the learned paths will be exactly consistent with the pre-deﬁned meta-paths, but it is unsure that the generated paths are useful for the recommendation. However, utilizing reinforcement learning to mine paths could at least guarantee the correlation of nodes on the paths because of the action calculation during exploring. The proposed ranking equation could obtain the k most relevant paths. Moreover, the pre-deﬁned meta-paths may not be able to deﬁne some more useful schemes. For example, in Figure 7, there are 4 schemes, but only ICICI is pre-deﬁned meta-path in TMER. Furthermore, if the meta-path deﬁnes all existing conditions and considers all situations, the calculating complexity will be very large. Therefore, using reinforcement learning to explore schemes is a better choice. Early recommendation systems mostly rely on Collaborative Filtering (CF) [49], [50], which are based on the idea that users with similar history will be more likely to purchase similar items. However, CF-based recommendations always have sparsity issues and cold-start problems. Therefore, some works utilize side information, like user and item attributes [51], item contents [52] to solve this issue. Among them, methods based on knowledge graph [1], [2], [4], [53] show great advantages in the recommendation performance and explainability. Knowledge graph-based recommendations are roughly be categorized into embedding-based approaches and pathbased approaches. Prior efforts on embedding-based knowledge graph recommendations [54] always use embeddings of the knowledge graph to model the user-item interactions for recommendations. For example, exiting works [55] utilizes TranE [56] to embed user-item interactions to integrate knowledge into the recommendation system. Similarly, [57] embeds user and item vectors into the same embedding space for recommendation. The above approaches model the relations of users and items using knowledge graph embedding methods, which achieves great improvement in model expressiveness. However, these methods are sensitive to the quality of related knowledge graphs. Fig. 6: It shows u273 and related historical purchased items in the upper part of the ﬁgure. In the lower part, it displays the reasoning item-item paths along this historical purchased items related to u273. Green blocks represent the category attributes. Blue blocks represent the brand attributes. Black blocks without physical pictures do not have meta information in the dataset. Fig. 7: Summary of 10 generated paths via reinforcement learning from i2954 to i2280 for u273. To this end, meta-paths [7], and the connectivity of different types of nodes are introduced to recommendations, which have the ability to learn the explicit expression along each meta-path schema. In [58], the authors introduce Matrix Factorization (MF) and Factorization Machine (FM) to learn similarities generated by each meta-path for recommendation. [18] models rich objects and relations in knowledge graph and extracts different aspect-level similarity matrices thanks to meta-paths for the top-N recommendation. Although they achieved appealing performance, the limitation is still obvious that structured meta-path based similarity latent factors can only reﬂect mutual infectivity along meta-path schemas in a graph but cannot capture the speciﬁc information along particular path instances, which limits the explainability of recommendation. More recently, injecting meta-paths as recommendation context (aggregation of meta-path instances) [5] was introduced for top-N recommendation. It provides ﬁnegrained explanations based on speciﬁc instances. However, it ignores the important sequential dynamics of user-item interactions, which limits the performance of the recommendation performance and interpretability. To consider the sequential information, [2] utilizes LSTM to model the sequential information, but it only considers path-based sequential information between users and items and ignores the importance of the user’s clicked history sequences, which are highly informative to infer user’s preferences. To tackle this issue, [4] attempts to model the sequences of user’s behaviours and path connectivity between users and items for recommendation. Nevertheless, it only considers user-item paths, which ignores the item-item intrinsic relation information and cannot learn some complex semantic information between items. Moreover, it has to pre-deﬁne some meta-paths and randomly sample metapath instances, which involves too much human efforts and random factor. Based on the above research, we propose a reinforcement learning based path exploration for recommendation with differentiated user-item and sequential item-item instances to enhance the learning ability for explainability recommendation. We propose TMER-RL, which explicitly models dynamic user-item interactions over time with path-based knowledge-aware explainable capabilities. We explore itemitem paths between consecutive items with attention mechanisms for users’ sequential behaviour modelling via a reinforcement learning framework. For evaluation, we conduct 6 sets of experiment to prove the effectiveness of TMERRL, including comparing with 8 state-of-the-art baselines on 4 datasets to show the high performance, ablation test on modules of TMER-RL to analysis the importance of each module, variable sensitivity test to show the inﬂuence of the learning rate varies, impact of the amounts of training data to prove the ability to process sparse data, case study to explain the way to explain recommendation via generated paths and another case study to show the generated paths via reinforcement learning framework. All the above experiments have proved the explainability, effectiveness, highperformance of the TMER-RL. Future works may include the following directions: 1) generate human-readable explanations for recommendation with NLP techniques, and 2) explore causality learning [59] to discover more appealing paths for explainablity.