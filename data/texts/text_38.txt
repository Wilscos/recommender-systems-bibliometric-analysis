Centre for Big Data Research in Health (CBDRH) Keywords Recommendation system · Causal Inference · Continuous Treatments · Survival Outcomes Continuous treatments or exposures (such as dose, duration, and frequency) arise very often in clinical studies. Importantly, such treatments lead to effects that are naturally described by curves (e.g., dose response curves) rather than scalars, as might be the case for binary treatments. Two major methodological challenges in continuous treatment settings are (1) to allow for a ﬂexible estimation of the dose response curve (for example, to discover the underlying structure without imposing a priori shape restrictions), and (2) to properly adjust for high-dimensional confounders (i.e., pre-treatment covariates related to treatment assignment and outcome). The application of data-adaptive models to healthcare has yielded great advancements in personalized medicine. The vast majority of these focus on diagnosing conditions or forecasting outcomes, yet few on treatment recommendations. Reinforcement learning has been proposed as a solution to ﬁguring out the optimal policy in the context of clinical studies for treatment advice to individual patients, but there remain many challenges in learning and evaluating on primarily observational data. The most prominent is the problem of confounding bias, where unobserved factors (confounders) affect both observed treatment assignment (policy) and the patient outcome and result in biased estimation and recommendations. In this study, our goal is to apply theories of statistical causal inference to provide debiased treatment recommendations to patients. Speciﬁcally, we focus on the observational setting, that is, the setting in which our recommender will propose treatment levels based on confounding-adjusted estimations of the treatment effect, and evaluate the patient’s elliott.zhu@unsw.edu.aub.gallego@unsw.edu.au We propose a general formulation for stochastic treatment recommendation problems in settings with clinical survival data, which we call the Deep Survival Dose Response Function (DeepSDRF). That is, we consider the problem of learning the conditional average dose response (CADR) function solely from historical data in which unobserved factors (confounders) affect both observed treatment and time-to-event outcomes. The estimated treatment effect from DeepSDRF enables us to develop recommender algorithms with explanatory insights. We compared two recommender approaches based on random search and reinforcement learning and found similar performance in terms of patient outcome. We tested the DeepSDRF and the corresponding recommender on extensive simulation studies and two empirical databases: 1) the Clinical Practice Research Datalink (CPRD) and 2) the eICU Research Institute (eRI) database. To the best of our knowledge, this is the ﬁrst time that confounders are taken into consideration for addressing the stochastic treatment effect with observational data in a medical context. outcome based on the historical data. This retrospective setting is common in healthcare applications, where it is impossible or unethical to experiment with alternative treatment strategies on patients. The confounding bias is perilous when there is a signiﬁcant lack of support in the examined cohorts, such as the lack of data on nontreated patients, where patients with critical conditions, despite receiving treatments, frequently experienced adverse outcomes. This leads to the earned policy suggesting no treatment or treatment that physicians would never do. And measures such as importance sampling and U-Curve share the same failure when evaluating the policy given there is no similar patient under different treatment conditions [ incorporates the general propensity score approach (GPS) [ survival curves for potential confounders. Despite the frequency of survival outcomes in biomedical research and the increased use of GPS, there are, to the best of our knowledge, no nonparametric studies applying GPS for estimating the effect of stochastic exposure on time-to-event outcomes. Secondly, we propose a recommender based on the potential difference in survival curves given the alternative and the original treatment levels. Compare to binary mortality outcomes, the survival curves possess the merit of balancing the short-term improvement with long-term success, which is discussed in our previous work on estimating the survival treatment effect. [ such as the periodic reduction in white blood cells or the terminal outcome such as death. The survival curves, on the other hand, provide the survival probability as a uniﬁed feedback to clinicians which incorporate the effect of short-term events on the long-term probability of survival. Two recommender algorithms based on random search and reinforcement learning were compared and found to have similar performance. As most major breakthroughs in deep learning have been trained on years worth of simulated data. Clearly, it is infeasible to obtain a large amount of data for a speciﬁc treatment in an observational context. We validated our model, which we called the Deep Survival Dose Response Function (DeepSDRF), mainly through simulators. The performance of the corresponding recommenders was in addition tested in a case study based on pseudo treatments created from the Clinical Practice Research Datalink (CPRD). [ generated using the eICU Research Institute (eRI) database [ problem of sepsis treatment in intensive care units (ICUs). Another is the health economic problem of the optimal timing to send patients from the ICUs to Step Down Units (SDUs). Across simulated and real datasets, we show that the proposed treatment effect estimator DeepSDRF, and its associated recommendations are robust to confounders and improve the patient outcome. Our proposed work solves three major methodological challenges in continuous treatment settings: (1) to allow for a ﬂexible estimation of the dose response curve (i.e., to discover the underlying structure without imposing a priori parametric restrictions), (2) to properly adjust for high-dimensional confounders (i.e., pre-treatment covariates related to treatment assignment and outcome), (3) to enable the estimation of the effect of stochastic treatments on survival outcomes. In Section 2, we discuss the methodology and the study design. We present the results in Section 3 and conclude with a discussion. Our major goal is to measure the effect of stochastic intervention on the time-to-event outcomes. This causal parameter will be used for providing causality based treatment recommendations in a dynamic clinical context to individual patients. Current approaches for estimating the effect of stochastic intervention are based on regression models (i.e., the dose response function) of continuous outcomes on covariates and treatments.[ entirely on the correct speciﬁcation of the outcome model and is sensitive to the curse of dimensionality by inheriting the rate of convergence of the outcome regression estimator. The alternative generalised propensity score model approaches [2,8,9] manage to correct the selection bias of the treatment assignment, but they still rely on the accurate choice of the treatment propensity model. In contrast, doubly robust estimators [ consistent treatment effect estimations as long as one of these two data generating processes is accurately modeled. The doubly robust methods converge faster than their nuisance estimators (i.e., outcome and treatment models) when both models are consistently estimated; this makes them less sensitive to the curse of dimensionality and can allow for inference using ﬂexible machine learning-based adjustment. However, standard semi-parametric doubly robust methods for estimating dose response functions rely on the parametric model of the effect curves, either by explicitly assuming a parametric dose response function [ 3,4] For example, when monitoring sepsis patients, popular outcome choices would be biomarkers model.[13 can be of limited practical use if the working model is far away from the truth. Recent work has extended semi-parametric doubly robust methods to more complicated nonparametric and highdimensional settings. The work of Super-Learner[ mator selection in causal inference problems, and particularly in the average treatment effect estimation on survival outcomes.[ on survival outcomes with static covariates [ subnetworks in the working paper of Causal Dynamic Survival (CDS) model. [ assumptions on binary treatment to estimate the effect of time-varying stochastic treatments on time-to-event outcomes. We present a new approach based on the doubly robust dose response function but without parametric assumptions. Our method has a simple two-stage implementation that is fast and easy to use with standard software: in the ﬁrst stage, a general propensity score (GPS) model is constructed based on the mapping between the treatment and covariates; and in the second stage, we regress the estimated propensity score and the treatment on the survival outcomes designed similar to our previous studies.[ tools. We provide the asymptotic results of our approach with extensive simulations. We also discuss a simple method for general propensity score estimation when the probability density function of the treatment assignment process is unknown. The method is validated via simulations and an empirical database and illustrated in two case studies which will be discussed later about the sepsis treatment in intensive care units (ICUs) and the decision of early discharge from ICUs to step down units (SDUs). 2.2 Conditional average dose response function for survival outcomes With time-to-event outcomes, we suggest that the concept of the dose–response function requires modiﬁcation. If one were to use the deﬁnition of the dose–response function used for continuous or binary outcomes, then the value of the dose–response function for a given value of exposure would denote the expected survival time under that value of the stochastic exposure. There are two limitations to this approach. The ﬁrst limitation is that it can be difﬁcult to estimate the mean survival time in the presence of a moderate to high degree of censoring. The second limitation is that differences in survival time are not quantiﬁed by a standardised measure of treatment effect. Instead, differences in survival are often quantiﬁed using differences in survival curves. For these two reasons, we propose that the dose–response function be modiﬁed so that the dose–response function for a given value of the stochastic exposure denotes the survival function if all subjects in the sample were to receive the given value of the exposure. Formally, suppose we observe a sample O of n independent observations generated from an unknown distribution P whereX Θbeing the maximum follow-up time of the study; at timet, t, whichever happened ﬁrst. For simplicity, we drop individual indicator a common probability space, that well-deﬁned random variable (this requires that the random function a dose–response surface measured in terms of the hazard rate at time t over a history of treatment levels a ∈ A as: which is the probability of experiencing an event in the interval and covariates from for each patient the trajectory of calculate the dose response surface, we assume the potential treatment level would be ﬁxed at the follow-up period. Thus, the probability of an uncensored individual will experience the event in time athroughout the follow-up period can be written as a product of terms, one per period, describing the conditional probability that the event did not occur since time 0 to t − 1 but occur in period (t − 1, t]: ] Unfortunately, the ﬁrst approach can lead to substantial bias under model misspeciﬁcation, and the second 14] We applied this framework to estimate the conditional average treatment effect of binary interventions (t) = (X(t), X(t), . . . , X(t)), d = 1, 2, . . . , Dare baseline covariates at timet,t = 1, 2, . . . , Θ,with Y= 1ifiexperienced an event andY= 0otherwise;tis determined by the event or censor time,tor Similarly, the probability that a censored individual will experience an event after time terms describing the conditional probability that the event did not occur in any observation: which is also the population survival function. We use the general propensity score (GPS) to eliminate the biases associated with differences in the covariates.[ This approach consists of two steps. First, we estimate the conditional expectation of the survival outcome function of two scalar variables, the treatment level function at a particular level of treatment, we average this conditional expectation over the GPS at that treatment value. Speciﬁcally, let us follow the deﬁnition in Imbens’ work[ received, is deﬁned as: and the GPS is propensity score. For a stratum with the same value of of the value of X: This implies that the assignment to treatment is unconfounded given the generalized propensity score: Proof. The LHS of the Equation 3 can be written as: And the RHS of the Equation 3 can be written as: Therefore, for each a, Equation 3 holds.  Equation 3 implies that if the assignment to the treatment is weakly unconfounded, given pretreatment variables have: Proof. Let Bayes rule and Equation 3 tell us: G(a, x) = g(A = a, X = x). The GPS has a similar balancing property to that of the standard f(·|a, g)denotes the conditional density ofS(t, a)givenA = aandg(a, X) = g. Then, the f(s(t)|a, g) =f(a|S(t, a) = s(t), g(a, X) = g)f(s(t)|g)f(a|g(a, X) = g) Then our causal parameter of interest, the survival conditional average dose response (CADR) function with respect to a subgroup X = x can be denoted as: and the population survival average dose response (ADR) function will be: In the following sections, we may drop the notation curve over time, that is: 2.3 Estimate of a dose response function through recurrent neural works The previous section describes the approach for identifying and estimating the CADR function for survival outcomes using the GPS approach.Two functions need to be modeled: the conditional expectation the GPS function random seeds to model both quantities in opposition to the semi-parametric and parametric model as discussed in previous sections. In particular, as detailed in our previous work on modeling the survival outcome[ outcome label Y The output of our model will be a probability of surviving a time interval, which will be curve will be given by neural networks with input from the observed treatment trajectory of each individual and the corresponding GPS. That isY= f(A, treatment generating process. The probability density function (PDF) of a data generating process only can be accurately measured by standard statistical distributions. For an unknown data generating process such as the treatment assignment process, we propose to use the recurrent neural network with the basis expansion technique for the univariate response conditional dense estimation (CDE) problem as a series of univariate regression problems as detailed in the FlexCode study.[16] Speciﬁcally, we will have: t ∈ [1, 2, . . . , Θ]givenaandx. In addition, we denote the term¯ψ(a, x)to indicate the mean CADR over g(A, X)in Equation 2. We propose to use an ensemble of recurrent neural networks with varying ˆG)), whereˆGis a plug-in value calculated from the estimated density functionˆg(A, X)based on the wherea covariates from g(a, x)onto the basis vectors. We can estimate these coefﬁcients by regressing the transformed response variables φ(a)on predictors coefﬁcients in Equation 5, we computes the coefﬁcients jointly with a recurrent neural network that minimizes the CDE loss: Since the true g(a using the trajectories of discussed in the original FlexCode study. In this study, we use Bayesian optimization [ outcome model, we tune the following hyperparameters: • Batch size n ∈ [min(128, N), N], where N is the sample size; • Number of dense layer L ∈ [1, Θ]; • Number of dense layer units Lu ∈ [1, D], where D is sample dimension, and; • Number of gated recurrent units (GRU) [18] Gu ∈ [1, Θ]. In addition to the above hyperparameters, the GPS model also tunes the following: To capture the estimation uncertainty of the proposed model, we create an ensemble of structure but varying random seeds. Hence, the ﬁnal estimate of the survival outcome will be with each byg(a, x) = combination of m × m models: where the subscripts deviation is straightforward. In our simulation and case studies, we choose not change the conﬁdence interval of the estimation by a meaningful amount. 2.4 Integrating causal parameters with automated treatment recommendation In clinical studies, patients are subject to different levels of risk based on their prognostic features, biomarkers, and treatments received. We generalize this assumption as follows. Let us assume that each treatment level an independent risk function given by the survival CADR function potential CADR averaged over time to calculate the personal risk ratio of prescribing one treatment option over another. We deﬁne this difference of log CADR as the recommender function: is the observed treatment level at timetandxis deﬁned similar as in section 2.2 as the trajectory of historical t−utot−1for an individual.φ(·)is an orthonormal basis like a Fourier or wavelet basis for functions . By the orthogonality property of the basis, the expansion coefﬁcientsβ(x)are orthogonal projections of Length of the history windowu ∈ [1, Θ], whereΘis the maximum follow-up period (This parameter is ﬁxed in the simulation study.); The number of basis functionsj ∈ [30, 60], the choice of parameter range is by trial and error with various simulation studies that will be discussed in the later sections. f(·)trained with a different random seed yet on the same data. Likewise, the GPS will be modeledPP The recommender function can be used to provide personalized treatment recommendations. We ﬁrst pass a patient through the network once in treatment group receives a positive recommendation the patient should be prescribed treatment a While this approach is feasible for a set of discrete treatments, for stochastic interventions we face the undesired choice to discretise the continuous treatment options. To avoid this subjective decision, we propose two methods for comparison in this study: In both methods, we restrict the set of actions to frequently observed treatment levels (i.e., values fall in the 90percentile of the observed treatment values.) taken by clinicians. As such, the resulting RL policy suggests the best possible treatment among all options chosen (relatively frequently) by clinicians. Random search (RS): This approach is inspired by the random search technique for ﬁnding the optimal hyperparameters of a neural network model. Here we pose the optimal treatment option as the hyperparameters in the model. By specifying a searching space bounded by the observed set of treatment levelsA. We locate the optimal treatmentaby calculating the expected recommender valuer(x, a, a)over randomly selectedainπand comparing it with the original treatment level a. In this study, we limit the search for the optimal treatment at the commencement of the follow-up window. This is because of the fact that by varying the level of initialathe entire survival curve will respond accordingly during the follow-up window. For fully dynamic treatment decisions, this framework can be easily extended to search aat the beginning of each time interval during the follow-up window. Reinforcement learning (RL): We performed an evaluation of the actual actions (policy) of clinicians using temporal difference learning (TD-learning) of a state-action value function (Q) by observing all prescriptions of treatments in existing records (ofﬂine sampling) and computing the average value of each treatment option using the pseudo environment created by the estimated survival CADR function. The advantage of TD-learning over policy iteration is that it does not require knowledge of the Markov decision process (MDP) and is model-free, which makes it possible to learn simply from sample trajectories.[19] It was computed iteratively from actual patient episodes of successive state-action pairs using the following updating formula: WithQ(a, x)being the current {action, state} tuple,Q(a, x)the next {action, state} tuple,αthe learning rate,rthe immediate reward andγ, the discount factor. We chooseγ = 0.99to model the fact that a future reward of higher survival probability is worth as much as the immediate survival probability. In this study, the state refers to the prognostic features and biomarkers observed during the history window. The immediate reward function r is deﬁned as the recommender function r(x, a, a) in Equation 6. We learn the optimal policy (which we call the RL policy) for the MDP using policy iteration, which identiﬁes the decisions that maximize the expected survival outcome of patients. Policy iteration started with a random policy that was iteratively evaluated and then improved until converging to an optimal solution. After convergence, the RL policy πcorresponded to the actions with the highest state action value in each state: Consistent with the RS approach, we estimate the optimal policyπ∗at the commencement of the follow-up window across patients. Thus, the corresponding value V of a policyπis computed using the one-step Bellman equation for Vand represented the expected return when starting in x and following π thereafter: where Q(a, x) =ˆψ(a, x) + r(x, a, a). Our simulation study assumes the patient’s survival probability follows a standard exponential distribution with timevarying risk over time, where the conditional distribution of the hazard rate for each time interval, treatment level a, is and the conditional mean of unit exponential, thus the marginal mean of h(t, a) is obtained by integrating out the covariate to get The derivation is presented in Appendix A. The corresponding survival CADR function following Equation 1 and 4 is with a and x indicate the trajectory time-varying covariates and treatments, respectively. We conduct simulations by generating the following variables: • D continuous covariates X(0) • Censoring probability: C(t) = exp(− • Survival probability given by Equation 8: S(t) = • Survival outcome given by indicator function: Y = I(T ≤ C), and; • The maximum follow up time is 12 time steps. A series of experiments were conducted by changing the following parameters: η ∈ {0.1, 0.5, 1} length of the history window on the accuracy of the estimated survival CADR. In particular, we investigate the length of the history window of size 0.5, N = 3000, and H = 1 with the same parameters but different random seeds. All evaluations are based on testing samples. We performed retrospective empirical analyses using three cohorts: distribution andD = dis the feature dimension. We update their value at timetasX(t)= X(t − 1)/t to construct the time-varying baseline; A stochastic exposure:A ∼ Exp(η/DPX(t)> +(1 − η) · 0.5), whereηcontrols the level of overlapping. Whenη = 0, the probability of receiving the treatment is independents ofX(0); whenη = 1, the allocation follows the mean of X(t); and when η = 0.5. An event indicator generated using root-ﬁnding [3] at each timet:E(t) = I(S(t) < U ∼ Uniform(0, 1))), with the event time deﬁned by T = t if E(t) = 1, otherwise T = max(T ) + 1; A censoring indicator generated using the root-ﬁnding technique:CE(t) = I(C(t) < U ∼ Uniform(0, 1))), with the censoring time deﬁned by C = t if CE(t) = 1, otherwise C = max(T ); ,N ∈ {1000, 3000, 5000}. In addition to the simulation parameters, we also test the effect of the The Clinical Practice Research Datalink (CPRD) database. [5] We captured a cohort of 20,270 patients (AF Age) with non-valvular atrial ﬁbrillation (AF) receiving either Vitamin K Antagonists (VKAs) or Non-Vitamin K antagonist oral anticoagulants (NOAC) during a follow-up period up to 36 months. To test the validity of the model, we used age as a pseudotreatment and modeled its impact on patient mortality. The null hypothesis The performance of DeepSDRF is assessed with simulation studies using the three metrics described below: Absolute percentage bias (Bias): treatment effect: for testing is that the recommended age should be the same as the original age of the patients. The summary statistics of the database are presented in Table 1, and a detailed description of the cohort can be found in our previous work. [20] The multicenter explantory cohort study utilizing ICU patients in the eICU Research Institute (eRI) database with complete hospitalization between January 1, 2007 and March 31, 2011. Detailed descriptions of the eRI database are provided in the original data report. [6] In the ﬁrst eRI cohort study, we tackle the problem of the optimal treatment strategies for sepsis in ICU as initially presented by Komorowski [21] from the angle of causal inference by assigning the treatment with the highest expected gain in average survival probability over a period of 48 hours. This cohort (eRI Vesopressor) includes 6,225 patients with eRI who experienced sepsis according to the Sepsis-3 deﬁnition [22] and having been treated with vasopressors. The interaction between the vasopressor dosage and the mortality of patients up to 48 hours in ICU was modeled. In hospitals, Step Down Units (SDUs) provide an intermediate level of care between the Intensive Care Units (ICUs) and the general medical-surgical wards. Because SDUs are less richly staffed than ICUs, they are less costly to operate; however, they also are unable to provide the level of care required by the sickest patients. Using the eRI dataset, we generated the third cohort (eRI Early Discharge) with 3,527 patients that have been sent to SDUs to understand whether and when the SDUs should be used. We modeled the relationship between the length of stay in ICU (ICU hours) and the terminal discharge status (i.e., discharged to home or not) of these patients in SDUs up to 180 hours. Compared to the previous study [23] which models the ﬂow dynamics between the ICU and SDU to ﬁnd the optimal allocation of patients to SDU, our model demonstrates the decision should be based on the optimal timing to send a patient to SDU when the terminal outcome can be potentially improved. We detailed the inclusion criteria of eRI cohorts in Appendix D. Coverage ratio: of the posterior distribution of the estimated individual treatment effect. whereIis an indicator function, Root-mean-square error (RMSE) effect: To test the performance of DeepSDRF on the estimation of conditional average dose response (CADR), we repeated and averaged the results from 50 iterations of each simulation. The performance of DeepSDRF was benchmarked against a plain recurrent neural network with survival outcome as described in the benchmark algorithms in our previous work [ the survival recurrent neural network (SNN), which uses the standardised value of the original features as the regressor instead of using the GPS and the treatment level. We conducted the study using Python 3.9.0 with Tensorﬂow 2.5.0 [ (code available at the time series data, we use the masking layers as described in previous studies. [25, 4] 4.1 Potential outcome estimation performance of Deep Survival Dose Response Function We compared the performance of DeepSDRF with the plain recurrent neural network for survival outcomes (SNN) in Table 2. Across four values of sample dimensions, DeepSDRF has signiﬁcantly outperformed SNN across the three captured metrics. In particular, our proposed causal model has approximately doubled the coverage ratio for the true treatment effect for treatment values in the 15th (included) to the 85th (included) percentile of observed treatment levels. Refers to the percentage of times that the true treatment effect lies within the 95% quantile intervals In Figure 1, we plot the conditional average dose response (CADR) for both models by treatment levels and time and compared them to the truth. In addition to the nominal estimation performance on CADR, DeepSDRF also has better performance in estimating the individual dose response (IDR), and its RMSE is only one-ﬁfth of the SNN. Figure 1: Conditional average dosage response function by benchmark models. Results from DeepSDRF and SNN are from one randomly selected simulation under the default scenario. An interesting setting for testing causal model performance is to tweak the levels of overlap. In the second section of Table 2, we varied the level of overlap and kept all other parameters under the default setting and found that our estimation has declined accuracy when the level of overlap is high, but has a similar level of accuracy when the level of overlap is low or medium. To improve the estimation performance under high overlap scenarios, we conducted an analysis with different sample sizes as shown in the third section of Table 2. Increasing the sample size from ratio from 0.560 (0.360,0.759) to 0.799 (0.642,0.956), but at the same time, the point estimation Bias for CADR when the sample size is at similar levels when the sample size is 3, 000 and above. The third section of Table 2 examines the scenarios by including history windows from one time step to six time steps in the outcome model of DeepSDRF and SNN. As the GPS model in DeepSDRF has already captured, the historical information, including additional history in the outcome model of DeepSDRF does not improve the performance. In comparison, SNN uses the outcome model to capture the historical information and has improved performance with a longer history window. The simulations with larger sample size achieved better coverage with higher estimation variance. As shown in the last section of Table 2, we saw the average standard deviation of the CADR estimations across samples is about doubled when the experiments have is increasing with sample size, but the level is lower. In contrast to binary/discrete treatments, the evaluation of the dose response function for stochastic treatments will face the challenge of estimating the penitential outcomes of rare treatment values. In Table 3, we conducted stress tests on rare values of treatment (i.e., the value falls below the 15th percentile (excluded) or above the 85th percentile (excluded) of the observed treatment values). Compared to Table 2, where the potential outcomes are assessed by more common values, the coverage ratios are about halved when the treatment values are in the lower 15th percentile, and when the treatment values are in the upper 15th percentile, the coverage ratios have declined by about a third. In both tails, DeepSDRF has higher accuracy and lower magnitude of degrading than SNN. Overall, we found DeepSDRF has stable performance regarding the sample dimension. At the cost of higher estimation variance, we can improve the model performance under high confounding scenarios by increasing the sample size. The separation between the GPS and outcome models makes the DeepSDRF insensitive to the historical windows modeled in the outcome model. The model has more reliable estimations for commonly observed treatment values. We applied DeepSDRF to recommend treatment to patients at the commencement of their follow-up. In the ﬁrst section of Table 4, we record the distribution of the original and recommended treatments from one sample generated under the default scenario. The average recommended treatment by DeepSDRF using random search (RS) is 0.017 (0.0166,0.0169) 10, 000is about4%worse than the sample size of3, 000. On the other hand, the RMSE for IDR are and using reinforcement learning (RL) is 0.017(0.0167,0.0171). While using the SNN, the recommendation with RS is 0.014(0.0144,0.0145 and with RL is 0.014(0.0141,0.0143). Generally, there is minimal difference between the RS and RL values under both models. Using DeepSDRF, the average treatment value is 0.008 (0.0080,0.0082) higher than the original value.The variance of the recommended treatments is at the same level as the original treatment. Figure 2: Comparison of survival curves by recommendation schema. The depicted survival curves are averaged over 50 samples generated under the default scenario and following the optimal DeepSDRF or SNN recommendation in each sample. The second section of Table 4 summarises the average survival probability of DeepSDRF/SNN-recommended patients and the probability estimated using the original treatments. We visualise the corresponding survival curves in Figure 2. Following the recommended treatment plan from DeepSDRF, the average survival probability of the patients is 0.816(0.806,0.826), which is 0.035(0.027,0.043) higher than the original plan, however the survival probability following SNN recommendations has negligible improvement compared to the original. In Table 4, we also observe that the standard deviation of the DeepSDRF outcomes is lower, where the difference between the higher and lower bound of the 95% conﬁdence intervals is 0.004 and the original one is 0.024. We apply the random search technique to DeepSDRF in all empirical studies due to its higher efﬁciency compared to reinforcement learning. We keep the null hypothesis that the DeepSDRF treatments have the same distribution of the original pseudo-treatments of age (see Figure 3a) values from the two polices is only 0.11(-0.010,0.230). Figure 3b shows the estimated survival curves following the DeepSDRF recommendations are identical to the survival curves estimated using the original treatments. Figure 3c depicts the dosage response contour of age. When the age increases (ceteris paribus), the mortality of patients declines slightly until 71 years old, after which the mortality increases. Over time, the survival probability drops below 60% after 12 months for most patients. The Kolmogorov-Smirnov test indicates a p-value of 0.7512. 5.2 Empirical performance with good overlap: optimal vasopressor dosage for sepsis in intensive care The sepsis case study features a high level of overlap in tertiles of vasopressor dosage : 0.000 to 0.001, 0.001 to 0.075, and above 0.075 lack the overlap in values of the GPS close to zero (see Appendix E). Figure 8a shows the distribution of the estimated value of the clinicians’ actions and the DeepSDRF policy tested on the eRI cohort. The values of clinicians’ policy were averaged at 0.147(0.142,0.152) and the DeepSDRF policies were estimated at and 1.059(1.046,1.071). Figure 8b shows the distribution of patient outcomes according to clinicians’ and DeepSDRF policies. On average, the DeepSDRF recommended patients are 4.3% (4.20%,4.40%) more likely to survive during their course of stay in ICU. The response contour in Figure 8c is monotonic, where a higher dosage (ceteris paribus) of the vasopressor is expected to result in better survival outcomes. 5.3 Empirical performance with moderate overlap: the health econometric evaluation of the time to introduce a Step Down Unit Figure 5a shows the empirical distribution of the ICU length of stay (LoS, hours) before the transfer to the SDUs, while Table 5c describes the recommended LoS. The average hours in ICU following DeepSDRF is 24.75(26.157,23.361) shorter than the observed one. We assessed the estimated GPS in Appendix E using the overlap in tertiles of the LoS: 0.0 to 48.0, 48.1 to 80.0, and above 80.1 hours. Over the follow-up period, it appears that there is 16.2% of patients in the comparison of the middle tertile versus the others, for whom there is a lack of overlap in values of the GPS close to zero. The average probability of being discharged to home has been improved by 7.1% (6.30%,7.91%) following the DeepSDRF suggestions. The relationship between the LoS and the discharge outcome seems to be U-shaped (Figure 5c). However, the CADRs for LoS other than 36 hours ﬁnd themselves decline below 50% after 96 hours since discharge from ICU, that is, the patients are unlikely to be discharged to home after 4 days in SDU and more than 36 hours in ICU. This work introduces the Deep Survival Dose Response Function (DeepSDRF) and illustrates its performance in simulation and empirical examples with characteristics typical of observational clinical evaluations where the sample size is moderate, and it is necessary to control for high-dimension covariates to make a plausible assumption about unconfoundedness. Overall, DeepSDRF achieves nominal performance for estimating the stochastic treatment effects on time-to-event outcomes. To be consistent with other outcomes, we term the dose response surface for survival curves associated with a given value of stochastic exposure as the survival conditional average dose response (CADR) function. The key contribution of DeepSDRF is the application of the general propensity score (GPS) framework in the context of survival outcomes. The usage of neural network models does not require correctly specifying the parametric model for the GPS or the outcome. We contrast this approach to the parametric implementation of the GPS approach in its original study on the effect of smoking on labor earnings and medical expenditures [ applications on survival outcomes. [ compared to the plain recurrent neural network for estimating survival outcomes (SNN). The extensive simulations ﬁnd µg/kg/min. There is only 5.6% of patients in the comparison of the middle tertile versus others who the introduction of the GPS into the complex machine learning framework produces superior performance in estimating the CADR function. Secondly, we propose treatment recommenders using the information derived from the estimated treatment effects. Two approaches have been demonstrated to construct the recommender. The ﬁrst approach uses the random search technique to efﬁciently locate the optimal treatment among the potential treatment space. The second approach uses a simpliﬁed version of reinforcement learning (or one-step reinforcement learning), which only considers the initial step of the treatment level given the historical information of patients. These two approaches have similar performance in improving patient outcomes, yet the random search is computationally more efﬁcient. This paper has some limitations. First, the GPS approach reports more conservative conﬁdence intervals than the regression approach. This is expected, as estimators using the propensity score are usually less efﬁcient than estimators based on a correctly speciﬁed outcome model.[28] Second, DeepSDRF relies on the assumption of no unmeasured confounders, speciﬁcally in the context of continuous treatment, the weak unconfoundedness assumption. This assumption requires that for any level of treatment, the probability of receiving this level is independent of the potential outcomes, conditional on covariates. In our empirical example for optimal timing for ICU early discharge, this assumption requires that factors that cause delays in discharge, and are also prognostic of the outcomes, are controlled for. We used all potential confounders captured in the eICU datasets without subjective inclusion and exclusion assessment. However, the possibility for unobserved confounding remains, for example, because the covariates are measured at the time of ICU presentation, so subsequent changes in patients’ prognosis after discharge, which might cause adverse outcomes during the stay in SDUs, are unmeasured. In the absence of appropriate instrument variables, the effects of unobserved confounders could be examined by employing sensitivity analysis methods in the context of continuous treatment.[29] Third, in this study, covariate balance following adjustment with the GPS did not improve for all subgroups (indicated by the tertiles of treatment levels that lack support). An alternative loss function for the DeepSDRF could explicitly consider a metric that takes into account the balance achieved. For the binary propensity score, the data adaptive algorithm has been proposed to estimate the GPS based on balance measures such as the Kolmogorov-Smirnoff test. [ Such approaches still require subjective choices of the appropriate balance measure, the prioritisation of confounders, and for continuous treatment, a method for categorising the treatment variable. Indeed, the most appropriate balance metric remains a topic of ongoing debate.[31] This work provokes areas of further research. Our data adaptive neural network avoids the misspeciﬁcation of both the outcome and GPS models but is not capable of improving estimation when the data lacks overlapping among treatment levels. Future simulation studies could examine the sensitivity of the survival CADR function to unmeasured confounding, which is a major cause of the lack of overlapping. Second, the treatment effect estimation and the associated recommendation provided by DeepSDRF is based on a ﬁxed window of historical covariates, future studies can extend this procedure to multiple rolling windows of history given it is possible to change the treatment policy during the estimation period. This work was supported by National Health and Medical Research Council, project grant no. 1125414. Ethics to use UK Clinical Practice Research Datalink data was obtained from ISAC (protocol number 17-093). The marginal mean of space, is obtained as follows: where the integration term can be simpliﬁed as: For each individual i, we deﬁne the hazard rate h(t), the probability of experiencing an event in interval (t − 1, t], as: history. Thus, the probability that an uncensored individual will experience the event in time product of terms, one per period, describing the conditional probabilities that the event did not occur since time t − 1 but occur in period (t − 1, t]: Similarly, the probability that a censored individual will experience an event after time terms describing the conditional probability that the event did not occur in any observation: which is the population survival function. =1(a + 1)exedx(a + 1)dx(a + 1) and¯Xare the history of treatments and covariates fromt − utot − 1withubeing the length of the observation The output of our model will be a probability of surviving a time interval, which will be curve will be given by We compared the treatment effect estimation performance between general linear model (GLM) and nonparametric neural networks (NN) in the setting of continuous interventions and outcomes. In particular, we examined three types of models to illustrate the improvement achieved by NN, which are NN for both GPS and outcome models; GLM for the GPS model and NN for the outcome model; and GLM for both GPS and outcome models. In this continuous outcome experiment, we simulate the conditional distribution of an outcome Y given X similar to Example 1 in the main study: wherea ∼ N(0, 1) that the marginal distributions of covariates to get we present the results at D = 6 in Table 6. Figure 6: Overlap, based on the GPS estimated at medians of tertiles of the ICU length of stay distributio (AF Age) Figure 7: Overlap, based on the GPS estimated at medians of tertiles of the ICU length of stay distribution (eRI Vesopressor) Figure 8: Overlap, based on the GPS estimated at medians of tertiles of the ICU length of stay distribution (eRI Early Discharge)