Abstract: Federal administrative tax data are invaluable for research, but because of privacy concerns, access to these data is typically limited to select agencies and a few individuals. An alternative to sharing microlevel data are validation servers, which allow individuals to query statistics without accessing the conﬁdential data. This paper studies the feasibility of using diﬀerentially private (DP) methods to implement such a server. We provide an extensive study on existing DP methods for releasing tabular statistics, means, quantiles, and regression estimates. We also include new methodological adaptations to existing DP regression algorithms for using new data types and returning standard error estimates. We evaluate the selected methods based on the accuracy of the output for statistical analyses, using real administrative tax data obtained from the Internal Revenue Service Statistics of Income (SOI) Division. Our ﬁndings show that a validation server would be feasible for simple statistics but would struggle to produce accurate regression estimates and conﬁdence intervals. We outline challenges and oﬀer recommendations for future work on validation servers. This is the ﬁrst comprehensive statistical study of DP methodology on a real, complex dataset, that has signiﬁcant implications for the direction of a growing research ﬁeld. Federal tax data, derived from individuals’ and businesses’ tax and information returns, are invaluable resources for research on a range of topics. Such research improves our understanding of individuals’ and ﬁrms’ responses to economic incentives, and researchers can also use the data to Andr´es F. Barrientos, Aaron R. Williams, Joshua Snoke, and Claire McKay Bowen Keywords— diﬀerential privacy, validation server, administrative data, tax analysis study areas far removed from taxation. For example, Chetty et al. (2014) used tax data to study economic mobility across generations and how elementary school teacher quality aﬀects economic outcomes later in life. However, full access to these data is available only to select government agencies, to a very limited number of researchers working in collaboration with analysts in those agencies, or through highly selective programs within the Internal Revenue Service (IRS) Statistics of Income (SOI) Division. In addition, the existing process of manually vetting each statistical release for disclosure risks is labor intensive and imperfect because it relies on subjective human review. The tremendous demand to participate in such projects, which is limited by SOI resource constraints, indicates that more high-quality research could be conducted if a safe and less resourceintensive method were developed to expand access. At the IRS, the current process to release analytic results on conﬁdential datasets requires researchers to undergo an extensive background check to access the data. IRS staﬀ then must review any results the researchers want to release. This process reﬂects the norm for researchers wishing to access federal, conﬁdential data. In general, researchers either gain access from a public use ﬁle that is an altered version of the conﬁdential data or have direct access to the conﬁdential data. research access to two experimental synthetic databases via the Synthetic Data Server at Cornell University: the Synthetic Longitudinal Business Database and the Survey of Income and Program Participation’s Synthetic Beta Data Product (Benedetto et al., 2013; Drechsler and Vilhuber, 2014). The Synthetic Data Server hosts a validation server that allows researchers to submit their statistical programs to run on the underlying administrative data after testing it on the publicly available synthetic data. However, this server has two disadvantages. First, because it is not automated, the process consumes limited staﬀ time, which demand often exceeds. This situation causes long delays for approval. Second, reviews may be inconsistent because they are manually evaluated by humans and do not adhere to formal notions of privacy that constrain the allowable output. diﬀerential privacy (DP), to speed up the process and to remove the ad-hoc decisions (Dwork As a potential middle ground between the two extremes, the U.S. Census Bureau provides To address these problems, some privacy researchers proposed a newer privacy loss deﬁnition, et al., 2006). Over the last decade, many data privacy experts have come to regard DP as the gold standard for privacy protection. It is often called a formally private method because people can mathematically prove the privacy loss from a data publication that uses DP methods. These methods diﬀer from prior statistical disclosure control or limitation methods because they do not require the same strong assumptions on how much information an intruder may have or what kind of disclosure is likely to occur. Note that this does not imply DP protects from all attacks, rather, for a deﬁned type of privacy loss it oﬀers provable amounts of protection. (such as a statistic) is changed given the absence or presence of the most extreme possible person or observation in the data population. DP requires the level of protection is set proportionally to this maximum potential change, thereby providing formal privacy protections scaled to the worstcase scenario. For further details, Dwork and Roth (2014) provide a rigorous mathematical review of DP. Bowen and Garﬁnkel (2021) cover the basics of DP and its challenges for adoption geared toward a general, mathematical audience, whereas Nissim et al. (2017) and Snoke and Bowen (2019) describe DP for a nontechnical, general audience. released statistic would meet a pre-deﬁned privacy guarantee. This could reduce the burden of manual review that exists in current validation servers and enable increased access to the server, allowing researcher on a wider range of topics that use IRS tax data. In a similar but diﬀerent approach, Barrientos et al. (2018) created a pilot veriﬁcation server for the U.S. Oﬃce of Personnel Management that allowed users to verify synthetic data estimates while satisfying DP. To understand the feasibility of creating an automated validation server, we conduct an extensive feasibility study on state-of-the-art DP methods for releasing tabular statistics, mean and quantile statistics, and regression analyses with cross-sectional data. Based on the current DP literature and informal interviews with tax experts, we prioritized these analyses as a ﬁrst stage of a potential validation server. There are several other analyses, such as model selection or regression discontinuity design, that have been identiﬁed as important but the current DP methodology is at an early At a high level, DP links the potential for privacy loss to how much the answer of a query A validation server that releases a DP output could theoretically be automated because every stage and would not support a validation server implementation. We will explore these in future work for the development of a validation server. nually develops and releases this database of sampled individual income tax returns with privacy protections. Several organizations, such as the American Enterprise Institute, the Urban-Brookings Tax Policy Center, and the National Bureau of Economic Research develop PUF-based microsimulation models that help inform the public on potential impacts of policy proposals. But access to this public ﬁle is limited to certain institutions, and we cannot provide the full data for others to replicate our results in this paper. For this reason, we also test on the 1994 to 1996 Current Population Survey Annual Social and Economic Supplements (CPS ASEC), publicly accessible through IPUMS USA Ruggles et al. (2021). Crucially, it has similar variables as the PUF, and the case study results on the CPS ASEC will be similar to those on the SOI. We provide results from the SOI in this paper and results from the CPS ASEC in the Supplemental Materials, along with a public repository of the code, data, and results. Testing these methods on speciﬁc case studies is a signiﬁcant contribution because it allows assessing how robust and accurate these methods are under conditions commonly encountered in real-life applications. Proposed methods (particularly for regression) have mostly been tested without paying attention to speciﬁc applied contexts. The assessment of their performance usually focuses on verifying that their outputs become more accurate, without considering a feasibility threshold for accuracy, as the sample size increases and less privacy protection is required. their ease of implementation, determine whether they require any additional tuning parameters, assess their computational feasibility, and other advantages and disadvantages. As part of study, we note which methods work in theory under speciﬁc conditions that would not normally be met in practice. This assessment will be useful for the data privacy and conﬁdentiality community in developing better and more robust DP algorithms in the future. tivity calculation for ﬁtting the models with binary or categorical predictors and provide standard To measure feasibility, we test the DP methods on the SOI Public Use File (PUF). SOI an- When selecting which DP algorithms to use, we provide descriptions of each algorithm, consider We also contribute new methodology for some DP regression methods. We improve the sensierror estimates in addition to point estimates. Many of the existing methods for DP regression only provide point estimates, but we require that the validation server provides full inference. Further, obtaining standard errors or conﬁdence intervals is crucial to most statistical analyses. policy decisions and their accuracy according to several utility metrics. We evaluate the methods using real data and identify how speciﬁc data features might challenge some of these methods. To the best of our knowledge, this paper covers the ﬁrst comprehensive case study on DP methodology for various statistical analyses. DP is a rapidly growing and popular ﬁeld of study, but the vast majority of the work has focused solely on theoretical developments. Our results and conclusions will be vital in informing the current state of DP methods, addressing practical problems, and identifying directions for future work, particularly for statistical inference. and theorems of diﬀerential privacy and the fundamental diﬀerentially private mechanisms that we use. Section 3 examines several diﬀerentially private methods, providing a thorough discussion on which methods we tested, the extensions we provided to the methods, and which methods could not be implemented in practice. Section 4 compares the diﬀerentially private methods on IRS tax data and determines the feasibility of using these algorithms for a validation server. Concluding remarks and areas for future work are given in Section 6. Additional technical details on the algorithms and expanded results for our case studies can be found in the Supplementary Materials. Diﬀerential privacy (DP) oﬀers a provable and quantiﬁable amount of privacy protection, colloquially referred to as the privacy loss budget. Those in the data privacy and conﬁdentiality community should note that DP provides a statement about the algorithm (or mechanism), not the data—a common misconception. In other words, DP requires that the mechanism or algorithm provably meets the privacy deﬁnition. We refer to these methods as diﬀerentially private (DP) mechanisms or algorithms. Note that we use DP to mean both diﬀerential privacy and diﬀerentially private. We deﬁne feasibility based on the impact of DP mechanisms on analyses for making public We organize the remainder of the paper as follows. Section 2 reviews the deﬁnitions, concepts, For this section, we reproduce the pertinent deﬁnitions and theorems of DP with the following notation: X ∈ R Deﬁnition 1. Diﬀerential Privacy (Dwork et al., 2006): A sanitization algorithm, M, satisﬁes -DP if for all subsets S ⊆ Range(M) and for all X, X where  > 0 is the privacy loss budget and d(X, X from X by one record. means to diﬀer by one record. One interpretation is the presence or absence of a record, and the other has the diﬀerence as a change, where X and X (2016) refers to these interpretations as unbounded DP for addition or removal of a record and bounded DP for the change of a record. They prove that unbounded DP satisﬁes an important composition theorem we will discuss later in this section (see Theorem 1), whereas bounded DP does not. Because many DP methods rely on Theorem 1, we assume unbounded DP in this paper. such as approximate DP (Dwork et al., 2006), probabilistic DP (Machanavajjhala et al., 2008), concentrated DP (Dwork and Rothblum, 2016), R´enyi diﬀerential privacy (Mironov, 2017), and zero-concentrated DP (Bun and Steinke, 2016). Though these deﬁnitions are still formally private, they oﬀer slightly weaker privacy guarantees. In return, they typically lessen the amount of noise required. We will cover approximate DP, also known as (, δ)-DP, and zero-concentrated DP in depth, because most of the methods we test in our study use one of these two deﬁnitions. Deﬁnition 2. (, δ)-Diﬀerential Privacy (Dwork et al., 2006): A sanitization algorithm, M, satisﬁes (, δ)-DP if for all X, X → Rdenotes the statistical query, i.e., M is a function mapping X to k real numbers. Deﬁnition 1 provides what is known as -DP. There are varying understandings of what it Several relaxations of -DP have been developed in order to inject less noise into the output, where δ ∈ [0, 1]. -DP is a special case of (, δ)-DP when δ = 0. allows, with small probability, that the strict bound given does not hold, which can be useful when dealing with extreme yet very unlikely cases. loss over multiple computations (more on composition of multiple queries soon when discussing Theorem 1). This deﬁnition of privacy was later on improved by Bun and Steinke (2016) who introduced zero-concentrated DP (zCDP or ρ-zCDP), given in Deﬁnition 3. They also show in their Proposition 1.3 that if M satisﬁes ρ-zCDP, then M is (ρ + 2 For the other direction, their Proposition 1.4 states that if M satisﬁes -DP, then M satisﬁes (1/2 Deﬁnition 3. Zero-Concentrated Diﬀerential Privacy (Bun and Steinke, 2016): A sanitization algorithm, M, satisﬁes (ξ, ρ)-zero-concentrated diﬀerential privacy if for all X, X d(X, X where D distribution of M(X such as a validation server. Each time a statistic or output is released, data information “leaks” and must be protected. DP protects the information by splitting the amount of  used for each output, and the composition theorems formalize this concept. Theorem 1. Composition Theorems (Bun and Steinke, 2016; Dwork and Rothblum, 2016; McSherry, 2009): Suppose a mechanism, M Deﬁnition 2 provides a simple relaxation of Deﬁnition 1 by adding the parameter δ. This Dwork and Rothblum (2016) proposed concentrated DP, which aimed to reduce the privacy )-zCDP, which allows us to relate ρ-zCDP algorithms to an -DP equivalent. ) = 1 and α ∈ (1, ∞), (M(X)||M(X)) is the α-R´enyi divergence between the distribution of M(X) and the As mentioned before, many DP algorithms require repeated responses from a query system, a) Sequential Composition: The sequence of M(X) applied on the same X provides state that we may allocate a portion of the overall desired level of  to each statistic by sequential composition. A typical appropriation is dividing  equally by J. For example, a data practitioner might want to query the mean and standard deviation of a variable. These two queries will require using the sequential composition, allocating an equal amount of privacy budget to each query. Conversely, parallel composition does not require splitting the budget because the noise is applied to disjoint subsets of the input domain. Privacy experts will often leverage parallel composition, for instance, to sanitize histogram counts, where the bins are disjoint subsets of the data. In this example, noise can be added to each bin independently without needing to split . applied to a DP output also satisﬁes DP. Many DP methods use the post-processing theorem to correct any inconsistencies or values that are not possible and to compute additional summaries required to perform statistical inference. Theorem 2. Post-Processing Theorem (Bun and Steinke, 2016; Dwork et al., 2006; Nissim et al., 2007): If M be a mechanism that satisﬁes (, δ)-DP or (ξ, ρ)-zCDP, and g be any function, then g (M(X)) also satisﬁes (, δ)-DP or (ξ, ρ)-zCDP. In this section, we present two of the fundamental mechanisms we consider that satisfy -DP and (, δ)-DP. We employ additional mechanisms that will be discussed in Section 3. For a given value of  and δ, an algorithm that satisﬁes DP or approximate DP will adjust the amount of noise added to the output based on the maximum possible change between two databases that diﬀer by one row. This value is commonly referred to as the global sensitivity (GS), given in Deﬁnition 4. Deﬁnition 4. l b) Parallel Composition: Let Dbe disjoint subsets of the input domain D. The sequence of M(X ∩ D) provides (max, maxδ)-DP or (maxξ, maxρ)-zCDP. More simply, suppose there are J many statistical queries on X. The composition theorems The post-processing theorem is another important theorem, which states that any function the global sensitivity of a function M is norm GS, l statistical query’s robustness to outliers. Though the deﬁnition is straightforward, calculating the GS can often be diﬃcult. For instance, we cannot directly calculate an upper bound for the GS of one of the most common statistical analyses, regression, where the coeﬃcients are unbounded. To address this issue, privacy researchers had to be creative in ﬁguring out how to add noise to regression analyses. We discuss this further in Section 3.4. and was ﬁrst introduced by Dwork et al. (2006). Another popular mechanism is the Gaussian mechanism that satisﬁes (, δ)-DP, given in Deﬁnition 6, which uses the l query. Deﬁnition 5. Laplace mechanism (Dwork et al., 2006): The Laplace mechanism satisﬁes -DP by adding noise (η the location parameter at 0 and scale parameter of ∆ Deﬁnition 6. Gaussian mechanism (Dwork and Roth, 2014): The Gaussian mechanism satisﬁes (, δ)-DP by adding Gaussian noise with zero mean and variance, σ where η We can calculate sensitivity under diﬀerent norms. For instance, ∆(M) represents the l -GS, of the function M. Another way of thinking about the GS is that it measures the The most basic mechanism satisfying -DP is the Laplace mechanism, given in Deﬁnition 5, , . . . , ηare independently drawn and σ = ∆(M)2 log(1.25/δ). Although Dwork and Roth (2014) proposed Gaussian mechanism for (, δ)-DP, the Gaussian mechanism satisﬁes ((∆ ditionally, if the l satisﬁes tiple counting queries to reduce the amount of noise being added from the Gaussian mechanism. only to numerical values (without additional post-processing, Theorem 2). A more general -DP mechanism is the Exponential mechanism, given in Deﬁnition 7, which allows for the sampling of values from a noisy distribution rather than adding noise directly. Deﬁnition 7. Exponential mechanism (McSherry and Talwar, 2007): The Exponential mechanism releases values with a probability proportional to and satisﬁes -DP, where u(X, θ) is the score or quality function that determines the values for each possible output, θ, on X. The scientiﬁc community still has no general consensus on what value of  should be used for practical implementation. Early diﬀerential privacy research focused on  values that were less than or equal to one and suggested that an epsilon of two or three would release too much information (Dwork, 2008). Other technical interpretations relating to hypothesis testing (Wasserman and Zhou, 2010) or odds-ratios (Machanavajjhala et al., 2008) have also been proposed as ways of interpreting and setting limits on . as a social and policy question. They interpret the parameter as a way to quantify the tradeoﬀ between accuracy and worst-case privacy loss. Privacy experts should inform and explain to policymakers potential ways to interpret the privacy and utility trade-oﬀ. But, ultimately, stakeholders will need to set the privacy parameter in ways that are relevant to their contexts. α,-R´enyi DP, per Corollary 3 from Mironov (2017). We use this relationship for mul- Both the Laplace and Gaussian mechanisms are simple and quick to implement, but they apply More recently, many privacy researchers working in practical applications frame the decision Accordingly, many practical applications of diﬀerential privacy use large values of  (by theoretical standards). In 2008, for example, privacy researchers applied (, δ)-diﬀerential privacy method with values at (8.6, 10 States commuter dataset (Machanavajjhala et al., 2008). More recently, in 2020, Google’s COVID19 Mobility Reports used 2.64-diﬀerential privacy for the daily reports a total of 79.22-diﬀerential privacy monthly (Aktay et al., 2020). In the same year, LinkedIn revealed their LinkedIn’s Audience Engagement API that protected LinkedIn members’ content engagement data, which used (, δ)-diﬀerential privacy with daily values of (0.15, 10 (Rogers et al., 2020). In 2021, the Census Bureau committed to  values of 17.14 for the persons ﬁle and 2.47 for the housing units data on the 2020 Census. in this paper based on values seen in theoretical work and practical applications. By doing so, we will gain a better sense of the feasibility of methods at diﬀerent levels of . Speciﬁcally, we will examine the eﬀects of  and δ on accuracy within the context of our study, which we hope will contribute to the conversation about how to set the privacy-loss budget. the value of  for any single query is sensitive to other factors, such as the sample size, the total number of desired queries, and the size of the population from which data are sampled. Those questions concern the overall framework that would need to be created to enable a fully implemented validation server, and we do not seek to answer those questions in this paper. We make this point to note that our goal is simply to identify which mechanisms are desirable, if any, based on their relative privacy and utility trade-oﬀs, rather than their absolute trade-oﬀs. The literature has shown that adding Laplace noise produces the most accurate estimates for single tabular queries. For example, (Bowen et al., 2021; Liu, 2018; Rinott et al., 2018; Shlomo, 2018) found the Laplace mechanism is still “hard to beat” for disseminating frequency tables, when The U.S. Census Bureau set the ﬁnal privacy loss budget on June 9, 2021, which can be found at https://www.census.gov/newsroom/press-releases/2021/2020-census-key-parameters.html. Given these examples and the evolving understanding of , we explore a wide range of  values It is also important to understand that when considering the total privacy-loss budget, choosing the data have a large number of observations, or there are a lot of parameters and attributes to consider. We also consider the Gaussian mechanism, since adding Gaussian noise may perform better than adding Laplace noise for multiple counting queries because of how the tails compose (Wang et al., 2019). We can take advantage of this composition property by leveraging R´enyi diﬀerential privacy (Mironov, 2017), which reduces the amount of noise added to each count. A drawback to using the Gaussian mechanism is that it satisﬁes (, δ)-DP, requiring the data user to balance two privacy parameters instead of one. There are other DP algorithms that tackle more complex tabular statistics, but for this study we are only concerned with simple counting queries. The leading methods for generating diﬀerentially private quantiles use either the Laplace mechanism or the Exponential mechanism. For instance, Smith (2011) proposed an algorithm, IndExp, for selecting individual quantiles using the Exponential mechanism. IndExp has since been implemented in the SmartNoise (2020) and IBM (2019) DP libraries. This method was recently extended by Gillenwater et al. (2021) to two other algorithms, AppIndExp and JointExp. The former is the same as IndExp but uses the composition theorem from Dong et al. (2020) to choose an optimal  for multiple queries given a total (, δ), and the latter samples multiple quantiles jointly. Using the Laplace mechanism, Nissim et al. (2007) developed an approach for sampling median values using smooth sensitivity that can be extended to query any other quantile. We will hereafter refer to this method as Smooth. A few other approaches or adaptations of the approaches listed here have been proposed, but we did not test them because they require ﬁne-tuning based on distribution assumptions that a researcher might not realistically have in our validation server setting. For mean estimates, we reviewed DP methods that released means with their associated conﬁdence intervals (CI). When we explored the general literature, we found common approaches use the Laplace mechanism, Gaussian mechanism, or Exponential mechanism for releasing some means with CIs. Du et al. (2020) conducted a comprehensive research study that aimed to move the theory to practice for releasing DP CIs. The authors developed ﬁve new methods, two based on directly applying Laplace noise named NOISYVAR and NOISYMAD and three based on querying quantiles from the Exponential mechanism to estimate the standard deviation named CENQ, SYMQ, and MOD. Du et al. (2020) also compared their methods against Karwa and Vadhan (2017); D’Orazio et al. (2015); and Brawner and Honaker (2018). are approximately Gaussian. We chose to not test these methods on heavily skewed data because preliminary tests showed poor performance. Also, some methods require more information than is realistic for our application. For instance, Biswas et al. (2020); Bowen and Liu (2020); D’Orazio et al. (2015); Karwa and Vadhan (2017) require the researcher to set bounds on the standard deviation to calculate the GS. In a validation server setting, a researcher might not have a good sense of the bounds. Given this limitation, we did not test them for our study. We begin with an overview of the currently available DP approaches for regression analyses. We then explain the criteria for including methods in this feasibility study, discuss the selected methods, and detail any adaptions required to include the methods in the experiments. We classify DP methods for regression analysis according to the outputs they produce: (1) point estimates only, (2) point and interval estimates, and (3) other outputs related to regression analysis, such as diagnostic plots. Because we are particularly interested in methods that provide full statistical inference, we focus our study on methods from category (2) and discuss these methods in greater detail. We survey the other two types further in the Supplemental Materials. output summary statistics useful for either traditional, linear regression or ridge regression. When the outputs are summaries for ridge regression, the penalization parameter is a function of the algorithm’s inputs instead of being predeﬁned by the user. Sheﬀet (2017) derives CIs and tstatistics that account for the noise added to the conﬁdential summaries and shows how such statistics relate to the underlying truth. In addition, the author discusses a diﬀerent algorithm that adds Gaussian noise directly to the suﬃcient statistics and shows that users could obtain A potential limitation to the approaches using quantiles is that they strongly assumes the data Sheﬀet (2017) developed (, δ)-diﬀerential private algorithms that, with certain probability, CIs for the regression coeﬃcients under certain conditions (i.e., the norm of the true regression coeﬃcients is upper bounded). Despite this method’s promise, the paper does not provide practical guidance on deﬁning additional tuning parameters that are essential to guaranteeing the correct conﬁdence or signiﬁcance level of the CIs and t-statistics. The lack of publicly available code also contributes to excluding it from our study. noise drawn from the Wishart distribution. The mechanism deﬁnes a noisy statistic that preserves the property of being positive-deﬁnite; a common problem when adding noise to the regression suﬃcient statistics. But, this mechanism only works for  < 1. Wang et al. (2019) also developed (, δ)and -DP methods that release noisy versions of the summary statistics while preserving positive deﬁniteness. These methods add noise using either a normal distribution (for (, δ)-diﬀerentially privacy) or the spherical analogue of the Laplace distribution (for -diﬀerential privacy). The positive deﬁniteness is achieved by using eigenvalue decomposition and censoring the eigenvalues falling below a given threshold. Although Sheﬀet (2019) and Wang et al. (2019) do not derive CIs or tvalues under the proposed mechanisms for the normal linear model, these contributions paved the way to develop DP methods that allow full inference for regression coeﬃcients. for diﬀerent DP mechanisms, including linear regression. The paper outlines two -DP strategies that employ a noisy version of the suﬃcient statistics. The ﬁrst one applies the noisy statistics in classic ordinary least squares point and interval estimators. This strategy’s accuracy and coverage is ensured by large-sample arguments. The second strategy also uses plug-in estimators, but computes CIs by means of parametric bootstrap. The method accounts for the injected noise as well as the underlying sampling distribution. A drawback of these two approaches is the lack of clarity on computing the points and interval estimates of the coeﬃcients when the inverse of the noisy covariance matrix is not positive-deﬁnite. We employ this method in the feasibility study and apply a regularized version of the noisy suﬃcient statistic to handle the positive deﬁniteness issue. Details on how we use regularization are provided in Section 3.4.2. We acknowledge that a new version of Ferrando et al. (2020) has been recently released, where the authors made the update after Sheﬀet (2019) proposed a follow-up (, δ)-DP mechanism that provides estimates with random Ferrando et al. (2020) developed a general approach to produce point and interval estimates we completed our feasibility study (Ferrando et al., 2021). Although there are slight diﬀerences between the main algorithms in each version, the ﬁrst version algorithm produces valid results. We provide a full description of the algorithm we used in the Supplementary Materials. cient statistics. The procedure uses a Bayesian framework and employs a large-sample distributional characterization of the suﬃcient statistics. Using a Bayesian approach allows the authors to draw from the regression coeﬃcient’s posterior distribution and, thus, provide point and interval estimates. Wang (2018) also provided a method that draws from the posterior distribution of the regression coeﬃcients. However, users need to spend part of the privacy budget for each draw. This aspect limits the applicability of Wang (2018)’s algorithm, since any accurate Monte Carlo approximations would divide the privacy budget into many small values. Splitting the privacy parameter too much dramatically decreases the method’s statistical usefulness. Tax economists rarely use Bayesian methods, so we don’t expect many users will be familiar with these models. Because of this, we didn’t pursue DP Bayesian regression methods further for this case study. Nonetheless, we plan to consider Bayesian approaches in future versions of the validation server. When selecting methods to include in the study, we sought to maximize the statistical usefulness of the outputs and the feasibility of implementation. We select methods that are frequentist, can be used for linear regression models with normal errors, can handle multiple predictors, and provide a full inference. For example, we exclude methods that only provide t-values for regression coeﬃcients without also providing point estimates. Finally, we exclude procedures that meet the criteria above yet were not possible to implement, notably if: the manuscript lacks the information needed to implement the method it describes, the pseudocode is absent and implementation requires nontrivial choices reﬂecting the theory underlying the proposed method, the method has diﬃcult-to-ﬁx errors, the authors failed to reply to inquiries about their method or its implementation, or the method achieves diﬀerential privacy under nontestable assumptions. previous subsection. Without our additional adaptations, only one method (that of Ferrando et al. Bernstein and Sheldon (2019) oﬀered an approach that relies on a noisy version of the suﬃ- We assess each of the methods in Section 3.4.1 based on the selection criteria listed in the (2020)) met all the inclusion criteria to be implemented in a validation server. By making adaptions to the methods in Ferrando et al. (2020) and applying them to other methods, we increased the number of testable methods from 1 to 6. nally designed for linear regression, a small adaptation would make it eligible. We modiﬁed both Ferrando et al. (2020)’s and Brawner and Honaker (2018)’s methods and obtained new versions of the methods to compare in the feasibility study. Importantly, we repurposed elements of the algorithm from Ferrando et al. (2020) to perform full inference with other mechanisms. Ferrando et al. (2020)’s approach employs a parametric bootstrap to approximate the distribution of the coeﬃcients’ estimator while accounting for the underlying data-generating distribution and the DP mechanism (see Algorithm 3 in Ferrando et al. (2020) for the method’s implementation). Although the original method uses the Laplace mechanism to achieve DP, we can employ this same technique with other mechanisms after making some simple adaptations. For that reason, we adapted Algorithm 3 to compare the method’s performance using the Analytic Gaussian mechanism from Balle and Wang (2018), the mechanism in Algorithm 2 from Sheﬀet (2019) (hereafter, the Wishart mechanism), and the mechanisms in Algorithm 2 from Wang et al. (2019) (hereafter, the Regularized Normal and Regularized Spherical Laplace mechanisms). statistics S Y = Xβ + e, Y is the vector representing the observations for the response, X is the design matrix, e is the vector of independent and identically distributed normal errors, and the matrix H denotes the noise added to achieve diﬀerential privacy. Algorithm 3 also uses the parameter deﬁning the corresponding DP mechanism, i.e., , δ, and the GS. Additionally, this algorithm assumes that the sample size n is known, which might not be true in many applied scenarios. Thus, we replace the unknown sample size with a noisy version of it. Note that when the model includes the intercept, a privatized version of the sample size is in the entry (1,1) of S spend part of their privacy budget querying this quantity. We included Brawner and Honaker (2018)’s method, because, even though it was not origi- Ferrando et al. (2020)’s Algorithm 3 inputs are all functions of the noisy version of the summary The implementation of Ferrando et al. (2020)’s algorithm also requires that Sbe positive deﬁnite, which is not always guaranteed in practice. For this reason, we use a regularization whenever needed, i.e., S positive or less than the minimum eigenvalue of S positive-deﬁnite. To ﬁnd r for the Wishart mechanism, we use Remark (2) of Sheﬀet (2019). The remark contains an analytic expression to ensure that S greater than 1 − δ. For the Laplace and Analytic Gaussian mechanisms implementations, we follow a similar idea and deﬁne r, such that P [H − rI For the Regularized Normal and Regularized Spherical Laplace mechanisms, we deﬁne S already-regularized resulting matrix obtained from Wang et al. (2019)’s Algorithm 2. as proposed in Pe˜na and Barrientos (2021), we employ simulations to approximate the distribution of the smallest eigenvalue of H and deﬁne r to be the p P [S fails to make S the minimum eigenvalue of S Ferrando et al. (2020)’s algorithm is provided in the Supplemental Materials. 1 in Ferrando et al. (2020) shows that Their results also extend to mechanisms diﬀerent to the Laplace mechanism, such as the Analytic Gaussian and Wishart. For this reason and to provide another method, we consider ignoring the noise added to S and plugging-in S point and interval regression coeﬃcient estimates in the absence of noise. of S and adaptations to the Analytic Gaussian, Wishart, Regularized Normal, and Regularized Spherical Laplace mechanisms, each using both of Ferrando et al. (2020)’s approaches except the BHM mechanism. We summarize the methods selected for evaluation in Table 1. Unfortunately, we only have an analytical expression for r for the Wishart mechanism. Hence, deﬁnite positive] > P [H − rIdeﬁnite positive]. When deﬁning r as before, r sometimes The eﬀect of H on the inferences should diminish for large sample sizes. In fact, Theorem Since the formulas for CIs also require that S be positive-deﬁnite, we use the regularized version , i.e., S. Therefore, we consider six methods, the Laplace mechanism, the BHM mechanism, In addition to the methods based on Ferrando et al. (2020)’s approach, we consider the boot- Table 1: Summary of the diﬀerentially private regression methods we tested for our tax use case studies. All methods return two types of conﬁdence intervals (bootstrap-based and plug-in-based asymptotic) estimated using an adaptation from Ferrando et al. (2020), with the exception of BHM. strap approach described in Section 6.3 of Brawner and Honaker (2018). We can directly apply this method when the summary statistic of interest is an average or a sum, such as S. Unfortunately, the strategy proposed by Brawner and Honaker (2018) to compute CIs cannot be used in a straightforward manner for the CIs of regression coeﬃcients. the privacy parameters (δ, )), we can approximate the sampling distribution of the regression coeﬃcients relying on an asymptotic assumption. Speciﬁcally, let sampled regression coeﬃcients. Each of these coeﬃcients are computed based on a realization of the noisy S using the equivalent of (δ/K, /K)-diﬀerential privacy under Brawner and Honaker (2018)’s approach. Thus, we approximate the sampling distribution of the regression coeﬃcients by using a multivariate normal distribution, where the mean and covariance matrix correspond to the sample mean and covariance matrix based on the sensitivity of S for the Laplace mechanism in the Supplemental Materials. We use the SOI 2012 PUF to evaluate the DP methods. SOI created this ﬁle based on a subsample of the conﬁdential taxpayer data. The ﬁle contains 200 variables with 172,415 records and represents United States tax ﬁlers. The PUF has a few notable features, such as a stratiﬁed probability sample, observational weights, and many variables with skewed distributions or have values predominantly zero. In this study, we do not consider the weights, since no current DP regression methods exist to handle those. A description of the additional case study using the CPS ASEC data can be found However, since this method allows drawing multiple realizations of the noisy S (after splitting in the Supplemental Materials, and the code can be found online. We based our tests on the types of analyses that tax economists would normally query for the PUF data. For example, a tax expert would likely query one or more of the following: • Counting query: How many tax returns have salary and wage income in excess of $100,000? • Mean statistic query: What are the means for the total and subsets of the total population? • Quantile statistic query: What is the income threshold for the top 10 percent of earners? • Regression query: What eﬀects do marginal tax rates have on capital investment? model estimates the relationship between “ﬁrst dollar” marginal tax rates on capital gains and the realization of long-term capital gains divided by dividends holding constant if the ﬁler is over age 65, the natural log of dividends, and the natural log of net Adjusted Gross Income (AGI). We limit the model to observations with at least $12,513 in dividends, which is $3,000 in 1980 dollars. an algorithm that applies tax laws to microdata. The ﬁrst dollar rate is calculated by running a tax calculator with zero long-term capital gains for every record and running a tax calculator with one penny of long-term capital gains for every record and then comparing the amount of taxes paid. We speciﬁcally used the Policy Simulation Library’s tax calculator (Tax-Calculator, 2021). The 2012 PUF is missing for about half of observations for age. This creates issues for replicating Feldstein et al. (1980), so we impute age by assigning observations with missing age to age 65+ if the record has non-zero total pensions and annuities received, non-zero pensions and annuities in AGI, or Social Security beneﬁts. All other records with missing age are assigned to ages 0-64. This is crude but should be somewhat precise for records with more than $12,513 in dividends. Furthermore, the estimates with and without noise will be ﬂawed in the same way. more complex methods, such as regression discontinuity design. For the former, the formal privacy GitHub repo website, https://github.com/UrbanInstitute/formal-privacy-comp-appendix For regression analysis, we replicate results from Feldstein et al. (1980) on the 2012 PUF. The We calculate the ﬁrst dollar marginal tax rates on long-term capital gains with a tax calculator, We use Feldstein et al. (1980), which is older, because most newer analyses use panel data or research is limited on how to handle this data type. For the latter, there are little to no formal privacy methods that apply to those regression models. We discuss these limitations further as part of our future work. More details on the histogram, means, and quantile analyses used in our evaluation are provided in the Supplementary Materials. As with any practical application, we encountered additional challenges and had to make certain assumptions. We assumed there were no empty subsets and no survey weights. In the naive case, if someone using the validation server applied their analyses to an empty subset, then they would receive an error message. An error message would inform the user that there are few or no observations in the interested subset, violating the guarantees of DP. We acknowledge the reality of this issue for creating a validation server, but addressing this problem is beyond our scope. for regression. Some methods exist for tabular statistics, but early testing showed that the GS became too large to be useful when applied to our data. Although we do not explore weights, we will consider them for later stages of the validation server and discuss this further in Section 6. For evaluating the methods, we utilize various statistical measures. For all of the methods, we report the bias and root mean squared error (RMSE). For means, we also compute the CI overlap (CIO) value. This metric is commonly seen in synthetic data literature, which compares the regression CIs from the original and synthetic data to see how much the privacy algorithm aﬀects regression inference. Karr et al. (2006) proposed the measure deﬁned as: where u The metric measures how much the CIs estimated the original and synthetic data overlap for a single estimate on average, where the maximum value is 1. The value is negative if the intervals do not overlap and grows more negative as they move further away. Note that a drawback to the IO To the best of our knowledge, there are little to no DP methods for handling survey weights , land u, lare the upper and lower bounds for the original and synthetic CIs respectively. measure is the inability to distinguish whether the original or the synthetic data have a wider CI that encompasses the other interval. If one interval is wider but completely encompasses the other interval, the minimum value is 0.5 regardless of the width. two additional utility measures for our regression analyses. We calculate the number of times across the 100 repetitions that the coeﬃcient signs of the original data match the DP coeﬃcients and if the DP CIs included zero. These two measures allow us to more accurately assess the inferential diﬀerences (for hypothesis testing) between the original and the private outputs. In a practical setting, this evaluation tells us how the DP methods will impact the public policy decisions for the particular tax case study. Speciﬁcally, we evaluate whether the tax public policy outcome will change for each analysis using the noisy results. In this section, we present the results of the DP tabular, mean, and quantile methods. When testing our methods, we replicated all DP methods 100 times to assess variability and set  = {0.1, 0.5, 1, 5, 10, 15, 20} and δ = {10 repo, We see a similar pattern in all three utility metrics between the two methods we tested. As expected, the Laplace mechanism outperforms the Gaussian mechanism, even for δ = 10 relative error is less than 1% for the Laplace mechanism at  = 1, and less than 1% for the Gaussian mechanism at  = 5. The mean cumulative sum error is less than 1% for the Laplace mechanisms when  = 5. We note that both methods are unbiased, and for  ≥ 5 they both perform well enough that there is little diﬀerence between them. Overall, these results suggest the Laplace mechanism would perform well enough to enable researchers to query private histograms. More details on these results and ﬁgures can be found in the Supplementary Materials. GitHub repo website, https://github.com/UrbanInstitute/formal-privacy-comp-appendix Given this issue, we calculate the ratio of the widths of the intervals (CIR) and also conducted which contains the code, data, and results from our study. We found overall that both AppIndExp and JointExp oﬀer high-quality quantiles, and they were generally preferable to Smooth for all but the highest values of . For  < 5, Smooth performs much worse than the other two methods, which is likely due to more extensive splitting of  and δ required by the algorithm. We choose not to show the results of Smooth to improve the clarity of the plots. We ﬁnd that JointExp performs better at estimating the zero-valued quantiles, though AppIndExp oﬀers high-quality performance at most levels of  and δ. Similarly, we see that JointExp has lower relative bias on average for the nonzero quantiles, but the diﬀerence between the two algorithms is very small. We also note that both algorithms show small but persistent bias, even for  = 20 (not shown), which suggests that the methods are not empirically unbiased. This may be an artifact of the method for sampling from the Exponential mechanism, which was implemented in the source code for these methods. For large values of , Smooth does improve and is unbiased unlike the other two methods. More details for these results can be found in the Supplementary Materials. cient to return accurate quantile estimates. The choice would likely depend on whether the system deploys pure DP or approximate DP. We do not recommend that a system use Smooth unless queries are made with very high levels of . Additionally, we ﬁnd that AppIndExp returns more equally biased results for each quantile because they are drawn independently. On the other hand, JointExp can return biased results, which are more biased for some quantiles than others. In our application, the quantiles follow an exponential trend. JointExp returns more accurate results for the lowest and highest quantiles but returns less accurate results for those in-between. It may be preferable to choose one or the other algorithm, depending on the application. We found that all three methods for means are approximately unbiased. NOISYMAD and NOISYVAR perform similarly and both provide highly accurate statistics. BHM performs comparably to the other two methods only when δ = 10 outperform BHM. We note that for higher  the scale of the relative error is quite small for all methods (less than 1%) and would likely not eﬀect the practical interpretation. For a practical validation server implementation, AppIndExp and JointExp both appear suﬃdiﬀering approaches to estimating uncertainty. Overall, we ﬁnd NOISYVAR oﬀers the best performance at all but the lowest . NOISYMAD performs well for  = 0.1, but as  becomes larger, the width of the CIs produced by NOISYMAD shrinks and are consistently narrower than the conﬁdential CI. These results would produce overly conﬁdent inference for researchers performing hypothesis testing. On the other hand, the average CIR and CIO for NOISYVAR moves closer to 1 as  grows (as it does BHM but more slowly). More details on these results can be found in the Supplementary Materials. These results suggest that NOISYVAR is preferable overall, and it is capable of providing suﬃciently accurate conﬁdence intervals for higher levels of . When testing our methods, we explored various values of  and δ. We replicated all DP methods 100 times to assess variability. We set  = {0.5, 1, 5, 10, 15, 20}, δ = {10 bootstrap size of 10 and 25 for the Brawner-Honaker method. We based these values from what is seen in other practical applications. Additionally, throughout this section, we limit ﬁgures to certain values of  and δ depending on the range of the results in order to improve readability. We found more variation for the CI measures than point estimate bias, which indicates the Figure 1: Distribution of Simulated DP Estimates for Regression Coeﬃcients We summarize our ﬁndings from the regression experiments, focusing on the methods that may oﬀer feasible results for a validation server. Unlike the tabular and summary statistics methods, the complexity of regression results makes it more diﬃcult to assign the best performance to one method. For simplicity, we show results for the three best methods that have similar overall performance at  = 5 on the Feldstein et al. (1980) model described in Section 4.1. We provide the results for other  and results on the CPS ASEC data in the Supplemental Materials. accuracy of the point estimates in absolute and relative terms. Figure 1 displays the distributions of simulated DP estimates for the coeﬃcients, for three diﬀerent methods at  = 5. The Regularized Spherical Laplace and Analytic Gaussian results shown use δ = 1e − 06. The red lines indicate the conﬁdential estimate, and the black lines indicate the 80% quantiles for the simulated DP estimates. estimate. This gives us an idea of the possible magnitude of bias. In this case, the red lines are at 0 for no bias. We see from these two ﬁgures that, while the distributions are generally centered at the conﬁdential estimate, they are quite wide and include very large errors even at  = 5. We remind readers that these are the three methods which we found to have the best performance. While many queries returned for this model may contain satisfactory results, there is a reasonably high We show ﬁndings for the four coeﬃcients other than the intercept. We ﬁrst consider the Similarly, ﬁgure 2 shows the distributions of the bias as a percentage relative to the true probability that the query could return estimates that are very far from the conﬁdential estimates. evaluating uncertainty of the regression estimates. As described in Section 3.4, we utilize two diﬀerent approaches for estimating CIs; bootstrap and plug-in asymptotic approaches. The former we expect to have wider CIs that account for the variability introduced by the noise mechanism. The asymptotic approaches, on the other hand, produce intervals with lengths more similar to the length of the conﬁdential estimates because they assume large sample sizes that minimize the noise from the privacy mechanisms. Because both of these interval estimates can be output from the algorithms without spending additional budget, a validation server could return both “for free.” We thus evaluate the diﬀerent estimates of uncertainty that these intervals provide. Figure 3: Conﬁdence Interval Overlap vs. Conﬁdence Interval Ratios for each regression coeﬃcient using the bootstrap variability estimates. The vertical red lines indicate a CIR of 1 and the horizontal red lines indicate a CIO of 0.5.  = 5. against each other because taken together they greatly aid the interpretation of the results. The red lines plotted at CIO = 0.5 and CIR = 1 form four quadrants on the charts. We summarize the interpretation of each quadrant as: top left quadrant indicates noisy CIs that are more narrow than the conﬁdential CI but mostly contained within the conﬁdential CI; top right quadrant indicates We also evaluate the noisy CIs compared to the original CIs, because we are interested in For ﬁgures 3 and 4, we show the distributions of CIO and CIR values. We plot these metrics noisy CIs that are wider than the conﬁdential CI but mostly encompass the conﬁdential CI; bottom left quadrant indicates noisy CIs that are both more narrow than the conﬁdential CI and biased away from the conﬁdential point estimate; and bottom right quadrant indicates noisy CIs that are both wider than the conﬁdential CIs and biased away from the conﬁdential point estimate. The plots indicate that in general the noisy intervals completely cover the conﬁdential intervals but are much wider, as much as 50 times wider for some coeﬃcients. We see that the categorical predictor has the narrowest intervals relative to the conﬁdential, followed by the logged predictors, and ﬁnally the marginal tax rates predictor. This suggests that in order to account for the noise from the mechanisms, a high level of uncertainty must be added to the estimates. It also suggests that the noise varies substantially based on the predictor type and distribution. The marginal tax rates predictor is both bi-modal and heavily skewed, which likely means that the noise added is proportional to values greater than the majority of the observed values. Figure 4: Conﬁdence Interval Overlap vs. Conﬁdence Interval Ratios for each regression coeﬃcient using the asymptotic variability estimates. The vertical red lines indicate a CIR of 1 and the horizontal red lines indicate a CIO of 0.5.  = 5. the CIR are centered around 1, but the majority of the results have negative CIO values. This Figure 3 shows the results for the bootstrap CIs. As a reminder, the results shown used  = 5. Alternatively, ﬁgure 4 shows very diﬀerent results for the asymptotic CI estimates. As expected, indicates that most noisy CIs here do not overlap at all with the conﬁdential intervals. Given the wide distribution of estimates seen in ﬁgure 1, this is understandable. CIs which do not take into account the noise added will frequently miss the conﬁdential estimates completely. suring how frequently the noisy results match the sign and signiﬁcance of the conﬁdential estimates. In this case, we assume researchers are primarily interested in understanding whether a predictor has a positive or negative relationship and whether that relationship is statistically signiﬁcant. We also assume they are less concerned about the exact magnitude of the estimate. Figure 5: Confusion matrix showing percentages of sign and signiﬁcance matches for each regression coeﬃcient using the bootstrap conﬁdence intervals. The upper left hand box indicates results that matched both.  = 5. the results are shown in ﬁgures 5 and 6 respectively. These results perhaps paint the most hopeful picture of any of the results for regression models, but they still have signiﬁcant limitations. Both approaches achieve relatively high sign match, which suggests that, though biased, the results will more often point in the right direction. The signiﬁcance match varies quite a lot by the uncertainty method used. All regression predictors were signiﬁcant in the conﬁdential models. Most of the time, we see that the bootstrap estimates are not signiﬁcant because of the very wide intervals. On the Lastly, we look at regression inferences from a purely hypothesis testing perspective by mea- We look at these results for both the bootstrap and asymptotic interval estimates again, and Figure 6: Confusion matrix showing percentages of sign and signiﬁcance matches for each regression coeﬃcient using the asymptotic conﬁdence intervals. The upper left hand box indicates results that matched both.  = 5. other hand, the asymptotic approaches all match signiﬁcance at high levels, and they match both sign and signiﬁcance for the majority of the results. The drawback for the asymptotic approach is that they have a high percentage of results that match the signiﬁcance but not the sign, which could be seen as the most undesirable result. The asymptotic is more accurate for the signiﬁcance because it will tend to produce narrower CIs that do not include zero. Since all the coeﬃcients in the case study are signiﬁcant, the asymptotic plug-in strategy matches signiﬁcance frequently. If we had non-signiﬁcant coeﬃcients, the asymptotic would have likely performed worse. In summary, the bootstrap approach is neither likely to result in correct or incorrect inference (of a signiﬁcant result), and the asymptotic can be seen as a high-risk, high-reward approach. In this paper, we surveyed and tested the feasibility of the latest DP methods for summary statistics and regression analyses on real tax data. To the best of our knowledge, this is the ﬁrst comprehensive evaluation of these DP methods for practical applications within a validation server framework for real-world data. We found that DP algorithms for summary statistics performed well if the privacy loss budget is larger than 1, whereas methods for regression analyses still need improvement when it comes to performing full inference. Practical applications would likely require either larger sample sizes or allocating more  on every query in order to return estimates with satisfactory levels of uncertainty. Based our study results, we identiﬁed a few challenges and avenues for future work. Through our study, we found that existing DP regression analyses were limited in applicability and often added more noise than needed to protect privacy. For example, suppose there are four coeﬃcients in the regression model. The tested DP methods add noise to the design matrix, which has 10 suﬃcient statistics. The added noise is multiplicative rather than additive, resulting in highly noisy estimates that were of little practical use. Other DP methods we reviewed in Section 3.4 could possibly perform better in other evaluations, but they did not meet our inclusion criteria, such as not reporting standard errors. Similar to some of the mean and quantile methods, more research is needed to develop methods that are robust to other data types. Many of the methods we reviewed were limited to particular applications or had unrealistic assumptions about the data. rithms. We sometimes discovered errors in pseudocode from a manuscript and from code we collected from GitHub or from the author(s). Overall, these were minor issues, and we informed the author(s) of bugs. However, obtaining code for applications was more problematic. Though we do not expect privacy researchers to provide production-ready code, we often discovered the research code to be messy, hard to read, and diﬃcult to alter for our use cases. This situation is still preferable to not having any code or hand-coding the method based on the paper. We encountered this problem a few times, which prevented us from implementing some approaches. We reached out to author(s) when no code was available. If the author(s) did not respond, we attempted to code the methods ourselves. But, in some cases, the manuscript did not provide enough information for us to implement the method and was thus excluded from the feasibility study. tance of DP algorithms in practice. For example, OpenDP from Harvard University and SmartNoise from Microsoft are developing a suite of open-source software tools to implement DP methods. Besides the methodological issues, we encountered challenges with coding the various algo- These issues emphasize the importance of open-source code to facilitate wider use and accep- These platforms are still under development, which is why we did not use their code for the feasibility study, but they may oﬀer improved solutions in the future. One vital area for improvement is developing DP algorithms for data that are not Gaussian. Many of the methods we tested performed well when originally proposed, because the authors tested on well-behaved or normally distributed data. Real data are often skewed, such as the 2012 PUF and CPS ASEC data, which resulted in these same methods performing poorly. uncertainty of the estimates. Many data privacy experts create DP regression analyses to output accurate predictions. But, as seen in Section 4, these methods performed poorly either by returning very large conﬁdence intervals or by not reporting the standard error at all. This appears to be a signiﬁcant gap in the DP literature that must be addressed. focus on improving formal privacy methods for OLS regression coeﬃcient and interval estimates and then expand that research to address other important economic use cases. Future areas for work indicated by tax experts are the incorporation of survey weights or regression discontinuity and regression kink designs. We are not aware of any research on formal methods to protect privacy in regression discontinuity and regression kink designs. We hope this study provides the data privacy and conﬁdentiality community with a better understanding of the capabilities, limitations, and challenges of current DP methods for summary statistics and regression analyses. This research was funded by the Alfred P. Sloan Foundation [G-2020-14024] and National Science Foundation National Center for Science and Engineering Statistics [49100420C002]. Johnson and Victoria Bryant, for their amazing support for this project. We also thank our stellar validation server project team, consisting of Leonard Burman, John Czajka, Surachai Khitatrakun, Graham MacDonald, Rob McClelland, Silke Taylor, Kyle Ueyama, Doug Wissoker, and Noah Another area for improvement is developing DP algorithms with a focus on estimating the With these potential research areas in mind, our future work developing a validation server will We would like to thank our collaborators at the Statistics of Income Division, especially Barry Zwiefel. Thank you to Gabriel Morrison for reviewing our code. Finally, we thank our advisory board for their invaluable advice and support. The members are John Abowd, Jim Cilke, Jason DeBacker, Nada Eissa, Rick Evans, Dan Feenberg, Max Ghenis, Nick Hart, Matt Jensen, Barry Johnson, Ithai Lurie, Ashwin Machanavajjhala, Shelly Martinez, Robert Moﬃtt, Amy O’Hara, Jerry Reiter, Emmanuel Saez, Wade Shen, Aleksandra Slavkovi´c, Salil Vadhan, and Lars Vilhuber. DP Summary Statistics and Regression Analyses for Administrative Tax Data.” For this section, we review the DP tabular, mean, and quantile algorithms that we considered and which we selected for the feasibility study. This ﬁle contains the Supplemental Materials to accompany the paper “A Feasibility Study of Table 2: Summary of the DP tabular methods we reviewed in Section 3.1. MethodPrivacyDeﬁnitionOﬀ-the-Shelf vs.Hand-CodingSelected for Case Study Laplace-DPoﬀ-the-shelf via R andYes mechanismPython code on GitHub Gaussian(, δ)-DPoﬀ-the-shelf via R andYes mechanismPython code on GitHub Smith, 2011) Propose-Test- Release (Dwork and Lei, 2009) Tzamos et al. MethodPrivacyDeﬁnitionOﬀ-the-Shelf vs.Hand-CodingSelected or Not Selectedfor Case Study JointExpoﬀ-the-shelf via Python et al., 2021)code on GitHub et al., 2007)(, δ)-DPcode on GitHubYes SmoothCDPoﬀ-the-shelf via PythonNo, requires ﬁne tuningwhich is not realistic for our et al., 2021)application (2020)-DPavailablewhich is not realistic for ourapplication Table 4: Summary of the DP mean conﬁdence interval methods we reviewed in Section 3.3. Honaker (2018) D’Orazio et al. Vadhan (2017) COINPRESS (Biswas et al., MOD (Du et al., MethodPrivacyDeﬁnitionOﬀ-the-Shelf vs.Hand-CodingSelected or Not Selectedfor Case Study (2015)-DPon GitHubset on standard deviation Karwa and(, δ)-DPoﬀ-the-shelf via R codeNo, requires a priori bounds 2020)on GitHubset on variance/covariance et al., 2020)-DPon GitHubYes et al., 2020)-DPon GitHubYes CENQ (Du-DPoﬀ-the-shelf via R codeYes, for non-skewed data et al., 2020)on GitHub 2020)-DPon GitHubYes, for non-skewed data SYMQ (Du-DPoﬀ-the-shelf via R codeYes, for non-skewed data et al., 2020)on GitHub We base our histogram analysis on a report by Mortenson and Whitten (2020), where the authors calculate bunching estimators on detailed histograms of univariate distributions. Their histogram presents earned income in $200-wide bins for single taxpayers with two children in 2014 from $0 to $30,000. Their goal is to identify bunching around the ﬁrst earned income tax credit kink point. We produce this histogram on the 2012 PUF data. As part of preprocessing step for the histogram, we calculated the earned income for ﬁlers with no dependent-status indicator who ﬁle as single or head of household. Dependents is the sum of exemptions for children living at home, exemptions for children living away from home, and exemptions for other dependents. Earned income is wage and salary income, positive net business income, and positive net farm income. In this section, we present ﬁgures for the results discussed in the main report. We tested the two fundamental mechanisms, Laplace and Gaussian, for providing tax data histograms. We also tested making separate queries for each bin of the histogram, but results were worse than the multivariate versions. We calculate the RMSE for the counts within each bin, and the results are shown in Figure 7. the error distributions in such a way that relates to how a tax researcher might use the queried histograms. In particular, discerning cut points or jumps in the distribution is important, which rely on understanding the cumulative distribution function. We measure utility on the CDF in two interpretable ways. First, we measure the maximum error of over all cumulative sums relative to the sum over the whole histogram. This tells the maximum percentage error for someone trying to determine the what percentage of individuals fall below or above a certain cutoﬀ. Second, we measure the mean error over all cumulative sums for the histogram, which tells us the average error across all adjacent subsets of the histogram. Results are shown in ﬁgures 8 and 9 respectively. In addition to RMSE, we utilize a couple other utility metrics which allow us to interpret Users may also query certain quantiles as a way to understand the distribution of data, such as income, rather than querying a histogram or mean value. We tested three diﬀerent methods for producing multiple quantiles, which is likely to be of interest for those making queries. We show the results in ﬁgures 10 and 11. 2 of the 9 estimated quantiles have conﬁdential values equal to 0. For readability, we ﬁrst show the mean absolute bias for those two quantiles, and then show the mean relative bias across the other seven quantiles. We tested the accuracy of estimates for mean income and the accuracy of conﬁdence intervals for the statistic. We compared three methods capable of computing a conﬁdence interval for the mean with only a priori assumptions on the data bounds. Three additional methods listed in table 4 were not tested due to the heavy skew of the data. We tested them on a subset of the CPS data, which was not skewed, but still found poor results. This indicated that they would only provide unbiased results for nearly perfectly Gaussian data. See Appendix 12 for more details. Figure 12 shows the results for the mean bias of the point estimate. interval ratio (CIR) values. We plot these two metrics against each other because taken together they greatly aid the interpretation of the results. The red lines plotted at CIO = 0.5 and CIR = 1 Figure 13 shows the simulated distributions of conﬁdence interval overlap (CIO) and conﬁdence form four quadrants on the charts. We summarize the interpretation of each quadrant as follows: • Top left quadrant: indicates noisy CIs that are more narrow than the conﬁdential CI but Figure 10: Quantile Absolute Bias Results, Only Quantiles with Conﬁdential Values = 0 Figure 11: Quantile Relative Bias Results, Only Quantiles with Conﬁdential Values > 0 • Top right quadrant: indicates noisy CIs that are wider than the conﬁdential CI but mostly • Bottom left quadrant: indicates noisy CIs that are both more narrow than the conﬁdential • Bottom right quadrant: indicates noisy CIs that are both wider than the conﬁdential CIs As stated in the main text, DP methods for regression can be classiﬁed according to the outputs they produce: (1) point estimates only, (2) point estimates and interval estimates, and (3) other outputs related to regression analysis, such as diagnostic plots. In this section, we cover categories (1) and (3). in this category frequently rely on objective-perturbation-based approaches, such as the functional Figure 12: Mean Income Relative Bias. BHM Results Only Shown for δ = 0.01. mostly contained within the conﬁdential CI. encompass the conﬁdential CI. CI and biased away from the conﬁdential point estimate. and biased away from the conﬁdential point estimate. Most DP algorithms fall into the ﬁrst category, returning only noisy point estimates. Methods Figure 13: Mean Income Conﬁdence Intervals Results. BHM Results Only Shown for δ = 0.01. mechanism (Chaudhuri et al., 2011; Fang et al., 2019; Gong et al., 2019; Zhang et al., 2012). These approaches provide DP coeﬃcients estimates by maximizing a perturbed version of the objective function. We can obtain the perturbed versions of the objective function by either adding noise to the function or using a polynomial representation of the function, where we add noise polynomial coeﬃcients. Medina (2020) proposes (, δ)-diﬀerential private methods to obtain robust estimators for various problems, including regression analysis. Chen et al. (2020) developed -DP methods for median regression, which can be seen as a robust version of ordinary least squares based regression. Finally, some DP point estimate approaches add noise to suﬃcient statistics (Wang, 2018). For a list of DP methods for simple linear regression, we refer the reader to Alabi et al. (2020). estimates. Even though these methods are beyond the current scope of the validation server, they provide key information for regression analysis and could be fruitful additions to future versions of the validation server. coeﬃcients. This approach has the advantage of not requiring the response and predictors to be bounded. However, the privacy loss budget may be costly when performing hypothesis testing for multiple coeﬃcients using this method. The Bayesian procedure by Amitai and Reiter (2018) has similar capabilities and limitations, since it targets speciﬁc summaries of the posterior distributions of the regression coeﬃcients, such as tail probabilities. when ﬁnding solutions to problems, such as heterogeneity of errors and lack of linearity. Chen et al. (2016) describe -DP methods that release a private version of the residuals versus ﬁtted values plot. Model selection is also key for regression analysis, and Lei et al. (2016) has developed an (, δ)-DP algorithm for this purpose. Other contributions related to regression analysis involve algorithms developed for regularized regression, such as Lasso (Dandekar et al., 2018; Talwar et al., 2015). Ferrando et al. (2020) proposed a DP bootstrap-based algorithm that adds noise to the suﬃcient statistic for linear model Y = Xβ + e, where Y is the vector representing the observations for the Other DP point estimate methods borrow ideas from robust statistics. For example, Avella- Next, we review recent contributions that release outputs distinct from point and interval Barrientos et al. (2019) proposed an -DP method to perform hypothesis testing for single Residual analysis is another important task in regression and a crucial tool for model validation response, X is the design matrix, and e is the vector of independent and identically distributed normal errors. We assume that the reported noisy statistic is of the form where S = [X, Y ] denotes the noise added to achieve diﬀerential privacy using either the Laplace, Analytic Gaussian, or Wishart mechanism, and the r is deﬁned as discussed in Section 3.4.2. For the Normal and Spherical Laplace mechanisms, we deﬁne S from Wang et al. (2019)’s Algorithm 2. We denote P of H under a given mechanism. To deﬁne H for the Normal and Spherical Laplace mechanisms, we use a symmetric version of the added noise as in Wang et al. (2019)’s Algorithm 2, i.e., we deﬁne H = ( Laplace distribution. The up-to-date version of the algorithm proposed by Ferrando et al. (2020) assumes that r is equal to zero and only considers the Laplace mechanism. This algorithm also assumes that the sample size n is known. This is something we cannot assume and, for this reason, we replace the sample size by a DP version of it. Notice that when the intercept is included in the model and represented by the ﬁrst column of X, a privatized version of the sample size is available at the entry (1,1) of S privacy budget querying this quantity. The algorithm below summarizes the employed algorithm after modiﬁcations and adaptations. To compute the sensitivity of S for the Laplace mechanism described in Section 3.4.2, we assume that the response and predictors are bounded—a common assumption in diﬀerential privacy. Without loss of generality, we assume that the response and predictors take values [0, 1]. Because S is a symmetric matrix and under the previous assumption, its sensitivity is upper-bounded by the number of entries in and above the diagonal, i.e., (p + 1)(p + 2)/2, where p is the number of regression coeﬃcients. While using the upper bound (p + 1)(p + 2)/2 as sensitivity is a valid strategy, it is particularly ineﬃcient in the presence of categorical predictors. To improve this upper bound, ˜H +˜H)/2 where the entries of˜H are drawn from the corresponding normal or spherical 10: we implement some strategies when categorical predictors are part of the analysis. We assume that all categorical predictors are included in the model as dummy variables and ﬁxing one level as the reference. The implemented strategies are listed below: 1. One or more entries in the diagonal of S are identical to entries in the oﬀ-diagonal. Hence, 2. If the categorical predictor has more than two levels, then some entries of S will be exactly 3. If the categorical predictor has more than two levels and the model has an intercept, then 4. If the categorical predictor has more than two levels and the model has a numeric predictor, we only need to add noise to the unique entries. zero, eliminating the need to add noise to those entries. we multiply the set of the corresponding dummy variables by the column of ones in X (representing the intercept) results in a vector that counts the number of ones in the dummy variables. The vector is equal to a contingency table that counts the number of observations at each level, leaving out the reference one. Although this vector has a dimension greater than one, its sensitivity is equal to one. Hence, we take advantage of this fact to reduce the sensitivity of S. then we multiply the set of corresponding dummy variables by the column in X representing the approach proposed by Brawner and Honaker (2018). For the Wishart mechanism, the sensitivity is equal to the upper bound for l i.e., an entry of S of the variables (response and predictors) involved in the analysis. Since the variables are often in diﬀerent scales, users can easily face scenarios where the magnitude of the sensitivity is highly dominated by, for example, a single variable. This single variable could have an interval length (upper minus lower bound) that is much larger than those of the remaining variables. If users ignore this issue under such scenario, the mechanism will add too much noise to those summaries involving the remaining variables. To avoid this problem, we ﬁrst use the provided bounds to rescale all variables to lie in the [0, 1] interval. We then implement the DP method and compute the point and interval estimates of the regression coeﬃcients. Finally, we use the provided bounds again to scale back and report the estimates in the original scale. For this section, we present additional ﬁndings from the regression experiments on the 2012 Public Use File (PUF). the numerical predictor results in a vector of partial sums. Each entry of this vector is equal to the summation of numerical predictor values across the observations that share the same level as the categorical predictor. Similar to the previous item, while this vector has a dimension greater than one, its sensitivity is equal to one. Hence, we take advantage of this fact to reduce the sensitivity of S. We follow the same strategy to deﬁne the sensitivity for the Analytic Gaussian mechanism and We also realize that the magnitude of the sensitivity depends on the upper and lower bounds Figure 14: Distribution of absolute bias for regression coeﬃcients produced by the Analytic Gaussian mechanism. Figure 15: Distribution of relative bias for regression coeﬃcients produced by the Analytic Gaussian mechanism. Figure 16: Conﬁdence interval overlap vs. conﬁdence interval ratios from the Analytic Gaussian mechanism for each regression coeﬃcient using the bootstrap variability estimates. The vertical red lines indicate a CIR of 1 and the horizontal red lines indicate a CIO of 0.5. Figure 17: Conﬁdence interval overlap vs. conﬁdence interval ratios from the Analytic Gaussian mechanism for each regression coeﬃcient using the asymptotic variability estimates. The vertical red lines indicate a CIR of 1 and the horizontal red lines indicate a CIO of 0.5. Figure 18: Confusion matrix of the Spherical Laplace mechanism results, showing percentages of sign and signiﬁcance matches for each regression coeﬃcient using the bootstrap conﬁdence intervals. The upper left hand box indicates results that matched both. Figure 19: Confusion matrix of the Spherical Laplace mechanism results, showing percentages of sign and signiﬁcance matches for each regression coeﬃcient using the asymptotic conﬁdence intervals. The upper left hand box indicates results that matched both. We also tested our DP algorithms on the 1994 to 1996 Current Population Survey Annual Social and Economic Supplements (CPS ASEC) to ensure robustness and to have one dataset that is publicly accessible because Internal Revenue Service Statistics of Income (SOI) Division limits the access to the PUF. Additionally, CPS ASEC is one of the most similar microdata ﬁles to the PUF. The U.S. Census Bureau generates the CPS ASEC from a probability sample, which contains detailed information about income. Similar to the PUF, the CPS ASEC data has skewed variables and variables that are predominantly zeros. The one of the biggest diﬀerences between the PUF and CPS ASEC is that the latter reports information at the person level and household level instead of tax units. This diﬀerence should not have a meaningful impact on the feasibility study and will help test the ﬂexibility of the DP methods. Moreover, unlike the PUF, the CPS ASEC represents the U.S. civilian non-institutional population and has 91,500 households and 157,959 people. ASEC data because the data are rounded and imprecise. However, we still calculate a histogram for demonstration using ﬁve years of pooled CPS ASEC data. ASEC never contains dividends and only has capital gains as recently as 2008. There are complex ways around this but the researcher degrees of freedom do not seem warranted. We instead borrow a cross-sectional multiple linear regressions from Card (1999). These models are not causal and have been replaced by more sophisticated methods that generally report smaller eﬀect sizes for the returns to education, but they are indicative of early quantitative publications on this topic. We reproduce Table 1 on page 1809 that aims to ﬁgure out what are the strong indicators of wage and salary income for gender. The complete CPS ASEC data and results can be found in the GitHub repo at UrbanInstitute/formal-privacy-comp-appendix. Selected ﬁgures for the regression results are provided here for comparison with the SOI results reported in the main paper. Note that the analysis from the Mortenson and Whitten (2020) does not work with the CPS We also could not recreate the same analyses from Feldstein et al. (1980), because the CPS Figure 20: Distribution of Simulated DP Estimates for Regression Coeﬃcients Figure 22: Conﬁdence Interval Overlap vs. Conﬁdence Interval Ratios for each regression coeﬃcient using the bootstrap variability estimates. The vertical red lines indicate a CIR of 1 and the horizontal red lines indicate a CIO of 0.5.  = 5. Figure 23: Conﬁdence Interval Overlap vs. Conﬁdence Interval Ratios for each regression coeﬃcient using the asymptotic variability estimates. The vertical red lines indicate a CIR of 1 and the horizontal red lines indicate a CIO of 0.5.  = 5. Figure 24: Confusion matrix showing percentages of sign and signiﬁcance matches for each regression coeﬃcient using the bootstrap conﬁdence intervals. The upper left hand box indicates results that matched both.  = 5. Figure 25: Confusion matrix showing percentages of sign and signiﬁcance matches for each regression coeﬃcient using the asymptotic conﬁdence intervals. The upper left hand box indicates results that matched both.  = 5.