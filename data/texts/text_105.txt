Abstract—To alleviate data sparsity and cold-start problems of traditional recommender systems (RSs), incorporating knowledge graphs (KGs) to supplement auxiliary information has attracted considerable attention recent ly. However, simply in tegrating KGs in current KG-based RS models is not necessarily a guarantee to improve the recommendation performance, which may even weaken the holistic model capability. This is because the construction of these KGs is independent of the collection of historical user-item interactions; hence, information in these KGs may not always be helpful for recommendation to all users. In this paper, we propose attentive Knowledge-aware Graph convolutional networks with Collaborative Guidance for personalized Recommendation (CG-KGR). CG-KGR is a novel knowledgeaware recommendation model that en ab les ample and coheren t learning of KGs and user-item interactions, via our proposed Collaborative Guidance Mechanism. Speciﬁcally, CG-KGR ﬁrst encapsulates historical interactions to interactive information summarization. Then CG-KGR utilizes it as guidance to extract information out of KGs, which eventually provides more precise personalized recommendation. We conduct extensive experiments on four real-world datasets over two recommendation tasks, i.e., Top-K recommendation and Click-Through rate (CTR) prediction. T he experimental results show that the CG-KGR model signiﬁcantly outperforms recent state-of-the-art models by 1.4-27.0% in terms of Recall metric on Top-K recommendation. Index Terms—Knowledge-aware Recommendation;Knowledge Graphs;Graph Convolutional Networks;Collaborative Guidance Recommender systems (RSs) nowadays play an increasingly important role throughout E-commerce platforms, social networks, and commercial websites. A traditional recommendation metho d - collaborative ﬁ lterin g (CF) - mo dels user preferences of interests based on the similarity of users or items from the historical interactions. Recent proposed graph neural network based methods simulating the CF process [ 1], [2] demonstrate the remarkable improvemen t over tradition a l matrix factorization (MF) models [ 3], [4], [5], [6]. However, CF-based RS models usually suffer from the data sparsity issue and cold-start problems [7], [8], [9]. To alleviate these issues, incorporating k nowledge graphs (KGs) as side information for RS mode ls has recently attracted considerable attention [10], [11], [12], [13], [14]. Essentially, a KG is a heterogeneous graph, wher e nodes denote entities (i.e., products or items with associated attr ibutes and properties) Figure 1. Illustration of p e rformance comparison, unbalanced graph substructure, and n eighborhood information learning. and edges represent mutual rela tions among the se entities. Based on KGs and user-item interac tions, a n intuitive and popular solutio n is to: ﬁrst model user-item interactions and KGs in the graph data structure, and then design graph-based models, e.g., graph convolutional networks (GCNs), to directly capture their semantic relations and topological structures. Instead of relying on interactive data solely, with the rich relational information in KGs to compensate for the sparsity, KG-integrated RS metho ds have the potential to provide more precise and interpretable recommendation. Major Motivation. Despite the se promising beneﬁts, simply integrating KGs in the RS models is not necessarily a guarantee to improve the rec ommenda tion performance. As shown in Figure 1(a), some KG-based models even underpe rform the best tr aditional CF-based models on Recall metrics of Top20 recommendation task ( details of datasets and experimental analysis are referred to Section IV-D). The main reason is tha t these KGs are usually constructed independently o f interaction data collection, where these two data sources may present unbalan ced substructures, such as the different edge densities as shown in Figure1(b). Furthermore, information in these KGs may not be all informative or helpful for recomm endation to all users, which m ay even suppress the holistic model performance. Thus, given th e intera ction data and KGs, the crux of boosting performance lies in better inf ormation extraction , by making sufﬁcient and coherent use of them. However, existing KG-aware RS models may fall short of satisfaction towards this goal mainly in three aspects: cient. Early studies [10], [11], [13] focus on encoding KGs triplets for knowledge supplement by propagating information among KG entities. However, they do not explicitly propagate interactive information in the embedding learn ing, but only use the objective fu nction to implicitly regularize the user-item embeddings. Speciﬁcally, interaction data directly reveal the users’ item preferences and items’ attracting groups, which is important to enrich their latent proﬁles, as a basic assumption in recommendation is: users who ac cept certain items are likely to accept similar ones in th e future (likew ise for items). Hence, without explicitly embedd ing historical interactive information, th ese methods may draw insufﬁcient model learning for recommenda tion. teractive information and external knowledge. To e nrich items’ embed dings, recent work [12], [14] purely relies o n the graph topology to learn item s’ neighboring information, which may lead to unbalanced information aggregation from possibly unbalanced stru ctures. Furthermore, if external knowledge is redundant and not necessarily all helpful for recommendation, it may cause excessive collection of uninformative knowledge. For instance, to learn item i’s embedd ing from Figure 1 (b) , conventional methods include interactive information and external knowledge at the sam e learning stage; as shown in Figure 1(c), due to the high density in its KG side and low density in the interactio n data side, iobtains an unbalanced information summarization from external knowledge against its interactive counterpart. alized recommendation is limited. Most work [10], [12], [13], [ 14] extracts knowledge by purely focusing on local KG structures. As shown in Figure 2(a), given the example topology in the upper half, conventional methods learn knowledge triplet (e, r, e) to invariably diffuse th e semantics within the interactive graph. However, for different interaction pairs <u, i>, <u, i>, and <u, i>, such local knowledge can not adaptively match with different interests and backgrounds that u, u, i, and irespectively have. As we just me ntioned, target users and items tend to have diverse preferences and attracting g roups. Thus, in personalized re c ommend a tion, the informative ness of the same knowledge triplet actually varies and knowledge compositions for embedding enrichment should be dynamically adjusted. In other words, the knowledge extraction phase should be customized accordingly. Note that KGCN [11] directly multiplies user embeddings with edge embeddings to weigh knowledge contribution. But simply using user and edge information is too general so that the distinct semantics of each triplet may be smoothed. In a nu tsh ell, current works may lack certain m e chanisms to dynamically adjust the knowledge com positions for target users and items, le ading to u nsatisfactory personalized recommendation. To address these limitations, we propose attentive Knowledge-aware Graph convolutional networks with Collaborative Guidance for personalized Recom m e ndation (CG-KGR). CG-KGR app roaches the prob lem for better personalized recommendation via GCN- based representation learning. We distinguish the interactive informat ion summarization from external knowledge extraction, via Figure 2. Illustratio n of knowledge extraction (best view in color). setting different learning strategies to provide balanced informa tion aggregation from interaction data and KGs. Technically, we perform the sufﬁcient learning of interactive data a nd coherent extraction of KG information as follows: preferences by visiting their interacted items an d summarize the attracting groups of items by exploring their associated users. By propagating the information back a nd forth between users and items, it simulates the collaborative ﬁltering effect for reco mmendation [15]. We explicitly embed such summarized information to make ade quate learning o f interaction data, which is crucial as the preparation for utilization in the following customized knowledge extrac tion. ommendation, we propose a novel two-step mechanism called Collaborative Guidance. As shown in Fig ure 2(b): (1) given the target user-item pairs, .e.g., <u, i>, we ﬁrst summarize their inter active information and encode it to the collaborative guidance signal; (2) then we immerse this signal into the knowledge extraction process that provides the early-matc hing functionality. Generally, the guidance signal co ntains the target user’s information that serves a s the preference ﬁltering to mask the ir relevant infor mation in KGs, and the target item’s information that works as the attraction grouping to further highlight the important factors. For instance, as shown in Figure 2(b), different interaction pairs. e .g., <u, i>, have differ e nt guidance effects to knowledge triplet (e, r, e), marked by the red, green, and pink arrows, which thus provide customized semantic enrichments to their corresponding embeddings. Unlike traditional models [10], [13], [12], [14] adopting the straightf orward KG seman tics extraction for local triplets, e.g., (h, r, t), CG -KGR develops the customized knowledge extraction based on the quintuplets (<u,i>, h, r, t). It provide a more ﬁne-grained learning paradigm to enrich the embedd ings of target users and items. To summarize, our main contributions are as follows: 1) We pr opose an end-to -end knowledge-aware recommen dation model na med CG-KGR. CG-KGR applies the twostep information summarization called Collaborative Guidance Mechanism to distinguish the learning of interactive informa tion from external knowledge, pr oviding balan ced semantic en richment to target embeddings. It develops a tailored knowledge extraction by binding user-item interactive information, which is a ﬁne-grained learning paradigm to p roduce more pr ecise personalized recommendation. 2) We cond uct comprehensive experiments on four benchmarks over Top-K recommendation and Click-Through rate (CTR) prediction. The experimental results demonstrate that CG- K GR achieves improvements over baselines by 1.35-27.03% of Recall@20 metric on Top-20 recomm endation and 0.49-2.04% of AUC me tric on CTR prediction. Organization. We ﬁrst deﬁne the problem in Sec tion II and then present the detailed methodology of the CG-KGR model in Section III. In Section IV, we report the experimental results on tasks of Top-K recommendation and CTR prediction. Finally, we r eview the related works in Section V and conclude the paper in Section VI. User-item interactions can be repr esented by a bipartite graph, i. e ., {(u, r, i)|u ∈ U, i ∈ I}. U and I denote the sets of users and items, and rgeneralizes all user-item interactions, e,g., browse, click, o r purchase, as one relation type between user u and item i. Moreover, we use y= 1 to ind ic a te there is an ob served in te raction between u and i, otherwise y= 0. A KG is formally deﬁned as {(e, r, e)|e, e∈ E, r ∈ R}, denoting that relation r connec ts entity eand e. E and R represent the sets of entities and relations. The KG is used to provide side information such as item attributes and external knowledge for items, e.g., (La La Land, ActedBy, Ryan Gosling). Mor eover, each item can be matched with an entity in the KG to achieve the alignment from items to some KGs entities, i.e., I ⊆ E, [12], [14]. For ease of interp retation, unifyin g interaction data and item kn owledge is thus deﬁned as G = (E, R), where E= E ∪ U and R= R ∪{r}. Notatio ns. We use bold lowercase, bold uppercase and calligraphy characters to denote vectors, matrices and sets. Non-bold ones are used to denote graph nodes or scalars. Task description. Given G = (E, R), the recommen dation task studied in this paper is to train a RS model predictin g the probability ˆythat target user u may ado pt target item i. We now present the details of our proposed CG-KGR model. Figure 3 de picts the model framework. In the following sections, we will demonstrate: (1) user-item interactive informa tion summarization for guidance signal encoding ; (2) knowledge extraction with co llaborative guidance; (3) model prediction and optimization of CG-KGR, accordingly. Interactive information summar iz a tion proﬁles user preferences and item attracting groups. Based on the summa rized informa tion, CG-KGR further en c odes it to the guidance signal. To explain the attentive information summarization, we start with the description of collaboration attention. 1) Collaboration Attention. Given the target interaction pair (u, i) between user u and item i , we co mpute the attentive weight π(u, i): where v, v∈ Rare the d-dimensional embeddings of u and i. M∈ Ris the transformation ma trix for relation r. Then the normalized coefﬁcients across all interactio ns from user u can be computed by using the softmax function: Attention mechanism has been widely studied in many tasks [16], [17], [18]. And our attention deﬁned above depends on the embeddings v, vand weight matrix M. Generally, ˆπ(u, i) characterizes the informativeness of historica l item neighbors, i.e., S(u), which enables user u to adaptively incorporate infor mation from his/her historical interacted items. 2) User-centric Interactive Information Propagation. As shown in Figure 3(a), users are direc tly interacted with items. To proﬁle the embedding of user u by characterizing u’s historical item interactions, we compute the latent representation of u-centric network S(u) as: Essentially, vis the linear combination of u’s neighbors in S(u). We extend our attention to ave raging multi-hea d attention [19] by taking the average of va nilla single attention mechanism that computed for H times in parallel. Compared to single -head attention, it can furthe r provide n umerical stability for the learning process of self-atten tion in information propagation [19]. Let ˆπ(u, i) denote the h-th normalized coefﬁcient, and we redeﬁne Equation (3) as follows: 3) Item-centric Interactive Information Propagation. Similarly, we comp ute the embedding of item i’s interactive neighbors, i.e., v, with multi-head attention as: where ˆπ(i, u) is the h-th normalized coefﬁcient that is computed by the collaboration attention. Obviously, v is calculated sim ilarly to Equa tion (3), a s they share the same transformation matrix Mthat generalizes the user-item relationship in the latent embedding space. Neighbor sampling. Generally, feed ing the whole graph to the graph convo lutional ne tworks suffers from highly computational overhead. Hence, neighbor sampling is often used to sample a sub-graph for efﬁcient training [20], [10], [11], [13]. This is particularly useful for web-scale recommender systems [21]. We implemen t the dynamic neighbor sampling as a ﬁxed-size random sampling in each training epoch, i.e., S(u) and S(i), instead of using its full neighbors. Figure 3. (a) User-centric network (white nodes represent unsampled neighbors). (b) I n the item-centric network, items are connected to users (brown) and KG e ntities (navy). (c) Illustration of the prop osed CG-KGR f ramework (best view in color). 4) Information Aggregation. The next step is to aggregate propagated information with current information to itera tively update the node embeddings, by using the aggregation function g(·, ·): R× R→ R. In each iteration, we update embeddings, e.g., user u, as follows: Similarly, we can iteratively aggregate interactive information for items to update the embedding v. For aggregator selections, we utilize three types of aggregators to im plement g(v, v) of two inp uts vand v. condu c t a nonlinear tra nsformation: lowed by a nonlinear transformation: resentation with the input embedding v: Here W and b are th e trainable weight and bias. σ is the nonlinear activation functio n such as ReLU. 5) Collaborative Guidance Signal Enco ding. Based on the updated embeddings of target user u (v) and target item i (v), we can encode them to the guidance signal. In this paper, we implement three simple optional types of guidance signal encoder s f (v, v): R× R→ R: values of inputs vand v: of inputs vand vas: f= αv+ (1 − α)v Once we get the gu idance signa l that contains the inform a tion of user prefe rences a nd item attracting groups, CG-KGR employs it for customizing knowledge extraction from KGs to further enrich the node e mbeddings. As shown in Figure 3(b), items are also associated with KG entities. Therefore, for target item i, CG-KGR needs to further extract the external knowledge from KG side, via incorporating the collaborative guidance signal, i.e., f (v, v). 1) Knowledge-aware Attention with Collaborative Guidance. In order to discriminate the impor ta nce of KG associations, given the KG triplet (i, r, e) where e is the KG entity that is associated w ith item i by relation r, we deﬁn e the quintuplet notation<u,i>,i, r, e. This represents that (i, r, e ) is guided by the target pair (u, i). We ﬁrst get the general relationspeciﬁc matrix M∈ R, and then compute the customized transformation matrix with the guidan ce signal as: where f(·, ·) ∈ Ris the guidance signal that seizes the interactive information between user u and item i. ⊙ represents the eleme nt-wise product with broadca st mechanism. Notice that Mdescribes the relation r in the (d×d)-dimensional space. By fusing the guidance signal fr om the target pair (u, i), Mcan simultaneously capture the relational repre sentation of relatio n r as well as the interactive information of u and i, biasing the coefﬁcient computation for (i, r, e) as: and it can be normalized by adopting the softmax function as: expω<u, i>, i, r, e where S(i) represents item i’s neighbo r set of KG entities. Coefﬁcient ˆω<u, i>, i, r, emeasures the relative informativeness of K G triplet (i, r, e) guided by th e target pair (u, i). 2) Knowledge Extraction and Aggregation. Based on the target pair (u, i), we explicitly anchor the guidanc e signal in the computation of the latent representation of i’s neighboring KG entities S(i) as follows: v=1Hˆω<u, i>, i, r, ev Likewise, we adopt the ﬁxed-size random sampling for S(i). After inc orporating the tailored knowledge, CG-KGR can supplement the additional backgrounds for items as well as their related interactive information. In each iteration of the embedd ing learning, we r euse g to compute the embedding speciﬁcally with the guidance signal as: High-order knowledge extraction. As shown in Figure 3(c), to further extract the high-order KG information and propagate it to items for better recommendation, we can stack more extraction hops in our proposed CG-KGR model. Centred at the user-item target pairs, e.g., (u, i), we can random-wa lk -based explore paths o utwards, e.g., i e· · ·e, where e∈ E and r∈ R. (e, r, e) is the l-th KG triplet on this path, where L is the path length. Here integer l > 0, and if l = 0, e= i. To gather distant informa tion along these paths, CG-KGR extends the aforementioned knowledge-aware attention in hig h-order knowledge extraction. Concretely, guided by the target p air (u, i) in the l-depth exploration, we get the neighbor set of KG entity e, i.e., S(e), and then formulate its embedding as: where c oefﬁcient ˆω<u, i>, e, r, ecan be nor malized using the softmax function similarly as Equation (15), after the comp utation of unnormalized coefﬁcient: Then we compute the embedding of KG entity eanchor e d with the guidanc e signal accordingly: where vis the unique embedding of entity e, memorizing e’s origina l information. Please notice that knowledge triplet (e, r, e) is originally explored from item i, which means if l = 1, v= v. This is the embedding of i’s ﬁr st-order entity neighbors deﬁned in Equation ( 16). High-or der knowledge extraction also relies on the neighbor sampling to generate a graph node ﬂow, which in essence is a multi-hop sub-gra ph where edges live in the consecutive hops. In ea ch hop of KG exploration, we conduct ﬁxed-size random sampling to collect the KG entities. Based on the highorder knowledge extraction with collaborative g uidance, item embedd ings can be further enriched, which thus bo osts the ﬁnal re commendation performance. Pseudocodes of the CG-KGR model. We attach the pseudocodes of CG-KGR in Algorithm 1. As illustra te d in Algorithm 1 , we ﬁrst conduct interactive information summarization for guidance signal en coding (lin es 2-9). For the customized knowledge extraction, guided by the collaborative signal, we iteratively propagate the l-hop KG information from l = L to l = 1 (lines 10-14 ). Then on the 1-hop subgraph, the condensed KG info rmation is further aggr egated to ﬁnally enrich item i’s representation (line 14). Please notice that we use S(i)to r epresent i’s l-hop neighbors. 0-hop neighbor of item i is i itself (line 11) , so that if l = 1, e = i and v= v(line 14). B denotes the batch size. Input: User-item interactions {U, I} and KG {E, R}; Output: Prediction function F(u, i|Θ, U, I, E, R) Time complexity analysis. Let c and Y deno te the number of epochs and user-item interactions, respectively. α is the average time cost of basic vector operations. The holistic training time cost is Oα·c·Y ·(|S(i)|+|S(i)|+|S(u)|). In this paper, as we will present later, for four benchmark s, we have c ≤ 10; the sampling size for all nodes is no more than 16. Although the theoretical time complexity is exponential to L, in our work, L ≤ 2. This is because stacking too ma ny extraction h ops may incur performance detriment, the main cause of which lies in the well-known over-smoothing [23], [24] problem, i.e., vanishing gradie nt problem that leads to features o f grap h nodes converging to the same values. As we will show in Section IV-E, compared to recent state-of-the-art KG-aware models stacking limited hops (L ≤ 2), CG-KGR is compara bly efﬁcient in practice. Model prediction. In many embedding-based models, inner product is widely adopted mainly for its simple but effective modeling of user-item interactions at the online matching stage. During the ranking stage, items with top scores ˆy are selected for recom mendation to u. In this work, based on the learned embeddings of target user-item pair (u, i), we use it to directly estimate their matching score as: Model optimization. Let Ydenote the positive interacted item set of user u, i.e., ˆy= 1, and Yrepresent the corresponding negative sampling set, i.e., ˆy= 0. To effectively optimize CG-KGR for train ing, in this paper, we set |Y| = |Y|. In each iteration of model training, we update Yand Yon the ﬂy. Fina lly, the loss fu nction is deﬁne d: L =J (y, ˆy) −J (y, ˆy)+ λ||Θ||. where J de notes the cross-en tropy loss term, Θ is the set of tr ainable model parameters and embeddings, and ||Θ||is the L2-regularizer parameterized by λ to avoid over-ﬁtting. We evaluate the CG-KGR model on the tasks of Top-K recommendation and Click-Through rate (CTR) prediction, to answer the following research questions: to th e state-of-the-art recommendation methods? baselines in model training? Mechanism affect CG-KGR model performance? KGR model performan c e? To evaluate the effectiven e ss of CG-KGR, we directly utilize the fo llowing four open datasets (in cluding the interactive data and corresponding KGs) for music, bo ok, movie, and restaurant reco mmendations, respectively. Due to the diversity in the domain, data size, and distribution, all these four benchm arks are widely evaluated in rece nt works [10], [11], [13], [14]. The ﬁrst three datasets are publicly accessible and the last one is contributed by Meitu an-dianp ing Inc. [13]. The statistics of the four datasets are summarized in Table I. by Last.fm music website. Musical tracks are viewed as items, and it consists of listening infor mation from a set of nearly two thousand users. The corresponding KG contains 9,366 entities, 15,518 KG triplets, and 60 relation types. Book-Crossing Community. Its related KG contains 77,903 entities, 151, 500 triplets, and 25 relation types. for movie recommendatio n. It contains a bout 20 million ratings on MovieLens. 102,569 entities, 499,474 triplets, and 32 relation types are included in the corr esponding KG. Dianping.comconsisting of over 10 million diverse interactions, e.g., clicking, saving, and purchasing, between about 2 million users and 1 thousand restauran ts. Related KG owns 28,115 entities, 160, 519 triplets, and 7 types of the relation. We include two streams of co mpeting methods: traditional CF-based methods (BPRMF, NFM), and KG-based methods. In KG-based methods, there are two main related types: regularization-ba sed methods (CKE and KGAT), and propagation-based methods (RippleNet, KGCN, KGN N-LS, CKAN). matrix factorization, optimized by the Bayesian personalized ranking optimizatio n criterion. recommendation without KGs involved. mendation method. CKE exploits seman tic embeddings learned from TransR [28] w ith information from structu ral, textual, and visual domains to subsume matrix factorization under a uniﬁed Bayesian framework. that collectively reﬁnes embeddings of users, items, and KG entities via jointly training interaction embeddings and KG embeddings. As suggested in [12], we use pre-trained embedd ings from BPRMF to initialize KGAT. model. RippleNet uses a memory -like network to propagate user preferenc es towards items by following paths in KGs. method that extends spatial GCN approaches to the KG domain. By aggregating high-order neighbo rhood informa tion selectively and biasedly, both structure information and semantic informatio n of the KG can be learned to capture users’ potential interests. applies graph ne ural network architecture to KGs with label smoothne ss regularization for recommendation. method employing a heterogeneo us propagation strategy to encode diverse information for better recommendation. To present reprodu cible and stable experimental results, we randomly split each dataset ﬁve times into training, evaluation, and test sets with the ratio of 6:2:2. In our evaluation, we consider two recommendation tasks: (1) Top -K reco mmendation and (2) Click-Through rate (CTR) predic tion. rank K items for each user with the highest predicted scores, i. e., ˆy. We choose two widely -used evaluation protocols Recall@K and NDCG@K to evaluate Top-K recommendation capability of CG-KGR model. to rescale ˆy, and then assign the click ra te to 1 or 0 determined by the rescaled ˆywith the thresh old 0.5. We adopt AUC and F1 as the evaluation metrics. We implement the CG-KGR model under Pytho n 3.7 and TensorFlow 1.14.0 with n on-distributed training. The ex periments are run on a Linux mach ine with a NVIDIA T4 GPU, 4 Intel Cascade Lake CPUs, 16 GB of RAM. For all the baselines, we follow the ofﬁcial hyper-parameter settings from original papers or as default in corresponding codes. For m ethods lacking recommended settings, we apply a grid search for hyper-parameters. The embedding size is searched in {8, 16, 32, 64, 128}. The learning rate η is tuned within {10, 5 × 10, 10, 5 × 10}. We initialize and optimize all models with default Xavier initializer [29] and Adam optimizer [30]. D. Perfo rmance Analysis (RQ1) In this section, we present a comprehensive perform a nce analysis between the CG-KGR model and all re presentative baselines in the tasks of Top-K rec ommenda tion and CTR prediction. For each task, we conduct Wilcoxon signed-rank tests [31] to evalua te the signiﬁcance of the improvement between the best per forming model and the second-best model. 1) Top-K Recommendation. We evaluate Top-K recommendation over four datasets by varying K in {1, 5, 10, 20, 50, 100}. To achieve a more detailed comparison between CG-KGR and all baselines, we ﬁrst summarize the re sults of Top@20 recommendation as well as corresponding standard deviations in Table II. Then we curve the complete results of Recall@K and NDCG@K metrics of all baselines in Figure 4. We have the followin g observation from the experimental results: based methods (without using KGs) on Top-K recommendation. As shown in Table II and Figure 4, traditional CF-based method s BPRMF works slightly better than methods RippleNet on Music dataset and CKE on Boo k dataset, respectively. For the movie dataset, BPRMF outperforms most existing KG-based methods except CKE and KGAT. For the largest dataset Restaurant, anoth e r CF-based method NFM, only u nderperforms CKAN but perfor ms better than other KG-based methods. This phenomenon indicates that simply integrating KGs in recommendation is not necessarily a guarantee of perfo rmance improvement. One possible reason to explain this is all these KG-based methods fully trust the information in KGs and d o not conduct the tailored informa tion extraction for a personalized recommendation. While in practice, info rmation in KGs ma y not all be helpful. So the key to boosting recommendation capability is to make sufﬁcient and co herent use of KGs. In this paper, we propose CG-KGR as one solution to attain this goal. performance improvements of CG-KGR are statistically stable and signiﬁcant. As shown in Table II, on Music, Book, Movie datasets, CG-KGR surpasses the state-of-theart models w.r.t Recall@20 and NDCG@20 by 1 .35%, 27.03%, 14.45%, and and 3.02%, 33.66%, 15.8 8%, re spectively. As for Restauran t dataset, CG-KGR achieves 5.39% of improvement on Recall@20 but does not perform the best on NDCG@20. This is probably because, CG-KGR can make good prediction on retrieving the top 20 items from the candidate corpus but may not precisely estimate their speciﬁc relative item order for each user, since Restaurant contains the fewest items comp ared to other three datasets. The standar d deviations show tha t the results of our model are on the same level of stability as these state-of-the-art methods. Furthermo re, Wilcoxon signed-rank tests verify that most improvements over the second-best model are statistically signiﬁcant under 95% conﬁde nce level. performs competitively compared to baselines. As shown in Figure 4, compared to state-of-the-art models, CG-KGR consistently obtains superior performance when K varies on Book and Movie da tasets and shows competitive performance on Restaurant dataset. By explicitly propagatin g interactive information between users and items, CG-KGR is capable of learning latent representations of user preferen ces and item attracting groups from the historical interactions. Furthermore, instead of directly integrating external knowl- TABLE II: Average results of Top@20 recommendation task. Underlines indicate models with the second-best performa nce. Bolds denote the empirical impr ovements against second -best (underline) models, and ∗ denotes scenarios where a Wilcoxon signed-rank test indicates a statistically signiﬁcant improvement over the second-best models under 95% conﬁdence level. edge without introdu c ing internal interactive information, CG-KGR model applies the collaborative g uidance mechanism. This mechanism collectively encodes historical interactions as guidance f or the customized knowledge extraction, which is particularly useful in the personalized ran king task: Top-K r e commendation. We observe that the performance curve of CG-KGR on Music dataset becomes ﬂatter for larger K values than smaller ones. This is probably because the effect of knowledge supplement on Music dataset is relatively limited. We use edge contribution to enrich item embeddings. Obviously, a higher valu e usually indicates that the KG owns richer semantics to boost items’ backgro unds. While of Music dataset is 4.03, the other three datasets presen t the value of 10.12, 2 9.46, 117.86 , respectively. Thus CG-KGR can perform much better on Book, Movie, and Restaurant datasets, by making sufﬁcient use o f rich semantics in these KGs to make precise item recalling from smaller K to larger one but presents limited performance , e.g., on Top-100 item recalling, over datasets with little knowledge contribution, e.g., Music dataset. 2) Click-Through Rate (CTR) Prediction. Table I II summarizes th e experimental results o f CTR prediction task over all datasets. Based on the results, we have the following observation and analysis. performance improvements w.r.t AUC metric o f CTR prediction. Con c retely, CG-KGR impr oves the baselines on Book, Movie and Restaurant datasets w.r.t AUC by 1.88%, 0.49% and 2.04%, as well as F1 by 0.61%, 1.02%, and 2.11%, with low variance respectively. Compared to the Top-K recommendation task, the performance gap between CG-KGR and baselines on CTR prediction is relatively smaller. This is because, while Top-K recommendation is a listwise ranking task that predicts the or der of items to recommend; CTR prediction is essentially a pairwise classiﬁcation task, which is actually easier. This means that the baselines can also p erform well on CTR pred ic tion and their performan ce gaps against CG-KGR a re thus not that la rge. Moreover, we con duct the signiﬁca nt tests o n CTR prediction. Based on the Wilcoxon signed-rank tests, our CG-KGR model evinces to improve CTR prediction performance signiﬁcantly. TABLE III: Average results of CTR prediction task. Underlines indicate mod e ls with the second-best perform ance. Bolds denote the empirical improvements against second-best (underline) models, and ∗ denotes scenarios where a Wilcoxo n signed-rank test indicates a statistically signiﬁcant improvement over the second-best models under 95% conﬁdence level. AUC metric but does not show a prominent performance on F1 metric. As we have explained in the pr evious section, the valueof Music dataset is the lowest. This implies that, for our proposed CG-KGR, th e effect of k nowledge extraction to enrich the item embeddings is limited. In addition, another po ssible explanation is that, after th e normalization of predicted score ˆy, we simply set the threshold as 0.5 to determin e whether item i will be recommended to user u . With the limited and unbalanced distribution of positive a nd n egative samples in Music, 0.5 may not be an appropriate threshold for binary classiﬁcation . In contrast, AUC scores actually evaluate the model performance average d over a whole range of thresholds, which, therefore, can better measure the classiﬁcation capability of RS m odels u nder such circumstances. E. Time Efﬁciency Comparison (RQ2) In this section, we study how time-efﬁcient our CG-KGR and baselines are in model training. All methods run on the same aforeme ntioned run ning environment withou t parallel training, and we use the default hyper-parameters that are reported in pape rs or ofﬁcial codes. Table IV reports the average results of time cost per epoch, de noted byt, and the numbers of epochs to reach the best performance, denoted by be. Please notice that we apply the early stopping strategy for all methods to prevent over-ﬁtting, and the trigger condition is: the model performance is non-increasing for 10 consecutive epochs after thebe-th epoch. We can observe that: most of the efﬁcient baselines (both CF-based and KGbased methods) on Music, Book , and Movie datasets. In addition, CG-KGR runs faster than the latest KG-aware methods, i.e., KGAT, CKAN, on these datasets. This shows the per-epoch training efﬁciency of CG-KGR mo del on the small to medium-sized datasets. On the largest Restaurant dataset, CG-KGR spends more training tim e per epoch to maximize the performance. This is because of different model designs, other state-of-the-art methods obtain their best performance within no more than 2-hops of information TABLE IV: Time cost (s) per epoch of model training. propagation [10], [14]; while for our proposed CG-KGR model, it may include more neighbor sam ples to make sufﬁcient learning for both collaborative guidance signal and further customized knowledge extraction. According to the aforementioned time complexity analysis, such time complexity is sustainable as well for large-size datasets. thus the holistic training time is comparable with the latest state-of-the-art methods. On Restaurant dataset, although CG-KGR needs more training time per epoch, it only requires abou t 2 epochs to converge. This means that the total training time of CG-KGR (i.e., 5,313.93×2.2 ≈1.1×10(s)) is still com petitive w ith some recent state-of-the -art works, e.g., CKAN costs 569.12×11.4≈6.5×10(s), and KGAT costs 2,61 9.77×2.4≈6.3×10(s). Considering the performance improvements of CG-KGR on this dataset, we argue that the time cost is acceptable in practice. F. Analysis of Collaborative Guidance Mechanism (RQ3) In this section, we ﬁrst conduct an ablation study to evaluate the effectiveness of collaborative guidance by masking information in the collaborative sign al. Then we give a case study for visualization and evalua te the robustness of CG-KGR and baselines with corrupted information in Boo k da ta set. 1) Ablation Study of Collaborative Guidance Mechanism. We evaluate Collaborative Guidance Mechanism on the task of Top-K recommendation and report the results in TABLE V: Ablation study of Collabor ative Guidance Mechanism on Top-20 recommendation (%). terms of Recall@20 and NDCG@20 on fou r d atasets th a t are respectively denoted by MS, BK, MV, and RT. Speciﬁcally, we set three variants of CG-KGR model. CG-KGRis the model variant that simply encodes node embeddings (i.e., user and item embeddings and masking the ir historical interactive informa tion) in the guidance signal. We use CG-KGRto denote the model variant that conducts the preferenc e filtering by only summarizing the user s’ historical interactions. CGKGRdenotes the variant that o nly explor es the items’ local structures for attraction grouping. Based on the results in Table V, we have the following observations: 1) Compared to our c omplete model implementation, variant CG-KGRpresents a large performance decay ranging 2.31-17.95% and 5.68 -17.21% w.r.t Recall@20 and NDCG@20 over four datasets. 2) Compared to CG-KGR, partially using users’ (CG- KGR) or items’ neighbor information (CG-KGR) helps to boost the performance. This demonstrates that encodin g user preferences or item attracting groups in the guidanc e signal is useful, rather than simply using node embedd ings without including neighbor information. 3) Our complete model CG-KGR consistently performs the best, as it jointly e ncodes the information of user preferences and item attractions in the collaborative guidance signal to maximize the model performance. This shows the superior effec tiveness and necessity of our proposed collaborative guidance mecha nism, as it fully exploits the interactive semantics as information guidan ce in the listwise ranking tasks, i.e., Top-K recommen dation. 2) Case Stud y of Collaborative Guidance Mechanism. To visualize the effect o f the Collab orative Guidance Mechanism, we show a real case from Book dataset in Figure 5. As we can observe in Figure 5(a), without using Collaborative Guidance Mechanism, KG entities make similar contributions to the knowledge extraction with the weights 0.164, 0.125, and 0.113, resp e ctively. However, by using collaborative guidance based on the target pair uand book: Th e Simpsons & Philosophy, our mo del can well customize the knowledge extraction: CG-KGR highlights the knowledge triplets associated with entities eand eby calculating the weights as 0.183 and 0.174; it pays less attention to the entity e with a lower weight 0.05 6. This shows that, endorsed by our Figure 5. A real example from Book dataset. proposed Collabo rative Guidance Mechanism, CG-KGR can well d istinguish the informative knowledge (i.e., associated with relations Author and Gen re) out of less informative one (i.e., associate d with relation Publish Date). Futhermore, comparing Figur es 5(b) w ith (c), we can ﬁnd th at users uand ushow different collaborative inﬂuences on the customized knowledge extraction, as they have different focuses of item information. Consequently, this is beneﬁcial to p ersonalized recommendation. 3) Model Performa nce on Corrupted Book Dataset. We also conduct an interesting experiment on how Collaborative Guidance Me chanism defends the error/noise in KGs. Spe ciﬁcally, we randomly generate corrupted knowledge in Book dataset and then replace it in the original KG: for example, we can replace a co rrect relation by a wrong one in th e kn owledge triplet. The ratio of corrupted knowledge is ranging f rom 0-40%. We evaluate the performance of all KGaware RS models on Top-K recommendation with corrupted informa tion. As shown in Figure 6, our proposed CG-KGR model can better defend the corrupted knowledge, with a Recall@20 decay from 10.81% to about 6.65%. By comparison , other models meet larger performance declines fro m about 8% to 3%. The reason of such phenomena is because they all lack a mechanism to sufﬁciently fuse internal interactive knowledge to gu ide the external infor mation propagation. Meanwhile, our proposed Collaborative Guidance Mechanism lower s the negative inﬂuence of corrupt knowledge on the who le model learning and thus leads to better perso nalized recom mendation . Figure 6. Model perfo rmance on corrupted Book dataset. G. Ablation Study of CG-KGR Model (RQ4) To provide the in tuition behind the performance improvement of CG-KGR, we conduct a comprehensive ablation study to evaluate the necessity of each model component. 1) Effect of Explicit Lea rning on Interactive Information. To verify the effectiveness of explicit information learnin g for user-item interactions, we con sid er one va riant of CG-KGR model by removing the interactive information propagation, TABLE VI: Ablation study on Top-20 rec ommendation (%). which is denoted as CG-KGR. As shown in Table VI, variant CG-KGRremarkably underperforms CG-KGR. This demonstrates that explicitly propagating interaction information is very important to boost CG-KGR per formance . 2) Effect of Independently Le arning on Two Da ta Sources. We study the effect of independently learning user-item interaction and externa l knowledge by mixing the learning of these two parts together. We denote this variant as CGKGR. As shown in Table VI, the va riant CG-KGR confronts a c onspicuous performance decay in recommendation, which justiﬁes the effectiveness of distinguishing the learning processes of these two data sources in improving CGKGR’s model per formance . 3) Effect of Knowledge-aware Attention Mechanism. To substantiate the impact of our knowledge-aware atten tion mechanism, we use a variant, i.e., CG-KGR, by enabling the neighbors to equally co ntribute to the knowledge extraction. From Table VI, we ﬁnd that the results of CGKGRare worse than those of CG-KGR across all datasets. This supports th at our knowledge-aware attention mechanism is effective to determine the knowledge informativeness in knowledge extraction phases, which ﬁn ally lea ds to a big boost in Top-K recom mendation task. 4) Effect of Collaborative Guidance Mechanism. We disable Collaborative Guidance Mechanism by replac ing f(v, v) to an all-one vector in the fo llow-up model learning. This a ctually degrades our proposed quintuple t-based learning parad igm for knowledge extraction to the triplet-based, i.e., from (<u,i>,h, r, t) to (h, r, t). We de note it as CGKGR. As we can observe that, with all other model components, enabling our pro posed Collaborative Guidance Mechanism can further improve the perf ormance for p ersonalized recommendation, showing that customized knowledge extraction is efﬁcacious in improving CG-KGR performance. H. Hyper-parameter Analysis (RQ5) 1) Implementation of Guidance Signal Encoder f . We conduct experim ents on different selections of the encoder f and report the results in Table VII. From the results, while encoder fworks well on Music dataset, f shows consistent super iority over oth er selections on the other three d atasets. fdirectly c ondenses information of user preferences and item attracting groups via the pairwise linear combining of embed dings, wh ic h is simple but effective in practice especially for these medium and la rge datasets. TABLE VII: Top-20 recommendation of different f (%). 2) Implementation of Information Aggregator g. Most related re commendation work [11], [12], [10], [14] usually try these aggregators and pick out the one with the best performance. Hence, in this paper, we empirically report all performance likewise to explore th e inﬂuence of aggregating neighbor information. As shown in Table VIII, under the scenario of Top -20 recommendation, gperforms the best in general. While for the Movie dataset, gsurpasses the other two aggregator s. This may be because g makes full use of external information by observing the entire neighborhood, which enlarges the predictive rankin g power o f CG-KGR model on Movie dataset. TABLE VIII: Top-20 re c ommendation of different g (%). 3) Depth of Knowledge Extraction Hops. We verify how the hop depth affects the pe rformance by varying L from 0 to 3, which depth 0 means no information aggregation from the knowledge graph side. For Top-K r ecommendation, CG-KGR achieves th e best perfo rmance when L is 1, 1, 2, and 1 for all benchmarks, respectively. This is because for Movie dataset, a relatively deeper knowledge extraction introduces more long-distance knowledge, wh ich enriches the latent representation of items. As for the other three datasets, local knowledge in KGs is more informative for the tr a ining of the proposed model. In con c lusion, preserving an appropriate depth of extraction hops can no t only avoid the over- sm ooth problem [23], [24] (details are r eferred in the time complexity analysis), but also enable maximized per formance over different recomm e ndation datasets. TABLE IX: Top-20 recommendation o f different L (%). Studying ubiquitous gra ph data has aroused interests in various applica tions [32], [33], [34], [35] and incorporating KGs in reco mmender systems rece ives much attentio n recently. Existing KG-aware RS models can be generally categorized into three branches: (1) path- based methods [36], [37], [3 8], [39], [40], (2) regularization-based methods [27], [12], and (3) propagation-based methods [10], [1 3], [11], [14]: among items in KGs, i.e., meta-paths or meta-graphs, to provide additional guidance in the predictive model. Suc h meta-paths are generated by: (1) either deﬁning constraint sub-patterns to concatenate the prominen t paths [39], [36], (2) or relying on manual selection and pa th generation algorithm s to directly ﬁnd the targets [37], [38], [40]. The main inadequacies of path-based methods primarily lie that: deﬁning effective sub-paths requires intensive input of domain knowledge and labor resourc es, which could be extremely expensive when the KG’s are large-scaled a nd complicated. Furthermore, it is difﬁcult to optimize the path retrieval for the r e commendation, while the selected paths do a great im pact on the ﬁnal per formance . Thus in this paper, we exclud e path-b a sed methods for model comp arison. loss terms to captur e the KG structur e s and fuse these to regularize the model tr a ining [12], [27], [41]. Based on the shared item embeddings, these methods merge the two tasks of general recom mendation and KG c ompletion to jointly train the m odel. One deﬁciency is that all the se regularization-based methods adopt a ﬁxed term to control the regularization effect; however, in the whole training process, the two different training phases may not always make constant contributions. T his implies that they may need more advanced strategies to determine the evolving values of regularization terms. Moreover, most regularization-based methods rely on traditional knowledge graph embedding methods to separ ately complete the KG training, while highorder semantic information in KGs and user-item interactions are no t explicitly pr opagated, which may result in suboptimal representation learning f or users and items. representations, usually perfo rm iterative information propagation under the gr aph convolutional/neural network framework for recommendation [42], [43], [44], [45], [46], [47]. KG-based propagation methods mainly focu s on exploring KGs for information enrich ment [10], [1 3], [11], [ 14]. With the auxiliary information passed along l-hop links in the KG, the embedding representations of users and/or items can be reﬁned. After this feature propagation process, the ﬁnal representation of an item is a mixtu re of its initial representation and information from its multi-hop neighbor s. Based on the enriche d embeddings, the user’s prefe rence towards candidate items can be more accurately predicted. Although many effective models have been proposed, the primary p roblem is that methods such as KGCN [11], KGNNLS [13], and Ripple N et [10] only focus on propagating knowledge in the KG, but do not fully exploit the useritem interactions. This may lead to insufﬁcient proﬁling for both users and items and thus the re commendation capability of RS models may be constrained. In ad dition, all these methods ignore the fact that these KGs a re imported from external sources and may contain irrelevant information. Via limited volume for information p ropagation, uncorrelated and uninformative informa tion may exclude the positive one, which suppresses the model performance. To address these issues, our CG-KGR model is proposed. CG-KGR explicitly pro pagates collab orative in formation in user-item interac tions to proﬁle their latent representations. Based on this latent summarization, CG-KGR then seam le ssly fuses this collaborative encodin g as gu idance to customize the knowledge extraction from external KGs. The extensive experiments well demon strate that CG-KG R signiﬁcantly improves the recommendation per formance over baselines on both tasks of Top-K recommendation and Click-Thro ugh rate prediction. As for future work , we point out two possible directions. (1) Unlike uniform neighbor samplin g in this paper, we may explore a non-uniform sam pler to screen out representative neighbors with high importance. This m a y further improve the efﬁciency and effectiveness of KG-based re commender systems, especially for large-scale datasets. (2) After the data integration of KGs and user-item interactions, the global data distribution m ay change. How to utilize su ch data distribution for better information propagation and aggregation is an important topic to investigate.