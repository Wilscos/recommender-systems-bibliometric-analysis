Modern wireless communication systems have reshaped the operations of the society and people’s lifestyle, becoming an engine for propelling the data economy. Many advances in wireless systems are based on the ideas rooted at Claude Shannon’s locus classicus on information theory [1]. In his work, Shannon deﬁned a communication problem as one concerning “reproducing at one point either exactly or approximately a message selected at another point”. He argued therein that “semantic aspects of communication should be considered as , Xu Chen, Petar Popovski, Kaibin Huang irrelevant to the engineering problem”. Guided by Shannon’s approach and philosophy, most existing communication systems have been designed based on rate-centric metrics such as throughput, spectrum/energy efﬁciency, and, with the advent of 5G, latency. Nevertheless, there is an increasing belief in the community that the classic Shannon’s framework needs to be upgraded for the next evolution step in communications. Its narrow focus on the reliability level of communication starts to show its limitations in meeting the ambitious goals set for the sixth generation (6G). In particular, the ignored meaning behind the transmitted data are expected to play an important role in 6G communications, which placesused is widely regarded as the distant ancestor of modern Maan unprecedented emphasis on machine intelligence and itschine Learning (ML) algorithms. The ensuing evolution of interface with human intelligence. In existing systems there isAI had experienced periodic bouts of enthusiasm interspersed a limited coupling of the high-level meaning or relevance ofwith “AI winters”. In a “winter”, research could stay stagthe data content with the transmission strategies; an examplenant for a decade due to limited computing power, insufis packet prioritization based on data content, implemented inﬁcient training data, and crudity of AI algorithms. These the upper networking and application layers [2-4]. However,obstacles were ﬁnally eliminated in the past few years after the separation of transmission and data’s meanings and effec-the preceding decades of fast development of chips with retiveness for achieving speciﬁc goals inevitably result in re-markable number-crunching power and growing abundance dundancy, e.g., transmitting information lacking relevance orof datasets. Nowadays, we witness the wide-spread use of freshness. This causes the existing techniques for informationpowerful large-scale neural-network models featuring billions ﬁltering, transmitting, and processing to struggle with keep-to tens of billions of parameters organized in hundreds of hiing pace with the exponential growth rate of data trafﬁc [5-7].erarchical layers, termed the Deep Learning (DL) architecThe need of highly efﬁcient communication for supportingture. Advanced ML algorithms have been designed for varimachine-intelligence services has triggered a paradigm shiftous tasks, including supervised learning, unsupervised learnfrom “semantic neutrality” towards semantic communicationing, and reinforcement learning. Via heavy-duty statistical (SemCom) [5,8-10]. This is the main theme of this article.analysis of big data, the ML algorithms can enable deep neural The concept of SemCom was introduced by Warrennetworks to understand the inherent patterns of physical ob- Weaver, a collaborator of Shannon, who deﬁned a commu-jects and attain a wide-range of human-like capabilities, from nication framework featuring three levels [11]. The ﬁrst-level,recognition to translation. which is targeted by Shannon’s information theory, aims at answering the technical problem that “How accurately caners into tens of billions of edge devices (e.g., sensors and the symbols of communication be transmitted?”. SemCom be-wearables) and connect them to the mobile networks [13,14]. longs to the second level concerning an answer to the semanticThereby, the resultant IoT can serve as a large-scale sensor problem that “How precisely do the transmitted symbols con-network as well as a massive platform for edge-computing. vey the desired meaning?”, beyond which the third level is de-Complex tasks can be executed on the platform to improve the ﬁned as the effectiveness problem that “How effectively doesefﬁciency of businesses and the convenience of consumers. the received meaning affect conduct in the desired way?”. InFor example, sensors and cameras connected to IoT can act Weaver’s time, communication activities dominantly servedas a surveillance network, or save energy by smart lighting; the purpose of information exchange among humans. ThusIoT connected cows can enable the cloud to track their health the Weaver’s SemCom deﬁnition should be interpreted as aconditions and eating habits, which provides useful data for concept of Human-to-Human (H2H) communication. In thesmart agriculture. Individual gains may not be walloping but modern era of machine intelligence, the connotation and scopethey are compounded as the scale of IoT grows. of SemCom, however, have been substantially enriched and broadened to cover all three levels. This necessitates the pre-full potential can be unleashed by integration. On one hand, sentation of a modern view of SemCom.AI endows on edge devices the human-like capabilities of de- The recent rapid advancements in Artiﬁcial Intelligencemous number of edge devices in IoT (e.g., more than a hun(AI) and Internet-of-Things (IoT) are two main factors con-dred trillion gigabytes of data in the next 5 years [15]). Such tributing to the rise of machine intelligence.data are fuel for AI and can be distilled into intelligence to Research on AI dates back to 1950’s. The term AI ﬁrstsupport a wide-range of emerging applications and improve appeared in a research proposal aimed at creating “the em-the efﬁciencies of data-driven businesses [7]. bryo of an electronic computer that will be able to walk, talk, see, write, reproduce itself and become conscious of its own existence” [12]. To materialize the vision, researchers invented neural networks to mimic the mechanism of brain neurons for processing information and realizing intelligence. Early attempts attained some success in demonstrating the ef-and the exponential growth of machine population usher in fectiveness of such models, e.g. Frank Rosenblatt’s famousthe new era of machine intelligence. The extensive involveconcept of Perceptron. The single-layer linear classiﬁer hement of machines in modern communication give rise to three Another paradigm shift in computing is to embed comput- The breathtaking advancements in machine intelligence basic types of communication context: H2H communications, human-to-machine (H2M) communications, and machine-tomachine (M2M) communications. The classic H2H SemCom as considered by Weaver is therefore insufﬁcient for describing future diverse communication tasks. This motivates us to broaden the scope of SemCom by deﬁning three sub-areas matching the mentioned contexts as follows. • H2H SemCom: The deﬁnition of H2H SemCom is consistent with the second level of the Weaver’s framework and addresses the semantic problem described earlier. To be precise, the communication purpose is to accurately deliver meanings over a channel for message exchange between two human beings. To this end, the system performance is measured by how well the intended meaning of the sender can be interpreted by the receiver. • H2M SemCom: This area concerns communication between a human being and a machine. The distinction of H2M SemCom lies in the interface between human and machine intelligence, which is different in nature and involves both the second and third level of the Weaver’s framework. For H2M SemCom to be effective, the transmitted messages have to be understood not only by humans but also by machines. To be more speciﬁc, the success in H2M SemCom hinges on two aspects: 1) a message sent by a human being should be correctly interpreted by a machine so as to trigger the desired actions or responses (the effectiveness problem); 2) a message sent in the reverse direction should be meaningful for the human at the receiving end (the semantic problem). The typical applications include human and AI symbiosis system, recommendation system, human sensing and care system, and virtual reality (VR)/augmented reality (AR) system. • M2M SemCom: In the absence of human involvement, M2M SemCom concerns the connection and coordination of multiple machines to carry out a computing task. Therefore, this area relates less the level-two communication (i.e., semantic problem) but more to the level-three communication (i.e., effectiveness problem). Latest research on M2M SemCom advocates the approach of integrated communication and computing (IC) that promises more efﬁcient system design under constraints on radio and computing resources. The resultant cross-disciplinary research has led to the emergence of a new class of M2M SemCom techniques to be introduced in the sequel. The typical applications include M2M SemCom are mainly related to those in the areas of distributed sensing, distributed learning, and distributed consensus (e.g., vehicle platooning). SemCom has been regarded as a key enabling technology for future networks. Research on SemCom concerns the representation of semantic information, SemCom modeling, enabling techniques, and network design. A number of surveys of the area have appeared where different SemCom frameworks are proposed. First, system-level issues of SemCom such as network architectures and modeling are discussed in [10,16]. Speciﬁcally, a semantic-effectiveness (SE) plane whose functionalities address both the semantic and effectiveness problems is proposed in [16] to realize information ﬁltering and direct control of all layers. The new layered architecture is showcased with particular applications including immersive and tactile scenarios, integrated communication and sensing (ISAC), and physical-layer computing. The survey in [10] focuses on SemCom modeling and semanticaware network architecture. Two SemCom models are introduced based on shared knowledge graph (KG) and semantic entropy, respectively, each which comprises semantic encoder/decoder and semantic noise. Building on these models, semantic networking for federated edge intelligence is then proposed to support semantic information detection and processing, knowledge modeling, and knowledge coordination. On the other hand, efforts have been made to explore SemCom enabling techniques including information representation, data transmission and reconstruction [5,17,18]. In particular, the work in [5] features the integration of semantic and goal-oriented aspects for 6G networks and KG based techniques for information representation, semantic information exchange measurement, semantic noise, and feedback. This survey also presents the interplay between machine learning and SemCom, identifying their mutual enhancement and cooperation in communication networks. In [17], a semanticaware communication system is discussed from the perspective of data generation/active sampling, information transmission, and signal reconstruction. To redesign communication networks for SemCom, conventional approaches should be revamped to support new metrics and operations such as semantic metrics, goal-oriented sampling, semantic-aware data generation, compression, and transmission as suggested in [18]. In view of prior work, existing SemCom frameworks are basically extended from the Weaver’s classical deﬁnitions and do not comprehensively incorporate current advancements of relevant technologies. There is still a lack of a systematic survey article that provides a uniﬁed framework of SemCom in the era of machine intelligence; this is precisely the motivation for the current work. The contributions of this paper can be summarized as follows. First, this paper deﬁnes three different areas of SemCom, i.e. H2H SemCom, H2M SemCom, and M2M SemCom, by identifying the involved subjects and objects. The proposed framework can accordingly describe existing technologies, models, and frameworks, providing a comprehensive reference for both researchers and practitioners. Next, with the proposed framework, we conclude current advancements of technologies that are relevant to or beneﬁcial for SemCom, which can help readers in interpreting easier their research in the context of SemCom. Furthermore, we incorporate the KG based SemCom technologies and extend their applications into H2M SemCom, H2M SemCom, and M2M4. A receiver performs decoding and demodulation to reSemCom scenarios. In addition, according to existing 6G visions, potential technologies and use cases that are helpful for SemCom are introduced. While H2H SemCom is a classic, well studied area, our5. A destination is a human being or a machine for whom discussion focuses on H2M and M2M SemCom for their being new paradigms in the modern era of machine intelligence. Furthermore, we propose a new direction of KG based Sem-Information-theoretic encoding focuses on the statistical propCom that helps accomplish H2H SemCom, H2M SemCom,erties of messages instead of the content of messages. The and M2M SemCom by exploiting the semantic representa-transmitted message is one selected from a set of possible tions of information. An overview of SemCom techniques andmessages with a given distribution. Mathematically, informaapplications covered in this article is provided in in TABLE 1.tion theory simpliﬁes H2H communication to transmission of The remainder of the paper is organized as follows. In Sec-a ﬁnite set of symbols. Nevertheless, in practice, the messages tion 2, we introduce the SemCom principles including seman-have meaning, relevance, and/or usefulness. To be speciﬁc, tic and effectiveness encoding, a new network layered archi-they refer to or are correlated with certain physical or conceptecture, and design approaches. Next, semantic/effectivenesstual entities or are contributing towards the achievement of encoding and transmission techniques targetting speciﬁc ap-some goal. This semantic aspect of communication was origplication areas of H2M SemCom and M2M SemCom are pre-inally treated in Shannon’s theory as being irrelevant to the sented in the following two sections. Speciﬁcally, in Sec-engineering problem of information transmission. For examtion 3, semantic encoding and H2M SemCom techniques areple, a tacit assumption in Shannon’s model is that the sender discussed for the areas of human-machine symbiosis, rec-always knows what is relevant for the receiver and the receiver ommendation, human sensing and care, and VR/AR. Sec-is always interested and ready to receive the data sent by the tion 4 focuses on M2M SemCom including effectiveness en-transmitter. coding and SemCom techniques for the areas of distributed learning, split inference, distributed consensus and machine-communication framework characterized by three levels of version cameras. Subsequently, we introduce the KG basedproblems, namely the technical problem (solved by Shannon’s SemCom approach in Section 5. Finally, in Section 6, a visinotheory), semantic problem, and effectiveness problem [11]. of SemCom in the 6G era is proposed.While Weaver’s framework targets H2H communication, we For ease of reference, We summarize the deﬁnitions of theconsider the modern SemCom in the era of machine intelliacronyms that are used in this paper in Table 2.gence as addressing both the semantic and effectiveness prob- In [1], the fundamental problem of communication wasthe design of such techniques is to solve the semantic problem described as that of reproducing at one point either exactlyin Weaver’s framework. or approximately a message selected at another point. The communication-theoretic model of Shannon consists of ﬁvetechniques target scenarios where the destination is a machine parts as illustrated in Fig. 1(a) and explained as follows.(e.g., H2M and M2M). Then the techniques aim at delivering 1. An information source produces messages to be trans-a message as a instruction or query to the machine such that mitted to the receiver.it can perform what the sender requires it to do or respond 2. A transmitter encodes and modulates the messages into aappropriately. In this sense, their design focuses on the effec-tiveness aspect of communication, thereby the name. signal for robust transmission over a unreliable channel. 3. A channel is the medium used to propagate the encodedmantic and effectiveness encoding are introduced while applisignal from the transmitter to receiver. In the propagationcation speciﬁc techniques are discussed in following sections. process, the external, random disturbance to the signal is called channel noise. construct the transmitted message from the received signal such that errors due to channel distortion are corrected; the message is intended. • Semantic encoding and transmission: This class of tech- In the remainder of this sub-section, the principles of se- Even though Shannon’s theory does not explicitly target SemCom, information-theoretic encoding can be adopted for the latter by extending two key notions, entropy and mutual information, to deﬁne semantic entropy and semantic mutual information. The entropy of a discrete source measures the amount of information in each sample and depends on the source’s statistics. Mathematically, the entropy of a message X is deﬁned as H(X) = −∑p(x)log p(x), where x,x,· ·· , xare possible outcomes of X with probabilities p(x), p(x),· ·· , p(x). Accordingly, the mutual information is given by I(X;Y ) = H(X) − H(X|Y ), which indicates how much the amount of information about the transmitted message X is obtained after receiving the message Y . On the other hand, the mutual information between the source and destination quantiﬁes the amount of information obtained about the former by observing the latter. The combined use of the two measures allows the study of the maximum data rate under a constraint of “physical distortion” [e.g., mean squared error (MSE)]. The unsuitability of these information-theoretic measures for SemCom due to their lack of semantic elements is obvious by considering the following example. A single-letter error results in a transmitted word of “big” to be received as “pig”; the reception of the word “cattle” due to the transmission of “cow” corresponds to errors in multiple letters. The former represents much more reliable information transmission than the latter but the reverse is true from the perspective of semantic transmission. An attempt on deﬁning the semantic entropy was made in [8]. Therein, a semantic source is modeled as a tuple (W, K, I, M) with W modeling the observable world that includes a set of interpretations, K representing source’s background knowledge, I indicating source inference that is relevant to background knowledge, and M denoting message generator or encoder. Then given the probability µ(w) for each elements in W, let Windicate the subset of W in which the message x is justiﬁed as “true” by the inference I, i.e., W= {w ∈ W |w= x}, and the logical probability of x is deﬁned as p(x) =and the corresponding semantic entropy is H(X) = −∑p(x)log p(x). Those deﬁnitions lay a foundation for semantic encoding/decoding and semantic transmission. For instance, the recent work in [10] argues that the key issue of SemCom is to ﬁnd a proper semantic in-tion parties in the form of a KG; 2) encoding data using the terpretation W (also termed as semantic representation) andKG. Detailed discussion is presented in Section V. Second, the coding scheme P(X|W ) such that the semantic ambigu-the power of ML gives rise to the learning based approach of ity of transmitted message H(W |X) and coding redundancyintegrated semantic and channel (i.e., information theoretic) H(X|W ) are close to zero. Consequentially, the model (se-encoding. As an example, for text transmission, a joint semantic) entropy H(W ) and the message (syntactic) entropymantic and channel coding scheme based on deep learning is follows from H(X) = H(W ) + P(X|W ) − H(W |X ), meaningproposed in [138], where encoding a sentence s is represented that the semantic encoder could achieve intentional sourceby x = C compression with an information loss H(W) − H(X).and C Departing from the above theoretic abstraction, there are di-ceived signal y. The encoders and decoders are trained as a versiﬁed approaches for designing practical semantic encod-single neural network by treating the channel as one layer in ing. The ﬁrst approach is KG based semantic-encoding thatthe model (similar to SplitNet discussed in the sequel). The is decomposed into two stages: 1) ﬁnding a proper represen-training process features the consideration of both semantic tation of common knowledge background of the communica- (C(s)) with C(·) denoting the channel encoder (s) denoting the semantic encoder. It follows that the similarity and transmission data rate. Speciﬁcally, the sentence similarity between the original sentence s and the recovered sentenceˆs is given by where B(·) represents bidirectional encoder representations from transformers (BERT), a well-known model used for semantic information extraction [138,139] (more details are presented in Section 3.1.2). Another approach is based on latent semantic analysis (LSA) which compresses text documents by ﬁnding their low dimensional semantic representations. This is achieved by ﬁnding a low-dimensional semantic subspace using singular value decomposition (SVD) of document-term matrices that indicates appearances of speciﬁc words in the documents and then projecting these matrices onto the the subspace (see more details in Section 3.1.1). Effectiveness encoding is to compress messages while retaining their effectiveness as instructions and commands for machines. Techniques are system and application speciﬁc and thus there exist a wide-range of designs. As examples, we discuss effectiveness source encoding targeting two representative tasks: classiﬁcation and distributed machine learning. More application speciﬁc effectiveness encoding techniques are discussed in Section 4. • Information Bottleneck (IB) for Classiﬁcation: Consider source encoding of an information source represented by a random variable X . Classic coding schemes based on Shannon’s rate-distortion theory aims at ﬁnding a representation close to x in terms of MSE. On the contrary, IB is aware of the computing task (e.g., classiﬁcation), denoted as Y , making it an effectiveness coding scheme. The main feature of IB is to extract information˜X from the signal source X that can contribute to the effective execution of Y as much as possible. Taking classiﬁcation for instance,˜X shall represent the most discriminative feature of X. Mathematically, the IB design aims at ﬁnding the optimal tradeoff between maximizing the compression ratio and the preserved effectiveness information, corresponding to simultaneously minimizing the mutual information I(˜X;X ) and maximizing I(˜X;Y ). This is equivalent to solving the following multi-objective optimization problem [140]: where the conditional distribution p( ˜x|x) denotes the source encoder and β is a combining weight. Its optimal solution is task-speciﬁc. For classiﬁcation, Y is the label predicted by the classiﬁer. A general algorithm constructs the optimal source encoder in (2) via alternating iterations. In each iteration, the probability density functions p( ˜x), p(y|˜x) and p( ˜x|x) are determined step-by-step. The IB has attracted attention in the area of machine learning as it contributes the much needed theory for studying deep learning [141]. In particular, training a feature-extraction encoder in a deep neural network (DNN) can be interpreted as solving a IB-like problem where the encoder’s function is to encode an input sample x into a compact feature map ˜x. The encoding operations, e.g., feature compression and ﬁlter pruning, regulate the discussed tradeoff in IB. method of implementing federated learning (FL), a popular distributed-learning framework based on SGD, requires a device to compute and transmit to a server a stochastic gradient, computed by taking derivative of a loss function with respectLayer is to perform semantic/effectiveness encoding/decoding to the parameters of a AI model under training. Detailed dis-discussed in the preceding subsections. On the other hand, cussion of FL is provided in Section 4.1. A gradient is highthe techniques for radio access layers (i.e., Physical Layer, dimensional as its length is equal to the number of modelMedium Access Layer, and Logical Link Control Layer) are parameters. For instance, the popular Resnet18 model haslargely derivatives of Shannon’s information theory; their dearound 11 million trainable parameters. As it’s transmissionsign is focused on improving semantic-agnostic performance incurs excessive communication overhead, a gradient shouldsuch as data rate, reliability, and latency. Then Semantic be compressed by quantization at the device. A generic vec-Layer transmits to lower layers Semantic/Effectiveness Entor quantizer is unsuitable for two reasons. First, its design iscoded Data (SEED) and receives from them Channel Debased on using the MSE as the distortion metric. This met-coded Datas (CDD). Based on the proposed architecture, we ric is undesirable for the current task since a gradient conveysdescribe two approaches to the SemCom system design, layera gradient-descending direction on a (learning) loss functioncoupling approach and split neural network (SplitNet), reand this metric fails to directly reﬂect the direction deviation.spectively. Second, the conventional vector quantizer can handle only low-dimensional vectors because its complexity grows expo-2.2.1 Layer-coupling Approach nentially fast with the vector dimensions. To tackle the two challenges calls for the design of new effectiveness techniques for source encoding of stochastic gradients. One such designjointly design the Semantic Layer and radio access layers. To is presented in [142] with two key features. The ﬁrst is to di-this end, we propose the possibility of exchanging control sigvide a high-dimensional gradient into many low-dimensionalnals between them (see Fig. 2). Among others, a set of basic blocks, each of which is quantized using a low-dimensionalsignals are deﬁned and their functions in layer-coupling decomponent quantizer. The results are combined to give thesign described as follows. high-dimensional quantized gradient with combining weights optimized to minimize descent-direction distortion. The sec-back from lower layers enables the semantic/effectiveness ond feature is to design a component quantization using the(SE) encoders to adapt their coding rates to the wireless chanmethod of a Grassmannian manifold. In the current design,nel state. the manifold refers to a space of lines where each line (plus the sign of an associated combining weight) suitably repre-erogeneous importance levels of elements of the SE encoded sents a particular descent direction. Essentially, the codebookdata. For a human receiver it is the interpretation, while for a of a Grassmannian quantizer comprises a set of unitary vectorsmachine that acts as a receiver is the is effective execution of that are optimized to minimize the expected directional distor-a task. Examples include identifying keywords in a sentence tion. The effectiveness source encoder for stochastic gradient,in terms of representation of its semantic meaning or discrimdesigned to target the task of FL, is shown to achieve close-inate gains of different features of an image for the purpose of to-optimal learning performance while substantially reducingclassiﬁcation. Such information facilitates adaptive transmisthe communication overhead with respect to the state-of-artsion, multi-access, and resource allocation in the lower layers. approaches, such as a binary gradient quantization schemeFor instance, for data uploading to a server for model training, called signSGD [142].the uncertainty levels of local samples can be used as DII to The protocol stack of a radio access network is modiﬁeddistributed computing (e.g., average or maximum). PAI enin [16] to support SemCom. Its key feature is the additionables the physical layer to deploy effectiveness transmission of a that interacts with and control all layers to provide efﬁ-techniques, such as AirComp discussed in the preceding subcient solutions for both semantic and effectiveness problemssection. in Weaver’s framework. In this subsection, we propose a new, simpler SemCom architecture as shown in Fig. 2. Itgory the data belongs to. This includes, for example, image builds on the conventional protocol stack but adds a Seman-for machine recognition, image for human, and stochastic gratic Layer that resides in the Application Layer as a sub-layer.dient for machine learning, etc. DTI enables the radio access This allows the Semantic Layer to interface with sensors andlayers to choose transmission techniques based on a suitable actuators, have access to algorithms and content of data inperformance metric (e.g., Grassmannian quantization for grathe speciﬁc application. The main functions of the Semanticdient source encoding discussed in the last sub-section) and • Data Importance Information (DII): It measures the het- • Partial Algorithm Information (PAI) that includes essen- • Data Type Information (DTI) that indicates which cateunderstand the corresponding performance requirements (e.g., an image is more sensitive to noise for human vision than for pattern recognition). The above control signals can be transmitted over a control channel to the receiver and used by its semantic layer to remove semantic noise from CDD for semantic symbol error correction or control computing at the Application Layer. The relevance of the above controls signals to techniques discussed in the sequel are summarized in Table 3. An extreme form of layer-coupling design is to integrate Semantic Layer and Physical Layer into a single end-to-end global DNN [138]. The global DNN is split into two parts, namely encoder and decoder and the communication channel is sandwiched between them. This is termed SplitNet and its architecture shown in Fig. 3(b). The encoder model (decoder model) is further divided into two sub-modules, semantic encoder (decoder) and channel encoder (decoder), each of which by itself is a neural network [143,144]. This facilitates training in practice (see more details in Section 4.2 about split inference). Note that the new channel encoder (decoder) in the SplitNet replaces the source and channel encoders (decoders) in the conventional digital architecture in Fig. 3(a). The new encoder directly transmits analog modulated symbols instead of quantizing them into bits and mapping them to predeﬁned modulation symbols. SplitNet is closely related to the area of joint sourcechannel coding. The optimality of source-channel separation was proved by Shannon in the case of a point-to-point link with asymptotically large code blocklength [1]. This simpliﬁes the design of communication system as source encoder/decoder and channel encoder/decoder can be optimized as separate modules. This has become a feature of classic design approaches and led to the establishment of source and channel coding as separate sub-disciplines [145]. However, source-channel separation is sub-optimal in the regime of ﬁnite code length [146]. It worth mentioning that the suboptimality is also shown in the context of SemCom [8]. In practice, given a ﬁnite bit-length budget (e.g., short packet transmission), the end-to-end signal distortion, or the reconstruction quality of transmitted information, sees a complex tradeoff between source and channel decoding errors. This has motivated researchers to explore the approach of joint source-channel coding with ﬁnite code lengths [147-149]. The joint design has been shown to be simpler and potentially more effective than its separation counterpart in practical SemCom applications, such as transmission of multimedia content [89,150-154], speech [144], and text [138,155]. In particular, the notion of deep joint source-channel coding has appeared in [89,144,151-153], where both the source encoder (decoder) and channel encoder (decoder) are implemented by DNNs. For example, the image retrieval problem in the context of wireless transmission for remote inference is considered in [89]. In their joint source-channel coding approach, the feature vectors are mapped to the channel symbols and decoded at the receiver, where the source and channel encoders are integrated by a DNN after the feature encoder while the the source and channel decoders are consolidated by a DNN, followed by a fully-connected classiﬁer. Most recently, SplitNet was also adopted in an end-to-end design of a SemCom system. For example, the SplitNet design presented in [138] for SemCom system is built on the deep-learning based natural language processing (NLP). The key component of the design uses a Transformer, which is a well-known language model for NLP and has the advantages of both recurrent neural networks (RNNs) and convolutional neural networks (CNNs), to construct the encoder and decoder. The loss function for training the DNN model is characterized by two terms: one is the cross entropy which measures the semantic difference between raw and decoded signals, while the other is the mutual information to maximize the system capacity. The SplitNet design was demonstrated to outperform a traditional communication system in terms of sentence similarity, which is speciﬁed in (1), and robustness against channel variation. In addition, there are other relevanttem, individual modules are simpler to design compared to the works on SemCom using the SplitNet approach, e.g., the dis-fully integrated SplitNet. Furthermore, given standarized intributed SemCom system for IoT [143] and SemCom systemterfaces between modules, their design can be distributed to for speech transmission [144] (see more details in Section IV-different parties. Inevitably, the advantages of layer-coupling C).approach are at the expense of optimized performance and 2.2.3 Comparison between Two ApproachesNet is a better choice. The advantages of layer-coupling designs include backward compatibility, simplicity, and ﬂexibility. Since the ap-particular application, somewhat losing the universality of proach is based on a modiﬁed version of the conventional pro-the layered approach. Given a speciﬁc task and a radiotocol stack, SemCom system designed using the approach al-propagation environment, the encoder and decoder parts of lows the use of existing coding and communication techniquesthe neural network are jointly trained to efﬁciently compress if they are suitably modiﬁed to allow some control by the Se-raw data into transmitted symbols while ensuring their robustmantic Layer. Furthermore, by modularizing a SemCom sys-ness against channel fading and noise. This makes it pos- A SplitNet design of SemCom system is dedicated to a sible to achieve a higher communication efﬁciency and better task performance than a layer-coupling design. Nevertheless, SplitNet faces its own limitation in three aspects. First, channel fading and noise result in stochastic perturbation to both forward-propagation and back-propagation of the DNN. This may result in slow model convergence during training. As proposed in [143], the issue can be alleviated by feedback of channel state information (CSI) to mitigate fading at the cost of additional latency and overhead. Second, the radio-propagation environment varies over time and sites, especially for high-mobility applications. A pre-trained end-toend SplitNet model tends to be ineffective in a new environment and re-training is needed, which is time consuming and may incur excessive communication overhead. Third, analog channel symbols generated by a neural network can be harder for circuit implementation than conventional modulation constellations due to, for example, a larger dynamic range. Nevertheless, research on the SplitNet approach is still in its nascent stage and continuous research advancements are expected to yield effective solutions for overcoming the above limitations. Recall that H2M SemCom features the transmission of messages that can be understood not only by humans but also by machines, such that they can have dialogue or the latter can assist or care for the former. The potential applications of H2M SemCom are illustrated in Fig. 4. In this section, we discuss semantic encoding and other H2M SemCom techniques in four representative areas: human-machine symbiosis, recommendation, human sensing and care, and VR/AR. Human-machine symbiosis (also known as man-computer symbiosis) refers to scenarios in which humans and machines establish a complementary and cooperative relationship. On one hand, using their complementary strengths, they can cooperate to carry out a task that is originally difﬁcult or even infeasible. Humans can beneﬁt from machines’ assistance to improve their life quality or productivity. On the other hand, humans and machine can teach each other to improve individuals’ capabilities e.g., AI-powered education or imitation learning. In this sub-section, we discuss SemCom in the scenarios of Human-machine symbiosis. A typical system is illustrated in Fig. 5 and its main operations are described as follows. First, human activities are sensed and the sending results are semantically encoded at edge devices. Then the encoded data are transmitted to an edge server for decoding and subsequent use to train an AI model. Finally, the trained AI model acquires some domain speciﬁc, human-like abilities, which are further used to assist humans. The distinction of the human-machine symbiosis lies in the semantic encoding techniques that maps human sensing data or knowledge into into low-dimensional vectors while capturing their semantic meanings or latent features [156]. For example, the encoded semantic data refers to the embedded knowledge in the case of text or boundaries between objects and the background in the case of image [116-118,157]. In the remainder of the subsection, we introduce two representative semantic encoding techniques widely used in human-machine symbiosis, linear LSA models [59,158,159] and BERT [138,144,160], and discuss their deployment in SemCom systems. Additional techniques are also brieﬂy described, followed by an overview of state-of-the-art applications. As a technique in natural language processing, LSA is used to model and extract semantic information from text documents. LSA has diverse applications, ranging from search engine to translation to the study of human memory. A basic LSA technique follows the following procedure. Consider a set of documents. To begin with, each document is expressed as a column vector where each element is binary indicating whether it includes a speciﬁc word or term associated with the element’s location. Then putting the column vectors together makes the document set a so called document-term matrix denoted as X. From the matrix, semantic information can be extracted via the following steps. First, the principle column subspace of the document-term matrix, called semantic space, is computed by SVD: X = UΣV, where U is the column space of X, Σ is the singular value matrix, and Vis the row space. Given desired dimensions k, the semantic space is deﬁned as U, which is the k-dimensional principle column subspace of X. The corresponding k-dimensional principle singular-value matrix is denoted as Σ. Second, all document vectors are projected onto the low-dimensional semantic space. Speciﬁcally, let drepresents the j-th column of X and is thus the j-th document. Then the extracted semantic vector, denoted asˆd, is obtained asˆd= ΣUd. Last, using the reduced-dimension semantic vectors, the similarity level between any two high-dimensional documents, say j-th and j-th documents, is measured by efﬁciently computing the following function: In the context of SeCom between a human and a machine, the function of LSA is to extract semantic information from human speech or messages and in that way aid the machine’s interpretation. Its deployment in a SemCom system essen-end. tially involves the design of a LSA-based semantic encoder and substituting the result into either the layer-coupling archi-3.1.2 Semantic Encoding by BERT tecture (see Fig. 2) or the SplitNet architecture (see Fig. 3(b)). As an example, the design proposed in [161] is based on SplitNet and features integrated semantic/channel coding/decodingon a popular model called transformer, which is the ﬁrst transimplemented by training a split DNN model with the trans-duction model relying entirely on self-attention to compute mitter half performing LSA. On the other hand, for a designrepresentations of its input instead of using sequence-aligned based on the layer-coupling architecture, LSA resides in theRNNs or convolution to generate its output [162]. A transsemantic layer to map each human message into the semanticformer comprises an encoding component and a decoding space. The distilled semantic information in the dimension as-component. Each includes several sequentially connected ensociated with a larger singular value is more important. Thiscoders or decoders. An encoder cascades one self-attention suggests the use of the singular values as DII indicators. Thenlayer with a feed forward neural network. The former perthe LSA-encoded information, together with the DII indica-forms feature extraction to ﬁnd the relation of words in the tors, are passed to the lower layers for transmission. On theinput sentence; the latter is trained with a suitable objective, other hand, the CRI feedback in the upward direction enablessuch as language translation. A decoder has a similar structure the semantic layer to adapt the dimensionality of the semanticas the encoder except for having an extra encoder-decoder atspace to the channel state. Consequently, when the channeltention layer inserted between the self-attention layer and the supports a high rate, the semantic space can be expanded tofeed forward neural network. The additional layer helps the yield a better representation of the human message and thus adecoder focus on a speciﬁc position in the input sequence to more accurate understanding by the machine at the receivinghandle issues, such as the case of one word having multiple Building on the transformer architecture, the key feature of BERT is a new training strategy, termed masked language model (MLM), that randomly masks some words in a sentence to generate training samples. The training objective is to learn the masked words in the sentence. This training strategy and objective make it possible to generate an enormous number of unlabelled text data samples for training. Another key feature of BERT is that a text sentence is input into the transformer as a whole rather word-by-word following the natural left-toright uni-direction. The features endow on the trained transformer the ability of predicting the missing words based on their context, giving the technique the name of bidirectional representations. With this ability, BERT outperforms the unidirectional approaches to become the state-of-the-art strategy for natural language processing. The combination with other techniques (e.g., classiﬁcation) broadens the applications of BERT, e.g., Q&A, and information retrieval. The procedure of deploying BERT in a SemCom system to support human-machine symbiosis is similar to that for LSA. In other words, BERT can be simply used as the semantic encoder. For the SplitNet design, BERT is used as a part of the split DNN. For the layer-coupling approach, BERT is used for extracting the important information from the sensed human activities with DII indicators showing their importance levels. The exchange of data and control signals between the semantic and lower layers are similar to those for LSA. Other techniques that can play an important role in semantic encoding for human-machine symbiosis are the CNN based approaches of object recognition [163-165]. Relevant techniques can efﬁciently compress human sensing data (e.g., facial expressions and behaviours) for efﬁcient transmission to machines for subsequent recognition. A typical object recognition technique detects the boundary between the targeted objects and the background based on contextual features. A representative design of CNN-based auto-encoder (AE) for segmentation is proposed in [157], termed SegNet, which comprises an encoding component, a decoding component, and a classiﬁer. The encoding component contains several encoders, each of which is paired with a decoder in the decoding component. Each encoder is a CNN, modiﬁed from the well known VGG-16 network [166]. Each decoder up-samples its input using the transferred pool indices from its corresponding encoder to produce sparse feature maps. Finally, the output feature maps of the last decoder are fed to a softmax classiﬁer for pixel-wise classiﬁcation. This generates the segmentation results. In 5G systems, there exist three generic connectivity types: enhanced Mobile Broadband (eMBB), Ultra-Reliable LowLatency Communication (URLLC), and massive Machine Type Communication (mMTC). They are deﬁned to support a wide range of services with heterogeneous quality-of-service (QoS) requirements. The choice of connectivity type for human-machine symbiosis is application dependent. Many relevant applications do not require high transmission rates, ultra reliability, or massive connections. Examples include AI-assisted learning, coding, and debugging. For such applications, normal radio access sufﬁces. On the other hand, there exist a class of symbiosis applications that involve tactile interaction, thereby requiring low latency and reliable transmission. For instance, AI-assisted driving and remote surgery require the response latency between robots and humans (i.e., drivers or surgeons) to be less than 10 ms and 1 ms, respectively [167]. For this class of applications, the provisioning of URLLC connectivity is crucial. Applications related to human-machine symbiosis can be separated into three main classes. The ﬁrst class of applications is AI-assisted systems. AI technologies provide ways for machines to acquire human-like skills and abilities by learning from the experiences of human experts (e.g., doctors and drivers), which, in turn, make the machines useful assistants for humans. Using LSA, AI-powered chatbots have started to replace humans in FAQs/customer services in places such astering. The choice of connectivity type for SemCom systems universities [19] and over social media [20]. Machines canto support recommendation will be also discussed, followed also play an important role in AI assisted healthcare via uti-by an overview of the state-of-the-art applications of recomlizing machine learning algorithms to extract key informationmendation systems. from patients’ records to help doctors with diagnosis and prediction of the risks of diseases [21]. Machine assistance have3.2.1 Collaborative Filtering also been applied to other professional areas, such as video game debugging [22], automatic programming [23], driving assistance [24], and second language learning and teachingusing their historical ratings [168]. Then the purpose of se[25].mantic encoding is to distill the rating information from the The second class of applications is interactive machinehistorical data recording user’s daily activities such as shoplearning that includes humans in the loop to leverage the gen-ping, entertainment, reading, and multimedia streaming. This eralized problem-solving abilities of human minds [26-30].removes redundant information to compress the data for efThis is particularly useful in cases lacking training samples forﬁcient transmission. The design of semantic encoder can be rare events that are needed for automatic machine learning tobased on LSA described in Section III-A by modifying the work. Moreover, the joint force of machines and humans candocument-item matrix to count the user’s access/purchase frecombine their complementary strengths to tackle grand chal-quencies of different items. In the case where such explicit lenges such as protein folding and k-anonymization of healthinformation is unavailable, an AI model can be trained to infer data [27]. In such collaboration, human experts uses their ex-the users’ preferences from sensing data recording his/her beperiences to guide machines to reduce the search space.haviour and emotions in either the physical world or on socialThe third class of applications is worker-AI collaborationmedia platforms [169]. where both human and machine workers cooperate as peers to ﬁnish real-time tasks, e.g., moderating content, data dedu-server compiles them into a user-item matrix. Each column plication [31,32]). In particular, relying on tactile communi-storing the ratings by one speciﬁc user is called an item veccation, robots can imitate the actions of remote surgeons intor. Let r minimally invasive surgery [33,34]. Such cooperative surg-representing the rating of i-th item in a set of interest. Moreeries can beneﬁt from the machine involvement to improveover, the accuracy and dexterity of a surgeon and minimize traumasthe Pearson correlation as a metric, the similarity in preference induced on patients. One important design issue for worker-between user j and i can be computed as AI collaboration is to prevent machines from telling lies or making mistakes [35]. A recommendation system predicts user preferences inwhere I terms of ratings of a set of items such as songs, movies, andj, The pairwise similarity measures allow the server to recproducts. Recommendation has become a popular tool forommend items preferred by some users to others sharing simmaking machines intelligent assistants and improve user expe-ilar interests. rience. Examples include playlist generation for multimedia streaming services, product recommendation for online shop-number and type, the user-item matrices become increasingly ping, marketing on social media, Internet search, and onlinesparse. The insufﬁcient rating data causes difﬁculty in clusdating [36,38,39,61]. A SemCom system aims at supportingtering of similar users. Researchers have developed solutions recommendation in a wireless network, as shown in Fig. 4. Infor this problem by applying techniques from data mining and the system, an edge device semantically encodes and trans-machine learning including SVD [170], non-negative matrix mits the user’s personal data to a edge server for generatingfactorization [171], clustering [172], and probability matrix recommendations for the user. The purpose of semantic en-factorization [173]). coding is to infer user ratings from the user data. Given a rating database of a large number of users, the server gener-systems for recommendation can be based on either the layerates recommendations for a target user using a ﬁltering tech-coupling or SplitNet architectures. When explicit rating innique. Among the most popular one is collaborative ﬁlteringformation is available at a device, its uploading is infrequent discussed in the sequel. We will also introduce other tech-and may even require only a single upload, as user preferences niques including content-based, collaborative, and hybrid ﬁl-usually do not change rapidly over time. On the other hand, Next, after receiving rating data from multiple users, the denotes the j-th item vector and rits i-th element S( j, j) =rr represents the set of items rated by both user j and As in the scenario of human-machine symbiosis, SemCom when such explicit information is unavailable, a large amount of user sensing data may need to be transmitted from the device to the server for preference inference. One way to address this issue is by designing semantic encoders that can locate a low-dimensional item-rating subspace without compromising the recommendation accuracy. The other way is utilizing high-rate access (eMBB) whenever it is available or by deploying a targeted large-rate technology, such as mmWave. Other available ﬁltering techniques for recommendation include content-based ﬁltering, demographic ﬁltering, and hybrid ﬁltering [174]. The content-based approach utilizes the users’ historical data for recommendation. Speciﬁcally, the recordings of, e.g., habits or interests, are useful for creating a user proﬁle characterized by a set of features. Then, an item aligned with the features of a proﬁle is likely to interest the associated user and thus can be recommended. Next, the demographic ﬁltering approach classify users according their demographic information such as nationality, age, and gender. Items preferred by one user are recommended to the users in the same demographic class. Last, the hybrid ﬁltering approach combines several aforementioned approaches and has been showcased to boost the recommendation accuracy. Recommendation systems are deployed in many areas. The most popular venue is social networks where recommendation is applied to emotional health monitoring by detecting abnormality [36], partner recommendation in online dating [38], and emoji usage suggestions [39]. Other applications include travel recommendation systems for mobile tourist [37], remote healthcare (e.g., cloud-assisted drug prescription [42] and cloud-based mobile health information in [43]), TV channel recommendation [40], video recommendation [41], and music recommendation [175]. Traditionally, to ofﬂoad the high computation load, recommendation systems are hosted in the cloud server with unlimited computation resources [42,43,176]. Nevertheless, the traditional approach can lead to excessive communication latency and overhead as the personal data to upload is known to grow at an exponential rate. Recent years see the increasing popularity of the splitcomputing approach that spreads a recommendation system across the cloud and the network edge leveraging the edge computing platform [60]. In addition, researchers have proposed unmanned aerial vehicle (UAV) assisted recommendation systems for location based social networks [61] as well as distributed recommendation systems featuring data privacy [62,63]. Human sensing-and-care refers to real-time tracking and monitoring of humans’ health conditions and movements by machines, such as the machines can offer a proper care to the humans. The human monitoring relies on sensors (e.g., temperature and positioning) on or around humans. The sensing data are then transmitted to a server for analysis and decision making. To facilitate the discussion, let us consider the concrete example of biomedical sensors, which are wearable or implantable and perform transduction of biomedical signals (e.g., electrocardiogram (ECG) signals) into electric signals. In this context, the purpose of designing a SemCom system is extract useful features from biomedical sensing data and transmit them to a server for diagnostics or medical image analysis. An example of a feature is the “main-spike” interval of ECG signals, termed QRS interval. In the sequel, we discuss the techniques for biomedical semantic encoding and the associated SemCom system design. 3.3.1 Biomedical Semantic Encodingarchitecture. Typical biomedical signals include ECG signals for detect-3.3.2 State-of-the-Art Applications ing heart activity and electromyography (EMG) signals for detecting e.g. skeletal activity. Such signals are characterized by a certain level of periodicity and predictability, making it pos-derly monitoring [44,45]. In [44], a wireless sensor network sible to estimate the signal statistics within a short time frame.is deployed to monitor the well-being conditions of the elIn the current context, semantic coding is particularized toderly. Speciﬁcally, multiple types of sensors are used to montechniques for estimating the statistics that contains usefulitor their activities such as cooking, dining, and sleeping. A information the biological activities of a human. Relevantsimilar system targeting the elderly with dementia is reported techniques are based on either the time-domain or frequency-in [45]. Another type of application is a super soldier sysdomain approaches. As an example, consider the R-peak de-tem [179], which monitors and analyzes the health status and tection of a ECG signal, where R refers a point correspondingfatigue levels of soldiers by sensing their temperatures, gesto a peak of the ECG wave. The detection of R-peak helps thetures, blood glucose levels, and ECG. The third type of appliheart-rate characterization [177]. More elaborate analysis ofcation is the set of general human activity recognition systems a ECG wave decomposes a main spike into three successive[47,48]. In [47], head-mounted smartphones are designed to upward/downward deﬂections, termed Q wave, R wave, andhave situation awareness, e.g., awareness of user behaviors S wave. A time-domain method for their detection mainly useand environmental conditions. To this end, the data collected the shape characteristics, such as ﬁnding the largest ﬁrst-orderfrom smartphone sensors (e.g., accelerometers, gyroscopes, and second-order derivatives. On the other hand, a frequencyand cameras) are transmitted to a server for feature extracdomain method ﬁrst transforms the signal into the frequencytion and situation inference. In another design presented in domain using, e.g., wavelet transformation, and then apply[48], a wearable magnetic induction device is used for sensﬁltering with a suitable passband to extracting the desired in-ing and wirelessly transmitting the magnetic induction signals formation.to a server for activity detection using a RNN based algorithm. In the SemCom system for human sensing-and-care, theOther applications of human sensing-and-care include remote biomedical signals that are semantically encoded and trans-healthcare systems [49-51] and smart-home monitoring sysmitted by an small-size edge device. Upon detecting abnor-tems [46]). mality, the transmissions from this device should be real-time and very reliable, to call for an urgent medical care [178]. In view of these requirements, it is preferable to design the SemCom system on the layer-coupling architecture rather than a DNN model. This is because no complex data should be pro-volves the use of mobile devices (e.g., smartphones, glasses, cessed and the complex DNN model may be an overkill, whileor headsets) to create new human experiences by replacing its long computation time unacceptable. The semantic encod-the physical world with a virtual one. On the other hand, ing and transmission can be controlled using DTI generatedAR devices alter humans experiences by augmenting real obas follows. The duration, amplitude, morphology, frequen-jects with computer-generated perceptual information across cies of Q/R/S waves are all useful for heart related diagnosticsdifferent senses (e.g., vision, hearing, haptics, hearing, presranging from detecting conduction abnormalities to diagnos-sure, and smell). VR/AR provide a way of seamlessly merging ventricular hypertrophy. But they are of different impor-ing the physical and virtual words. The resulting immersive tance levels that are also disease-dependent. In other words,human experience can give a rise to a plethora of future serthe features of biomedical signals can be assigned differentvices, such as entertainment, virtual meetings or remote eduimportance levels, resulting in the DII. At the lower layers,cation. Ofﬂoading computation and caching to edge servers the adopted radio-access technologies depend on applications.makes it possible to implement latency sensitive VR/AR apFor indoor applications, sensors are usually linked to a localplications on resource-limited devices. VR/AR data processhub (e.g., a smartphone) using short-range and low-latencying and SemCom between devices and servers are discussed technologies such as Zigbee, Bluetooth, and WiFi. For thein the following sub-section followed by a summary of statehubs to access the cloud or for outdoor applications, cellularof-the-art SemCom for AR/VR. communication is the preferred choice. In regions with no or poor cellular coverage, satellite communications can be used3.4.1 VR/AR Semantic Encoding and Transmission instead while GPS helps human positioning and tracking. A large-scale network that connects a massive number of sensors can rely on the mMTC service supported within the 5GAR and VR systems are illustrated in Fig. 7. Consider AR The common application of human sensing-and-care is el- VR and AR are two H2M technologies. VR essentially in- The procedures of semantic encoding and transmission in semantic encoding whose purpose is to recognize and track physical objects of interest to the user and then project icons, characters and information onto them. Its implementation requires cooperation between a device and an mobile edge computing (MEC) server. First, raw video data recorded locally using on-device cameras are uploaded to the server for processing. In the MEC server, three algorithms, namely mapper, tracker, and object recognizer, are executed [52]. The function of the tracker is to detect the object’s position based on input raw data and to proactively adjust a rendering focal area. Based on the tracking results, the mapper is to distill features (e.g., virtual coordinates) of objects embedded in the raw data using image processing techniques. In parallel, the object recognizer leverages both the object features and video streaming to produce desired rendering data (e.g., cartoon icons and explanatory text) according to the application requirements. Such data are downloaded onto the device where they are superimposed onto the actual scenes by a local renderer and the edited VR videos are displayed to the human user. Next, the function of VR semantic coding is to select only part of the video depicting the virtual world to download and display to the user such that the heavy burden of downlink transmission is alleviated [53]. To this end, the user’s kinesthetic information (e.g. location, angle of view, and head movements) is collected over multiple on-device sensors and efﬁciently transmitted to the server. The information is processed by a tracker and a mapper operating at the server to detect the ﬁeldof-view (FoV) and select the corresponding video output by extraction from cached 360video streaming such that it best ﬁts the user’s movements. Then video output is downloaded onto a pair of VR glasses or a VR headset for constructing the virtual world. Such semantic encoding dramatically reduces the required downlink data rate as opposed to the full 360video streaming. It also makes it possible to meet the stringent latency requirement for immersive user experience. The communication efﬁciency can further improved by deploying advanced semantic encoding techniques such as video segmentation and compression by head-movement prediction and eye-gaze tracking. The connectivity requirements for VR/AR SemCom are discussed as follows. In general, VR/AR systems need to collect and process real-time multimedia data from the physical world and generate/transmit high-resolution visual and auditory data. Therefore, the required connectivity is characterized by high rate and low latency [53-55]. As an example, a human FoV covers a horizontal and a vertical ranges of 150 and 120, respectively. The simulation of a realistic FoV generally requires 120 frames per second with each frame consisting of 64 million pixels (60 pixels/degree). Given standard video quantization (36 bit/pixel) and H.265 encoding (with 1 : 600 compression rate), the required transmission rate is at least 1 Gb/s [6,53]. On the other hand, real-time interaction needed for immersive human experiences requires motion-tophoton latency to be lower than 15 ms [56]. Such requirements places VR/AR connectivity at the intersection between eMBB and URLLC. A solution that addresses these issues is the MEC platform in 5G that ofﬂoads computation intensive tasks (e.g. tracking, mapping, and recognition) and caching storage-demanding multimedia content at edge servers in the proximity of users as shown in Fig. 7. This reduces the burden of devices to be merely responsible for data collection and displaying videos. Building the MEC platform, a VR/AR system can be designed based on either the layer-coupling or the SplitNet architecture. Consider the former. Different types of human kinesthetic information are of heterogeneous importance for a speciﬁc application and can be thus assigned different DIIs to facilitate importance aware adaptive transmission. On the other hand, for collaborative VR/AR involving multiple devices and servers, the SemCom system design can beneﬁt from exploiting the PAI of AI models (e.g. classiﬁcation) and other data processing algorithms (e.g. compression and ﬁltering), the DTI and DII of raw data (e.g. voice and images) to optimize the operations of data aggregation and rendering data feedback for boosting the communication efﬁciency. On the other hand, the scene-data collection, local rendering, and global data processing at servers can be integrated in an endto-end design using the SplitNet approach. Then the trained neural-network is split for partial implementation at a device and server according to the application requirements and device’s resource constraints. There exists a wide range of VR/AR applications with a vast literature (see e.g., the surveys in [57,58] and references therein). However, the area of SemCom for VR/RA is relatively new and still largely uncharted. Some recent advancements are highlighted as follows. The challenges and enablers for URLLC communications to implement VR/AR are discussed in [53]. Furthermore, a case study of deploying VR in wireless networks is also presented, which integrates millimeter-wave communication, edge computing, and proactive caching. Another design of wireless VR network is proposed in [54]. It is proposed that small base stations are used to ﬁrst collect and track information on a VR user and then send to the user device the generated 3-D images. The resource management issue targeting such a system is also investigated that accounts for VR metrics such as tracking accuracy, processing delay, and transmission delay. In addition, a new type of VR/AR system enhanced by skin-integrated haptic sensing is proposed in [55]. Such a special wireless sensor can be softly laminated onto the curved skin surfaces to wirelessly transmit haptic information conveying the spatio- temporal patterns of localized mechanical vibration.tion operation suppresses the noise in local updates arising Recall the objective of M2M SemCom is to efﬁciently con-ing a trained model, the layer-coupling approach is a more nect multiple machines and enable them to effectively executesuitable approach for designing a FL system. In a FL system, a speciﬁc task in a wireless network. It usually targets IoTthe uploading of high-dimensional model updates by many applications as illustrated in Fig. 8. The typical tasks in M2Mdevices poses a communication bottleneck. For instance, the SemCom span the areas of sensing, data analytics, learning,popular ResNet-50 model comprises 25.6 million parameters reasoning, decision making, and actuation [16]. In this sec-or equivalently 1638.4 million bits in the “ﬂoat64” format. tion, we discuss effectiveness encoding and transmission tech-Relevant SemCom techniques for tackling this bottleneck inniques in four representative types of application, namely dis-cluding effectiveness encoding, modulation, multi-access, and tributed learning, split inference, distributed consensus, andradio-resource management (RRM) are discussed separately machine-vision cameras.in the following sub-sections. The main theme of distributed machine learning is to train an AI model using distributed data at many mobile devices asworkers, and an arbitrary communication round (i.e., iterawell as their computation resources.tion) in the FL algorithm, say the t-th round, that comprises FL mentioned in Section 2.1.2 stands out as arguably theseveral sequential phases: model broadcast, local effectivemost popular distributed-learning framework [180,181]. Itsness encoding, model-update uploading, and global-model popularity is mainly due to its feature of protecting the own-updating. The focus of this subsection is the effectiveness enership of mobile data by avoiding their direct uploading to acoding at a device. Its goal is to convert local training data server. Instead, based on the classic stochastic gradient de-into a local model by updating the broadcast global model, or scent (SGD) algorithm, FL requires each device to computea local (stochastic) gradient representing the update. At the a local model updated using local data or a stochastic gra-beginning of the t-th round, the server broadcasts the globaldient representing the update, as illustrated in Fig. 9. Thenmodel parameters W the local model updates are transmitted to the server for ag-puted at worker-m and the worker’s local dataset are denoted gregation before updating the global model. The aggrega-as G Consider a FL system with one server and M devices, called and D=(x,y), respectively, where Nis the •Blockchain •Digital twin •Vehicle platooning local-dataset size, xthe i-th sample, and yits associated label. The effectiveness encoding involves multi-step (say Bstep) local gradient descent. To this end, let Dbe partitioned into B mini-batches with the b-th mini-batch denoted as D. The local gradient in step b is computed as where L (·) denotes the loss function pre-deﬁned for the learning task. The above computation can be implemented using the well-known back-propagation algorithm. Essentially, implementing the differential operator ∇ in (5) involves computing the gradient w.r.t. the model parameters W from the last layer to the ﬁrst layer backwardly (see details in [182]). Using the local gradient, the step-b gradient descent refers to updating the local-model parameters as where λ is the step size and W= W. After the last minibatch is processed, worker-m obtains the local model W= Wor the corresponding local gradient G= W− W. This completes the effectiveness-encoding process. The uploading of the local model or local gradient ends the current communication round. The effectiveness encoding can include the additional operation of local model/gradient compression described as follows. Consider the case of gradient uploading. A gradient tends to be sparse in the sense that a large number of its elements are much smaller in magnitude than others. A simple method of gradient compression is to keep a ﬁxed number of elements with the largest magnitudes and set the remaining ones to zeros, thereby substantially reducing the communication overhead [64,65]. Consider the case of gradient uploading. Local models also exhibit sparsity. Parameter (or neurons) pruning can be performed progressively during the process of training using a suitable metric, for example, variance or magnitude [66]. A much simpler method is called Dropout that randomly samples parameters for deletion [67]. Besideson classic information theoretic encoding that ﬁrst quantizes reducing communication overhead, the above model pruningthe observations into bits and channel encoding the bits. The is also effective in avoiding model over-ﬁtting.main reason is the mismatch of the task with the objective of 4.1.2 Effectiveness Modulation and Multi-accessbols transmitted by sensors. A more vivid interpretation is This section aims at overcoming the communication bottleneck in a FL system form the perspective of effectivenessalize “over-the-air aggregation” for fast FL, termed over-themodulation and multi-access.air FL [64,65,69]. Given its awareness of the FL algorithm Linear analog modulation (LNA) supports fast transmis-(especially the aggregation operation), AirComp enabled by sion by avoiding the computation-intensive processes ofLNA represents a joint effectiveness design of modulation digital modulation, channel encoding and decoding [183].and multi-access targeting FL. Consider the uploading phase Though the lack of protection by coding limits its appli-of a communication round and the FL implementation based cation to reliable communication, recently, LNA is gainingon local-gradient uploading. The discussion can be extended popularity in SemCom especially in fast multimedia trans-to the other case of local-model uploading straightforwardly. mission [184] and machine learning [69,143,185] as humanEach worker modulates its local gradient using LNA and quality-of-experience, machine inference and learning are ro-transmits the result over the same frequency band simultabust against noise if it is properly controlled by, for exam-neously as other workers. By supporting such simultaneous ple, power control and scheduling. In the context of learning,access, the communication latency is reined in to avoid linit is even possible to exploit channel noise to accelerate theear scaling with the number of devices, as in conventional learning process by escaping from saddle and local-optimalorthogonal-access schemes. For over-the-air aggregation it is points [68].required to align the magnitudes of the received signals. To LNA is known to be optimal for the task of distributed sens-this end, each worker performs channel-inversion power coning in a sensor network as illustrated in Fig. 10. The task istrol. By synchronizing workers’ transmission (by, for examto compute an aggregation function (e.g., averaging) of dis-ple, timing advance) and exploiting the wave-form superpotributed sensor observations so as to suppress the observationsition property of a multi-access channel, the server receives noise. To efﬁciently carry out the task, a technique calledthe desired average of local gradients. Mathematically, each over-the-air computing (AirComp) based on LNA exploits thereceived symbol is denoted as y and given as waveform superposition property of a wireless channel to perform over-the-air aggregation of simultaneously transmitted sensing data using LNA [70]. Let Udenote a noisy observation at sensor m of a common source X: U= X +Wwherewhere M is the number of devices and for worker m, s Wrepresents the sensing noise (see Fig. 10). All observa-resents a transmitted symbol modulating a single gradient cotions are transmitted at the same time over Gaussian channelsefﬁcient, h to a server (fusion center) using uncoded LNA. This results inpower control with P being a given constant, and at last z the the following received signal:channel noise. Over-the-air FL is designed for a broadband where Sresults from modulating Uand Z is the Gaussianproach. In this case, the PAI passed from the Semantic Layer channel noise. The modulated symbol Sis the scaled versionhito the Physical Layer is the speciﬁcs of the aggregation opof Uunder the power constraint E(S)≤ P. The servereration (e.g., aggregation weights, selected devices and their produces an estimate of the source X, denoted asˆX, that min- imizes the distortion D = lim∑E(X[n] −ˆX[n]),4.1.3 Effectiveness Radio Resource Management where n represents the symbol index. In the presence of channel noise, the server receives the desired average of distributed observations. It is proved in [186] that in the case of Gaus-FL from the perspective of RRM. To overcome the commusian sources and noise, AirComp achieves the optimal rate-nication bottleneck, RRM should be guided by the principle distortion tradeoff for a large number of sensors, making Air-of allocating more resources to the transmission of data that Comp an effective multi-access technique for the task. Onhas a higher importance for the model training, while prethe other hand, it is sub-optimal for the current task to relyventing the unimportant data from occupying channels. This Most recently, AirComp discussed above is applied to re- In this subsection, we answer the effectiveness problem for leads a new class of effectiveness techniques called (data) importance-aware RRM [73-76]. In a FL system, There exists multiple types of data including training samples, local gradients, or local models. Regarding training samples for a classiﬁer model, their importance is measured by data uncertainty, a popular concept in the area of active learning. It is deﬁned as the level that how conﬁdent an AI model holds for its prediction to a data sample [73,187]. Consider a neural-network based classiﬁer model. A common metric for measuring the uncertainty of a sample x is the entropy of posteriors of L labels as computed using the model, where Pr(`|x, W) is the posterior of label-` given input x and model parameters W. On the other hand, the importance of gradients can be measure by gradient divergence [74] or squared multivariate coefﬁcients of variation (SMCV) [75]. For a local gradient G, its gradient divergence is measured by the variance to the global gradient, given by vec(G) −vec(E[G])where pis the probability that this local gradient is selected and vec(·) is the vectorizing operator. The SMCV of an aggregated global gradient vector is given by the sum of means of each entry divided by the sum of variances of each entry with randomness due to channel noise. In addition, the importance of a local model can be measured by its variance to the current global model kvecW− vec(W)k (see, e.g., [188] for an overview). These schemes features both channel and importance awareness and aim at striking a balance between scheduling devices with strong channel for the objective of rate maximization and those with important data for the objective of accelerating model convergence. As a result, the schemes favour devices with either very important data, very strong channel, or satisfactory levels in both aspects. It should be emphasized that in the context of FL, the two objectives mentioned earlier are not entirely in conﬂict from the perspective of latency minimization. The former reduces latency per round but the latter reduces the required number of rounds for model convergence. To minimize the total latency (in second), the . . . above tradeoff should be optimized. A common design approach is to derive a DII for implementation using the layercoupling approach, which accounts for both the data importance and channel state. Then the criterion for importanceaware scheduling is simply to maximize the DII. Consider an edge learning system (e.g., a closed system without the dataprivacy issue) directly uploading data from devices to a server for model training. The DII is a linear combination of a channel quality indicator and maximum sample uncertainty of a local dataset [73]. Next, consider scheduling for a FL system. Probabilistic scheduling is adopted to avoid a bias of the trained model towards a particular local dataset. To be speciﬁc, in each round, each device is scheduled with a given probability. The optimal probability of a device is shown to be proportional to the local-gradient variance and a monotone decreasing function of the communication latency [74]. Besides scheduling, effectiveness power control schemes have been also designed for FL to address the issue of differential privacy [77,78]. By power control, such schemes regulates a sufﬁciently high channel-noise level to meet the privacy constraint at the cost of reduced training accuracy. While the preceding sub-section focuses on model training, the theme of this sub-section is the other facet of machine learning, namely inference using a trained model. In this area, split inference is an emerging paradigm for 5G-and-beyond to ofﬂoad a large part of the inference task from a mobile device to an edge server hosting a large-scale model [79]. The remaining task executed on-device is to extract useful features from raw data for transmission to the server. The task splitting gives the name of split inference. This mitigates the impact of the resource limitation on the device and enriches its capacity via access to a server model, much more powerful and complex than the one that can be afforded as an on-device counterpart. For instance, classiﬁers in the Google Cloud can recognize thousands of object classes and that in Alibaba Cloud hundreds of waste classes for litter classiﬁcation. In the remainder of the subsection, we discuss effectiveness cod- ing and communication separately for the layer-coupling andtant features) [80,87,88]. Moreover, the DII also determines SplitNet architectures.the transmission sequence (i.e., more important features are 4.2.1 Effectiveness Encoding and Transmission forunder a inference-uncertainty requirement [84]. On the other Layer-Coupling Approachhand, PAI providing some information on the effectiveness In the context of split inference, effectiveness encodingchoice of a matched classiﬁer model at the server and thus refers feature extraction, referring to the process in whichpassed to the latter. a device encodes high-dimensional raw data into reduceddimension features or feature maps [182]. Features represent4.2.2 Effectiveness Encoding and Transmission for Splitinformation essentially for inference while raw data contains a large amount of redundant information (e.g., background objects and noise known as spatial redundancy in raw images [189]). Stripping away the redundancy substantially re-Net architecture in Fig. 3(b) with semantic encoder/decoder duces communication overhead without compromising infer-replaced by their effectiveness counterparts targeting the task ence performance. Our discussion focuses on feature extrac-of inference. The function of the effectiveness encoder is to tion (i.e., effectiveness encoding) while details on inferenceextract feature based on designs discussed in the preceding using features (i.e., effectiveness decoding) can be found insub-section. On the other hand, the effectiveness decoder is a a typical standard machine-learning book (see e.g., [182]).neural network performing inference. The popular approach A classic, simple technique is principal component analysisof designing the pair of channel encoder/decoder is to use (PCA) [190]. PCA uses SVD to identify the most informa-AE [182]. An AE comprises an encoder and an decoder. Gentive low-dimensional linear subspace (feature space) embed-erally, the AE’s encoder compresses high-dimensional inputs ded in a large high-dimensional dataset, called principle com-to reduced-dimension outputs; using them as inputs, the deponents. Then projection of a data sample onto the featurecoder attempts to reconstruct the encoder’s inputs. In a splitspace yields its features. Modern feature extraction exploitsinference system, the two AE components interface with a the powerful representation capability of neural networks andwireless channel (see Fig. 3(b)). Then the AE based chanrich training data. Such a feature-extraction model can be im-nel encoder directly maps features to analog modulated chanplemented using multi-layer perceptrons (MLPs) for a gen-nel symbols and the channel decoder decode received symbols eral purpose, CNNs for visual data [80,81], and RNNs forinto features as input to the subsequent effectiveness decoder time-series data [82] or leverage the emerging graph neuralto generate inference results [89]. The design of semantic and networks to improve inference performance with point cloudchannel encoders are under two constraints. First, given B and non-Euclidean data [83].complex channel symbols, the number of extracted features A SemCom system designed for efﬁcient feature transmis-(real scalars) should be 2B. Second, a normalization layer is sion is characterized by its feature-importance awareness. Asrequired in the channel encoder such that channel symbols can widely reported in the deep learning literature, features dosatisfy transmit power constraints. The end-to-end training of not contribute evenly to inference performance and thus havethe encoders/decoders in SplitNet is difﬁcult to a large number heterogeneous importance levels [191]. Available impor-of layers in the combined global model and also channel hostance measures include divergence for data statistical modelstility (i.e., fading and noise) embedded in it. This difﬁculty (e.g., discriminant gains of speciﬁc feature dimensions) [192]is overcome by training the two AE components separately and other classiﬁcation-loss related metrics for DNN mod-from the semantic encoder/decoder. Speciﬁcally, the effecels [191]. Consider an importance-aware SemCom systemtiveness encoder and decoder are pre-trained in advance since designed using the layer-coupling approach. The CRI passedthey are independent of the channel and remain unchanged to the discussed effectiveness encoder controls the number ofeven if the channel statistics vary [89]. On the other hand, features to extract. Given the number, features are selectedthe AE based channel encoder and decoder can be quickly rebased on their importance levels (DII) to be transmitted in thetrained using transfer learning as the radio-propagation enviradio-access layers [84]. There exist numerous algorithms forronment changes [90]. This provides the components capabilfeature pruning for neural networks (see e.g., [85]). Some de-ity to cope with channel noise. As a ﬁnal step, an end-to-end sign supports channel adaptation of encoding under given re-training of all neural is conducted so that they can be further quirements on latency and inference performance [86]. Theadjusted to achieve optimal end-to-end inference performance DII is also passed to the layers for importance aware quanti-in the presence of channel hostility. zation (e.g., more important features have higher resolutions) and RRM (e.g., more bandwidth/time-slots for more impor-tradeoff, described as follows. The effectiveness encoder and Consider the implementation of split inference on the Split- Split inference involves a computation-communication decoder in the SplitNet architecture (see Fig. 3(b)) can be generated by splitting a single AI model (i.e., a neural network) into two parts with unequal numbers of layers. Shifting the split point to the left results in simpler on-device effectiveness encoding and and higher complexity for effectiveness decoding at the server, and vice versa. Intuitively, as the device is resource constrained, it is desirable to push the split point as close to the input layer of the AI model as possible. The intuition is correct from the perspective of computational load but overlooks the other perspective of communication overhead. Speciﬁcally, in a large class of popular AI models in practice, the size of features output by “shallow” feature-extraction layers is large and can be even much larger than that of raw data at the input, which is known as “data ampliﬁcation effect” [193]. Consequently, a shallow split point may results in unacceptably large communication overhead and energy consumption, defeating the original purpose of split inference. This motivates researchers to adjust the split point with the aim of optimizing the communication-and-computation tradeoff [91,92]. Relevant algorithms rely on proﬁling the operational statistics of individual model layers including feature size, latency, energy consumption, and required memory size. Then the proﬁles are applied to design algorithms for adapting the split point to the time-varying communication rate under latency requirements and devices’ resource constraints. Last, the required connectivity type for split inference depends on the speciﬁc application. For the family of mission critical applications (e.g., ﬁnance, auto-driving, and automated factories), URLLC connectivity is required [194]). For instance, remote inference for autonomous driving is expected to have 1 ms latency and near 100% reliability in communication [195,196]. Other applications are not latency sensitive but require the close-to-human machine vision (i.e., recognition of hundreds of object classes for a high-end surveillance camera), eMBB will be needed to transmit high-dimensional features extracted from high-deﬁnition images. Distributed consensus refers to the process that agents in a distributed network act together to reach an agreement by message exchange. A typical algorithm involves each agent interactively updates its own state based on received information on peers’ states [197]. When there are many agents, the convergence could be slow and as a result the iterative process could incur excessive communication overhead, for example, in the speciﬁc scenarios of vehicle platooning [98] and blockchains [101]. To address this issue, the criterion for designing SemCom for efﬁcient distributed consensus is to reduce the overhead without signiﬁcantly decreasing the convergence speed. The key component is the design of effectiveness encoding that is aware of the algorithm and its objective and based on the knowledge, extracts and transmits semantic information from an agent’s state to others. In the remainder of this subsection, we introduce two representative scenarios of distributed consensus, namely vehicles platooning and blockchains, and discuss matching effectiveness coding techniques. Vehicle platooning is a high-way automatic transportation method for driving a cluster of connected vehicles in a formation (e.g., a line) to achieve higher road capacity and greater fuel economy [93]. This requires the member vehicles to brake and accelerate together based on the system state, which represents the consensus. Maintaining the system state requires vehicles to continuously share and update their local states e.g., vehicle parameters (e.g., positions, accelerations and velocities), sensing data (e.g., trafﬁc lights, pedestrians, obstacles, road conditions, and LIDAR imaged point cloud), and even individual auto-pilot models. Transmitting all the raw state data is impractical. For instance, an typical autonomous vehicle collects from its sensors up to several gigabytes of data per seconds. Thus, it is essential to design effectiveness encoding to extract from the raw state data the information essential for convergence to a consensus. To better understand the principle of a vehicle-platooning algorithm, consider a simple scenario of driving a platoon along a straight high-way in a line formation. In this case, effectiveness encoder of each vehicle, say vehicle m, outputs its distance to its predecessor, s, and its own speed, v, which deﬁnes the local state, while its control variable is its acceleration, a. The local states are assumed to be exchanged continuously between vehicles over wireless links. Let r(τ) denote the cost at time τ for front situation (i.e., the relationship between vehicle-m and its predecessor, vehicle-(m − 1)). Typically, r(τ) accounts for all or some of the following aspects, namely safety cost, efﬁciency cost and comfort cost, each of which can be deﬁned as function of the states of vehicle m and those of its neighbours (see examples in [93,94]). Hence r(τ) represents the behind situation of vehicle m. Then the local control problem at the vehicle over a duration T and with the objective of behind-and-front cost minimization can be formulated as [93]Z where τ = 0 denotes the current time instance. Iteratively solving the problem, applying the computed acceleration, and broadcasting the local state by all vehicles will eventually reach their consensus on the platoon’s optimal speed and intervehicle separations gaps. There exists a tradeoff between: 1) the complexity of effectiveness encoding and the amount of its output information (that determines communication over- head), and 2) the sophistication of the platooning algorithm. For example, a vehicle’s predicted trajectories can be sharedbuilding construction [96]. A large-scale project involves a with others in the platoon, requiring effectiveness encoders tolarge team and many contractors/sub-contractors that perform compress the trajectories. Most recently, deep learning havedistributed ﬁeld works. A blockchain can be used as as a been adopted to empower platooning. Essentially, CNN-basedsecure distributed ledger to facilitate cooperation and ensure effectiveness encoders are designed to intelligently extract in-construction quality. Based on this platform, the physical formation from real-time videos captured by on-board cam-and functional features of building components are stored in eras, such as trafﬁc lights, lanes and obstacles [95]. Exchang-blocks and validated by all parties. During the construction, a ing such sensing data and use them for consensus on complexchange made on a particular component (e.g., a new design or manoeuvres give the platoon collective intelligence for auto-construction progress) by a stakeholder will trigger updating driving.of all nodes in the blockchain. For this to happen, the change Other SemCom techniques have been extensively studiedin question has to be submitted as a updating proposal (i.e., in the literature. First, URLLC connectivity is required in thisa transaction) and approved by other nodes upon validation mission-critical application to avoid collisions [99]. In termsbefore it is made on the blockchain. The detailed digital forof latency for vehicle platooning, it should be measured andmat of a transaction depends on on the choice of data model minimized in terms of information latency rather than the con-structure for that blockchain, such as the Industry Foundation ventional over-the-air latency as the former directly relates toClasses schema for civil engineering, and the transaction alcoordinated control performance [100]. To overcome the limitgorithm. One design of effectiveness encoding for communiof radio resources, its effectiveness allocation for vehicularcating transactions is based on transmitting differential states, platooning should be importance aware by identifying criticalcalled semantic difference transaction (SDT) in [96]. Speciﬁand less critical information in vehicles’ state data, allowingcally, the SDT-based encoder compares the objects in the new them to be compressed accordingly to the speciﬁc driving al-schema with the validated ones recorded in the blockchain, gorithm [98]. On the other hand, it is proposed in [99] that ef-aiming to identify the objects that require updating. Then the fectiveness RRM and multi-access should also have situationencoder generates the required changes of only the identiﬁed awareness and be optimized for a speciﬁc vehicular networkobjects, which is broadcast to all other nodes for validation. topology represented using a graph. Based on the principles,Compared the case in which the whole schema is broadcast, SemCom techniques are designed based multi-agent RL to in-SDT can substantially reduce the communication overhead, tegrate the operations in the semantic layer and physical layerespecially given that the changes are usually minor. (e.g., transmission stopping), thereby reducing the intensity of communication.for further reduction of the communication overhead via 4.3.2 Blockchainseffectiveness-based resource allocation mechanism groups A blockchain is a growing chain of blocks, each of whichtion of transactions for convergence of consensus with a given contains a time stamp (when the block was published), trans-security threshold [97]. action data of the blockchain, and cryptographic information of the previous block. In this way, the chain is robust against any alteration of the transaction data by an individual block as it requires changes on subsequent blocks too. As they can implement public distributed ledgers, blockchains ﬁnd a broadrelies on servers for sensing data analysis, are capable of range of applications ranging from crytocurrencies to gamingidentifying interested labels in recorded images and videos to ﬁnancial services [97]. In a distributed network containingsuch as time, location and objects [103]. They are commonly a blockchain, the devices are nodes within that blockchain.used as standalone cameras or as a surveillance network deNodes can propose changes to the blockchain by submittingployed in homes, factories, and cities to detect human gestransactions via broadcasting to all other nodes. One distinc-tures and activities [106], for security management [102], or tive feature of the blockchain protocols is that a transactionidentify defective products on a production line [105]. At a should be broadcast to all member nodes in order to reach con-larger scale, machine-vision cameras are merged into aerial sensus. For this reason, transaction approval relies on frequentand space sensing networks to form a universal network [107]. communication to exchange information and reach a consen-The communication bottleneck of a machine-vision camera sus across a large number of nodes. This motivates the designnetwork arises from large-size raw data generated by each of effectiveness encoding for blockchains.camera and the enormous camera population (e.g., millions of Machine vision cameras, which are connected by IoT and connected surveillance cameras in a metropolitan city) [198]. A single frame in 1080P videos consists of two million pixels while there can be up to 60 frames per second, generating data at a rate of 100Mbps [199]. In the sequel, we discuss effectiveness encoding and RRM for efﬁcient SemCom in such a network. One key feature of effectiveness encoding is to detect regions of interests (ROIs) in a set of visual data that contain interesting labels and thereby facilitating trimming of videos or images for efﬁcient streaming to edge or cloud servers for analysis [103]. A CNN model is commonly deployed as an effectiveness encoder to detect ROIs. Speciﬁcally, consider a set of K frames (or images), denoted as {I}, each of which, say frame k, comprises R regions, denoted as {I}. A lightweight on-camera CNN detector scans each region of every frame to search for interesting objects. For frame k, the indices of spatial ROI will be grouped into the index set F(k) deﬁned as F(k) = {r | objects captured in I}. Then the number of spatial ROI is |F(k)|. In the temporal dimension, frames comprising interesting objects are then included into the index set Fdeﬁned as F= {I| |F(k)| > 0}. Consider security management as an example [102]. A region of a frame containing dangerous objects such as knives and guns will be tagged as a spatial ROI. The temporal ROIs sets Fare then encoded and transmitted to servers for further analysis while those frames not in Fcan be coarsely compressed or even discarded. While conventional RRM schemes deliver video bits indiscriminately, effectiveness designs targeting machine-vision cameras differentiate the importance level of sensing data given their relevance to ROIs, which can be used as DII in the layer-coupling approach. In terms of quantization, more bits can be allocated to high-resolution quntization of the pixel regions in F(k) and fewer bits to quantizing background pixels [103]. In the presence of multiple cameras, the quality of contents from each camera should be assessed in terms of how critical they are for executing a given task. Cameras capturing critical ROIs should be given a higher priority in RRM [106]. Besides ROI detection, it is possible for cameras with increasing computation capacity to perform part of data analysis and extract features from multimedia sensing data using a DNN model and a knowledge base [104]. Last, it should be mentioned that given the above operations, IoT connected computer-vision cameras can be implemented using either the layer-coupling or the SplitNet approaches, discussed earlier. A KG is composed of the representations of many entities in a semantic space and the relations among them. KGs have become a powerful tool for interpretation and inference over facts [200,201]. Many massive KGs have been constructed including Wikidata [202], Google KG [203], WorldNet [204], Cyc [205], YAGO [206]. They have formed the foundation for Internet and a knowledge base for understanding how the world works. In particular, large-scale KGs are used by search engines such as Google, chatbot services such as Apple’s Siri, and social networks such as Facebook. In this section, we introduce a paradigm of SemCom featuring the use of KGs as a tool to improve communication efﬁciency and effectiveness. In this context, the key function of a KG is to provide a semantic representation of information such that semantic encoding is not only efﬁcient but also robust against communication errors. For H2H communication in the presence of errors, a KG based decoder can correct the errors by decoding the received erroneous message as a correct one with largest similarity on the graph [116,117]. For H2M symbiosis, a KG can function as a set of human behavior rules to exclude unreasonable results due to faulty sensing results [207-209]. Furthermore, for M2M SemCom, KGs are useful in knowledge sharing between different types of machines and thereby serving as machine interfaces in heterogeneous networks. In the remainder of the section, we will provide a preliminary on KG theory and then discuss KG based SemCom techniques, applications, and architectures. KG refers to the broad area of graph representation of concrete discussion, we consider the deﬁnition introduced in [119] where nodes are nouns related to real-world objects/names/concepts and edges specify their relations. One example is illustrated in Fig. 11. A fact, a basic element of knowledge, can be represented by a so-called factual triple (head node, relation, tail node) or mathematically (h,r, t), e.g., (Albert Einstein, Graduated From, University of Zurich). A node (e.g., h or t)) is a vector, say a L-dimensional vector, storing relevant information, creating a L-dimensional semantic space. For instance, if Einstein is the head node h, the tail node t can be “Theory of Relativity”, “The Nobel Prize”, “University of Zurich”, “Hans Einstein” (his son), and so on. The relation r is either a vector if the mapping is distance based, i.e., h + r = t, or a matrix (re-denote r as M) if the mapping semantic-similarity based, i.e., hM= t. The knowledge relevant to an object, such as a human, is potentially inﬁnite. A KG reduces the inﬁnite knowledge to a ﬁnite-dimensional semantic space to enable practical knowledge processing and transmission. One potential issue that can arise from the ﬁnite dimensionality of a KG is that a fact involving two nodes, h and t, is still plausible even if it is not captured by the graph due to a missing edge/relation connecting the nodes. The issueCom efﬁciency and robustness [116-118]. As a concrete excan be addressed by introducing a scoring function measur-ample, we discuss the use of the design presented in [117] ing plausibility. Two typical functions, namely the distanceto encode a simple sentence “Albert Einstein won the Nobel based and a semantic-similarity based function, are given asPrize for physics in 1921”. The most important component follows [210,211]of the KG assisted encoder is a knowledge encoder. Conf(h,t) =kMh − Mtk(h,t) = kh + r − tk, (11)sentence/message. Deﬁne an entity embedding as a node of where Mand Mare two relation matrices (edges) of thethe KG to which some tokens of the input sentence can bemapped. For instance, the words/tokens “Albert” and “EinKG.stein” can be mapped to the node “Albert Einstein” of the Provisioned with sets of valid and invalid facts, a KG canKG in Fig. 11 and hence share the same entity embedding. be constructed using either the rule-based or the data-drivenSimilarly, the words namely “Nobel”, “Prize”, and “physics” approach. Either approach requires the deﬁnition of a suitableare mapped to corresponding nodes of the KG. The distincloss function. One typical choice is the margin-based functiontive feature of a knowledge encoder is to fuse the tokens of given as [212]the original message with their entity embeddings to generate where F and Frepresent the set of valid and invalid triples,tities. For example, an input token “Albert” would generate respectively, and γ (12) is a given margin. Other available de-the output “Albert” and “Einstein”. The encoder is made of signs include logistic based and cross-entropy based functionsstacked aggregators, each further consisting of two multi-head [138,213,214].self-attention modules. Note that each such module is deKGs are useful for training AI models especially those withsigned to concatenate multiple self-attention modules, each of semantic requirements such as linguistic applications and in-which relates different positions of the input single sequence volving human-machine interaction. The structured knowl-to compute a representation of the sequence [116]. The use of edge in a KG reduces the search complexity in training anda knowledge encoder at a semantic receiver can exploit a KG helps improve the accuracy of a trained model. Successto correct inaccuracy in the semantic meaning and ﬁll some has been demonstrated in the areas of question answeringmissing tokens of a received message as caused by channel [108,109], virtual assistants [110,111], dialogue [112], anderrors during the transmission. recommendation systems [113-115]. Some KG based techniques and their use in SemCom are discussed in the sequel. For H2H SemCom, a KG representing knowledge on thein the received message from human beings and react intellibackground of the parties or the domain of their conversa-gently [122,123]. To be more speciﬁc, training a model untion can be injected into a semantic encoder to boost Sem-derpinning the machine using structured knowledge gives it For H2M SemCom, a KG helps a machine to understand the ability to recognize the entities embedded in the received messages and their relations to other entities, which helps the generation of logical reactions. Such an approach has found applications in question answering, dialogue and recommendation systems [112,115]. In the area of robotics, imitation learning has been designed based on a knowledge-driven approach where the robotic assistants imitate human by inferring semantic meanings in the observed human actions [124,125]. Furthermore, in human sensing applications, KGs can be used to deﬁne a set of human behavior rules. For concrete discussion, the remainder of the sub-section focuses on the use of KG in utterance generation, a basic topic in conversational AI assistants. The task is to generate relevant utterances (sentences or phrases) from a knowledge base. In this area, a long-short-term memory (LSTM) network is widely used. It refers to a speciﬁc RNN with long-term memory for the important and consistent information while short-term memory for the unimportant information. The effectiveness of LSTM networks has been proven in enabling a machine to generate utterances based on the received message, the knowledge base as well as its dialogue history with the human partner [108,112]. On the other hand, feeding the DBpedia KG corresponding to the Wikipedia database into a LSTM network makes it capable of interpreting questions and producing reasonable answers. There exist other designs. In [109], a KG is provided to a CNN to extract semantic features of an input question for subsequent answer searching. On the other hand, a knowledge-driven multi-model dialogue system designed in [110] is capable of gesture recognition, image/video recognition, and speech recognition, providing multi-model human-like abilities to virtual assistants. Futhermore, KGs can also render the operations of recommendation systems more explainable [113-115]. KGs are related to M2M SemCom in several ways. First, KGs can provide a platform for implementing large-scale IoT networks such as smart cities, logistics networks, and vehicular networks. Consider a vehicular network as an example. A large-scale dynamic KG can be constructed and periodically updated to represent the states of connected vehicles (e.g., locations, velocities, acceleration, routes, and destinations) and their relationships (e.g., chances of collision and whether they form platoons) [215]. Such a KG paves a foundation for facilitating vehicle-to-vehicle communication (e.g., exchange of state information) to avoid accidents or facilitate platooning as well as a platform for trafﬁc management and operating ride-sharing or car-hailing services. Second, KGs provide a tool for managing SemCom or other types of networks to facilitate resource allocation, work-ﬂow recommendation, and service selection [132-134]. The machine intelligence needed for efﬁcient network management can be powered by structured knowledge embedded in a network KG. Such a KG can be constructed to contain the network topology, requirements of different applications, expert knowledge from community data, product documents, engineer experience reports, user feedback, etc. Third, an M2M SemCom system can be deployed to support the extension and updating of a KG. In particular, SemCom between a large number of edge devices enables distributed knowledge extraction, storage, and fusion [126,127]. To this end, each device obtains up-to-date local knowledge via interaction with its environment and uploading the real-time knowledge to servers for fusion and updating the global KG [128-131]. The efﬁcient knowledge transmission can rely on some efﬁcient SemCom technique discussed in preceding sections (e.g., importanceaware transmission). Last, KGs can provide a tool for enabling inter-operability which is necessary for M2M SemCom in cross-domain applications, where the knowledge and infor-started with an accelerating pace so that the technologies can mation of devices of heterogeneous types have to be shared orbe ready for commercialization in 2030 [216-218]. Compared aggregated [135-137]. One particular architecture for such awith preceding generations, 6G will achieve limitless connecpurpose is proposed in [136]. It uses a server as a semantictivity that will scale up IoT to become Internet-of-Everything core to exchange the messages sent by heterogeneous devices(IoE) and revolutionize networks by connecting human beings by serving as both a relay and a semantic encoder that trans-to intelligent machines in such an synergistic way as to crelates a message from one machine language into another.ate a cyber-physical world [219]. Realizing the vision will First, consider the SplitNet architecture discussed in Sec-integration of communications, sensing, control, and computtion 2.2.2. The use of KGs in training AE and auto-decodersing. As a result, SemCom has the potential to play a pivhas been demonstrated to improve their capabilities to decodeotal role in 6G. The realization of SemCom will power several the correct semantic meanings from the received messages de-new types of 6G services, aiming at creating truly immersive spite their distortion by communication channels [117]. A re-experiences for humans, such as extended reality (XR), highlated but different approach is proposed in [116], where com-ﬁdelity holographic communications, and all-sense communibining source information and its corresponding representa-cations [221]. In the sequel, we will discuss the 6G services, tion in a KG as inputs to the AE is shown to enhance thetheir requirements for SemCom, and how they can be met by SemCom performance. Next, an architecture featuring KGthe development of 6G core technologies. server assisted SemCom is presented in [10]. The server located at the network edge relies on a KG to interpret the se-applications that extend human senses in a fusion of the virmantic meaning of the messages sent by a source device, ef-tual and physical worlds. They include ubiquitous wireless ﬁciently encode/translate the messages, and then relay the re-intelligence, data teleportation, immersive XR, digital replisults to the destination device. As a comprehensive KG cancation, holographic communications, telepresence, wearable have an enormous size, its storage and inference complexitynetworks, and sustainable cities. Several of them that are far exceeds the capacities of devices. Ofﬂoading the KG to aclosely related to SemCom are described as follows, along server overcomes the limitations of devices to exploit the KGwith the new challenges they pose to SemCom. for reducing the SemCom overhead. 1. Immersive XR: XR is an umbrella term encompassing While the 5th generation of mobile networks are being rolled out around the world, the global research on 6G has VR, AR, the mixed reality (MR), and the intersections between them [6]. Boundless XR technologies will be integrated with networking, cloud/edge computing, and AI to offer truly immersive experiences for humans, applicable in a wide range of areas such as industrial production, entertainment, education, and healthcare. Its implemen- tation requires the collection and processing of data reﬂects or describes human movements and surroundings to generate key features that guide system operations, e.g., shifting rendered targets and displaying particular videos. Smooth human experience relies on intentions and preferences that are being interpreted properly by devices and machines, so that they can produce and display desired contents. The continuous human-machine interaction places XR in the domain of H2M SemCom discussed in Section 3. Relevant designs are similar to SemCom for VR/AR discussed therein but their requirements are more stringent in terms of accuracy and diversity of sensing human characteristics (e.g. head movement, arm swing, gestures, speeches), data rates (e.g., 1Gbps for 16K VR [6,53]) and latency (e.g., motion-tophoton delay below 15-30 ms [56]). Moreover, the increased reliance of immersive XR on AI calls for SemCom design that is capable of a more efﬁcient support of training and inference using large-scale AI models (i.e., scaling up SplitNet). 2. High-ﬁdelity Holographic Communication: Holographic communication involves transmission of 3D holograms of human beings or physical objects. Based on highresolution rendering, wearable displays, and AI, mobile devices will be able to render 3D holograms to display local presence of remote users or machines, creating a more realistic local presence of a remote human being or physical object [221]. Scenarios such as remote repair, remote surgey, and remote education can all beneﬁt from this new form of communication [216]. This new form of SemCom aims at to enhancing visual perception of users to improve the effectiveness of virtual interaction. This requires high-resolution encoding of haptic information, colors, positions, and tilts of a human/object. Displaying interactive high-ﬁdelity holograms requires extremely high data rate (up to 4.3 Tbps) and stringent latency constraints (possibly sub-milliseconds) [216]. Such requirements make it crucial to boost the efﬁciency and speed of semantic/effectiveness encoding and transmission techniques to unprecedented levels. Moreover, since holographic communication can potentially involve both human users and machines, their real-time holographic interaction will require seamless integration of H2M and M2M SemCom techniques. 3. All-Sense Communication: All of ﬁve senses, including sight, hearing, touch, smell, and taste will be included in 6G communications using an ensemble of sensors that are wearable or mounted on each device. Combined with holographic communication, the all-sense information will be efﬁciently integrated to realize close-to-real feelings of remote environments [216,219]. Such technologies will facilitate tactile communications and haptic control. In all-sense communication, the diversiﬁed types of sensing signals create different new dimensions of information, resulting in exponential growth of the complexity of semantic information representation. The aforementioned future services presents formidable tasks for developing next-generation SemCom technologies. On the other hand, breakthroughs in the area are made possible by leveraging the revolution of 6G technologies. Some key aspects are described as follows. 1. Almost Limitless Connectivity: While 5G realizes ubiquitous connectivity, 6G will strive to achieve almost limitless connectivity. Speciﬁcally, in the 6G era, we expect to experience enormously high bit rates of up to 1 Tbps, low end-to-end latency of less than 100 microseconds or high reliability with properly relaxed latency (e.g. 99.999% with 3ms in new radio vehicle), high spectral efﬁciency of about 100 bps/Hz, massive connections reaching at least 10devices/km, and ultra-wide and multi-frequency frequency bands of up to 3 THz with air, space, earth, and sea coverage [220,222]. As a result, all machines and human beings will not only be connected but do so in a profound, instantaneous way as to enable in-depth knowledge sharing and interaction, largescale collaboration, and extensive mutual care. Naturally, the advanced forms of SemCom techniques discussed in this article (for e.g., human-machine symbiosis and dialogues, human sensing and care, learning, inference, etc.) will beneﬁt from almost-limitless connectivity and at the same time bring to it unprecedented end-to-end performance. 2. Comprehensive AI: AI has been established as a tool for solving problems originally intractable due to either prohibitive complexity or the lack of models and algorithms. 6G are being designed to be comprehensive AI systems where AI will be extensively used for optimizing the overall system performance and network operations [6,223]. At the physical layer, AI provides a data-driven approach for optimizing modulation and channel coding. At the system level, AI models can automate the collaboration between devices and base stations. It is even possible to apply large-scale AI to optimize the end-to-end performance of a network by enabling, for example, network self-recovering and self-organization. An AI comprehensive system, which comprises a large number of wirelessly connected nodes/entities, intertwines machine learning, inference, and SemCom. For efﬁcient implementation of such systems, it is essential to have the availability of a rich library of advanced SemCom techniques from which highly efﬁcient effectiveness coding and transmission techniques can be retrieved and used to support any of a wide-range of speciﬁc optimization tasks and network/system conﬁgurations with heterogeneous models and complexity. On the other hand, leveraging the omnipresence of AI, more complex and intelligent SemCom operations can be realized to improve semantic and effectiveness encoding, thereby deepening the level of H2H and H2M conversations, and narrowing the quality gap between machine and human assistance and care. 3. Integrated Communication, Sensing, Control, and Computing: The realization the 6G applications (such as immersive XR and mobile holograms mentioned earlier) requires resolving the conﬂict between the required extensive computation capabilities and their reliance on many specialized low-cost, low-power edge devices. One mainstream approach is to jointly design communication, sensing, control, and computing so as to improve the overall system performance under the devices’ constraints. Another relevant approach is to split computing intensive tasks and ofﬂoad parts from devices to edge servers, which provide an edge computing platform, for execution (which is aligned with the SplitNet approach discussed in this article). These approaches reﬂect the main theme of the 6G innovation, namely the tight integration of different aspects of data processing and transportation. The required deep application and semantic awareness by future wireless techniques will likely place SemCom at the central stage of 6G development. There is no doubt that SemCom will continue its growth, potentially becoming a primary area for technology innovation and breakthroughs in the 6G era. Coupling advanced SemCom and 6G technologies paves the way towards the disappearance of the boundary between the physical and virtual worlds.