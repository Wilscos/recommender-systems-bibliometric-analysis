Clinical decision support tools rooted in machine learning and optimization can provide signiﬁcant value to healthcare providers, including through better management of intensive care units. In particular, it is important that the patient discharge task addresses the nuanced trade-oﬀ between decreasing a patient’s length of stay (and associated hospitalization costs) and the risk of readmission or even death following the discharge decision. This work introduces an end-to-end general framework for capturing this trade-oﬀ to recommend optimal discharge timing decisions given a patient’s electronic health records. A data-driven approach is used to derive a parsimonious, discrete state space representation that captures a patient’s physiological condition. Based on this model and a given cost function, an inﬁnitehorizon discounted Markov decision process is formulated and solved numerically to compute an optimal discharge policy, whose value is assessed using oﬀ-policy evaluation strategies. Extensive numerical experiments are performed to validate the proposed framework using real-life intensive care unit patient data. Keywords: Healthcare, Intensive care unit, Markov Decision Process, Policy learning, Machine learning 1. Introduction stantial challenge in intensive care units (ICU). Advanced patient needs, coupled with the greater demand for staﬀ and resources as well as limited capacity, elevate the costs of healthcare delivery in ICUs to levels much greater than those in generic medical-surgical hospital wards (Badawi and Breslow, 2012; Halpern and Pastores, 2010). These factors intuitively The demand for accurate recommendation systems for discharging patients poses a submotivate the discharge of patients from ICUs as soon as their health status no longer demands such extensive resources (Gordon et al., 2018). Nonetheless, patients who are readmitted after being prematurely discharged from ICUs, or whose health status declines rapidly after discharge, impose an even greater burden on hospitals and have disproportionately high mortality rates (Badawi and Breslow, 2012; Mcneill and Khairat, 2020). A recent review of hospital mortality studies reported that readmitted patients can have readmission mortality rates as high as 40 percent compared to non-readmitted mortality rates of 3.6 to 8.4 percent (Mcneill and Khairat, 2020). reduce rates of premature or improper discharge, as they can be penalized through the Hospital Readmissions Reduction Program (HRRP) if they fail to meet federal standards (Wasfy et al., 2017). HRRP penalizes the majority of American hospitals for substandard readmission rates, up to a maximum penalty rate of one percent of the hospital’s Medicare base payments (James, 2013). Ensuring eﬃcient patient discharge with minimal probability of ICU readmission is therefore an important priority for critical care providers, which incentivizes the creation and deployment of decision support tools that can help clinicians optimize the timing of patient discharge (Levin et al., 2021). This priority has become even more pressing with the ongoing COVID-19 public health crisis, which has imposed a dramatically higher burden on critical care worldwide (Arabi et al., 2021). The development of well-designed machine learning and optimization schemes could meet this need by interpreting ICU patients’ electronic health records (EHR) data in real-time, assessing their probability of readmission, and providing clinicians with concise assessments to assist them with these diﬃcult, high-stakes decisions. Algorithms and decision support tools may also encourage clinicians to discharge patients outside of normal rounding hours, allowing for greater ﬂuidity in patient turnover (McWilliams et al., 2019). of the challenges in developing algorithms that meet the complex demands of this clinical problem. ICU patient populations are highly heterogeneous with respect to disease state and comorbidity (Forte et al., 2021), and the relatively low proportions of ICU patients who are readmission cases may yield imbalance in data sets (Loreto et al., 2020). The death of patients after discharge from ICUs, either at home or at other healthcare facilities outside the purview of data collection, is a competing risk in algorithm development that may often be driven by the same factors that would indicate the need for readmission (Loreto et al., 2020). The increased mortality rate within ICUs relative to other hospital wards also generates a higher attrition rate for data collection (Wilcox and Ely, 2019; McWilliams et al., 2019). Despite these setbacks, tools for classifying patients by their probability of readmission continue to be developed with steadily improving performance (McWilliams et al., 2019; Mcneill and Khairat, 2020; Balshi et al., 2020; Czajka et al., 2020; Loreto et al., 2020; Levin et al., 2021). patients’ physiological conditions, inherently reﬂecting mortality and readmission risks. This health state representation is then used to formulate an inﬁnite horizon Markov decision Furthermore, hospitals in the United States have an additional ﬁnancial motivation to The ﬁelds of operations research (OR) and artiﬁcial intelligence (AI) are well informed In this work we present an unsupervised machine learning approach for representing process in order to numerically compute an optimal discharge policy for a given cost function. The proposed policy is validated using recently developed oﬀ-policy evaluation algorithms on a large scale real-life ICU patient data set. We discuss the resulting policy’s implication to hospital management, as well as its interpretability relative to the clinicians’ decisions. 2. Literature overview sion within 48 hours (Desautels et al., 2017), and 7, 14, or 30 days (Maali et al., 2018; Jaotombo et al., 2020; Lo et al., 2021) or within the same hospitalization (Rojas et al., 2018) have been published. A recent review of the application of machine learning in predicting hospital readmission identiﬁed 43 relevant studies employing a variety of modeling methods (Huang et al., 2021). Additional studies have focused on predicting multiple outcomes simultaneously including both post-discharge mortality and readmission (Badawi and Breslow, 2012; Campbell et al., 2008; Ouanes et al., 2012; Thoral et al., 2021), as well as length of stay and readmission (Hilton et al., 2020). potential exclusion of patients due to missing data, varying feature consistency and availability across electronic medical record systems, and the temporal availability of data codes for classifying patients Temple et al. (2015). Because of these reasons models developed to predict patient discharge or time to discharge have been studied to a lesser extent. McWilliams et al. (2019) proposed random forest and logistic regression classiﬁers to identify dischargeready patients based on a variety of demographic and EHR features. The developed models signiﬁcantly outperformed a much more conservative nurse-led discharge criteria (Knight, 2003) used as benchmark, although the relatively high rate of false-positives indicated the necessity of further development before clinical deployment. Temple et al. (2015) developed a random forest model to identify neonatal ICU patients with high discharge likelihood within a time window of two to ten days. A random forest regression model was developed by Cuadrado et al. (2019) to predict the discharge time, i.e., the length of stay or time to discharge, of ICU patients based on 49 clinically relevant variables and values from 15 diﬀerent assessment scores. Several artiﬁcial neural network methods have been used to develop prediction algorithms for length of stay of ICU patients (Gholipour et al., 2015), and speciﬁcally for cardiac patients (Rowan et al., 2007; LaFaro et al., 2016). Safavi et al. (2019) developed a feedforward neural network model to predict daily inpatient surgical care discharges within a 24 hour time window. Further, the framework proposed by Safavi et al. (2019) was used to quantitatively identify clinical milestones to recovery and barriers to discharge that, respectively, indicate progression or postponement towards discharge. et al., 2019), identifying patients that are suitable for ICU discharge is a complex task due to the myriad of factors that can drive such recommendations (e.g., patient demands, hospital management culture, procedures favored by a given clinician, resource availability, proﬁt motivations, etc.). In discharge prediction models, determining the risk level or threshold Several machine learning methods to predict unplanned hospital or ICU ward readmis- Machine learning models leveraging EHR data suﬀer from several limitations including: As noted in several studies (Rubenfeld and Rhodes, 2014; Stelfox et al., 2015; McWilliams above which a patient can be safely discharged is challenging and involves balancing truepositives and false-positive rates, depending on the needs of the clinical team. For example, clinicians may be interested in a lower threshold to identify all potential discharge patients including those that may not be ready yet for discharge, or hospital bed managers that may prefer higher speciﬁcity so they can more accurately balance beds for incoming patient demand (Safavi et al., 2019). Limitations in the aforementioned prediction algorithms, such as restrictive feature sets and high false positive rates (McWilliams et al., 2019), as well as missing hospital-level factors such as ICU bed availability and hospital census data (Rojas et al., 2018) have fostered the development of prescriptive (i.e., recommending a speciﬁc course of action as opposed to predicting a likely outcome) artiﬁcial intelligence frameworks. tion policies, rather than to train models to predict either patient time to discharge, or readmission and out-of-hospital mortality instances. The former approach optimizes over custom objective functions considering patient health dynamics and reﬂecting clinician and hospital management preferences to recommend a speciﬁc course of action, and provide more easily translatable and clinically usable health-based decision rules. Several related modelling schemes have been proposed for constructing optimal policies for sequential decision-making to address various types of medical problems (Schaefer et al., 2005; Bennett and Hauser, 2013; Komorowski et al., 2018). These studies introduce frameworks typically based on diﬀerent variants of Markov decision process (MDP) models (Bertsekas, 2012; Puterman, 2014) that can eﬀectively capture the dynamic nature of patients’ health condition and provide optimal clinical decisions within the limits of the structural assumptions invoked in deﬁning the system states, actions, transitions, and costs. These often called “artiﬁcial intelligence clinicians” (AIC) (Komorowski et al., 2018) simulate clinical decision-making through consideration of multiple dynamic factors, including patient health conditions and demographics, as well as hospital system-related characteristics and costs. For example, Bennett and Hauser (2013) developed a general purpose (non-disease speciﬁc) computational environment to sequentially simulate multiple decision paths for replicating and even improving clinician decision-making in real-time. The framework was evaluated in a chronic care setting, in which the “clinical utility” (capturing the cost-eﬀectiveness of treatments reﬂected by outcomes and costs) was optimized improving patient outcomes by 30-35% at a much lower cost of care. A plethora of frameworks have been proposed for constructing treatment policies for diﬀerent speciﬁc chronic medical conditions including HIV (Shechter et al., 2008), diabetes (Denton et al., 2009), anemia (Gaweda et al., 2005), and breast cancer (Ayvaci et al., 2012), among several others. Recently, Komorowski et al. (2018) proposed an AIC to compute real-time optimal sepsis treatment strategies consisting of intravenous ﬂuids and vasopressor dosages to maximize patients’ 90-day expected survival. Komorowski et al. (2018) demonstrated that the AIC consistently outperformed the clinician policy even on external validation data corresponding to diﬀerent hospitals, and conﬁrmed that the AIC decisions were also highly interpretable. Comprehensive reviews of successful applications of MDPs and reinforcement learning for medical treatment policies can be found in Schaefer et al. (2005); Steimle and Denton (2017); Yu et al. (2019). The focus in this work is to develop patient-speciﬁc data-driven discharge recommendaliterature. Kreke et al. (2008) proposed a ﬁnite-time MDP framework that modelled when to discharge patients with pneumonia-related sepsis to maximize their expected survival rate. Through structural and computational analyses, Kreke et al. (2008) showed that for speciﬁc problem instances the optimal discharge strategy follows a non-stationary control-limit-type policy, implying that the level of illness at which it is optimal to discharge a patient changes over the course of the hospital stay. The Sequential Organ Failure Assessment (SOFA) Score is used to represent the patient health states, which is recognised to be a simplistic metric that may fail to capture the complex set of clinical features available to represent the patient’s physiological condition. Chan et al. (2012) developed a demand-driven index-based greedy policy that discharges an ICU patient with the lowest “criticality index” when a new patient arriving in the ICU must be accommodated. The proposed state-space reﬂected the total number of ICU patients at a given time period, where each patients was labeled from a ﬁnite set of ailments/health conditions. The resulting greedy policy balanced patient healthrelated costs (such as physiological deterioration leading to readmission or post-discharge mortality) with system related costs (relating to increased length of stay and capacitylimited ICU resources), and was theoretically proofed and empirically demonstrated to be near-optimal in settings of low ICU utilization. Numerical experiments demonstrated that the resulting policy reduced the patient readmission load by nearly 30% respective to selected benchmark policies. Ouyang et al. (2020) considered a related ICU bed allocation problem during periods of high patient demand. The objective was to minimize the long-run average expected mortality rate, and the model considered two possible health states: critical and highly critical condition. Seven diﬀerent policies were evaluated, and numerical simulations showed that the proposed framework consistently reduced patient mortality risk. Shi et al. (2021) developed a large-scale MDP to optimize ICU patient ﬂow management, patient quality of care, and patient outcome (readmission risk). The proposed model featured a personalized readmission prediction model to dynamically determine which patients to discharge on each day based on current ICU occupancy. Under the assumption that costs related to ICU congestion and discharge (dependent on the expected number of readmissions for a given a number of discharges) have quadratic structure, Shi et al. (2021) developed an eﬃcient linear decision rule approximation for the optimal policy which was empirically demonstrated to decrease readmission risk from 32% to 28% by increasing the average length of stay from 3.33 days to 3.55 days. modeling patient health states from high dimensional time series EHR data, computing optimal discharge policies based on diﬀerent cost trade-oﬀs, and evaluating their performance and ICU management implications in real ICU patient health trajectories. The main contributions of the present work are: 1. A ﬂexible, data-driven prescriptive framework for making discharge decisions such 2. A clustering-based approach for identifying discrete patient health states from high- Similar frameworks related to optimal patient discharging have been less studied in the To our knowledge, our work is the ﬁrst to provide an end-to-end framework that includes that a given cost function (reﬂecting the trade-oﬀ between hospitalization expenses, readmission penalties, and out-of-hospital mortality rate) is minimized. 3. Numerical validation experiments performed using a large ICU database (MIMIC-III, 4. Oﬀ-policy evaluation algorithms and results to derive statistically signiﬁcant perfor- 5. The resulting policy can eﬀectively lower hospital readmissions ∼2%, while at the same Mart for Intensive Care (MIMIC-III, version 1.3) data set (Johnson et al., 2016). MIMICIII consists of EHR data from the ICU visits of over 400,000 patients, collected from a large, tertiary care hospital in Boston, Massachusetts, from 2001 to 2012. Each encounter included vital signs, medication information, laboratory measurements, and diagnostic codes, among other data. Because the MIMIC-III data are de-identiﬁed, this study qualiﬁed as a nonhuman subject study according to the deﬁnition of human subjects research put forth in 45 CFR 46, and was exempt from Institutional Review Board approval. consisted of measurements of clinical variables, including demographic information, vital signs, and laboratory tests (Tables S1 and S2). The ﬁrst step of the inclusion procedure removed encounters with no measurement of more than half of the vital signs and laboratory measurements. clinical variable within each 12-hour period were aggregated either by averaging the measurements (for most vital signs and laboratory tests) or by adding them (e.g., for urine output, drug and ﬂuid administration). Missing measurements were imputed by carrying forward the last observation. If no aggregated measurement was available in a period, then the latest available observation of a patient’s health state (prior to that time period) was applied. If values were missing for medications or treatments, it was assumed that none were administered or performed and they were imputed with zeros. Outliers were replaced by capping the aggregated feature measurements to their associated 99.9 and 0.1 percentiles. If any missing values remained (patients not having an entire measurement available, or the ﬁrst observation of a given measurement time series) iterative imputation was performed based on Bayesian Ridge regression as the default estimator (Pedregosa et al., 2011). dimensional continuous EHR data, that inherently reﬂects the relationship between physiological conditions and outcomes such as mortality and readmission. Johnson et al. (2016)) collected from over 400,000 adult patients in the United States. mance guarantees of the proposed discharge policy relative to selected policy benchmarks. time reducing the average length of stay by ∼1 day relative to the clinician policy in a hold-out testing set. We developed and validated the proposed framework using the Medical Information Encounters were subjected to the inclusion procedure depicted in Figure S1. Encounters Measurements were binned into 12-hour periods. Speciﬁcally, the measurements of each 3.2. Markov decision process framework on the information presently available regarding their condition (Table S2). The objective was to minimize a given cost function comprising two components: We considered the discharge of a patient to be unsuccessful if the patient was readmitted to the ICU within T days of discharge, or if the patient died within T days of discharge. intensive care to improve the odds of a successful discharge at the expense of higher operating costs to the hospital, higher medical bills to the patient, and higher ICU bed occupancy. The latter may be undesirable, especially in the context of the COVID-19 pandemic. The relative weights of each component of the cost function are to be determined on a caseby-case basis, in such a way that the resulting discharge policy reﬂects the hospital’s ICU management strategy. We formalized the problem using the notation of Bertsekas (2012). 3.2.1. Time representation task was formulated as an inﬁnite-horizon discounted MDP, that captured the transitions of patients through discrete health “states” which represented the condition of the patient in consecutive 12-hour time periods indexed by t ∈ {1, 2, . . . }. While only the T -day time window following discharge was considered, a patient could in principle be kept in the ICU indeﬁnitely if their health condition was not seen to improve or if a high weight was placed on the readmission component of the cost function. This property will be elaborated in Section 6. 1, 2, . . . , H represented the patient’s physiological condition during their ICU stay, and where the (absorbing) states SD and U D corresponded to successful and unsuccessful outcomes following the decision to discharge a patient. Denote the condition of a given patient in the t {1, 2, . . . , H} were learned from data, and deﬁned in terms of the information in Table S2. We remark that, while continuous state-space representations can retain more information about a patient (Raghu et al., 2017), their use can lead to computational tractability issues, which motivates the use of discrete representations (Kreke et al., 2008; Komorowski et al., 2018). one more time period and D, the action to discharge them from it. In fact, the action u We considered the problem of whether or not to discharge a patient from the ICU based • the daily cost of hospitalization and implied treatments; and • the T -day expected rate of unsuccessful discharges, where typical values of T include 30, 60, and 90 days (Kreke et al., 2008). The cost function was intended to capture the trade-oﬀ between keeping a patient in According to the model, discharge decisions were made every 12 hours. The discharge The MDP state space, S, was the set of health states {1, 2, . . . , H, SD, U D}, where states 12-hour time period of their stay by x∈ S. In Section 4, we detail how states The action space A consisted of K, the action to keep a patient in the ICU for at least taken at the end of time period t depended on the health state x then u Assumption 1. This framework does not consider any actions/decisions with respect to medical treatments, laboratory measurements or other procedures received by the patients during the ICU stay. When estimating transition probabilities P (˜x|x, K) from data, an implicit policy is learned regarding the procedures used to treat the patient’s condition when the health state is x. This treatment policy is tacitly followed every time that the proposed discharge policy recommends keeping the patient in care. 3.2.3. Transition probabilities time period, given that the current state is x and action u is taken. These probabilities were estimated using data corresponding to health transition observed for a large number of diﬀerent patients during their stay in the ICU. By deﬁnition, if ˜x ∈ {SD, UD}, then P (˜x|x, u) = 1 if and only if x = ˜x and u = ∅. Note also that a patient could not transition to SD or U D unless discharged, i.e. P (SD|x, K) = P (U D|x, K) = 0. 3.2.4. Costs cost of taking action u in state x by g(x, u). If x ∈ {1, 2, . . . , H}, then g(x, K) was the cost of care for one time period. The cost g(U D, ∅), or simply g(U D), corresponded to a penalty for an unsuccessful discharge. A reward in the form of g(SD) < 0 reﬂected a favorable discharge outcome. As the choice of cost function g will vary across diﬀerent hospitals and according to ICU bed utilization preferences, the numerical results presented below explored the eﬀects of diﬀerent cost functions on the behavior of the optimal policy. 3.2.5. Inﬁnite horizon discounted MDP objective of solving an MDP is to ﬁnd a policy, or a mapping from a patient’s health state to a discharge decision for all decision epochs that minimizes a measure of longterm, expected, discounted costs for a patient’s stay in the ICU. While discounting in the context of this problem had no practical signiﬁcance, time-discounted MDPs have been studied extensively and beneﬁt from favorable convergence properties and multiple solution algorithms (Puterman, 2014). policy π = {µ ∈ A but, if x∈ {SD, U D}, u= ∅ (no further action could be taken). Let P (˜x|x, u) denote the probability that a certain patient’s health state is ˜x in the next We formulated the MDP problem in terms of cost minimization. Denote the immediate Together, the states, actions, transition probabilities, and costs deﬁne an MDP. The For an initial state xand discount factor α ∈ (0, 1), we are interested in ﬁnding the given by where Π is the set of all admissible policies. A policy is said to be stationary if it has the form of π = {µ, µ, . . . }, in which case π is simply referred to as µ. The reader is referred to Bertsekas (2012) and Puterman (2014) for a comprehensive discussion on MDPs. 4.1. Clustering electronic health records data a health state {1, 2, . . . , H}, on the basis of the information in Table S2 available during that period. This involved (i) determining a number H of health states to deﬁne and then (ii) deﬁning each health state in terms of the clinical variables. Concerning (i), if too few of health states are deﬁned, then they will reﬂect the patient’s condition poorly (Alagoz et al., 2010). However, if too many health states are deﬁned, then the subsequent policy optimization step will not be computationally tractable, and there will not be enough data to accurately estimate the transition probabilities between them. Concerning (ii), unsupervised machine learning—speciﬁcally, clustering algorithms—have been used to identify groups of patients with similar medical characteristics (Forte et al., 2021; El-Darzi et al., 2009; Alashwal et al., 2019; Komorowski et al., 2018). sponds to the number of possible states, H. In brief, the algorithm seeks to partition the collection of data from each 12-hour time period in the training data into k clusters, such that each example belongs to the cluster with the nearest centroid, which were found by minimizing the intra-cluster distance. Formally, the objective was to solve where k · k denotes the Euclidean distance and y denotes the examples in the training set. The constituent sets of Y = {Y points of Y algorithm, are used instead to iteratively ﬁnd the local optimum of (3) and corresponding cluster centroids. algorithm. The number of possible health states H, equivalent to the number of clusters k, was chosen to be 400 according to the elbow method (Syakur et al., 2018) (Figure S2). This number of clusters was large enough to ensure separability between patients based on their distinct clinical features, but small enough such that there was a suﬃcient number of transitions observed in the training set in order to estimate the transition probabilities empirically. The identiﬁed clusters are shown in Figure 1, where the axes represent the We assigned to each 12-hour time period (preceding discharge) of each patient’s stay We employed the k-means clustering algorithm to identify health states, where k corre- The training data were scaled using the min-max scaler prior to training the clustering three principal components with the highest explained variance. The marker size in the scatter plots reﬂects the number of examples in the entire training data set assigned to each cluster, and the color scale reﬂects the average mortality and average 30-day readmission of the assigned examples to each cluster. alized in Figure 1A, despite the fact that mortality information was not provided to the clustering algorithm, which is unsupervised by deﬁnition. This observation supports the validity of the cluster assignment as a reﬂection of the severity of the patient’s condition. We observed an analogous gradient in the average 30-day readmission rate of the learned health states (Figure 1B). The high mortality health states corresponded the states with the lowest 30-day readmission rates because the patients assigned to these states either died in the hospital, and therefore never had the chance to be readmitted, or were in such critical condition that their condition must have improved before being discharged. Figure 1B indicates that the highest readmission rates typically resulted from patients that were in moderate mortality clusters, perhaps after their condition improved but before they had fully recuperated, which may have resulted in readmission. An example time series 12-hour periods of EHR data and associated health states are shown in Figure 2. The bold, vertical line indicates the time period at which the optimal policy recommended discharge (details on how this policy is computed are presented shortly), and the grey-shaded region corresponds to the continuation of the stay under the clinician policy. We observed a gradient of average in-hospital mortality rate for the health states visu- 4.2. Empirical estimation and validation of transition probabilities tween health states. For example, the transition probability P (˜x|x, K) was estimated by counting all observations in the training set in which a transition from state x to state ˜x occurred, and dividing the count by the total number of observations of state x for which the patient was not discharged. To hedge against discharging patients with very small readmission rates but high mortality rates, P (U D|x, D) was estimated by also taking into consideration instances of in-hospital mortality. That is, P (U D|x, D) was estimated by counting three events: (1) the number of 30-day readmissions when patients were discharged with health state x, (2) the number of 30-day out-of-hospital mortality instances when patients were discharged with health state x, and (3) the number of in-hospital deaths for patients with last observed health state x. The sum of these three observations was divided by the total number of discharges, plus the number of in-hospital deaths observed for patients with health state x. Similarly, P (SD|x, D) was estimated as 1 − P (U D|x, D), as UD and SD are the only two possible outcomes when a patient is discharged. servations in the hold-out testing data set. Given the number of transitions contained in the test set, we used the estimates of P (˜x|x, K), P (SD|x, D) and P (U D|x, D) to compute the expected number of observations of all possible transitions (e.g., from state x to state ˜x if the patient was kept, or from x to SD or UD if they were discharged). We compared this expected number against the number of transitions observed in the testing set, to assess the goodness of ﬁt of the empirical transition matrices. The validation results for all three transition probability matrices are shown in Figure 3. The estimated transition probabilities generalized well to the testing set as indicated by the high coeﬃcient of determination computed for each transition matrix. Table S3 lists the median R obtained from repeating the clustering and validation process with 50 random train-test splits of the entire data set. After determining the 400 health states, we estimated the transition probabilities be- We evaluated the quality of the estimated transition probability matrices using the ob- We further validated the estimated transition probability matrix P (˜x|x, K) by simulating the ﬁrst exit time from each state, as in Komorowski et al. (2018). For each initial health state x, we conducted 500 random simulations of the dynamics, to observe the length of time spent at health state x before transitioning to a diﬀerent health state ˜x. The results, shown in Figure S3, conﬁrmed that this time is roughly exponentially distributed for all states. An exponential ﬁt of the times for each state, resulted in a median R 0.988 and an interquartile range of (0.996-0.999). 5.1. Policy characterization the parameters from the training data, and validated the estimates using a hold-out test set. We turn our focus to identifying the policy which minimizes (1). First, we state the assumptions and properties that are critical for the numerical algorithms we used to solve the MDP. The reader is referred to (Puterman, 2014; Bertsekas, 2012) for a comprehensive analysis of these properties, as well as the ensuing computational aspects. Assumption 2 ((Bertsekas, 2012, Assumption D)). The costs per stage g(x, u) are bounded, that is |g(u, x)| < M for all (x, u) ∈ S × A where M is some scalar, and the discounting factor satisﬁes 0 < α < 1. policy and the convergence of numerical methods (Bertsekas, 2012). It holds if the rewards and penalties for successful and unsuccessful discharges respectively are ﬁnite, because S and A are ﬁnite sets, and because the costs associated with hospitalization are bounded. The assumption that α ∈ (0, 1) ensures that the series in (1) converges. Proposition 1 ((Bertsekas, 2012, Proposition 1.2.2)). The optimal cost function J Bellman’s optimality equations given by J In the preceding sections, we deﬁned the MDP components {S, A, P, g, α}, estimated Assumption 2 is used to derive necessary and suﬃcient conditions for the optimality of a Furthermore, J deﬁned in (4). Bellman’s optimality equations for health state x ∈ {1, . . . , H} is given by Bellman’s equations associated to the post-discharge absorbing states x ∈ {SD, U D} are given by mapping T Based on these results, we provide the conditions for which the discharge policy’s optimality and existence are guaranteed, which is critical for understanding the numerical solution schemes discussed subsequently in Section 5.2. Proposition 2 ((Bertsekas, 2012, Proposition 1.2.3)). A stationary policy µ is optimal if and only if µ(x) attains the minimum in Bellman’s equations J T J Theorem 1 ((Puterman, 2014, Theorem 6.2.10)). Assume S is discrete and A is ﬁnite for each x ∈ S, then there exists an optimal deterministic stationary policy that solves the optimality equation J 2 gives a way to identify it in terms of Bellman’s equations. We proceed to discuss the algorithm we used to compute the optimal policy. 5.2. Policy computation cost problem (1). We chose it because the ﬁniteness of the state and action spaces, and the satisfaction of Assumption 2 guaranteed that policy iteration would terminate in a ﬁnite number of steps (Bertsekas, 2012). Because the number of states was not particularly large, we did not expect computational complexity to be an obstacle, and thus preferred it over other approaches, like value iteration. The premise of the policy iteration algorithm is to sequentially compute stationary policies using Bellman’s equations, such that the cost of each policy is lower relative to the preceding one. The steps involved in policy iteration are outlined in Algorithm 1. Proposition 1 establishes that the optimal cost function is the ﬁxed point of mapping T For every stationary policy µ the associated cost function satisﬁes J= TJ, where the Theorem 1 establishes the existence of an optimal discharge policy, while Proposition We used policy iteration (Bertsekas, 2012) to ﬁnd a numerical solution to the discounted Algorithm 1: Policy iteration (Bertsekas, 2012) value function J the transition probabilities and the cost per stage evaluated for the current policy, and I denotes the identity matrix of appropriate dimensions. We note that policy evaluation is susceptible to the curse of dimensionality, as the problem size increases with the number of state variables, and other numerical algorithms and eﬀective approximations (e.g., (De Farias and Van Roy, 2003)) might be preferable for MDPs with larger state spaces. Once the current value function has been computed, policy improvement is performed by applying the dynamic programming mapping T deﬁned in (4) on the value function J to compute the subsequent, lower-cost policy. The algorithm terminates once the value function no longer improves, which implies convergence to a ﬁxed point and to the optimal policy (Proposition 2). 5.3. Policy cost estimation implicitly represented in the training and testing data to respectively learn and estimate the value of a diﬀerent policy (µ Because the execution of a bad policy can be costly and even dangerous in practical settings, particularly pertaining to ICUs in which erroneous discharge decisions can be fatal, it is important to establish the performance of µ trajectories D = {H {(x Approaches for oﬀ-policy evaluation are an active topic of research in the context of related reinforcement learning frameworks (Hanna et al., 2017; Thomas et al., 2015; Festor et al., 2021). It should be noted that the factors driving µ chosen to derive µ the two policies. Algorithm 1) to estimate the value (1) of µ that follow µ to a random train-test split of the data and resulting clustering solution), the cost of the Inputs: MDP elements {S, A, P, g, α}, initial policy guess µ for k ∈ {0, 1, 2, . . . } do Policy evaluation: compute Jby solving (I − αP)J= g Policy improvement: compute µsuch that TJ= T J if J= T Jthen return µ end end The policy evaluation step involves solving a system of linear equations to compute the The policy learning framework presented in this work uses a clinician policy (µ) , u), (x, u), . . . , (x, u)} generated by following the clinician’s policy H ∼ µ. We employed the model-based bootstrapping algorithm proposed in (Hanna et al., 2017, policy is estimated by following the test trajectories D reﬂecting µ tween the policies is observed: either µ discharged the patient but µ oﬀ-policy evaluation (Hanna et al., 2017) is performed by simulating future trajectories following µ probabilities estimated using the training data—to estimate the expected policy costs. If the empirical transition probabilities generalize well to unseen data sets, then this approach reduces the variance of the estimate, at the expense of introducing bias resulting from e.g. data sparsity. The average cost over all trajectories in D of µ trajectories in D. strapping in combination with the aforementioned oﬀ-policy model-based estimation approach. The 95% conﬁdence upper bound (95% UB) of the cost of µ proposed in (Hanna et al., 2017), by using bootstrapping with replacement to generate B trajectory sets { and where U(·) is the uniform distribution. Similarly, the 95% conﬁdence lower bound (95% LB) corresponding to the implicit clinician policy µ strapped samples. The upper and lower bounds for each policy served to ensure that the worst-case realization of µ a number of trained models. The UB and LB were obtained by computing the 97.5 and 2.5 percentiles (denoted by Q oﬀ-policy evaluation procedure was previously demonstrated for clinical decision support tools in the context of sepsis treatment (Komorowski et al., 2018). Algorithm 2 presents this evaluation procedure in detail, and numerical results pertaining to oﬀ-policy evaluation are discussed below. Algorithm 2: Model-based oﬀ-policy evaluation performed for all policies µ all i ∈ {1, 2, . . . , 50} (Hanna et al., 2017) . Note that the costs associated with µare estimated directly by following the To obtain a distribution for the cost associated with a policy µ, we performed boot- Inputs: Evaluation policy µ, set of test trajectories D, required number of bootstrap estimates B, conﬁdence level δ ∈ [0, 1] Estimate transition matricesˆPfrom D for j ∈ {1, 2, . . . , B} do ˜D← {H, H, . . . , H} where H∼ U(D) for l ∈ [1, n] do Compute g(H) for µby simulating model {S, A,ˆP, g, α} end return Q({ˆJ|j ∈ {1, 2, . . . , B}}) 5.4. Random discharge policies for benchmarking performances against policies that make discharge decisions at random. The ﬁrst random policy was In words, under µ ﬂipping a fair coin at each time period. This random policy was used to compare the costs relative to µ and out-of-hospital mortality instances (unsuccessful discharges) by keeping and treating patients in the ICU longer, we wanted to assess how eﬀectively µ to discharge and which ones to keep in care. To this end, we considered a second, pseudorandom policy denoted by µ that implicitly follows µ of stay randomly with probability γ (i.e., by ﬂipping a biased coin). To compare against observed in the test set D state when making the discharge decision. A summary of the four policies considered in this work are displayed in Table 1. 6. Numerical simulations and results policies were evaluated against the ones corresponding to the clinician policy observed in the hold-out test set, as well as to the previously described random policies. The test set trajectories exclusively consisted of encounters in which the clinician was observed to discharge a patient, excluding in-hospital death instances. For the subsequent numerical studies, 50 diﬀerent clustering solutions were computed using diﬀerent random train-test splits of the entire data set. We compare the policies on the basis of their resulting expected discounted costs in Section 6.1, and evaluate their performances in terms of the ICU management outcomes of interest (e.g., fraction of unsuccessful discharges and average patient length of stay) in Section 6.2. We discuss the interpretability of the proposed policy in relation to the clinician policy in Section 6.3. In addition to comparing µand µagainst one another other, we evaluated their Since the proposed policy µwas intended to reduce the number of ICU readmissions , γ was set to the fraction of patients kept in care by µrelative to all the patients discharged the same number of patients as µ, but without considering their health µOptimal policy computed via Algorithm 1 for a given cost function µClinician policy implicit in the training and testing data µPurely random policy for arbitrary discharges at any time µPseudo-random policy with same net discharges as µ To assess the eﬀectiveness of the proposed data-driven policy, the computed discharge 6.1. Oﬀ-policy cost evaluation for patients with high 30-day out-of-hospital mortality and readmission rates, as well as in low costs for patients that have a high rate of successful discharge (Figure S4)—it is important to establish statistical signiﬁcance on the performance diﬀerence between µ and µ policy evaluation procedure discussed in Section 5.3 are displayed in Figures 4A and 4B. The policy cost estimates for µ random simulations by sampling the transition matrices, and 2000 bootstrapped samples were used to estimate the associated cost distributions (and associated conﬁdence bounds) of µ largely inferior than the 95% LB on the costs of µ between the two policies grew with the number of models trained. The distribution of estimated costs for µ learned policies is, to some extent, robust to the the number of discrete health states or clusters used to represent a patient’s physiological condition. The oﬀ-policy evaluation results corresponding to policies computed using 350, 400, and 450 clusters are shown in Table S4. 6.2. Implications on unsuccessful discharges and length of stay icy iteration for a range of diﬀerent cost functions, which were determined by varying the penalty associated with unsuccessful discharges g(UD) while keeping all else constant (that For a ﬁxed cost function that is well calibrated—meaning that it results in high costs on the test set trajectories D. The results corresponding to the model-based oﬀand µ. Figure 4A shows that the 95% UB on the costs of µis consistently and Furthermore, we used oﬀ-policy evaluation to demonstrate that the performance of The policies associated with each of the 50 clustering solutions were computed via polis, g(x, K) = 1, g(x, D) = 0, g(SD) = 0, α = 0.95). Naturally, the proposed policy µ discharged at most as many ICU stays as were observed in each of the hold-out test sets. Nonetheless, depending on the cost function of choice, µ of the patients are kept in care until their health states are seen to improve (i.e., the patient transitions to a state having a lower probability of unsuccessful discharge), thus leading to a lower total number of discharges than the observations in the test set. To conﬁrm that the improvements stemming from µ discharged, the pseudo-random policy (µ in Figure 5. In the extreme case when g(U D) approaches zero, meaning there is no penalty associated with unsuccessful discharges, µ associated with hospitalization. Conversely, increasing g(UD) resulted in a greater fraction of patients kept in care for µ at the expense of a longer length of stay. Since the discharged encounters are sampled at random from the test set for µ on average with the clinician policy (the average and standard deviation of p-values for all instances of g(U D) were 0.67 and 0.28 respectively). On the other hand, for the optimal policy, the fraction of unsuccessful discharges consistently decreased relative to µ of being unsuccessfully discharged. The higher variance observed in the fraction of UD corresponding to large values of g(UD) for both µ sample of discharged patients used to compute the corresponding mean. that can be safely discharged at a much earlier stage in their ICU stay than µ values of g(UD), µ thus reducing the patients’ length of stay. This property of µ showing the resulting fraction of UD and the average length of stay for same range of values Results comparing µand µagainst µfor a range of g(U D) values are shown , indicating that the proposed framework eﬀectively identiﬁed patients at a high risk In addition to reducing the number of unsuccessful discharges, µcan identify patients of g(UD) used in Figure 5. For instances in which µ relative to µ compute the expected length of stay (which is naturally higher than that of µ corresponding results for µ of µ greater than or equal to the one observed for µ (p-value < 0.001) while also reducing the mean percentage of unsuccessful discharges by 2.00% (p-value < 0.001), relative to the mean values observed for µ increase of the mean patient length of stay of 2.4 days (p-value < 0.001) and a reduction of the mean percentage of unsuccessful discharges of 2.83% (p-value < 0.001). ization and unsuccessful discharges) are conﬂicting, since reducing the number of patients that are readmitted or deceased after discharge can only be accomplished by increasing their length of stay (an implied medical treatment) in the ICU. The parameter g(UD) can be used by hospital management and clinicians to address their preferences associated with the two cost factors, reﬂecting aspects such as hospital capacity and resource availability at a given period in time. Despite the conﬂicting objectives, these results show that µ upon the clinician policy with respect to the two metrics in the hold-out test sets. 6.3. Policy interpretability policies, classiﬁers were trained to predict discharge decisions associated with each policy based on the full-dimensional data (i.e., using the complete patient’s EHR without any clustering or dimensionality reduction). The binary classiﬁcation task at hand used the full set of clinical and demographic features observed at a point in time to predict whether a patient was the same as that of µ, and thus µhad an average expected length of stay obtained using g(UD) ∼ 2 reduced the mean expected length of stay by 0.88 days (corresponding to the cost function chosen for the results in Section 6.1) yielded an From Figure 6 it is clear that the two objectives (i.e., the costs associated with hospital- To better understand the diﬀerence in the factors that drive the clinician and proposed was discharged or not by a given policy. A gradient-boosted decision trees classiﬁer (maximum tree depth of 4, and number of estimators of 100) was used to predict the discharge outcome for each policy on the same training set used to perform clustering to generate the patient’s health state. The receiver operating characteristic (ROC) curve for the classiﬁers and corresponding area under the curve (AUC) for the two policies are shown in Figure S6, indicating that both policies can be predicted with high performance (median AUC of 0.937 and 0.920 for mu importances corresponding to mean decrease in impurity (MDI) or Gini importance for each of the classiﬁers are shown in Figure 7, which serve to shed light on to main factors being considered by each policy. corresponding to µ particular, several of the most important features used in predicting the clinician policy also have high importance in predicting the proposed optimal policy, which further supports its interpretability. Nonetheless, the feature importances corresponding to µ proposed policy employs a much larger set of relevant clinical features in recommending patient discharge than µ risk of being unsuccessfully discharged, thus leading to an overall improved policy relative to the clinician policy and the random policies used as benchmarks. Markov property may prevent the leveraging of a patient’s past clinical history when making The average feature importances shown in Figure 7 conﬁrm that the discharge decisions An inherent limitation of the proposed policy learning framework is that the MDP’s the discharge decision. In particular, we note that µ that show a brief, temporary improvement in their health condition but later exhibit a rapid deterioration and in-hospital death. These results are shown in Figure S5, by evaluating of discharge, future IHD and non-IHD instances are almost indistinguishable based on the respective mortality risks, it is evident that: (i) patients with IHD were observed to be in clusters with higher mortality rates than non-IHD patients prior to µ discharge, and (ii) the transitions following µ to clusters with much higher mortality rates. These observations suggest that µ employed in practical settings in combination with the clinician’s assessment of the patients clinical history, and with a “wait-and-see” period in which the patient is kept in care for a brief observation period. From a modeling perspective, it would be interesting to explore higher-order Markov models which consider explicit dependencies on prior system states. Additional features reﬂecting prior health measurements could also be incorporated in the state clustering procedure to implicitly include a patient’s clinical history. is time-homogeneous with respect to the transition probabilities and the costs per stage (i.e., these components do not vary in time). Certain practical settings where the transition probabilities might be time-varying depending on a patients length of stay would require formulating time-inhomogeneous MDPs. These models have been much less studied in the literature relative to their time-homogeneous counterparts, and their application to clinical decision-making problems is an interesting direction of future research. discharge decisions, the resulting policy is still a proof-of-concept and does not constitute a medical device that is ready for deployment. The proposed framework should be validated prospectively to a greater extent on observational data sets collected from multiple diﬀerent hospitals and in a variety of clinical settings. For clinical use, extensive clinical trials must be performed to evaluate this work in real-time, in closed-loop, and interactively with ICU patients Komorowski et al. (2018). Furthermore, it is clear that the implementation of clinical decision support tools is hindered by several factors including their compatibility and interoperability with current EHR systems, inconsistency and hospital-speciﬁc practices in recording and storing of patient data, and concerns of eventual over-reliance on models over medical expertise Sutton et al. (2020). Based on these limitations it is evident that on top of the additional validation studies required, the proposed tool must always be used in conjunction with physicians’ subjective judgement about patient discharge decisions and treatment strategies. 8. Conclusions the outcome of ICU patient discharges, as well as in improving the overall hospital management eﬃciency. In this paper, we presented an end-to-end framework for modeling patient on a hold-out test set with in-hospital death (IHD) instances. While, at the moment Moreover, based on the structural elements introduced in Section 3.2 the resulting MDP We note that despite the proposed framework’s superior performance relative to clinician The development of clinical decision support tools can play a signiﬁcant role in improving health states to subsequently derive data-driven policies for optimal patient discharge recommendation. The proposed policies balance competing objectives relating to hospitalization costs and penalties associated with unsuccessful discharges (i.e., T -day ICU readmission or out-of-hospital mortality). Extensive numerical experiments performed on real-life ICU patient EHR data demonstrated that the proposed policy reduced both the rate of readmission and the average patient length of stay for certain cost parameters. Furthermore, the oﬀ-policy evaluation strategies showed that the proposed policy consistently outperformed the clinician and random policy benchmarks. At the same time, the policy was shown to be clinically interpretable, an auspicious property for its deployment in practical settings. Acknowledgements manuscript. We acknowledge the insightful comments provided by Dr. Jana Hoﬀman in writing the All authors who have aﬃliations listed with Dascena (Houston, Texas, U.S.A) are em-