Keywords: shannon entropy, mutual information, conditional entropy, ﬁrst order statistics, Eﬀort-ToCompress, compression-complexity Shannon’s 1948 mas terpiece on a mathematical theory of communication [ Age which has seen unprecedented developments in the last few decades . Information theory ﬁnds important applications in artiﬁcial intelligence (AI), artiﬁcial neural networks (ANN), machine learning (ML), de e p learning (DL), causality testing and the list goes on and on. Cross entropy, a closely related cousing of Shannon entropy is used to deﬁne a loss function for logistic regression. Information gain ratio [ overcome the limitation of information gain by reducing bias towards multi-attributes (by accounting for number and size of branches while choosing an attribute). Tishby et al. [ for distributional clustering and dimension reduction, and recently suggested it as a theo retical foundation for deep learning. Causality testing is rife with rigrous application of information theory and use of infotheoretic quantities. For example, Transfer Entropy [ between coupled systems [ theoretic statis tics [6], information ﬂow [7] and several others (see [8] a nd re ferences therein) employ infotheo retic quantities for causal inference in bivariate/multi-variate systems. The starting point of a infotheoretic approach in all of the aforementioned areas is of c ourse the celebrated formula of Shannon’s entropy function H(·). For an independent and identically distributed (i.i.d) source Z, The language of information theory is favored in both causal reasoning and machine learning frameworks. But, is there a better language than this? In this study, we demonstrate th e pitfalls of infotheoretic estimation using ﬁrst order statistics on (short) seq uences for causal learning. We recommend the use of data compression based approaches for causality testing since these make very little assumptions on data as opposed to infotheoretic measures, and are more robust to ﬁ nite data length eﬀects. We conclude with a discussion on the challenges posed in mod eling the eﬀects of conditioning process X with another process Y in causal machine learning. Speciﬁcally, conditioning can increase confusion which can be diﬃcult to model by classical information theory. A conscious causal agent creates new choices, decisions and meaning which poses huge challenges for AI. with its time series Z where Z takes values from a discrete alphabet of size K distinct symbols with respective probabilties p p(assuming that none of these are zero). H(Z) is measured in bits. Deﬁnitions of joint entropy, conditional entropy, mutual information – all deﬁned for two o r more discrete ra ndom variables are naturally built upon H(·) (see [9], also Appendix A.1). The connection betwe en entropy and data compression is very tight - as proved by Sha nnon in the now famous source coding theorem [ by entropy. This also means that entropy can be calc ulated by using lossless data compress ion algorithms or by measures derived from these - such as Lempel-Ziv complexity [ been employed to estimate entropy rate of spike trains [ to compute the value of entropy given in Eq . 1 is still popular and widely used. The innocent looking Eq. abilities of the K outcomes of Z. a cleverly designed ex ample. The res t of the paper is organize d as follows – in section 2, the pitfalls with mutual information estimation is demonstrated with an exa mple, and how data compr e ssion based measures are immune to them. Section 3 deals with casual inference on the same example using Transfer Entropy – one of the most popular infotheory based causality testing algorithm. A discussion on the problems with information theory in trying to model the decision making process of a conscious causal agent is explored in section 4. We conclude with Shannon’s warning in section 5. Consider three hypothetical neuro ns X where A, B and C are 12-length ﬁring patterns shown in Fig. neurons can be in only one of three states: excitatory (+1), inhibitory (− 1) or inactive/OFF (0). At any instant of time, all three neurons are simultaneously made inactive/OFF by a higher order mechanism Z. Thus, the time stamps of 0s in the ﬁring pattern coincide for all the three neurons making them (nonlinearly) correlated. X are cyclic pe rmutations of each other. Ta ble 1: Z is switched ON. Linear correlation coeﬃcient ρ, Mutual Information (MI) and Mutual Eﬀort-ToCompress (METC) for the multivariate system {X In Table 1, we provide the pair-wise estimates of Pearson’s linear corr e lation coe ﬃcie nt (ρ), ﬁrst-order mutual information (MI, see Appe ndix A.1) and mutual Eﬀort-To-Compress (METC). The Eﬀort-To-Compress (ETC) Figure 1: Three disc rete-time ﬁring patterns A, B and C of duration 12 time units. The values of ﬁr ing are from the set {+1, −1, 0} corresponding to {excitatory, inhibitory, inactive/OFF}. All 3 take the value 0 (inactive/OFF) at the same time instants governed by a higher order mechanism Z. and METC are described in the Appendix (A.2). Notice that the values of ρ are zero for all pairs indicating that the ﬁring s are linearly uncorrelated. T he ﬁrst-order MI estimates are identical (= 0.9183 bits) contradicting the fact that X this. The data-compression based measure METC gives a value of 0.27 66 between X than twice of the value for the other pairs. Thus, METC is able to better capture the tight dependence between Xand X Ta ble 2: Z is switched OFF. Linear correlation coeﬃcient ρ, Mutual Information (MI) and Mutual Eﬀort-ToCompress (METC) for the multivariate system {X Consider the scenario where the higher order mechanism Z is such that it never allows X to be inactive/OFF fo r any time instant. This implies that we have to remove all the time instants in the ﬁring of the three ne urons corresponding to the value 0 to obtain the new ﬁring patterns X values of ρ, MI and METC are now updated as given in Table patently wrong since it is indicating that all pairs are independent when in fact (X -0.5 and Xare highly dependent on each other than on X. But, ﬁrst-order MI is unable to capture permutations of ea ch other and thus highly mutually dependent. METC is able to c orrectly capture all the pairwise relationships in this scenar io - yielding a value of 0 .0968 for the pair (X The a forementioned example is just a simple demonstration of the limitations of ﬁrst-order MI and the power of data compression based measure (such a s METC) to robustly capture the non-linear dependencies between short-length sequences. In practical applications in causality testing and machine learning, such problems are bound to oc c ur and one must exercise utmos t caution with ﬁrst order estimates of infotheoretic quantities (MI in this instance, but it could be others such as entropy, conditional entro py, cross entropy, re lative entropy etc.). ETC, METC and similar data compression inspired measures don’t make explicit assumptions about stationarity or ergodicity. They work by parsing the given sequence and recognizing and learning patterns. In order to explicitly demonstrate the problems in causal reaso ning using infotheoretic ideas, we employ a popular and widely used causal discovery algorithm known as Trans fer Entropy (TE) [4, 12]. TE has been applied in a large number of applications [ order to estimate the causal inﬂuence of a time series x on y, the idea behind TE is to estimate the KullbackLeibler (KL) divergence b e tween the two distributions p(x Here, (s) and (t) denote the number of past s tates of X and Y respectively and n represents the index of the current tempora l sample. If X and Y are independent processes, then p(x n, s, t and hence T E information (in bits) from a process Y to another proces s X. In general, T E shown that TE is entirely equivalent to Granger Causality for Gaussian variables [ We apply TE on both the multi-variate systems {X MuTE [ joint probability distributions. The numbe r of bins was set to 3 (as there are only three symbols in the sequences) and the maximum past lags considered was 5. 100 surrogates with 0.05 signiﬁcance level was chosen. Tables and 4 show the results obtained for the multi-variate systems {X TE values are in bits. Results for TE (in Tables 3 and 4) show the problems in estimating causality for such a small network using infotheoretic approach. For the {X system {X right settings for TE is a challenging task even for small networks. To test whether TE estimates would improve 14] toolbox and choose both the binnue and nnnue non-uniform embedding as the binning estimato r for , X, X}. The binnue setting does not yield meaningful results in both cases . Thus, choosing the with a longer data length, we doubled the lenghts. T hus, we took: But res ults did not improve at all (hence we do n’t include them here). Thus the problem is not just with ﬁnite length eﬀects, but more of a fundamental nature , namely, reliably estimating probability densities in order to estimate infotheoretic quantities accurately. For the example used in this s tudy, one way to get the ‘correct’ results is to use higher order estimates. In TE computation (using MuTE toolbox), this is achieved by a prudent setting of the number of maximum past lags for binnue and nnnu e estimators. Since the ﬁring patters A, B and C are all of length 12, by setting the number of lags = 12 (in MuTE) we can get the correct ca usal relationships and streng ths of TE . With binnue settings, TE(X (values of TE for the r e maining pairs are zero). However, there was no success for the nnnue estimator as the results don’t change even when the number of lags is set to 12. Thus, in real world applications, determining the number of lags for TE is extremely critical to estimate the correct c ausal relationships. One way to go about determining the lags to be used is to look at autocorrelation plots. Fig. 12 gives the highest autocorrelation for X estimator in MuTE toolbox to yield the corre c t causal relations hips and strengths. In this section, we dr aw attention on some uncomfortable aspects of important and c entral concepts of information theory that needs to be engaged by any serious researcher in c ausal learning. A well known inequa lity in informa tion theory is the following. Given two random variables X a nd Y , the following is always true [ where H(X|Y ) and H(X) stand for conditional entropy (of X given full knowledge of Y ) and Shannon entropy of X respectively. practical scenar ios where the above ineq uality is (or needs to be) violated, some examples are: 2 shows the sample autocorrelation function plots for the three neurons X, Xand X. A lag of Figure 2: Sample a utocorrelation function of X autocorrelation for X toolbox to yield the correc t causal relationships and strengths. 2. What about scenarios where entropies don’t exist? This is very much possible if the distribution is non- 3. An important point of Sha nnon’s theorems pertaining to sourc e coding and channel capac ity that is permutations of ea ch other) and vice versa, implying H(X|X) = 0 and H(X|X) = 0 bits. However, the MI estimated from ﬁrst- order statistics is zero implying that Xand Xare independent, and hence H(X|X) = H(X) 6= 0, and H(X|X) = H(X) 6= 0. In fact, for this case, the estimated ﬁrst-order Shannon entropies are H(X) = H(X) = 1. 0 bit. Thus, we wrongly infer from ﬁr st-order estimates that knowing Xis of no use in reducing the uncertainty of Xsince they are (wrongly) inferred to be independent, when in fact they are completely deterministic. This is an extreme case of an himalayan blunder where complete dependence is mistaken for its oppos ite - namely, independence. In actual practical scenarios, it may be less disastrous (or may be not!). stationary (for eg., varying with time) or the information source is non-ergodic. This is probably true in many practical scenarios. Another aspect to consider is the role of noise - could be either devastating or constructive (stochastic resonance) depending on the context. sometimes missed is that they assume the property of memorylessness. Thus, many of these inequalities are invalid if the source/channel under conside ration have memory. In many real-world situations, a 4. Is it po ssible for the inequality in Eq. 3 to be actually reversed? The answer is Yes, though not in the strict The above example opens a very interesting challenge for information theoretic approach to causal reasoning. It is well understood that Shannon’s notion of information or average uncertainty or degree of surprise is all about making a single choice from a list of given known choices. rarely determinate in the number and type of choices. The re ar e always an unknown number (and unknown k ind) of unknown possibilities lurking in the background. space of the random variable as new outcomes/choic es may pop up in the future (while possibly destroying some existing choices/options as well). The classical probability theoretic framework on which Shannon’s information theory is based is clearly inadequa te in handling such scenarios. One option is to explore the formalism of quantum theory of probability and dec isions [ From a causal learning p oint of v iew, it is important to recognize that the hallmark of a causal a gent is the ability to make conscious choices and decisions exercising free-will. In fact, a conscious causal agent can create new choices w here none existed previously. This brings us to the most elusive aspect of a conscious causal agent – “Consciousness”. Until we get a grip on this most important aspect of intelligence, causal learning is a distant dream. By means of a carefully designed illustrative example, the pitfalls of ﬁrst-order estimates of infotheoretic quantities (such as MI) were demonstrated. The short data lengths forces one to use ﬁrst-order estimates which leads to disastrous inferences. Data compression based mea sures (compression-complexity measure) seem to be more robust to ﬁnite data length eﬀects. However, extensive and rigorous testing of thes e measures (ETC, METC) needs to be performed in actual practical applications in machine learning and causal reasoning to make an informed judgement and evaluation. Causal discovery algorithms using data compression methods deﬁnitely needs a careful look. The limitations of using the for malism of informatio n theory is quite obvious - it fails to capture semantic aspect of information and the a bility of causal agents to make decis ions in an ever changing world of possibilities. A conscious causal agent can create new choices/ decisions/ meaning consciously and this is what makes rigorous accounting for the memory present is nontrivial, and may even be impossible. For example, if one were to ask a human to list out all of his past memories - this is an impossible ta sk. However, in every decision making event, some speciﬁc past experience or memory of the human is brought to bear. The human may not even be aware of the presence of this memory until it is triggered in the moment of decision making. formalism of information theory as laid out by Shannon. If semantic infor mation were to be considered, the above inequality can be easily violated. The possibility o f confusion in knowledge of X can a rise by knowing about Y . This is c le arly true in most of human decision making scenarios in real-life. Consider the following hypothetical scenario. Tara has applied for gra duate programme at several universities and she has received oﬀers from both MIT and Stanford University. Her dre am was to study at MIT and as she is about to make this decision when Stanford oﬀers her a newly constituted ‘best incoming student’ award (a possibility which did not exist before Tara applied). Now, she is confused. Here, k nowing new information (the award from Stanford) dras tically increased Tara’s uncertainty in making a decision whether to join MIT or not. causal learning possible in humans (and pos sibly in other animals). Consciousness is the holy grail for our understanding of intelligence, learning and causality. Let us conclude this with a warning made by none other than the father of information theory – Claude E Shannon [ “...it has perhaps been ballooned to an importance beyond its actual accomplishments.” Also, in the same article he mentions “...it carries at the same time an e le ment of danger”, “...it is certainly no panacea for the communication engineer or, a fortiori, for anyone else.” “It will be all too easy for our somewhat artiﬁcial prosperity to collapse overnight when it is realized that the use of a few exciting words like information, entropy, redundancy, do not solve all our problems .” So have we been forewarned. Financial support of ‘Cognitive Science Resea rch Initiative’ (CSRI-DST) Grant No. DST/CSRI/2017/54, ‘Science a nd Technology for Yoga and Meditation’ (SATYAM-DST) Grant No. DST/SATYAM/2017/45(G) and Ta ta Trusts is gratefully acknowledged. The author is thankful to Aditi Kathpalia for the help r e ndered on the MuTE toolbox. 16]. Referring to the rapid mushrooming o f applications of information theory, he wrote in [16]: