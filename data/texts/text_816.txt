 of molecular and solid-state phenomena, such as photoionization[1–3], thermodynamic properties[4, 5], magnetic[6] and non-equilibrium phenomena[4]. A full self-consistency guarantees several important theoretical features of the approximations, such as thermodynamic consistency, gauge invariance, and current continuity[7, 8]. These theoretical features ensure that in practical calculations, the values of thermodynamic observable evaluated either using thermodynamic integration or employing the grand canonical partition function remain mutually consistent. deﬁne the imaginary-time one-particle Green’s function G[9, 10] as Self-consistent approximations to the Dyson equation are important for description To access thermodynamic properties, we use the Matsubara imaginary time contour and where Z is the grand canonical partition function, β is the inverse temperature, µ is the chemical potential, deﬁned as a series of grid points). In the molecular case, the indices p, q enumerate spinorbitals. In the solid case, the multiindices p, q contain both enumeration of spin-orbitals and momentum k (because of momentum conservation, only one index k needs to be stored for the Green’s function and self-energy). In the imaginary frequency domain, the Dyson equation is expressed as where ω that is discrete (however, for the sake of brevity in the remaining text we list it as ω leaving the subscript n denoting the grid points out). G Σ[G](iω The self-energy decomposes into the static and dynamical parts where the static part is the Fock matrix built from the correlated one-electron density γ = −G(τ = β body correlational eﬀects that are not described at the one-body level of theory. While Eq. 3 is exact, in practice diagrammatic approximations to the self-energy are used. The speciﬁc approximations, such as GF2[11–15] and GW[16–25], deﬁne the explicit functional form of the self-energy. equation is solved iteratively. Unfortunately, in practice such an iterative procedure is often diﬃcult to converge. The lowest-order approximation to the self-energy is static. It is called the Hartree–Fock (HF) approximation, which is a basic building block of many quantum chemical methods. In the zero-temperature formulation, the simplest Roothaan’s direct steps[26] for HF take the density matrix γ from the current iteration, construct the new Fock matrix F [γ], diagonalize it, and assign its lowest eigenvectors as the occupied orbitals based on the Aufbau principle. Subsequently, using these eigenvectors one generates a new density matrix. Such direct steps often converge slowly or even diverge, especially when a poor initial guess is used. To stabilize the convergence, a constant mixing with the previous iteration (so called “damping”) is introduced for the Fock or density matrix [27, 28] This technique is commonly applied in the Green’s function methods, where the full selfenergy containing both static and dynamic parts instead of the Fock matrix is used for mixing. However, in most cases, both in traditional HF and Green’s function calculations, damping still leads to a relatively slow convergence of the iterative procedure. vergence has been developed, such as direct inversion in the iterative subspace[29, 30] (DIIS), is the fermionic (odd) Matsubara imaginary frequency ) is the self-energy functional depending on the full one-electron Green’s function. Due to the explicit dependence of the self-energy on the Green’s function, the Dyson A variety of techniques for acceleration and stabilization of the zero-temperature HF conrelaxed constrained algorithm[31] (RCA), energy-DIIS[32], ADIIS[33], least-squares commutator in the iterative subspace[34] (LCIIS), second-order methods[35–38], linear-expansion shooting techniques[39, 40] (LIST), maximum overlap methods[41] (MOM). Since the initial guess has a big impact on the behavior of iterations, a number of advanced guess generators has been introduced[42–44]. Calculations of periodic problems provide additional convergence challenges related to the singular behavior of Coulomb interaction, which is addressed by re-weighting contributions for each k-point and preconditioners[45–47]. function methods, such as multi-conﬁgurational self-consistent ﬁeld method[48], orbitaloptimized coupled-cluster methods[49–51], orbital-optimized M¨oller–Plesset method[52–54], the orbital optimization is very challenging and convergence diﬃculties often limit applicability of these methods, which resulted in a development of advanced algorithms targeting this problem[55–58]. nature of the Green’s functions, many algorithms, used in the wave function domain, are not easily and directly applicable. For example, in the full self-consistent Green’s function evaluation, the Fock matrix F [γ] that depends on the full one-particle density matrix is updated together with the self-energy Σ[G](iω). One of the consequences of the full selfconsistency is the gauge invariance, which can be seen as orbital optimization in the presence of correlation. However, since the Green’s function formulation does not rely on the explicit description of the orbital rotations, one cannot take advantage of orbital rotations in the exponential form with the second-order methods. There are also other diﬀerences. For instance, the non-convexity of the grand potential with respect to the Green’s function[59–61] violates initial assumptions of the RCA, EDIIS, and ADIIS algorithms, making their Green’s function generalizations not mathematically rigorous. Moreover, at a ﬁnite temperature, the Orbital optimization can be also done with the presence of electronic correlation. In wave- Green’s function methods also encounter many of these challenges. Moreover, due to the distinction between occupied and virtual orbitals is blurred, and the MOM method is not applicable in such cases. Additionally, since in the grand canonical ensemble, the calculations can be conducted for a ﬁxed chemical potential µ, the number of particles between iterations can ﬂuctuate thus exacerbating the convergence problems. quasiparticle GW) [62] either did not require self-consistency or relied only on a partial self-consistency, the construction of eﬃcient algorithms for the Green’s function convergence received little attention previously. While for some model systems Green’s function methods were converged fully self-consistently, these optimizations usually were performed in a small orbital space and in a narrow energy window, which either hid convergence problems in less trivial situations or were cheap enough that the acceleration was not necessary. The goal of this paper is to study applicability of the subspace extrapolation techniques to the solution of the ﬁnite-temperature Dyson equation. We formulate and compare DIIS (with commutator and diﬀerence residuals), LCIIS, and KAIN algorithms for Green’s functions and apply them to both molecules and solids. A general self-consistency scheme used in this paper is shown in Fig. 1. of DIIS is general, which enabled its use in a variety of contexts[29, 30, 63–71]. DIIS is a subspace method that uses memory of the previous iterations to provide a guess for the new iteration in the following way. Here, the vector quantities are labeled as v subscript enumerates iterations. The vectors can be represented as where the ﬁnal solution has a star subscript and the error vector is e norm of the error vector decreased with iterations. DIIS does that via linear extrapolation where c natural to use the constraint DIIS seeks to minimize the Euclidean norm of the extrapolated error ||e extrapolation coeﬃcients. The corresponding Lagrangian for minimization of the squared Since many of the methods used for large realistic systems (such as G0W0, GW0, and One of the most successful techniques is DIIS extrapolation[29, 30]. The formulation are the extrapolation coeﬃcients. In order to converge to the ﬁnal solution, it is norm is Assuming that the extrapolation coeﬃcients are real, the diﬀerentiation gives a necessary condition for minimum However, the numerical solution of the equation system above could be plagued by a bad condition number. As the residuals become smaller, their overlaps become smaller, leading to the appearance of small numbers in the B matrix, which worsens the condition number. Many practical implementations of DIIS apply tricks to mitigate this problem. As a simple preconditioning one can partition the equation system This equation system can be solved with λ = 1, which gives the correct set of c constant multiplier. Then the coeﬃcients are scaled to produce the DIIS constraint, which gives the solution of the original minimization condition. placed with the error estimates, which may depend on the nature of the v common and universal strategy is to take the diﬀerence between the subsequent iterations, cluster equations[64] and response coupled-cluster equations[67–70]. The DIIS has been recently applied to quasiparticle self-consistent GW[71] (qsGW, not to be confused with the fully self-consistent GW used in this paper), where self-energy was extrapolated and the diﬀerence between the density matrices was used as residuals. Another variant common in SCF calculations (CDIIS[30]) uses Fock matrices as v as error vectors where the F commutator assuming that either the orbital set is orthonormal or that the overlaps have already been absorbed in the density matrix. commutator residual, which follows from multiplication of both sides of the Dyson equation Of course, in practice the ﬁnal solution vis not known. The exact errors eare re- = v− v, as an error vector. This strategy has been successfully applied to coupled- For Green’s function calculations, we use the total self-energy Σas the vvectors. We use both the diﬀerence residuals between the subsequent iterations and the generalized (Eq. 3) by G(iω) from the left and right and taking a diﬀerence at the same iteration j: We then evaluate the commutator-error overlaps and norms in the time domain integrating over time. update of the chemical potential changes the G choose to re-evaluate the commutators or skip updating them. For periodic systems, irrespective of the method used for evaluating the self-energy, the computational scaling of commutator evaluation is O(n the frequency points, n cell. This scaling is up to a prefactor the same as the evaluation of the Green’s function from the Dyson equation. The cost of the Fourier transform of the commutator on the non-uniform grid is O(n trace, which is done as O(n may take a sizeable amount of memory, in our implementation, we store the subspaces of residuals and self-energies on disk and read them as they need to be accessed. Note that this additional computational cost necessary to perform DIIS is modest in comparison to the cost of evaluation of self-energy in both GW and GF2 procedures (O(n molecular GW and O(n basis functions in resolution-of-identity approximation). a set of coeﬃcients extrapolating both the Fock matrix and the density Indeed, since the Fock matrix depends on the density linearly, one can expect that the extrapolation coeﬃcients for both of them are the same[72]. Once the coeﬃcients are found and the extrapolation is performed for the Fock matrix, the new density P the F objective function—the squared norm of the commutator If the Green’s function is expected to reproduce a user-speciﬁed number of electrons, the We will comment now on the computational cost necessary to perform the DIIS procedure. In the context of HF and DFT methods, Li and Yaron introduced LCIIS[34], which ﬁnds The LCIIS extrapolation coeﬃcients are found from the minimization condition of the To perform the calculation of the objective function, a 4-index tensor is introduced The objective function and its derivatives are easily written as polynomials depending on coeﬃcients and T on the coeﬃcients (Eq. 10). Using Lagrange multipliers, the minimum could be found by applying the Newton method: where H is the Hessian of the objective function f(c), g is the gradient of the objective function, and ∆c is the Newton step direction for the coeﬃcients. The same partitioning of the system as for DIIS could be used to improve the condition number. In our implementation, we use a modiﬁed backtracking line search for the step size α, where instead of a gradient of a function, only its tangential component to the constraint manifold is taken. This ensures that the Newton step does not violate the DIIS constraint (Eq. 10). The minimization of the objective function continues until convergence is achieved. correlation potential does not depends linearly on the density. A generalization of the LCIIS algorithm to the Green’s functions is straightforward. Introducing extrapolations for the Green’s function and the self-energy as well as the commutator the LCIIS algorithm can be applied to the solution of the Dyson equation. The cost of the commutator evaluation is the same as in the CDIIS generalization. The only substantial cost diﬀerence is due to the number of necessary commutators that grows as N the subspace size. However, in all practical cases studied here, this overhead is very small. However, it has been found that LCIIS also works for DFT[34], where the exchange- One can suggest a modiﬁcation to LCIIS procedure (called here modLCIIS), where the extrapolation coeﬃcients for the Green’s function and for the self-energy are diﬀerent: The minimization of the objective function is a subject of the DIIS constraints on c c. Therefore, the corresponding Lagrangian and the Newton step are Although the simple system partitioning is not applicable to the system above, one can apply a simple diagonal preconditioner to improve the condition number. However, such a modiﬁcation is naive. Although it improves the values of the objective function in comparison to LCIIS, it does not present a good extrapolation, since already for the HF case the coeﬃcients for the Fock matrix and for the density are diﬀerent (which violates the linear connection between the Fock matrix and the density). The goal of KAIN is to ﬁnd a root v method for the step is given by where F is a Jacobian. In the subspace version, i = 1..n and the f(v Jacobian approximation can be used, giving an inexact Newton algorithm If P is a projector onto an (n −1)-dimensional subspace spanned by the diﬀerences v the equation for the step can be written as Harrison[73] introduced the Krylov subspace accelerated inexact Newton method (KAIN). Projecting Eq. 38 onto the space of diﬀerences, the subspace KAIN equations are obtained: We apply the KAIN algorithm in the same manner as DIIS, taking the self-energy as v vectors. However, not all choices of DIIS residuals can be used in KAIN. The commutator residuals are orthogonal to self-energy, leading to an ill-deﬁned system (Eq. 41). In this paper, we use the diﬀerence residuals, which do not lead to this issue. interpret the DIIS and LCIIS extrapolation as a given position (from the last iteration) and a step[73]: Here, the F interpreted as a step. In this picture, an overstep can happen if the step size is too large. We used a simpliﬁed step restriction measure from Ref.[73] to understand the impact of overstepping. If the norm of the coeﬃcients ˜c rescale them and perform extrapolation with the scaled coeﬃcients: The problematic DIIS iterations often have large extrapolation coeﬃcients. One can In case of KAIN, we measure the norm of the coeﬃcients and restrict the coeﬃcients if the norm exceeds a user-speciﬁed threshold in the following way: where the coeﬃcients ˜c components of the step through the v vectors (self-energies) and f vectors (diﬀerences of self-energies between the subsequent iterations), respectively. change website [77, 78]. The setup for NiO and Si solids was the same as in the previous publications[79–81]: the gth-dzvp-molopt-sr basis[82] and gth-pbe pseudopotential[83] were used, 6 × 6 × 6 grid was used for Si, 2 × 2 × 2 grid was used for NiO with doubled unit cell along [111] direction (to capture the broken-spin antiferromagnetic solution of type II). The gth-tzvp-molopt-sr basis, gth-pade pseudopotential, geometry from the Ref.[84], and 2 ×2 ×2 grid were used for BiVO PBE0 calculation. The stretched H H–H and N–N distances of 3.15 The resolution-of-identity approximation was used in the GW calculations [79]. The oneand two-electron integrals were generated with PySCF program [85]. The intermediate representation was used for the frequency grids [86]. All the algorithms are implemented in our in-house code. a beryllium atom. It is a closed-shell system, which does not show any problematic behavior in the zero-temperature Hartree–Fock calculations. However, the ﬁnite-temperature calculations show a diﬀerent behavior. Note that these calculations are performed at a constant chemical potential (not a constant number of particles). This can give rise to a varying number of particles during the self-consistent iterations. In Fig. 2, we plot the convergence of GW iterations with damping starting from a zero-temperature HF solution. At low temperatures[87] (β = 30–100 a.u. However, at higher temperatures (β = 10, 20 a.u. in the average number of electrons (computed from the Green’s function at a given iteration), leading to divergence of iterations. In this case, a step restriction is necessary. More signiﬁcant damping values (α = 0.3 and 0.5) stabilize the iterations and lead to convergence. We used the double-zeta cc-pVDZ basis sets [74–76], from the EMSL Basis Set Ex- One of the simplest systems for the investigation of the iterative convergence pattern is In Fig. 3, we display the DIIS iterations with the diﬀerence (DDIIS[88]) and commutator residuals (CDIIS) for the Be atom. The DDIIS iterations without step restriction are more oscillatory than the iterations with the step restriction. As expected, the smaller the parameter r is, the closer the iterations are to the direct Roothaan steps. Yet, even the iterations without restriction perform similar to the slightly damped iterations at a low temperature. However, at high temperature, DDIIS with all used values r diverge. As shown in SI (Fig S1), the increase of the subspace size slows the convergence, but does not not lead to better stability at high temperature. The cause of this behavior is likely the following. The DDIIS extrapolation takes into account only self-energy, but not the Green’s function, which leads to a ﬂuctuation of the number of electrons, impacting the computed self-energy from the Green’s functions. KAIN shows a similar behavior to DDIIS (Fig. S2). This is not accidental, because the step ∆v is dominated by the subspace component at most iterations. As shown in the Ref.[73], this regime is expected to be similar to DIIS. Fig. S2 shows that the divergence patterns at high temperature are similar to DIIS as well. The unsatisfactory behavior of the diﬀerence residual has been reported before in the context of coupled-cluster equations, where it also led to oscillatory behavior[89]. Commutator residuals, however, lead to a much more stable behavior of iterations. This is not surprising since the commutator residuals include both the Green’s functions and selfenergies. Fig S3 shows commutator residuals within DIIS. The CDIIS converges very rapidly with a loose convergence criterion As the changes in the density matrix and energy become of the order of 10 The likely reason is in the numerical errors in the commutator residual evaluation. Moreover, this also makes the extrapolation coeﬃcients sensitive to the numerical noise coming from the evaluation of the commutators leading to a noisy estimate of the error and noisy extrapolation coeﬃcients, preventing convergence with a tight convergence criterion. on the convergence of iterations, partially suppressing ﬂuctuations near convergence (the same is true for CDIIS). We recommend to switch to a stable damping near convergence if the tight convergence is required for LCIIS and CDIIS. diﬀerent temperatures, where the chemical potential is optimized after each extrapolation to yield a number of electrons for neutral systems. The best performing algorithms are CDIIS and LCIIS, the same as for the Be atom. and LCIIS show a similar performance, both signiﬁcantly outperforming simple damping. Interestingly, for NiO, the convergence of iterations with constant damping slows down when |∆γ| reaches small values. For BiVO LCIIS (Fig. 4) behaves similarly to CDIIS. The trust norm does not have a strong impact The Fig. S4 and S5 in SI show the convergence of iterations for Mg and Ca atoms at Fig. 5 shows the performance of CDIIS and LCIIS for solid Si, NiO, and BiVO. CDIIS damping is used. This is probably due to complicated electronic structure of these solids that includes both covalent and ionic contributions. Note that for both NiO and BiVO with simple damping (α = 0.5 and 0.3), the convergence of the energy (10 respectively) is achieved, however, |∆γ| is either showing a slow down in convergence or even a diverging pattern. This highlights that the convergence of the density matrix should be checked in addition to the usual convergence criteria based on energy. molecules or solids is notoriously diﬃcult. For example, the restricted GF2 calculation at a low temperature (β = 1000 a.u. temperature RHF guess fails to converge even if a severe damping is used. The oscillations between the iterations are so large that they cannot be eﬃciently damped, and both CDIIS For low-order methods such as GW or GF2 achieving convergence in strongly correlated and LCIIS algorithms do not converge (Fig S6 in SI). We found that for such cases a better starting guess is crucial for achieving convergence. At a high temperature (β = 30 a.u. stretched molecules studied here), the strong correlation between nearly degenerate orbitals is eﬀectively diminished[90] and RGF2 calculation converges rapidly when started from a high-temperature HF guess (Fig. 6 shows such convergence for stretched H subsequently used the converged self-energies and Fock matrices form the higher temperature calculations as an initial guess for the lower temperature calculations (leading to gradual cooling of the system). Fig. S7 in SI shows how the RGF2 converges with CDIIS and LCIIS for a stretched H the convergence. Similarly to the known practice of CDIIS in the zero-temperature SCF calculations, the increase of the subspace size stabilizes iterations. While the subspace size of 2 is suﬃcient to converge RGF2 for stretched H to increase the subspace to 3 in order to converge calculations at lower temperatures. This strategy can be use to converge the stretched N large extrapolation subspace (dim = 5) to stabilize iterations. This is not surprising since breaking a triple bond leads to a stronger correlation than breaking a single bond. Green’s function methods containing the Dyson equation. For the convergence acceleration algorithms analyzed here, the introduced computational overhead is negligible in comparison with the cost of the evaluation of self-energy during iterations, making the approach very , and the increase in the number of strongly correlated radical centers does not worsen We presented an application of subspace convergence acceleration algorithms to iterative promising for treating both molecules and solids. concept of commutator residuals to an arbitrary treatment of electron correlation via a selfenergy functional and used it to generalize CDIIS and LCIIS. On a number of examples, we showed that the choice of residuals is crucial. If the chemical potential is ﬁxed, the diﬀerence self-energy residuals often lead to divergencies of iterations (due to ﬂuctuations in the average number of electrons), even if the overstep treatment is applied. The commutator residuals with CDIIS and LCIIS behave much more regularly, both with the chemical potential being ﬁxed and optimized. mance is comparable. Both these algorithms outperform simple damping in almost all the cases. If the high-temperature initial guess is given, CDIIS and LCIIS dramatically extend the applicability of the restricted Green’s function methods to strongly correlated systems, (such as stretched H We used the diﬀerence self-energy residuals for DIIS and KAIN. We generalized the For molecules and solids, for the cases tested, we observed that CDIIS and LCIIS perforimpossible or very diﬃcult before. edges support of the Center for Scalable, Predictive methods for Excitation and Correlated phenomena (SPEC), which is funded by the U.S. Department of Energy (DOE), Oﬃce of Science, Oﬃce of Basic Energy Sciences, the Division of Chemical Sciences, Geosciences, and Biosciences. We thank Dr. Robert J. Harrison for his comment regarding the use of commutator residuals with KAIN algorithm. We thank Yanbing Zhou for providing the input data for the BiVO P.P. and D.Z. acknowledge support from NSF grant CHE-1453894. Ch-N. Y. acknowl- Iterations of DDIIS, CDIIS, KAIN, LCIIS for atoms and molecules.