Recent advents in recommender systems, especially in text-aided methods and Cross-Domain Recommendation (CDR), lead to promising results in solving data-sparsity and cold-start problems. Despite such progress, existing CDR approaches have some critical defects such as requiring overlapping users for the knowledge transfer or ignoring domain-aware features. In addition, text-aided methods, in general, emphasize aggregated item reviews and fail to capture the latent of individual reviews. To overcome such limitations, we propose a novel method, named Domain-aware Feature Extraction and Review Encoder (DaRE), which consists of the key components; domain-aware text analysis module, and review encoders. DaRE debilitates noises by separating domain-invariant features from domain-specic features through selective adversarial training. Then, with the features extracted from aggregated reviews, the review encoder ne-tunes the representations by aligning them with the features derived from individual reviews. The experiments on four real-world datasets show the superiority of DaRE over state-of-the-art single-domain and cross-domain methodologies, achieving 9.2 % and 3.6 % improvements, respectively. • Information Systems → Recommender Systems. Cross-Domain Recommendation; Disentangled Representation Learning; Domain Adaptation; Textual Analysis; Data Sparsity ACM Reference Format: Yoonhyuk Choi, Jiho Choi, Taewook Ko, and Chongkwon Kim. 2021. DaRE: A Cross-Domain Recommender System with Domain-aware Feature Extraction and Review Encoder. In Proceedings of ACM Conference (Conference’17). ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/ With the rapid growth of e-commerce, recommender systems have become an obligatory tool for interconnecting customers with relevant items. Early schemes suer from the cold-start problem caused by data insuciency. To tackle the problems, some of them exploit auxiliary information such as social relations [12], the trustworthiness of reviewers [1], item images [40], and textual information. Especially, textual or linguistic information such as reviews are commonly available, and many text-aided recommendation algorithms have been introduced [6, 9, 10, 36, 45]. Most text-aided schemes deal with aggregated reviews rather than individual texts since aggregation provides richer information. Some studies infer the preferences of users by applying NLP techniques such as topic modeling [2,28] to aggregated texts. More recently, [13,44,45] adopt DNN-based FEs (Feature Extractors), while others utilize attention mechanism [6,10]. Extracted preferences or features are fed into prediction modules in the forms of MF or MLP. Contrary to the prior methods that ignore individual texts, we propose to utilize individual texts as well as aggregated reviews, simultaneously. We extract features via two dierent routes, one from aggregated reviews and the other from individual texts, and align them using a review network. Along with the text-based recommender systems, numerous Cross-domain recommendation (CDR) algorithms [13,18,42] and transfer learning methods [16,41] have been introduced. CDR leverages the information learned from source domains to improve a recommendation quality in a target domain. Some schemes [38,41] use network ne-tuning, but they may suer from catastrophic forgetting [7]. Context mapping techniques [15,23,25,42], which map shareable information from a source to the target domain, is another branch of transfer learning popularly adopted in CDRs. These approaches require the same contexts like overlapped users or features, a restriction that can conne their applicability severely [19]. In real-world datasets, overlapped users are scarce and, more importantly, the contributions of overlapped users may not be signicant, prompting further investigations for a model oblivious to overlapped users. As one solution, some CDR algorithms focus on capturing domain-invariant features common to both source and target domains [5,14,20,30,44], which is independent of sharing same contexts. Though domain common knowledge improve the accuracy of recommendations, italicizing this kind of information only may lead to sub-optimal performance, especially when two domains have dierent distributions. To solve such constraints: require duplicate users, only capturing domain-invariant features, we propose a novel domain adaptation algorithm that extracts domain-aware knowledge from review texts, including both domain-invariant and domain-specic features without depending on the user or item overlap. Domain adversarial approaches extract domain-invariant features by minimizing source risk as well as H-divergence [4,14,21,22]. However, these methods are highly dependent on the consistency of source and target distributions (e.g., similar category). To mitigate such restriction, we extend the concept of domain adaptation, which emphasizes the extraction of domain-specic feature to distill pertinent knowledge from multiple seemingly counterproductive domains. Summarizing the above insights, Domain-aware Feature Extraction and Review Encoder (DaRE) adopts the following key components; domain-aware feature extraction, and a review encoder. Two mechanisms are closely coupled and interact with each other. DaRE extracts domain-aware features using three pairs of FEs, two for domain-specic features and one for domain-invariant feature. For domain-aware learning, we cleverly utilizes the domain adversarial technique that adequately controls the importance of domainspecic features or domain-invariant features. Through a selective adoption of the gradient reversal layer, three FEs are trained to capture these features. Another property of DaRE is that it utilizes individual texts as well as aggregated reviews. The review encoder network ne-tunes representations extracted from aggregated texts by aligning them with those extracted from individual reviews. The example of domain-aware feature extraction and review encoder can be seen in Figure 9 and 10, respectively. We perform extensive experiments on real datasets to compare DaRE with several state-of-the-art algorithms. Experimental results show that DaRE outperforms all baselines. Also, the ablation studies scrutinize the contributions of the key modules of DaRE, showing all components are indispensable to performance enhancement. The contributions of our work is summarized as follows. •We propose a novel algorithm that adaptively extracts domaininvariant and domain-specic features depending on the characteristics of the source and target distributions. DaRE is a comprehensive method where domain-awareness is closely integrated with text-based feature extraction. Its domain adversarial gradient updates eventually modify the text-based FEs and capture domain-specic and domain-invariant features concurrently. •Unlike previous CDR approaches that require duplicate entities such as common users or items from heterogeneous domains, DaRE focuses on retrieving review information that is domain-independent. Consequently, DaRE enjoys wide applicability and can be applied regardless of source and target domain homogeneity or heterogeneity. •We propose a unique review encoder that compares features extracted in two routes. It ne-tunes features extracted from aggregated information using features from individual reviews. The review encoder improves the accuracy of representation and the quality of recommendation. •We perform extensive experiments to answer the important research questions. Our results indicate the superiority of DaRE and the eectiveness of all key modules. We delve into the two types of categories; text-based recommender algorithms and CDR. Textual information is the most popular side information and many text-based methods [8–10,45] have been proposed. Most techniques integrate DNN based feature extraction with MF for a rating prediction. DeepCoNN [45] utilizes two parallel CNNs, while NPT [24] adopts Gated Recurrent Units for review analysis. Attention mechanisms are widely used also to pinpoint useful words and reviews [6,10,34,35]. Even though prior works show the usefulness of textual information, the limitation of review information due to the limited size of training data, the irrelevance of reviews toward target items have been raised also [33,43]. Unlike the prior works, DaRE utilizes both aggregated reviews and individual reviews. Also, DaRE couples the domain adversarial mechanism with three textbased FEs. To the best of our knowledge, this is the rst attempt that integrates the two mechanisms. CDR utilizes information from source domains to alleviate the coldstart problem in the target domain. Early studies [11,26] adopt feature mapping technique that requires overlapped users. For example, RC-DFM [13] applies Stacked Denoising Autoencoder (SDAE) to each domain, where the learned knowledge of the same set of users are transferred from source to target domain. To overcome the restrictive requirement of overlapped users, CDLFM [37] and CATN [44] employ neighbor or similar user-based feature mapping. However, this kind of cross-domain algorithm implicates defects [46] like ltering noises or requiring duplicate users. DA (Domain Adaptation) with the powerful mechanism of adversarial training has been adopted for various elds; VQA [32] for question answering, DAREC [42] for a recommendation. TDAR [39] assumes no user or item overlap and extracts domain-invariant textual features. However, these approaches focus on domain shareable knowledge ignoring domain-specic features. MMT [20] considers domain-specic features as well as domaininvariant knowledge, but it simply adopts user and item embedding as domain-specic features. DADA [30] suggests domain-agnostic learning, but its domain discriminator focuses on domain-invariant feature extraction only also, leaving domain-specic feature extraction to be solely guided for the minimization of mutual information with MINE [3], which has proven to have some defects [27]. DaRE clears the aforementioned limitations, adopting a framework for the simultaneous extraction of domain-specic and domain-invariant knowledge through the modication of domain adaptation. Assume two datasets,𝐷and𝐷, be the information from the source and target domains, respectively. Each dataset consists of tuples, (𝑢, 𝑖, 𝑦, 𝑟)which represents an individual review𝑟written by a user𝑢for item𝑖with a rating𝑦. The two datasets take the form of𝐷= (𝑢, 𝑖, 𝑦, 𝑟)and𝐷= (𝑢, 𝑖, 𝑦, 𝑟), respectively. The goal of our task is to predict an accurate rating score𝑦, using 𝐷and a partial set of𝐷. A detailed explanation of the notations can be seen in Table 1. On the upper side of Figure 1 (training phase), our model Domainaware Feature Extraction and Review Encoder (DaRE) starts with review embedding layers followed by three types of feature extractors (FEs). Integrated with domain discriminator, three FEs are trained independently for the parallel extraction of domain-specic 𝑂, 𝑂and domain-common knowledge𝑂, 𝑂. Then, for each domain, the review encoder generates a single vector𝐸, 𝐸with extracted features𝑂by aligning them with individual review𝐼, 𝐼. Finally, the regressor predicts an accurate rating that the user will give on an item. Here, shared parameters across two domains are common FE and a domain discriminator. We now explain each component precisely. We adopt text analysis method [45] that extracts user and item features from aggregated reviews using two parallel networks. Unlike the previous techniques [6,10,45] that use one or two pairs of parallel networks, DaRE adopts three pairs of FEs (Feature Extractors),𝐹𝐸,𝐹𝐸, and𝐹𝐸, named source, common, and target, for the separation of domain-specic, domain-common knowledge. The three FEs share the same architecture with unshared parameters,𝜃, 𝜃, 𝜃. As illustrated in Figure 2, each FE consists of a user feature extraction network𝐹𝐸and an item feature extraction network𝐹𝐸. To distinguish the domain identier from the FE identier, we use a superscript𝑑to denote the domains of datasets (𝑠for source and𝑡for target) and𝑘to represent three FE types (𝑠,𝑐, 𝑡). Note that the common FE (i.e.𝐹𝐸) uses both source and target domain reviews as an input. 𝐷, 𝐷Source and target domain datasets 𝑢, 𝑖, 𝑦, 𝑟User, item, rating, and review Figure 2: The architecture of a single review feature extractor. DaRE has three parallel review feature extractors of the same architecture with dierent inputs and parameters. Another distinctive characteristic is that DaRE utilizes individual texts as well as aggregated reviews, simultaneously. First, all reviews (except for individual review𝑟) written by user𝑢are concatenated to a single𝑅. Likewise,𝑅for each item𝑖is the concatenation of user reviews. Each individual review,𝑟, ne-tunes the nal representations of𝑅and𝑅through the review encoder. An𝐹𝐸begins with a word embedding layer. We utilize rst𝑛 𝑤𝑜𝑟𝑑𝑠 in𝑅or𝑅and adopt GloVe [31] for word vectorization. The words are mapped to𝑐-dimensional vectors𝜙 (𝑤). Word vectors are concatenated to form𝑉= 𝜙 (𝑤) ⊕ 𝜙 (𝑤) ⊕ ... ⊕ 𝜙 (𝑤), where𝜙and ⊕are embedding and concatenation function, respectively. Then 2-D convolutional network with lters𝐹 ∈ Rextract features from𝑉, followed by non-linear activation function ReLU with max pooling layer. Specically,𝑗-th lter,𝐹for user feature extraction yields 𝑓as follows: Figure 3: The architecture of (a) Domain adaptation, and (b) Domain-aware feature extraction. The dotted line (blue and red) denotes back-propagation for domain loss ,𝑏is a bias term. The representation𝑂,𝑂of user𝑢and item 𝑖is the concatenation of the scalar outputs 𝑓, , where𝐽is the number of lters. The nal representation𝑂is a simple concatenation of 𝑂and 𝑂. Likewise, we derive the embedding𝐴of an individual review 𝑟with three FEs as follows: As shown in Figure 1, the input for source and target FEs are (𝑅, 𝑅, 𝑟)and(𝑅, 𝑅, 𝑟), respectively. The common FE accepts both inputs. The outputs of three FEs are denoted as follows: from 𝐹𝐸. We propose a mechanism that separates the domain-invariant features from the domain-specic features. The DANN [14] architecture, which utilizes a domain-shareable module, eectively transfers knowledge between two dierent domains. As can be seen in Figure 3-(a), a domain discriminator gives a penalty to prevent a common FE from capturing domain-specic knowledge. One drawback of DANN is that it is vulnerable to domain-mismatches (e.g., categories) resulted in prohibitive applicability. To subjugate the limitation, we additionally adopt source and target FEs to capture domain-specic knowledge. Figure 3-(b) is the architecture of the proposed scheme. The domain-awareness module is closely coupled with the three text-based FEs explained before. Using the domain of reviews as a label, the domain discriminator prevents a common FE from capturing domain-specic features. On the contrary, the domain discriminator penalizes the source and the target FEs if source feature𝑂or target feature𝑂has insucient domain-specic information. In this way, our scheme can adaptively secure robustness against similarity or dierence between source and target domains; if source and target domains are different, then domain-specic features will be emphasized, and vice versa. For a domain discriminator, we utilize two layers of a fullyconnected neural network as below: , where𝑔is an activation function and𝐻, 𝐻are the parameters of the MLP.b𝑑denotes predicted domain label of feature𝑂. A domain loss can be calculated through binary cross-entropy between true 𝑑and predictedb𝑑label as follows: where𝑁and𝑁are the number of training data in source and target domains, respectively. The domain label𝑑is a binary value, {0, 1} for source and target, respectively. The proof of Equation 6 can be seen in supplementary material. Through Figure 3-(b), we can see that a domain discriminator is being updated with four types of losses. Then, two losses −L, −L(blue arrows) with Gradient Reversal Layer (GRL) updates the common FE, while another lossesL, L(red arrows) updates source, target FE, respectively. During back-propagation, GRL multiplies a negative constant, which is positioned between common FE and domain discriminator. Thus, the common FE is trained to capture domain-indiscriminative knowledge: fooling domain discriminator. This reinforces common convolution lter𝐹. On the contrary, domain loss without GRL prompts the source and the target FEs to capture domain-discriminative information: minimizing domain loss, which updates source or target convolution lters 𝐹, 𝐹. 3.3.1Remark.The domain-aware feature extraction employs the idea of domain disentanglement [30] but they dier in two perspectives. First, we selectively adopt GRL for domain-aware feature extraction without calculating mutual information. Second, our method notably focuses on the review analysis rather than image classication. Figure 4 illustrates the architecture of a review encoder taking a user𝑢and an item𝑖as an example. Prior methods only utilize Figure 4: A simple architecture of review enco der the gross review information such as𝑅and𝑅and ignore peculiar information𝑟that𝑢gives on𝑖. Intuitively, to retrieve the detailed latent representations, we propose a novel review encoder that handles specic review 𝑟from 𝑂and 𝑂. First, from an individual review, its nal representation,𝐼, is extracted as the summation of two vectors as shown in Figure 1: Also, we can obtain the representation of user and item from aggregated texts. From aggregated reviews𝑅, 𝑅, FEs obtain representations𝑂and𝑂, respectively. We devise the review encoder to align the latent from an individual review𝐼with the latent from aggregated reviews. Two embeddings𝑂, 𝑂are loaded to the encoder (fully connected network), generating a nal representation 𝐸as: To align the two vectors,𝐼, 𝐸, we adopt Euclidean distance as the loss function, The regressor predicts a rating score that user𝑢will give to the item𝑖. A single deep feed-forward neural network consists of two layers serves as the regressor. For each domain, the predicted ratings 𝐸and 𝐼are, b𝑦= 𝑅𝑒𝑔𝑟𝑒𝑠𝑠𝑜𝑟(𝐸) = 𝑊𝑔(𝑊𝐸+ 𝑏) + 𝑏 b𝑦= 𝑅𝑒𝑔𝑟𝑒𝑠𝑠𝑜𝑟(𝐼) = 𝑊𝑔(𝑊𝐼+ 𝑏) + 𝑏, whereb𝑦is a predicted rating based on aggregated reviews and b𝑦is an inferred rating from an individual review in domain𝑑. Finally, we can dene a regression loss function: the dierence between predicted scoresb𝑦,b𝑦and true label𝑦. We adopt MSE loss for the objective function as below: During the inference phase, DaRE utilizes the trained modules (common and target FEs, target review encoder, target regressor) with the entire aggregated reviews of user and item. Finally, the rating prediction in a target domain is as follows: 𝑂, 𝑂= [𝐹 𝐸(𝑅) ⊕ 𝐹 𝐸(𝑅)], [𝐹𝐸(𝑅) ⊕ 𝐹𝐸(𝑅)] , For the optimization, we can dene the objective function through the weighted sum of three Equations 6, 9, 11 as below: The hyper-parameters𝛼,𝛽balance the domain and encoder losses. From our experiment,𝛼 =0.1,𝛽 =0.05 yield the best performance (details are in supplementary material).𝜃denotes all parameters of our model and𝛾is a regularization term. We update the model’s parameters through the gradient descent by minimizing Equation 13, where the parameter update for each module can be seen in Figure 1 with three basic shapes. A shape with a horizontal stripe denotes a loss from the source domain. For training, we adopt a mini-batch with Adam optimizer𝑙𝑟 =1𝑒 and early stopping. The trainable parameters of DaRE are three FEs, a domain discriminator, two review encoders, and two regressors. We now explain the parameter updates of each module in detail. First, let us assume the parameters of source and target regressor as𝜃, 𝜃. The loss function associated with the update of𝜃, is a regression error dened in Equation 11 (see purple triangles in Figure 1). We can simply update the parameters of regression layer, 𝜃and 𝜃with proper learning rate 𝜇 as follows: Then, we can dene the losses for the update of two review encoders 𝜃using chain rule: , where L= ||𝐸− 𝐼||(blue circles in Figure 1). For a domain discriminator, the parameter𝜃is updated with the summation of domain-invariantL, Land domainspecicL, Llosses (red squares in Figure 1), which is dened in Equation 6: Finally, we can dene the update functions for three FEs𝜃, 𝜃, 𝜃, integrating three types of losses as follows: In this section, we conduct experiments with multiple real-world datasets of dierent categories to answer the following research questions: • RQ1:Does DaRE outperforms compared with several stateof-the-art recommendation approaches? • RQ2:Does the core components of DaRE: domain-aware feature extraction and review encoder, are essential for the recommendation quality? • RQ3:How well the properties of domain-aware knowledge and peculiar information are preserved in extracted features? We systematically conduct experiments with publicly available datasets Amazonand Yelp. The target domain includes the following four categories of Amazon: Oce Products(OP), Automotive(Au), Patio Lawn and Garden(PL), and Instant Video(IV). The source domain consists of four datasets: three categories, Baby, Kindle Store(KS), Toys and Games(TG) from Amazon and one from Yelp. We adopt Yelp data to scrutinize the eect of excluding duplicate users for CDR scenario. Also, to lens on the cold-start problem, we designate datasets with sparse interactions as the target domain. The statistical details of datasets are summarized in Table 2. Like previous studies, each target dataset is divided into three parts: 80 percent for training, 10 percent for validation, and another 10 percent for testing. We randomly sample source domain data such that its size equals that of the target domain data. For word embedding, we use Glove with a xed embedding dimension of 100. We apply 100 convolution lters of size𝐹 ∈ R. The performance is evaluated based on the validation score with early stopping under 300 iterations. We upload our codefor a reproducibility. We select 10 exemplary state-of-the-art single-domain and crossdomain approaches. Detailed explanations are as follows: 4.2.1 Single-Domain Approaches. • PMF[29] is a classical probabilistic matrix factorization method. • NeuMF[17] combines deep neural networks with a probabilistic model. NeuMF achieves great performance enhancement over classical methods. • DeepCoNN[45] leverages review texts for rating prediction. They retrieve users’ interest from textual reviews and jointly encode the latent of user and item with two parallel neural networks. • NARRE[6] improves the DeepCoNN by employing attention mechanisms to measure the usefulness of reviews. • AHN[10] proposes a hierarchical attention mechanism: review embedding is generated by applying sentence-level attention, followed by review-level attention for retrieving user and item embedding. 4.2.2 Cross-Domain Approaches. • DANN[14] proposes the seminal domain adversarial technique that extracts domain-invariant features from two different domains. Here, review texts are embedded as 5,000dimensional feature vectors. • DAREC[42] assume the same set of users between two domains and integrate AutoEncoder with domain adaptation to transfer rating patterns from a source to the target domain. • RC-DFM[13] fuses review texts with rating information. With SDAE, it preserves the latent features with rich semantic information. For a fair comparison, we additionally train the text convolution layer for each domain. • CATN[44] transfers knowledge at an aspect level. The model extracts multiple aspects from review texts and learns aspect correlation across domains with an attention mechanism. • MMT[20] adopt domain-invariant components shared across two domains. Here, we adopt text convolution layers for a knowledge transfer (review texts can act as domain-invariant information). Also, the trained parameter of the text convolution layer is retrained in a target domain for performance enhancement. DaRE consistently outperforms all single-domain approaches. Table 3 shows the MSE score of DaRE with state-of-the-art approaches. For single-domain methodologies, rating-based PMF and NeuMF performed worse than text-based methods indicating the usefulness of textual information. NARRE and AHN which adopt attentions outperform DeepCoNN. Nonetheless, with the aid of domain-aware knowledge transfer and review encoder, DaRE outperforms AHN, which is competitive rather than attention mechanism. The quality of cross-domain recommendation can be degraded with respect to the domain discrepancy.We rst investigate the performance of ve cross-domain algorithms. Like DaRE, DANN and MMT transfer knowledge without user overlapping. The results show that DANN and MMT are unstable depending on Figure 5: Performance of DaRE excluding core components; domain-aware feature extractor and review encoder the pairing of source and target, which reveals the limitation of DANN and MMT. Typically, in the case of Patio Lawn and Garden, AHN with single-domain achieves the best performance among all baselines. This result demonstrates that utilizing additional domains without considering noises can degrade the recommendation quality. In contrast, DaRE shows stable performance highlighting that its domain-aware feature extraction eectively alleviates noises from the source domain. Knowledge transfer of overlapping users has limited contribution for the cross-domain recommendation quality.Some argued [19] that the knowledge transfer based on overlapping users has a limited impact on the overall performance. Note that DAREC, RC-DFM require duplicate users for a knowledge transfer. Specically, DAREC, which utilizes rating information of duplicate users only, shows relatively low performance, again suggesting the usefulness of review information. Compared to DAREC, RC-DFM achieves the best performance for the two datasets. However, even excluding a knowledge transfer by removing duplicate users (selecting𝑌𝑒𝑙𝑝as a source domain), the performance of DAREC and RC-DFM varies insignicantly (no more than 1% on average). Though CATN utilizes auxiliary reviews of another user who gave the same rating, does not show outstanding performance in our experiments. Instead, DaRE eciently utilize additional domain through the adoption of review texts, which is less restrictive for the selection of a domain. Summary.The performance of DaRE exceeds the state-of-theart single (AHN) and cross-domain (RC-DFM or MMT) approaches about 9.2 % and 3.6 %, respectively. We assume two variants of DaRE to show the inuence of excluding a domain-aware feature extractor and the review encoder. In Figure 5, the mean and variance of the variants of DaRE are plotted, with respect to each target domain. Here, the purple and green box denotes the performance of excluding domain-aware feature extractor (DaRE - Da), and review encoder (DaRE - RE), respectively. Domain-aware feature extraction is fundamental for debilitating noises.First, we exclude domain discriminator from Figure 6: With the output of FEs and review encoder, we highlight most similar words of user, item’s past reviews DaRE (DaRE - Da). Through Figure 5, we can see that the performance of DaRE - Da shows higher variance (purple boxes) compared to DaRE - RE (green boxes), suggesting the domain discrepancy is critical for overall performance. For example, in Figure 5-(b), the adoption of Yelp as source domain leads to the performance improvement for Instant Video (IV), while the selection of Toys and Games (TG) can degrade the recommendation quality. Review encoder contributes to the overall performance signicantly.Compared to DaRE - Da, DaRE - RE shows relatively stable results independent of a category of source domain. Though the mechanism of domain-aware feature extraction eectively controls the mismatches between two dierent domains, we notice that the excluding review encoders are critical for the recommendation quality. Specically, we notice that DaRE - RE shows relatively lower performance compared to DaRE - Da except for Figure 5-(c). Here, we empirically show the signicance of utilizing a domainaware feature extractor, and the review encoder, respectively. Based on the above results, we contemplate that DaRE systematically improves the recommendation quality under the cross-domain scenario, through the integration of two novel mechanisms. To provide intuitive analysis, we investigate the interpretability of DaRE. We adopt Toys and Games and Automotive as source and target domains, respectively. Figure 6-(a) and 6-(b) denote specic user and item reviews in the target domain. 6-(c) is a review that the user has written after purchasing the item. A detailed aspect of this item can be available in Amazon Automotive with its code (id: B00002243X). First, we apply the common and target feature extractors for each review and retrieve its embedding vectors𝑂, and𝑂, respectively. Then, for each word embedding in Figure 6-(a) and (b), we highlight the most similar words, e.g., cosine similarity, compared to𝑂and𝑂. Specically, the blue highlighted words are the most similar to the output of the common feature extractor 𝑂, while the red highlighted words are the most similar to the output of the target feature extractor𝑂. As can be seen, the blue words are more related to the semantic meaning of words which can be domain-indiscriminative (e.g., nice and good quality), while red words are relevant to domain-specic knowledge (e.g., cable and vehicle). Similarly, in Figure 6-(c), we highlight top-2 similar words (green) compared to the output of review encoder𝐸, which is generated from𝑂and𝑂. Here, a review encoder well captures (e.g., high quality and cable) that the user will be interested in. To summarize, DaRE not only well predicts the accurate rating (4.89 for 5.0) but also demonstrates the vitality of domain-aware feature extractor and review encoder for capturing the transferable knowledge and relatedness between the user and item. In this paper, we propose DaRE, a novel domain adaptation method utilizing review texts from multiple domains for a knowledge transfer. Compared to previous approaches, our method is able to capture domain-invariant and domain-specic information of dierent categories with the aid of domain-aware feature extraction. Moreover, we suggest the use of a review encoder, to better represent the attribute of reviews that the users will generate after purchasing a specic item. Extensive experiments and ablation studies on real datasets conrm the superiority of our method which is independent of users and items of dierent domains. In Equation 13, we dene the two hyper-parameters𝛼and𝛽to balance the signicance of domain and encoder loss. In Figure 7, the x-axis denotes the value of𝛼, the y-axis is the value of𝛽, and the z-axis demonstrates MSE score. For a simplied analysis, we Figure 8: Convergence analysis w.r.t. MSE score for test data simply visualize the performance of a single target domain Instant Video, adopting Baby as a source domain. First, we start with𝛼which denotes a weight hyper-parameter for a domain loss. Three feature extractors (FEs) are trained based on three losses. Generally, when𝛼becomes large, e.g., 1.0, the FEs focus on the minimization of domain loss, while disregarding the reduction of classication loss (making an inaccurate prediction). On the contrary, when𝛼gets lower, e.g.,𝛼 =0, DaRE solely focuses on decreasing classication loss, which is independent of domainaware feature extraction. Here, DaRE achieves the best performance if the value of 𝛼 is 0.1. Likewise, for𝛽, the weight hyper-parameter aects three FEs and the encoder to generate similar embeddings between the individual review and aggregated reviews. In our experiments,𝛽with 0.05 shows better performance compared to other values. As can be seen, proportional to the value of𝛼and𝛽, the prediction error increases. Through a grid search, we systematically dene parameters,𝛼 =0.1 with𝛽 =0.05, which shows relatively higher performance compared to another value. For a convergence analysis, we plot the MSE score based on four target domain datasets in Figure 8. Each gure demonstrates the MSE score of the target domain data based on four source domains, respectively. Here, we update the parameter of DaRE for 500 iterations. The x-axis and y-axis denote the number of iterations and MSE scores. At the beginning of training, DaRE shows relatively unstable performance due to the domain and encoding losses. As learning progresses, the domain and encoding losses decrease, leading to the convergence of parameters. Near 300 iterations, we can see that DaRE shows relatively stable results. Figure 9: Example of domain-aware feature extraction. We assume two phases: training and inference, with two different domains: Musical Instruments and Toys & Games for cross-domain recommendation scenario The domain label𝑑, 𝑑consists of binary values, {0, 1} for source and target domain, respectively. Since a domain classication can be identied as a binary classication task, to retrieve a domain loss, we adopt binary cross-entropy loss for calculation. First, we can induce a domain probability[b𝑑,b𝑑]with interleaved common features[𝑂, 𝑂], respectively. The true label is [0,1], for source and target domain features. Here, we can dene a binary cross entropy loss for common features as follows: Figure 10: Example of review encoder. With user and item’s previous reviews, the encoder assumes a real feedback that user will leave after purchasing an item We can substitute domain labels𝑑, 𝑑with[0,1], redene Equation 18 as: Likewise, we can derive domain-specic losses with domainspecic featuresb𝑑,b𝑑as follows: Substitute domain labels𝑑, 𝑑with[0,1], we can derive domainspecic losses L, L, which are dened in Equation 6. In Figure 9, we show an example of domain-aware feature extraction from a real-world benchmark dataset Amazon. The scenario assumes a training phase with source (Fig 9-(a), upper) and target (Fig 9-(b), lower) domain. The dierence is that a common FE (red box) is shared across domains, while the source and target FEs (green and blue boxes) are domain-specic networks. Taking Fig 9-(a) as an example, the objective is predicting a rating that a user𝐴gives on item 2. Excluding individual review, user𝐴𝑠review on item 2, the source and common extractors distillate latent of user and item respectively. Specically, for user 𝐴in𝑀𝑢𝑠𝑖𝑐𝑎𝑙𝐼𝑛𝑠𝑡𝑟𝑢𝑚𝑒𝑛𝑡𝑠, a source FE captures domain-specic knowledge that she makes much of sound quality, while common FE extracts domain-common information like beautiful, and nice price. The analysis for item 2 follows the same mechanism. To summarize, our model not only considers domain-shareable knowledge with common FE but also reects domain-specic information through the source and target FE. For the training of a review encoder, we utilize individual review that user𝐴has written on item 2 (blue box) as another label. Taking Figure 10-(a) as an example, the review encoder (purple box) takes four types of inputs which are extracted from the source and common FEs. Then, the encoder generates a single output, which contains mixed information of user𝐴and item 2. Here, the encoder is trained to infer an individual review, negative feedback of user𝐴 who takes sound quality into account. Likewise, another encoder in a target domain can be trained in a same manner.