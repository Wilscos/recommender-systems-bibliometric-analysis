fundamental crowd dynamics research allowing to quantify statistics of relevant observables including walking velocities, mutual distances and body orientations. As this technology advances, it is becoming increasingly useful also in society. In fact, continued urbanization is overwhelming existing pedestrian infrastructures such as transportation hubs and stations, generating an urgent need for real-time highly-accurate usage data, aiming both at ﬂow monitoring and dynamics understanding. To successfully employ pedestrian tracking techniques in research and technology, it is crucial to validate and benchmark them for accuracy. This is not only necessary to guarantee data quality, but also to identify systematic errors. Currently, there is no established policy in this context. dard in the community, for privacy-respectful pedestrian tracking techniques. The suite is technology-independent and it is applicable to academic and commercial pedestrian tracking systems, operating both in lab environments and real-life conditions. The benchmark suite consists of 5 tests addressing speciﬁc aspects of pedestrian tracking quality, including accurate line-based crowd ﬂux estimation, local density estimation, individual position detection and trajectory accuracy. The output of the tests are quality factors expressed as single numbers. We provide the benchmark results for two tracking systems, both operating in real-life, one commercial, and the other based on overhead depth-maps developed at TU Eindhoven, within the Crowdﬂow topical group. We discuss the results on the basis of the quality factors and report on the typical sensor and algorithmic performance. This enables us to highlight the current state-of-the-art, its limitations and provide installation recommendations, with speciﬁc attention to multi-sensor setups and data stitching. Key words: High-ﬁdelity pedestrian tracking – Sensor benchmarking – Crowd monitoring – Real-life pedestrian measurements – Industrial and societal applications Growing population and continued urbanization puts urban infrastructures at large stress. Moreover, over the next 10 years in densely populated European countries public transport facilities such as, e.g. train or metro stations, expect a passenger growth as high as 40% [1]. Potentially dangerous crowd-capacity issues – possibly in combination with distancing requirements – increase by the day, and demand substantial crowd management eﬀorts. To unlock sustainable and scalable crowd management, maximizing comfort and safety, real-time, high-accuracy, anonymous individual pedestrian tracking is a must. This enables reliable usage monitoring and performance proﬁling, and, on a broader perspective, the possibility to develop a fundamental understanding of the motion of crowd ﬂows. Pedestrian dynamics researchers, who historically mostly relied on controlled laboratory experiments (see e.g. [2, 3, 4, 5, 6, 7, 8]), can now also acquire fundamental knowledge in real-life environments collecting large-scale statistics of observables such as walking velocities, mutual distances, body orientations and group structure [9, 10, 11, 12, 13, 14]. Optic-based tracking, leveraging on visual-like signals, is the most widespread technology when (sub-)centimeter pedestrian positioning resolution is required. Raw signals are generally acquired via arrays of color cameras (as CCTV) [2, 5], stereo cameras [3, 14, 15] or infrared depth-cameras [9, 16, 17]. Speciﬁcally, the last two technologies, hinged on three-dimensional imaging, allow higher accuracy and will be considered in this paper. After a calibration stage in which, among others, pixel-coordinates are matched to spatial coordinates, raw signals are postprocessed to yield pedestrian positions and trajectories. Highly accurate, optical methods are generally limited in range by the visual cone of the individual sensors. Note that, at the price of a substantial accuracy loss, Bluetooth-based [18, 19] or Wi-Fi-based [20, 21] tracking enable larger spatial coverage per sensor. Optic-based tracking techniques become rapidly more aﬀordable over time, this makes highaccuracy pedestrian tracking accessible to a wide variety of users beyond academic research. Over the last few years, for instance, managers of public transport facilities have adopted pedestrian tracking technologies to gain valuable insights in the ﬂow dynamics through their facilities (see e.g. [14, 22, 23, 24]). To successfully employ pedestrian tracking techniques in research and technology, it is crucial to measure the level of performance and asses the quality of the output data. This means establishing a benchmark as well as measuring the performance of the current state-of-the-art. This is not only necessary to guarantee data quality, but also to identify systematic errors, such as erroneous objectperson recognition, and misaligned stitching. To the best of our knowledge, there is no established tool in this context. In this contribution we propose a benchmark that consists of a minimal set of ﬁve tests to quantify pedestrian detection accuracy and time-tracking reliability. The tests have been iteratively improved over the past 3 years [22] and follow from a joint eﬀort between academic research and large-scale public facility managers. The full benchmark, designed to take limited time and resources, can be executed in less than 2 hours with as few as 12 participants. The ﬁve distinct tests span from macroscopic to increasingly microscopic observables of pedestrian dynamics. Considering ﬁner and ﬁner aspects of pedestrian dynamics, the tests get increasingly challenging from a technological perspective. The tests output quality factors expressed as single numbers. The ﬁrst two tests probe large-scale observables by gauging reliability in estimating: 1. crowd ﬂuxes (ped/min), and 2. local densities (ped/m). Note that these are averaged quantities, respectively over a time interval or over a surface, and therefore beneﬁt from error compensation, i.e. false negatives could counterbalance false positives. In test 3, we focus on the signiﬁcantly more challenging task of instantaneous individual localization. In tests 4 and 5, we consider Lagrangian time-tracking proﬁciency over full multi-sensor measurement domains. We present the benchmark results for two pedestrian tracking setups operating in real-life, one developed in-house at TU Eindhoven, and the other one commercially available. This aims at reporting on the current state-of-the-art and providing a reference for new pedestrian tracking setups. This paper is structured as follows: In Section 2 we discuss the essentials of optic-based pedestrian tracking. This is followed, in Section 3, by a description of the two experimental setups we employ to validate our benchmark. In Section 4, we introduce the benchmark suite and detail individual tests and their rationale. In Section 5, we report the benchmark performance of our experimental setups. The discussion in Section 6 concludes the paper. In 3D optic-based tracking, visible-light or infrared 3D imaging data, acquired by camera-like sensors, are processed to localize pedestrians in space and track them over time. Three-dimensional imaging, richer in information than ﬂat 2D pictures, substantially simpliﬁes and allows high accuracy in the tasks connected to tracking. At the core it is the estimation of a depth-map of the scene, that encodes the position of each pixel in the three-dimensional space [12, 16, 17]. This can be achieved via stereoscopic vision, scattered infrared illumination e.g. [25], or time-of-ﬂight sensors. For each pedestrian and each 3D-frame acquired, the tracking process yields quadruplets (x, y, t, id) where x and y are spatial coordinates (a z-coordinate can be added if needed), t is the frame acquisition time, and id is an identiﬁer unique to each pedestrian. This enables us to deﬁne the set of recorded trajectories T = {γ}, with γthe trajectory of the pedestrian with identiﬁer id. The tracking process generally happens in two stages: localization and Lagrangian timetracking. In the localization stage, each frame is processed independently to single out each pedestrian and estimate their position. To this purpose image processing and/or machine learning models are used [13, 16, 17, 26]. Lagrangian time-tracking assigns an id to each detection on the basis of continuity arguments. These two stages can also happen simultaneously, e.g. using optical-ﬂow like techniques [15]. Cameras or infrared sensors are generally mounted in overhead position, aimed perpendicularly to the ﬂoor to reduce mutual pedestrians occlusions. The scope of their view-cone depends on, and in general, limited to, the mounting height (typically the height of the ceiling). Grids of sensors with partially overlapping view-cones can be combined to enlarge the measurement domain [27]. During the installation, a calibration step which establishes a global coordinate system across all the sensors is generally performed. Additionally, background subtraction which removes stationary objects (e.g. benches) from the image can be used to simplify the localization phase and increase its accuracy. Despite its growing adoption, optic-based pedestrian tracking still features numerous open technical challenges. First, localization algorithms can fail due to poor image quality, e.g. caused by impurities on the camera lenses, excessive or insuﬃcient illumination, or interference in the infrared spectrum (caused by direct sun exposure). Additionally, objects in the scene such as luggage or bicycles can yield false positive detections. Instead, possible causes for false negatives are (partial) occlusions by other pedestrians or infrastructural objects, e.g. trusses, signage, and lighting. Especially at the boundaries of each sensors view-cone the acquired image can be distorted which also lowers the localization quality. False negatives in the localization process yield gaps over which the time-tracking algorithm is unable to return continuous trajectories. As a consequence, two or more “broken” trajectory pieces with distinct ids are returned. Combining information from multiple sensors presents also challenges connected to insuﬃcient overlap or misalignment between the sensor view-cones (cf., e.g., the view-cone stitching algorithm in [12]). These are typical causes for “broken” trajectories. Our benchmark contains tests that are designed to recognize these bottlenecks, probing eﬃciently localization accuracy, geometric conformality, and the absence of tracking artifacts such as misassigned ids. We discuss our benchmark considering two pedestrian tracking setups brieﬂy described below. The systems, which operate anonymously and in real-life conditions, leverage on diﬀerent opticbased tracking approaches. The ﬁrst, developed in house at TU Eindhoven, within the Crowdﬂow topical group, is based on depth reconstructed via scattered infrared illumination [25] and, the second, is based on depth reconstructed via stereoscopic vision. In the following we shall refer to these systems, respectively, as “TU/e setup” and “commercial setup”. We give a description of the pedestrian tracking systems in the paragraphs below. Note that in both setups we did not apply any further processing of the raw images nor post-processed the obtained trajectories. The performance of these tracking systems can be enhanced by setup-speciﬁc manual operations e.g. smoothing or restitching of the individual trajectories. This choice was deliberately made to focus on the bare, baseline, tracking accuracy. TU/e setup The tracking system developed in house at TU Eindhoven leverages on overhead depth-map images, which represent the distance between pixels and the sensor plane (colorized in shades of gray in the example of Fig. 1c). Localization occurs via depth clustering (as in [12]), and time-tracking uses the Trackpy Python library [28]. The same approach has been successfully used in e.g. in stations, streets, and museums [9, 12, 13, 26]. The speciﬁc setup considered consists of a grid of 3 × 4 Microsoft Kinect[25] depth sensors. The sensors are attached to the ceiling of a large public area within the University campus in Eindhoven, the Netherlands, at a height of about 4.5 m (see Fig. 1a, b). The grid records depth images (Fig. 1c) over an area of S = 150 m with f = 30 frames per second. Commercial setup The commercial system anonymously tracks pedestrian movements using 3D stereoscopic images. The system consists of 3 commercial pedestrian tracking sensors (Xovis), used in e.g. train stations [14, 22, 23, 24], to monitor complex crowd ﬂows. Every sensor records images at f = 10 frames per second and processes the stereo images in real-time only storing pedestrian locations as x, y coordinate pairs. This system is installed at real-life operational train station Breukelen, the Netherlands. The sensors are mounted to the ceiling of a platform covering an area of 4 m × 12.4 m ≈ 50 m. We report an overview of the platform in Fig. 2. Note that (most) commercial systems only return trajectories, whereas in custom setups one can retain also the raw data which can be used to further improve the algorithms and/or extracting additional features such as body orientations. Figure 1: TU/e measurement setup based on overhead depth sensors at Eindhoven University of Technology, The Netherlands, during test 3. (a) Picture taken during test 3 of the benchmark. At the top of the image part of the 3 × 4 sensor grid is indicated with red arrows. We guide participants during this test using taped markings on the ﬂoor. (b) Detail of one of the three arrays of 4 sensors, taken at sensor height. The sensors are attached to a truss near the ceiling pointing downward, perpendicularly to the ﬂoor (c) Overhead depth image captured by the sensor grid already encompassing merging and perspective correction [29]. The gray color in the depthmap represents the distance to the camera plane. Bright shades are far from the sensor and darker colors are closer to the sensor. In the depth-map we can distinguish silhouettes of pedestrians (as seen from above) where the shoulders are a lighter tint of gray and the head is slightly darker. The inset reports the silhouette of a single pedestrian. The trajectories of the pedestrians are super-imposed and show the walking direction. Figure 2: Experimental setup for the commercial tracking system at train station Breukelen, The Netherlands, visualized with a schematic ﬂoorplan. The train tracks are shown in the top and bottom of the image. The dimensions of the measurement domain, with size 4 m×12.4 m = 50 m is highlighted with a red dashed rectangle. We describe here the ﬁve tests comprised in our benchmark, which is also resumed and schematized in Table 1 encompassing an illustration and key features for the individual tests. We additionally present advises on test duration, ∆T and number of participants, N, using a gray cell background. Test 1: Line-based crowd ﬂux estimation. We probe the accuracy in estimating crowd ﬂuxes, as count of pedestrians crossing a line in a predeﬁned time window, t compare counts automatically estimated, N(t, t), with the ground-truth, N evaluated. As a ﬁnal score we retain the following indicator which equals 100 in case of a correct count estimate and is lower otherwise. Commercial systems generally include internal algorithms to compute line crossings, whereas in the TU/e system we employ the algorithm described in Appendix A. To reach a challenging ﬂux of J we ask participants to follow a circular path, which is crossed twice by the straight line across which the ﬂux estimation occurs. In particular, we employ N = 12 participants walking a loop with a diameter D ≈ 3 m for ∆T ≈ 5 minutes. Test 2: Local density estimation. We target the accuracy in estimating local pedestrian densities. We consider the number of people N, N, N, . . . moving freely within virtual regions S, S, S, . . . determined by the tracking systems, and compare it with the ground-truth. For simplicity, we keep the number of pedestrians in each virtual region constant, N the following time-averaged relative error as the score With few participants we only target low average crowd densities in this test. However, the localization task is very challenging due to short distances between ﬁrst neighbors that yield instantaneously high densities. Additionally, (stationary) objects can be added to the test area to validate the ability to diﬀerentiate between objects and people. Test 3: Individual position detection. We target, in line with [22], the capability of accurately determining individual positions. To bypass the need to manually establish a groundtruth for point-wise comparisons, we ask participants to walk following simple geometric patterns, speciﬁcally, a grid of straight lines (cf. markings in Fig. 1a). We score how closely the measured trajectories agree, as an ensemble, with the geometric pattern, i.e. they form thin and straight bands. Operationally, for each collected trajectory, we isolate the portions that follow single grid lines. For each grid line, we obtain a set of trajectory pieces of which we consider averages. We either retain the best ﬁtting straight line (linear regression) or we ﬁnd a piece-wise average in bins of D= 5 cm (local regression). Naming, without loss of generality, these ﬁtting curves, respectively, y= y(x) and y= y(x), we quantify the following (the segments naming is as in Tab. 1 third entry): • spread of trajectories along each grid line, that should be comparable to the individual pedestrians body sway amplitude (about 5 cm [30]). We consider for each x-location parametrizing a line the quantity z(x) = y(x)−y(x) where y(x) is a generic measurement of coordinate y at position x. Note that z(x) is approximately zero-centered at each x. Our benchmark quantiﬁes likewise it holds for σ; • distance between linear ﬁts over parallel lines, that should be constant. We score them with slopes, such as the following, for the case of segments AK, BL (for the other segments the formula works similarly) • angles between linear ﬁts over perpendicular lines, that should be 90 we score this as follows (generalization for the other angles is not reported) Test 4: Trajectory accuracy in controlled environment We target the capability of tracking pedestrians for extended time periods and along complex trajectories. We divide the measurement domain in regions S, S, S, . . ., and ask each participant, id, from a set of N to stand in a region Sand walk to an assigned destination S choice taking roughly ∆T ≈ 30 s. Origin and destination regions are assigned exclusively to a single pedestrian. With few participants, e.g. N≈ 12, the average density is low during this test. However, instantaneously we have extremely high densities due to short distances between ﬁrst neighbors, this makes tracking very challenging. A recorded trajectory is considered correct when its origin and destination respectively lie within the boundaries of the assigned origin-destination pair (S, S). The ﬁnal score is the percentage of correct trajectories. To increase the diﬃculty, (stationary) pedestrians standing outside all the regions S measurement domain. Test 5: Trajectory accuracy in real-life environment Finally, we test in a real-life environment the capability of tracking pedestrians without interruptions. We deﬁne an inner region, S, in which no trajectory can physically start or terminate. Each trajectory recorded in a time window ∆T ≥ 1 day, that enters the domain S, is classiﬁed according to its quality: 1. correct: neither the trajectories initial nor ﬁnal point lay inside region S 2. faulty termination: the trajectory terminates inside region S We report the percentage of trajectories correctly tracked A(5), approximating the total number of trajectories as the correct trajectories plus broken trajectories. In formulas this reads where broken trajectories are interrupted paths consisting of two or more trajectory pieces. Because one trajectory piece must enter domain Sand another must leave this domain we can approximate broken trajectories as Participants walk in a circular path, thereby crossing a virtual line (in red). The test reports for every minute the error between the sensor estimated and the ground-truth crowd-ﬂux across the (red) virtual line. The number of participants inside a predeﬁned area is kept constant (e.g. N = 8). The test reports the relative error between the estimated, N (t), and ground-truth number of pedestrians, N, inside the area. Participants walk in a row in a straight line. The test reports the standard deviation in the distance between the recorded data point and the local and linear regressions. Additionally, we report the angles and distances between the linear regressions to identify distortions in the measurement setup. Table 1: Synthetic description of the benchmark tests including key features and an illustration. The metric used to score the test which we supplemented with advised quantities for the test duration, ∆T , and number of participants, N , is included. Cells with advised quantities have a gray background. In this section we report and elaborate on the benchmark results for the pedestrian tracking systems introduced in Section 3. We iteratively improved each test by trying diﬀerent methods and variants. This optimization process, in combination with the ever-changing nature of the real-life testing environments, caused, for some tests, minor diﬀerences between the two setups. For each test, we report synthetic results plus illustrations taken from either setups Test 1: Line-based crowd ﬂux estimation. In Fig. 4 we report a sample of captured trajectories and the results, in graph form, for the TU/e measurement setup. Speciﬁcally, in Fig. 4b we report the minute-by-minute estimation accuracy (blue bars), the cumulative pedestrian count (red line), and the average crowd ﬂux (black slope). Synthetic results for both setups are in Tab. 2, which includes, in time windows t< t < tof 1 minute, the ground-truth pedestrians count, N(t, t), the crowd ﬂux estimation error, N (t, t) − N racy, A(Eq. 1). The commercial setup is tested with an average crowd ﬂux of J whereas the TU/e measurement setup is tested with a more challenging J sults of the TU/e and commercial setups are A= 95% and A the relative diﬃculty of the commercial setup can be quantiﬁed to ∼ 1/3 due to the lower crowd ﬂux. Test 2: Local density estimation. We report, for the commercial setup, the test layout in Fig. 4a and the test results in Fig. 4b. For the commercial setup we deﬁne two regions S (cf. Fig. 4a), both with an area of 6.2 m. In the case of the TU/e setup we employed only one larger region S = 150 m. To improve test reliability, we perform multiple runs for each setup, thereby realizing four density estimations each A − D, see Tab. 3. In the table we report also the ground-truth region occupation, N, the local density, ρ = A(Eq. 2). The commercial setup shows a systematic error in the density estimation of region S, most likely related to false positive detection of 2 stationary objects. Therefore, in Tab. 3, we include an additional column containing a corrected estimate A Participants walk in an irregular path from a predeﬁned origin to a predeﬁned destination, passing in close proximity from each other. The test reports the percentage of trajectories that is accurately tracked from origin to destination without interruption. We deﬁne a domain, well within the sensor range, where no trajectory should originate or terminate. The test reports in real-life conditions the percentage of trajectories that is continuously tracked through that domain. (t, t), and the estimation accu- Figure 3: (a) Trajectories captured during test 1 by the TU/e setup, superimposed to the schematic illustration from Tab. 1. (b) Results of test 1 for the TU/e setup. Blue bars report the accuracy, A, on a minute-by-minute basis, red lines indicate measured (dark) and ground-truth (light) pedestrian count, N(t), and a black line indicates the slope i.e. the average crowd ﬂux, J 100 ped/min. Table 2: Synthetic results of test 1 for both pedestrian tracking setups. We report, on a minuteby-minute basis, the ground-truth number of pedestrians, N and the estimation accuracy, A. While testing the TU/e setup, we considered a crowd ﬂux of J= 100 ped/min, whereas in the commercial case, a far less challenging crowd ﬂux of J 30 ped/min was maintained. Therefore, the test of the commercial system can be considered relatively less diﬃcult. , the error in the count, N − N, Figure 4: (a) Measurement domain for the commercial setup. Red domains indicate regions S and Sboth with an area 6.2 m. (b) Results of test 2 for the commercial setup. The ﬁgure reports for all repetitions, (A − D), the measured pedestrian count, N(t). A color matching mark on the left y-axis indicates the ground-truth pedestrian count N report for A and C a systematic error corrected pedestrian count denoted A The left y-axis indicates pedestrian count whereas the right y-axis shows the corresponding crowd density ρ inside the 6.2 mregion. The inset shows an enlarged view of the graph part inside the black box. setup sustained an average local density of ρ = 0.85 ped/m, whereas the density across the TU/e measurement domain is a factor 10 lower. Because pedestrian localization is more challenging in dense crowds, we reﬂect the diﬀerence in pedestrian density in the relative diﬃculty. Throughout run D, the infrared sensor of the TU/e setup is overexposed by excessive sunlight. Reduced image quality causing false negatives results, for this run, in a lower density estimation accuracy. Test 3: Individual position detection. We report in Figure 5a, for the commercial setup, the recorded trajectories during test 3. We ﬁt a linear regression for every isolated set of trajectory pieces. The regressions accurately reconstruct the geometric structure that is followed by the participants i.e. closely resemble a grid of straight lines. We added the angles and distances between the grid lines to emphasize the correspondence. Figure 5b provides the isolated set of trajectory pieces belonging to grid line BE. We ﬁt a local (blue) and linear (red) regression through the trajectory pieces. Additionally, we report the spread along the grid line with histograms for z(x) (top) and z(bottom) annotated with test scores σ for the standard deviations, σand σ, for both setups. All standard deviations are the same order as typical body sway amplitude i.e. σ= 5 cm. The test is relatively more challenging for the TU/e setup which needs more sensors for the large measurement domain. In Table 5 we report the correspondence to the grid geometry in terms of the distance between trajectories on parallel grid lines D, and the angle between trajectories on perpendicular grid lines L for each repetition. Additionally, we and σ. We refer to Table 4 Table 3: Synthetic results of test 2 for both tracking setups. We report for the repetitions A − D the ground-truth number of pedestrians, N, the local density, ρ and the estimation error,  The TU/e setup estimates density over an area of S = 150m considers much smaller regions of S = 6.2m. Due to the lower crowd density the test of the TU/e setup can be considered relatively a factor 10 less diﬃcult. For the commercial setup we report additionally the estimation error after correction for systematic errors A grid geometry is reconstructed with high accuracy as the angles and the mutual distances in the recorded trajectories agree up to 99% with the original grid structure. Test 4: Trajectory accuracy in controlled environment. In Figure 6, we report side-by-side the trajectories recorded by the TU/e measurement setup during the three runs of test 4. Correct trajectories have a green and faulty trajectories a red color. Table 6 reports the test results for both setups indicating, for each run, the number of trajectories, N jectories, N, and the trajectory accuracy, A. The participants experience high instantaneous densities with almost body-to-body contact. Minimum mutual distances in the order 20 cm are recorded several times over the lifespan of their trajectories. Some tests of the commercial setup also contained additional stationary pedestrians to increase the local density, this is represented in the table with an extra column N. The TU/e setup records, over an area of S = 150 m 22 correct from a total of 30 trajectories whereas the commercial setup, on a much smaller area S = 50 m, scores 49 out of 64 trajectories. Both setups report a trajectory accuracy in the order of A≈ 75% (Eq. 6). This shows that in conditions with highly entangled trajectories tracking procedures can be imperfect, as only 75% of the trajectories are captured properly. Test 5: Trajectory accuracy in real-life environment. In Figure 7 we report all trajectories, recorded during ∆T = 1 day, partitioned in subsets: correct, faulty termination, and faulty origin (cf. Sec. 4) using an inner domain S≈ 38 m. The ﬁrst row of ﬁgures reports, per subset, the raw trajectories and the second row reports all the origins (red) and destinations (blue) of trajectories in the corresponding subsets. The percentage accurately tracked trajectories, A determined to be 79%, which is in the same order as the trajectory accuracy test in controlled conditions. This shows that under normal operational conditions 79% of the trajectory recordings is interrupted and broken into smaller pieces. In this contribution we presented a benchmarking suite for pedestrian tracking systems. The suite is light-weight and easily reproducible as it only contains a minimal set of 5 tests. The developed tests are tailored to take minimal eﬀorts, taking typically less than two hours in total, Figure 5: (a) Recorded trajectories by the commercial setup during test 3. The ﬁgure reports a linear ﬁt for every set of trajectory pieces. The regressions reconstruct the geometric structure followed by the participants. Additionally, we report the distances between parallel ﬁts and the angles between perpendicular ﬁts. (b) Isolated trajectory pieces for grid line BL. We ﬁtted a linear (blue) and local (red) regression through the trajectory pieces. Additionally, we report the histograms of z(x) (top) and z(x) bottom including a Gaussian ﬁt (pink). Table 4: Synthetic results of test 3 for both tracking setups. The table reports for each grid line, the number of overhead sensors, N, and the standard deviation with respect to the local, σ and to the linear, σ, regression. σ[cm] σ[cm] Table 5: Synthetic results of test 3 for both setups. The table reports how accurate the recorded trajectories agree with the grid geometry. In particular, we report the accuracy in reconstructing parallel grid lines, D, and the accuracy in reconstructing perpendicular grid lines, L Figure 6: Trajectories captured by the TU/e setup during test 4. Green lines indicate correct trajectories whereas red lines indicate faulty trajectories. Trajectory origins and destinations are indicated with spheres and crosses respectively. Table 6: Synthetic results of test 4 for both setups. We report for runs A − D the number of participants, N, the number of correctly tracked trajectories, N Additionally we report for the commercial setup the number of (stationary) objects, N , and the test accuracy, A. Figure 7: The recorded trajectories by the commercial setup during test 5. The upper row with ﬁgures reports the trajectories, partitioned per subset, and the bottom row reports the corresponding origin-destinations pairs. The black rectangle indicates the inner domain, S while requiring only a dozen participants. Each test accurately targets the validation of one of the following key components of pedestrian tracking: line-based crowd ﬂux estimation, local density estimation, individual position detection, and trajectory accuracy. The tests output quality factors expressed as single numbers. The combination of tests focuses on error-prone features like personobject recognition, and multi-sensor stitching. From a civil engineering standpoint, the tests reﬂect observables connecting with immediate awareness of a facility (1. instantaneous usage, 2. crowding distribution), as well as with longer-term eﬃciency and design (3. localization, 45. tracking, i.e. usage modes). Facility usage and crowd distributions can indicate potentially hazardous capacity issues and overcrowding in an early stage, while localization and tracking enable eﬃciency improvements such as separation of usage mode. Together with the benchmarking suite we presented the benchmark results of two real-life pedestrian tracking systems, one commercial and one developed in academia. These test results, synthesized in Tab. 7, are meant as a reference of the state-of-the-art for new tracking installations and as a standard for novel tracking technologies. The higher accuracy of the commercial setup can be easily explained by its smaller measurement setup using fewer sensors. The high error in the density estimation test for the commercial setup is most likely caused by a systematic error due to faulty person-object diﬀerentiation. This emphasizes the great importance of background removal and proper sensor calibration. The benchmark results show us that optic-based tracking systems can estimate crowd ﬂuxes and local densities, and localize pedestrians with high accuracy. The biggest open challenge is Lagrangian time-tracking in case of complex and highly intertwined trajectories by pedestrians walking in close proximity. In this case the systems scored an accuracy of about 75%. 1.Line-based crowd ﬂuxestimationA95% 2.Local densityestimationA97% 4.Trajectory accuracy incontrolled environmentA73% 5.Trajectory accuracy inreal-life environmentANA Table 7: Table with the aggregated results of each test for both tracking setups. The table contains a column for each test. The top two rows show the name of the test and the metric used to score the test. Underneath we have two rows For each tracking setup indicating how the setup scored and the diﬃculty of the test. This work is part of the HTSM research program “HTCrowd: a high-tech platform for human crowd ﬂows monitoring, modeling and nudging” with project number 17962, and the VENI-AES research program “Understanding and controlling the ﬂow of human crowds” with project number 16771, both ﬁnanced by the Dutch Research Council (NWO). The authors want to thank Dr. Antal Haans and Dr. Philip Ross for their eﬀort in the establishment of the TU/e tracking setup.