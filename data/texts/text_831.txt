Data-driven prediction of future observations is a fundamental problem. Here our focus is on applications where the data Z = (X, Y ) consists of explanatory variables X ∈ X ⊆ R for some d ≥ 1, and a response variable Y ∈ Y. The two most common examples of such applications are regression and classiﬁcation, where Y is an open and ﬁnite subset of R, respectively. We consider both cases in what follows. pairs from an exchangeable process P, a value x “prediction” here we mean quantifying uncertainty about Y i.e., depending on the observed data Z tive on prediction uncertainty quantiﬁcation is the construction of a suitable family of More speciﬁcally, we observe a collection Z= {Z= (X, Y) : i = 1, . . . , n} of n , and then the goal is to predict the corresponding future response Y∈ Y. By prediction sets representing collections of suﬃciently plausible values for Y Vovk et al. (2005), Campi et al. (2009), Kuleshov et al. (2018), and Equation (21) below. While prediction sets are practically useful, there are prediction-related tasks that they cannot perform, in particular, it cannot assign degrees of belief (or betting odds, etc.) to all relevant assertions or hypotheses “Y is to develop what we refer to here as a probabilistic predictor, i.e., a probability-like structure (precise or imprecise probability) deﬁned on Y, depending on Z designed to quantify uncertainty about Y evant assertions; see Equation (17) below. The most common approach to probabilistic prediction is Bayesian, where a prior distribution for P is speciﬁed and uncertainty is quantiﬁed by the posterior predictive distribution of Y Other non-Bayesian approaches leading to predictive distributions include Lawless and Fredette (2005), Coolen (2006), Wang et al. (2012), and Vovk et al. (2018). tion with prediction sets and with probabilistic predictors. One does not need a full (precise or imprecise) probability distribution to construct prediction sets and, moreover, sets derived from a probabilistic predictor are not guaranteed to satisfy the frequentist coverage probability property that warrants calling them genuine “prediction sets.” Therefore, the only possible motivation for going through the trouble of constructing probabilistic predictor, Bayesian or otherwise, is that there are important prediction-related tasks that prediction sets cannot satisfactorily handle. So it must be that the belief assignments provided by a (precise or imprecise) probability are a high priority. Strangely, however, the reliability of probabilistic predictors is only ever assessed in terms of (asymptotic) coverage probability properties of their corresponding prediction sets. Our unique perspective is that, since belief assignments are a priority in applications, there ought to be a way to directly assess the reliability of a probabilistic predictor’s belief assignments. variables Y for probabilistic predictors. Roughly, their validity condition requires that the event “the probabilistic predictor, depending on the observed data, assigns a relatively high degree of belief to A and Y are given in Deﬁnitions 1–2 below. It turns out these notions of validity have some important consequences, imposing certain constraints on the mathematical structure of the probabilistic predictor. Indeed, we show that in order for a probabilistic predictor to achieve validity in the sense of Deﬁnition 2, and to achieve the desirable behavioral and statistical properties described next, it must take the form of an imprecise probability. explore their behavioral and statistical consequences. First, we show that even the weaker validity property in Deﬁnition 1 implies that the probabilistic predictor avoids sure loss, hence is not internally irrational from a behavioral point of view. We go on to show that prediction-related “tests” derived by a valid probabilistic predictor control frequentist Type I error. Moreover, under the stronger notion of validity in Deﬁnition 2, prediction sets derived from the probabilistic predictor achieve the nominal frequentist coverage probability. The take-away messsage is that a valid probabilistic predictor provides the “best of both worlds,” in the sense that it allows the data analyst to simultaneously achieve both desirable behavioral and statistical properties. Before moving forward, it is important to distinguish between uncertainty quantiﬁca- For prediction problems without explanatory variables, where only the (response) After describing the basic problem setup and introducing these notions of validity, we is how to construct one? The probabilistic predictor we construct here is largely based on the general construction of a valid inferential model (IM) as described in Martin and Liu (2013, 2015b). The setup in the aforementioned references assumes a parametric family of distributions for Y or for Y given X—the prediction problem under such assumptions was addressed in Martin and Lingham (2016). Here, however, we aim to avoid such parametric assumptions and, for this, we use particular extension of the so-called generalized IM approach developed in Martin (2015, 2018). The basic idea is that a link—or association— between observable data, quantities of interest, and an unobservable auxiliary variable with known distribution can be made without fully specifying the data-generating process. Like the conformal prediction approach of Vovk et al. (2005) and others, we establish this association using only the assumption of exchangeability, hence we can avoid any parametric model assumptions. There is also an interesting connection between conformal prediction and our proposed solution. for probabilistic predictors is deﬁned and its consequences are investigated. After a brief background on the general IM theory, a generic construction from which the derived probabilistic predictor would be provably valid is given in Section 3. The speciﬁcs of this construction are presented in Section 4, in the context of regression. In Section 5, we show that the discreteness of Y in classiﬁcation problems may cause the IM random set output, from which the probabilistic predictor is derived, to be empty with positive probability. Two possible adjustments are provided, with the one based on “stretching” the random set being most eﬃcient. Section 6 gives some concluding remarks. Recall that there is an exchangeable process Z Zis a pair (X that it is exchangeable and supported on Z Section 1, a common strategy is to construct so-called prediction sets that achieve the nominal frequentist coverage probability. That is, a collection of functions C Z× X to subsets of Y, indexed by α ∈ [0, 1] and n ≥ 1, deﬁnes a family of 100(1 − α)% prediction sets for Y where “for all P” means “for all exchangeable distributions P supported on Z that the probability on the left-hand side above is with respect to the joint distribution of Z P is unknown so we cannot tailor C quantify uncertainty about Y are both practically relevant and not fully/satisfactorily resolved through the use of prediction sets. In particular, quantifying uncertainty about claims of the form “Y Given the desirable properties of a valid probabilistic predictor, the natural question The remainder of the paper is organized as follows. In Section 2, the validity property of X, the goal is to reliably predict the corresponding Y. As discussed in and Z= (X, Y) under P. This uniformity in P is needed because the true However, the continued interest in the construction of a probability distribution to for relevant A ⊆ Y, in a reliable way is desirable. To formalize this, we follow Cella and Martin (2021c) and deﬁne a probabilistic predictor as a map (z for notational simplicity, the probabilistic predictor’s dependence on the observed data zis encoded in the superscript “n” only. Then uncertainty quantiﬁcation about Y given z sample size is needed in order to properly deﬁne it. For example, if some standardization procedure is being employed, then it would be necessary to have n large enough to estimate standard errors. As a rule in what follows, if n is smaller than the necessary sample size, then we will silently take the probabilistic predictor to be vacuous, i.e., assign lower and upper probabilities 0 and 1, respectively, to every assertion. denote the σ-algebra of subsets of Y that are measurable with respect to the (common) marginal of the Y singletons, e.g., like the Borel σ-algebra. Then the lower and upper probabilities are capacities deﬁned on A, i.e., monotone set functions, taking value 1 at Y and value 0 at ∅. However, being “lower” and “upper” suggests a link between the two. We formalize by requiring that, for each z conjugate to the upper probability, and from sub-additivity is follows that hence the name “lower” and “upper” probabilities. Ordinary or precise probabilities are additive—and hence sub-additive—so they satisfy these condition with Π Moreover, all of the standard imprecise probability models—belief functions, possibility measures, lower/upper previsions—satisfy these conditions, so our assumptions corresponding to no loss of generality. Since we will be interested in the statistical properties of the probabilistic predictor as functions of the data, we will assume that (Z follows. For given data z probabilities represent where 1(B) denotes the indicator of the event B. Therefore, based on data z new feature x, if the investigator’s Π the gamble $1(Y to sell the gamble $1(Y the gamble. For this reason, Π , Π) is a pair of lower and upper predictive probabilities for the corresponding Y; and X= x, is provided by the function A 7→ (Π(A), Π(A)). We are deﬁning the probabilistic predictor for all n, but it could be that some minimum What kind of mathematical form does the function A 7→ (Π(A), Π(A)) take? Let A for Yis sub-additive. Then the lower probability Πis deﬁned as the dual or (A), Π(A)) is measurable for each n ≥ 1 and for each A ∈ A. The interpretation of the probabilistic predictor’s output is subjective and goes as the plausibility of the event “Y through a requirement that its predictions be reliable in a statistical sense. predictor, plus its interpretation is subjective, so virtually no construction can be ruled out at this point. However, the probabilistic predictor’s practical utility requires that the uncertainty quantiﬁcation derived from it be reliable in a certain sense. The particular sense we have in mind is statistical, but see below for some behavioral consequences. That is, we require that inferences drawn based on the probabilistic predictor not be systematically misleading. Based on the interpretations of the lower and upper probabilities described above, events of the general form and should they occur, put the investigator at risk of making erroneous predictions and incurring losses, monetary or otherwise. To protect the investigator from this risk, we impose the following condition on probabilistic predictors, ensuring that the aforementioned undesirable, risk-creating events are controllably rare. Deﬁnition 1. The probabilistic predictor (Z both of the following equivalent conditions hold: Here “for all (α, n, A, P)” is short for “for all α ∈ [0, 1], all n ≥ 1, all A ∈ A, and all distributions P for the exchangeable process Z equivalent by the duality in (2) and the “for all A” clause. to assign small upper probability to assertions about Y large lower probability to assertions about Y ensures that the data analyst is not making systematically misleading predictions. seem overly strong, but it turns out that there is an even stronger property that is needed and can readily be attained. This stronger property requires validity to hold uniformly in A, not just point-wise in A. In particular, the “for all A” clause on the outside of the probability statement in (4) will now be moved to the inside, allowing the choice of A in the bound to be data-dependent. This generalization will be important for technical reasons—see Proposition 3 below—but here we give some intuition in the gambling scenario described above. Consider that the agent’s opponents have access to the data (z strategic choices about which assertions A to negotiate with the agent. Of course, if the agent’s opponents can make these more sophisticated data-dependent plays and he is only able control errors for predictions speciﬁed in advance, then that could make his error rates unacceptably large. The following uniform-in-assertions validity guarantees protection against these strategic choices. So far, we have imposed eﬀectively no mathematical constraints on the probabilistic The key point, again, is that validity ensures the probabilistic predictor will not tend That the calibration property imposed in (4) is required to hold for all A ⊆ Y might Deﬁnition 2. The probabilistic predictor (Z nition 2 is stronger than validity in the sense of Deﬁnition 1. Indeed, the “for some A” inside the probability statement in (6) is eﬀectively a union of A-dependent events like those in (4) over all A. So if the union over A of these A-dependent events has probability bounded by α, then so would any individual event in that union. In general, this union is uncountable so one might anticipate issues with measurability, but it turns out that there are no such issues; see Section 2.3 below. The validity conditions above have a number of interesting implications. Below are two results of a very diﬀerent nature. First, despite validity’s focus on frequentist-style operating characteristics, it turns out that it has some important behavioral consequences, `a la de Finetti, Walley, and others. One example of this is Proposition 1, a generalization of the result presented in Cella and Martin (2021c). the lower/upper probabilistic predictor evaluated at A, minimized/maximized over all of its data inputs. Then an especially poor speciﬁcation of prediction probabilities is a situation where, for some A ⊆ Y, Ideally, the probabilistic predictor would mimic the true conditional probability at least in the sense that its average over data inputs would not be far from P(Y situation like in (7), where the probabilistic predictor is uniformly bounded away from P(Y undesirable outcome in (7) leads to sure loss in the sense of, e.g., Condition (C7) in Walley (1991, Sec. 6.5.2) or Deﬁnition 3.3 in Gong and Meng (2021). Fortunately, as we show below, the validity property in Deﬁnition 1 implies no sure loss. Proposition 1. Suppose that the probabilistic predictor, (z sure loss in the sense that (7) holds for some A ⊆ Y. Then validity in the sense of Deﬁnition 1 fails. Proof. We present the argument here for the case where γ argument for the γ As the name and the discussion above suggest, uniform validity in the sense of Deﬁ- ∈ A) in one way or the other, is a clear sign of trouble. More precisely, the so that (4) is equivalent to According to (7), there exists an A ⊆ Y and a threshold α ∈ [0, 1] such that Then from (10), with this choice of (A, α), Then (8) and, hence, (4) fails, so the claim follows. behaviorist consequences. This gives mathematical support to the following intuition: a method that is externally reliable across applications ought not be internally irrational in any one application. erties, and we will consider two diﬀerent questions. The ﬁrst concerns testing certain “hypotheses” about the next observation Y sell a certain asset when the price exceeds some ﬁxed level, say y quantify uncertainty about an assertion or hypothesis of the form Y and, in particular, decide if the new price being below the y to warrant taking quick action to sell. The following proposition establishes that the test derived from a valid probabilistic predictor controls frequentist Type I error at level α. Proposition 2. If the probabilistic predictor (z Deﬁnition 1, then the test described in (11) controls frequentist Type I error at level α in the sense that Proof. This is an immediate consequence of the deﬁnition of validity. In particular, compare the Type I error probability above to the left-hand-side of (4). the construction of a prediction set, i.e., a set of suﬃciently plausible values for Y It is interesting to see that a frequentist calibration property can have meaningful The second implication concerns the more classical frequentist-style prediction prop- Perhaps a more common—and arguably more challenging—prediction-related task is given the observed data. A natural way to construct a candidate prediction set from a probabilistic predictor is as follows: That is, C predictor assigns lower probability at least 1 − α. This is consistent with strategies used in the Bayesian literature for constructing posterior credible regions for inference and prediction. The following proposition shows that uniform validity implies that this is a genuine 100(1 − α)% prediction set in the sense that its frequentist coverage probability is at least the advertise/nominal level 1 − α. Proposition 3. If the probabilistic predictor (z sense of Deﬁnition 2, then the derived set (12) is a genuine 100(1 − α)% prediction set in the sense that (1) holds or, equivalently, that By uniform validity, in particular, Equation (5), the right-most event has P-probability no more than α, proving the claim. diction sets. This is in addition to the behaviorist no-sure-loss property that is implies by the weaker validity condition. After some additional high-level implications of (uniform) validity in Section 2.3, a general construction of a (uniformly) valid probabilistic predictor is presented in Section 3. Before proceeding to our proposed construction of a (uniformly) valid probabilistic predictor, we believe that it is helpful to discuss how some other developments in the literature compare to what was presented above. predictor equal to the true conditional probability, i.e., satisﬁes the validity-related properties (3) and (4), but only at the known P. Similarly, one can also easily show that the set C at least 1 − α, but only at the known P. However, the validity property, as stated in Deﬁnition 1, requires those inequalities to hold for all P; this uniformity is important because P is virtually always unknown applications, so its knowledge cannot be assumed C(Z, X) 63 Y⇐⇒ Y6∈{A : Π(A) ≥ 1 − α} As expected, a uniformly valid probabilistic predictor leads to reliable frequentist pre- If P was assumed known, then it follows immediately from (9) that the probabilistic when constructing a probabilistic predictor. While a formal statement and proof of the following claim presently escapes us, it seems intuitively clear that there are no probabilistic predictors with the mathematical form of a precise/additive probability that are valid in the sense of Deﬁnition 1. If this claim is true, then it provides a version of the false conﬁdence theorem (Balch et al. 2019; Martin 2019) in the context of prediction: that is, the only way to achieve valid probabilistic prediction is via a proper imprecise probability (Π property. More generally, one could start with a suitable credal set P, a collection of candidate distributions P, and deﬁne the probabilistic predictor’s upper probability as and lower probability with sup replaced by inf. Then the same argument presented above for the known/assumed-P case implies that the validity-related properties (3) and (4) hold, but only for P ∈ P. If reliable choice of set P were available in a given problem, then of course it should be used, and one way it could be used, while maintaining validity, is via the lower and upper envelop construction described above. However, if no such information is available, then taking P to be all distributions or blindly assuming that the chosen proper subset P contains the true P would not be satisfactory options. An interesting open question is how genuine prior information in the form of a proper subset P of probabilities could be incorporated into the proposed construction in Section 3. Indeed, a necessary and suﬃcient condition for uniform validity is that where The proof—which follows by showing that both probabilities on the left-hand sides of (5) and (6) are equal to the left-hand side of (14)—is an immediate consequence of the probabilistic predictor’s monotonicity property. This explains why there are no measurability issues when working with the (potentially) uncountable unions related to the “for some A” in (5) and (6). At least in the case of an absolutely continuous additive/precise probabilistic predictor, even that based on the true P, it is clear that (14) cannot hold. So uniformly valid probabilistic prediction requires imprecise-probabilistic considerations. In particular, (14) closely resembles the properties satisﬁed by p-values from hypothesis testing in classical statistics. It is also eﬀectively the same as the so-called fundamental frequentist principle, or FFP, in Walley (2002). This connection to classical frequentist statistics strongly suggests that, to achieve uniform validity, the probabilistic predictor have the mathematical form of a consonant belief/plausibility function or a necessity/possibility measure. Our proposed probabilistic predictor construction in Section 3 indeed implies this special form. in the imprecise probability literature. In particular, using our terminology and notation, Denœux (2006) deﬁnes a probabilistic predictor to have a “100(1 − α)% conﬁdence It is not just precise/additive probabilities that have trouble achieving the validity A closer look at the uniform validity property can provide some helpful insights. The condition (14) is familiar, at least when connections are drawn to other contexts. Finally, we mention here connections with certain notions of “frequency-calibration” property,” for a ﬁxed α ∈ [0, 1], if This and other variations are discussed more recently in Denœux and Li (2018). Obviously, since the event on the left-hand side does not explicitly depend on α, it must be that the probabilistic predictor depends implicitly on the speciﬁed α value, and various approaches to incorporate this α-dependence so that the above property can be achieved are given in the aforementioned references. The key observation is that calibration requires some relation between the probabilistic predictor for Y distribution of Y the true conditional probability in a strict sense as in (13) or a less-strict sense as in the above display. This same kind of dominance appears in our deﬁnition of validity, but through the alternative formulation in (9), speciﬁcally, That is, our notion of validity implies that, when restricted to data sets (Z which Π be any bigger on average. An inferential model (IM) is a data-dependent probabilistic quantiﬁcation of uncertainty about unknowns, like the probabilistic predictor described above. The diﬀerence is, as the name suggests, that IMs are focused on the statistical inference problem, where the unknowns are ﬁxed quantities. IMs have connections to various other approaches to statistical inference, some that quantify uncertainties with ordinary probabilities, e.g., Bayesian inference (Martin and Liu 2015a), ﬁducial inference (Fisher 1935; Taraldsen and Lindqvist 2013), and generalized ﬁducial inference (Hannig et al. 2016), as well as with imprecise probabilities, e.g., Dempster–Shafer theory (Dempster 1967, 1968, 2008, 2014; Shafer 1976) and other belief function frameworks (Denœux 2014; Denœux and Li 2018). While there are some technical diﬀerences resulting from the unknown being ﬁxed in the inference case and random in the prediction case, the common goal of providing valid uncertainty quantiﬁcation is more or less the same. Therefore, we expect that the key ideas behind the construction of a valid IM for inference ought to be applicable to the prediction problem as well, modulo a few adjustments. Below we describe the key ideas behind the IM construction and how they can be employed to construct a probabilistic predictor that is valid in the sense described in Section 2. observable data and unknown quantity of interest with an unobservable auxiliary variable whose distribution is fully known. In the early work on IMs, this association was usually a complete description of the data-generating process. For example, suppose we have, say, n independent and identically distributed (iid) observations Z the vector Z would eﬀectively be a description of how to generate data Z The general IM construction is composed of three steps. The A-step associates the where U distribution, e.g., Unif(0, 1). While such an association can always be written down, there are a few obstacles one might face when trying to complete the IM construction: However, Martin (2015, 2018) showed that the A-step’s requirements can be relaxed. All that is needed is an association that relates a suitable function of both the observable data and the unknowns to an unobservable auxiliary variable. Besides the examples presented in Martin (2015, 2018), this idea has been applied to meta-analysis and survival analysis in Cahoon and Martin (2020, 2021). An extension of that initial generalization, which can avoid even speciﬁcation of a statistical model was recently developed in Cella and Martin (2021a), with a focus on machine learning applications. construction proceed exactly as described in, say, Martin and Liu (2013). Roughly, the P-step introduces a random set that aims to predict or guess the unobserved value of the auxiliary variable. Easy to arrange properties of this user-speciﬁed random set ensure that the guessing of the auxiliary variable is done in a reliable way, which turns out to be fundamental for validity. Next, the C-step combines the results of the A- and P-steps, yielding a new, data-dependent random set on the space where the quantity of interest resides. Finally, this random set’s distribution determines lower and upper probabilities that can be used to assign degrees of belief and plausibility to any relevant assertion about the unknown quantities of interest. Below we describe the generalize IM construction in more detail for the prediction problem at hand. IM formulation described above. So the kind of association needed is one that identiﬁes a function of (Z (generalized) IM construction proceeds as follows. A–step. Suppose there exists a function φ Q, of the random variable φ P. Then associate the observable data Z unobservable auxiliary variable U as follows: For our case where Z association deﬁnes a set-valued mapping P–step. Deﬁne a nested random set U (see below) on the space U of the auxiliary variable U, designed to reliably contain realizations of U ∼ Q distribution of the random set U will be denoted by R • When the dimension of Uis greater than that of θ, as is often the case, an eﬃciencymotivated dimension-reduction step is recommended by Martin and Liu (2015a), but this can be challenging. • The association itself requires (more than) a fully speciﬁed statistical model for data, which may not be available in the application at hand. Once a generalized association has been set, the remain steps of the (generalized) IM For prediction, the unknown is Y, not a model parameter in the IM and generalized C–step. Combine the results of the A- and P-steps to get the data-dependent random set Then the distribution of this new random set, derived from the distribution of U, determines the probabilistic predictor for Y Remark 1. If Y the probabilistic predictor in (17) is needed. This will be relevant for the classiﬁcation problem in Section 5. identifying the function φ Other examples were explored previously in Martin and Lingham (2016) where P was assumed to belong to a speciﬁed parametric family of distributions. The additional structure provided by the parametric family makes it possible to borrow much of the theory in Martin and Liu (2015b). Here, however, no parametric assumptions about P are being made, so diﬀerent techniques are required. The remainder of this section investigates the properties of the abstract probabilistic predictor construction above. its support, one is a subset of the other. As a consequence, the derived probabilistic predictor is a consonant plausibility function (Shafer 1976, Ch. 10) or, equivalently, a possibility measure (Dubois and Prade 1988), which means it is completely determined by its corresponding plausibility contour function. That is, deﬁne Then the probabilistic predictor’s upper probability can be equivalently written as This alternative expression is important for at least two reasons. First, the plausibility contour is an ordinary function, which makes it relatively easy to visualize and compute with compared to a set-function. Second, the consonance property appears to be fundamental to achieving validity both in the inference and prediction contexts; see, for example, Martin (2021). struction is (uniformly) valid. This requires stating the required conditions on U more precisely. Since the cases in the following sections involve an auxiliary variable U that is discrete, we will focus on the discrete case. For the corresponding theory when U has a continuous distribution, see Martin and Liu (2015b). First, deﬁne the random set’s containment function The above construction is abstract for the purpose of generality. The challenge is in The random set U is assumed to be nested in the sense that, for any two sets in It remains to establish that the probabilistic predictor resulting from the above con- Then the required link between Q where I link between the auxiliary variable’s distribution Q R, we are ready to state and prove the main result. Theorem 1. If the random set U satisﬁes (20), and if Y probability 1 for P-almost all (Z or equivalently (19), is uniformly valid in the sense of Deﬁnition 2. The R respectively, so these two random variables—the ﬁrst as a function of (Z the second as a function of U ∼ Q that f(U) is uniform and, therefore, so is π needed to the deﬁnition in (17), as mentioned in Remark 1, to address this. We will discuss this below in the speciﬁc application to classiﬁcation in Section 5. and the general results in Propositions 1–3 in the previous section. Corollary 1. Under the conditions of Theorem 1, the probabilistic predictor deﬁned in (17) or, equivalently, in (19) Moreover, there is an equivalent form of that prediction set in terms of the plausibility contour, namely, that is computationally more convenient and, of course, also achieves the nominal frequentist coverage probability. subjective/behaviorist and objective/frequentist properties simultaneously. Two speciﬁc and practically relevant applications of this construction in the context of regression and classiﬁcation will be presented in Section 4 and 5, respectively. which is easiest to understand in the context of calibrated prediction sets as in (1). That is, the conditional coverage probability of the prediction set is -probability of the left- and right-hand side events are π(Y) and f (U), The non-emptiness condition is not necessary for validity, but some adjustment is The following is an immediate consequence of the uniform validity conclusion above probability in the sense of (1). Consequently, the proposed probabilistic predictor construction achieves the desired It is important to point out that the kind of validity being considered here is marginal, a function of x function, with respect to the marginal distribution of X This marginal coverage guarantee, of course, says nothing about the conditional coverage at any particular x relevant, and we discuss this brieﬂy in Section 6. Recall that the A-step requires the speciﬁcation of a real-valued function φ the distribution of φ sisting of the observable (Z transformation Z where Z Yto a prediction derived from Z disagree. For example, to each Z to get an estimated mean response ˆµ residual The critical property of Ψ is that it be symmetric in the elements of its ﬁrst vector argument. This symmetry guarantees that the assumed exchangeability in Z preserved when Z write T Y’s are continuous and Ψ is non-constant on sets of Y the one in (23), so that there are no ties, a well-known consequence of exchangeability of T, . . . , T discrete uniform law on I plete the A-step of the IM construction by writing a version of (16) as follows: where r(·) is the ascending ranking operator. The choice of T other T it does implicitly depend on all the T procedure. In summary, to complete the A-step, the only task for the data analyst is the speciﬁcation of Ψ. realization of the auxiliary variable U, introduced above, is needed. Consider It is straightforward to show that this random set satisﬁes the critical calibration property (20). Moreover, this choice also makes intuitive sense, as U always includes the value 1. (Z) where necessary to highlight that dependence. In regression, where the Having identiﬁed a function of (Z, Z) whose distribution is known, we can com- ’s in (24) is simply because Tis the one that holds the to-be-predicted value, , in special status. Note that, while it appears this expression only depends on T, For the P-step, the speciﬁcation of a nested random set targeting the unobserved This is desirable given the ascending ranking operator in (24) because it implies values of Y that arise from the association (24). Here and below, note that z observed z as described in the previous section, It is easy to see that Y contour function for Y As Y needed to deﬁne a probabilistic predictor and, consequently, quantify uncertainty about any assertion A ⊂ Y of interest. For example, an upper probability about A would be given by (19), which can easily be approximated by sequence of Theorem 1. Consequently, this probabilistic predictor satisﬁes (4), so we are guaranteed that the assignment of small (large) upper (lower) probabilities that happen to be true (false) will be controllably rare, which prevents the data analyst from making systematically misleading predictions. with n = 200, and let Y µ(x) = sin Figure 1 displays the data, the true regression function µ(x) and the ﬁtted regression curve ˆµ(x) based on a B-spline with 12 degrees of freedom. A 95% prediction band is also displayed, derived by (21) and x developed here and the powerful conformal prediction presented in Vovk et al. (2005). The careful reader may have recognized the Ψ function in the A-step of our construction as the so-called non-conformity measure, an essential component in the conformal prediction framework. Moreover, the basic output from the IM construction presented below is the plausibility contour in (26), which is precisely conformal prediction’s p-value or transducer. The theory in Vovk et al. (2005) takes this conformal transducer, which is uniformly distributed as stated in Theorem 1, and constructs a prediction set as in (21) with the prediction coverage probability property as in (1). Apparently it was recognized only recently (Cella and Martin 2021c) that the conformal prediction output could be converted into a valid probabilistic predictor in the sense of Deﬁnition 1, one that can make valid belief assignments, by treating the transducer as the contour of a consonant that make the residual Tsmall will be assigned high plausibility. Finally, in the C-step, U is combined with the u-indexed collection of sets (U) is both nested and non-empty, its contour function above is all that is Uniform validity of the probabilistic predictor derived in this Section is a direct con- For illustration, consider the following example. Let X, . . . , Xbe iid Unif(0, 1), We end this section pointing out an important connection between the prediction IM Figure 1: Panel (a): Data and the plausibility contours at selected values of x. Panel (b): Data, the true mean curve (heavy line), the ﬁtted B-spline regression curve (thin line), and the 95% pointwise prediction band. plausibility function via (19). We refer to this general probabilistic predictor construction as “conformal + consonance,” and all it requires is that the conformal transducer π a plausibility contour function, i.e., This is easy to verify in cases like regression where Y is a continuous random variable. Indeed, for the Ψ function in (23), the supremum is attained at y = ˆµ cases, like in classiﬁcation where Y is discrete, the “conformal + consonance” construction is not so straightforward. We discuss these considerations next in Section 5. In Section 4, we found that the A-step boils down to the speciﬁcation of a suitable real-valued, exchangeability-preserving function Ψ, which Vovk et al. (2005) refer as a non-conformity measure. In binary classiﬁcation problems, a Ψ function like in (23) can also be used here by encoding the two possible values of Y However, when Y has more than two labels and they are not in an ordinal scale where the assignment of diﬀerent numbers to them is justiﬁed, there is no natural way to measure the distance between labels. Consequently, we cannot measure how wrong a prediction is—it is simply right or wrong (Shafer and Vovk 2007). To circumvent this, Vovk et al. (2005) suggest the following non-conformity measure based on the nearest-neighbor method for classiﬁcation: where d is the Euclidean distance. In words, Ψ(Z element in X label equal to Y Vovk (2007) recommend taking the ratio also to be 0. Other non-conformity measures for classiﬁcation problems can be found in Vovk et al. (2005). namely the identiﬁcation of Ψ, so that Z changeability, and the continuity of the T continuous, so there could be ties in the T longer uniform distributed on I cally no larger than the discrete uniform distribution it would take if there were no ties. This leads to an “association” of the form But for situations like this where the association involves a stochastic inequality, the general arguments in Martin and Liu (2015c, Sec. 5) imply that the inequality can be ignored and the association (24)—with stochastic equality—can still be used. gously to that in the previous section: the A-step is completed by writing (24), the random set (25) is chosen in the P-step to target the unobserved realization of the auxiliary variable U, and, in the C-step, the ingredients in the A- and P-steps are combined to get Y of Y, it is possible that Y in Section 3, in these cases, some adjustment to the probabilistic predictor in (17) is necessary to avoid the counter-intuitive “conﬂict” cases where realizations of the random set Y be meaningful, but we defer this discussion to Section 6. of the random set Y event that the random set is non-empty, which happens to be equivalent to Dempster’s rule of combination (e.g., Shafer 1976, Chap. 3). For example, the post-conditioning plausibility contour is given by It is easy to see that conditioning simply rescales the original plausibility contour, making it larger at each y this conditioning adjustment—which only inﬂates its plausibility contour values—cannot fail to be valid. This inﬂation does, however, suggest a potential loss of eﬃciency, e.g., larger prediction sets in (21). ciency, is based on a suitable stretching of the original random set; see, e.g., Ermini Leaf and Liu (2012) and Cella and Martin (2019). Roughly, those U such that Y correspond to “conﬂict cases,” and Dempster’s conditioning rule simply removes these conﬂict cases and renormalizes the U-probabilities. As an alternative, Ermini Leaf and Liu (2012) suggested to stretch those conﬂict U cases just enough so that Y Two factors were fundamental to the speciﬁcation of the association (24) in Section 4, Having identiﬁed the appropriate association, the IM construction proceeds analo- (U) happens to be empty. There is a sense in which empty prediction sets could There are two available adjustments to account for the potentially empty realizations The second adjustment strategy, designed to preserve validity without sacriﬁcing eﬃnon-empty. Their formulation was in the context of inference under non-trivial parameter constraints, but here we apply this to classiﬁcation. There are only ﬁnitely many y collection of ranks that are possible for the given Z is empty if and only if U has empty intersection with U cases mentioned above can be alternatively deﬁned as realizations of U that have empty intersection with U out the conﬂict U, we stretch it to a suitable U controls how far U is stretched toward U Following Ermini Leaf and Liu (2012), the parameter e is chosen as the smallest value at which the intersection of U In summary, in the stretching IM, the IM’s original random set output Y placed with Y tor derived from it valid. It is also more eﬃcient than conditioning since it avoids globally inﬂating the plausibility contour via renormalization, as the following example highlights. describing the primary food choices and lengths of n = 39 male alligators caught in Lake George, Florida. Assume the 40th caught alligator is two meters long, i.e., X The goal is to predict Y The corresponding plausibility contour, as given in (18), is represented by the solid lines in Figure 2(a). By thresholding it at any α > 0.6 we obtain 100(1 − α)% prediction sets that are empty, which is undesirable. sented by the dashed lines in Figure 2(a). To calculate the plausibility contour under ˆe = min{e : U∩ U6= ∅} = For illustration, consider the data in Table 1, taken from Agresti (2003, p. 304), The plausibility contour conditioned on (30) 6= ∅ is easy to evaluate, and is repre- Table 1: Primary food choice (I, invertebrates; F, ﬁsh; O, other) and lengths (in meters) for n = 39 male alligators (Agresti 2003, p. 304). the stretching approach, we obtain, after some calculations, U min U where U and the dotted lines in Figure 2(a) illustrate its corresponding plausibility contour. Note, ﬁrst, that empty prediction sets are eliminated with both the conditioning and the stretching adjustments. Second, for any α, the 100(1 − α)% prediction sets derived from the stretching adjustment are no larger than the corresponding ones derived from the conditioning adjustment, which indicates that the former is no less eﬃcient than the latter. Another way to see this is through the diﬀerence between the upper and lower probabilities derived by the respective probabilistic predictors. Dempster (2008) referred to this gap as the “don’t know” probability. Of course, between two valid probabilistic predictors, the one with less “don’t know” is preferred because it is more eﬃcient. Figure 2(b) shows the upper and lower probabilities for the singleton assertions {I}, {O} and {F }, for both strategies. Clearly, stretching leads to a more eﬃcient probabilistic predictor. the USA Forensic Science Service, available in the UCI Machine Learning Repository (Dua and Graﬀ 2017). = 17, ∼ Unif(1, 2, . . . , 40). Therefore, To further see this gain in eﬃciency we consider the Glass Identiﬁcation data set from Figure 2: Panel (a): Plausibility contours in Equation (18), derived from an IM construction with no adjustment (solid lines), conditioning adjustment (dashed lines) and stretching adjustment (dotted lines). Panel (b): Upper and lower probabilities for the singleton assertions {I}, {F } and {O} derived from an IM construction with the conditioning adjustment (solid lines) and the stretching adjustment (dashed lines). These predictions are based on a new alligator of length x Table 2: Coverage probabilities and average size of 95% prediction sets in (21) derived from an IM construction with conditioning and stretching adjustment. a categorical variable—with six categories, including “containers” and “headlamps”—is the response variable. The nine remaining variables, which describe the oxide content, i.e., Na, Fe, K, etc., are the explanatory variables. Classiﬁcation of types of glass is relevant in criminology applications, where glass fragments left at the scene of the crime may be important evidence if correctly identiﬁed. To evaluate the performance of the IM in classifying glass fragments, we randomly split the data in half and train both the conditioning and stretching strategies in the ﬁrst half, with Ψ function as in (28). Table 2 shows the empirical coverage probabilities and the average sizes (cardinality) of 95% prediction sets for the responses in the second half of the data. As expected, both strategies lead to valid predictions, but stretching is slightly more eﬃcient. + consonance” construction is valid according to Deﬁnition 1, given that the conformal transducer π from the continuity of Y , and the derived probabilistic predictor is equivalent to the Recall from Section 4 that the probabilistic predictor derived from the “conformal one that would be obtained from an IM construction (assuming both use the same Ψ function). In classiﬁcation problems, however, (27) may not hold because Y is discrete. This implies the “conformal + consonance” cannot be applied directly without some adjustment. This is not surprising given that similar adjustments were needed in the IM construction discussed above too. Consider the following two adjusted conformal transducers: and where ˆy = arg max for the diﬀerent y ∈ Y and divide them by their maximum, and ¨π conformal transducer values except for its maximum, which is assigned the value 1. That both adjusted transducers reach the value 1 makes the probabilistic predictors derived by them, through (19), valid in the sense of Deﬁnition 1. It is also easy to see that these probabilistic predictors obtained from ˙π derived from the IM construction with, respectively, the conditioning and the stretching adjustments. This shows that forcing consonance of the conformal transducer is not an ad hoc strategy; it is justiﬁed by the corresponding operations on random sets. Moreover, in light of this connection to the IM’s random set adjustments, we ﬁnd that the second adjustment to the conformal predictor, i.e., setting the maximum value equal to 1, is the more eﬃcient adjustment. Here we focused on the important problem of prediction in supervised learning applications with no model assumptions (except exchangeability). We presented a notion of prediction validity, one that goes beyond the usual coverage probability guarantees of prediction sets. This condition assures the reliability of the degrees of belief, obtained from a imprecise probability distribution, assigned to all relevant assertions about the yet-to-be-observed quantity of interest. We also showed that, by following a new variation on the (generalized) IM construction ﬁrst presented in Martin (2015, 2018), this validity property can be easily achieved. We also noted the connection between this new IM construction and the conformal prediction strategy in, e.g., Vovk et al. (2005), and presented illustrations in both regression and classiﬁcation settings. we cannot establish the distribution of the auxiliary variables. While exchangeability is a relatively weak assumption compared to iid from a parametric family, there are, of course, situations where exchangeability is inappropriate, such as time series or spatial applications. Work to develop conformal prediction methods in not-exactly-exchangeable A natural adjustment is to force the conformal transducer to attain the value 1. Exchangeability was crucial to our IM construction, that is, without exchangeability, settings is an active area of current research (e.g., Mao et al. 2020), and it would be interesting to see what the IM perspective has to oﬀer here. marginal validity, which is diﬀerent (and weaker) than the so-called conditional validity property. While this is usually framed in the context of prediction sets, the corresponding deﬁnition in the context of probabilistic predictors is and, of course, for all (α, n, A, P) as before. Given the impossibility results in, e.g., Lei and Wasserman (2014), it seems unlikely that conditional validity can be achieved by any non-trivial probabilistic predictor. Asymptotic validity is possible, and some promising ideas are given in Chernozhukov et al. (2019). tical value. This concerns the so-called open- versus closed-world view of the prediction problem. If the world is closed in the sense that all the possible labels are known, then it makes sense to remove the empty set cases and, hence, force consonance. However, if the world is open in the sense that other labels are possible, then the empty set realization is an indication that the new object being classiﬁed may be of previously-unknown type, which itself is valuable information. How this open-world view can be captured by the IM framework developed here remains an open question. This work is partially supported by the U.S. National Science Foundation, grants DMS– 1811802 and SES–2051225. The authors thank the reviewers of our ISIPTA’21 conference proceedings submission for their feedback, and the IJAR guest editors—Andr´es Cano, Jasper De Bock, and Enrique Miranda—for the invitation to submit an extended version of our conference proceedings paper to the special journal issue. In Section 3 we noted that the IM construction there leads naturally to a notion of We mentioned in Section 5 that, surprisingly, empty random sets may have some prac-