Synthetic data and simulators have the potential to markedly improve the performance and robustness of recommendation systems. These approaches have already had a beneﬁcial impact in other machine-learning driven ﬁelds. We identify and discuss a key trade-oﬀ between data ﬁdelity and privacy in the past work on synthetic data and simulators for recommendation systems. For t he important use case of predicting algorithm rankings on real data from synthetic data, we provide motivation and current successes versus l imitations. Finally we outline a number of exciting future directions for recommendation systems that we believe deserve further attention and work, including mixing real and synthetic data, fe edback in dataset generation, robust simulations, and privacy-preserving methods. Additional Key Words and Phrases: s ynthetic data, simulators, dataset ﬁdelity, privacy preservation ACM Reference Format: Adam Lesnikowski, Gabriel de Souza Pereira Moreira, Sara Rabhi, and Karl Byleen-Higley. 2021. Synthetic Data and Simulators for Recommendation Systems: Current State and Future Directions . In SimuRec 2021: Workshop on Simulation Methods for Recommender Systems at ACM RecSys 2021, October 2nd, 2021, Amsterdam, NL and online. ACM, New York, NY, USA, 1 INTRODUCTION Synthetic data generation and simulation techniques have been popular and successful in machine learning areas such as c omputer vision [ with [1, 21, 22] being notable exceptions. These techniques have the potential to address problems such as the lack of publicly available large datasets for research outside of industry. This problem is motivated by companies’ concerns about user privacy, and the possibility of revealing strategic internal KPIs, such as t he level of user engagement and t heir recurrence in the service, or the growth of the company’s item catalog over time. Synthetic data, when representative of real data, can enable researchers to benchmark, evaluate their methods on datasets of the scale and complexity used in commercial applications. The question remains however, t o what extent can simulated data eﬀectively balance the trade-oﬀ between being close enough to the real data to act as an eﬀective surrogate, while not being close enough to the real data to leak sensitive personal information. Simulators can potentially generate an inﬁnite amount of synthetic data at very little cost. They bring opportunities fo r d esign decisions on recommender systems and algorithms. An algorithm designer could simulate diﬀerent patterns of user behaviour to evaluate and compare recommendation algorithms, or could emulate the fe edback look between users and recommendations. The complexity of simulators proposed for recommendation systems varies from simple to complex, depending on its purpose, whether for algorithm comparison, framework development, or simulating the fe edback loop between recommendations and user interactions. We explore and motivate these uses, and highlight exciting future directions, in this work. 1.1 Past Successes of Synthetic Data and Simulators Domains such as computer vision outside of recommendation systems have beneﬁted markedly from applying machine learning on synthetic or simulated data [17][14]. Synthetic data in computer visions tasks such as object detect io n and segmentation has proven to be an eﬀective strategy to increase model validation set performance[24], and in particular, domain randomization has been surprisingly eﬀective[25]. Domain randomization is a technique where simulator parameters are sampled from values which are known to be unrealistic. For example training with domain randomization in a physical simulator would include training with uncommon or extreme valu es for friction, gravity, and object density. This approach might a priori seem detrimental to ﬁnal model performance by unduly fo c using model performance on cases not expected to be encountered in the intended application. Nonetheless this approach of domain randomization has been shown to be eﬀective[24] [2 5]. One explanation for the eﬀectiveness of this technique is that the beneﬁt from a large increase of training d iversity outweighs any negative eﬀects from data-distribution shifts towards physically unrealistic scenarios, while another explanation is that the training cur riculum is purposefully made more diﬃcult than the intended application, so that the intended application is an easier, more simpler sub-problem than that encountered during the totality of training. In recommendation systems, domain randomization might include setting simulator parameters for users that are known to be unrealistic, such as browsing time, b udgets, or spending habits, in order to increase training diversity, so long as validation set perfor mance is improved. We believe this p ast success is a cause of optimism for the use of simulator s and synthetic data in recommendation systems. 2 FIDELITY VERSUS PRIVACY TRADE-OFF 2.1 Fidelity Synthetic data should share some statistical p roperties of real data. There have been a number of past approaches to capture real data ﬁdelity in synthetic data. For instance [1] build synthetic clickstreams through graph walks that explicitly remain faithful to transition probabilities between items and co-occurrence probabilities of items appearing in the same clickstream. The authors measure synthetic dataset ﬁdelity by performance on downstream tasks, suc h as training recommendation systems o n their synthetic data and analyzing the performance of these trained models. Past work [2] evaluate their data-generation method on MovieLens 20 M by comparing the item-wise and user-wise rating sums, as well as the singular values, of their generated data matrix versus the real data matrix, in addit ion to baselines such as histograms of movie ratings between real and generated d ata. Past work [11] evaluates dataset ﬁdelity of generated time-series data by auto correlation metrics, distribution of generated labels and categorical event types, as well as the prediction of baseline recommendation system algorithm rankings by training and testing on synthetic data. In general it is important that features have similar distributions, but this requirement is sensitive to the intended usage of synthetic data. When synthetic data is used to test recommender systems framework and tool s based on neural networks, the cardinality and frequency distribution of categorical features is especially important, as they are represented by embeddings in the model. High-cardinality categorical features result in very large embedding tables that may exceed the capacity of a single GPU memory. That p oses engineering challenges, like distributing those huge embedding tables to multi-GPU [8] and minimizing the inter-communication between GPUs by caching the embeddings of popular categorical values [7], issues addressed by the HugeCTR framework other hand, these requirements are mu c h more strict for the purpose of comparing diﬀerent algorithms, as they in general learn patterns from the conditional dependency among the features and the prediction target. Hence ignoring these conditional probabilities between features would be far from a realistic scenario. We discuss this requirement more in Section 2.2 Privacy Another research direction of synthetic data generation focuses on using statistical disclosure control techniques to transform original data by hiding speciﬁc information. The scale of the resulting data remains the same, but personalized information about user’s preferences is masked to prote ct his privacy. These past works can be classiﬁed into two categories: attack modelling [ threats, which can take at least three forms: identity disclosure, attribute disclosure and inferential disclosure. Once one or multiple of these threats are identiﬁed, synthesized data is generated to prevent attacks. The main limitation of such methods is the requirement of identifying beforehand the attacker’s capabilities and goals, a requirement which is very challenging in practice. In RecSys, previous studies have fo c used on the classiﬁcation of recommender attack models [4] and designed simple proof-of-concept models [23] to evaluate if the relative performance of algorithms when trained and tested on the synthesized data matches with the relative performance o f al gorithms trained and tested on the original data. By contrast diﬀerential privacy aims to p revent attackers from gaining information about their targets, even if the attacker has knowledge about the dataset. One approach towards diﬀerential pr ivacy consists of injecting probabilistic noise in the original data while maintaining the same probability distributions. In RecSys diﬀerential privacy has been applied to matrix factorization (MF) at diﬀerent levels of modelling: input perturbation of user-item matrces, private MF optimizers via gradient descent or alternating l east squares solvers, and outpu t perturb ation. Previous work [ MF al gorithm accuracy and demonstrated that input perturbation ensures the highest performance. However the authors point out that high degree of noise motivated by ensuring high-level privacy directly impacts the relative ranking of models’ performances. Most recent works are extending diﬀerential privacy methods to co mplex deep recommender systems such as wide and deep architectu res [30] and collaborative bandits learning [26]. 3 PREDICTING ALGORITHM RANKINGS 3.1 Motivations There are very few pu blicly available high-quality datasets, in terms of size and diversity o f available features, likely due to companies concerns on having user pr ivacy or public data that can leak internal company metrics. This scenario limits the research advances in the RecSys ﬁeld, as scientists outside popular online service companies cannot assess and compare their propo sed algor ithms on large datasets. Synthetic generation can be an approach for companies 3 below. to release data which is similar to its large real data but does not leak this sensitive information, so that third-party researchers can evaluate their proposed algorithms. 3.2 Successes and Limitations Past works have shown that one can successfully predict what model performance ranking on datasets are, given model perfor mance rankings on simulated and synthetic datasets. For instance [11] show a successful prediction o f the relative performance rankings o f various recommendation systems algorithms trained and tested on real data, obtained by training and t esting on synthetic data. Here the algorithm ranking of the authors’ proposed GAN-based data-generation method on two diﬀerent datasets is perfectly aligned, with a correlation ranking of 1.00, w ith the actual performance among ﬁ ve other algorithms trained and tested on real data. Similarly [21] provides successful results on the prediction of real algorithm rank orderings from synthetic algorit hm rank orderings among three other recommendation system algorithms trained and tested on real dat a. On the other hand, [1] provide inconclusive or contradictory evidence that algorithm rank orderings may be successfully predicted fo r click-stream algorithms, at least for the p robabilistic graph walk dataset generation method that the authors propose in this past work. 4 FUTURE DIRECTIONS FOR SIMULATORS AND SIMULATED DATA 4.1 Data Augmentation, Mixing Synthetic and Real Data for Recommendation Systems Data augmentation te c hniques have been shown to outperform purely synthetic or purely real data in machine learning. In compu ter vision, techniques like random cropping, image mirroring, and color shifting have helped models to generalize better and to achieve improved accuracy[20]. Similar strategies have been proposed for raw signals and audio spectograms, such as perturbation and noise injection [10, 13], as well as in in NLP [28]. However augmentation techniques for reco mmender systems have been largely unexplored, with [6, 27, 29] being some notable exceptions. We believe mixing synthetic and real data can be a promising direction for domains or recommender systems d epl oyments, especially early stages of data colle ction and small dataset size scenarios. For research scientists outside large online services companies, it would be very helpful for synthetic data generation to augment real small data, allowing an accurate emulation of algorithm behavior on datasets larger than currently available. 4.2 Feedback in Dataset Generation In production recommendation systems, there is often a back-and-forth p rocess between dataset generation and model training[19]. In particular a model is likely to be trained on dat a that a previous model iteration solicite d by providing some action that the model selected, like recommending a part icu lar item to a user. This feedback cycle may be positive for performance, in selecting data that future iterations of model training ﬁnd useful for increasing performance, or this feedback cycle may be pernicious, in either halting or reversing model performance[18]. This latter phenomenon may occur by selecting data points which are repetitions in the existing dataset, or more broadly, by focusing on short-term utility rather than promoting dataset coverage or diversity[5]. One concrete example o f this latt er phenomenon is when a recommendation system recommends a small number of highly popular items, and hence fails to build diverse datasets for future model training iterations. We believe that this b ack-and-forth process that occurs in commercial applications of recommendation systems, but typically does not in the academic or open-source study of recommendation systems, should be more placed at a higher priorit y for future recommendation systems research. 4.3 Robust Simulations Generating high-ﬁdelity synthetic data from real data may not be fully feasible, due partly to biases introduced in the real data by the policies under which the data was collected, and partly due to o ur imprecise understanding of what dataset properties state-of-the-art models model. We believe that robust simulators are a promising approach for these concerns. For exploring what patterns models are capable of capturing, one can generate synthetic data with known, but not necessarily realistic, properties, towards understanding how the feedback loop between users and algorithms would evolve over time, and which recommendation algorithms would perform better in such scenarios. Most public datasets do not include t he information necessary to tell apart the actual preferences of the user base and the biasing eﬀects of what the recommender presented to users, which makes u nbiased evaluation of new models diﬃcult. By evaluating on MovieLens and other public datasets, RecSys as a ﬁ eld has overﬁt to whatever policy was used during data collect io n for the MovieLens and other canonical RecSys datasets. In the robust simulators that we envision, we can make explicit assumptions about what the distribution of tr ue preferences in the user population are, select a particular known logging policies, and generate a set of observations with known properties. Simulation allows system administrators to model recommender system dynamics over time. Simulators can be used to test how generalizable are the proposed recommendation algorithms with respect to edge cases not frequent in real datasets. Simulator interpretability allows us to better u nderstand the eﬀect of model parameters we want to test. One can choo se a distribution of true user interests and an observation sampling policy such that we end up with a dataset that has comparable statistics to MovieLens for example, then expand the simulated data to whatever large size is desired. We do not think RecSys has yet achieved this vision for robust simulators, but simulation frameworks such as RecoGym[ 4.4 Privacy-Preserving Methods Motivated by preserving users sensitive data and global statistics related to business KPIs, large companies have not shared large-scale datasets with external communities. Privacy-preserving methods discussed in section a promise for guaranteeing privacy while releasing large scale datasets for research development. However it is still unclear how these noisy aggregated data impact learning eﬀective recommender system models that maintain the relative ranking of diﬀerent approaches for performance comparison and mod el selection. A recent Criteo chall enge organized in collaboration with the CAP21’ training data to explore the trade-oﬀ between privacy level and prediction performance. In p ar ticular individual data is transformed through an embedde d, anonymized, and compact representation. Then machine learning models are trained and tested on two objectives: the privacy attacks protection and the outcome prediction task. If such privacy functions are demonstrated to lead to high performance machine learning models, large companies may generate large anonymized synthetic data using a given privacy function, and more openly share it with the RecSys community. 5 CONCLUSION In this paper, we motivate and state the uses of synthetic data and simulators for recommendation systems. The success of these approaches in other machine learning ﬁelds provides promise for these methods. For approaches that use real data, we identify a key trade-oﬀ between data ﬁdelity and privacy. The important use case of predicting algor ithm rankings using synthetic data is well-motivated, and has had b oth su cc esses and limitations. Finally there are a number of exciting and promising fu ture directions we believe the ﬁeld should invest in, including data augmentation that mixes real and synthetic data, feedback in dataset generation in production systems, robust simulators, and privacypreserving methods.