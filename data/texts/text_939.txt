Keywords: Best optimizing system, probability of false selection, exponential rate, stochastic gradient descent, sequential elimination The need to select a system with the best mean system performance among a number of diﬀerent systems naturally arises in various decision making problems. The decision maker is ty pically able to We formulate selecting the best optimizing system (SBOS) problems and provide solutions for those problems. In an SBOS problem, a ﬁnite number of systems are contenders. Inside each system, a continuous decision variable aﬀects the system’s expected performance. An SBOS pro blem compares diﬀerent systems based on their expected performances under their own optimally chosen decision to select the best, without advance knowledge of expected performances of the systems nor the optimizing decision inside each system. We design easy-to-implement algorithms that adaptively chooses a system and a choice of decision to evaluate the noisy system performance, sequentially eliminates inferior systems , and eventually r ecommends a system as the best after spending a user-speciﬁed budget. The proposed algorithms integrate the stochastic gradient descent method and the sequential elimination method to simultaneously exploit the structure inside each system and make comparisons across systems. For the proposed algorithms, we prove exponential rates of convergence to zero for the probability of false selection, as the budget grows to inﬁnity. We conduct three numerical examples that represent three practical cases of SBOS problems. Our proposed algorithms demonstrate consistent and stronger perfo rmances in terms of the proba bility of false selection over benchmark algorithms under a range of problem settings and sampling budgets. generate or collect unbiased noisy random samples of the expected performance for each system in contention. The task of selecting th e best system in a statistically principled way, as an abstraction of many practical applications, is a fundamental research problem in several growing research areas. In the area of stochastic simulation, this research problem is referred to as Ranking and Selection or Selecting the Best System; see Hong, Fan, an d Luo (2021) for comprehensive reviews and see Chick and Wu (2005), Lan, Nelson, and Staum (2010), Waeber, Frazier, and Henderson (2010), Luo, Hong, Nelson, and Wu (2015), Fan, Hong, and Zhang cisions, production management, ﬁnancial risk evaluation and decisions, etc. For most Selecting the Best System problems, noisy random samples are generated from running costly stochastic simulations, w here the simulation model is often built to represent real complicated systems or new systems that have yet to be developed. The task of selecting the best system also appears in experimental designs for clinical trials or A/B testing (see Gans, and Yapar costly treatment experiments on individuals. Both the Selecting the Best System literature and the clinical trials literature point back to (1995), and both literature aim at selecting the best or better system in a s tatistically principled way. The two literature share the same notion that samples are noisy and costly to generate or collect, despite of the diﬀerence on how the samples are generated or collected. Most existing literature on selecting the best system (i.e., selecting a system with the best mean system performance) assumes that one has access to independent unbiased noisy samples of the system performance for each system in comparison. However, this access can be unavailable for problems where each system in comparison involves optimizing a decision insid e the system. For instance, such a phenomenon arises in the follow ing application examples. • Medication and Healthcare. Suppose a pharmaceutical factory has designed two new drugs to • Simulation Optimization for Complex Stochastic Systems. For non-stationary service systems, treat insomnia symptom for some speciﬁc type of patients. The factory needs to run experiments to test the eﬀects of the two new drugs and the decision is to select the best (better) one to massively produce, distribute, promote, and s ell. In this example, each drug is a “system” corresponding to the problem of selecting the best system. For each drug, diﬀerent doses can lead to diﬀerent expected eﬀects for the targeted patients (see for exampleErman, Seiden, Zammit, Sainati, and Zhang(2006), Verweij, Danaietash, Flamion, M´enard, and Bellet (2020)). Therefore, when comparing two drugs (systems) and selecting the better one, the “system performance” is the expected eﬀect of a drug at its optimal dose. That said, the dosage is often a continuous variable and what exact dosage is optimal for a drug may not be known a priori. Therefore, a challenge is that the decision maker has no access to an unbiased estimator for the optimizing expected eﬀect for each drug. The task of selecting the best system (drug) naturally involves an inner layer of optimization to optimize the dosage amount inside each system. • Data-driven Revenue Management and Product Selection. Suppose a new platform hopes to In all aforementioned applications, each sy stem has a continuous decision variable to choose inside the system. The comparison between systems is based on each system’s optimizing performance under the optimally chosen decision. A priori, the decision maker may not know which decision is optimal for each system and therefore does not have access to an unbiased sample of a system’s optimizing performance. Another common feature in these application is that samples can be costly to generate or collect, either because of costly simulation or because of costly data collection from the real world. Formally, these aforementioned applications motivate us to deﬁne and analyze a class of problems that we call selecting the best optimizing system (SBOS). The SBOS problems have two layers of optimization. The ou ter-layer optimization involves a selection from a ﬁnite number of systems. For each system, there is an inner-layer optimization inside the system, where there is a continuous decision variable that aﬀects the expected system performance. The in ner-layer optimization decides a manager often uses simulation optimization to make staﬃng plans under resource constraints (e.g., a constraint on the total number of staﬀ members). Suppose that a manager has N staﬀ members and needs to select a staﬃng p lan that has the best expected system performance (where the performance metric may involve service revenue, total customer abandonment due to long waiting times, etc.). In this example, the service system und er each staﬃng plan is a “system”. Within each system (w hich is, given each staﬃng plan), the manager also needs to make other decisions to imp rove the system perf ormance. One example of such decision is to set a price for the service (Kim and Randhawa (2018), Lee and Ward (2019)). With a given objective function, for diﬀerent staﬃng plans, the optimal price to set for the service may be diﬀerent. In addition, what is the optimal price for each system (staﬃng plan) is a priori not unknown. The comparison between each system is based on the expected system performance where an optimal price is successfully set in side that system. Therefore, when selecting the best system (staﬃng plan), the m an ager needs to optimize the price decision inside each system in order to obtain the best optimizing performance of each system. select the best product from a pool of N products to post and sell on the platform. T he platform has no priori knowledge about the daily exogenous demand distribution of each product, but has the ab ility to, for each day, choose one product (and only one, due to display limit) to post on the platform and collect a data sample of the ran dom daily demand. Each p roduct is a “system”. Within each system, the platform also needs to make an inventory decision in order to maximize the expected proﬁt for that system. The optimal inventory decision is a priori unknown, but can be better informed when the platform collects more data samples for the system. Given a budget of T days (i.e., T data samples), the platform then hopes to make a good arrangement to dynamically decide which system (product) to collect one more data sample of the random daily demand, w ith the goal of choosing a product that has the best optimizing expected proﬁt. the optimizing perf ormance of each system by choosing the b est decision variable inside the system. The outer-layer optimization s elects the best system accordin g to the optimizing performance. In this work, we consider a ﬁxed-budget f ormulation of the SBOS problems. That is, there is a given budget of samples and one has the ability to sequentially decide how the samples are allocated to diﬀerent systems. Once the sampling budget is exhausted, based on all observations, a recommendation needs to be made on wh ich system has the best optimizing performance. The goal is to design easy-to-implement algorithms that are allowed to sequentially allocate the samples and end up with a recommendation on the best optimizing system. The metric to evaluate how go od an algorithm is by the pr ob ab ility of false selection (PFS) given a ﬁ x ed budget. The designed algorithms are d esir ed to demonstrate good empirical performances and, enjoy a theoretical guarantee on the upper bound of PFS under a given budget. In fact, a key challenge in designing algorithms for SBOS problems is that the comparison of diﬀerent systems are based on their optimizing performances but the optimizing decision is not known a priori. Exactly kn owing the optimizing performan ce of a system requires the inner layer of optimization for that system to be completely solved. However, when the number of samples allocated to each system is ﬁnite, it is often impossible to h ave an unbiased estimator of the optimizing performance for the system. Statistically, this means that one does not have access to unbiased samples of the optimizing system performance for a given system. In contrast, for classical problems of selecting the best system that do not have an inner layer of optimization, one has access to independent unbiased samples of the each system’s performance. Fortunately, for SBOS problems, with more and more samples intelligently assigned to a system, one can derive an estimator that has smaller and smaller bias to the optimizing system performance. In the algorithm design, when deciding on which system to assign the next sample, one needs to understand how optimized a system already is, in addition to the standard notion of how much variability a system has in classical problems of selecting the best system. Another challenge, as well as an opportunity, arise from the structures of the inner-layer optimization and their impact on the outer-layer optimization. For certain ap plications, the inner layer optimization has clear structures such as convexity or local convexity. When making selections based on the outer-layer optimization and deciding which system to allocate samples, it is crucial to understand how the structures in the inner-layer optimization can be strategically used. This poses a challenge to algorithm design b ut also opportunities to achieve stronger performances by incorporating the inner-layer optimization’ structural information. We summarize our main contributions in the following subsection. First, motivated by applications in simulation optimization, data-driven stochastic optimization and medication decisions, we formulate a new class of problems named selecting the best optimizing system (SBOS). In SBOS problems, systems are compared based on their optimizing performances, which involve an inner-layer of optimization in addition to the standard selection optimization. Building on classical problems on selecting the best system in the simulation literature, we consider a ﬁxedbudget formulation where th e decision maker has the ability to sequentially decide how to spend the sampling budget, based on sequentially observed samplin g outcomes. Th e SBOS problems naturally incorporate two s treams of settings where the sampling cost is because of expensive simulation and is because of expensive real experiments and d ata collection. Second, we propose easy-to-implement algorithms and prove exponential-rate performance guarantees. That is, when the total number of samples (budget) increases to inﬁnity, the probability of false selection mad e by the proposed algorithm is proved to decay exponentially fast with an explicit positive exponential rate. Diﬀerent from classical problems of selecting the best, where an estimation for a system’s performance is the mean of independent and identically distributed samples, we need to perform the inner-layer optimization to derive each system’s optimizing performan ce. Our algorithm design integrates stochastic gradient descent and sequential elimination to exploit the stru cture of the inner-layer optimization and make comparisons on the ou ter layer. The proposed algorithms carefully examine the bias and variance of the estimation for a s y stem’s optimizing performance. Our theoretical analysis takes both the bias and variance into account and simultaneously incorporates the structure inform ation of the inner-layer optimization for each system. We show that our algorithm design and theoretical analysis (exponential rate) hold for both simulation optimization problems where the inner-layer optimization is convex and general data-driven stochastic optimization p roblems, which are two important classes of prob lems in SBOS problems. We hope that the analysis and proofs can be useful to more broad class of simulation optimization problems with both continuous and discrete d ecision variables. Third, we conduct comprehensive numerical stu dies for the SBOS problems, including three practical applications. T he ﬁrst application is an optimal staﬃng and pricing problem in a nonstationary queueing system. The second application is an optimal dosage ﬁnd ing problem in the selection of the best drug. The third application is a data-driven newsvendor problem in the selection of the best product. We compare our proposed algorithms to the uniform sampling method and the Optimal Computing Budget Allocation (OCBA) method. We demonstrate that our method achieve the lowest probability of false selection in all problem settings. Our work is closely connected to the literature on ﬁxed-budget ranking and selection (R&S) problems. Instead of using the term R&S, we adop t in this work the terminology of selecting the best system, which has been an equivalent or even slightly more precise notion when one d oes not rank the systems but only selects the best (see computing bu dget allocation (OCBA) procedure proposed by Chen, Lin, Y¨ucesan, and Chick (2000) and its sequential ver sion is among the most famous algorithm for ﬁxed -budget R&S problems. and Juneja (2004) establishes a rigorous guarantee for the OC BA procedure using a large deviation principle. exponential decaying rate for the Probability of False Selection (PFS) as the budget goes to in ﬁnity. Wu and Zhou (2018) takes a closer look at sequential OCBA algorithms and demonstrate We refer to the references within Hunter and Nelson (2017), Wu and Zhou (2018) and Hong, Fan, and Luo frequentist approaches, Frazier, Powell, and Dayanik (2009), Chick , Branke, and Schmidt (2010), Chick and Frazier (2012), R y zhov (2016), Chen and Ryzhov (2019), Russo (2020), Li, Lam, Liang, and Peng (2020) and references within for the use or discussion of Bayesian methods. Denote the problems of selecting the optimizing s y stem (SBOS) in a ﬁxed-budget setting as ﬁxedbudget SBOS problems. Despite of the close connections between ﬁxed-budget SBOS problems and ﬁxed-budget R&S problems, especially on their common goal to strategically assigning samples to diﬀerent systems to achieve a small PFS with a given sampling bu dget, their problem settings have key diﬀerences. For SBOS problems, one does not have direct access to draw unbiased samples to estimate a system’s optimizing performance, because each system has an inn er -layer optimization that cannot be completely solved given ﬁnite samples. That said, the OCBA method that is popularly used in R&S problems can s till help solve SBOS pr ob lems. Consider a simulation optimization setting where for each system (say there are in total K systems), the inner-layer optimization concerns the selection of an optimal price p system to run simulation, that simulation also needs to s pecify a price as input. The OCBA method works as follows. One can break down each system into M (small) systems where each of the M (small) systems concerns a diﬀerent price. In this way, the two-layer SBOS problem becomes a “big” standard R &S problem with in total KM systems, for which the OCBA method can conveniently be applied. There can be two challenges for this break-down-and-then-O CBA approach. First, when the decision variable in the inner optimization is continuous, any ﬁxed M cannot ensure that the optimizing system (one that is associated with the unknown optimal continuous decision variable for th e inner optimization) is included. Dynamically scaling up M as the budget increases can partially alleviate th is issue but adds complications to algorithm design and analysis. Second, this break-down-and-then-OCBA approach may not eﬀectively utilize the s tructure information of th e inner-layer optimization (e.g., concavity or convexity) because this approach can be viewed as doing grid search for the inner-layer optimization. In this work, we will describe an appr oach based on sequential elimination that does not require the break-dow n of the original sy stem, which can address the two aforementioned challenges. We then conduct extensive experiments to compare our prop osed approach and the break-down-and-then -O CBA ap proach. Our work is also related to of the best s y stem (RSB), where the probability distributions associated with each system are not exactly known but may come from a set consisting of a ﬁnite number of options. In and Zhang the RSB problems in Fan, Hong, and Zhang (2020) and our SBOS problems have two layers of optimization, but they have distinct problem settings that address diﬀerent needs of applications. Intuitively, their s etting can be viewed as a max-min problem, while ours is a max-max problem. Another diﬀerence is that in our setting, the inner-layer optimization has a continuous d ecision variable, which corresponds to inﬁnite number of options in the inner layer of maximization. This (2021) for comprehensive reviews of ﬁxed-budget and ﬁxed-conﬁdence R&S work. Besides (2020), the best system is the one possessing the best worst-case performance. Both motivates the use of gradient-descent method to do the optimization search in the inner layer of our SBOS problems, diﬀerent from the RSB problems. Further, a ﬁxed-conﬁdence setting and proves in their Section 4 asymptotic statistical validity. We consider a ﬁxed-budget setting and proves exponential rate of decaying of PFS as the budget increases. The algorithm design is diﬀerent between based on the indiﬀerence zone-free sequential procedure in on a ﬁxed-precision setting, while ours is based on the “Successive Rejects” algorithm introduced in Gabillon, Ghavamzadeh, Lazaric, and Bubeck (2011) focused on a ﬁxed-bud get setting. Both their work and our work share the spirit of integrating the inner-layer optimization and the outer-layer selection to enhance algorithm performan ce, but from a diﬀerent perspective. Notations. We denote [K] to be set of {1, 2, . . . , K}. We sometimes use [K] as an abbreviation for {1, 2, ··· , K} when there is no ambiguity. Let ⌊·⌋ be the ﬂoor function. And |A| stands for the cardinality of the set A. N(µ, σ variance σ Suppose that a decision maker needs to select one from K systems, labeled as 1, 2, . . . , K. We denote the optimizing performance of the i-th system as v of an inner-layer optimization. Speciﬁcally, in which X for system i, and G performance under decision x for the i-th s y stem. The selection of the best system is to select the system with the best optimizing performance, formally given by The decision maker has access to choose any i and x and draw a sample of G concrete and diﬀerent settings as follows, which will be the main problem settings for algorithm design and analysis in this work. The optimizing performance of the i-th system, denoted by v problem as the inner-layer optimization. Speciﬁcally, the inner-layer optimization is given by and the Poisson distribution with rate λ, respectively. in which x denotes the choice of decision variable in a compact and convex set X system randomness, and F logic and outp uts a system performance. The expected perf ormance function f continuous so that the maximum can be attained over a compact set. The goal of Selecting the Best Optimizing System(SBOS) problem in this simulation optimization setting is to optimize We consider settings in which f (x pensive simulation samples F systems, the most time consum ing part often comes from the evaluation of the function F which summarizes all the complicated system logic and operational rules. In this context, generating one simulation sample refers to one fu nction evaluation of F evaluation of ∂ T is deﬁned as the total number of samples that can be used to generate independent function and gradient calls of F sense that one can decide where to spend the next s ample after observing outcomes from all previous samples. After th e b udget is us ed up, one needs to decide which system has the best optimizing performance max allocate simulation samples and eventually achieve provably small probab ility of false selection (PFS) after the budget T is spent. The optimizing performance of the i-th system, denoted as v problem as the inner-layer optimization, given by where F random variable having distribution P 2.1, here the evaluation of f unction g is not the bottleneck for data-driven stochastic optimization problems. However, the distributions P from collecting real-world data samples. This setting notes that each data sample is costly to collect, rather than that th e computation or function evaluation is costly. Speciﬁcally, we consider scenarios where indepen dent an d identically distributed (i.i.d.) samples that come from the true unknown distribution P of i.i.d. samples that can be collected aggregated for all K systems. The collection of one sample refers to obtaining one i.i.d. ob servation from the distribution P (3), no unbiased estimator for v can be parametric or non-parametric function classes, and X denotes a general-dimensional implement algorithms that sequentially decide which sample to collect and eventually decide which system achieves the best optimizing performance max We have now introduced two classes of SBOS problems - one class on simulation optimization (Section 2.1) and the other class on data-driven stochastic optimization (Section 2.2). In the rest of this work, we will present algorithm design and analysis for the class of simulation optimization problems in Section 3 and present algorithm design and analysis for the class of data-driven stochastic optimization problems in Section 4. We summarize that the key technical diﬀerence between these two settings are how the budget is counted and how one sample is deﬁned. Such technical diﬀerence captures diﬀerent sets of applications and demands algorithm design and analysis respectively. In this section, we focus on the class of SBOS simulation optimization problems as formulated in Section 2.1. We present our algorithm which is named Sequential Elimination for Optimizing systems (SEO). The SEO algorithm integrates the s tochastic gradient descent method in the inner layer and the s equential elimination method in the outer layer. The sequential elimination method is motivated by Algorithm 22 in K, the basic idea is to divide the budget into L = ⌊log the algorithm evenly allocates the budget to each system that still remain considered. Within each phase, the budget that is allocated to each system is used to solve the inner layer op timization. For the inner layer optimization of a sys tem, the algorithm performs stochastic gradient descent (SGD) using all the allocated budget and then obtains a (biased) estimator of th e optimizing performance of that system. At the end of each phase, the algorithm eliminates the bottom half of systems. The elimination is based on the estimated optimizing performance for all the systems under consideration up to that phase. The full pro cedure of our proposed SEO algorithm is summarized in Algorithm 1. It is evident that, with ﬁnite number of samples, the inner layer optimization cannot be completely solved, and the decisions recommended for the inner layer optimizations are non -optimal. A major challenge for designing and analyzing the SEO algorithm is that we need to balance the bias (compared to th e optimal) arised from non-optimal decisions and the variance of each random sample. As a further challenge, unlike theory f or standard stochastic op timization problems, we n eed to estimate the optimal objective value rather than the optimal solution. This is because the comparison between systems is based on their optimal objective function value rather than the optimal choice of decision variable. Therefore, we need to carefully design and analyze the SGD method used in the algorithm and the corresponding estimators. Algorithm 1 Sequential Elimination for Optimizing Systems (SEO) in Simulation Optimization In this sub section, we prove a performance guarantee for the SEO algorithm (Algorithm designed for SBOS problems in the simulation optimization setting. A key obstacle in the analysis is to bound the bias in the estimator for the optimal objective value in the inner-layer optimization and to control how the bias from the inner-layer optimization aﬀects the ou ter-layer selection. When analyzing the b ias, a major challenge arises because th e algorithm needs to average out all the samples including those which may be farther from the optimal value to reduce the variance. Before presenting the analysis and theory, we ﬁrst state the assumptions. (x, ξ) is concave on x and ﬁnite-valued. where σare positive real nu mbers that can depend on i. The subgradient estimator −G(x, ξ) is unbiased in the sense E[G(x, ξ)] = f(x) for all x. Also, the variances and tail conditions for the subgradient estimator are regularized as E[kG(x, ξ) − f(x)k] ≤ The concavity in Assumption Otherwise, the algorithm can (and need to) be modiﬁed to have multiple random initializing points. Assumptions the stochastic gradient G special case. Assumption these assumptions are standardly needed in the continuous stochastic optimization literature that establish convergence rates. T hen, we have the following convergence result from ˆv is the optimizing performance for sy stem i as deﬁned in ( T steps of SGD (where T is a dummy variable), as shown in line 12 of Algorithm 1. Proposition 1. Suppose Assumption 1 is enforced. For the constant-step size policy, we have for any ǫ > 0 the following holds For part(a), by martingale argu ments and Azuma’s inequality, we have For part (b), we borrow the results from ( where σare positive real nu mbers that can depend on i. is also valid for The detailed proof is in Appendix A.1. Proposition 1 shows that if the SGD scheme is chosen appropriately, the estimated objective value converges to the true optimal objective value exponentially fast as the sampling size grows to inﬁnity, even in the presence of bias. Proposition the bias rate in th e estimated optimal objective value, which to our knowledge, is an independent contribution, given that the literature largely focuses on the optimizer property instead of the objective value. By u tilizing Proposition selection of Algorithm 1. Note that the probability of false selection (PFS) is given by P(1 /∈ A where A Theorem 1. Suppose Assumption 1 is enforced and v i = 2, 3, . . . , K. When we have the output from Algorithm = G(x, ξ)−f(x). Since the step-size is constant, by Markov inequality and Assumption Pkδk/σ> (1 + λ)T≤ exp(−(1 + λ)T )Eexpkδk/σ(4) is the set returned from Algorithm1 that contains only one system. Sketch of Proof. For simplicity, we assume K = 2 T= T 2 Next, we deﬁne a new set to be the bottom (ordered by true value) three-quarters of the systems in round ℓ. Then, if the optimal system is eliminated in this round, we must have Then, by applying the union bound to the bound ( Finally, we have the desired r esults by sum ming the telescoping series. This pr ocedure is inspired by proof of Theorem 33.10 in The detailed proof is in Appendix A.1. This result also includes Gabillon, Ghavamzadeh, Lazaric, and Bubeck (2011) and Carpentier and Locatelli (2016) as special cases, which do not have in nerlayer optimizations in each system. The bound ( hand when T is much larger than K log linear on T . And the rate is exponentially inverse proportional to the log of the number of systems log(K), the complexity term H demonstrated reliable performance guarantee for the SEO algorithm that have desirab le dependence on the budget T (exp on ential decay) and on the number of s y stems K. Note that, within each system, there are technically a inﬁnite continuum of “sub-systems”, a challenge that is overcome by the SEO algorithm by exploring the concavity structure. Following th e upper bound exponential rate result to control the PFS, we also provide a brief lower bound result in Proposition 2, utilizing the results from Carpentier and Locatelli (2016). Here, we ﬁrst deﬁ ne the oracle model, which is similar the setting discussed in Agarwal, Wainwright, (v) = max, H(v) = max, and M= max{3σD+ σ/6}. Bartlett, an d Ravikumar (2009) and Nemirovskij and Yudin (1983). K, T and X the decision maker. At time t ∈ [T ], the decision m aker chooses a system i ∈ [K] and also queries a point x ∈ X the class of all oracles satisfying Assumption H(v) ≤ a, wher e H(v) = Proposition 2. Let K > 1 and a > 0. If T ≥ 16¯σ for any algorithm it holds that the algorithm’s recommended system by the end of T , labeled as i, satisﬁes that Proof. Proof We rely on the proof ideas from instances. Let (p to the Bernoulli distribution with probability p. Then, for the k-th system of the i-th instance, we assume F follows distribu tion 2¯σBer(1 −p than O. Following the notions in the i-instance, the complexity is H(i) = 1/4¯σ the same as the problem in Locatelli Remark: The relation H together with Theorem 1 shows that the hardest problems are those H In this section, we present the Sequential Elimination for Optimized Systems (SE O) algorithm designed for SBOS problems in the data-driven stochastic optimization setting, as introduced in Section 2.2. In this setting, the bottleneck in terms of cost is not the simulation evaluation cost, but is the number of r eal data samples we can collect. We presume that the function evaluation cost of g(·) is much cheaper compared to the cost of collecting real data. Therefore, the sampling budget only counts the number of collected real data samples. Speciﬁcally, we assume there is an oracle that eﬀectively solves the following sample average ap proximation problem . An oracle answers th e query by giving F(x, ξ) and G(x, ξ) . We let Oto denote (x, ξ) follows distribution 2¯σBer(p) if i 6= k. Otherwise, if i = k, we assume F(x, ξ) (2016) gives the desired result. up to constant. where P our method. Intuitively, for the outer layer, the algorithm perform s sequential elimination. In the inner layer, the algorithm draws the oracle to solve the sample average approximation problem ( We note th at despite of the algorithm’s simp le form, which itself is an advantage, the performance guarantee analysis for the algorithm remains challenging. Algorithm 2 Sequential Elimination for Optimizing Systems (SEO) in Data-driven Stochastic Optimization obtain an estimation ˆv In this subsection, we prove performance guarantee for the prop osed SEO algorithm to solve SBOS problems in the data-driven stochastic optimization setting. In order to quantify the favorable biasing caused by overﬁtting, we need a complexity notion of the f unction classes F covering numb er ( Deﬁnition 1 (Covering number). A δ-cover of a set F with respect to a metric ρ, N(δ, F, ρ) is a set {g number N(δ, F, ρ) is the cardinality of the smallest δ -cover. Then, the complexity of the set F is measured by the entropy integral ( deﬁned below. Deﬁnition 2 (Entropy integral). Deﬁne where P samples from P , and the metric k·k denotes the empirical distribution with ndata samples from P. Algorithm2 details , . . . , g} ⊂ F such that for each g ∈ F, there exists i ∈ [N] that ρ(g, g) ≤ δ. The δ-covering denotes the n-times product measure of P , Pis the empirical distribution with n i.i.d. Many important function classes have known and ﬁnite entropy integral. We provide several instances below. Example 1. The following f unctional classes have ﬁnite entropy i ntegrals. • Vector spaces ( • Lipschitz parametrized class: Suppose that F = {g(θ, ·) : θ ∈ Θ} is a parametrized class, • VC classes ( More examples can be found in Chapters 4&5). To help our analysis of the probability of the false selection, we assume the function classes are uniformly bounded and have ﬁnite entropy integrals. • There exits B > 0 such that f (z) ∈ [−B, B] for all f ∈ We are ready to show our results on the upper bound of the probability of false selection (PFS) for Algorithm Sketch of Proof. Let g binationsλfof a given, ﬁnite set of functions {f, . . . , f} on X. Suppose F is uni formly bounded in X. Then, F has ﬁnite entropy integrals. where Θ is a d-dimensional unit Euclidean ball B⊂ R. And we assume for all x, |g(θ, x) −√ g(θ, x )| ≤ Lkθ − θk. Then, J(F, P ) = O(Ld). The proof follows the covering number bound in (Wainwright 2019, Example 5.18). with VC-dimension d (Vapnik and Chervonenkis 1971), then J(F, P ) = O(d). (v) = max. The d etailed proof is in Appendix A.2. The biases from overﬁtting the collecting d ata are controlled by the complexity of the function class J(F rate of convergence of PFS as budget increases to inﬁnity, establishing a performance guarantee for the SEO algorithm applied on SBOS problems in the data-driven stochastic optimization setting. Similar with Proposition the class of all oracles satisfying Assumption the following lower bound: Proposition 3. Let K > 1 and a > 0. If T ≥ 16B for any algorithm that return systems i The proof follows the same routine as the pr oof of Proposition In this section, we present th ree applications that need the selection of best op timizing system. Two applications correspond to the setting in Section 3 and one application corresponds to the setting in Section 4. For each application, we describe the problem setting, implement ou r proposed algorithm and compare with the uniform samplin g algorithm. For the simulation optimization (Section and the selection of the best d rug (Section the Optimal Computing Budget Allocation (OCBA) algorithm (Chen et al. 2000) with discretization. The uniform sampling algorithm is that we treat each system in a uniform way by allocating a load T/K samples to each sy stem. E ach system receives the same amount of samples to solve the innerlayer optimization, using the same approach as in our proposed SE O algorithm. For the OCBA algorithm, We adopt the variant proposed in Zhou (2018) with the size of samples for an initial estimation N (2018) show that a ﬁxed N in Algorithm 3. We show that our prop osed algorithm consistently outperforms the two ben chmarks regarding probability of false selection, for diﬀerent number of systems K and diﬀerent total budget T . Algorithm 3 Optimal Computing Budget Allocation (OCBA) for Optimizing Systems phase proportion α possible decision x i ∈ {1, 2, . . . , K} and j ∈ [d]. Let N To ensure the probability of f alse selection converging to zero when T → +∞, we show that technically the the cardinality d of the discretization set could be very large in Lemma Lemma 1. We consider simulation optimization regime. Let O with K systems, Lipschitz constant less than M, the complexity term H less than a. and the innerlayer decision space X. Then, if d < the probability of false selec tion of Algorithm (ℓ + 1) ← N(ℓ) + 1, and update¯X(ℓ + 1) and S(ℓ + 1). In this examp le, we apply our proposed method to a simulation optimization problem in the queueing context, with the goal of selecting the best staﬃng plan for a two-station service system under optimized pricing plans. Speciﬁcally, we consider a ﬁrst-in-ﬁrst-out service system with two connected stations, Station One an d S tation Two. Th e service system has in total K + 1 homogeneous staﬀ members (servers). The system manager needs to select x ∈ {1, 2, ··· , K} staﬀ members to serve at Station One and K + 1 − x staﬀ members to s er ve at Station Two. Each station has a ﬁrst-in-ﬁrstout logic with inﬁnite waiting room capacity. Station One oﬀers a type-one service and Station Two oﬀers a ty pe-two service. The type-one service is required to be completed before type-two service. That is, cu stomers who enter th e system always ﬁrst join Station One to receive type-one service. Upon completion of service in Station One, customers will immediately join Station Two to receive type-two ser v ice. The speciﬁcs are given as follows. Arrival process. The system is open to arriving customers on [0, H]. The arrival process of customers to the system is a non-stationary Poisson process with time varying rate {λ(t) : t ∈ [0, H]}. C on sider λ(t) = λ services. Service times. For the i-th customer, the type-one service time requirement S two serv ice time requirement S mean vector (µ distribution as (exp(Y identically distributed. Abandonment and patience. T he i-th customer has a patience time P a independently and identically distributed according to an gamma distribution with rate parameter β and shape parameter α than P a The system can set a price p ∈ [0, 1] and there is an elasticity function q(p) = 1 − p for customers. That is, if the price is set as p, then each arriving customer from the aforementioned non -stationary Poisson process has an independent probability q(p) of accepting the price and entering the system, but otherwise rejecting the price and immediately leaving the system. Queueing performance and objectives. For each given staﬃng plan {x, K − x} and service price p, denote D(x, p, H) as total number of customers that end up accepting the price and receiving services in the system. The system receives an overall reward pD(x, p, H). Denote W (x, p, H) as the total amount of waiting times for all customers in either station. The system receives an overall penalty cW (x, p, H) that is proportional to the total amount of waiting time. Optimization Goal. The goal is to select the best staﬃng plan that maximizes the expected net reward. For each staﬃng plan, the price needs to be optimally set to maximize the expected net reward associated with that plan. Speciﬁcally, the optimization prob lem is give by , σ, σ, ρ. Speciﬁcally, let Yand Y, 2 be jointly distributed Gaussian random variables with time in the waiting room of Station One. Pricing of service and customer reaction. Note that the m ost costly computational part is for any given x and p to obtain a sample of pD(x, p, H) − cW (x, p, H), which requires running through the entire time h orizon of system logic. This optimization problem can be classiﬁed as a staﬃng-pricing joint decision making problem, which have been widely considered in the literature and related applications. See Kim and Randhawa (2018), Lee and Ward (2019), Chen, L iu, and Hong (2020) and references within. Most of work in this literature presumes the system to have a steady-state behavior and uses the steady-state vehicle to derive insightful decisions. We alternatively focus on providing a computational tool when some applications desire the selection of an optimized staﬃng plan but observe non-stationarities and potentially complicated system uncertainties. In presence of non-stationarities and potentially complicated system uncertainties, it is often diﬃcult to derive closed-form solutions and demands the use of Monte Carlo simulation to solve the associated optimization pr ob lem. In this example, we do not consider the use of common random numbers, wh ich can be potentially added as an additional tool to improve eﬃciency for all algorithms in comparison. For the experiment speciﬁcs, we choose λ log(K), µ E[S set β γis chosen as 2/H = 1/1000 and the initial point p is obtained by ﬁnite diﬀerence gradient estimator. Speciﬁcally, we approximate the gradient by (F(p, ξ) −F one gradient, we need to evaluate the function F as the input in Algorithm OCBA approach, we discretize the space [0, 1] to 10 possible systems {0.1, 0.2, . . . , 1}. Figure optimal staﬃng and pricing p roblem. Figures 1(a) - 1(c) plot the probability of correct selection averaged over 1000 replications as a function of increasing bud get, for K = 16, 40, 128, resp ectively. The black solid line, the blue dashed line, and the orange dotted line represent the SEO, uniform, and OCBA algorithms, respectively. It is evident to see that our proposed SEO algorithm performs better than the uniform and the OCBA algorithms for almost every K and T . The only exception is that when K = 16 and T small, likely due to the initial estimation bias. Another thing worth noting is that in theory, each lin e in those ﬁgures should be monotonically increasing. The zig-zag phenomena in those ﬁgures are due to random errors. In th is example, we consider K diﬀerent drugs (or treatment plans) that are being compared to treat a disease for a targeted population. Each drug can have diﬀerent expected eﬀect on the population with diﬀerent dosage amount ( for each drug what is the dosage amount that has the best expected eﬀect for that drug among a continuous range of allowable dosage amount. Suppose that one can sequentially do T experiments, = log(2) + log(K). Therefore, there is in averageλ(t)dt = λH/6 = 1000/3 and ] = 10.5 + K and E[S] = 2.5 + K. For the patience time distribution of the customer, we = 1 and α= 2µ. In the SEO and un if orm s ampling algorithm, the s tep-size constant (p −∆, ξ))/∆, where we choose ∆= 0.03 here. T herefore, to obtain one sample and 1 shows the comparison between SEO, uniform sampling and OCBA algorithms in the Figure 1: The comparison between SEO, uniform sampling and OCBA in the optimal staﬃng and pricing problem. where each experiment selects one of the K drugs and a speciﬁc dosage of that drug. Suppose that for each experiment, a noisy observation can be obtained on the eﬀect without much delay. Th e goal is to select one drug with the best expected eﬀect u nder the best dosage amount for each drug. In this experiment setting, we presume that for each drug, the expected eﬀect as a function of the dosage amount is concave. This concavity assum ption on one hand has been captured by empirical evidence for some drugs (e.g., Verweij et al. (2020) identiﬁes a quadratic function form) and on the other hand captures the intuition that neither too small dosage nor too large dosage is desirable. In the new experiments, we based on th e results in dose-response of aprocitentan. The eﬀect is measured by the mean change from baseline in sitting diastolic blood pressure (SiSBP) and the dosage amount r an ges from 0 to 50 mg. The small SiSBP is, the better. Since the data is not public, we ﬁt the “center” system. We perturb th e “center” system to generate K possible systems. Speciﬁcally, Figure 2: The eﬀect curve with respect to the dosage amount (Verweij et al. 2020, Figure 3A) we ﬁrst generate K uniform random numbers u system is a quadratic function of the form a and ǫ ∼ N(0, 1) for i = 1, 2, . . . , K. For our algorithm (SEO) and the uniform sampling algorithm, we pick the starting point x q + cwith a= 9/1250, b= −23/50, c= −5 wh ich is also plotted in Figure 2. We call it optimization discu ssed in Section 5.1, we use ﬁnite diﬀerence grad ient estimator with ∆ diﬀerence is that we cannot use common random number to generate two samples with x and x−∆ Therefore the variance of the gradient will be enlarged. For the OCBA algorithm, we discretize the dosage space as [11, 12, . . . , 40]. Figure optimal dosage pr ob lem, which is an analog of algorithm over the other two algorithms. Since the problem is inherently hard problem as we enforce diﬀerent drugs have similar eﬀects, the probability of correct selection is still high when K ≤ 40. More plots are contained in Figure 3: The comparison between SEO, uniform sampling and OCBA in the optimal dosage problem. Newsvendor p roblems decades in revenue management, op er ations research, and management science, as they are tractable yet still can capture many important realistic characteristics in practice. In the big-data era, datedriven newsvendor problems ( and Rudin 2019 of uncertainties, therefore informing better business decisions. However, data collection (or data purchasing) can be costly in practice, yielding a need to intelligently collecting data to achieve high-quality decisions. In this example, we assu me there are K products as contenders. Each product is a system, having their own price, cost structure and diﬀerent demand function. Speciﬁcally, we consider the function classes where p is the pr ice and c denotes the cost. We consider the newsvendar problem 3 shows the comparison between SEO, uniform sampling and OCBA algorithms in the where p we assume p costly samples from the distribution P proﬁts max For the experiment speciﬁcs, we assume that p a Poisson distribution with rate λ the empirical optimal solution is the (p Figure problem. It is clear that our algorithm has consistently higher probability of correct selection than one of the uniform sampling algorithm. Fur ther, sup er iority is even more signiﬁcant when the number of product K is large. We do not compare our algorithm with OCBA since the focus here is the sample-eﬃciency. Once we collect samp les that reﬂect the unknown underlying distributions, the optimization part is easy and straightforward. Therefore, it is not relevant to discretize the decision space inside each system and perform OCBA. Figure 4: The comparison between SEO and uniform sampling in the newsvendor problem. In this work, we have formulated and provided solutions f or a class of problems that we refer to as selecting the best optimizing system (SBOS). In a SBOS problem, there are a ﬁnite number of systems as contenders. Inside each system, there is a decision variable that aﬀects the system’s expected performance. The comparison between diﬀerent systems is based on their expected performances under their own optimally chosen decisions. Without knowing the systems’ expected performances nor what is the optimizing decision inside each system, we design an easy-to-implement algorithm that sequentially assigns samples to diﬀerent systems and recommend s a selection of the best after exhausting a user-speciﬁed sampling budget. Th e proposed algorithm integrates sequential elimination and sto chastic grad ient descent to exploit the structure inside each system and make comparisons across systems. In this ﬁxed-budget setting, we prove an exponential rate of converge to zero for the algorithm’s probability of false selection as the sampling budget increases. We then demonstrate , c, Pstands for the price, cost and the demand distribution for the i-th product. Here, 4 shows the comparison between SEO and uniform sampling algorithms in the newsvendor reliable algorithm performance through three numerical examples. In future work, we ﬁnd two lines that are interesting and relevant. The ﬁrst line concerns a diﬀerent ﬁxed-precision (or ﬁxed -conﬁdence) framework for SBOS problems, which will have distinct needs for algorithm design and analysis compared to the ﬁxed-budget s etting in this work. The second line concerns a distributionally robust framework of SBOS problems. One motivation to consider a distributionally robust setting is because of system non-stationarities, where the prob ab ility models built to reﬂect today’s system can be diﬀerent (but closely connected) to those of the system in one month. That said, the robus t SBOS problems will present a m ax-max-min structure, demanding new algorithm design and analysis.