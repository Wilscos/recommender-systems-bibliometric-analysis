<title>Single-Item Fashion Recommender: Towards Cross-Domain Recommendations  Seyed Omid Mohammadi*     </title> <title>Hossein Bodaghi       </title> <title>Ahmad Kalhor         </title> University of Tehran, College of Engineering, School of Electrical and Computer Engineering, Tehran, Iran  Fashion Recommendation, Cross-Domain, Augmentation, Evaluation.  The ever-growing fashion e-commerce has led to a massive increase in the number of fashion items, including clothing,  bags, shoes, and accessories, posted online. However, the bigger the market, the harder it will be for the customers to  find items suited to their needs. Thus, online shops are beginning to implement visual search engines and recommender  systems as these systems increase customer satisfaction by providing a pleasant shopping experience and facilitating  the buying process.  Most  of the  conventional recommender  systems are  designed  based  on textual  information and  user similarities  which means that they are incapable of using visual features, as a critical source of information and one of the most  important aspects of fashion, to their advantage. Deep learning techniques can enable these systems to be capable of  multi-level understanding of similarities, utilizing low-level details, namely shapes, edges, and colors, as much as higherlevel abstractions and human-level notions of similarity. Unlike collaborative-filtering methods, deep learning is also  promising in cold-start problems and high data sparsity cases.  This article takes three steps towards achieving a single-item fashion recommender system that can handle both inshop  and  street-to-shop recommendations. The  first  step aims to  design and develop  a content-based recommender  system using fashion items’ “Shop” images. The proposed system uses deep convolutional neural networks to extract  visual features of images and forms recommendations based on a similarity check. Then, we utilize this content-based  structure  to  create  a  two-stage  personalized  recommender  system  and  show  that  the  proposed  method  improves  previous works’ results.  As most small e-commerce businesses utilize user-created fashion images and content, fashion recommenders must  perform well on standard Shop images and handle Street/Wild images as well. Moreover, the primary connection of  users  to these  systems  is  through uploading  pictures  that they  have  shot.  Hence,  the next  stage of  this research  is  dedicated  to  finding  a  solution  that  tackles  the  problem  of  cross-domain  recommendation  using  a  background  augmentation technique.  Although fashion retrieval (finding an exact match) and fashion recommendation (finding similar items) might be  very close and use similar methods, the main focus of this article is on recommendation tasks. While evaluation methods  for retrieval tasks are numerous and well-developed, including precision/recall @k and accuracy, it is challenging to  define a precise objective evaluation metric for recommendation tasks. One can only use the same retrieval evaluation  metrics for these tasks if similar items are labeled and ground truth is available, which is not most of the time. Thus, we  also propose an evaluation framework to obtain quantitative information from subjective evaluations and be able to  compare multiple recommendation systems with a specific goal in mind.  The main contributions of this article are as follows:  •  It develops an in-shop content-based fashion recommender and shows its power in returning similar fashion  items from single catalog image queries.  •  It utilizes previous works to turn this system into a personalized fashion recommender that considers user  preferences. An increase in performance is also illustrated.  •  It presents a new background augmentation technique to narrow the gap between Shop and Street fashion  image domains and develop a system much more robust to out-of-domain queries.   •  Finally,  it  suggests  a  method  of  evaluating  recommender  systems  with  specific  goals  and  discusses  the  evaluation results of several systems.   This work is organized into six sections. Sec. 2 provides a background of the matter. Sec. 3 further explains the methods,  followed by the experiments presented in Sec. 4. Then, Sec. 5 discusses the results and different aspects of the system.  Finally, Sec. 6 develops a conclusion and presents future research directions.  Many studies used Bayesian Personalized Ranking (BPR) [1] for item recommendation tasks until [2] introduced VBPR,  its  visual  form  which  takes  into  account  the  content  of  images  as  well.  Reference  [3]  used  a  convolutional  neural  network,  VGG, to  be  specific and  cosine  similarity  for content-based  recommendations.  However, the network was  trained using less than 50 thousand images, and it could only classify the items into seven single-label categories. On  the other hand, [4] experimented with AlexNet and BN-Inception mixed with KNN as a similarity measurement, but the  number of classes was still limited to nine categories and five texture types, which were classified using two separate  networks. Like many other studies, this work did not provide a comparison for the recommendation task and only used  classification accuracy as an implicit objective metric.  For personalization purposes, [5] proposed a structure using DenseNet, pre-trained on ImageNet, to capture user  preferences and recommend a set of outfits for each user. Moreover, inspired by the structure of VisNet [6], [7] used  ResNet101 paralleled with a shallow net to extract features and generated personalized recommendations using a second  dense neural network. The importance of this study was twofold. First, it used ResNet101 and showed that the results  were superior compared to that of VGG16. Furthermore, unlike previous works, the proposed network used multi-label  classification, and the number of classes was considerably high, which was closer to real-life conditions.  Another well-known challenge in fashion recommendation is the gap between professional catalog images used in  online shops (called Shop images) and user-created images (called Street or Wild images). The problem of cross-domain  recommendation has attracted lots of attention through the years as many researchers, including [8], [9], and [10], have  tried to bridge the gap between two fashion domains. One of the most famous, because of its real-world application,  examples of this is called street-to-shop. Reference [11] was one of the firsts to address this issue. Soon others gained  interest  as [12]  used  visual  phrases and  [13]  used  articulated pose  estimation and  image  retrieval  techniques.  Deep  learning-based approaches such as [14] and [15] led to far superior results. Zalando researchers proposed a model called  Street2Fashion to segment the background of images in 2019, which highly improved their results [9]; unfortunately,  they did not release their images. Furthermore, recent studies suggest that it is possible to further improve the results  by using fashion landmarks [16], [17].  While most of the studies mentioned above use two sets of data (Shop and Street) to train their networks, these crossdomain fashion datasets are rarely available. It can be challenging to find a large-scale, publicly-available fashion dataset  that meets the needs of training such systems as most of the existing datasets are either too small (in terms of size or  number of tags) or not accessible to the public. Thus, we aim to put the idea, whether it is possible to achieve acceptable  results using only one dataset of Shop images, to test. We propose a background augmentation technique to use a Shop  dataset and simulate the conditions of Wild or Street fashion datasets.            where:      The final feature extractor is depicted in Figure 2. It takes a single fashion item catalog image as input and predicts labels  for that image from a pool of 1102 labels. The features are extracted from the layer before the last (classification) layer.  Needless to say that this network can also be used directly in attribute and label prediction tasks in online shops. Now  that visual features are obtained, a similarity check is needed to form the recommendation list. Cosine similarity is used  here as it is fast and leads to great results.   The next phase  is to  personalize the recommendations.  The  same  feature extractor network  can be  used  for  this  purpose, as shown in Figure 3. For the second network, we use the structure proposed by [5]. The system can take a mix  of previously purchased items’ image features (called  Cart or shopping cart items) as input and recommend a list of  similar items tailored to a specific user’s taste. This mix of items can be an average of all items’ features weighted by  user rating as in Equation 3. This way, there will not be a limit to the number of items before a prediction can be made,  as this method supports carts with any number of items.  Furthermore, this way, we explicitly use user preferences in the form of user ratings. The main downside to this is that  carts should be uniform  and from the same fashion categories. One way is to break a user’s main cart into multiple  smaller uniform carts and use the network to find recommendations for each group separately. For example, one can  use K-Splits [18] to automatically identify different item categories formerly purchased by a user (namely shoes, shirts,  jeans) and cluster similar items together. There are many ways to improve this system, but personalization is not the  main focus of this article.  Previous works which used deep domain adaptation methods utilized images from two different domains. However, this  research aims to train a network robust to street images by only using one fashion dataset made of Shop catalog images  with neutral  backgrounds and standard poses. Thus, it proposes a new augmentation  technique  to  create street-like  images that force the network to focus on fashion items present in the image and not the background.  The background augmentation technique puts fashion items in front of various backgrounds with different levels of  complexity in the training phase of the network. For this purpose, we find the boundaries of the fashion item or model  shown in the image by using contours. This task will generally be straightforward and error-free as shop images contain  neutral and one-color backgrounds. After this, the main images are masked and cropped from the background. Next, we  paste these masks onto random, more complex backgrounds. This method has several benefits. Firstly, the system sees  the same fashion outfit in front of varying real-world backgrounds in each run, which helps focus attention only on the  outfits and  not the  whole  image.  Secondly, we  have  complete control over the  whole process. For instance,  we can  choose the settings that best suit the final goal of the system since both the complexity of background images and the  ratio of images with backgrounds are controllable. Lastly, real-world scenes and images can be downloaded in bulk, and  a good dataset of backgrounds can be gathered with minimum effort. Figure 4 shows images with standard augmentation  techniques, including flip, rotation, shift, and shear, alongside images with background augmentation. This method can  close the gap between fashion shop images and street images.  The experiments are conducted using Python 3.7.4 and Tensorflow and Keras libraries. Numerous significant publicly  available fashion datasets exist. This work needs a large-scale dataset of “Shop” fashion images with user history and  item descriptions. Thus, this research chooses the Amazon Fashion dataset [19] as it perfectly suits its needs.   5(.-6**7#$%  5(.-6**7- "'-6**7-"'-8-,'*7However, evaluating the recommendation results is not that straightforward as subjectivity plays an essential role in it,  and there is no ground truth. Logically, better visual features lead to better recommendations. Thus, the IOU or feature  extractor’s classification accuracy can be used as implicit objective metrics for this purpose, but these are not one-toone comparable. This article tackles this issue by proposing an objective-guided human score which turns a subjective  evaluation of the results into comparable numerical values based on specific goals of the recommendation system.  Not all recommender systems are the same. In fact, the goal behind using such systems might be completely different  from company to company. If the system is to be used as an image search engine, then the results are expected to be of  the same category with similar shapes and colors. On the other hand, recommendation results for advertising need to  be novel items with a wide variety. Hence, an objective-guided metric is proposed to evaluate different systems based  on the goals they are meant to satisfy.  First,  for  an objective-guided  human  score,  some fashion images  are needed  as queries.  These  images  should  be  carefully chosen to indicate the goal of the system. For example, the ratio of Shop/Street images should be set based on  the predicted ratio of Street image queries the systems need to handle in the future.  It is good to mix a set of easy and  more complex images to make sure the system works well under different circumstances. The number of images is also  optional;  more images  probably increase  the accuracy  of  this  evaluation,  provided that  they do not  bore or tire  the  human scorers. In short, the number of chosen images, their domain, and their complexity are all controllable based on  the system’s goals.  Next, multiple criteria are defined to score the functionality of each system based on them. This step, again, is entirely  flexible based on the needs of the evaluators. This article uses seven criteria: category, subtype, fabric/texture, color,  variety, details, and shape difference. The order of showing the results, domain sensitivity, price range, and many more  criteria can be added to this list optionally.  •  Category: Defines the main category of an image, such as top, bottom, footwear, and jewelry.  •  Subtype: Defines subtypes of the same category, such as boots, high heels, college, and slippers.  •  Fabric/Texture: Shows the main fabric or garment’s texture, such as denim, leather, smooth, and shiny.  •  Color: Defines the dominant color of the item, such as red, green, blue, yellow.  •  Variety: The number of novel items (different category, subtype, or color). Almost on the opposite side of  the other criteria, because the higher the variety score is, the lower other scores will be.  •  Details: The number of results that follow fine details, such as necklines, zipper, pockets, and design.  •  Shape Difference: The number of items that do not follow the outline of the query item, such as images  with different angles, different perspectives, rotations, flips.  Finally,  we  input  the  queries  into  all  different  recommender  systems,  save  top-10  results  for  each,  and  create  an  evaluation sheet as shown in Figure 14. Every human scorer now scores each system separately based on individual  criteria mentioned before. For each criterion, the scorer assigns a hit@10 score from 0 to 10. These scores can easily be  turned into percentages later. All criteria scores are then processed using a weighted average, and the weight of each  criterion is set based on its importance regarding the goal of the system. Additionally, all the scores for each system are  averaged as well, and one final objective-guided human score for each system is obtained, which will be comparable to  other scores provided that they have the same goals.  This method is called objective-guided as almost all of its parameters (queries, criteria, and weights) are flexible and  can be set based on the needs of the evaluator. Nevertheless, once the parameters are set for a specific goal, the results  of this evaluation will be directly comparable. Not only that, but evaluation results of each criterion are also comparable,  which helps determine the effects of different methods on each criterion separately and increases interpretability. This  article uses this evaluation method to compare different street-to-shop recommender systems in Sec. 4.5.  Clean and well-labeled data plays a critical role in training networks. Hence, it is good to dedicate some time to make  sure  the  data  is properly  cleaned.  Amazon Fashion  dataset  contains  information on  45,184 users and  166,270 items.  However, some irrelevant images (Figure 5), duplicates, very small images, corrupted, and missing data in the dataset  had to be taken care of. These summed up to 2,672 images which were deleted, and the final number of items turned to  163,589.  This article uses “Category” and “Title” information in the dataset to extract labels. First, all keywords are separated and  extracted, duplicated and stop-words are removed, words are normalized and cleaned, and only labels with more than  50 repetitions are selected. Then, similar words and synonyms are merged, and finally, only words with 100 repetitions  are extracted as labels. A word cloud of these 1102 final labels is presented in Figure 6. As shown in Figure 8, these labels  are heavily imbalanced, but hopefully, the weighted loss function chosen for the task will mitigate this problem to some  extent. Another potential problem is the imbalance of the number of labels per image. As a multi-label classification  task, each image activates a tiny portion of neurons from the last layer. It can be seen from Figure 7 that images have 125 labels (one exception with 30 labels).  For this purpose,  the  network shown in Figure 2 is used. The dataset is separated into 80% train,  10%  test,  and  10%  validation. All images are resized to 99:!99: with the aspect ratio unchanged. ResNet50 is loaded with ImageNet pretrained weights, and the whole network is fine-tuned using the training data at hand. Dropout, regularizations, early  stopping,  and regular  augmentation techniques are  used to improve the  results. The  final  test  results of the  trained  system are 44.4% IOU, 73.1% precision, and 48.4% recall for the multi-label classification task.   Next, eight random images are chosen as queries, and after feeding them through the network, cosine similarity is  used to form Top-8 recommendations. As shown in Figure 10, the results are fantastically similar in all aspects, including  color,  category,  and  design.  Furthermore,  random  examples  of  label  prediction  results  using  the  same  network  are  illustrated in Figure 9.  Truth: Girls, Multi, Scooters, Skirt, Skorts.  Predicted: Girls, Multi, Print, Scooters, Skirt, Skorts.  *********************************************************************************  Truth: Black, Casual, Dress, Empire, Maxi, Plus, Size, Star, Strap, Women.  Predicted: Black, Casual, Dress, Maxi, Plus, Size, Women.  *********************************************************************************  Truth: Accessories, Boys, Dakota, Flats, Girls, Mary Jane, Toddler.  Predicted: Accessories, Boys, Girls, Mary Jane, Sneaker, Stride Rite, Toddler.  This section trains a second network on top of the feature extractor trained in the previous section to personalize the  results using the structure illustrated in Figure 3. For personalization, the work of [5] is followed. 44,103 users are chosen,  each with 5-7 reviews to balance the data. The total number of reviews is 269,104, so each user has approximately 6.1  reviews (bought items). Carts are calculated based on Equation 3 using these users, their bought items, and their ratings.  After training the network, it reaches 78.4% test accuracy. In Figure 11, the proposed method (fine-tuned ResNet50  paralleled with a shallow net and a personalizer network on top) is compared to collaborative filtering, VGG, ResNet101,  fine-tuned  ResNet101, and  fine-tuned ResNet101  paralleled  with  a  shallow  net. The figure shows that  the  Recall@K  result  for  the  proposed  method  is  almost  always  better  than  previous  methods  for  all  K  values,  except  for  Top-1  recommendation results.  Visual inspection also shows the power of this personalized recommender. The results are shown in Figure 12 for six  random users. The network takes items bought by each user (their cart) and the ratings and outputs a list of similar  items. Each row shows a user’s cart, followed by two rows of recommendations. ‘U’ stands for users, ‘B’ for the bought  items, and ‘R’ for the recommendation results. User ratings for each bought item are also shown in the figure using stars.  It can be seen that the results are of high quality and very similar.  Although the results in previous sections seem promising, if the image domain is changed to Street photos, the quality  of results will decrease. The network is robust to some extent of change, but this robustness is not enough to enable the  system  to  handle  out-of-domain  images  efficiently.  Thus,  this  section  re-trains  the  network,  this  time  using  the  background augmentation technique introduced in Sec. 3.1.  A  dataset  of  several  thousand  backgrounds  is  collected,  primarily  natural  or  city  scenes.  The  system  randomly  chooses a background for each image in each epoch. After completing the training process, the system will be able to  handle both in-shop catalog images and more complex street-like queries. We collected a small dataset of out-of-domain  images from online shops on Instagram to show that the proposed structure can find and recommend similar items to  these queries from the items available in the shop. Examples are illustrated in Figure 13.  Next,  the  objective-guided  human  score  is  used  to  compare  the  results  of  multiple  networks.  Although  the  results  presented here are the best of more than 80 versions and trials with different conditions, only five networks are compared  in this section. These versions are as follows, and they all utilize the background augmentation and the same training  techniques:  •  V1: Only a ResNet50 network.  •  V2: ResNet50 paralleled with a shallow network.  •  V3:  Similar  to  V2  but  with  heavier  augmentations  to  check  to  what  extent  traditional  augmentation  techniques can improve street-to-shop recommendations.  •  V4: Only an EfficientNet [20] with ;!; input.  •  V5: The same EfficientNet paralleled with a shallow network.  Top-10 street-to-shop recommendation results of different systems are gathered as an evaluation sheet depicted in Figure  14.  It can  be  seen  that it  is  challenging  to subjectively  rate  and  compare these  recommendations as  the  results  can  sometimes be very close to, very different from, or even contradictory to other queries. The objective-guided human  score is a framework that organizes these subjective evaluations into comparable percentage scores.  Seven criteria, explained in Sec. 4.1, are chosen to compare these systems. Fifty query images with mixed complexities  and a Shop/Street ratio of 2/3 are prepared and fed to each system, resulting in 50 evaluation sheets like the one shown  in Figure 14. Next, human evaluators rate (hit@10) the results of each system for each query based on each criterion  separately. The scores are then processed using a weighted average based on the importance of each criterion for the  specific goal of the network. The weights in this article are five for the category, four for subtype, one for color and  variety and details, and 0.25 for the shape difference criterion. The scores for each criterion and the final objective- guided human score (OHS) for each system are provided in Table 1 in percentages. The best and worst scores in each  column are in green and red colors, respectively.  Table  1  reveals  fantastic  information  about  the  systems.  First  of  all,  it  can  be  seen  that  although  the  IOU  of  the  classification task of the feature extractor can be used as an implicit evaluation of the recommendation system, it is not  directly comparable. IOU is also not interpretable either. On the other hand, OHS explicitly shows the effect of each  parameter change on every single criterion.  Adding a shallow branch to deep networks marginally decreases the category score but improves color and variety  scores. This finding agrees with [7] as they pointed out that a shallow net helps recover the color, which is usually lost  in deeper network structures. Additionally, this technique leads to better results in terms of final OHS. The power of  EfficientNet is also shown as both V4 and V5 output far more superior results. It seems that variety and shape difference  are the only criteria in which the EfficientNets show weakness. Thus, it is preferable to use these networks in image  search engines in which these two criteria are of less importance.  This section discusses several aspects of the experiments done on the recommender systems earlier. First, the amount  of time and effort spent on preparing the dataset and labels, especially the label extraction phase, is of critical importance  as it will be the base of other networks. This article used the old-fashioned label extraction method. However, newer  natural  language  processing  techniques  and  models,  like  BERT  [21],  might  significantly  improve  the  results  as the  relationship  between the  words  are  kept  intact. Noisy  and  missing  labels,  for  example,  pink labels  in  Figure 9,  also  deteriorate the performance. A problem that can be solved by choosing a cleaner dataset with better labels.  Next is the overfitting problem. The training samples seem to be enough (more than 130 thousand images), and the  network size is also logical. At first, it seems like that the heavy imbalance of labels leads to this problem. Even though  it indeed has adverse effects on the results, it is not the only case. Further inspection of the labels reveals that most of  them are repeated only 100 to 1000 times which makes them hard, if not impossible, to learn. In fact, apart from the  imbalance, we are also facing a lack of data regarding each separate label. Statistically speaking, 775 labels (70% of total)  have less than 500, and 456 labels (41% of total) have less than 200 repetitions. These 41% might be the reason why the  recall evaluation metric is so low.   To further  investigate this theory, we trained four networks using different sets  of labels.  In each trial,  the least  number of repetitions for tags is increased, and we delete more labels to see the effect these low repeated labels have on  the network. The results are summarized in Table 2. It can be seen that precision is always high, and the system assigns  the learned labels with high certainty; however, the recall is problematic due to the reasons mentioned earlier. This lack  of data for some labels even causes numerous neurons in the last layer to die, and finding and pruning these might also  improve the final results.   The true power of the background augmentation technique in bridging the gap between Street and Shop images can be  seen in Figure 13. The system can successfully recommend similar items, although the inputs are more complex Street  images that never existed in the training data. Almost none of the out-of-domain queries would lead to acceptable results  without applying this technique.  Finally, the advantages of using the objective-guided human score for evaluating final recommendation results can  be inferred from Table 1. Every aspect and detail of this method is customizable based on the user’s goals, hence the  name objective-guided. Furthermore, this scoring method is completely interpretable, and the effects on each criterion  can be  analyzed separately. Two things  are  essential to make sure  this method  provides reliable results. Firstly,  the  number of test queries and their complexity should be chosen carefully to show the whole dataset’s qualities. Secondly,  the more human scorers are, the more accurate the results will be.  Fashion e-commerce is growing at an unbelievably fast pace. However, as the number of fashion items in online shops  increases  exponentially,  so  does the  difficulty  of  finding  specific items  in this  vast  market.  Thus,  online  stores  and  companies are feeling the need for powerful content-based recommender systems and image search engines.  This article provided a single-item content-based fashion recommender for in-shop search and recommendation by  training a convolutional neural network consisting of double branches, a deep ResNet50 network, and the other one a  shallow  net.  Then,  it  used  this  network  as  a  feature  extractor  in  a  two-stage  structure  to  form  personalized  recommendations. Next, a background augmentation method was proposed to enable the system to make cross-domain  suggestions.  Finally,  this  work  introduced  objective-guided  human  score, an  evaluation  metric  for  recommendation  tasks, a customizable framework that turns subjective evaluations into interpretable and comparable percentage values.  The comparison results showed that EfficientNets could be superior to ResNets for the task at hand.  One future research direction is to utilize clustering methods like k-means and k-splits to guide the personalization  system through the fashion feature space. Another promising direction is using advanced natural language processing  methods and relation extraction techniques to obtain noise-free labels. Furthermore, a comparison of the method with a  twin or triplet network would also be scientifically interesting. 