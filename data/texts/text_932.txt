Conversational recommender systems (CRS) aim to recommend suitable items to users through natural language conversations. For developing eective CRSs, a major technical issue is how to accurately infer user preference from very limited conversation context. To address issue, a promising solution is to incorporate external data for enriching the context information. However, prior studies mainly focus on designing fusion models tailored for some specic type of external data, which is not general to model and utilize multi-type external data. To eectively leverage multi-type external data, we propose a novel coarse-to-ne contrastive learning framework to improve data semantic fusion for CRS. In our approach, we rst extract and represent multi-grained semantic units from dierent data signals, and then align the associated multi-type semantic units in a coarse-to-ne way. To implement this framework, we design both coarse-grained and ne-grained procedures for modeling user preference, where the former focuses on more general, coarsegrained semantic fusion and the latter focuses on more specic, ne-grained semantic fusion. Such an approach can be extended to incorporate more kinds of external data. Extensive experiments on two public CRS datasets have demonstrated the eectiveness of our approach in both recommendation and conversation tasks. • Information systems → Users and interactive retrieval;Recommender systems. ACM Reference Format: Yuanhang Zhou, Kun Zhou, Wayne Xin Zhao, Cheng Wang, Peng Jiang, He Hu. 2022. C-CRS: Coarse-to-Fine Contrastive Learning for Conversational Recommender System. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining (WSDM ’22), February 21–25, 2022, Tempe, AZ, USA. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3488560.3498514 With the rapid development of intelligent agents in e-commerce platforms, conversational recommender system (CRS) [4,13,24] has become an emerging research topic, which aims to provide eective recommendations to users through natural language conversations. In general, a CRS consists of a conversation module to converse with users and a recommender module to make recommendations. To improve user satisfaction, a major objective of the CRS is to accomplish the recommendation task within as few conversation turns as possible. Therefore, it is important for a CRS to accurately capture user preferences based on several initial turns of conversational utterances, which contain very limited context information to understand user needs. Considering this issue, existing works [2,16,32] have introduced external data sources to enrich the contextual information. One line of research [2,36] utilizes structured external data (i.e., knowledge graphs) to enhance the representations of entities and words occurring in the conversational context. Another line of research [18] introduces unstructured external data (e.g., item reviews) to improve the item representations for recommendation and help generate informative responses. Due to the data heterogeneity, it is dicult to directly external data for improving CRS, because conversation data and external data usually correspond to very dierent information forms (e.g., conversation utterances v.s. knowledge graphs) or semantic content (e.g., conversation utterance v.s. online reviews). There exists a natural semantic gap between conversation data and external data. The case becomes even more dicult when multi-type external data (also in dierent data forms) is available for utilization. Several eorts have been made to leverage external data for improving CRS [18,36]. However, they mainly focus on designing specic semantic fusion model tailored to some type of external data, which cannot apply to multi-type external data. Therefore, it is essential to develop a general approach to bridging the semantic gap between dierent data signals for CRS. To fuse multi-type context data, a major challenge is that they usually correspond to very dierent semantic spaces. And, it may Figure 1: An illustrative example of a conversation on movie recommendation between a user and the system. The associated external structured data (knowledge graph) and unstructured data (reviews) of conversational context have been also presented. Items (movies) are in blue and entities (e.g., actors) are in red. hurt the original representation performance if we directly align their semantic space as previous studies [18,36]. To address this issue, we are inspired by an important observation that context data itself (no matter external data or conversation data) is in a multi-grained form, e.g., entity and entity subgraph in knowledge graphs, and word and sentence in utterances. Actually, user preference is also reected in a multi-grained way [34]: a ne-grained semantic unit reects some specic tastes (e.g., an actor entity), while a coarse-grained semantic unit reects some general tastes (e.g., a set of comments for ction movies). Given a conversation scenario, the semantic units from dierent data signals can be associated according to the reected user preference. For example, in Figure 1, the word “It” in the fourth utterance corresponds to the entity “It (2017)” in Freebase, and the fourth utterance essentially corresponds to a subgraph spanned based on the entity “It (2017)”. Such an example indicates that it needs a multi-grained semantic alignment in order to fuse dierent semantic spaces and better characterize user preference. To this end, in this paper, we propose a novelCoarse-to-ne Contrastive learning approach forConversationalRecommender System, calledC-CRS. The core idea is to rst extract and represent associated multi-grained semantic units from dierent data signals, and then align the corresponding semantic units from dierent data signals in a coarse-to-ne way. To implement coarse-to-ne semantic fusion, we involve both coarse-grained and ne-grained pre-training procedures, where the former focuses on more general, coarse-grained user preference while the latter focuses on more specic, ne-grained user preference. Such a way allows the model to gradually fuse dierent semantic spaces in a multi-grained manner, which is likely to yield more coherent fusion representations. The optimization objectives for coarse- and ne-grained fusion are developed in a unied form of contrastive learning, where we pull semantically associated semantic units from dierent data signals together and push apart irrelevant ones in their representation spaces. Based on the pre-trained representations, we develop a recommender module and a conversation module to accomplish the corresponding tasks. Our approach is general to leverage various types of external data for CRS. To our knowledge, it is the rst time that multi-type external data has been leveraged for CRS. We address this task with a novel coarse-to-ne contrastive learning approach, which can better fuse semantic spaces from dierent data signals. Such an approach can be extended to incorporate more kinds of external data. Extensive experiments on two public CRS datasets have demonstrated the eectiveness of our approach in both recommendation and conversation tasks. In this section, we review the related work from the following two perspectives, namely conversational recommender system and contrastive learning. With the rapid development of dialog system [21,28,30,39] in recent years, interactive conversation with users becomes an appealing approach to obtaining user dynamic intent and preference. Based on it, conversational recommender system [12,13,24] (CRS) has become an emerging research topic, which aims to provide high-quality recommendations to users through natural language conversations. One category of CRSs utilized predened actions to interact with users, such as item attributes [4,37] and intent slots [24]. Most of these methods mainly focus on accomplishing the recommendation task within fewer turns [12,24]. A surge of works adopt multi-armed bandit [4], reinforcement learning [12] and Thompson sampling [14] for interaction with users. However, this category of works do not pay much attention on generating high-quality natural language responses but usually rely on predened dialog templates and rules to compose responses [12, 24]. Another category of CRSs develop natural language based approaches, focusing on both making accurate recommendation and generating human-like responses [15,16,26,36], these methods incorporate a generation-based dialog component to converse with users. However, since a conversation usually contains a few sentences, lack of sucient contextual information for accurately capturing user preference. Existing works leverage entity-oriented knowledge graph [2], word-oriented knowledge graph [36] and review information [18] to alleviate this issue. This paper extends the second category of research by leveraging rich external data for improving CRSs. Our key novelty lies in the coarse-to-ne contrastive learning approach, which can eectively fuse multi-type heterogeneous data in a principled way. Contrastive learning has been long considered as eective in constructing meaningful representations [3,6,17], which learns the representations by making a comparison between dierent samples. Usually, it assumes a set of paired examples, where both examples are semantically related neighbors. Then the training objective is dened to pull the representations of neighbors together and push apart non-neighbors. Recently, as a pre-training technique, contrastive learning has achieved remarkable success in computer vision [3,8], natural language processing [5,27] and information retrieval [1]. These works utilize data augmentation strategies to construct semantic related example pairs based on original data (e.g., random cropping and rotation of images [3]). Besides, contrastive learning has also been adopted to fuse multi-view information, such as image and text [19,29,33], text and graph [9]. It drives the representations of related information in dierent types to be similar, such that each kind of representations can be enhanced by each other. In our method, we rst extract and represent associated multigrained semantic units from dierent data signals, and then align the corresponding semantic units from dierent data signals via a coarse-to-ne contrastive learning. Such a contrastive learning approach can eectively fuse the representations of these semantic units from heterogeneous signals. The goal of CRS is to recommend appropriate items to a user via a multi-turn natural language conversation. Typically, a CRS consists of two core components, namely the recommender component and the conversation component, and the two components should be integrated seamlessly to fulll the recommendation goal. Notations for CRS.Formally, let𝑢denote a user from user set U,𝑖denote an item from item setI, and𝑤denote a word from vocabularyV. A conversation (or a conversation history)𝐶consists of a list of utterances, denoted by𝐶 = {𝑠}, in which each utterance𝑠is a conversation sentence at the𝑡-th turn and each utterance𝑠= {𝑤}is composed by a sequence of words. As the conversation goes on, the conversation utterances are aggregated (called conversation history or conversation context), and the CRS estimates the user preference based on the conversation history. At the𝑡-th turn, the recommender component selects a set of candidate itemsIfrom the entire item setIaccording to the estimated user preference, while the dialog component needs to produce the next utterance 𝑠to reply to previous utterances. External Data.Besides the conversation history𝐶, in the online platform, some external data is usually available to enhance the performance of CRS. In the literature, two kinds of external data are widely used for CRS, namely structured external data knowledge graph [2,36] and unstructured external data item reviews [18]. We also consider leveraging the two kinds of external data in this work. For knowledge graphG, it is composed by an entity setNand a relation setR. The entity set contains all the items (i.e.,Iis a subset of the entity set) and other item-related entities. Furthermore, for each user𝑢, her/his interacted entities set (i.e., entities occurring in the conversation history) is denoted byN, which composes a subgraphGthat reect the user preference. For an online review, it can be considered as a document consisting of sentencesS = {˜𝑠}. The two kinds of external data covers both structured and unstructured data, and reect a multi-grained semantic form: entity v.s. subgraph for knowledge graph, and sentence v.s. document for online reviews. As will be shown later, our approach is general to incorporate multiple types of external data in CRS. Task Denition.Based on these notations, the task of this paper is dened as: given the multi-type context data (i.e., conversation history𝐶, knowledge graphGand reviewsS), we aim to (1) accurately recommend itemsIand (2) generate proper response𝑠 to the user 𝑢 at the (𝑡 + 1)-th turn of a conversation. In this section, we present the proposedCoarse-to-neContrastive learning forConversational recommender system, calledC-CRS. Since we consider utilizing multi-type context data for CRS, we rst study how to separately encode these context data. Then, we introduce the coarse-to-ne contrastive learning approach to gradually fusing context data for pre-training eective data representations. Based on the learned representations, we nally describe our solutions for both recommendation and conversation tasks. The overview illustration of the proposed model is presented in Figure 2. Given the multi-type context data, we adopt corresponding encoding modules to generate the data representations in separate semantic spaces. Next, we present the encoding modules for conversation history, knowledge graph and reviews, respectively. 4.1.1 Encoding Conversation History. Conversation history𝐶consists of utterances{𝑠}generated in a session between the CRS and the user, which depicts the user-system interaction about the information needs. Since the utterances, which are usually short sentences, are closely relevant, following previous works [2,36], we concatenate these utterances{𝑠}in a chronological order to form a long sentence𝑠. To obtain the representations of the conversation history, we adopt a standard Transformer [25] to encode 𝑠as following: where contextual word representations𝑭are obtained on the top layer of Transformer. Then we utilize a self-attentive layer to produce the representation of the conversation history e: where Wand 𝒃 are learnable parameter matrix and vector. 4.1.2 Encoding Knowledge Graph. The knowledge graphGconsists of an entity setNand a relation setR. It stores semantic facts in the form of a triple ⟨𝑛, 𝑟, 𝑛⟩. Consider that the edges connected the nodes may own useful relation information, we utilize R-GCN [20] to encodeG. Formally, the representation of node 𝑒 at (𝑙 + 1)-th layer is calculated as: where𝒏∈ Ris the node representations of𝑒at the𝑙-th layer, Edenotes the set of neighboring nodes for𝑒under the relation𝑟, WandWare learnable matrices and𝑍is a normalization factor. After aggregating the graph information, we obtain the node representations matrix𝑵on the top R-GCN layer. As shown in previous studies [2,36], it is particularly important to consider the historically interacted entitiesNfor modeling the user preference. Figure 2: The overview of our model in a movie recommendation scenario, where “SA” denotes the self-attention layer. In the coarse-to-ne contrastive learning, we rst conduct coarse-grained contrastive learning using coarse-grained features, and then conduct ne-grained contrastive learning using ne-grained features. Therefore, we collect the node representations of user interacted entities as𝑵, and utilize self-attentive mechanism as Eq. 2 to generate the graph-based user representation𝒆. The basic idea is to automatically learn the importance of each interacted entity for user𝑢, so that we can derive the user preference considering the levels of entity importance. 4.1.3 Encoding Reviews. The review textSof an item is a set of sentencesS= {˜𝑠}written by online users about the item𝑖. Similar as the conversation history, we utilize the standard Transformer model to encode each sentence and leverage a self-attention layer to obtain the sentence representation matrix𝑬. Note that the parameters of this Transformer and self-attention layer are dierent from those in Section 4.1.1. Besides, consider that the reviews are usually noisy and may be irrelevant to user preference [18], we further utilize a sentence-level self-attention layer to select the useful information within the sentence representations. Finally, we produce the review-based user representation 𝒆. After the above encoding, we can obtain the corresponding representations for conversation history, knowledge graph and review text. The three kinds of context data are represented in dierent semantic spaces. Next, we study how to fuse them in order to derive shared data semantics. In order to utilize context data, we need to eectively fuse their representation spaces, so that their information can be shared and leveraged across dierent data signals. In this section, based on the multi-grained correlations between multi-type context data, we propose a coarse-to-ne contrastive learning method to fuse the multi-type information to enhance the data representations. The main idea is to represent each type of data from both coarsegrained and ne-grained views and associate the corresponding representations at dierent granularities in a coarse-to-ne manner. We will introduce the coarse-grained and ne-grained pre-training approaches in the following. 4.2.1 Coarse-Grained Contrastive Learning. Multi-type context data in a coarse-grained form mainly reects the overall user preference. As in Section 4.1, we obtain the coarse-grained representations of the user from the views of the conversation data𝒆(i.e., conversation history), knowledge graph𝒆(i.e., subgraph) and review text𝒆(i.e., review document) . There exists a natural semantic gap between these data representations. To bridge this gap, we propose a contrastive learning based pre-training approach to aligning and fusing the three types of context data. Contrastive learning is a widely adopted pre-training technique which learns the representations by pulling semantically close representations together and pushing apart non-related ones. In our setting, we have three representations𝒆,𝒆and𝒆depicting the same user preference from dierent views, which are considered as semantically close ones. Therefore, based on the three representations, we take the pairs(𝒆, 𝒆),(𝒆, 𝒆), and(𝒆, 𝒆)as positive examples, while the representations from dierent users in the same batch are considered as negative examples. Thus, for a mini-batch with𝑏pairs, the coarse-grained pre-training objective is the sum of the triple contrast learning loss, which can be formulated as: 𝐿= 𝐿(𝒆, 𝒆) + 𝐿(𝒆, 𝒆) + 𝐿(𝒆, 𝒆), (4) 𝐿(𝒉, 𝒉) = log𝑒Í where𝒉and𝒉are two types of coarse-grained representations of a user,{𝒉}is the negative example set for positive examples(𝒉, 𝒉), 𝜏is a temperature hyperparameter andsim(𝒉, 𝒉)is the cosine similarity. Since the representations of the same users under dierent views are pulled together, this objective aligns the semantic space of the three types of context data. The three types of representations capture user preference from dierent views, which are complementary to each other. By semantic alignment and fusion using the contrastive learning objective, these representations can be also mutually improved by each other. 4.2.2 Fine-Grained Contrastive Learning. The above coarse-grained contrastive learning fuses the semantic space at the overall level. However, the corresponding semantic associations between negrained semantic units (e.g., words and entities) are neglected. Finegrained context data captures specic user preference about negrained characteristics. Therefore, we further propose to conduct ne-grained contrastive learning for better fusing the representation spaces. For the three types of context data, the ne-grained preferences are encoded in the contextual word representation (𝑭) of a word from conversation history, the node representation (𝑵) of an entity from the knowledge graph, and the representation (𝑬) of a sentence from the review document, respectively. Similar to the coarse-grained pre-training, we also adopt the contrastive learning method for ne-grained pre-training. To construct the semantic-closed example pairs, we consider capturing the correlations among these ne-grained semantic units, i.e., words from conversation history, entities from knowledge graph and sentences from review text. We also consider inter-type data associations. For the word-entity correlation, we utilize the entity linking method [2] to match the entity from the knowledge graph with its corresponding word in the conversation history. For the entitysentence correlation, we match the entity with its most related sentence, which may be the most highly-rate review or descriptive text of the entity. In this way, we can construct the semanticallyconsistent word-entity-sentence representation triples(𝑭, 𝑵, 𝑬) to depict the same ne-grained user preference. Then, we split the triples into pairs(𝑭, 𝑵),(𝑭, 𝑬)and(𝑵, 𝑬)to construct paired positive examples for contrastive learning. Similarly, the representations from other users in the same batch compose a negative example set. Therefore, our ne-grained pre-training objective can be formulated as: where𝐿(·)is dened according to Eq. 5. This optimization objective enforces the alignment among semantic spaces of words, nodes and sentences. To further preserve the enhancement eect of coarse-grained contrastive learning, we integrate its optimization objective with a weight𝜆. Then, the nal ne-grained pre-training objective𝐿is given as follows: Instead of directly fusing dierent semantic spaces, we design a coarse-to-ne fusion way, so the semantic space will be gradually pulled close and nally fused. Based on the pre-trained representations, we introduce our approach to ne-tuning the data representations and network architectures to accomplish the conversational recommendation task. In the following, we will describe the architectures of our recommendation module and response generation module, and detail how to ne-tune them. 4.3.1 Fine-tuning Recommendation Module. Given the pre-trained item representations, we study how to ne-tune them for the recommendation task. We rst generate the user representation, and then ne-tune it on item recommendation task. Note that after semantic fusion, the learned entity representations have learned useful information from other types of context data. Therefore, we only adopt the entitiesNoccurring in the conversation history for learning the user representation. Specically, we stack the entities’ representations of Ninto a matrix 𝑵, and then utilize self-attentive mechanism as in Eq. 2 to produce the user representation𝒆. Finally, we compute the probability that recommends an item 𝑖 from the item set to a user 𝑢: where𝒏is the learned item embedding for item𝑖. We can utilize Eq. 8 to rank all the items and generate a recommendation set to a user. To ne-tune the user representation𝒆and item embedding 𝒏, we apply a cross-entropy loss as the optimization objective: where𝑁is the number of conversations,𝑗is the index of a conversation,𝑀is the number of items, and𝑖is the index of an item. Here, we consider the case with a single ground-truth recommendation. It will be easy to extend the above loss to the case with multiple ground-truth items. 4.3.2 Fine-tuning Response Generation Module. Here, we study how to ne-tune the pre-trained representations for the conversation task. Following KGSF [36], we incorporate multiple crossattention layers in a standard Transformer [25] decoder to fuse the pre-trained representations as following: whereRis the output representation matrix from the decoder at 𝑙-th layer. The above equation follows the similar transformation chain as KGSF [36]: generated words→conversation history→ knowledge graph→reviews. We omit the equation details. Based on it, following existing works [36], we also design the copy network to enhance the generation of informative response. To ne-tune this module for generating more informative responses, we devise an instance weighting enhanced cross-entropy loss as: 𝛼=max(𝛾,) if 𝑓≥ 𝛽 where𝑚is the number of words in generated response,𝛼is the weight considering the frequency of this token,𝛽is a preset threshold,𝛾is to avoid punishing the high-frequency words too much, and𝑓is the word frequency of𝑤in corpus. With the above cross-entropy loss, we can punish the high-frequency tokens, and help generate more informative responses. To summarize, our approach provides a novel coarse-to-ne contrastive learning framework for leveraging multi-type context data to improve CRS. Next, we compare it with existing studies. Conversation-centered approachessuch as ReDial [13] and CRM [24] mainly focus on using the conversation history to accomplish the conversational recommendation task, with or without the external auxiliary data. Our work falls into this category and extends it by leveraging multi-type context data with a novel coarseto-ne contrastive learning framework. As a comparison, most of existing studies focus on some specic type of external data, which is not general to leverage various heterogeneous external data. Knowledge graph based approachessuch as DeepCR [16], KBRD [2] and KGSF [36] fuse external KG and conversational context to help model user representations and generate more informative responses. This category of studies only considers structured external data, which neglects rich unstructured data as below. Review-enhanced approachessuch as RevCore [18] introduce external reviews to CRS as the supplement of conversational context. These methods extract entities from reviews for recommender module and utilize copy mechanism for conversation module. However, reviews are inevitable to contain noise. In our approach, we leverage the coarse-to-ne pre-training approach to fuse the multi-type data, which can adaptively fuse useful information from data and prevent the noisy reviews to directly aect the modeling of user preference. In this section, we rst set up the experiments, and then report the results and give a detailed analysis. In this subsection, we provide an introduction to the details of our experiments, including dataset, baselines, evaluation metrics and implementation details. 5.1.1 Dataset. We evaluate our model on ReDial [13] and TGReDial [38] datasets. The ReDial dataset is an English conversational recommendation dataset constructed with Amazon Mechanical Turk (AMT). Following a set of comprehensive instructions, the AMT workers played the roles of seekers and recommenders to generate dialogue for recommendation on movies. It contains 10,006 conversations consisting of 182,150 utterances related to 51,699 movies. The TG-ReDial dataset is a Chinese conversational recommendation dataset, which emphasizes natural topic transitions from non-recommendation scenarios to the desired recommendation scenario. It is created in a semi-automatic way, hence human annotation is more reasonable and controllable. It contains 10,000 two-party dialogues consisting of 129,392 utterances related to 33,834 movies. For each conversation, we start from the rst Table 1: Results on the recommendation task. Numbers marked with * indicate that the improvement is statistically signicant compared with the best baseline (t-test with pvalue < 0.05). sentence one by one to generate reply to utterances or give recommendations. Since the above datasets do not contain the review data, we retrieve reviews for movies in ReDial and TG-ReDial from IMDBand doubanrespectively. 5.1.2 Baselines. In CRS, we consider two major tasks to evaluate our method, namely recommendation and conversation. Therefore, we not only compare our approach with existing CRS methods, but also select representative recommendation or conversation models as baselines. •Popularity: It ranks the items according to recommendation frequencies in the training set of the corpus. •TextCNN [10]: It applies a CNN-based model to extract user features from conversational context for ranking items. •Transformer [25]: It utilizes a Transformer-based encoderdecoder method to generate conversational responses. •ReDial [13]: This model is proposed in the same paper with the ReDial dataset. It consists of a dialog generation module based on HRED [22] and a recommender module based on auto-encoder [7]. •KBRD [2]: This model utilizes DBpedia to enhance the semantics of contextual items. The Transformer architecture is applied in the dialog generation module, in which KG information is used as word bias in generation. •KGSF [36]: This model incorporates DBpedia and ConceptNet to enhance the semantic representations of items and words, and uses Mutual Information Maximization to align the semantic spaces of dierent components. •KECRS [31]: It constructs a high-quality KG and develops the Bag-of-Entity loss and the infusion loss to better integrate KG with CRS for generation. •RevCore [18]: It proposes a review-enhanced framework, in which reviews are selected by a sentiment-aware retrieval module and are utilized to enhance recommender module and dialogue generation module. For a fair comparison, we use the same review as our approach. Among these baselines, Popularity and TextCNN [10] are recommendation methods, while Transformer [25] is the state-of-theart text generation method. We do not include other recommendation models since there are no historical user-item interaction records except dialogue utterances. Besides, REDIAL [13], KBRD [2], KGSF [36], KECRS [31] and RevCore [18] are conversational recommendation methods. We name our proposed model as C-CRS. 5.1.3 Evaluation Metrics. In our experiments, we adopt dierent metrics to evaluate on the two tasks. For the recommendation task, following [2], we adopt Recall@𝑘(𝑘 =1,10,50) for evaluation. For the conversation task, the evaluation consists of automatic evaluation and human evaluation. Following [2], we use Distinct𝑛gram (𝑛 =2,3,4) to measure the diversity at sentence level. Besides, we invite three annotators to score the generated candidates in two aspects, namely Fluency and Informativeness. The range of score is 0 to 2. The nal performance is calculated using the average score of three annotators. 5.1.4 Implementation Details. We implement our approach with Pytorchand CRSLab [35]. The dimensionality of embeddings (including hidden vectors) is set to 300 and 128, respectively, for conversation and recommender modules. In the structured encoder module, we set the layer number to 1 for GNN networks. We use Adam optimizer [11] with the default parameter setting. In experiments, the batch size is set to 256, the learning rate is 0.001, gradient clipping restricts the gradients within[0,0.1], the temperature of contrastive learning is set to 0.07, and the normalization constant 𝑍of R-GCN in Eq. 3 is 1. During the coarse-grained pre-training stage, we directly optimize the loss as Section 4.2.1. While in the ne-grained pre-training stage, the weight𝜆of the coarse-grained contrastive learning loss in Eq. 7 is set to 0.2. The code and data are available at: https://github.com/RUCAIBox/WSDM2022-C2CRS. To verify the eectiveness of our proposed method on the recommendation task, we conduct a series of experiments and present the results in Table 1. In general, conversational recommendation methods perform better than recommendation methods (e.g., TextCNN and Popularity). Since these methods mainly focus on integrating the conversational module and the recommendation module, which are mutually benecial for each other. For recommendation methods, we can see that TextCNN achieves better performance than Popularity. One reason is that Popularity only recommends the most popular items without considering the contextual information. In contrast, TextCNN is able to model personalized preference from contextual text for better recommendation. For conversational recommendation methods, rst, compared with the TG-ReDial dataset, ReDial model performs better on the ReDial dataset. One possible reason is that the contextual items in conversation from the TG-ReDial dataset are much sparser than those in ReDial dataset, but ReDial model relies heavily on the contextual items to generate the recommendation. Second, KBRD achieves better performance than ReDial. Since KBRD utilizes knowledge graph as external contextual information to improve user preference modeling, and then utilizes R-GCN and Transformer to accomplish the recommendation and conversation tasks, respectively. KGSF achieves better performance than KBRD and KECRS. Table 2: Automatic evaluation results on the conversation task, where "Transf" denotes Transformer model. We abbreviate Distinct-2,3,4 as Dist-2,3,4. Numbers marked with * indicate that the improvement is statistically signicant compared with the best baseline (t-test with p-value < 0.05). C-CRS 0.163* 0.291* 0.417* 0.189* 0.334* 0.424* It improves the data representations by aligning the two semantic spaces between conversations and items via mutual information maximization. Finally, RevCore achieves better performance than other baselines. It incorporates external reviews to enhance the description of items, which help better capture user preference. Our model C-CRS outperforms all the baselines, since C-CRS utilizes multi-type external information to help understand the conversational history, including conversational text, knowledge graph and reviews. To achieve it, our approach applies the coarseto-ne contrastive learning to gradually fuse dierent types of information. Such a way can be benecial to the recommender module by enhancing the data representations. In this subsection, we verify the eectiveness of the proposed model for the conversation task and report the results on automatic and human evaluation metrics. 5.3.1 Automatic Evaluation. We present the results of the automatic evaluation metrics for dierent methods in Table 2. First, we can see that ReDial performs better than Transformer, since ReDial applies a pre-trained RNN model to produce better representations of historical conversation. Second, KBRD achieves better performance than ReDial in most settings. Since it enhances contextual entities and items by external KG and these entities are utilized to produce word probability bias for conversational module. Third, KGSF generates the most diverse response among these baselines. Since it not only aligns the 1 of conversational text and items, but also enhances their representations. Besides, multiple cross-attention layers are performed in the Transformer decoder to further interact the contextual information with the generated response. Finally, RevCore performs not well. One possible reason is that its involved reviews may contain noise. Compared with these baselines, our model C-CRS performs consistently better in all the evaluation metrics, and it improves the Transformer decoder with enhanced multi-type data representations by coarse-to-ne contrastive learning. Such a gradual fusion approach is robust to the noise in the contextual information and can better capture useful semantics from conversational text, knowledge graphs, and reviews. Besides, we further design an instance Table 3: Human evaluation results on the conversation task, where Transf refers to the Transformer model. Numbers marked with * indicate that the improvement is statistically signicant compared with the best baseline (t-test with pvalue < 0.05). Table 4: Results of ablation and variation study on the recommendation task. Coarse and Fine refer to coarse-grained and ne-grained contrastive learning, respectively. CH, SD and UD refer to conversational history, external structured data and external unstructured data, respectively. weighting mechanism to help generate more informative responses. It shows that our approach can eectively improve the response generation task. 5.3.2 Human Evaluation. Table 3 presents the results of the human evaluation for the conversation task. First, ReDial achieves better performance than Transformer, since it incorporates a pre-trained RNN encoder [23]. Second, KBRD achieves a comparable performance with ReDial, which indicates that the entity information from KG is benecial to informativeness. Third, among these baselines, KGSF performs the best in term of informativeness since it aligns the conversational text and items via knowledge graph semantic fusion. Fourth, RevCore performs the best in term of uency, since it utilizes external reviews to enhance the decoder for generating more uent responses. Finally, C-CRS performs the best in both metrics. By eectively leveraging and fusing multi-type data, our model is able to generate more informative words or entities, and meanwhile maintains the uency of the generated text. Besides, the instance weighting mechanism in the ne-tuning stage also helps generate more uent and informative tokens. We also conduct the ablation study based on dierent variants of our model, including: (1) C-CRS w/o Coarse-Fine removes the coarse-tone contrastive learning; (2) C-CRS w/o Coarse removes the coarsegrained contrastive learning; (3) C-CRS w/o Fine removes the negrained contrastive learning; (4) C-CRS Multi-task combines all the pre-training and ne-tuning tasks as a multi-task training; (5) C-CRS w/o CH removes the conversational history; (6) C-CRS w/o SD removes the structured data (i.e., knowledge graph); and (7) C-CRS w/o UD removes the unstructured data (i.e., reviews). As shown in Table 4, rstly, we can see that removing coarse-tone contrastive learning leads to the largest performance decrease. Since there is a natural semantic gap in the multi-type data, it is key to fuse the underlying semantics for eective information utilization. Secondly, the direct multi-task setting (combining all the pre-training and ne-tuning tasks) yields a worse performance than our approach. The major reason is that it is dicult to fuse dierent types of data, which requires a more principled approach for semantic fusion. Finally, the variants that remove any kind of external data lead to a performance decrease. It shows that all kinds of external data are useful in our approach in enhancing the data representations. In this paper, we proposed a novel contrastive learning based coarseto-ne pre-training approach for conversational recommender system. By utilizing the coarse-to-ne pre-training strategy, multi-type data representations can be eectively fused, such that the representations for limited conversation context are further enhanced, which nally improve the performance of CRS. By constructing extensive experiments, the eectiveness of our approach in both recommendation and conversation tasks has been demonstrated. It has shown that our approach is eective to bridge the semantic gap between dierent external data signals for CRS. Note that our approach is exible to incorporate more kinds of external data, and is general to improve other tasks. Currently, our focus is how to perform eective semantic fusion for incorporating external data for CRSs. As future work, we will consider designing a more general representation model that can be directly pretrained with various kinds of context data. We are thankful to Xiaolei Wang for their supportive work and insightful suggestions. This work was partially supported by the National Natural Science Foundation of China under Grant No. 61872369 and 61832017, Beijing Academy of Articial Intelligence (BAAI) under Grant No. BAAI2020ZJ0301 and Beijing Outstanding Young Scientist Program under Grant No. BJJWZYJH0120191000200 98, and Public Computing Cloud, Renmin University of China. Xin Zhao is the corresponding author.