Personalized news recommendation aims to provide attractive articles for readers by predicting their likelihood of clicking on a certain article. To accurately predict this probability, plenty of studies have been proposed that actively utilize content features of articles, such as words, categories, or entities. However, we observed that the articles’ contextual features, such as CTR (click-through-rate), popularity, or freshness, were either neglected or underutilized recently. To prove that this is the case, we conducted an extensive comparison between recent deep-learning models and naive contextual models that we devised and surprisingly discovered that the latter easily outperforms the former. Furthermore, our analysis showed that the recent tendency to apply overly sophisticated deep-learning operations to contextual features was actually hindering the recommendation performance. From this knowledge, we design a purposefully simple contextual module that can boost the previous news recommendation models by a large margin. • Information systems → Recommender systems. News Recommendation, Recommendation System, News Modeling, User Modeling, Deep Neural Networks ACM Reference Format: Sungmin Cho, Hongjun Lim, Keunchan Park, Sungjoo Yoo, and Eunhyeok Park. 2021. On the Overlooked Signicance of Underutilized Contextual Features in Recent News Recommendation Models. In Woodstock ’18: ACM Symposium on Neural Gaze Detection, June 03–05, 2018, Woodstock, N Y . ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/1122445.1122456 Nowadays, the majority of news consumption happens online. Online news platforms seek to assemble news articles from multiple sources and provide a personalized recommendation of these articles for each user. These services face unique challenges since the lifespan of each news is very short, the volume of articles and the number of users are very large, and users have very diverse and dynamic interests. Therefore, the system requires a news recommendation model that can eectively model the relevance of news articles in a timely manner [6, 31, 37, 38, 42]. News recommendation models have beneted from the recent advances in deep learning methods in terms of news modeling and user modeling. Since deep learning methods are capable of creating meaningful representations in embedding space, they were used to create succinct news representations from the articles’ content features such as words, images, and categories [16,25,34,49,52– 54,56]. Likewise, deep learning techniques were also used to capture the preferences of users by generating user representations from their past interactions with the system [1,24–26,34,35,43,48, 49,52–54,56–58,65,68]. These representations were then used to measure the relevance of an article to a user, which ultimately led to better recommendation performance. While the research progress has been immense in modeling these content features, we claim that contextual features (for instance, the trendiness of an article) haven’t been paid the same amount of attention recently. To show this, we relied on a recent thorough survey [55] to gather the published papers on these subjects, then plotted their distributions over the years in Figure 1. As it shows, the amount of research on utilizing contextual features of news articles has continuously been fairly low compared to the amount of research on utilizing content features which has been rapidly increasing with the advent of deep learning. However, considering that news consumption often happens with regard to its context (e.g., how "hot" is this subject right now?), there seems to be a need to reevaluate the importance of the contextual features and their potential for improving recommendation quality. In this paper, we attempt such reevaluation as follows. First, we select and dene the contextual features that prove to be consistently eective across many datasets. Then, we devise a number of naive contextual models that work with these features. By showing that these naive models easily outperform recent content-based deep-learning models, we show the overlooked importance of the Figure 1: Number of news recommendation papers on each subject by their publication years (reconstructed from News Modeling section in [55]). Content features include: words, topics, entities, categories, etc. Contextual features include: popularity, recency, novelty, location, etc. contextual features, and analyze the reasons for such underutilization. From this analysis, we nally suggest a deep learning module that can boost the accuracy of previous content-based models by a large margin. We present extensive experiments on four real-world datasets where we achieve state-of-the-art performance. The goal of this section is mainly threefold. First, in section 2.1, we aim to summarize recent deep learning based approaches to news recommendation. We only covered deep learning models here since there is a big performance gap between them and the more traditional methods (e.g. Bag-of-Words, TF-IDF, etc). These works naturally consist of content-based models because of their abundance in recent publications. Second, in section 2.2, we trace the history of works that tried to utilize contextual features of news articles. Unlike section 2.1, in section 2.2 we also include traditional works to give our work the right context. Few deeplearning models that are included here are excluded from section 2.1. Finally, in section 2.3, we briey touch on gradient boosting methods that we used in section 4. 2.1.1 Problem Formulation. The problem of news recommendation can be formulated as follows. LetUbe a set of users andNbe a set of news articles. The history of each user𝑢 ∈ Ucan be represented asN= [(𝑛, 𝑡), ..., (𝑛, 𝑡)]where𝑛∈ Nis the𝑘th news article clicked by 𝑢 at timestamp 𝑡. Given the above, our goal is to recommend a set of news articles for a user at target timestamp. More specically, at target time 𝑡, given 𝐾 candidate news articles [𝑐𝑎𝑛𝑑, ..., 𝑐𝑎𝑛𝑑] and the user’s history[𝑛, ..., 𝑛], our goal is to rank those candidates in the order of the user’s estimated preferences. Figure 2: A typical framework for news recommendation where the user representation is compared with candidate news representations by a dot product operation. 2.1.2 Architecture. Figure 2. illustrates a typical architecture for news recommendation [54], which roughly captures most recent deep-learning based news recommendation models. Their approach is similar in the sense that they compare the user vector with the vectors of candidate news articles based on similarity-measure operations such as dot product. Therefore, central to the whole framework are two components that create these vectors: news encoder and user encoder. A typical news encoder [54] encodes a news article into a low-dimensional vector. Then a typical user encoder [54] generates a user representation by aggregating news representations from the user’s history that are each encoded by the former news encoder. In this section, we will describe in detail how previous works approached each one of these components. 2.1.3 News Modeling. As news is inherently textual, many works focused on generating news representations from the text. DSSM [16] was an early attempt to learn representations of web documents and queries by using letter n-gram based word hashing and dense layers to project them into low-dimensional vectors. Okura et al. [34] proposed to apply denoising autoencoder to news articles to get distributed representations. Meanwhile, other works proposed to use Convolutional Neural Networks (CNNs) in various ways [1,25,48,49,52,53,65,68]. For example, Weave&Rec [25] applied CNN on word2vec representations of words in news articles. DKN [49] designed a KCNN module to make use of knowledge entities aligned with news titles. More recently, attention mechanisms were used to boost the power of news encoders [11,52–54,56–58]. For example, NRMS [54] proposed to apply self-attention and additive attention to the word embeddings to generate news representations that are aware of the importance of each word. NAML [52] suggested to include (sub)category information of news articles by using (sub)category embeddings together with word representations in an attention operation. Wu et al. [56] showed that one can empower the news encoder by using pre-trained language models (e.g. BERT [8]), which seems to imply that the power of news encoders will continue to improve as long as there are advances in NLP research. 2.1.4 User Modeling. Deep learning methods were shown to be much more eective than traditional methods in terms of user modeling. For example, Okura et al. [34] reported signicant performance improvement over traditional temporal methods such as time decay when they used Recurrent Neural Networks (RNNs) to model user behaviors. In fact, since GRU4Rec [15] was rst proposed, many sequential recommendation methods employed RNN to benet from its sequence understanding capability [14,40,51,59,64,66,67]. The same trend occurred in the news domain for user modeling [1,24,26,34,35,43,65,68]. For example, LSTUR [1] proposed to use GRU on the users’ history to learn their short-term representations while their long-term representations were learned by ID-based embeddings. Some found Convolutional Neural Networks (CNNs) to be useful [25,48]. For example, Weave&Rec [25] applied 3D CNN to the user’s behavior sequence where each item was represented as a 2D matrix comprised of word embeddings. More recently, prevalent usage of attention mechanisms were witnessed in recommendation models. In sequential recommendation, following the huge success of transformers in NLP [4,8,46,61], models such as SASRec [21], BERT4Rec [44] and other variants [28] fully adopted attention techniques, in contrast to previous models where attention was merely a supplementary part of the model [27,32]. The same was true for user modeling in news domain [49,52–54,56– 58,65,68]. For example, models such as NRMS [54], NAML [52] and NPA [53] all used similar attention operations to combine the user’s history into a single representation. In contrast to content features which capture relatively static information about news articles and users, contextual features try to capture their more dynamic aspects. For example, popularity of an article is an important signal that measures its relevance to the mass For the same reason, CTR (click-through-rate) of an article is also an important signal since it measures the article’s general attractiveness [3,39]. Freshness/Recency should also be taken into account to consider the staleness of an article [5,12,22,29,30,39,45,69]. Some works incorporate other contexts such as location [17,22,42, 45, 47, 62] or weather [62]. Central dierence between these works lies in the way they choose to encode these signals. For example, [5] suggested to use number of views of an article as its popularity, whereas [29] suggested to encode the article popularity as, and [12] suggested𝑙𝑜𝑔(1+ # clicked users)to represent it. An article’s recency was represented asin [29], while𝑙𝑜𝑔(1+ Δ𝑡)was used in [12]. For CTR, [3] proposed to estimate the CTR at event time by using Kalman lters, whereas [39] chose to use past CTR either as its raw value (in their popularity predictor module), or by quantifying its value then doing an embedding look-up (in their popularity-aware user encoder). From this we would like to note two things. First, judging by the number of publications, some features such as past CTR haven’t been paid much attention despite being very important signals. In fact, experiments in [39] suggest that a simple baseline model that rank articles only by their CTRs can match the performance of heavy deep learning models. Our work seeks to further explore this discovery. Second, the encoding methods for these features remained rather primitive, and the eect of recent non-linear methods such as deep learning on these features needs to be reevaluated, which is precisely what we aim in this work. Gradient boosting method is a machine technique that trains a prediction model from an ensemble of decision trees. It grows decision trees by progressively reducing the residual errors from the previous trees. Gradient boosting libraries such as XGBoost [2], LightGBM [23], and CatBoost [9] are currently go-to solutions for many data science and machine learning challenges that deal with tabular data. In fact, although the prominent approach for recommendation tasks have shifted to deep learning, gradient boosting methods persistently appear as winner solutions in recommendation challenges [18,41]. Also, a recent paper [63] surprisingly discovered that gradient boosting methods can be both more efcient and more eective than over-parameterized deep learning methods in CTR prediction task. In this section we dene the contextual features that will be used throughout the rest of the paper. Click-through-rate of an article is naturally dened as follows: In other words, it is a ratio of the number of clicks to the total number of times it has been shown to all users. Since higher CTR usually indicates successful recommendation, predicting CTRs has been a popular optimization task for recommendation models [63]. However, one should note that it can also be used as a feature of an item that describes its attractiveness, and therefore as an input to the recommendation model. In an oine evaluation setting, one should be careful not to incorporate current and future records when creating features since it causes data leakage problem. Therefore, to use as a valid feature, we parameterize CTR with current time𝑡: We use two popularity features. First is the obvious number of clicks: The downside of this feature is that it is not aected by the temporal distance between now and the event of the click. However, in reality, even articles that have a large amount of clicks should not be considered as being popular if the clicks happened a long time ago. To incorporate this temporal inuence, we suggest a second popularity feature called trendiness: where𝑚(𝑡, 𝑘)is the "mass" of the𝑘click of the article at time 𝑡,𝑡is the timestamp of the𝑘click, and𝛼is a hyperparameter to control the degree of decay (we use𝛼 =0.001 in this paper). In other words, every click generates a mass of 1 at the time of click which gets exponentially decayed as time passes. The article’s trendiness is dened as the accumulation of these decayed masses. The benet of this feature is that it captures both the popularity and its temporal relevance, and that it is computationally simple to maintain its value because exponential functions support easy updates (multiplications can be chained). Following previous works, we dene freshness feature as: In other words, it measure how much time has passed since the publication of the article. We use seconds as the unit of time. Although we settle for these four features in this paper, note that the list is not exhaustive and that more features can be imagined. We have tried other features such as CTR in a particular user group (e.g. groups by age and gender), CTR in a particular time window (e.g. pertaining only to the last 10 minutes), timestamp (or hour) of the event of recommendation, etc. However, we omitted them since they weren’t proved to be consistently eective across all datasets. Engineering more useful features remains as a future work. This section aims to prove the overlooked importance of contextual features with the following strategy. We prepare four real-word news recommendation datasets for solid comparison between models. Then, on the other hand, we prepare recent deep-learning news recommendation models that heavily make use of content features of articles, some of which tries to also incorporate contextual features. In addition, we devise naive contextual models that make use of contextual features in a purposefully naive way. By showing that the latter models easily achieve superior performance, we emphasize the overlooked signicance of contextual features and assess the reasons for such underutilization in the past. We used three public datasets (Mind[60],Globo[7], andAdressa [13]) and one proprietary dataset (Prop) to conduct experiments. Mindis a large English news recommendation dataset used for a Table 1: Dataset details. Note that this is after we have ltered and preprocessed the datasets. recent challenge [60] collected from Microsoft News.Adressa is a large Norwegian news recommendation dataset collected from Adresseavisen.Propis a large news recommendation dataset collected from a large news service company. The details of these datasets can be found in Table 1. As the table shows, some datasets lack important information. SinceGloboandAdressadon’t have impressions, CTR can’t be computed for them. SinceMindlacks publish timestamps of news articles, freshness can’t be computed. Models that utilize entityembeddings can only be applied to Mind. As a temporary solution, features which can’t be computed were omitted from the experiments for that dataset. We sorted the targets by their timestamps and split them by 8:1:1 to get train, validation, and test set respectively. For datasets with impressions (MindandProp), the unclicked items in the same impression were used as negative items.𝐾 =4 items were sampled from them for training, and all negative items were used for evaluation. For datasets without impressions, following [7], we sampled negative items from the clicks of other users within the recent queue of 10 minutes.𝐾 =4 and𝐾 =20 items were sampled for training and evaluation respectively. Model’s performance was measured as its capability to rank positive items higher than negative items, which was measured with metrics such as NDCG@k, Recall@k, and AUC. For this section, we sampled 5K users from each dataset and used these subsets for experiments. We compared ve dierent kinds of methods. The rst two consist of existing baselines: (1) Previous deep-learning content models and (2) Previous deep-learning content models that incorporated contextual features. Then, to compare against these baselines, we Figure 3: Five kinds of methods we compare. Each method uses various features and operations to predict the probability of the user clicking on the candidate article (ˆ𝑦 in the gure) (a) Previous deep-learning content models (illustrated in detail in Figure 2) (b) The architecture of PP-Rec [39]. (c) Naive-CTR which uses raw CTR value as the logit. (d) NRMS+Naive which does a weighted sum of content logits and naive contextual logits to make the nal prediction. Some contextual features such as 𝑛𝑢𝑚𝑐𝑙𝑖𝑐𝑘𝑠 and 𝑡𝑟𝑒𝑛𝑑𝑖𝑛𝑒𝑠𝑠 are omitted in the gure for the sake of space. The scale operation is identity for CTR and 𝑙𝑜𝑔( for the rest. (e) Decision tree created by gradient boosting method. The prediction is made by the value of the leaf node. devised three kinds of models: (3) Naive context models, (4) Deeplearning content model with naive context incorporation, and (5) Gradient boosting context models. First, previous deep-learning content models denote the models described in section 2.1. It is also illustrated in Figure 3 (a). For experiments in this section, we usedNRMSto represent this class of models.NRMSis a good representative because many other models can be seen as its variations. For example, if we simply replace its self-attention layers with convolution layers, and additionally use articles’ category/subcategory information in its news encoder, we getNAML[52]. Also, it is a good representative because its performance is on par with other models according to [39]. For Globo, since it doesn’t provide textual information of news articles and instead provides each item’s pre-trained embedding, we had to use a variation ofNRMSwhere we replace the output of news encoders with those embeddings. Second, for previous deep-learning content models that incorporated contextual features, we usedPP-Rec[39] since there were no other alternatives to our knowledge. Its architecture is illustrated in Figure 3 (b). As for the usage of content features,PP-Rec uses a similar news encoder as the one fromNRMS, except with additional entity information and cross-attention operations (the details of the news encoder are abstracted in the gure for the sake of space).PP-Recincorporates contextual features mainly in two ways. First, it proposes a news popularity predictor (left side of the gure), which takes CTR, freshness, and content features as its input. The CTR is used as its raw value, while freshness is quantized into an embedding, and content features are processed by a separate news encoder from the one in the content side. The last two are combined with a gating operation, whose output is combined with CTR by weighted summation to produce the nal popularity prediction. The second usage of contextual features inPP-Recis in its user encoder (right side of the gure), which is also similar to the one fromNRMS, except for the additional usage of CTR value and content-popularity joint attention network (the details of the user encoder are also abstracted in the gure). In this module, CTR value is quantized into an embedding to be used in the joint attention network. Finally,PP-Recaggregates the results from the popularity predictor and from the content side via a personalized aggregator that uses the computed user embedding as the input for the gating operation. SincePP-Recrequires CTR and freshness features, experiments couldn’t be conducted onMIND,GloboandAdressa. In addition, since it also requires entity information, it also couldn’t be experimented onProp. However, this would mean eliminating PP-Recfrom our experiments completely, which could be viewed as an unfair comparison. Therefore, we enabled its experiments forPropby using its variation where we removed entity inputs and the corresponding cross-attentions in its news encoder, which basically makes it identical to the one from NRMS. Third, naive context models are the ones that utilize the features we’ve dened in Section 3 without applying any sort of operations to them. For example,Naive-CTRwill rank the candidate news articles just by their𝐶𝑇𝑅 (𝑡)values (articles with higher𝐶𝑇𝑅 (𝑡) values will be ranked higher). Its concept is captured in Figure 3 (c). Likewise,Naive-numclicks,Naive-trendiness, andNaivefreshnesswill rank the items according to their𝑛𝑢𝑚𝑐𝑙𝑖𝑐𝑘𝑠 (𝑡 ), Table 2: Performance Comparison between four kinds of models. The numbers are measured by NDCG@10 metric. 𝑡𝑟𝑒𝑛𝑑𝑖𝑛𝑒𝑠𝑠 (𝑡), and𝑓 𝑟𝑒𝑠ℎ𝑛𝑒𝑠𝑠 (𝑡). These models will serve as baselines that show the bare eects of contextual features alone. Fourth, for deep-learning content models with naive context combination, we tookNRMSand simply added the contextual features to its side. Its structure is illustrated in Figure 3 (d). In NRMS+Naive, the logits fromNRMSare combined with contextual features of candidate items by a weighted sum with learnable weights. Since𝑛𝑢𝑚𝑐𝑙𝑖𝑐𝑘𝑠,𝑡𝑟𝑒𝑛𝑑𝑖𝑛𝑒𝑠𝑠, and𝑓 𝑟𝑒𝑠ℎ𝑛𝑒𝑠𝑠oer values that are intolerably high for neural networks, we applied𝑙𝑜𝑔(1+ 𝑥) operation to scale each of them following [12]. However, except for these scaling operations, note that we omitted any other non-linear operations such as MLPs (Multi-Layer Perceptrons). Also note that whilePP-Recuses the contextual features in an indirect way (through sophisticated operations such as embedding, gating, crossattentions, etc), inNRMS-Naivewe simply use them as logits that directly contribute to the recommendation prediction. Finally, for gradient boosting context models, we organized the contextual features and labels (i.e. clicks) into a tabular form. Then, following [63], we used CatBoost library [9] to build a prediction model from these features. This model serves to show how much more can be exploited from the contextual features when we apply learnable non-linear operations such as decision trees. Table 2 shows the performance comparison between the ve dierent kinds of methods introduced earlier. Many things are noticeable in this comparison. First is the surprising eectiveness of CTR. Note thatNaiveCTRoutperformedNRMSin both datasets where𝐶𝑇𝑅 (𝑡)feature was available. This is very impressive becauseNaive-CTRrequired no training at all, and𝐶𝑇𝑅 (𝑡)feature wasn’t transformed by any operations. This suggests that𝐶𝑇𝑅 (𝑡), a global measure of the amount of appeal that the article has to the population at time𝑡, can be a strong indicator of whether the next user will click it or not. It even suggests that this global context feature could be a stronger cause of a click than the personal preferences of the user, which is understandable when considering the nature of news media. Second, for similar reasons as the rst, other context features also proved to be eective, oering decent performance inProp and Mind without any kind of operations. 𝑛𝑢𝑚𝑐𝑙𝑖𝑐𝑘𝑠 (𝑡 ), which is equivalent to the numerator in the denition of𝐶𝑇𝑅 (𝑡), proved to be less eective than𝐶𝑇𝑅 (𝑡), which again emphasizes the importance of having impression data in the dataset.𝑡𝑟𝑒𝑛𝑑𝑖𝑛𝑒𝑠𝑠 (𝑡), which incorporate temporal factors into𝑛𝑢𝑚𝑐𝑙𝑖𝑐𝑘𝑠 (𝑡 ), proved to be more eective, which suggests that temporal aspects must indeed be considered.𝑓 𝑟𝑒𝑠ℎ𝑛𝑒𝑠𝑠 (𝑡)was shown to be the most eective in GloboandAdressa, while it wasn’t shown to be a dening factor in Prop. Third, the performance gap betweenPP-RecandNRMS+Naive is noticeable. Recall that while they utilize the same features (both content and context),PP-Recutilizes the contextual feautres in an intricate manner whileNRMS+Naivejust uses them as additional logits. This seems to contradict the myth that complicated deep-learning operations must be applied to the features in order to utilize them properly. In fact, to investigate the factors that were hindering the performance ofPP-Rec, we conducted a simple ablation study by taking out some of its components. Table 3 shows the performance comparison betweenPP-Recand two of its variants. The rst variant,PP-Rec-onlyctr, was created by removing freshness and content components in the news popularity predictor module, leaving only the CTR value as its output. As a result, the performance increased slightly, but the big gap persisted. Then, we identied the big dierence betweenPP-Rec-onlyctr andNRMS+Naive, which was the personalized aggregator module at the nal layer inPP-Rec, which was blocking the direct contribution of CTR value to the nal prediction. Replacing this layer with a simple linear one as inNRMS+Naive(PP-Rec-onlyctrnoagg), the performance greatly increased and achieved similar performance asNRMS+Naive. This suggests that direct usage of contextual features can be more eective than using them indirectly through complex deep-learning operations. Fourth, the impressive performance of gradient boosting model is notable. InMind,Globo, andAdressa, gradient boosting method outperformsNRMS+Naive. This is very impressive because the former only utilizes the contextual features with a light tabular method, whereas the latter utilizes content features besides the contextual features, with a deep-learning method that is much heavier than gradient boosting both in terms of the number of parameters and the training time. SinceNRMS+Naiveuses contextual features without any operations, whereas the gradient boosting model uses them via decision trees, we can infer that the presence of such learnable non-linear operations are crucial for good recommendation performance. Lastly, we stress the importance of good quality datasets to facilitate news recommendation research. Note that the absence of some features in the datasets crucially aected the experiments on multiple levels. On the feature-level, the absence of impression data made it impossible to compute features such as CTR, which excludes the possibility of utilizing these features for recommendation. Even for the datasets where impression data was present, note that the𝐶𝑇𝑅 (𝑡)values we used were just an approximation, since it was reconstructed from only within the dataset which is only a sample from the real-world. The same goes for every other contextual features. Therefore, better results are possible for those that have access to the real-world records, or at least the true values for the contextual features. On the evaluation-level, for datasets with no impression items, negative items couldn’t be constructed naturally, and instead had to be sampled from other users’ clicks. This makes the experiments inaccurate, since it is dicult to regard those items as being truly negative because the users might have clicked the items had they been shown to them. In fact, this factor could have contributed to the comparatively large performance gap inGloboandAdressacompared toPropandMind. Also, since Globoprovides no text information, existing content deep-learning models such asNRMScouldn’t be used as-is, and had to be transformed into a weaker version. We assume that the unusually large performance gap inGloboresults from this tragedy. These observations oer a consideration for future parties willing to publish a good quality news recommendation dataset. We summarize the lessons of this section below. •Contextual features such as CTR, popularity, and freshness prove to be very powerful. Without any operations, contextual features alone can match and sometimes outperform the heavy deep-learning models that use content features. •Contextual features have largely been neglected or underutilized in recent models. •Recent models that tried to incorporate contextual features haven’t been able to use them to their full potential. Our analysis shows that such underutilization results from trying to use them indirectly through sophisticated deep-learning operations, whereas a more direct approach proved to be more eective. •When using these contextual features directly, having a learnable non-linear operation applied to them is crucial for recommendation performance. This is shown by the effectiveness of the gradient boosting method. •Many published news recommendation datasets lack crucial features such as impression data. This aects fair evaluation of certain news recommendation models and can possibly hinder the research in this area. Although the previous section seems to imply that the contextual features and cheap tabular methods are all we need for good news recommendation, this is not quite the case when the data size increases. Recall that the previous experiments were each done with a subset of 5k users. As the data size grows into a larger scale, it becomes dicult to outperform deep-learning content models by contextual features and cheap tabular methods alone (however, the comparison and the analysis from the previous section still hold at this scale). In addition, while it is true that non-personal features such as CTR or popularity greatly aect the users’ news consumption, the users’ distinct preferences cannot be ignored in order to provide personalized news recommendation, thereby making the usage of content features necessary. Furthermore, since many companies already deploy deep-learning based models, it would be more convenient for them to reinforce their models if our solution is in the form of a deep-learning module. For these reasons, we suggest a contextual deep-learning module, which can be attached to any previous content-based deep-learning model in a modular manner to boost their performance by a large margin. We propose a purposefully simple method to accommodate the lessons learned in the previous section. Since direct usage of contextual features proved to be more eective, we suggest to use the architecture illustrated in Figure 3 (d). The left side of the gure represents any previous content-based deep-learning news recommendation model, while the right side of the gure represents an additional context module that we propose. Unlike Figure 3 (d) however, we suggest to apply an additional dense layer (i.e. MLP) right after the scaling operation of the contextual features. These dense layers, with learnable parameters, oer the non-linearity that was shown to be crucial in the previous section. Note that other learnable non-linear operations such as decision trees are still applicable here, but it would require an additional engineering to connect the deep-learning components and the decision tree. Therefore, for companies that are already deploying deep-learning recommendation models at scale, our approach comes in handy. To show the eectiveness of our method, we conducted the following experiment. Using the same datasets and evaluation schemes in Section 4, we evaluated how much the recommendation performance is increased when we attach our context module to a previous content-based model. For this experiment we used the fullscale datasets to give the deep-learning models the full leverage(?). We used the following models as baselines: • NPA[53]: A news recommendation model that uses CNNs and personalized attention module to identify important words with regard to each user in the news encoder. Words from news titles are used as news encoder inputs. Similarly, personalized attention is used as user encoder to identify important articles with regard to each user. • NRMS[54]: A news recommendation model that uses selfattention and additive attention operation to learn both news and user representations. Words from news titles are used as news encoder inputs. • LSTUR[1]: A news recommendation model that uses GRUs and ID-based embeddings to learn the user’s short-term and long-term representations respectively. It uses CNNs and additive attentions on word embeddings then concatenate Table 4: Performance Comparison. +CTX columns denote the model on its left side with our context module attached to it. Each "Improv." column computes the relative improvement between the two. Adressa the output with (sub)category embeddings to represent an article. • NAML[52]: A news recommendation model that uses CNNs and additive attentions on word embeddings and applies another additive attention on its output together with (sub)category embeddings to learn news representations. It uses additive attention operation to learn user representations. We implemented all baselines in PyTorch [36] and experimented with the same device (Tesla M40). For each model we used the hyperparameters suggested by the authors. We used appropriate pretrained word embeddings for each dataset (300-dimension Glove embeddings forMind, 100-dimension skip-gram Norwegian word embeddings forAdressa, and 128-dimension word embeddings pre-trained on large corpus of proprietary news articles for Prop). As in our earlier experiment, forGlobo, since it doesn’t provide articles’ textual information and instead provide their pre-trained item embeddings, we had to use variations of the models where we used the pre-trained item embeddings in place of news encoder outputs. Table 4 shows the comparison results. As the table shows, the addition of our context module increases the performance of previous content-based models by a large margin. As noted earlier, the relatively larger gaps inGloboandAdressacould have partially resulted from their lack of crucial features. However, since the experiments inPropandMindwere done in a more realistic setting, our module can be said to be eective in a real-world environment. Note that the performance gain is protably high, especially when considering that the addition of our context module adds very small number of parameters and the amount of computation to the system compared to the heavy content models. In this paper we sought to reevaluate the signicance of contextual features of news articles. We conducted a thorough comparison between recent deep-learning news recommendation models and naive contextual models on four real-world datasets. As a result, we learned (1) that contextual features hold great potential for improving recommendation performance, (2) that these features were largely neglected or underutilized in recent research, (3) that one reason for such underutilization was the tendency to apply overly sophisticated deep-learning operations to the features, (4) that a more direct usage with learnable non-linear operations prove to be much more eective, and (5) that currently published news recommendation datasets lack crucial features that hinder fair evaluation of contextual models. From this knowledge, we proposed a simple contextual deep-learning module that can be attached to previous content-based solutions in a modular manner. Experiments showed that our module boosts the recommendation performance by a large margin on many real-world datasets. Although in this paper we only proposed a context module for news articles, suggesting a similar module for users could be a possible future work. The user’s context might include: user’s CTR, user group, age, gender, location, etc. As [50] pointed out, the separation of user module, item module, and user-item module could enable a counterfactual inference and reduce the popularity bias. Also, as mentioned earlier, examining more contextual features such as user-group specic CTR remains as a future work. Acknowledgements.