Abstract—Recently, due to the ubiquity and supremacy of E-recruitment platforms, job recommender systems have been largely studied. In this paper, we tackle the next job application problem, which has many practical applications. In particular, we propose to leverage next-item recommendation approaches to consider better the job seeker’s career preference to discover the next relevant job postings (referred to jobs for short) they might apply for. Our proposed model, named Personalized-Attention Next-Application Prediction (PANAP), is composed of three modules. The ﬁrst module learns job representations from textual content and metadata attributes in an unsupervised way. The second module learns job seeker representations. It includes a personalized-attention mechanism that can adapt the importance of each job in the learned career preference representation to the speciﬁc job seeker’s proﬁle. The attention mechanism also brings some interpretability to learned representations. Then, the third module models the Next-Application Prediction task as a top-K search process based on the similarity of representations. In addition, the geographic location is an essential factor that affects the preferences of job seekers in the recruitment domain. Therefore, we explore the inﬂuence of geographic location on the model performance from the perspective of negative sampling strategies. Experiments on the public CareerBuilder12 dataset show the interest in our approach. Index Terms—Next-Application Prediction, PersonalizedAttention, Neural Network, Job Recommendation Recently, the rapid development of E-recruitment has considerably inﬂuenced the human resource management ﬁeld. In particular, due to the explosion of recruitment data (i.e., over 3 million jobs are posted on LinkedIn in the U.S. every month), many works have been proposed to build effective job recommender systems [1]. Like many other domains, Deep Learning (DL) based recommendation models have been extensively studied in the recruitment domain. Nevertheless, while mostly studied, there are still important issues with current approaches, which we summarize below: namic and constantly evolving Job-Person interactions, which can be built from job application records or working histories. Identically, we assume that temporal relations between application records tend to point ´e Paris-Saclay towards sequential/session-based recommendations. To our knowledge, although various session-based methods have been proposed in others domains, session-based job recommendation is less studied. Moreover, another important aspect of the Job-Person interaction matrix is its sparsity, since most job seekers only apply for a few job positions or work as a speciﬁc occupation. of recommendations. Indeed, two job seekers can apply for the same job with different motivations. As a consequence, the important information in a job is speciﬁc to the job seeker. Thus, it is essential to weigh the jobs differently in the modeling tasks of job seeker careers. General-purpose approaches are often unable to capture such speciﬁc information. In addition, the personal context information of the job seeker is of prime importance in the recruitment domain. For example, the geographic location of a job seeker often has a substantial impact on the application decision and the recommendation result. It raises two opposite goals: (i) it is essential to consider this personal context information when modeling personal preference, (ii) it also requires the recommender system to distinguish this information from more core content, i.e., job content, when making recommendations. the recruitment domain. In fact, in addition, to constantly updated E-recruitment websites (i.e., a large number of job postings are added or removed daily, and hundreds of candidate proﬁles are created or updated), the domain is still evolving (i.e., new occupations, formations, and skills). All of this intensiﬁes the cold-start problem. Therefore, it is impractical to build a static method that cannot be adjusted quickly as the data constantly changes. We thus need to avoid retraining a deep model for each change. Moreover, from the perspective of content analysis methods, due to the sensitivity and privacy of the data in the recruitment domain, it is not easy to create an unbiased and evolving labeled dataset [2], [3]. Thus it prevents the use of supervised machine learning methods. In this paper, we address the problem of job recommendation under the task of the next job application prediction. We propose a hybrid Personalized-Attention Next-Application Prediction model (PANAP) to answer the previous issues partially. Speciﬁcally, for Issue 1, we model the next job application problem as a sequential recommendation problem, and then compare our proposed model with different sessionbased recommendation methods to analyze the dynamics in the recruitment domain. Our model is composed of three independent modules. The ﬁrst module learns job representations from textual job content and available metadata in an unsupervised way to answer Issue 3. The second module contains a personalized-attention mechanism to learn the job seeker representation that can solve the problem of personalized recommendations mentioned in Issue 2. The third module is used to predict the next-application that a job seeker will apply for. In order to answer Issue 3, this module is inspired by the Deep Structured Semantic Model (DSSM) [4] with a training loss based on representation similarities. Moreover, based on the nature of the recruitment domain, we propose a speciﬁc negative sampling strategy considering the geographic location factor. To summarize our contributions as follows: for Next-Application Prediction task. It integrates the personalized-attention mechanism to improve the recommendation accuracy. the CareerBuilder12 dataset, allowing us to investigate the effect of leveraging different metadata types and textual job contents, and the impact of different sampling strategies on the quality of recommendations. Job recommender systems based on traditional approaches (i.e., collaborative-, content-based and hybrid methods) have been well-studied [5]. However, these methods have some important limitations in the recruitment domain. For example, the sparsity of Job-Person interaction matrices limits the performance of collaborative-based methods. When the information contained in job contents is insufﬁcient, or the feature-engineering on contents is difﬁcult, content-based approaches may become inaccurate. Furthermore, these methods generally lack the ability to model personal information. Recently, DL has dramatically revolutionized recommendation systems. As in other domains, DL-based methods have been applied in the recruitment domain. These works can be categorized into three classes according to the data they used and the learning paradigm. (i) Text-based matching models: When labeled Person-Job matching records are available, the recommendation problem can be seen as a supervised text matching task to match jobs with candidates automatically. Many approaches [2], [3], [6] with different architectures have been proposed in the literature. However, due to the protection of trade secrets and personal privacy, collecting such labeled records is difﬁcult. (ii) Unsupervised representation learning models: When matching records are not available, the recommendation task can be seen as the learning of representations of job and person in the same embedding space. The recommendation is then modeled as a top-K search based on these learned embeddings using similarity-based algorithms. For example, [7] uses graphs to learn job title and skills representations. [8] proposes a collective multi-view method to learn job title representations. In these approaches, the different level/view of information is of prime importance. (iii) Approaches based on career paths: The methods mentioned above primarily focus on characterizing the person or the job information. Transitions in career paths are less considered. To address this problem, some works are proposed, e.g., NEMO [9] explores action dependencies in career paths through Long Short-Term Memory (LSTM) [10] to predict the next career move. In [11], they use a hierarchical LSTM to predict the next potential employer of a person and how long he/she will stay in the new position. However, predicting the next job application based on application records received relatively little consideration except [12], which recommends the next job posting in a K-nearest neighbor manner. It is one of our baselines. The next-application prediction problem can be considered as a sequential recommendation problem, which has been extensively studied recently in other domains, such as news or product recommendation [13]–[16]. Recurrent Neural Networks (RNNs) have been widely studied for the sequential recommendation since they have demonstrated their effectiveness in processing sequential data, one representative work is GRU4Rec [17]–[19]. The attention mechanism [20] has shown promising potential in improvements of accuracy and interpretability, like the vanilla attention-based [14], [21] and self-attention based one [22], [23]. Different from the previous state-of-the-art in the recruitment domain, in this paper, we tackle the problem of nextapplication prediction by leveraging session-based recommendation models. We further study the effectiveness of sessionbased models in the recruitment domain. Moreover, we integrate the personalized-attention mechanism to model the different informativeness of job postings for different job seekers, and we take into account the “location” factor when making recommendations. Let U be a set of job seekers and J be a set of job positions (referred to jobs for short). A job j ∈ J can be represented as j = (ID, {w, . . . , w}, meta), where IDis the unique identiﬁer of job j. {w, . . . , w} is a sequence of m words, representing the textual content of job j. It can be any text information about the job. metaare associated metadata attributes (i.e., job city). Similarly, each job seeker u ∈ U can be summarized as a tuple u = (ID, H, meta) with an identiﬁer ID, a professional proﬁle H, and metadata attributes meta, like the education background or the geographical information. Speciﬁcally, the professional proﬁle Hcan be represented either as his/her working experience or his/her job application record. In this work, we target at the job application record, and we denote Has a job sequence (session) ordered by time H= {j, . . . , j}, where each jis a speciﬁc job in J . With the above notations, the Next-Application Prediction problem can be formally deﬁned as follows: Given a set of jobs J and a set of job seeker U, for each speciﬁc job seeker u ∈ U who has a job application sequence H= {j, . . . , j} at one speciﬁc time step t. Predict the next most likely job jthat the job seeker u might apply for, which means maximizing the likelihood P (j= j|H, J ) of the actual next-applied job jgiven the application sequence H. An overview of our PANAP model is given in Figure 1. We detail our model by describing these three different modules. JCR (Job Content Representation), is responsible for learning a representation of each job j ∈ J , where j = (ID, {w, . . . , w}, meta). Speciﬁcally, for job j, a textual representation h∈ Ris learned from its textual content {w, . . . , w} with a text encoder: where the text encoder can be some unsupervised textual embedding approaches (e.g., Word2Vec [24] and Doc2Vec [25]) or pre-trained models (e.g., BERT [26]). We believe that textual representations generated by different text encoders will affect the accuracy of the recommendations. It will a research line in our future work. The metadata attributes meta (e.g., city and state) are respectively embedded into vectors (e.g., vand v) through different trainable embedding matrices (e.g., Mand M), which will be jointly learned during the training process. The vector vis then obtained by concatenation of all vectors, v= [v⊕ v⊕ . . . ], where the symbol ⊕ represents the concatenation operator. Then the textual job representation hand job metadata vector vare combined by using a sequence of Fully Connected (FC) layers to produce the Job Content Vector v∈ R: It is worth mentioning that the textual job representation h is trained separately in an unsupervised way or generated by a pre-trained language model, so that a new job can be added easily, thereby alleviating the job cold-start problem. JSR (Job Seeker Representation), is responsible for learning representations of job seekers. It requires three inputs: the identiﬁer IDof job seeker u, his/her historical applied job sequence H= {j, . . . , j}and associated metadata attributes meta. In addition, Hcan be transformed as a sequence of Job Content Vectors {v, . . . , v}, where each v∈ Ris obtained from JCR module. Since the same job may have different informativeness for different job seekers, it contributes differently to characterize career proﬁles of job seekers. Then, we learn the job seeker representation with a personalized-attention mechanism [27]. We ﬁrst embed the IDof job seeker u into a vector eusing an identiﬁer embedding matrix M∈ R, where ddenotes the dimension of identiﬁer embedding. Then eis passed to a dense layer parameterized with W∈ Rand b∈ Rto form the preference query vector q= ReLU(W× e+ b), where dis the query dimension. The importance score of i-th job for job seeker u is calculated as follows:P where p= tanhW× q+ b, with projection parameters W∈ Rand b∈ R. Note that the attention scores might differ for the same job, as the query vector depends on the ID of the job seeker. This allows forming a weighted career preference representation hfor job seeker u:P Similar to JCR module, the metadata vector of job seeker u is represented as v= [v⊕v⊕. . . ] by concatenation. vand hare combined by using a sequence of FC layers to produce the ﬁnal job seeker representation: where vhas a dimension of d, which is equal to the dimension of Job Content Vector v(e.g., d= d). In classical deep recommendation models, the output is usually a probability vector whose dimension is the number of available items. In our scenario of job recommendation, due to the evolving nature of the recruitment domain (Issue 3), such models are not tractable in practice. Thus this dynamic scenario needs an approach that does not need to retrain the whole network at each change. As a consequence, inspired by the highly dynamic news recommendation scenario, we use the ranking loss [13] to train the predictor. The principle of this loss is to train the predictor to maximize the similarity between user preferences and positive samples, while minimizing similarities with negative samples. The idea of the ranking loss comes from DSSM [4], which is an effective document ranking model and has been leveraged for the recommendation. In our case, it can immediately recommend a newly published job as soon as its representation is learned. More precisely, given the application history H= {j, . . . , j} of job seeker u, we formulate the above representation generating processes as v= JSR(ID, H, meta; Θ), where each j∈ Hcan be embedded into a Job Content Vector vthrough JCR(j; Θ), Θand Θare model parameters. vand vare vectors of the same dimension, and we thus can deﬁne the relevance score between job seeker u and job j by the cosine similarity of their representations: The posterior probability of j being the next-job for u is formulated as follows: Fig. 1: The proposed PANAP framework consists of three parts: (i) Job Content Representation (blue dashed box) is used for job content representation learning. (ii) Job Seeker Representation (green dashed box) uses the personalized-attention mechanism to characterize the career preference of job seekers based on the Job Application Record. (iii) Next-Application Predictor (yellow dashed box) utilizes a ranking loss based on the representation similarity of job and job seeker to train the model. where jis the actual next-application, and Jrepresents the negative sample set of jobs which are not applied by the job seeker during his active session. The recommender should learn to maximize the similarity between the content vector vof jand the job seeker preference vector v, while minimizing similarities with job vector vin the set J.Q L= − logP (j|ID, H, meta; Θ, Θ). (8) Since our method is trained and evaluated with negative samples as described in Section IV-C, the negative sample set Jsigniﬁcantly inﬂuences the model performance. A well-used sampling strategy is the mini-batch based sampling proposed in [17], which treats the items from the other training/evaluation sessions in the same mini-batch as negative samples. [19] extends the mini-batch based strategy by adding additional samples (based on unity or based on popularity). For some applications, such as news, music, and video, popularity is also an essential factor that inﬂuences user choice besides personal preference. Therefore, sampling based on popularity is a good sampling strategy. However, in the recruitment ﬁeld, unlike these applications, the choices of job seekers are more inﬂuenced by their personal contexts, such as the geographic location factor. When job seekers make a choice, they usually ﬁrst need to consider the job location. They are more likely to apply for jobs in their cities or other cities not far from their current locations (i.e., cities in the same state). We will prove this observation in Section V-A. To solve this problem, our method cooperates with the “location” metadata attributes (e.g., city, state and country) of job and job seeker to model their representations, respectively. As a consequence, these representations contain the “location” information. In addition, considering the “location” when generating negative samples can enable our model to learn useful information for more meaningful recommendations. More experimental details are provided in Section V-B. We employ CareerBuilder12to evaluate our proposed method. Its statistics are given in Table I. In this dataset, job seeker has ﬁve metadata: City, State, Country, Degree, and Major. Job metadata are City, State and Country. The textual job content includes a Job Title, a Job Description and some Job Requirements. From this initial dataset, we created two datasets: (i) CB12s like in [12], in which sessions are created via a time-based split of 30 minutes inactivity threshold, and we discarded sessions with less than two applications for nextjob prediction purpose. (ii) CB12 l uses all application records during 13 weeks to model the career proﬁle of each job seeker. Thus, CB12 l has longer sequences that enable us to evaluate the effectiveness of our proposed method. We further split the last 14 days for testing and the remaining sessions for training. We ﬁlter job applications in the test set that do not belong to the training set as this enables a better comparison with the approaches, which can only recommend items that have been used to train the model. TABLE I: Statistics of datasets, #S represents the session number, and #A is the applications number. Avg SLen is the average application number in sessions. #Metadata contains the cardinality of each metadata attribute. Fig. 2: The relationship between locations of the job seeker and the applied job in CareerBuilder12 datasets. As we described in Section IV-D, the “location” is an essential factor that needs to be considered in the job recommendation. In order to further prove this observation, in Figure 2, we illustrate the relationship between locations of job seekers and applied jobs in CareerBuilder12 datasets. As shown in Figure 2b, most job seekers (92.7% in CB12 s and 93.8% in CB12 l) have applied for jobs in their states. Among these people, 81.3% and 79.7% of job seekers only consider jobs in their own states. Figure 2a shows that only 39.6% and 40.5% of job seekers apply for jobs in their own cities, because job opportunities in their cities are usually limited. People are also applying for jobs in other cities in the same state, as explained above. Therefore, the “location” (the job site or the current location of the job seeker) is an essential factor to be considered in the job recommendation. In this experiment, job representations hwere obtained by Doc2Vec with dimension d = 300 via the distributed memory. The dimension dof identiﬁer embedding eand the query dimension dwere set to 100. The dimensions dand dwere also set to 300. We applied the dropout technique with a rate of 0.2 to each layer and L2 regularization with rate 1e-4 to parameter weights. The PANAP was trained and evaluated with a 256 mini-batch size, and we used 15 negative samples for training and 50 for evaluation. The Adam [28] optimizer with a learning rate of 5e-4 was used. Metadata attributes with low cardinality (<= 10) were one-hot encoded, and high cardinality attributes were represented as trainable embeddings. We used two FC layers, with Leaky ReLU [29] and tanh activation functions to combine metadata vectors. We ﬁrst explore a sampling strategy inspired by [30], and then propose an improved sampling strategy for the job recommendation scenario. This improved strategy considers the current geographic location of the job seeker and the job site when sampling negative jobs. The two strategies are: proposed in [30], which adds additional samples with a uniform sampling strategy from a global buffer of the N most recently applied jobs, when there are not enough negative samples within the mini-batch. Jobs are uniformly sampled from the “candidate set” (i.e., jobs within the mini-batch and additional jobs); location-biased: Different from Strategy 1, in Strategy 2, we ﬁrst select the jobs in the same state as the job seeker from the “candidate set” as negative samples. When there are not enough negative samples in the current state, we sample jobs in other states from the “candidate set”. The baselines used are listed as follows: tion rule [31] with a maximum rule size of two; on the cosine similarity between representations of each applied job and the N most recently applied jobs in the global buffer; last applied job during the current session as in [17]; session with the past sessions in the training dataset, rather than considering only the last job; of SkNN that emphasizes jobs more recently interacted within the current session, when computing the similarities with past sessions (a linear decay function is used); model to model user behavior sequences; personalized-attention layer with a LSTM layer, Figure 3a, and (ii) PLSTM adds job seeker metadata to each job representation to generate Personalized job embedding [13] before the LSTM layer, Figure 3b. The evaluation metrics used in this work are Hit Rate (HR@5) [33], Mean Reciprocal Rank (MRR@5) [33] and Normalized Discounted Cumulative Gain (NDCG@5) [34]. In this section, we present our experimental results (HR@5/MRR@5/NDCG@5). For all tables shown in this section, the score in bold is the best in each metric, and the score in the underline is the second best. TABLE II: Next-Application Prediction performance. PANAP (S2) 0.691/0.492/0.541 0.742/0.543/0.593 According to Table II, we have the following observations: (i) Among all models, POP and CS give the lowerest scores, as they neither model the personalized preference nor consider the sequential information. Although POP is often a strong baseline in certain domains, i.e., news and movies, career preferences are less affected by popularity factors in the recruitment domain. (ii) Overall, the NN-based methods consistently outperform traditional methods, demonstrating that NNs are good at modeling sequential information, and the selfattention mechanism can improve accuracy. (iii) Our proposed method PANAP (S2) with sampling strategy S2 and its variants LSTM and PLSTM perform best among all baselines, which indicates the job content and metadata can effectively improve the recommendation performance, similar observations can be found in Section VI-C. (iv) PANAP (S2) outperforms LSTM and PLSTM, which use LSTM to model the sequential information. One possible reason is that in the recruitment domain, career preferences are less dynamic than other domains, and application sequences are relative short (3.87 and 5.61 on average for both sets), thus the advantage of RNN can not be well demonstrated. This result also demonstrates the advantage of personalized-attention as different jobs might have different importance for career preference modeling, and selecting the more critical jobs is useful for achieving better recommendation performance. Moreover, LSTM is better than PLSTM, one possible reason is that PLSTM merges the job seeker metadata into each job in the session, which will weaken the information carried by the job itself. In this part, we analyze the effectiveness of the personalizedattention mechanism using CB12 s dataset. As shown in Table III, the models with attention mechanism consistently outperform the model without attention, and our model with the personalized-attention outperforms its variant with vanilla attention (similar to the global attention used in [11]). Such a result is probably since the vanilla attention uses a ﬁxed query vector and cannot adjust to different personal preferences. TABLE III: Different attention mechanisms. As shown in Table IV, (i) It is obvious that methods with the additional information (i.e., content representation or metadata) generally give better results than what is achievable from the job identiﬁer IDonly (Only JobID) on CB12 s dataset. (ii) The metadata has a fewer inﬂuence on PANAP (S2) than LSTM (29.1% average reduction between Meta+Content+JobID and No Meta on three metrics compared to 41.0%). One possible reason is that PANAP (S2) utilizes a personalized-attention mechanism to model career preferences, which already contain personal information. (iii) Since the “location” factor affects the choice of job seekers, and our sampling strategy is location-biased. The job metadata, e.g., City, State and Country could give more relevant information about “location”, so the scores of No JobMeta are lower than that of No SeekerMeta. (iv) PANAP (S2) consistently outperforms LSTM, even only the job identiﬁer IDis used, which indicates that PANAP (S2) does capture personal preference. This observation also proves the advantage of the personalized-attention mechanism in cases where no additional information is available. We examine the performance of two sampling strategies described in Section V-B on CB12 s dataset. According to Table V, PANAP (S1) outperforms PANAP (S2). To explain these results, we visualize job seeker representations (session representations) generated from PANAP (S1) and PANAP (S2) in Figure 4. We use t-SNE [35] to reduce representation dimensions. For illustration purposes, we categorize each job seeker according to his/her Major. TABLE IV: Different feature combinations. No Meta means that neither the job seeker metadata nor the job metadata is considered. TABLE V: Different negative sampling strategies. Note that categorizing job seekers through Major is not the most reasonable way because some job seekers are currently engaged in occupations that do not match their majors. Thus, we select three non-similar majors. People with these professional backgrounds are more likely to engage in related jobs, including Management, Computer Science and Medical Assistant. We also plot job seeker representations labeled with State in Figure 4b and Figure 4d to show the inﬂuences of different sampling strategies. Each color corresponds to one State. We observe from Figure 4b that representations learned by our model with S1 (i.e., PANAP (S1)) are well-clustered into groups, each corresponds to a State. This can be used to explain why the accuracy scores of PANAP (S1) are better than that of PANAP (S2). A reasonable explanation is that S1 does not consider the “location” factor when generating negative samples. More speciﬁcally, as mentioned in Section IV-D, job seekers are more likely to apply for jobs located in their cities or other cities in the same state. The two main reasons why a job seeker does not apply for a job are: the job content is inappropriate, or the work location is not suitable. If most of the negative samples are jobs in other states, regardless of the job content, these negative samples tend to force the model to capture subtle information between different states rather than different job contents. For instance, a job seeker in SeattleWashington has a background of computer science. sales representative and java developer are two negative samples from Miami-Florida. Due to the “location” factor, this job seeker may not apply for java developer, while sales representative is not suitable from both “location” and job content perspectives. With these negative samples, the model learns to distinguish between locations (e.g., Seattle-Washington and Miami-Florida) rather than the contents of jobs (e.g., computer science and sales representative). Therefore, the learned job seeker representations are not categorized according to their Major categories, as shown in Figure 4a. Instead, they are grouped together by the “location” as in Figure 4b. To handle this problem, we propose a location-biased sampling strategy, S2, as described in Section V-B, which prioritizes jobs in the same state as the job seeker as negative samples. We visualize the representations learned through S2 in Figures 4c and 4d Fig. 4: Visualization of learned representations. Fig. 5: Different numbers of training negative samples k. to show the promising results of our proposed strategy. We observe that the job seekers are grouped by Major in Figure 4c, which demonstrates the effectiveness of S2. This section discusses the inﬂuence of the number of negative samples used for training on prediction accuracy. The experimental results on CB12 s dataset are shown in Figure 5, where k negative samples are used for training and 50 samples for evaluation. When k increases (e.g., from 5 to 10), the performance of our model ﬁrst has a noticeable improvement. This may be because when k is too small, the information provided by negative samples is relatively limited, and the model cannot learn useful information. Then, when k continues to increase (e.g., from 10 to 20), the performance becomes stable. However, if k is too large, there may not be enough jobs in the same state. Negative samples in other states become dominant, making it difﬁcult for the model to identify the valuable information correctly. As explained in Section VI-D, the model will learn to distinguish the difference of positions, just like PANAP (S1). As a result, the performance consistently improves. In this work, we proposed a personalized-attention model for the Next-Application Prediction problem, which improves the prediction accuracy. The experiments conﬁrm that, by incorporating personalized-attention, our method can better capture the personal career preference than baseline methods. We investigated the importance of incorporating job content information and metadata in the recruitment domain. Moreover, considering the “location” factor when generating negative samples can provide more useful information on job content. This work is supported by Randstad corporate research chair in collaboration with Universit´e Paris-Saclay, CentraleSup´elec, MICS. We would like to thank the M´esocentre computing center of CentraleSup´elec and´Ecole Normale Sup´erieure Paris-Saclayfor providing computing resources.