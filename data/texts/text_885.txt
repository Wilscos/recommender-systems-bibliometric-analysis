Suppose we have a black-box function (e.g., deep neural network) that takes an image as input and outputs a value that indicates preference. How can we retrieve optimal images with respect to this function from an external database on the Internet? Standard retrieval problems in the literature (e.g., item recommendations) assume that an algorithm has full access to the set of items. In other words, such algorithms are designed for service providers. In this paper, we consider the retrieval problem under dierent assumptions. Specically, we consider how users with limited access to an image database can retrieve images using their own black-box functions. This formulation enables a exible and ner-grained image search dened by each user. We assume the user can access the database through a search query with tight API limits. Therefore, a user needs to eciently retrieve optimal images in terms of the number of queries. We propose an ecient retrieval algorithm Tiara for this problem. In the experiments, we conrm that our proposed method performs better than several baselines under various settings. • Information systems → Web searching and information discovery; Users and interactive retrieval. Information Retrieval, Web Searching, Linear Bandits, Private Recommender Systems ACM Reference Format: Ryoma Sato. 2022. Retrieving Black-box Optimal Images from External Databases. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining (WSDM ’22), February 21–25, 2022, Tempe, AZ, USA. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3488560. 3498462 As the amount of information on the Internet continues to drastically increase, information retrieval algorithms are playing more important roles. In a typical situation, a user of a system issues a query by specifying keywords, and an information retrieval algorithm retrieves the optimal items with respect to the query words. Here, the retrieval algorithm is designed by the service provider, not by the user. The uses of information systems have become divergent, and various retrieval algorithms have therefore been proposed, e.g., a cross-modal image search [9,32], complex query retrieval [47], and conversational recommender systems [16, 58]. Deep neural networks have achieved state-of-the-art performances in computer vision tasks [27,34], notably image retrieval [4,8,25,48]. In a conventional setting of image retrieval, algorithms assume that they have full access to the image database. A straightforward method under this setting is to evaluate all images in the database and return the one with the maximum score. When the image database is extremely large, two-step methods are used, i.e., a handful of images are retrieved through fast retrieval algorithms such as a nearest neighbor search, and the results are ranked using sophisticated algorithms. Hash coding further improves the eectiveness and eciency [36, 40]. In this study, we consider information retrieval under a dierent scenario. Whereas most existing studies have focused on how a service provider can improve the search algorithms, we focus on how a user of a service can eectively exploit the search results. Specically, we consider a user of a service builds their own scoring function. The examples of the scoring functions are as follows. Example 1 - Favorite Image Retrieval:A user trains deep neural networks using a collection of favorite images found in dierent services and wants to retrieve images with similar properties in a new service. Example 2 - Similar Image Retrieval:Deep convolutional neural networks are known to have a superior ability to extract useful image features [4,8,23]. Although some online services provide similar image search engines, users do not have full control of the search. For example, even if the service provides a similar texturebased image search engine, some users may want to retrieve similar images based on the semantics. The user-dened score function allows image searches at a ner granularity. Example 3 - Fair Image Retrieval:A search engine can be unfair to some protected attributes. For example, when we search for images through a query “president,” an image search engine may retrieve only male president images [56]. Some users may want to use their own scoring function, e.g., scoring male and female images equally. Recent advancements in deep learning, such as self-supervised contrastive learning [13,28] and meta-learning [22], enable the training of deep neural networks with a few labeled samples. In addition, many pre-trained models for various vision tasks have been released on the Internet. Machine learning as a service platform, such as Microsoft Azure Machine Learning Studio and AWS Machine Learning, has also made it easy to build a machine learning model. These techniques and services enable an individual to easily build their own black-box scoring function. Suppose a user has already built a black-box function she wants to optimize. How can she retrieve optimal images with respect to this function from an image database on the Internet? O : T → X × 2 Under this setting, an individual cannot evaluate all images in the image database because it contains a signicant number of images. It is also impossible for an individual to build a search index (e.g., a hash index) because of both limited access to the database and the insucient computational resources of the individual. These limitations prohibit the use of standard image retrieval algorithms. In this paper, we assume that a user can access the database through a search query alone and that a tight query budget exists. In addition, we assume little knowledge about the database to apply our method to a new environment. We formulate the problem through the lens of the multi-armed bandit problem and propose a query ecient algorithm, Tiara, with the aid of pre-trained representative word embeddings. We conrm the eectiveness of the proposed method under various settings, including the online Flickr environment. It is noteworthy that Bayesian optimization and optimization on deep neural networks [21,46,55] also aim to optimize black-box or complex functions. However, these methods assume a continuous and simple optimization domain, typically the entire Euclidean spaceR, a hypercube[0, 1], or a unit ball{𝑥 | ∥𝑥 ∥ ≤ 1}. By contrast, we aim to retrieve optimal images from the xed database. Therefore, the optimization domain is a discrete set of images. Although there are several methods for discrete black-box optimization [6,49], they also assume that the optimization domain is simple, e.g.,{0, 1}, or at least they have full access to the optimization domain. Under our setting, an algorithm does not even know the entire optimization domain, i.e., the image database. This limitation causes numerous challenges, as we describe in the following sections. The contributions of this paper are summarized as follows: •We formulate the black-box optimal image retrieval problem. This problem examines how a user of an online service can eectively exploit a search engine, whereas most existing studies focus on how a service provider can improve a search engine. •We propose Tiara, an eective method for this problem for the rst time. Tiara is a general algorithm that works in various situations and retrieves optimal black-box images with few API queries. •We investigate the eectiveness of Tiara using many realworld data. Notably, we conduct “in the wild” experiments on the real-world Flickr environment and conrm that Tiara can be readily used in real-world applications. Reproducibility:Our code is available at https://github.com/joisino/ tiara. LetXbe a set of images in the image database. We do not know the exact set ofX. Let𝑓 : X → Rbe a black-box function that evaluates the value of an image. For example,𝑓measures the preference of the user in favorite image retrieval and measures the similarity in similar image retrieval. The notations are summarized in Table 1. In this section, we formulate the problem of black-box optimal image retrieval. We observe that many image databases, such as Flickr and Instagram, support (hash) tag-based search. We assume that we can search for images by specifying a tag through an API. For example, in the Flickr case, we use theflickr.photos.search API. For a formal discussion, we generalize the function of tag search APIs. LetT ⊂ Σbe the set of tags, whereΣis the set of strings. We formalize a tag search API as a (randomized) oracleOthat takes a tag as input and returns an image with the tag. We assume that Oalways returns dierent images even when we query the same tag twice. In addition to the image itself, we assume that the oracle Oreturns the set of tags of the image. Therefore, for any tag𝑡 ∈ T, O(𝑡) ∈ X ×2. LetO(𝑡).image ∈ Xdenote the returned image and O(𝑡).tags ∈ 2denote the returned tags. As the oracle returns an image with the query tag, 𝑡 ∈ O (𝑡 ).tags always holds. We nd that myriad tags exist in real-world services, and we cannot know the entire tag set. Therefore, we assume that we know only a fractionTof the tag set. Here,Tcan be constructed by browsing the online service or retrieving popular tags through an API, e.g., flickr.tags.getHotList, in the Flickr example. We assume that there is a budget𝐵 ∈ Zfor the oracle call. For example, in the Flickr case, There is an API rate limit of3600calls per hour. Thus, it is natural to assume that we can use at most3600 API calls in one task. If we retrieve many images within a short period of time, the API limits become tighter for each retrieval. To summarize, the black-box optimal image retrieval problem is formalized as follows. Black-box optimal image retrieval. Given: • Black box function 𝑓 : X → R • Oracle O : T → X × 2 • Known tags T⊆ T • Budget 𝐵 ∈ Z Goal:Find an image𝑥 ∈ Xin the image database with as high an 𝑓 (𝑥) as possible within 𝐵 accesses to the oracle. In this section, We introduce our proposed method, Tiara (Tagbased image retrieval). We rst propose regarding the black-box optimal image retrieval problem as a multi-armed bandit problem [37,57]. Specically, we regard a tag as an arm, the budget𝐵as the time horizon, and the objective value𝑓 (O (𝑡).image)as the reward when we choose arm𝑡. This formulation enables us to use o-the-shelf multi-armed bandit algorithms, such as UCB [3],𝜀-greedy, and Thompson sampling [60]. This formulation is the basics of our proposed algorithm. However, there are several challenges to a black-box optimal image retrieval problem. First, we do not initially know all arms but only a fractionTof arms. ConsideringTalone leads to suboptimal results becauseTdoes not contain the best arm in general. Second, myriad arms exist, and the number|T |of arms is larger than budget 𝐵in practice. Standard multi-armed bandit algorithms rst explore all arms once. However, they are unable to even nish this initial exploration phase under a tight budget constraint. The rst problem is relatively easy to solve. We obtain tags O(𝑡).tagswhen we choose arm𝑡. These tags may contain new tags. We can add such tags into the known tag set and gradually grow the known set. A good bandit algorithm will choose relevant tags, and the returned tags will contain relevant tags. For example, suppose that the black-box function𝑓prefers cat images. A good bandit algorithm will choose “cat” and “animal” tags and obtain cat images accompanied by many cat-related tags. Even if the budget is so tight that we cannot know all tags within the budget, a good bandit algorithm ignores irrelevant tags and prioritizes the collection of many relevant tags. The second problem is essential and dicult to solve. We investigate how to improve the query eciency using tag embeddings in the following sections. Discussion on the max-bandit problem.It should be noted that standard bandit algorithms aim to maximize a cumulative reward or regret, whereas the black-box optimal image retrieval problem aims to nd an image with the maximum value. These goals are not exactly the same. The problem of obtaining a maximum reward is known as a max𝐾-armed bandit [17] or extreme bandit [10]. However, we adhere to the standard bandit setting in this study for the following reasons: First, we assume that the reward distribution is Gaussian-like, whereas existing max-𝐾-armed bandit algorithms [10,17] mainly assume that rewards are drawn from extreme value distributions, such as the GEV distribution. We nd that this is not the case in the applications considered herein, i.e., image retrieval. Second, under our setting, an arm with a high expected value often leads to a high maximum value because such an arm usually represents the concept captured by the black-box function𝑓. By contrast, max-bandit algorithms focus on detecting heavy tail arms with possibly low average rewards. We nd that this is not necessary for our setting. Finally, we experimentally conrm that our proposed method already shows a superior empirical performance even though it does not directly maximize the maximum objective value. We leave the exploration of the max-bandit algorithms in our setting for future work. Budget 𝐵 ∈ Z, Oracle O : T → X × 2, Tag Embedding {𝒗∈ R| 𝑡 ∈ T }, Regularization coecient 𝜆 ∈ R, Exploration coecient 𝛼 ∈ R. ← 𝒗𝑨𝒃 + 𝛼𝒗𝑨𝒗∀𝑡 ∈ T// Scores ← argmax𝑠// Choose the best arm ← O (𝑡 Because we cannot choose each arm even once on average, we need to estimate the value of each arm without observing the reward from it. We estimate the value of one arm from the rewards obtained from the other arms. The key is how to dene the similarities of the arms. As the challenge here, we assume a new image database, and owing to the tight API limit, it is dicult to learn the similarities from the current environment in an online manner. To tackle this problem, we utilize external resources. We nd that a tag in an image database is usually described through natural language and typically is a word or composition of words. We use a pre-trained word embedding [45,50] to dene the similarities between tags. Specically, we rst decompose a tag into a bag of words by nonalphabetical symbols, e.g., a white space. We use the mean of the word embeddings in the bag of words as the tag embedding. Owing to the tag embeddings, we can infer the value of an arm from similar arms. For example, if the reward from a “cat” tag is high (resp. low), we can assume the black-box function is highly (resp. rarely) related to cats, and we can infer that similar tags with similar embeddings, such as “Aegean cat” and “animal,” are also valuable (resp. irrelevant) without actually querying them. Our proposed method combines the aforementioned tag embeddings with a bandit algorithm. Specically, we utilize LinUCB [39]. Because there are no contextual features, we use only features of arms. We dene the feature of an arm as the tag embedding introduced in Section 3.2 and apply LinUCB to this feature. We call this variant Tiara-S, where S stands for “single” and “simple.” However, we found that there are too many tags, and LinUCB is still inecient for learning a reward because of the tight query budget and limited training samples. To improve the query eciency, we use another signal from the oracle. The oracleOreturns not only an image but also the tags of the returned image. We assume that these tags have similar average rewards and add these tags into the training dataset. Specically, when we query tag𝑡 ∈ T, we use{(𝑠, 𝑓 (O (𝑡).image)) | 𝑠 ∈ O (𝑡).tags}as training data, whereas Tiara-S uses only{(𝑡, 𝑓 (O(𝑡).image))}. As we will see in the experiment, this technique signicantly improves query eciency and performance. Algorithm 1 shows the pseudo-code of Tiara. Time Complexity.The bottleneck of the computation is in Line 7. The inverse matrix𝑨can be eciently computed in an iterative manner using the Sherman–Morrison formula, i.e., This technique reduces the cubic dependence on the number of dimensions to the quadratic dependence. Therefore, the computation is in Line 7 takes𝑂 (|T|𝑑)time. Let𝑇be the maximum number of tags of an image. The value of𝑇is typically10to 100. Because|T|increases by at most𝑇in an iteration, the total time complexity is𝑂 ((|T| + 𝐵𝑇)𝐵𝑑)in the worst case. In our problem setting,𝐵is small (e.g., in the hundreds) because of the tight API limitation, and|T| ≈ 100and𝑑 ≈ 300are also small during the experiments. Therefore, the oracle calls in Line 9 become a bottleneck in the wall-clock time because it requires communication to the Internet. As the oracle calls are common in all methods, Tiara is suciently ecient. When the black-box function is complex, its evaluation can be a computational bottleneck as well. Tiara evaluates𝑓as few as𝐵times, which is the same as with other baseline methods. In addition, when the eciency is insucient, we can speed up Tiara through a lazy variance update [19] and by applying sub-sampling heuristics. Discussion on graph-feedback bandits.There are several multiarmed bandit algorithms with a so-called feedback graph setting [1, 31,42]. This is an intermediate setting between the bandit and full feedback. Specically, it assumes that there is an underlying graph, where a node represents an arm, and when we choose arm𝑡, we can also observe the rewards of the neighboring arms. The underlying graph can be directed and time-varying. Therefore, if we dene the neighbor of𝑡asO(𝑡).tags, our problem is seen as a variant of the feedback graph setting. However, we do not employ the feedback graph framework for the following reasons: First, existing graph feedback bandit algorithms require the number of neighbors of each neighbor [1,31,42], i.e.,|𝑓 (O (𝑠).tags)|, ∀𝑠 ∈ 𝑓 (O(𝑡).tags)in our setting. We need additional API queries to compute these values. Such additional queries are prohibitive because the API limit is tight under our setting. Second, graph feedback bandit algorithms assume that the reward feedback of neighboring arms is an unbiased estimate of the true rewards [1,31,42]. However,𝑓 (O (𝑡).image) is not unbiased for arm𝑠 ∈ O (𝑡 ).tags. Therefore, we cannot enjoy the theoretical guarantees of the graph feedback bandits. Third, the improvement obtained by the feedback graph framework is on the order of𝑂 (𝛼/𝑛)[31], where𝑛is the number of arms, and𝛼is the size of the maximum independent set of the feedback graph. Under our setting, the sizes of the feedback graphs and𝛼are still large in practice. How to leverage the existing graph-feedback bandit algorithms for our setting is an interesting area of future study. Discussion on the reward estimation model.Tiara uses LinUCB and a linear model for estimating the reward from the feature vector. In general, we can use any model for prediction. We use a linear model owing to the following reasons: First, complex models are dicult to train with a tight sample budget. Second, LinUCB empirically performs quite well under various tasks [33,39] regardless of its suboptimal theoretical regret. Third, we use the average word embeddings as the feature vector of an arm. It has been conrmed that word embeddings are representative and that the weighted average of the word embeddings with a cosine similarity or liner models produce superior performances in many NLP tasks [2,54] and sometimes outperform even neural network-based methods. Although not our original goal, Tiara provides an interpretation of the black-box function 𝑓 as a byproduct. Deep neural networks suer from interpretability issues for reliable decision making. There have been many interpretation methods developed for deep neural networks [55,59]. We consider model-level interpretability [46,55,62], i.e., interpreting what function each model represents. It is unclear what function each model represents by simply looking at the model parameters of deep models. Even if the model is prepared by the user, deep models sometimes behave in unexpected ways [24,41]. Input instances that produce high values can be regarded as representations of the model [46,55,62]. Tiara can retrieve such images from external image databases. Compared to methods that use a xed dataset, the search space of Tiara is extremely large. Therefore, there are more chances that relevant images will be found. In addition, tag scores of Tiara also provide another interpretation of the black-box function through words. We show that these tags are also benecial for interpretability by visualizing word clouds in the experiments. The tag-based interpretability is benecial for further exploration as well. When the result is unsatisfactory, the user can continue manual exploration from the tags with high scores. We investigate the performance of Tiara using various real-world datasets. 4.1.1 Baselines. We use the following baselines. • Random queries random known tags. • 𝜀-Greedyis a bandit algorithm. This algorithm chooses the best tag with the highest empirical mean reward with a probability of1−𝜀and chooses a random tag with probability 𝜀. The candidate pool is set to T. • UCBis a bandit algorithm. The score of tag𝑡is the empir- ical mean reward plus𝛼1/𝑛, where𝑛is the number of observations from tag𝑡, and𝛼is a hyperparameter. UCB chooses the tag with the highest score. The candidate pool is set to T. Figure 1: Open Image Environment. (Top) Tench, (Bottom) Black Swan. (Left) Learning curves averaged over 10 independent runs. (Mid) Word clouds that represent the scores computed by Tiara at the end of the last iteration. These visualizations provide an interprtability of the black-box function. (Right) Best images found at each iteration. Table 2: Open Image Environment. Each score is the highest 𝑓 (𝑥) found by an algorithm. The scores are averaged over 10 independent runs, and the standard deviations are also reported. The highest score is highlighted by bold in each column. • Ada-𝜀-Greedyis a variant of𝜀-Greedy. This algorithm inserts new tags to the candidate poolTwhen new tags are found and chooses a tag from T. • AdaUCBis a variant of UCB. This algorithm inserts new tags to the candidate poolTwhen new tags are found and chooses a tag from T. • Tiara-Sis a variant of Tiara that uses only the query tag for training. 4.1.2 Hyperparameters. We use𝜆 = 1and𝛼 = 0.01for Tiara and Tiara-S across all settings without further tuning. We will show that Tiara is insensitive to the choice of these hyperparameters over orders of magnitude in Section 4.5. We use300-dimensional GloVetrained using six billion Wikipedia 2014 + Gigaword 5 tokens for the word embeddings. We report the performance with various hyperparameters for the baseline methods. Note that hyperparameter tuning is prohibitive in practice because of the tight API limit. If we apply hyperparameter tuning, we should use these query budgets for the main task instead. Therefore, this setting is slightly advantageous for the baseline methods. We use the Open Images Dataset V6 [35] to construct the environment for the rst testbed. Each image in this dataset has multi-class annotations, such as “cat,” “Aegean cat,” and “Pumpkin pie.” An image has8.8classes on average. We use these classes as tags. We utilize ResNet18 [27] trained with ImageNet for the black-box functions. Specically, for each class𝑐of ImageNet, we use the presoftmax logit for𝑐as the back-box function. Among1000classes of ImageNet, we use10classes𝑐 = 1, 101, · · · , 901, i.e., Tench, Black Swan, Tibetan Terrier, Tiger Beetle, Academic Gown, Cli Dwelling, Hook, Paper Towel, Slot Machine, and Water Tower. Note that the retrieval algorithms do not know these class names, i.e., the function is a black-box. We use these class names for only evaluations and interpretations of the results. Note also that the set of tags (i.e., Figure 2: Safebooru Environment.(Left) Learning curves averaged over 10 independent runs. (Middle) Source images. (Right) Best Images found. In the rst row, we show the second best image for Tiara because Tiara found the exact source image. classes of the Open Image Dataset) diers from the set of classes of ImageNet. We subsample10,000test images from the Open Images Dataset and construct an environment. When we query tag (class)𝑡, this environment returns a random image with class𝑡and the set of classes this image belongs to. We choose100random tags as the initial known tags Tand set the budget to 𝐵 = 500. We run ten trials with dierent seeds. Table 2 reports the means and standard deviations of the best𝑓for each method within𝐵 queries. The last column reports the average of ten classes. These results show that Tiara performs the best under all settings, and Tiara-S performs second best on average. The middle panels in Figures 1 show the word cloudsgenerated by Tiara. The size and color of a tag represent the score of the tag at the nal iteration. These scores provide interpretations for the black-box functions. For example, in the case of tench, sh-related tags, such as Trout, Carp, and Milksh, have high scores. In the black swan case, bird-related tags, such as Swan, Waterfowl, and Duck, have high scores. We stress again that Tiara does not use the ground truth class name but instead treats𝑓as a black-box function. Even when the ground truth class name is unavailable to us, the word cloud generated by Tiara and the retrieved images indicate that𝑓is sh-related in the rst example and bird-related in the second example with signicant interpretability. The aim of this section is to conrm that Tiara is eective even in a completely dierent domain. We use Safebooru as a testbed. We use a dump retrieved on June 7, 2019. Each image has34tags on average, such as “smile,” “long hair,” and “blonde hair.” We use illustration2vec [52] to construct the black-box functions. We use the latest100,000images from this dataset and construct an environment. As a result of the broken links, this environment contains81,517images in total. When we query tag𝑡, this environment returns a random image with tag𝑡and the set of tags this image belongs to. We choose100random tags as the initial known tags Tand set the budget to 𝐵 = 500. We conduct semantically similar image search experiments. We emphasize that although this environment does not provide an ocial image-based search, our algorithm enables such an image-based search. Given a source image𝑠, we compute4096-dimensional embedding𝒗∈ Rusing the pre-trained illustration2vec model . We use the Gaussian kernel between the embeddings of an input image𝑥and the source image as the black-box function, i.e., 𝑓 (𝑥) = exp(−∥𝒗− 𝒗∥/𝜎), where𝒗∈ Ris the embedding of input𝑥computed using the illustration2vec model, and𝜎is the bandwidth of the Gaussian kernel. We set𝜎 = 100during this experiment. The more semantically similar the input image is to the source, the higher the value taken by this function. We use two illustrations shown in Figure 2 (middle) as the source images. The right panels in Figures 2 show images retrieved by the methods. The rst source image is in the image database, and Tiara succeeds in retrieving the same image from the database. We show the second best image retrieved by Tiara in this case. Even the second best image is semantically similar to the source image, i.e., it depicts the same character with cherry blossom motifs, and has a higher objective value than the images retrieved by the baseline methods. For the second case, the source image is not in Figure 3: Flickr Environment. (Top) Black swan. (Bottom) Similar image retrieval. (Left) Learning curves averaged over ten independent runs. (Top middle) Word cloud generated by Tiara. (Bottom middle) Source image. (Right) Best images found duing each iteration. the database. Although not exactly the same, Tiara succeeds in retrieving a semantically similar image with the same characters and motifs, i.e., horn, rabbit, and costume. These results show the exibility of our framework such that Tiara can be applied to not only photo-like image databases but also illustration-like image databases using appropriate black-box functions. e.g., the illustration2vec model. The aim of this section is to conrm that Tiara is eective and readily applicable to real-world environments. We use the online Flickr environment in operation as a testbed. We also use ResNet18 trained with ImageNet to construct the black-box functions. We implement oracleOby combiningflickr.photos.searchand flickr.tags.getListPhotoAPIs. We use thelicense=’9,10’ option such that it returns only public domain or CC0 images. We also set the budget to𝐵 = 500. Because Flickr contains as many as ten billion images, it is challenging to nd relevant images within 𝐵 = 500queries. Each image has15tags on average, including “summer,” “water,” and “sea.” We conduct two experiments in this environment. First, we conduct the same experiment as in the open image environment. The top row of Figure 3 shows the result for the black swan class. Compared to Figure 1, Tiara in this environment learns more slowly than in the open image environment. We hypothesis that this is because the Flickr environment contains noisy tags annotated by users, which are occasionally described in foreign languages, whereas the open image environment contains only clean tags that indicate solid categories judged by annotators. Nevertheless, Tiara succeeds in retrieving black swan images in several hundred queries. Second, we conduct similar image retrieval experiments as in the safebooru environment. We use the output of the penultimate layer of the pre-trained ResNet18 for the image embedding. We use the Gaussian kernel between the embeddings of an input image 𝑥and the source image𝑠as the black-box function, i.e.,𝑓 (𝑥) = exp(−∥𝒗− 𝒗∥/𝜎), where𝒗∈ Ris the embedding of input 𝑥computed using ResNet18, and𝜎is the bandwidth of the Gaussian kernel. We set𝜎 = 10in this experiment. Figure 3 (bottom, center) shows the source image. As the right panels show, Tiara succeeds in retrieving semantically similar images depicting a sunrise over the sea. We investigate the hyperparameter sensitivity of Tiara in this section. Tiara has two hyperparameters, i.e., exploration coecient𝛼 and regularization coecient𝜆. Tiara also has a choice of word embeddings. It is crucial to ensure stability with respect to the hyperparameter choices because tuning the hyperparameters in a new environment is dicult with tight API budgets. The left panel of Figure 4 shows the average performance of Tiara in the Open Image Dataset environment with various values of𝛼maintaining 𝜆 = 1.0(default value). The𝑥-axis is plotted on a log scale. We show the performances of Tiara-S, UCB, and Random for reference. In this plot, we do not tune the hyperparameters of Tiara-S accordingly to maintain the conciseness of the plot. This plot shows that Tiara is stable with respect to𝛼over several orders of magnitude. The middle panel of Figure 4 shows the average performance with various values of𝜆maintaining𝛼 = 0.01(default value). The𝑥-axis is plotted on a log scale. The result shows that Tiara is stable with respect to𝜆over several orders of magnitude. The right panel of Figure 4 shows the average performance with various dimensions Figure 4: Hyperparameter sensitivity. As the default settings, we set the exploration co ecient as 𝛼 = 0.01, regularization coecient as 𝜆 = 1.0, and word embedding as 300-dimensional Glove and change one conguration in each panel. These results show that Tiara is stable with respect to the hyp erparameter choices across several orders of magnitude. of the GloVe word embedding maintaining𝛼 = 0.01and𝜆 = 1.0 (default values). This result shows that Tiara performs better with higher dimensional embeddings, i.e., more expressive embeddings. It also indicates that Tiara indeed utilizes the word embedding geometry. We recommend using high-dimensional and strong word embeddings for Tiara. Image retrieval has been studied for decades. The main concern is how to retrieve relevant images [4, 30, 38] with eciency [36, 40]. Deep neural networks have been preferred for image retrieval in recent years because they can extract rich features including texture [18], style [23], and semantics [4]. Hash-based methods have also been extensively studied for their eciency [36,40]. In addition, many extensions have been studied, such as multi-modal image search [9,32] and contextual retrieval [61]. We investigated the image retrieval problem from a dierent perspective. Specically, we consider how an outsider can retrieve desirable images from an external image database with as few queries as possible. Our problem setting can be seen as a crawling problem. Developing ecient web crawlers is a long-standing problem in the literature [11,12,14,15,20,51]. In particular, focused crawling [5,12,26,29, 43] is relevant to our problem setting. Focused crawling aims to eciently gather relevant pages by skipping irrelevant pages. However, there are several dierences between our study and existing focused crawling. First, focused crawling is used to search web pages by following WWW hyperlinks, whereas we search for images from an external database utilizing the tag search oracle. Thus, the existing crawling methods are not directly applicable to our setting. Second, we assume the API limit is extremely tight, e.g., 500, whereas existing focused crawlers typically visit hundreds of thousands of pages. Third, existing focused crawlers focus on retrieving pages of a specic topic [12,43], popular pages [5], pages with structured data [44], or hidden web pages [7]. By contrast, deep convolutional neural networks in our setting realize rich vision applications, as we show in the experiments. These applications are qualitatively dierent from the existing focused crawlers and are valuable in their own right. Private recommender systems [53] aim to build a fair recommender system when the service provider does not oer a fair system. Our problem can also be seen as constructing a private recommender system when the black-box function is a recommendation score. There are several dierences between our approach and private recommender systems. First, the existing methods, PrivateRank and PrivateWalk, assume the use of an item recommendation oracle, which is unavailable under our setting. Second, Tiara considers content-based retrieval, whereas PrivateRank and PrivateWalk mainly focus on a collaborative recommendation scenario. Third, our application is not limited to fairness, and we showed promising applications, including semantically similar image retrieval. Although we use deep neural networks as a black-box function, our framework and the proposed method are not limited to deep neural networks. For example, we can use human judgment as the black-box function, i.e., when we evaluate𝑓 (𝑥), we actually ask a human viewer how much he/she likes image𝑥. Because our proposed method requires several hundred evaluations for a single run, the current method is too inecient for human-in-the-loop experiments. More ecient methods are important for developing such intriguing applications. In this work, we have assumed that𝑓is a well-behaved function. It may be interesting to use buggy𝑓functions. For example, when we debug a deep neural network model𝑓, applying Tiara to𝑓may reveal what𝑓has already learned and has not yet. We hypothesize that there are much room for further applications of Tiara. We have assumed that the only way to access the image database is the tag search oracleO. Although our method is general owing to this formulation, many other APIs are available in real applications, such as user-based searches, popularity ranking, and collaborative ltering recommendations. Utilizing richer information to enhance performance and query eciency is important in practice. At the other extreme, dropping the assumptions of tag anity and tag search APIs to make the method applicable to broader databases is also an intriguing direction. Although we have focused on image retrieval problems, our formulation is not limited to such problems and can be applied to other domains such as music, document, and video retrieval problems. Exploring further applications of our framework is left as future work. In this paper, we formulated the problem of optimal image retrieval with respect to a given black-box function from an external image database. This problem enables each user to retrieve their preferable images from the Internet, even if the image database does not provide such features. We combined a bandit formulation with pre-trained word embeddings and proposed an eective retrieval algorithm called Tiara. Finally, we conrmed the eectiveness of Tiara using three environments, including an online Flickr environment. This work was supported by JSPS KAKENHI GrantNumber 21J22490. We are grateful to ARAM,トマリ,でんろく, Qie_,亀村江龍,こ んぺ伊藤,小本呆毛, andミテディーfor allowing the use of their wonderful illustrations.