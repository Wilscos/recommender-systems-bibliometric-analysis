Integrated Frontier Research for Medical Science Division, Institute for Open Department of Biomedical Statistics, Graduate School of Medicine, Osaka University, 2-2, Yamadaoka, Suita, Osaka 565-0871, Japan. Department of Medical Statistics, University Medical Center G¨ottingen, Department of Biomedical Statistics, Graduate School of Medicine, and and Transdisciplinary ResearchInitiatives (OTRI), Osaka University, Meta-analyses play a very important role in medical research and may have substantial impact in establishing sound medial evidence. Meta-analysts try to gather all the available evidences by conducting systematic literature searches including not only the scientiﬁc literature but also the so-called grey literature such as documents for regulation of new drug a pplications and conference abstracts (Gopalakrishnan and Ganeshkumar, 2013). Despite of such pain-taking eﬀorts, it is very ha rd to collect all infor ma t ion; then the reporting biases may arise when some negative results might not be reported by investigator s or are not likely to be accepted by scientiﬁc journals or mig ht be presented in a way that they become positive. Especially when it comes to the situation that publication status (publication or non-publication) depends on the nature and the direction of research ﬁndings, it was usually referred to as the publication bias (Thornton and Lee, 2000). used methods to identify and adjust for publication bias (Egger et al., 1997; Duva l a nd Tweedie, 2000). Despite of their simple interpretability through gra phical presentation, results obtained by these methods may be misleading (Terrin et al., 2003; Peters et al., 2 007). Modeling the selective publication process by a selection model may yield more reliable and interpretable results to quantify the impact of publication bias (Carpenter et al., 2009; Schwarzer et al., 2010). The Copas-Shi selection model was suggested to be preferable to the trim-and-ﬁll method by Schwarzer et al. (2010). It was an adoption of the Heckman selection model, which was ﬁrst proposed in the context of econometrics, then introduced The funnel plot and the trim-and-ﬁll method ar e among the most widely to the area o f meta-analysis by Copas (1999) and Copas a nd Shi (2000). A notable feature of the Copas-Shi selection model is that it modeled the selection process based on a simple G aussian latent variable, which can be easily linked to any nor ma lly distributed population model for its mathematical nature. This simplicity led wide extensions to more complicated meta-analyses such as the network meta-analysis (Mavridis et al., 20 13) and the diagnostic meta-analysis (Hattori and Zhou, 2018; Piao et al., 2019; Li et al., 2021), interpretation of the Heckman-type selection function might not be satisfactory in medical research. Selection functions deﬁned with the t est statistics used in each publication might be more a ppealing since P-va lues might be a very inﬂuential factor for the decision to publish. Preston et al. (2004) discussed maximum conditio na l likelihood estimation with a series of one-parameter selection functions based on the empirical P -va lues; Copas (2013) proposed a likelihood-based sensitivity analysis method with the selection function modeling the Wald-type statistics directly. Following Copas (2013), we denote these selection functions as t-type selection functions. Since inf erence of these methods is based on published data only, the maximization of the conditional likelihood can be computationally challenging even only with one parameter, hence a sensitivity analysis is recommended in practice by bo th Preston et al. (2004) and Copas (2013). With some sensitivity parameters ﬁxed in a plausible range, then the impact of the publication bias can be studied. Indeed, as will be demonstrated in our simulation study, the maximum likelihood estimation conditional on published might be hard to get converged and result in an unreasonable conﬁdence interval. Registration of study protocols in clinical trial registries is a non-statistical approach against selective publication; by prospectively registering all the clinical trials, one can identify all the studies and then address whether selective publication matters. According to the recommenda tion by the International Committee of Medical Journal Editors ( ICMJE) (DeAngelis et al., 2005), several clinical trial registry systems have been established and widely used in practice such as ClinicalTrials.gov (https://clinicaltrials.gov/ct2/home), World Health Organization’s (WHO) International Clinical Trials Registry Platfo rm (ICTRP) (http://apps.who.int/trialsearch/), EU Clinical Trials Register (EUCTR) (https//:www.clinicaltrialsregister.euctr-search/search) and ISRCTN (https//:www.isrctn.com/). Actually, the accumulated information in clinical trial r egistries could potentially be very useful in reducing publication bias (Hart et al., 2012; Ba uda r d et al., 2017) . However, their roles in meta-analysis practice are usually limited as a searching tool to identify those conducted but still unpublished studies. Some important study speciﬁc informa tion (e.g. the planned sample sizes) in the clinical tria l registries has not been utilized eﬃciently, in particular to address the potential impact on the estimation of eﬀect size. conducted but not published yet, which was available regardless of clinical trial registries, to make inference on the Copas-Shi selection model. Copas and Shi (2000) proposed to take a sensitivity analysis approach ﬁxing some unknown parameters as sensitivity parameters, since the likelihood function conditional on published was likely to have a ﬂat plateau and was hard to maximize. Huang et al. (2021) observed that the full likelihood function with the pla nned sample size was Huang et al. (20 21) utilized the planned sample sizes of studies that were likely t o be convex and all the unknown parameters could be well estimated by maximizing the full likelihood. The method by Huang et al. (2021) successfully simpliﬁed the inference for the Copas-Shi selection function. On the other hand, as argued, the Copas-Shi selection function may not be satisfactory in interpretation. In addition, to draw a sound conclusion, it is desirable to evaluate how robust the result is against various settings of the selective publication processes. bias under the selective publication process driven by the statistical signiﬁcance of the result, more speciﬁcally, the t-type statistic of each study, which is an a ppealing alternative to the Heckman-type selection function by Copas and Shi (2000). We propose a publication bias adjusted estimator based on inverse probability weighting (IPW), which is a widely used technique in missing data problems and causal inference. Considering the correspondence between the propensity score in missing data and causal inference and the selection function in metaanalysis, use of the IPW idea in meta-analysis is very natural and indeed is not new; Matsuoka et al. (2007) and Mathur and VanderWeele (20 20) examined t he IPW estimator to quantify publication bias in the context o f the meta-analysis. However, both relied on sensitivity ana lysis approaches. That is, the publishing probability which corresponds to the propensity score in the IPW estimator, was pre-deﬁned by the speciﬁed selection function and was not calculated from data, which can be a very diﬃcult ta sk in practice. With the planned sample size in the clinical trial registries, we intro duce an estimating equation for unknown parameters in the selection f unction, borr owing the idea to handle the propensity score in the general missing data problem under missing not at random (Kott and Chang, In this paper, we develop a simple inference procedure to correct publication 2010; Miao and Tchetgen Tchetgen, 2016; Morikawa and Kim, 2021). The estimating equation is tr actable and once the parameters in the selection function are obtained, our IPW estimator for the overall mean over studies is very simple of a closed form expression. In addition to providing a combined mean, evaluation of the between-study heterogeneity is also an important objective of meta-analyses; the common-eﬀect assumption is implausible in many systematic reviews and therefore random-eﬀects models are recommended in practice (Borenstein et al., 2010). We propose an IPW-type DerSimonian-Laird estimator for the betweenstudy var iance a nd also some other heterogeneity measures, all of which have a simple closed form. We developed asymptotic theory and a parametric bootstrap procedure to construct conﬁdence intervals fo r the overall mean a nd the between-study variance. duce notatio ns and the standard DerSimonian-Laird estimator for the ra ndo meﬀect meta-analysis, which our development relied on. In Section 3, the proposed method is introduced. In subsection 3.1, nota t ions considering clinical trial registries are introduced. In Section 3.2, some selection functions based on t-type statistics are introduced. In Section 3.3, the IPW estimators for the overall mean and the between-study variance are proposed. In Section 3.4, a parametric bootstrapping for constructing conﬁdence intervals are presented. In Section 3.5, we introduce IPW versions of other heterogeneity measures. In Section 4, we report results of simulation studies to examine the perfor ma nce of the proposed methods. In Section 5, illustrations are given with some meta-analysis datasets. We conclude this paper by mentioning issues in the methods and potential future The organization of the rest of the paper is as follows. In Section 2, we introwork. All the theoretical developments are placed in the web-appendix. Suppose we are conducting a meta-analysis o f N published studies to compare two treat ment groups. Let the estimated treatment eﬀect of the ith study denoted by y σis supposed to be available. Following the standard convention in the metaanalysis ﬁeld, σ the following random-eﬀects model; given µ is the true va lue of the ith study and is regarded as a random-eﬀect such that µ∼ N(µ, τ study variance. Then, the marginal model y above. where ω mators are available. In t his paper, we consider the DerSimonian-Laird (DL ) estimator (DerSimonian and Laird, 1986), which is given by where Q = estimator, which is deﬁned by (1) with τ such as the log-odds ratio or the log-hazard ratio, and its standard error The inverse variance weighted estimator (Cochran, 1954) for µ is denoted by = (σ+ τ). In practice, τshould be estimated and various esti- In addition to N published studies, suppose we identify M unpublished studies by using clinical trial registries. For i = 1, 2, ..., N +M, let t he random variable D 1 if the ith study is published a nd be 0 if unpublished. Without loss of generality, we assume that the ﬁrst N studies are published. As deﬁned in Section 2, for published studies, (y registered in a clinical trial registry, the planned sample sizes of the two groups (not separately by groups) are available regardless of clinical trial registry systems. Let n studies and be the planned sample size in the two groups for unpublished studies. We assume n we suppose the following dat a ar e ava ilable; f or i = 1, 2, ..., N (published studies), nis available. In the following, we suppose (y random samples fr om a population. In this subsection, we introduce some selection functions describing selective publication processes. We focus on the selection functions deﬁned with the ttype statistic t rameter (vector) . We consider one- or two-parameter selection functions. For two-parameter cases, we denote β = (β be the number of sample size enrolled in the two groups for published , n) is available and for i = N + 1, ..., N + M (unpublished studies), only , n) is denoted by π(β) = P (D= 1 | y, σ, n; β), where β is a pacluding the 1-par ameter logistic function and the modiﬁed 1-parameter logistic function where Φ(·) is the cumulative function of the standard normal distribution. Other one-parameter selection models were also considered such a s the half-normal and the negative-exponential selection functions and their modiﬁed versions. Preston et al. (2004) proposed t o estimate all the parameters o f (µ, τ maximizing the conditional log-likelihood function for published studies. However, as they commented, parameters in t he selection function might be estimated imprecisely, which in turn may inﬂuence the estimates of eﬀect size and result in an unreasonable conﬁdence interval. Probably, due to diﬃculty in estimation, Preston et al. (2004) mainly focused on one-parameter selection functions. Although these one-parameter selection functions have an advantage o f simplicity, they have a disadvantage of impossibility to describe the publication process that does not depend o n the t-type statistic, o r say a random selection. If some studies are unpublished independently from outcomes, β in the selection function (3) or (4) should be zero. Then, the marginal selection pro bability p = P (D should be 1, which does not allow existence of randomly unpublished studies. Preston et al. (2004) considered several one-par ameter selectio n functions in- Besides, two-parameter selection functions are also considered including the and the 2-parameter logistic model the marginal selection probability p ﬁxed, one could estimate all the parameters by satisfying the marginal selection probability and maximizing the observed conditional likelihood iteratively. Then the impact of the publication bias can be studied by monitoring how the eﬀect size changed as the selection probability decreased. With publication indicator D where S = N + M. This representatio n motivates us to use an estimate of the form by the propensity score, which is widely used in missing data problems and in causal inference. For estimation of β, consider the following estimating equation Copas (2013) proposed a likelihood-based sensitivity analysis method; with This is a natura l analogy of the inverse probability weighted (IPW) estimator where g(n motivated by t he propensity score a nalysis in the missing not at random setting (Kott and Chang, 20 10; Miao and Tchetgen Tchetgen, 2016; Morikawa and Kim, 2021). On speciﬁcation of g(n 2021), but we employ rather simple ones as f ollows. When we consider a oneparameter selection function such as (3) and (4), we use consider the estimating equation, ing equations (10) and (11) are unbiased and then the true value β (Kott and Chang, 2010; Miao and Tchetgen Tchetgen, 201 6; Morikawa and Kim, 2021) if the selection function is correctly sp eciﬁed (see proof in web-appendix A). tone function of β and then the equation can be easily solved by the NewtonRaphson or the binary search methods. For two-parameter selection functions, the Hessian matrix for (11) may not be positive deﬁnite and we observed computational diﬃculties in applying the Newton-Raphson method. We propo se to obtain the solution to the equation (11) by minimizing When we use a two-parameter selection function such a s (5) and (6), we The solution to the equation (10) or (11) is denoted byˆβ. The estimat- For o ne- parameter selection functions, one can easily see that (10) is a mono- We use the nlminb() function in R (package stats, version 3.6.2 ) for implementation. is deﬁned by ˆτ We call the estimator (13) the IPW-DL estimator. Q are the IPW versio ns of Q statistics in (2) and the ﬁxed-eﬀect model estimator, respectively. web-appendix A, we show consistency of ˆµ is correctly speciﬁed as S goes to inﬁnity and n Conﬁdence intervals of µ, τ estimators o f their asymptotic variance, whose derivations and deﬁnitions are given in web-appendix B. For estimation of τ, we propose an IPW version o f the DL estimator, which Finally, we propose the IPW estimator ˆµ= ˆµ(ˆβ, ˆτ) for µ. In Alternatively, one may use a pa r ametric bootstra p approach to construct conﬁdence intervals. Conditional on the data, parametric bootstrap samples ˜y generated from ˜y (β) is deﬁned by π(β) replacing t= y/σwith ˜y/σ, Let t he solution Then, deﬁne ˜µ= ˜µ(˜β, ˜τ), where strap samples of ˜y by B and the bth bootstra p sample is denoted by ˜y bth bootstrap samle by ˜µ 95 percent conﬁdence interval is constructed by ˆµ q(0.9 75)σ standardized bootstrap samples of (˜µ intervals of τ Higgins and Thompson (2002) discussed several heterogeneity measures alt ernative to τ interpreted approximately as the ra tio of conﬁdence interval widths for the overall mean from random-eﬀects and ﬁxed-eﬀect models, the latter can be used to describe the percentage of variability for µ that is due to heterogeneity rather than sampling error. The I summary measure of heterogeneity in their Review Manager Software and other commonly used packages for meta-analysis (e.g. metafor package, meta package). With the IPW version of Q-statistics (Q can be deﬁned as H would be useful to describe heterogeneity in the presence of selective publication process. For i = 1, 2, ..., S, suﬃciently large number (say, 100 0) of parametric boot- Simulation studies were carried out to assess the performance of the proposed IPW estimator. We conducted two kinds o f simulation studies; one was based on one-parameter selection functions and the other on two-parameter ones. We generate multiple studies and according to one- or two-parameter selection f unctions, some of them were selected as published studies. published studies. The simulation design for generating all the studies was similar to those considered in Huang et al. (2021). Suppose we are interested in conducting a meta-analysis of r andomized clinical tr ials to compare two treatment groups with a dichotomous outcome. The log-odds ratio was used as the summary measure of the treatment eﬀect between the experimental group and control group. We set the population treatment eﬀect µ = -0.50 which was motivated by the Clopidogrel study in Section 5.2 and τ = 0.05, 0.1 5 or 0.30, which reﬂects small to moderate heterogeneity. The total number of studies including published and unpublished was set as 15 , 25, 50 or 100. At ﬁrst, we generated t he true log-odds ratio of the ith study µ in the control group p event rate in the treatment group p Following Kuss (2 015), the total sample size of each study was generated from LN(5,1), the log-normal distribution with the location parameter 5 a nd scale parameter 1, and the minimum sample size was restricted to 20 patients (values below 20 were rounded up to 20). Subj ects were allocated to the two treatment We begin with describing how to generate complete data of published and ungroups with probability of 0 .5. Then the individual part icipant data could be generated fr om the binomial distributions B(n With t he generated individual participant data, we could calculate the empirical log odds rat io y tively picked several studies according to one- or two-parameter selection models and then created four datasets, which are referred as sDatasets 1 to 4, among which the ﬁrst two were based on one- parameter selection functions and the latter two were on two- parameter ones. The indicator of publication status D generated from the binomial distribution B(1, π published studies with the one-parameter logistic selection function (3) of β = 2. For sDataset 2, the one-pa rameter modiﬁed logistic selection function (4) of β = 5 was used. In these datasets, about 20 percent studies were regarded as unpublished. For sDataset 3 and sDataset 4, the two-parameter selection functions of (5) and (6) with β=(-0.3, -1) were used, and about 25 percent studies in sDataset 3 and 30 percent studies in sDataset 4 were regarded as unpublished, respectively. Selection functions used to generate sDataset 3 and sDataset 4 were plotted in Figure 1. In this subsection, we summarize r esults for one-parameter selection functions. In estimation, we used the one-parameter lo gistic selection function (3) and the modiﬁed logistic selection f unction (4) . For sDataset 1, the logistic selection model was correctly speciﬁed and the modiﬁed one was mis-speciﬁed. For sDataset 2 vise versa. We examined inﬂuence of correct/mis-speciﬁcation of the selection function From the complete data g enerated following the above procedure, we selecon estimation. For comparison, we applied the maximum conditional likelihood method by Preston et al. (200 4) with a correctly-speciﬁed or mis-speciﬁed selection function. To maximize the conditional log-likelihood, we used the nlminb() function in R. 1. The results for sDataset 2 were presented in the web-supplementary Table S1. We applied the standard mixed-eﬀects model (1) with the DerSimonian-Laird τ estimator using metafor package in R and observed that it had considerable biases. We found that the maximum conditional likelihood method by Preston et al. (2004) fa iled to converge in abo ut 20 percent realizations. Furthermore, even if the selection function was correctly speciﬁed, there were still certain bia ses a nd the covera ge probabilities were far fr om the nominal level of 95 percent. mates in all the realizations. If the selection function was correctly speciﬁed, the IPW estimator eliminated publication biases and the proposed asymptotic conﬁdence intervals had empirical coverage probabilities close to the nominal level of 95 percent under the large study scenarios (S = 50 and 100), while the parametric bootstra p conﬁdence intervals can result in much improvement with f ew studies (S = 15 and 25). For sDataset 1, misspeciﬁcation of the selection function did not lead serious biases. For sDataset 2, as summarized in the web-supplementary Table S1, we observed that misspeciﬁcation led certain biases with large number of studies (S = 50 and 100). Table S2 for sDataset 1 and sDataset 2, respectively. We o bserved that t he In Table 1, we presented the simulation results for estimation of µ for sDataset On the other hand, the proposed IPW estimator successfully obtained esti- Results for estimation of τwere presented in Table 2 and the web-supplementary DerSimonian-Laird estimator τ geneity due to the selective publicatio n process and the proportion of zero τ estimates could be extremely high even when S= 5 0 a nd 100, similar ﬁndings were also reported by Augusteijn et al. (2019) and Friede et al. (2017); while our IPW version of the DerSimonian-Laird estimator τ and less zero estimates in most scenarios. For both sDataset 1 and sDataset 2, misspeciﬁcation of the selection function did not inﬂuence the performance so much. However, the coverag e probabilities of t he asymptotic conﬁdence intervals for the τ τ, whereas the parametric bootstrap conﬁdence intervals led more conservative coverage probabilities. In this subsection, we summarized the results with the two-parameter selection functions. Fo r sDataset 3, the two-parameter probit model was correctly speciﬁed and the two -parameter logistic model was misspeciﬁed, and for sDataset 4 vise versa. We compared our proposed method with the maximum conditional likelihood method by Copas (2 013). As mentioned in Section 3.2, the method is implemented with a marginal selection probability ﬁxed (sensitivity analysis). In order to make a fair comparison, we used the empirical publication rate (p = N/ S) in implementation of the Copas method, and nlminb() function was used for its conditional log-likelihood o ptimization. 3, and the results for sDataset 4 were presented in t he web- supplementary Table S3. For reference, we also showed results with the standard mixed-eﬀects model. In Table 3, we pr esented the simulation results of µ estimates with sDataset The crude estimates were highly biased suggesting that the simulation design successfully generated data under selective publication. Both the Copas sensitivity analysis method and the proposed IPW method could reduce the biases and ours had smaller biases in almost all the scenarios when the selection model was cor rectly speciﬁed. We observed that the proﬁle likelihood method in the Copas sensitivity analysis gave substantially narrow conﬁdence intervals of inaccurate coverage probabilities. The asymptotic conﬁdence intervals for the IPW estimator might be so wide. On the ot her hand, the conﬁdence intervals based on parametric bootstrap seemed more reasonable and the covera ge probabilities were close to the nominal level in a lmo st all the scenarios. We also observed that both in sDataset 3 and sDataset 4, mis-speciﬁcation of selection function could introduce considerable biases, although the mis-speciﬁed IPW estimators were still less biased than the standard mixed-eﬀect model. 4 in Tables 4 a nd web-supplementary S4, respectively. We observed that our IPW version of DerSimonian-Laird τ zero estimates than the τ probabilities of the asymptotic conﬁdence interva ls were unsatisfactory when the true τ was 0.3, a more conservative parametric bootstrap conﬁdence interval can always perform well with the covera ge probabilities close to the nominal level of 95 percent. We also observed t hat mis-speciﬁcation of the selection function did not have much impact on the performance of τ sDataset 4. We presented the simulation results of τestimates for sDataset 3 and sDataset Firstly, we illustrate our proposed method with the antidepressant study which aimed to evaluate the improvement in depression symptoms of 12 antidepressant drugs, and the outcome was measured as the standardized mean diﬀerence between the treatment group and placebo group. In this study, Turner et al. (2008) identiﬁed 73 r egistered randomized clinical trials from the FDA registry, among them 50 were published and 23 were unpublished, and selective publication process was suggested by t he nature of data that most of the published studies showed statistical signiﬁcance while unpublished studies did not (see Turner et al. (2008) for more details). Since their focus was the meta-analysis of studies used for licensing, only the FDA registry was used for study searching and hence both the eﬀect size and standard error were available for all the studies (published and unpublished). Although this was not a typical situation of meta-analysis, we used this dat aset for an illustrative purpose of our proposed method. Regarding the overall mean o f all the 73 studies with the standard mixed-eﬀect model as the ”gold standard” , we compared the performance of our proposed method a nd ot her competitive methods empirically. The “gold standard” of DerSimonian-Laird estimate with all the 7 3 studies was 0.344 with a 95% CI o f [0.300, 0.388], while the DerSimonian-Laird estimate only with the 50 published studies was 0.409 with a 95% CI of [0.366, 0.453 ], indicating that the underlying selective publication process might have considera ble inﬂuence on estimation (see Table 5). We applied the one-parameter logistic (3) and its modiﬁed version ( 4), the At ﬁrst, we summarized t he results with the one- parameter selection functions. were estimated as 7.168 (95% asymptotic CI: [3.106, 11.231]; 95% bootstrap CI: [6.158, 8.711]) and 47.722 (95% asymptotic CI: [21.524, 73.920]; 9 5% bootstrap CI: [42.743, 55.285]) with (3) and (4), resp ectively. The resulting estimates of µ as well as those conditional likelihood-based estimators were summarized in Table 5. Preston’s conditional likelihood-based method gave the estimates of 0.355 (95% CI: [0.296, 0.414]) a nd 0.357 (9 5% CI: [0.301, 0.414]) with the oneparameter lo gistic selection function (3) and its modiﬁed version (4), respectively. Our IPW method gave the more conservative estimates as 0.333 (95% asymptotic CI: [0.2 83, 0.38 3]; 95% bootstrap CI: [0.263, 0.395]) a nd 0 .339 (9 5% CI: [0.287, 0.392]; 95% bootstrap CI: [0.251, 0.411]), accordingly. gistic (6) selection functions. As we mentioned in last paragraph, one beneﬁt of this data is it included all the information for both published a nd unpublished studies, hence an empirical comparison could be do ne by checking the estimation all the 73 studies and o ur estimating equations (11) to the 50 published studies. For two-parameter probit (5) selection function, the estimated selection functions were plotted with solid line and dashed line in Figure 2 ( a) for MLE and our method, r espectively. For the estimation using MLE, 3.206, -1.223]) and using the sample sizes of unpublished studies, we got totic CI: [-18.158, 14.867]; 95% bootstrap CI: [-2.379, -1.117]) and (95% asymptotic CI: [-9.122, 12.375]; 95% bootstrap CI: [0.995, 2.046 ]) . The asymptotic CIs were very wide, while the bootstrap ones seemed relevant. Ob- Next, we demonstrated the results with the two- parameter probit (5) and lo- ˆˆβ,ˆβ) using standar d maximum likelihood estimation (MLE) applied to servations for the two-parameter logistic (6) selection function were similar to this (Figure 2 (b)). We explained such observations in simulation studies, and we trust t he bootstrap CIs more. With both selection functions, the null hypothesis of β tion process behind. For the results of µ estimates with two -parameter selection functions, we estimated the Copas selection model with the marginal selection probability ﬁxed at p = 50/73 and obtained the estimate of 0.373 with a very short 95% CI of [0.356, 0.405]. Our IPW method gave the estimates o f 0.330 (95% asymptotic CI: [0.282, 0.378]; 95% bootstrap CI: [0.2 19, 0.419]) and 0.339 (95% asymptotic CI: [0.295, 0.383 ]; 95 % bootstra p CI: [0.25 8, 0.400]) with the twoparameter probit (5) and logistic (6) selection function, respectively. It seemed that in this study all these methods successfully eliminate certain publication bias. We observed that all the methods only relying on published studies gave zero estimates, while the proposed IPW version of DerSimonian-Laird ˆτ gave the non-zero estimates. With 73 studies (published and unpublished), the I was 22.8%. On t he other hand, with only published 50 studies, it was estimated as 0%, whereas the IPW version of I selection functions (see Table 5). Chen et al. ( 2013) conducted a meta-a nalysis of 12 published studies to compare the high and standard maintenance-do se clopidogrel on major adverse cardiovascular/cerebrovascular events (MACE/MACCE). Huang et al. (2021) revisited = 0 was statistically signiﬁcant, successfully suggesting a selective publica- We also compared the estimation of heterogeneity with the methods above. this study and identiﬁed 3 unpublished studies from multiple clinical trial registries (see Table S5 in web-appendix D for details). We use this data to gain some insights of the performance of our IPW method in small meta-analysis. tion function (3) and its modiﬁed version (4), asymptotic CI: [-0.222 , 2.257]; 9 5% bootstrap CI: [0.611, 1.681]) and 1.309 (95% asymptotic CI: [-0.114, 2.733]; 95% bootstrap CI: [0.9 53, 1.9 57]), resp ectively. The results of µ estimates were presented in Table 6. Without accounting for the publication bias, the result of standard mixed-eﬀects model concluded the significantly lower event rate in the high maintenance-dose clopidogrel group with the pooled odds ratio o f 0.622 a nd a 95 % CI of [0.441, 0.8 77]. While the adjusted results with these one-parameter selection functions suggested that the signiﬁcant eﬀect of high maintena nce-dose of clopidogrel might be marginal. Furthermore, the estimates with Preston’s conditional likelihood method were very sensitive to the choice of the selection functions which was similar to observat ions in the simulation study; the integrated odds ratios were estimated as 0.849 (95% CI: [0.319, 2.259]) and 0.696 (95% CI: [0.434, 1.116]) with the one-parameter logistic (3) and its modiﬁed version (4), respectively. In contrast, the IPW estimates with these two selection functions were relatively close; the pooled odds ratio were estimated as 0.666 (95% asymptotic CI: [0.452, 0.9 82]; 95% bootstrap CI: [0.471, 0.95 3]) and 0.648 (95% asymptotic CI: [0.425, 0.987]; 95% bootstrap CI: [0.451, 0.965 ]) , respectively. The estimated selection functions were shown in Figure 3. We observed an al- We ﬁrst illustrated the proposed method using one-parameter logistic selec- Next, we demonstrated the results with the two-parameter selection functions. most ﬂat dotted line with selection function, indicating that it might be failed to identify the selective publication process; while the two-parameter probit (5) selection function gave the estimate of [-1.119, 0.153]) , although we still could not reject the null hypothesis of β in Figure 3 the solid line indicated that the selective publication process might be concerned. Similar with the antidepressant study, we found the bootstrap CI might be more reasonable for the β inference in practice. For the estimation of µ, Copas sensitivity analysis method gave the pooled odds ratio a s 0.691 a nd a 95% CI of [0.468, 1.012] with the marginal selection probability ﬁxed at p = 12/15; while t he proposed IPW method with two-parameter probit (5) gave the estimate of 0.662 with a 95% asymptotic CI of [0.474, 0.923] and a 95% bootstrap CI of [0.468, 0.904]. As we observed in Figure 3, two-parameter logistic (6) selection function did not suggest the selective publication process. Then the resulting estimate was very close to the standard mixed-eﬀects model (see Table 6). function for small meta-analysis, and t hen plotting the selection functions and checking the estimate of the ˆτ ate heterogeneity. Similarly, Huang et al. (2021) also reported that the methods using maximum likelihood estimation with the 12 published studies gave a moderate heterogeneity, while the publication bias adjustment method with all the 15 studies gave a zero estimate. In summary, we must be cautious of the fa ilure in estimating the selection were 0, while the conditional likelihood-ba sed methods gave a moder- In this paper, we successfully introduced the IPW method t o address the publication bias issue in meta-analysis context. Diﬀerently from Matsuoka et al. (2007) and Mathur and VanderWeele (2020), by introducing a simple estimating equation for the selection function, we can avoid massy processes of sensitivity analyses. The simplicity and ﬂexibility of t he IPW estimator allows us to handle various t-type selection functions, and as shown in Section 4, it can result in certain improvement in estimating both overall eﬀect size and heterogeneity than the original conditional likelihood-based methods by Preston et al. (2 004) and Copas ( 2013). On the ot her hand, we focus on one- and two-parameter selection functions in this paper, since the information of unpublished studies from clinical trial registries only enables us to handle small number of parameters. Selection functions with more parameters (Dear and Begg, 1992 ; Hedges, 1992) might be useful to describe more ﬂexible and complicated selective publication processes. It would be worthwhile to develop methods to handle such kind of selection functions. problem. However, there is a notable diﬀerence between the publication bias issue and the general missing data problem. In general missing data problems such as drop-out in clinical trials, the whole study population is clearly understood. In other words, we know how many subjects are missing and some information such as baseline covariates are available for missing subjects. In the publication bia s issue, it is hard to deﬁne a complete study population since we only observed published studies. Due to this reason, well-developed missing data methodologies Publication bias issue has long been recognized as a kind of missing da t a such as the IPW method are hard to be used in this area directly and most of the methods for publication bias rely on funnel-plot symmetry. After long years development of clinical trial registries, prospective registration has been widely accepted by clinical trial researchers, and searching on clinical trial registries plays a more and more import ant role when performing systematic reviews. This allows us to identify those unpublished studies and give us the opportunity to handle the publication bias issue like a general missing data problem. between the publication bias issue a nd the general missing data problem. Our development of the IPW estimator as well as the maximum likelihood estimation by Huang et al. (202 1) was along with this persp ective. These two methods used diﬀerent types of selection functions and t hen complement each other. With these methods, we can address robustness of the results of meta-analysis against diﬀerent selective publication process described by the Heckman-type and the t-type selection functions. Since it was impossible to identif y the t rue selective publication process in reality, a comprehensive sensitivity analysis with multiple selection functions would be useful and is always recommended in practice. In our view, clinical trial registries play an import ant role to ﬁll the gap