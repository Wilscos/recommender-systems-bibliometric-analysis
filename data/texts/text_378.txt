Noname manuscript No. (will be inserted by the editor) Nuo Li · Bin Guo · Yan Liu · Lina Yao · Jiaqi Liu · Zhiwen Yu Abstract Questions in Community Question Answering (CQA) sites are recommended to users, mainly based on users’ interest extracted from questions that users have answered or have asked. However, there is a general phenomenon that users answer fewer questions while pay more attention to follow questions and vote answers. This can impact the performance when recommending questions to users (for obtaining their answers) by using their historical answering behaviors on existing studies. To address the data sparsity issue, we propose AskMe, which aims to leverage the rich, hybrid behavior interactions in CQA to improve the question recommendation performance. On the one hand, we model the rich correlations between the user’s diverse behaviors (e.g., answer, follow, vote) to obtain the individual-level behavior interaction. On the other hand, we model the sophisticated behavioral associations between similar users to obtain the community-level behavior interaction. Finally, we propose the way of element-level fusion to mix these two kinds of interactions together to predict the ranking scores. A dataset collected from Zhihu (1126 users, 219434 questions) is utilized to evaluate the performance of the proposed model, and the experimental results show that our model has gained the best performance compared to baseline methods, especially when the historical answering behaviors data is scarce. Keywords Community question answering · hybrid behaviors interaction · Sparse data · Question recommendation Community Question Answering (CQA) site, such as Quora a kind of Web service where people can search for information (getting the answers from other people) and share knowledge (answering the questions from other people) online. Compared with traditional information retrieval that only return several related web pages, CQA is more like a high-level information retrieval system, which contains abundant questions and answers that meet users’ need. With the increasing demand of knowledge sharing, the number of questions is continuously increasing and the number of unanswered questions is increasing at a faster rate. For example, Stack Overﬂow statistics show that the number of questions has a linear increase while the number of unanswered questions has an exponential increase [1]. As a result, it is necessary to solve the problem of question recommendation to guide users to look through the questions they like, make the questions can be answered eﬀectively, and promote the development of the community in a sustainable and harmonious manner. example, there are eight kinds of user behaviors (creating answer, creating article, creating question, following user, following question, following topic, voting answer, and voting article) on Zhihu platform. And for a certain question, most users follow and vote it while only a few users answer it. We crawl 3996 users of various occupations and educations on the Zhihu platform, and count the number of users’ diﬀerent behaviors. These statistics are shown in Figure 1. Obviously, the numbers of the following question and voting answer behaviors are more than others. And we can also observe that the two behaviors have higher similarity with the target question in Figure 2. Therefore, when users’ data is scarce, these two behaviors can help improve the performance of question recommendation. However, it is obvious that the amount of the answering behavior is the least, with an average of 40 questions per user, while the amount of the following and voting behavior are nearly ﬁve times that of answering behavior, reaching an average of 200 questions per user. However, the existing work on question recommendation, including the Users only browse or ask questions but not answer questions in CQA. For topic models such as PLSA (Probabilistic Latent Semantic Analysis) and LDA (Latent Dirichlet Allocation) [2,3,4,5,6] and deep leaning method [7] rely on abundant and rich content data to characterize the user’s interest better. They are not so eﬀective when the historical answering data is scarce. Fig. 1: Numbers of diﬀerent behaviors with users or answers for recommendation to alleviate the data sparseness problem, which mainly apply heterogeneous network containing social relationship. For example, Tu et al. [8] consider social connections to obtain user representation based on that there are strong social connections between users in CQA. Fang et al. [2] and Li et al. [3] propose the heterogeneous network embedding that can collaboratively utilize the rich interaction among the questions, answers and users. These methods mine the relationships among users, questions and answers from the view of the content of questions and answers for recommendation. If a user’s social relationships exist, other users connected this user can be regarded as a group, whose interest is similar to this user’s interest. However, Such a discrete representation is not enough to show the degree of similarity between users. At the same time, other rich behaviors, such as following and voting behaviors, are rarely considered. problem of utilizing following and voting behaviors to improve the question recommendation performance as illustrated in Figure 3. The ﬁrst challenge is how to model the individual-level interaction, i.e., how to deal with the multiple behaviors with huge diﬀerence in the amount of data and make them interact with each other. Each kind of the user’s behavior, e.g. following, voting or answering, reﬂects the user preference to some extent. At present, some studies [9,10,11] model these diﬀerent behaviors in a same space and obtain the complicated interaction between all behaviors using RNN and other methods to acquire more accurate representation of interest. However, the amounts of user’s following and voting behaviors are far more than that of answering behavior as illustrated in Figure 1. Therefore, if we model the three behaviors in the same space, then the interest represented by following Recently, some methods jointly model the auxiliary information associated Therefore, we need to tackle two main challenges when facing with the and voting behaviors may cover the interest expressed by answering behavior, they cannot promote the possibility of answering, but reduce the probability of answering due to the noise. Consequently, in the case of unbalanced multibehavior data, how to model the sophisticated associations between behaviors is a great challenge. Another challenge is how to model the communitylevel interaction, i.e., how to model the impact of behavioral associations of social users. Some studies have demonstrated that considering social relationships improves recommendation performance when the user’s historical behavior data is scarce [8,12]. Generally, these relationships are represented by adjacent matrices, so that the relationship between two persons is either 0 or 1. Such discrete representation indicates that some information is lost to some extent. Fig. 3: The case that the individual-level interaction and the community-level interaction interaction method, named AskMe, which can fuse the individual-level interaction and community-level interaction for question recommendation in CQA. In particular, in order to deal with the problem of the multiple behaviors with huge diﬀerence in the amount of data and make them interact with each other, we propose the individual-level behavior interaction, which can learn the users’ main interests from the diﬀerent behaviors sequences ﬂexibly. In addition, following the spirit of the CF (Collaborative Filtering, CF), we propose the community-level behavior interaction to tackle the problem of the social relationships’ inﬂuence for question recommendation in CQA. It calculates the group’s interests by means of weighted sum. Meanwhile, we regularize the dif- For the aforementioned two challenges, we propose the hybrid behavior ference between it and the user interest so that the user and the group are more likely to have similar interests. Finally, the individual-level behavior interaction and the community-level behavior interaction are mixed by a concatation and projection operation to predict the click probability simultaneously. – We propose the individual-level interaction method to deal with the prob- – We propose the community-level behavior interaction to handle the prob- – We propose the AskMe model to combine the individual-level behavior – We make experiments on the real-world dataset to evaluate recommenda- The related work is mainly divided into two parts: question recommendation and behavior modeling. With CQA system becoming popular in recent years, more and more people study the appealing and challenging problem of question recommendation. And for question recommendation, the goal is to automatically recommend a new question in CQA to the suitable users. Generally, we utilize PLSA, LDA and other topic modeling methods [2,3,4,5,6] to extract the user’s interest distribution from the historical answers or historical questions, and then calculate the relevance between the user’s interest distribution and the target question. Finally, we recommend top k questions to the user according to the relevance scores. For instance, Ni et al. [5] proposed a generative topic-based user interest (TUI) model, which aims to extract the users’ interests by mining the questions they asked and relevant answer providers in the User-Interactive Question Answering (UIQA) systems. Fu et al. [3] considered intimacy between asker and answerer over a topic and proposed a user intimacy model (UIM), which models the relations among the asker, question and answerer, and then the recommendation is obtained by the user’s interest and the intimacy. Finally, the main contributions can be summarized as follows: lem of multiple behaviors with large diﬀerence in the amount of data, which ﬁrstly splits the sequence of the following and voting behaviors according to the answering time point and then predicts the results through a multiview idea. lem of the discrete social relationship representation. We calculate the similarity between users based on the users’ individual-level interest to describe the continuous relationship representation between users. interaction and the community-level behavior interaction based on user’s multi behaviors interests to alleviate the problem of data sparsity. tion performance and the experimental results show that our model has gained the best performance, especially when the historical answering behaviors data is scarce. widely used to extract the features of images or texts [13]. The word sequence information is also taken into account to learn the semantic representation of the questions in CQA [4,7,8]. Tu et al. [8] employs CNN model to obtain explicit the question textual representation while Zhao et al. [7] and Li et al. [4] utilize LSTM model to get the question features. These methods model the text of the answers or questions, which contains the content and description of the answers or questions. If them are few in CQA, the performance may be poor due to the insuﬃcient extracted interest. multi-source data such as social relationships or memory network to improve the recommendation performance [2,7,8,29,30]. Fang et al. [2] proposed the HSNL (CQA via Heterogeneous Social Network Learning, HSNL) model to combine the textual contents with the social relationships to improve the recommendation results. Tu et al. [8] proposed the JIE-NN (Joint Implicit and Explicit Neural Network, JIE-NN) to combine explicit factors and implicit factors based on multiple data sources to deal with the problem of data heterogeneity and sparsity. And Zhao et al. [7] proposed a ranking metric network framework based on users’ relative quality rank to given questions and their social relations to alleviate the data sparsity problem from the viewpoint of learning metric embedding. Sun et al. [29] designed an end-to-end framework that leverages heterogeneous graph and textual information to address the challenge of cold questions. Liu et al. [30] proposed a statical model MAGIC (multi-aspect Gamma-Poisson matrix completion, MAGIC) to automatically generate answer keywords to solve the problem of new questions. Our approach extracts the user’s immediate interest via user’s multiple behaviors and tackles the problem of data sparsity from two aspects: the individual-level behavior interaction and the community-level behavior interaction. User behavior modeling is a common and challenge problem in the recommendation system. That’s because there are many kinds of user behaviors in the logs, and these behaviors can be applied to analyze the user behavior rules, mine the user preference and predict the user behavior at the moment. Generally, we can divide user modeling into single behavior modeling and multi behavior modeling. Single behavior modeling methods mainly include RNN series (such as DIEN [14], LSTM and context information [15], etc.), CNN [16] and Attention mechanism (such as DIN [17], DSIN [18], etc.). Multi behavior modeling methods include collective matrix factorization (CMF) [19, 20] and modeling into deep semantic spaces together (such as ATRank [11], NMTR [9], CSAN [10], EHCF [31], MBGCN [32], etc.). In this part, we focus on multi-behavior modeling, which mainly aims to solve the problem of behavior heterogeneity and data sparsity. With the popular of the deep neural network, representation learning is Facing such a problem of data sparsity, some researchers proposed to apply CMF) [20] proposed by Singh et al. is the most widely used method, which decomposes the rating matrices for diﬀerent types of behaviors jointly by sharing the same user latent representation across diﬀerent behaviors. Cheng et al [19] extended the CMF model and proposed GLFM (Group Latent Factor Model, GLFM) model to integrate multi-behaviors by modeling both the correlation and heterogeneity of them. With the development of deep learning, representation learning is more and more popular. Some studies [10,11, 31,32] map all behaviors into a uniﬁed low-dimensional space, then the user’s interest can be obtained from the interaction between these behaviors in the low-dimensional space. For example, Zhou et al. [11] proposed an ATRank model based on self-attention mechanism, which maps the heterogeneous behavior sequence into multiple implicit semantic spaces, and selects some important semantics by self-attention to obtain the user’s interest. Huang et al. [10] proposed a CSAN (Contextual Self-Attention Network, CSAN) model, which mapped multi-behaviors into a common latent place, and then the output is fed into speciﬁc network to obtain the user’s interest. Chen et al. [31] proposed a transfer-based prediction model EHCF (Eﬃcient Heterogeneous Collaborative Filtering, EHCF) for multiple behaviors with shared embedding matrices and can model ﬁne-grained user-item relations from a semantic perspective. Jin et al. [32] constructed a uniﬁed graph to model the multi-behavior data, and proposed MBGCN (Multi-Behavior Graph Convolutional Network, MBGCN) model to capture behaviors’ diﬀerent inﬂuence strength and semantics. These methods make each type of behavior important equally, and not take into account the huge diﬀerence in the number of behaviors. sider the diﬀerence in the amount of various behaviors. At the same time, most of them are multi-task learning, that is to obtain users’ embedding representation and then to learn downstream multiple tasks. While our method cares about the users’ professional knowledge rather than general interests and our approach can select important parts from the abundant following and voting behaviors data, can combine with three data imbalance behaviors. We denote U = the set of questions, where |U|, |I| denotes the number of users and questions, respectively. According to the user’s historical behaviors, we can obtain the set of the user’s historical answers at every moment I where |ans answered. For a historical answer i the questions that the user u has followed and voted, which are denoted as For the data sparsity problem, CMF (Collective Matrix Factorization, In conclusion, most methods for multi behaviors recommendation not convoted before answering the question i tion that the user u may answer according to the questions before the user u has answered at the time t, and the user u has followed and voted at the time t + 1. Table 1 lists the frequently used notations and descriptions in this paper. There is a phenomenon that data for the answering behavior is scarce while data for the following and voting behavior is rich. Therefore, we improve the recommended accuracy through all three behaviors based on multi-view model [22,23,24], which is as shown Figure 4 . It mainly concludes two parts: features extraction and click prediction. The section of features extraction is to extract the features of these three behaviors, and the click prediction part is to fuse all these features based on a behavior-level attention mechanism to get the ﬁnal prediction results. Answering Behavior Features Extraction The historical questions that users have answered indicate the users’ historical interests, which users like, excel at and are keen to answer in the past. Therefore, we model the historical answering questions to express users’ answering preference. As far as we know, LSTM [26] can better capture the long-distance dependence, and can eﬀectively model the historical sequences. However, standard LSTM model can’t capture future information. The user’s answers at any time represent the user’s interest, the user’s previous asnwers would have an impact on the current answers,and at the same time, the user’s current answers would also produce an eﬀect on the embedding of the previous answers. Therefore, we apply Bi-LSTM to model the historical questions that users have answered. =i, i, . . . , iand I=i, i, . . . , , i, where Nand denote the number of historical questions that user u has followed and that user u has answered, where |ans answering questions. Through an embedding layer , it can be converted into a low-dimension, dense vectors model is formulated as shown in Eq.(1)-(5): object respectively. W matrices. b state respectively. original forward LSTM network, then we can denote the hidden state of i-th as: h hidden state of i-th of the reverse LSTM. We denote I=i, i, . . . , ias the set of historical questions where i, oand fdenote the input, forget and output gate of the t-th , b, band bare bias vectors. cand hare cell state and hidden We apply Bi-LSTM method, i.e. adding a layer of reverse LSTM to the =h⊕h, where ⊕ denotes the addition of corresponding elements, denotes the hidden state of i-th of the forward LSTM, andhdenotes the The output of the Bi-LSTM is a sequence h=h, h, . . . , h. Following Behavior Features Extraction The historical questions that users have followed indicate the users’ interest. Due to the scarce answering behavior, we extract users’ current preference from the historical following questions to represent the external factors of users’ answering behavior. We apply a followlevel attention mechanism to capture the relationship between these questions that the user u has followed and the target question, and choose the related questions as the user’ following behavior features. tions that the user u has followed, where |fol the historical following questions. Then it is transformed into a dense vectors where V and D are the number of all questions and the question embedding dimension respectively. Considering that not all of them aﬀect the ﬁnal target question, we get important and contextual questions by a follow-level attention method [27] immediately. followed, and q Voting Behavior Features Extraction The historical questions that users have voted are similar to the historical questions that users have followed, they all indicate the users’ current preference. Therefore, voting behavior features extraction method is akin to following behavior features extraction method. We apply a vote-level attention mechanism to capture the relationship between these questions and the target question, and ﬁnally, we get the voting behavior features representation p The users’ behaviors reﬂect the users’ preference, and diverse behaviors may lead to various results. For example, the user may answer the questions with same topics compared to the questions that he has followed or voted a kind of question. Therefore, we apply a behavior-level attention mechanism to obtain the weight of each type of behavior and distinguish the role of various behaviors at diﬀerent times. The representation of the users’ current time can be described as: We denote I=i, i, . . . , ias the set of historical quesei, ei, . . . , eivia an embedding look-up table W∈ R The ﬁnal following features can be denoted as: where βdenotes the importance of each question that the user u has a user will answer a target question based on their representation is formulated as: where W , b and σ denote the weight matrix, biases vector and the sigmoid activation function, respectively. To train the model, we use the cross-entropy loss following the probabilistic optimization framework [28] : where D represent all the samples, and y ∈ {0, 1} is the label representing whether a user have answered a question. The framework is designed to model the user’s three relevant behaviors by the way of the multi-view to capture the association between the candidate item and three behaviors. However, there is no interaction relationship among three behaviors. For example, the following behavior at the moment can help improve the performance of the answering behavior at the next time. Therefore, if we model the interaction at each moment to mine the complicated interaction among three behaviors, the eﬀect of recommendation will be better. Considering the interaction at each moment mentioned above, we introduce the thought of the multi-view into each time to get the prediction of the next time. On the other hand, taking other similar people’ s behaviors into account can improve recommendation performance from the perspective of community. In this part, we learn the individual-level behavior interaction and the community-level behavior interaction jointly to tackle the problem of data sparsity. The framework is shown as Figure 5. It mainly concludes two parts: The Individual-level Behavior Interaction and The Community-level Behavior Interaction. For each moment, given the hidden state h representation vectors p followed and voted at the time t + 1, we aggregate them with multi-view model, and then feed it into Bi-LSTM to get the prediction at the time t + 1. Speciﬁcally, the representation vector p Where β followed before the time t + 1, ei question at the time t + 1, and the user u has followed before the time t + 1. as the representation vector p the hidden state h and the voting vector p level attention method, and feed it into Bi-LSTM to get the prediction at the Similarity, the representation vector pis calculated in the same way next moment. Finally, we take the last state h2 as the representation of the user’s interest. And then the ﬁnal result can be formalized as: Considering the inﬂuence of the behaviors of other similar people, we ﬁrstly calculate the similarity between the target user and other all users in a dotproduct way, which is a widely used method calculating the similarity in a space. If the personal can be formalized as: sentation of similar users’ group by the way of weighted sum. The process of community-level interaction can be formalized as: We combine the two components for deeper and more complicated interaction between the individual-level interaction and the community-level interaction, and make predictions in a dot-product way: We still use the cross-entropy loss to train the model. Simultaneously, we regularize the diﬀerence between the user representation and the similar user group to make the user and the similar user group have the similar interests. It can be formalized as: L = − personal= ReLUWh2; h; p; p+ b(14) Based on that, we select the most similar N users and achieve the repre- 1X[ylogˆy + [1 − y] log [1 − ˆy]] + λ kpersonal− groupk(18) We experimented with a real-world dataset including various kinds of user behaviors collected from Zhihu, which is the largest CQA website in China. The statistics of the dataset are summarized in Table 2. People of diﬀerent occupations have diﬀerent behavioral preferences and diverse interests. Therefore, we also crawled the users of four types occupations on Zhihu website to make our algorithm more convincing and valuable. The data of Computer dataset is the largest, both for numbers of users and questions. Although the data volume of the other three datasets is similar, their sparsity is diﬀerent (sparsity refers to the number of users multiplied by the number of questions, and then divided by the number of their interactions). In particular, the sparsity of Art dataset is the largest. The statistics of four datasets are listed in Table 3. In order to evaluate the recommendation performance, we applied two popular metrics, HR (Hit Ratio) and NDCG (Normalized Discounted Cumulative Gain) [28]. HR visually indicates whether the question i that user u in the test set would answer in the next time in the recommendation list for the user u. Where hits@k represents the number of the same questions in the test set and the recommended Top-K, and N denotes the number of the questions in the test set. Where j denotes the position we hope for the goal question in the recommended list and r (j) denotes the relevance for the position j in the recommended list. In this part, if the recommended question at the position j is in the test set, r (j) = 1, otherwise r (j) = 0. Z to make the result be in the range of 0-1. used leave-one-out technique [28], that is, the ﬁnal answering question is as the test set, and the others as the train set. In order to evaluate the recommendation performance of our methods, we compare it with the following baselines: – HSNL [2]: It encodes not only the contents of question-answer but also – JIE-NN [8]: We combine the explicit and implicit information to model – NeRank [7]: We apply the deepwalk and word2vec method to learn the – CNN [16]: We model the users’ historical answering behavior by CNN, and NDCG shows the ranking quality of the recommendation list. In order to verify the recommendation performance, we adopted the widely the social interaction cues in the community to boost the CQA tasks. Here, we refer to its deepwalk method on user-question interactions to get the latent vectors of the users and questions. Then we employ LSTM to model the relationships among historical behaviors to get the user’s preference. user-question interactions. Speciﬁcally, we employ CNN from the historical behaviors of a user to get the explicit representation, and get latent user groups representation as the user’s implicit representation, then we combine them to get the ﬁnal results. representation for the user and question in an interaction view and the embedding of question content from the view of content sequence respectively. There three types embedding as input to fed into convolutional scoring function to get the ﬁnal results. obtain the user historical answering behavior embedding via avg pooling method. We set window sizes from one to ﬁve to extract diﬀerent features and all feature maps to have the same kernel size with 32. – DIN [17]: We use the attention mechanism to obtain users’ diﬀerent inter– DIEN [14]: We use the GRU method and the attention mechanism to – ATRank [11]: We use self-attention mechanism to model user answering – CNN M, DIN M, DIEN M, ATRank M: The above four advanced our methods – AskMe M: The ﬁrst model we proposed in section 3.2, which computes – AskMe B: The model increases the interactions between all behaviors at – AskMe: The second model we proposed in section 3.3, which adds the – AskMe A: It denotes that the model contains the historical answered data – AskMe P: It only includes the interactions from other similar people, – AskMe MP: It contains two parts: AskMe M and AskMe P. 4.1.4 Parameter Settings We implement our and baseline methods in TensorFlow 1.4 and Python 3.6. The experimental parameters are set as follows: – Initialize approaches. We utilize Gaussian distribution (mean value is 0 – Network embedding size. The network embedding size is set to 128. – Optimizer. We utilize the Adam, the highly eﬀective optimizer, as the – Batch size. The batch size is set to 100. – Learning rate. We set the initial learning rate to 0.001, which then decays ests. model the evolution of users’ interest and extract users’ preference. behavior sequence to get the user embedding. approaches only model the historical answering behavior. Taking following and voting behaviors into account based on that, we can obtain models CNNM, DIN M, DIEN M and ATRank M respectively. Speciﬁcally, we sort the three kind of behavioral data according to the time order, and then input the data into CNN, DIN, DIEN and ATRank as a sequence. the interaction among following behaviors, voting behaviors at the last moment and all historical answering behaviors in a multi-view way. each moment compared to the AskMe M model, so it’s clearly that the individual -level interaction is eﬀective. interactions from similar people compared to the AskMe B model. only, so that we can show the diﬀerences between our proposed method and the CNN, DIN, DIEN or ATRank method. so we could easily demonstrate that our proposed the community-level interaction is powerful. and standard deviation is 0.1) to initialize the parameters for all models optimizer. with the decay rate of 0.5 at every epoch. – Question embedding size. For each question, we ﬁrst split the sentence – The length of following and voting behavior. We set the length of – The number of the similar persons. We carry out experiments for this Table 4: Evaluation of Top-K question recommendation performance compared to the methods. The results are shown in Table 4 and Table 5. It is easy to obverse our ﬁnal approach AskMe achieves the best performance both under HR and NDCG. At the same time, from the whole point of view, our three methods are superior to the CQA methods, single-behavior methods and the multi-behavior methods. That is because that our methods simultaneously model the interaction of user’s own behaviors and that of other similar users. For CQA methods, HSNL constructs the graph model from the perspective of user-item interaction, and then achieves the initial vectors of users and items in the way of random walk. It’s obvious that the more recommended items, the better the recommendation performance. Although the metric for HR is low, into word sets by Jieba tool, and then calculate the word embedding vector of each word (100 dimensions) by word2vec method. And then we utilize the mean value of word sets in a sentence as the vector representation of this question. In order to make the vector more appropriate, we retrain 28 dimensional vectors, which can be spliced with 100 dimensional vectors into 128 dimensional vectors, as the ﬁnal representation vector of the question. following and voting behavior to 5 to save the calculated time and space. number which is set to a range of [3,5,10,20,all] and the performance is the best when the number is 5, so we set it to 5. We ﬁrst analyze the top-K performance in our models and all baseline the metric for NDCG is high, which shows that the quality of sorting is good, and the model can capture the relative scores of users to the items. As for JIE-NN model, which integrates explicit and implicit information, is better than single-behavior recommendation on HR metric, but worse than multibehavior and our methods recommendation. There are two possible reasons for the conﬂict. First, the two metrics cover diﬀerent aspects: HR estimates the accuracy of prediction, and NDCG calculates the diﬀerence between two ranked lists (of a list of candidate items) and emphasizes the location of the items found. Therefore, the changing of them may not coincide under diﬀerent experiment settings. Second, the candidate items may be similar, so even though the HR value is large, the predicated ranking order of items can be signiﬁcant diﬀerence. This may also lead to conﬂicts between HR and NDCG results. Meanwhile, it also demonstrates that other behaviors at every moment can eﬀectively improve the recommended accuracy. And for NeRank, an approach based on pairwise loss, its performance on HR is worse than other methods based on pointwise loss, but its performance on NDCG is better. This is also due to the diﬀerence between the pointwise loss and pairwise loss. Table 5: Evaluation of Top-K question recommendation performance compared to the formance and CNN obtains the worst performance among the four singlebehavior methods. The main reason may be that DIEN models the user’s dynamic interest and extracts the main and proper interest while CNN captures speciﬁc sequence patterns, but whether the historical answering behavior contains speciﬁc patterns is not sure due to the variability of users’ interests. similar to that of single-behavior methods. However, compared with the performance of single-behavior methods and multi-behavior methods, the result of CNN M is worse throughout than CNN. It is because that CNN can’t well mine the main information from the rich and extensive following and voting For single-behavior methods, we observe that DIEN achieves the best per- As for multi-behavior methods, we can see that the trend of results is behaviors, but the attention mechanism can. Therefore, we can ﬁnd DIN M is superior than DIN both on HR and NDCG. Table 6: Evaluation of Top-10 question recommendation performance compared to the Table 7: Evaluation of Top-10 question recommendation performance compared to the model more convincing, we conducted additional experiments on four types of datasets, and the ﬁnal results are shown in Table 6 and Table 7 (average and variance after ﬁve times). It’s clear that the performance of Computer dataset is the best, followed by Education dataset, and that of Art dataset is the worst. The reason may be that the Computer dataset is the largest, and the sparsity of Art dataset is smallest among the Art dataset, Education dataset Furthermore, in order to verify the eﬀectiveness of the model and make the and Finance dataset. At the same time, For the dataset with less and sparse data such as Art dataset, AskMe model can get better results, and for the dataset with large amount of data such as Computer dataset, the performance of AskMe model improves more than other models, which indicates that our algorithm has better robustness. multi-behavior approaches or our methods, the results of these four types datasets are consistent with the previous results, and our proposed algorithm performance is always the best. and the deviation of our model is least, indicating that our algorithm is most stable. Therefore, our algorithm is more convincing and eﬀective. Compared with some advanced approaches, we can prove that our model is effective in the part Model Performance Comparison. While in this part, we analyze the components of the model to show the eﬀectiveness of our method. The ﬁnal result is shown as Figure 6. It’s clear that the model with interactions of user’s own behaviors and other similar people’s behaviors has obtained the best performance. Furthermore, we have the following three ﬁndings: Fig. 6: Evaluation of Top-K question recommendation performance compared to each model – Observing the results on HR and NDCG for models AskMe B, AskMe M – Comparing the performance of model AskMe B and AskMe M, model On the whole, whether for CQA approaches, single-behavior approaches, and AskMe A, we can discover that the performance of models AskMe B, AskMe M both are better than AskMe A, which proves the eﬀectiveness of increasing the user’s multiple behaviors. AskMe and AskMe MP, we can inform that the performance of model AskMe B is better than model AskMe M on HR, while slightly lower than model AskMe M on NDCG, which demonstrates that other behaviors at every moment can eﬀectively improve the recommend accuracy from the perspective of user’s own behaviors. That may be due to the rich and wide – For the interaction component of similar users’ behaviors, we can conclude The above experimental comparisons are all under the condition that the length of the historical answering behaviors is 5, due to the common phenomenon of scarce answering data in Zhihu website. In this part, we analyze the recommendation performance changes with the length of the historical answering behaviors and the results are showed as Figure 7. It is obvious that our model AskMe always gets the optimal performance no matter what the answering length is. Especially, when the length is less than 5, the performance of this model is far greater than other two methods. At the same time, we can see that the performance of this model is not signiﬁcantly improved compared with the other two methods when the length is larger than 5. Therefore, there is a conclusion that our model AskMe is very suitable for users with scarce answering data, and the model can obtain good performance when there are 5 historical answering behaviors. Fig. 7: Evaluation of Top-K question recommendation performance in diﬀerent lengths In order to understand how the various behaviors in the AskMe model interact with each other, we ﬁrst analyze the mean of attention distribution at each following and voting questions. At the same time, we can observe that the performance of model AskMe is better than model AskMe MP from alpha to omega, which shows that it’s necessary to increase the component of user’s behavior at each moment. that the results of model AskMe AP, AskMe and AskMe MP are always better than model AskMe A, AskMe B and AskMe M from the Figure 6, respectively. Obviously, it’s necessary and very important to increase the interaction component of similar users’ behaviors. Fig. 8: The attention scores at each moment moment, as shown in Figure 8. From the results, we can observe that the distribution at each moment is extremely similar. And it can be seen that the biggest contribution for the answering behavior at the next moment is the following behaviors no matter what moment. The main reason is probably that the question that the user has followed is what the user likes, then the user is more likely to answer. Therefore, the following behaviors and the voting behaviors at the previous moments will help recommend the questions that the user would answer at the next moment. As the attention distribution is similar at each moment, we analyze the overall attention distribution, that is, the mean of the attention distribution at all moments, and we can get the result as Figure 9. From this ﬁgure, we can see that most of the attention scores of the user’s answering behaviors are mostly in the range of 0-0.2, which indicates that most of the answering behaviors at the previous time do not work for the answering at the next time. While for the attention scores ranged in 0.9-1, it is clear that the number of the following behaviors is largest, which indicates that the users’ following behaviors at previous moments have promoted the answering behavior at the next moment. In summary, we can see that the distribution of attention scores for diﬀerent kinds of behaviors and know that users have various attention scores for diverse behaviors in diﬀerent situations. All of these just verify the eﬀectiveness of our model. The overall attention scores’ distribution of diﬀerent behaviors is summarized above, and in this section, we randomly select one sample to get the attention score of each behavior at each time, as shown in Figure 10. It’s easy to see that the attention score of every behavior at each moment is diﬀerent. In conclusion, our model can select the more important behaviors at each moment to predict the question to be answered at the next moment, and the learned attention scores are consistent with the original data. At the same time, to further illustrate the eﬀectiveness of our method, Table 8 shows an example of top 3 questions recommended by our methods AskMe, AskMe B and another model JIE-NN with best performance in CQA approaches. Fig. 10: The original data and the learned attention scores for the ﬁrst sample selected In this work, we propose the AskMe method to solve the problem of scarce answering behavior for the question recommendation in CQA. It can select the important behaviors from rich following behaviors and voting behaviors, and learn the complicated interaction in two aspects: the individual-level behavior interaction and the community-level behavior interaction to predict the question to be answered at the next moment. The extensive experiments are conducted on Zhihu dataset and demonstrate that the complex individual-level and community-level interaction are eﬀective, and the result of the AskMe method is superior to other state-of-the-art approaches on both HR and NDCG, especially in the situation of the scarce historical answering behaviors data. As for the future work, we will study the multi-behavior recommendation based on multi-behavior data [9]. As learning the main behavior from multiple behaviors improves the recommend accuracy but wastes some resources, such as the time. On the other hand, the time factor is extremely important [21]. For instance, the following behaviors in the ﬁrst minute may reﬂect users’ current interests more than that in the ﬁrst three days, and it is more helpful to predict the question to be answered for users. Therefore, we will add time factor to the model to improve the recommendation accuracy.