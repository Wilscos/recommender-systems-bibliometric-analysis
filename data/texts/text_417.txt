In this paper, we present a pre-trained language model (PLM) based framework called RID for conversational recommender system (CRS). RID ﬁnetunes the large-scale PLMs such as DialoGPT, together with a pretrained Relational Graph Convolutional Network (RGCN) to encode the node representations of an item-oriented knowledge graph. The former aims to generate ﬂuent and diverse dialogue responses based on the strong language generation ability of PLMs, while the latter is to facilitate the item recommendation by learning better node embeddings on the structural knowledge base. To unify two modules of dialogue generation and item recommendation into a PLMs-based framework, we expand the generation vocabulary of PLMs to include an extra item vocabulary, and introduces a vocabulary pointer to control when to recommend target items in the generation process. Extensive experiments on the benchmark dataset REDIAL show RID signiﬁcantly outperforms the state-of-the-art methods on both evaluations of dialogue and recommendation. Building an intelligent agent that can freely chat with humans and provide accurate recommendations through interactive conversations, has been one of the longest standing goals in natural language processing (NLP) and artiﬁcial intelligence (AI). Thanks to the progress in deep learning, the research on the dialogue system has been greatly advanced over the past few years. Various end-to-end neural approaches have been proposed to address the open-domain dialogue system (Vinyals and Le, 2015; Shang et al., 2015; Sordoni et al., 2015; Serban et al., 2016; Xing et al., 2017) and task-oriented ones (Bordes et al., 2017; Zhao et al., 2017; Lei et al., 2018; Peng et al., 2020). The recent breakthrough in pre-training techniques (Devlin et al., 2019; Liu et al., 2019; Radford et al., 2019; Brown et al., 2020; Dong et al., 2019) sheds a light on the future direction of dialogue system. Large-scale generative pre-training dialogue models such as DialoGPT (Zhang et al., 2020a), Meena (Adiwardana et al., 2020), BlenderBot (Roller et al., 2021) and PLATO-XL (Bao et al., 2021b), also exhibit the compelling performance. In recent years, there are fast-growing research interests to address Conversational Recommender System (CRS) (Li et al., 2018; Sun and Zhang, 2018; Zhou et al., 2020a), due to the booming of intelligent agents in e-commerce platforms. It aims to recommend target items to users through interactive conversations. Traditional recommender systems perform personalized recommendations based on user’s previous implicit feedback like clicking or purchasing histories, while CRS can proactively ask clariﬁcation questions and extract user preferences from conversation history to conduct precise recommendations. Existing generative methods (Chen et al., 2019; Zhou et al., 2020a; Ma et al., 2020; Liang et al., 2021) are generally composed of two modules, i.e., a recommender module to predict precise items and a dialogue module to generate free-form natural responses containing the recommended items. Such methods usually utilize Copy Mechanism (Gu et al., 2016) or Pointer Network (Gulcehre et al., 2016) to inject the recommended items into the generated replies. On the one hand, these strategies cannot always incorporate the recommended items into the generated responses precisely and appropriately. On the other hand, most of the existing CRS datasets (Li et al., 2018; Zhou et al., 2020b; Liu et al., 2020, 2021) are relatively small (∼10K dialogues) due to the expensive crowd-sourcing labor. The end-to-end neural models trained on these datasets from scratch are prone to be overﬁtting and have the undesirable quality on the generated replies in practice. Encouraged by the compelling performance of pre-training techniques, we present a pre-trained language models (PLMs) based framework called RIDto address these challenges.RIDintegrates the itemRecommendationInto theDialogue generation under the pretrain-ﬁnetune schema. Specifically, RID ﬁnetunes the powerful PLMs like DialoGPT (Zhang et al., 2020b) together with a pretrained Relational Graph Convolutional Network (RGCN) to encode the node representation of an item-oriented knowledge graph. The former aims to generate ﬂuent and diverse dialogue responses based on the strong language generation ability of PLMs, while the latter is to facilitate the item recommendation by learning better structural node representations. To bridge the gap between response generation and item recommendation, we expand the generation vocabulary of PLMs to include an extra item vocabulary. Then a vocabulary pointer is introduced to control when to predict a target item from the item vocabulary or an ordinary word from generation vocabulary in the generation process. The introduced item vocabulary and vocabulary pointer effectively unify the two individual modules into one PLM-based framework. To better investigate end-to-end CRS system, we argue to evaluate the performance of recommendation by checking whether the ﬁnal responses contain the target items. Existing works separately evaluate the performance of the two modules, i.e., dialogue generation and item recommendation. However, copy mechanism or pointer network cannot always inject the recommended items into generated replies precisely and appropriately. The performance of the ﬁnal recommendations is actually lower than that of the recommender module. For instance, the Recall@1 of recommender module in KGSF (Zhou et al., 2020a) is 3.9% while the actual performance is only 0.9% when evaluating the ﬁnal integrated responses. We conduct extensive experiments on the benchmark REDIAL (Li et al., 2018). Our RID achieves a remarkable improvement on the recommendation over the state-of-the-art, and the generated responses are also signiﬁcantly better on automatic metrics as well as human evaluation. Further ablation studies and quantitative and qualitative analyses demonstrate the superior performance of our approach. The contributions of this work can be summarized as follows: RID for conversational recommendation. RID ﬁnetunes the large-scale PLMs together with a pre-trained Relational Graph Convolutional Network (RGCN) to address the low-resource challenge in current CRS. •By introducing an extra item vocabulary with a vocabulary pointer to control when to recommend, RID effectively uniﬁes two components of item recommendation and response generation into a PLM-based framework. •Extensive experiments show RID signiﬁcantly outperforms the state-of-the-art methods on both evaluations of dialogue generation and recommendation. Recently, extensive efforts from both academia and industry have been devoted to exploring conversational recommender systems (CRS) based on different hypotheses and application scenarios. Existing works in the literature can be mainly divided into two groups, namely attribute-based CRS and openended CRS. In the rest of this section, we will brieﬂy review these works. Attribute-based CRS.The attribute-based CRS can be viewed as a question-driven task-oriented dialogue system (Zhang et al., 2018; Sun and Zhang, 2018). This kind of systems proactively ask clariﬁcation questions about the item attributes to infer user preferences, and thus search for the optimal candidates to recommend. There are various asking strategies studied by existing works, such as entropy-ranking based approach (Wu et al., 2018), generalized binary search based approaches (Zou and Kanoulas, 2019; Zou et al., 2020), reinforcement learning based approaches (Hu et al., 2018; Chen et al., 2018; Lei et al., 2020a; Deng et al., 2021), adversarial learning based approach (Ren et al., 2020b) and graph based approaches (Xu et al., 2020; Lei et al., 2020b; Ren et al., 2021; Xu et al., 2021). Another line of research on this direction address the trade-off issue between exploration (i.e., asking questions) and exploitation (i.e., making recommendations) to achieve both the engaging conversations and successful recommendations, especially for the cold-start users. Some of them leverage bandit online recommendation methods to address cold-start scenarios (Li et al., 2010, 2016b; Christakopoulou et al., 2016; Li et al., 2020), while others focus on the asking strategy with fewer turns (Lei et al., 2020a,b; Shi et al., 2019; Sun and Zhang, 2018). Open-ended CRS.Existing works (Li et al., 2018; Lei et al., 2018; Jiang et al., 2019; Ren et al., 2020a; Hayati et al., 2020; Ma et al., 2020; Liu et al., 2020; Liang et al., 2021) on this direction explore CRS through more free-form conversations, including proactively ask clariﬁcation questions, chat with users, provide the recommendation, etc. Multiple datasets have been released to help push forward the research in this area, such as REDIAL (Li et al., 2018), TG-REDIAL (Chinese) (Zhou et al., 2020b), INSPIRED (Hayati et al., 2020) and DuRecDial (Liu et al., 2020, 2021). Li et al. (2018) make the ﬁrst attempt on this direction and contribute the benchmark dataset REDIAL by the paired crowd-workers (i.e., Seeker and Recommender). Follow-up studies (Chen et al., 2019; Zhou et al., 2020a,b) leverage the multiple external knowledge to enhance the performance of open-ended CRS. CR-Walker (Ma et al., 2020) is proposed to perform the tree-structured reasoning on the knowledge graph to introduce relevant items, while MGCG (Liu et al., 2020) addresses the transition policy from a non-recommendation dialogue to a recommendation-oriented one. Recently, Liang et al. (2021) propose NTRD to decouple the dialogue generation from the item recommendation, which combines the advantage of classic slot ﬁlling approaches and modern neural NLG approaches. Besides, Zhou et al. (2021) develop an open-source toolkit CRSLab to further facilitate the research on this direction. Most of these works utilize pointer network (Gulcehre et al., 2016) or copy mechanism (Gu et al., 2016; Sha et al., 2018) to inject the recommended items into generated replies. Our work lies in the research of open-ended CRS. While different from the previous work, we present a PLM-based framework for CRS, which ﬁnetunes the large-scale PLMs together with a pretrained Relational Graph Convolutional Network (RGCN) to encode the node representations of an item-oriented knowledge graph. In this section, we present our proposed RID model. Figure 1 shows the model overview. We ﬁrst formalize the conversational recommendation task, then elaborate the response generation model architecture and vocabulary pointer. After that, we introduce how to ﬁnetune the generation model with a Relational Graph Convolution Network (RGCN) pre-trained on an item-oriented knowledge graph and top-k item recommendation in beam search. Finally, we describe the model training objectives. The dialogue context is denoted as a sequence of utterances{t, t, ..., t}, wheremrepresents the length of context i.e., the number of utterances. Each utterance is either given by the seeker (user) or recommender (the model), which contains the token sequence{w, w, ..., w}(1 ≤ i ≤ m), wherewis thej-th token in thei-th utterance andnis the number of tokens ini-th utterance. Note that we deﬁne the name of an item as a single token and do not tokenize it. The output tokens sequence by the model is denoted as {w, w, ..., w}, wherekis the number ofP generated tokens andn =nis the total number of tokens in context. When the model conducts the recommendation, it will generate an item token wtogether with the corresponding context. In this way, recommendation item and response are generated concurrently. In this subsection, we introduce how to extend PLMs to handle conversational recommendation task and produce items recommendation during the dialogue generation. PLM-based Response Generation.Given the input (i.e., the conversation history context {t, t, ..., t}), we concatenate the history utterances into the contextC = {w, w, ..., w}where nis the total number of tokens in the context. Then the probability of the generated response R = {w, w, ..., w} is formulated as: wherePLM(·|·)denotes the PLMs of Transformer (Vaswani et al., 2017) architecture. For a multi-turn conversation, we can constructNsuch context-response pairs, whereNis the number of utterances by the recommender. Then we ﬁnetune the PLMs on all possible(C, R)pairs constructed from the dialogue corpus. By this means, not only does our model inherit the strong language generation ability of the PLMs, but also simultaneously can learn how to generate the recommendation utterances on the relatively small CRS dataset. PLM-based Item Generation.To integrate the item recommendation into the generation process of PLMs, we propose to expand the generation vocabulary of PLMs to include an extra item vocabulary, and devise a vocabulary pointer to control when to generate token from the ordinary vocabulary or item vocabulary. Concretely, we denote each item as a single token and add all items into the item vocabulary. Hence, our model can learn the relationship between context words and candidate items. Such a process integrates the response generation and item recommendation into a uniﬁed model that can perform the end-to-end recommendation through dialogue generation. Vocabulary Pointer.We ﬁrst preprocess the dialogue corpus and introduce two special tokens [RecS]and[RecE]to indicate the start and end positions of the item in utterance. Then we divide the whole vocabularyVintoVandV, where Vincludes the general tokens (i.e., tokens in the original vocabulary of PLM) and[RecS]while Vcontains the all item tokens and[RecE]. After that, we introduce a binary Vocabulary Pointer Ito guide the generation fromVorV. The model generates tokens inVwhenI= 0, and generates the tokens inVwhenI= 1, which can be formulated as follows: where˜h = hWis the feature vector before the softmax layer in Figure 1,˜hmeans the feature value of thei-th token.Iis initialized as0at the beginning of the generation and won’t change until the model produces[RecS]or[RecE]. It changes to1if the model produces[RecS](i.e., the model begins to generate items) and changes back to0if[RecE]is emitted. Such a procedure continues until the current turn is ﬁnished. With the devised Vocabulary Pointer, our model can alternatively switch between generating response words and recommending items based on its previous outputs in a uniﬁed fashion. Due to the difﬁculty of fully understanding user preferences by the conversation context, it is necessary to introduce the external knowledge to encode the user preferences when ﬁnetuning response generation model. Inspired by the previous work (Chen et al., 2019; Zhou et al., 2020a), we also employ a knowledge graph from DBpedia (Lehmann et al., 2015) and perform entity linking (Daiber et al., 2013) to the items in the dataset, which helps better model the user preferences. A triple in DBpedia is denoted by< e, r, e>, wheree, e∈ Eare items or entities from the entity setEandris entity relation from the relation set R. Relational Graph Propagation.We utilize RGCN (Schlichtkrull et al., 2018) to encode structural and relational information in the knowledge graph to entity hidden representations. Formally, the representation of nodeeat(l + 1)-th layer is calculated as follows: whereh∈ Ris the node representation ofe at thel-th layer, andEdenotes the set of neighboring nodes foreunder the relationr.Wis a learnable relation-speciﬁc transformation matrix for the embedding from neighboring nodes with relationr, whileWis another learnable matrix for transforming the representations of nodes at the l-th layer and Zis the partition function. At the last layerL, structural and relational information is encoded into the entity representation hfor eache ∈ E. The resulting knowledgeenhanced hidden representation matrix for entities inEis denoted asH∈ R. We omit the (L) in the following paragraphs for simplicity. Entity Attention.Given a conversation context, we ﬁrst collect the entities appeared in the context, and then we represent the user preference asT= e, e, ..., e, wheree∈ E. After looking up the knowledge-enhanced representation table of entities in Tfrom H, we get: whereh∈ Ris the hidden vector of entitye. Then the self-attention mechanism (Lin et al., 2017) is applied toH, which outputs a distributionα over |T| vectors: whereW∈ Randw∈ Rare learnable parameters. Then we get the ﬁnal representation for user history u as follows: Knowledge-Aware Bias.To incorporate the knowledge from the constructed knowledge graph into our model while generating recommendation items, we ﬁrst map the derived user representation tinto the item vocabulary space|V|as follows: whereM∈ Rare learnable parameters. Then we addbto the projection outputs before softmax operation in the generation as a bias. In this way, our model can produce items in aware of their relational knowledge and thus enhance the performance of recommendation. 3.4 Recommendation in Beam Search To enable the top-k item recommendation in the generation process, we implement it in the beam search decoding. Speciﬁcally, each time after the generation is ﬁnished, we check whether the best response in the beam contains the target items. If yes, then we choose the top-k items between[RecS] and[RecE]according to the probability scores at current time-step to calculate Recall@k. 3.5 Learning Objectives There are learning objectives, i.e., node representation learning on knowledge graph and the ﬁnetuning of response generation model. For the former, we optimize the R-GCN and the self-attention network based on the cross entropy of item prediction, which is deﬁned as follows: where the itemiis the ground-truth item anduis the corresponding user history, whileDcontains all training instances and tH∈ R. For the latter, we optimize another cross entropy loss for all generated responses, denoted asR. The following formula summarizes the process: wherep(w)refers to Eq. 2 andDcontains all (C, R) pairs constructed from the dataset. Datasets.We evaluate our model on the benchmark dataset REDIAL (Li et al., 2018), which collects the human conversations on movie recommendation on Amazon Mechanical Turk (AMT) platform with pair crowd-workers (i.e., Seeker and Recommender). The statistics of REDIAL dataset is shown in Table 1. As we can see, the users speak brieﬂy (as the average token length of utterances is 6.8), and most conversations last for a long round (as the average turn number is 18.2). There are 6924 movies in total, and they are mentioned 7.5 times on average. More detailed statistics of movie mentions are shown in Figure 2(a). Most of the movies occur less than 5 times in the dataset, which indicates an obvious data imbalance problem in the REDIAL. We also show the relationship between the average number of movie mentions and the number of dialog turns in Figure 2(b). As we can see, there are only less than 2 movie mentions when the number of dialogue turns is less than 5. Cold-start problem will be discussed in Section 5.5. Finally, we following (Li et al., 2018) to split the dataset into 80-10-10, for training, validation and test (i.e., original division). Parameter Setting.We ﬁnetune the small size pre-trained DialoGPT model, which consists of 12 transformer layers. The dimension of embeddings is 768. It is trained on 147M multi-turn dialogues from Reddit discussion threads. For the knowledge graph (KG), both the entity embedding size and the hidden representation size are set to 128, and we set the layer number for R-GCN to 1. For BART baseline, we ﬁnetune the base modelwith 6 layers in each of the encoder and decoder, and a hidden Table 1: Statistics of ReDial dataset. “#" means number and “avg" refers to average. Figure 2: For Figure 2(a), X-axis: the movie mentions range; Y-axis: movie numbers. For Figure 2(b), X-axis: turn positions; Y-axis: average movie mentions. size of 1024. For GPT-2 baseline, we ﬁnetune the small model. For all model’s training, we adopt Adam optimizer and the learning rate is chosen from {1e − 5,1e − 4}. The batch size is chosen from {32, 64}, the gradient accumulation step is set to 8, the warm up step is chose from {500, 800, 1000}. All the hyper-parameters are determined by grid-search. Baselines and Comparisons.We ﬁrst introduce two baselines for recommender and dialogue modules, respectively. (1)Popularity. It ranks the movie items according to their historical frequency in the training set without a dialogue module. (2) Transformer(Vaswani et al., 2017). It utilizes a transformer-based encoder-decoder to generate responses without recommender module. We then compare the following baseline models in the experiment: (3)ReDial(Li et al., 2018). It consists of a dialogue generation module based on HRED (Serban et al., 2017), a recommender module based on auto-encoder (He et al., 2017), and a sentiment analysis module. (4)KBRD(Chen et al., 2019). It utilizes a knowledge graph from DBpedia to model the relational knowledge of contextual items or entities, and the dialogue generation module is based on the transformer architecture. (5) KGSF(Zhou et al., 2020a). It incorporates and fuses both word-level and entity-level knowledge graphs to learn better semantic representations for user preferences. (6)GPT-2. We directly ﬁnetune GPT-2 and expand its vocabulary to include the item vocabulary. (7)BART. We directly ﬁnetune BART and expand its vocabulary to include the same item vocabulary. (8)DialoGPT. We directly ﬁnetune DialoGPT and expand its vocabulary to include same item vocabulary. For our RID, in addition to the full model (9)RID, we also evaluate two variants: (10) RID w/o VP, where we remove the vocabulary pointer; and (11)RID w/o KG, where the knowledge graph part is removed. Evaluation Metrics.As we discussed above, the previous works evaluate the recommender and dialogue modules separately. Following the previous setting (Chen et al., 2019; Zhou et al., 2020a), we evaluate the recommender module by Recall@k (k = 1, 10, 50). Besides, we also evaluate Recall@k in an end-to-end manner, i.e., to check whether the ﬁnal produced response contains the target item. For the dialogue module, automatic metrics include: (1)Fluency: perplexity (PPL) measures the conﬁdence of the generated responses. (2) Relevance: BLEU-2/4 (Papineni et al., 2002) and Rouge-L (Lin, 2004). (3)Diversity: Distinct-n (Dist-n) (Li et al., 2016a) are deﬁned as the number of distinct n-grams divided by the total amount of words. Speciﬁcally, we use Dist-2/3/4 at the sentence level to evaluate the diversity of generated responses. Besides, we also employ Item Ratio introduced in KGSF (Zhou et al., 2020a) to measure the ratio of items in the generated responses. In this section, we ﬁrst report the comparison results on recommendation and response generation, respectively. Then we discuss the human evaluation results. After that, we show an example to illustrate how our model works, followed by further qualitative analysis. The main experimental results for our RID and baseline models on recommendation side are presented in Table 2. And we can draw several observations from the results. There is a signiﬁcant gap between the performance of the recommender module and the performance of the ﬁnal integrated system. KGSF, the state-of-the-art model, achieves 3.9% Recall@1 in the recommender module evaluation but yields only 0.9% in the evaluation of the ﬁnal produced Table 2: Main comparison results on recommendation. R@k refers to Recall@k (k=1, 10 and 50). Table 3: Comparison results on ablation study. responses. This indicates that the integration strategies utilized by previous methods have signiﬁcant harm on the recommendation performance. Finetuning PLMs on the small CRS dataset is effective. As we can see, compared to nonPLM based methods, directly ﬁnetuning GPT2/BART/DialoGPT on the REDIAL achieves the obvious performance gain on recommendation. Our RID model signiﬁcantly outperforms the SOTAs on recommendation performance. As shown in Table 2, our RID achieves the best Recall@k (k = 1, 10, 50) scores under the end-to-end evaluation, which demonstrates the superior performance of the PLMs with the uniﬁed design. Since CRS aims to recommend items during natural conversations, we conduct both the automatic and human evaluations to investigate the quality of generated responses by RID and baselines. Automatic Evaluation.Table 4 shows the main comparison results on Dist-2/3/4, BLEU-2/4, Rouge-L and PPL. As we can see, RID signiﬁcantly outperforms all baselines on Dist-n, which indicates that PLM helps generate more diverse responses. Previous works suffer from the lowresource issue due to the small crowd-sourcing CRS dataset and tend to generate boring and singular responses. On the other hand, our RID model tends to recommend items more frequently, as the Item Ratio score of RID is much higher than those of baselines. Besides, our RID and PLM-based Table 4: Automatic metrics on generated responses. IR denotes the Item Ratio. methods consistently achieve remarkable improvement over non-PLM based methods on all metrics, which demonstrates the superior performance of PLMs on dialogue generation. Human Evaluation.To further investigate the effectiveness of our RID, we conduct a human evaluation experiment, where two crowd-workers are employed to score on 100 context-response pairs that are randomly sampled from the test set. Then, we collect the generation results of our model and the baseline models and compare their performance on the following three aspects: (1)Fluency. Whether the response is organized in regular English grammar and easy to understand. (2) Informativeness. Whether the response is meaningful and not a “safe response”, and repetitive responses are regarded as uninformative. (3)Coherence. Whether the response is coherent with the previous context. The crowd-workers give a score on the scale of [0, 1, 2] to show the quality of the generated sentences, and higher scores indicate better qualities. We use the following three criteria in PLATO (Bao et al., 2021a) and the scoring details are provided in Appendix. We calculate the average score for each model, as well as the ground truth that humans give. As shown in Table 5, our model shows better performance than all the baselines. Interestingly, groundtruth Human cannot get a 100% correctness in all the four evaluation metrics and our RID achieves even better ﬂuency performance than Human. The reason may be that words and phases sent by human annotators on AMT platform sometimes are the casual usage popular on Internet, which have the wrong grammars. For the ﬂuency, all models generate ﬂuent utterances and show similar performance. For the informativeness, our RID achieve much better performance than the baselines, which indicates RID tends to generate more meaningful responses. We then report the performance comparisons on our model’s variants. Table 3 shows the end-to-end recommendation performance and generation results. Removing the vocabulary pointer leads to signiﬁcant drops on R@k and Item Ratio. This indicate Vocabulary Pointer (VP) introduced in RID is crucial to the performance of item recommendation. The reason is that the generation process would lose the guidance to switch between general tokens and recommended items without the help of the vocabulary pointer. Besides, we can also found that knowledge graph enhanced ﬁnetuning helps achieve better recommendation performance. Introducing the node representations learned on the knowledge graph is beneﬁcial to a better user preference modeling, which could further enhance the recommendation performance. In this subsection, we present a conversation example to illustrate how our model works in practice. More examples are included in Appendix. In Figure 6, the Seeker states that he likes scary movies. Our model successfully captured the keyword of “scary” and recommends a famous scary movie “It (2017)” while the state-of-the-art model KGSF produces a safe response “Hello!”, which shows our RID can generate the responses that are more coherent with the context. Interestingly, after the Seeker says he watched the old “It (1990)”, our model recommends another horror movie “Psycho (1960)” also released in the last century. The possible reason is that RID infers the seeker is interested in old horror movies. The example in Figure 6 shows that our RID tends to generate a more informative response than KGSF. In addition, we ﬁnd that KGSF always generates “I would recommend Item” (Item is replaced with Get out (2017) in this example) and “I would recommend it.”. The ﬁrst response pattern successfully integrates the movie item into the response, while the second fails to make a complete recommendation, which reveals the drawback of the copy mechanism in KGSF. Table 6: A conversation example on movie item recommendation. The responses of KBRD, KGSF and RID are from the test results for corresponding models. Human responses are ground-truth. Analysis on Data Imbalance.As we discussed aforementioned, the movie occurrence frequency shows an imbalanced distribution over different movies (see Figure 2(a)). To investigate the effect, we report the Recall@30 and Recall@50 scores over movie mentioned times in Figure 3(a). As we can see, the recall scores for low-frequency movies (with mentioned times less than 10) are much lower than those high-frequency movies (with> 100 mentions). However, most of the movies (5467 out of 6924 movies) in the REDIAL dataset are lowfrequency movies, which leads to relatively low results in the overall performance. Analysis on Cold Start.Figure 2(b) shows that the REDIAL dataset suffers from the cold-start problem. It is hard for models to recommend precise items in the ﬁrst few turns of the conversation. We report the Recall@30 and Recall@50 scores of our RID over different dialogue turns in Figure 3(b). Generally, we can see that the recall scores are getting better with richer information Figure 3: Y-axis: Recall. For Fig. 3(a), X-axis: Movie mentions range. For Fig. 3(b), X-axis: turn numbers. gradually obtained from dialogue interactions. The scores begin to drop when there are more than 5 turns. The possible reason is that as the conversation goes deeper, the Seekers are no longer satisﬁed with the recommended high-frequency movies but prefer more personalized recommendations, which makes it more difﬁcult to predict in practice. This paper presents a novel PLM-based framework calledRIDfor CRS, which integrates the item recommendation into the generation process of PLM. Speciﬁally, we ﬁnetunes the large-scale PLMs together with a pre-trained relational graph convolutional network on an item-oriented knowledge graph. To unify the response generation and item recommendation into the existing PLMs, we expand the generation vocabulary of PLMs to inlcude an extra item vocabulary, and devise a vocabulary to control when to generate a ordinary word from generation vocabulary or an item from item vocabulary. Extensive experiments on a CRS benchmark dataset REDIAL show that our proposed RID significantly outperforms the state-of-the-art methods.