Keywords: Design-based inference; potential outcomes; restricted least squares; robust standard error Randomized experiments are the gold standard for causal inference, and justify simple comparisons across treatment groups. Regression adjustment provides a convenient way to incorporate covariate information for additional eﬃciency. This article provides a uniﬁed account of its utility for improving estimation eﬃciency in multi-armed experiments. We start with the commonly used additive and fully interacted models for regression adjustment, and clarify the trade-oﬀs between the resulting ordinary least-squares (ols) estimators for estimating average treatment eﬀects in terms of ﬁnite-sample performance and asymptotic eﬃciency. We then move on to regression adjustment based on restricted least squares (rls), and establish for the ﬁrst time its properties for inferring average treatment eﬀects from the design-based perspective. The resulting inference has multiple guarantees. First, it is asymptotically eﬃcient when the restriction is correctly speciﬁed. Second, it remains consistent as long as the restriction on the coeﬃcients of the treatment indicators, if any, is correctly speciﬁed and separate from that on the coeﬃcients of the treatment-covariates interactions. Third, it can have better ﬁnite-sample performance than its unrestricted counterpart even if the restriction is moderately misspeciﬁed. It is thus our recommendation for covariate adjustment in multi-armed experiments when the ols ﬁt of the fully interacted regression risks large ﬁnite-sample variability in case of many covariates, many treatments, yet a moderate sample size. In addition, the proposed theory of rls also provides a powerful tool for studying ols-based inference from general regression speciﬁcations. As an illustration, we demonstrate its unique value for studying ols-based regression adjustment in factorial experiments via both theory and simulation. Importantly, although we analyze inferential procedures that are motivated by ols, we do not invoke any assumptions required by the underlying linear models. Multi-armed experiments enable comparisons of more than two treatment levels simultaneously, and are intrinsic to applications with multiple factors of interest (see, e.g., Chakraborty et al. 2009; Collins et al. 2009; Mukerjee et al. 2018). They have been extensively used in agricultural and industrial settings (see, e.g., Box et al. 2005; Wu and Hamada 2009), and are becoming increasingly popular in social and biomedical sciences (see, e.g., Duﬂo et al. 2007; Karlan and McConnell 2014; Hainmueller et al. 2014; Egami and Imai 2019; Alsan et al. 2021; Torres et al. 2021; Blackwell and Pashley 2021). Linear models remain the dominant strategy for downstream analysis, delivering not only point estimates but also standard errors via one ordinary least-squares (ols) ﬁt. The ﬂexibility of model speciﬁcations further provides a convenient way to incorporate covariate information for additional eﬃciency. adjustment by ols. The theoretical superiority of the fully interacted regression under treatmentcontrol experiments is well established in the literature (see, e.g., Freedman 2008a; Lin 2013; Li and Ding 2020). Similar discussion, however, is largely missing for experiments with more than two treatment arms, except for some preliminary results in Freedman (2008b), Lin (2013), Lu (2016b), and Schochet (2018). To ﬁll this gap, we clarify the validity and relative eﬃciency of the additive and fully interacted regressions for estimating average treatment eﬀects under multi-armed experiments from the design-based perspective, which conditions on the potential outcomes and evaluates the sampling properties of estimators over the distribution of the treatment assignments. The results are highly similar to those under the treatment-control experiment. The ols estimator from the fully interacted regression is consistent, and ensures eﬃciency gains over the unadjusted regression asymptotically. The additive regression, on the other hand, is always consistent, yet only ensures eﬃciency gains when the correlations between potential outcomes and covariates are constant across treatment levels. In addition, we establish the asymptotic conservativeness of the associated Eicker– Huber–White (ehw) robust covariances for estimating the true sampling covariances under both the additive and fully interacted regressions. The result justiﬁes the Wald-type inference based on ols from the design-based perspective. This constitutes our ﬁrst contribution on the design-based justiﬁcation of regression-based covariate adjustment. interactions between treatment indicators and covariates, and can incur substantial ﬁnite-sample variability when there are many treatment levels, many covariates, yet only a moderate sample size (Zhao and Ding 2021a). Simulation studies further suggest that the additive regression can have better ﬁnite-sample performance than both the unadjusted and fully interacted regressions under such circumstances so long as the treatment eﬀects are not too diﬀerent across treatment levels. The choice between the additive and fully interacted models is thus a trade-oﬀ between ﬁnite-sample performance and asymptotic eﬃciency. Of interest is the availability of alternative The additive and fully interacted regressions are two commonly used strategies for covariate Despite being theoretically superior, however, the fully interacted speciﬁcation includes all strategies for achieving better middle ground. estimates and standard errors from the fully interacted regression, and establish for the ﬁrst time its properties for inferring average treatment eﬀects under the design-based framework. The resulting inference has multiple guarantees. First, it is asymptotically eﬃcient when the restriction is correctly speciﬁed. Second, it remains consistent as long as the restriction on the coeﬃcients of the treatment indicators, if any, is correctly speciﬁed and separate from that on the coeﬃcients of the treatment-covariates interactions. Third, it can have better ﬁnite-sample performance than its unrestricted counterpart even if the restriction is moderately misspeciﬁed. It is thus our recommendation for covariate adjustment in multi-armed experiments when the ols estimator from the fully interacted regression risks large ﬁnite-sample variability. We also propose a novel design-based Gauss–Markov theorem for rls, clarifying the asymptotic bias-variance trade-oﬀ between ols and rls under constant treatment eﬀects. These design-based results on rls are not only of theoretical interest in themselves, but also provide a uniﬁed framework for studying regression-based inference from general, possibly unsaturated speciﬁcations. This constitutes our second contribution on the design-based theory of rls for estimating average treatment eﬀects. Importantly, the classical theory for rls assumes a correct linear model with homoskedastic errors under correct restriction; our theory, in contrast, is design-based and allows for not only heteroskedastic errors but also misspeciﬁcation of both the linear model and the restriction. et al. 2015; Zhao and Ding 2021a), and illustrate the value of the above theories for studying covariate adjustment under this special type of multi-armed experiments. Speciﬁcally, factorial experiments concern multiple factors of interest, and assign experimental units to all possible levels of their combinations. The special structure of the treatment levels enables convenient factorbased regression analysis (Wu and Hamada 2009; Lu 2016a,b; Zhao and Ding 2021a), which ﬁts the observed outcome on indicators of the factor levels by ols and interprets the resulting coeﬃcients as the factorial eﬀects of interest. The design-based theory on covariate adjustment under factorial experiments so far focuses on factor-saturated regressions that include all possible interactions between the factor indicators (Lu 2016b; Zhao and Ding 2021b). The resulting speciﬁcations have model complexity that increases exponentially with the number of factors, risking substantial ﬁnitesample variability even with a moderate number of factors and covariates. of the interactions between the factor indicators, and clarify the design-based properties of the resulting ols estimators for covariate adjustment under factorial experiments. The choice between the factor-saturated and factor-unsaturated speciﬁcations, as it turns out, boils down to a trade-oﬀ between asymptotic bias and variance, extending the existing literature in the covariate-free setting (Zhao and Ding 2021a). The resulting theory includes the dominant speciﬁcations in practice as special cases, and oﬀers practical guidelines on the causal interpretations of their results. This constitutes our third contribution on the factor-based inference of factorial experiments. To this end, we propose restricted least squares (rls) as an alternative way to construct point We then move on to the factorial experiments (Box et al. 2005; Wu and Hamada 2009; Dasgupta To address this issue, we consider factor-unsaturated speciﬁcations that include only a subset a linear model, we do not invoke its underlying assumptions, but view the regression as a purely numeric procedure based on ols or rls. The sampling properties of the resulting point estimators and standard errors are then evaluated over the distribution of the treatment assignments. All our theories are as such design-based, and hold regardless of how well the regression equations represent the true data-generating process (see, e.g., Freedman 2008a,b; Schochet 2010; Lin 2013; Miratrix et al. 2013; Imbens and Rubin 2015; Bloniarz et al. 2016; Schochet 2018; Fogarty 2018; Liu and Yang 2020; Abadie et al. 2020; Guo and Basse 2021). Let Y the numeric outputs of ols and rls, and evaluate their design-based properties. be the m × 1 vector and m × n matrix of ones, respectively. Let I matrix. We suppress the dimensions when they are clear from the context. Let 1(·) be the indicator function. Let ⊗ denote the Kronecker product of matrices. For a set of real numbers {u let diag(u the relative eﬃciency between diﬀerent estimators. Deﬁnition 1 (peakedness). For two symmetric random vectors A and B in R peaked than B if pr(A ∈ C) ≥ pr(B ∈ C) for every symmetric convex set C ∈ R A  B. second moments, A  B implies cov(A) ≤ cov(B). For A and B that are both Normally distributed with zero means, A  B is equivalent to cov(A) ≤ cov(B). Intuitively, A ∼ B if and only if A  B and A  B. Deﬁnition 2 (asymptotic relative eﬃciency). For two estimators for some parameter θ ∈ R For notational simplicity, we will abbreviate θ)  context. Importantly, although the regression-based covariate adjustment was originally motivated by ∼ udenote the linear regression of Yon ufree of any modeling assumptions. We focus on Let 0and 0be the m ×1 vector and m×n matrix of zeros, respectively. Let 1and 1 )denote the diagonal matrix with u’s on the diagonal. Following Li et al. (2020), we use the notion of peakedness (Sherman 1955) below to quantify A more peaked random variable has smaller central quantile ranges. For A and B with ﬁnite For two sequences of random vectors {A}and {B}with A A and B B in , write ABif A  B, and write A∼ Bif A ∼ B. ˆθandˆθare asymptotically equally eﬃcient if√N(ˆθ− θ)∼√N(ˆθ− θ); ˆθis asymptotically more eﬃcient thanˆθif√N(ˆθ− θ) √N(ˆθ− θ). N(ˆθ− θ) asˆθˆθorˆθˆθ, respectively, when the meaning of θ is clear from the Consider an experiment with Q ≥ 2 treatment levels, q ∈ T = {1, . . . , Q}, and a study population of N units, i = 1, . . . , N. Let Y q (Neyman 1923). Let ¯Y = ( q ∈ T } ﬁnite-population average treatment eﬀect for some prespeciﬁed contrast matrix C with rows orthogonal to 1 treatment-control experiment, the 2 general K ≥ 2 as running examples to illustrate the main ideas. We give below their deﬁnitions for concreteness. The theory we are about to develop applies to general experiments with arbitrary structures of treatment levels; see, e.g., Karlan and List (2007); Sinclair et al. (2012); Alsan et al. (2021), and Zhao and Ding (2021a, Section A). We use customized indexes for treatment levels in Examples 1–3 to match the convention in the literature. Example 1. The treatment-control experiment has Q = 2 treatment levels, indexed by q = 0, 1. The individual treatment eﬀect is τ eﬀect is τ = N Example 2. The 2 A, B ∈ {−1, +1}, and a total of Q = 2 (−1, +1), (+1, −1), (+1, +1); we abbreviate (−1, −1) as (−−), etc. when no confusion would arise. Deﬁne equal respectively, with c (Dasgupta et al. 2015). Intuitively, the main eﬀect of a factor compares the average potential outcomes when the factor is at level +1 and level −1, respectively; the interaction eﬀect between A and B compares the average potential outcomes when the two factors take the same and diﬀerent levels, respectively. ¯Y (1), . . . ,¯Y (Q)). Let S = (S)be the ﬁnite-population covariance matrix of {Y(q) : with S= (N −1){Y(q) −¯Y (q)}{Y(q) −¯Y (q)}. The goal is to estimate the The above setting is general and includes many common designs as special cases. We use the ¯Y = (¯Y (−−),¯Y (−+),¯Y (+−),¯Y (++)). The standard main eﬀects and interaction eﬀect Example 3. The 2 tors, k = 1, . . . , K, and a total of Q = 2 where z iments are both special cases with K = 1 and K = 2, respectively. There are 2 factorial eﬀects corresponding to the main eﬀects and two- to K-way interaction eﬀects, respectively (Wu and Hamada 2009; Dasgupta et al. 2015). We focus on complete randomization deﬁned below. Deﬁnition 3 (complete randomization). The experimenter assigns completely at random N to treatment level q ∈ T , where the N for unit i. Let sample-mean estimator of as an intuitive choice for estimating τ . Under complete randomization, ˆτ sampling covariance cov(ˆτ the treatment indicators for unit i as Then over i = 1, . . . , N without an intercept. We call (4) the unadjusted treatment-based regression, featuring the treatment indicators as regressors. denote the J × 1 covariate vector for unit i. To simplify the presentation, assume centered S= (N − 1) ∈ {−1, +1} indicates the level of factor k. The treatment-control and 2factorial exper- Let Z∈ T denote the treatment level received by unit i. The observed outcome equals The presence of covariates promises the possibility of additional eﬃciency. Let x= (x, . . . , x) throughout the paper with mean ¯x = Nx= 0and ﬁnite-population covariance give two intuitive ways to adjust for covariates on the basis of (4). Refer to them as the additive and fully interacted treatment-based regressions, respectively, depending on whether the regression equations include the interactions between t vectors of t ˆY. As a convention, we use the subscripts “n”, “f”, and “l” to signify quantities associated with the unadjusted, additive, and fully interacted regressions, respectively. Example 4 in Section 3 will clarify their respective connections with Neyman (1923), Fisher (1935), and Lin (2013). Replacing as two convenient covariate-adjusted estimators of τ. Of interest is their validity and eﬃciency relative to ˆτ clarifying the intuition behind the regression formulations in Section 2.3 below. The derived linear model (Kempthorne 1952; Hinkelmann and Kempthorne 2008) provides the intuition for using the coeﬃcients of t ols ﬁt with the Y with  model of the observed outcome: with  adjustment. Consider the ols ﬁt of Y theoretical ols ﬁt, and yields the ﬁtted model Y model in (2) implies the covariate-adjusted derived linear model of the observed outcome: with  regression (6). With a slight abuse of terms, we call and 1(Z that the coeﬃcients of the 1(Z To begin with, consider the ols ﬁt of Y(q) ∼ 1 over i = 1, . . . , N for q ∈ T . This is a theoretical (q) = Y(q) −¯Y (q). Plugging the ﬁtted model in (2) implies the unadjusted derived linear =1(Z= q)(q). This motivates the unadjusted regression (4). The presence of covariates motivates extension of the classical model to include regression =1(Z= q)(q) and γ = (γ, . . . , γ). This motivates the fully interacted = q)xin (6), respectively, concatenated as θ= (¯Y, γ). Intuitively, the unadjusted speciﬁcation (4) can be viewed as a restricted variant of (6), assuming to be viewed as a restricted variant of (6), assuming that the coeﬃcients of the 1(Z all equal. This motivates the deﬁnitions of the zero and equal correlation conditions below. They provide not only the heuristics for the functional forms of (4) and (5) relative to (6), but also the suﬃcient conditions for the asymptotic eﬃciency of ˆτ Section 3. Condition 2 stipulates that the covariates have equal correlation with the potential outcomes across treatment levels, implying homogeneous treatment eﬀects. Condition 1 is stronger than Condition 2, and stipulates uncorrelatedness within all levels. Condition 3 below gives a suﬃcient condition for Condition 2. Condition 3 (constant treatment eﬀects). For all q, q Y(q) − Y any assumptions on the data-generating process. We use them as props to motivate the zero and equal correlation conditions, and introduce the notion of target parameters. Under the designbased framework, the derived linear model conditions on the potential outcomes, and attributes the randomness in Y of ( in general neither jointly independent nor homoskedastic under complete randomization. the randomness in Y of some hypothetical super-population. The covariance of the error terms is speciﬁed by model assumptions, with joint independence and homoskedasticity being two most commonly invoked ones. Freedman (2008a) pointed out that randomization does not justify these assumptions. The theory we are about to present, nevertheless, suggests that from ols, can still deliver valid design-based inferences when coupled with the ehw covariances. We elaborate on the details in Section 3 below. We establish in this subsection the validity and asymptotic relative eﬃciency of ˆτ for design-based inference of τ . The result extends Fisher (1935), Freedman (2008a), and Lin (2013) to multi-armed experiments, and complements Freedman (2008b) on the asymptotics of The variation in {γ: q ∈ T } measures heterogeneity in treatment eﬀects (Ding et al. 2019). (q) are constant across i = 1, . . . , N. Importantly, (7) and (8) are purely numeric decompositions of the observed outcome without )(∗ = n, l) are accordingly fully determined by the joint distribution of the Z’s, and are The classical Gauss–Markov model, on the other hand, conditions on the Z’s, and attributes the fully interacted regression. Results under alternative super-population frameworks appeared in Tsiatis et al. (2008), Bugni et al. (2018), and Negi and Wooldridge (2021) for treatment-control experiments, and in Bugni et al. (2019) and Ye et al. (2021) for experiments with more than two treatment levels. randomization. Condition 4. As N → ∞, for q ∈ T , (i) e ﬁnite-population moments of {Y are nonsingular; and (iii) there is a ﬁxed c < ∞ independent of N such that N 1, . . . , N . Let γ be the ﬁnite-population covariance matrices of {Y {Y(q; γ Condition 4 ensures that presentation, we will also use the same symbols to denote their respective limiting values when no confusion would arise. a moderate contribution by providing a uniﬁed theory for the design-based properties of sampling covariance. Lemma 1. Assume complete randomization and Condition 4. Then (iii) (iii) point estimator and estimated covariance, respectively, for ∗ = n, f, l. Lemma 1(ii) ensures the asymptotic eﬃciency of ˆτ ˆτ, especially when the experiments have unequal group sizes and heterogeneous treatment eﬀects with respect to the covariates (Freedman 2008a). Lemma 1(iii) gives two exceptions. First, assume the ﬁnite population satisﬁes the equal correlation condition. Then ˆτ Condition 4 states the standard regularity conditions for design-based inference under complete kxk≤ c, and NkxY(q)k≤ c. Recall that γdenotes the coeﬃcient vector of xfrom the ols ﬁt of Y(q) ∼ 1 + xover i = LetˆΨbe the ehw covariance ofˆYfrom the same ols ﬁt for ∗ = n, f, l. We ﬁrst make (∗ = n, f, l) in Lemma 1 below. The results clarify the consistency and asymptotic Normality for estimating¯Y , and ensure the asymptotic conservativeness ofˆΨfor estimating the true N(Y−Y )  N(0, V) for ∗ = n, f, l with NΨ− V= S+ o(1), where S≥ 0; ˆY∼ˆYˆYunder Condition 2 with V= V≤ V; ˆY∼ˆY∼ˆYunder Condition 1 with V= V= V. Lemma 1(i) justiﬁes the Wald-type inference of τ based on ˆτ= CˆYand CˆΨCas the eﬃciency as ˆτ the zero correlation condition. Then ˆτ experiment as a special case. We review in Example 4 below the results from Neyman (1923), Fisher (1935), and Lin (2013), and clarify their connections with (4)–(6). Example 4. Inherit the notation from Example 1 with τ = (−1, 1) (1 − Z estimator, and can also be computed as the coeﬃcient of Z coeﬃcient of Z estimator does not necessarily improve the asymptotic eﬃciency over ˆτ improved estimator as the coeﬃcient of Z that it is asymptotically at least as eﬃcient as ˆτ ensures that Fisher (1935)’s and Lin (2013)’s estimators equal ˆτ the connections of (4)–(6) to Neyman (1923), Fisher (1935), and Lin (2013), respectively, and illustrates a way to compute ˆτ experiment. Their design-based properties follow readily from Lemma 1. We next extend Lemma 1 to a class of linear covariate-adjusted estimators that include n, f, l) as special cases. Let be a covariate-adjusted estimator of and b = (b ˆY (q; b with Lemma 1 uniﬁes the existing theory on regression adjustment under the treatment-control ˆY, whereˆY(∗ = n, f, l) are the coeﬃcient vectors of t= (1(Z= 0), 1(Z= 1))= , Z)from the ols ﬁts of (4)–(6), respectively. Then ˆτequals the diﬀerence-in-means Neyman (1923) showed that ˆτis unbiased for τ. Fisher (1935) suggested to estimate τ by the The invariance of least squares to non-degenerate linear transformation of the regressor vector , . . . , b)∈ Rfor some prespeciﬁed b∈ R(Lin 2013; Li and Ding 2020). Intuitively, ) equals the sample mean of the covariate-adjusted potential outcomes Y(q; b) = Y(q) − . We focus on estimators in Recall that γ = (γ shows that where S T } Lemma 2. Assume complete randomization and Condition 4. For have with V over all estimators in E = {C to multi-armed experiments. Asymptotically, (ˆY (1; γ covariates, and thereby guarantee the eﬃciency of the asymptotic eﬃciency of ˆτ further ensures the asymptotic eﬃciency of ˆτ Despite the gains in asymptotic eﬃciency, the fully interacted regression (6) involves p = Q + JQ estimated coeﬃcients, subjecting ˆτ N is moderate relative to Q and J. Heuristics under the Gauss–Markov model and simulation evidence, on the other hand, suggest that ˆτ as the equal correlation condition is not severely violated. The choice between the additive and fully interacted regressions is thus a trade-oﬀ between ﬁnite-sample performance and asymptotic eﬃciency. This, together with the asymptotic eﬃciency of ˆτ tion, grants ˆτ outcomes, ensures asymptotic eﬃciency over E if the γ sample performance than ˆτ covariance, as a result, may not be a bad idea after all. See Schochet (2010) for empirical evidence based on eight large social policy experiments. of (6), assuming that the coeﬃcients of 1(Z approach to regression adjustment via restricted least squares (rls), which estimates the coeﬃcients + o(1), and b= γ + o(1), respectively. For b ∈ B with plim b = b= (b, . . . , b), let . The V(∗ = n, f, l) are special cases of Vfor b = b. ≥ VandˆY hbi ˆY. In particular,ˆY hbi∼ˆYwith V= Vif b= γ. Lemma 2 includes Lemma 1 as a special case, and ensures the asymptotic eﬃciency of ˆτ ), . . . ,ˆY (Q; γ)). The properties of ols ensure full reduction of the variability due to the Recall from Section 2.3 that the additive regression (5) can be viewed as a restricted variant of (6) subject to some prespeciﬁed linear restrictions. We establish the design-based properties of the resulting inference in Section 4. Restricted least squares (rls) is a standard tool for ﬁtting linear models, enabling convenient encoding of prior knowledge on model parameters. Its theoretical properties are well studied under the classical Gauss–Markov model (Theil 1971; Rao 1973; Greene and Seaks 1991). The corresponding theory, however, is so far missing under the design-based framework, where the errors are intrinsically dependent and heteroskedastic from the derived linear model perspective (c.f. Section 2.3). This section ﬁlls this gap, and clariﬁes the design-based properties of rls for regression adjustment. The resulting theory is not only of theoretical interest in itself but also provides a powerful tool for studying ols-based inference from general regression speciﬁcations. We focus on rls-based inference for multi-armed experiments in this section, and demonstrate its unique value for studying ols-based regression adjustment in factorial experiments in Section 5. Importantly, the classical theory for rls assumes a correct linear model with homoskedastic errors under correct restriction; our theory, in contrast, is design-based and allows for not only heteroskedastic errors but also misspeciﬁcation of both the linear model and the restriction. by the derived linear model (8). Let χ ﬁt of (6) estimates θ where prespeciﬁed linear restrictions. Deﬁnition 4 (restricted least squares). The rls ﬁt of (6) yields for some prespeciﬁed restriction matrix R that has full row rank. respectively, with Recall θ= (¯Y, γ)as the target parameter of the fully interacted regression (6), motivated ˆYandˆβ= (ˆβ, . . . ,ˆβ)denote the coeﬃcient vectors of tand t⊗x, respectively, with corresponding to 1(Z= q)x. The rls ﬁt, on the other hand, estimates θsubject to some LetˆYandˆβ= (ˆβ, . . . ,ˆβ)denote the rls coeﬃcient vectors of tand t⊗ xin (11), prior belief of Of interest is the utility of the resulting ˆτ to (11) as the rls ﬁt subject to (12). The restriction (12) as such is a purely numeric input for rls that may or may not match the truth. We say (12) is correctly speciﬁed if it indeed matches the truth. (6), assuming the zero and equal correlation restrictions, respectively. Examples 5 and 6 illustrate the numeric correspondence between the rls ﬁt and the ols ﬁt of the corresponding restricted speciﬁcation. Lemma S3 of the Supplementary Material states a more general result that includes Examples 5 and 6 as special cases. Importantly, the equal correlation restriction diﬀers from the equal correlation condition in that we view the restriction as a purely numeric input for rls that may or may not match the truth. The equal correlation condition, in contrast, represents our assumptions about the true data-generating process. The equal correlation restriction is as such correctly speciﬁed if and only if Condition 2 holds. Likewise for the correspondence between the zero correlation restriction and Condition 1. restrictions on both Example 7. Recall the setting of the 2 are willing to assume zero individual interaction eﬀects that τ which can in turn be used as a restriction for ﬁtting (6) by rls. A matrix representation of this restriction is Rθ We will use (12) to represent the restriction in (11) in terms of the target parameters, and refer = 0with R = (0, I). ˆβ= ··· =ˆβ, whereˆYandˆβare the coeﬃcients from the rls ﬁt of (6) subject to = 0with R = (0, (−1, I) ⊗ I). Recall from Section 2.3 that regressions (4) and (5) can be viewed as restricted variants of The restrictions in Examples 5 and 6 involve only the γ’s. Example 7 below instead imposes {Y(−−) + Y(++)} − 2{Y(−+) + Y(+−)} as the interaction eﬀect for unit i. Suppose we Write (8) in matrix form as where Y = (Y model assumes that Y has expectation χ among all linear unbiased estimators when the restriction is correctly speciﬁed (Theil 1971; Rao 1973). The design-based framework violates these assumptions, and leaves the sampling properties special cases, and justiﬁes the Wald-type inference of τ based on ˆτ assumptions. For simplicity, we assume that χ more general formulas. Lemma 3. consequence of Lemma 3, and ensures correctly speciﬁed or not. Denote by plim To simplify the presentation, we relegate the most general theory to the Supplementary Material, and focus on the following two types of restrictions in the main paper due to their prevalence in practice and their ability to convey all main points of the general theory. Deﬁnition 5. A separable restriction restricts for some prespeciﬁed ρ is no restriction on Deﬁnition 5, R = diag(ρ both R = (0, ρ restriction is correctly speciﬁed by deﬁnition. unclear. This is our focus for this subsection. The resulting theory includesˆY(∗ = n, f) as To this end, we ﬁrst review in Lemma 3 below the numeric expression ofˆθfree of any modeling Recall the deﬁnition of B from (9). Theorem S4 in the Supplementary Material is a direct for b =ˆβfrom (10). A correlation-only restriction concerns only γ, with (14) reduced to The correlation-only restriction is a special type of the separable restriction with ρ= 0. In ¯Y and γ; R = (ρ, 0) and r = rfor a separable restriction with only restriction on¯Y ; and ) and r = rfor a correlation-only restriction with non-empty restriction on γ. An empty exempliﬁes the more general separable restriction. A common choice of ρ with rows orthogonal to 1 eﬀects, namely ρ the assumptions of no higher-order interactions for analyzing factorial experiments all fall into this category; see Zhao and Ding (2021a). We give more examples under the 2 in Section 5. estimation for large-sample Wald-type inference. Sections 4.3.2 and 4.3.3 establish properties following immediately from Lemma 2. Section 4.3.4 then proposes a novel estimator of the true sampling covariance of 4.3.2. Proposition 1. Assume rls subject to (15). Then plim to Y = { Theorem 1. Assume complete randomization, Condition 4, and rls subject to (15). Then 1 establishes two theoretical guarantees of ensures that it is always consistent and asymptotically Normal regardless of whether (15) is correctly speciﬁed or not. Theorem 1(ii) ensures that it has the same asymptotic eﬃciency as when (15) is indeed correct. Simulation in Section 6 further suggests that sample performance than restriction on Such reduction in variability, despite having no eﬀect on the asymptotic eﬃciency of correctly speciﬁed, improves its precision in ﬁnite samples. This gives the third guarantee of the correlation-only restriction, with for mitigating the conundrum of many covariates and many treatments when the sample size is moderate. over Examples 5 and 6 are special cases of the correlation-only restriction, whereas Example 7 We focus on not only consistency but also asymptotic Normality and conservative covariance ˆβi under both correlation-only and separable types of restrictions, with asymptotic sampling ˆβ= γ if (15) is correctly speciﬁed. Proposition 1 states the numeric equivalence betweenˆYandˆY hˆβi, and ensures thatˆYbelongs ˆY hbi : b ∈ B} with b =ˆβ. Its design-based properties then follow immediately from Lemma Recall thatˆYensures the maximum asymptotic eﬃciency over all estimators in Y. Theorem Additional restriction on¯Y , on the other hand, promises the possibility of additional eﬃciency ˆY. We elaborate on the details below. 4.3.3. (ii) µ properties then follow immediately from those of ensures that plim whether that on as ρ ˆYwhen the restriction on depend on distinct restrictions on Theorem 2. Assume complete randomization, Condition 4, and rls subject to (14) with ρ Then (ii) Further assume that ρ unless the restriction on that the resulting tional eﬃciency over Theorem 3. Assume complete randomization, Conditions 3–4, and rls subject to (14) with ρ being a contrast matrix with rows orthogonal to 1 ˆYunder the separable restriction with ρ6= 0 6= 0. ˆβ∈ B. In particular, ˆβ= γ if ργ = ris correctly speciﬁed; = 0, and henceˆY−¯Y = U{ˆY hˆβi −¯Y }, if ρ¯Y = ris correctly speciﬁed. Equation (17) is numeric and ensures thatˆYis a linear function ofˆY hˆβi ∈ Y. Its sampling γ = ris correctly speciﬁed. Proposition 2(ii), on the other hand, suggests the consistency of ˆY−¯Y = µ+ o(1), where µ6= 0 in general unless ρ¯Y = ris correctly speciﬁed. where V≥ Vand satisﬁes V= Vif ργ = ris correctly speciﬁed. Theorem 2(i) shows that theˆYfrom the separable restriction is in general not consistent exactly when ρ6= 0, this illustrates one advantage of imposing restriction on only γ. When the restriction on¯Y is non-empty and indeed correctly speciﬁed, Theorem 2(ii) ensures (ii) Further assume that ρ to the covariate-adjusted settings, and illustrates the asymptotic bias-variance trade-oﬀ between and correctly speciﬁed restriction on γ. Theorem 3(i) states the reduction in asymptotic covariance by arbitrary restriction on contrasts of assume that the restriction on counterpart of the classical Gauss–Markov theorem for rls, ensuring the asymptotic eﬃciency of ˆYover all linear consistent estimators of the form L sampling properties of when misspeciﬁed, yet ensures lower asymptotic variance than The choice of whether to restrict restriction on γ, on the other hand, retains consistency regardless of whether correctly speciﬁed or not, but undermines asymptotic eﬃciency when misspeciﬁed. Simulation studies further suggest that it can improve the ﬁnite-population performance of thus a trade-oﬀ between ﬁnite-sample performance and asymptotic eﬃciency. Recall that as a variant of the ehw covariance of terparts ˆ submatrix of (I and Condition 4. Let S Theorem 4. Assume complete randomization and Condition 4. (i) Under rls subject to (15), we have N γ = ris correctly speciﬁed, thenˆY−¯Y = µ+ o(1) withˆYhaving smaller asymptotic covariance thanˆY. estimator of the form LˆY hbi + a. That is,ˆYis asymptotically Normal with mean¯Y and ˆYLˆY hbi + a for all linear consistent estimator in {LˆY hbi + a : b ∈ B} that satisﬁes LˆY hbi + a =¯Y + o(1). In particular,ˆYˆYgivenˆY=ˆY hbi is a linear consistent estimator. Theorem 3 extends the results in Zhao and Ding (2021a, Theorem A5) on unadjusted estimators ˆYwhen the restriction on¯Y is non-empty. Speciﬁcally, assume constant treatment eﬀects Juxtapose Theorems 1–3. The restrictions on¯Y and γ have distinct consequences on the Let β= plimˆβ(q ∈ T ) denote the probability limit ofˆβunder complete randomization : q ∈ T }, with S= (N − 1){Y(q) − xβ−¯Y (q)}{Y(q) − xβ−¯Y (q)}. = diag(S/e)− Sby deﬁnition. (ii) Under rls subject to (14) with ρ speciﬁed from Theorem 2. Theorem 4 thus ensures that estimating the true sampling covariance of inference of τ based on ˆτ respectively, when ρ variants of (6), assuming the zero and equal correlation restrictions, respectively. The above provides an alternative way to estimate the covariance of (6) subject to the zero and equal correlation restrictions, respectively. Theorem 4(i) and Lemma 1(i) together ensure that in the Supplementary Material further gives a stronger result on their numeric equivalence, i.e., between the ehw covariance from the rls ﬁt and that from the ols ﬁt of the corresponding restricted speciﬁcation. See Lemma S3 in the Supplementary Material for a general result. This concludes our discussion on the various models for regression adjustment in multi-armed experiments. The rls estimator ˆτ 6, and ensures a triple guarantee under complete randomization. First, it is asymptotically eﬃcient when the restriction is correctly speciﬁed. Second, it is consistent as long as the restriction on correctly speciﬁed and separate from that on γ. Third, it can have better ﬁnite-sample performance than the unrestricted ˆτ the asymptotic conservativeness of C advantage of rls-based inference in ﬁnite samples. tion in the design stage of experiments (Cox 1982; Morgan and Rubin 2012). It is the experimentaldesign analogue of rejective sampling (Fuller 2009), and accepts a complete randomization if and only if it satisﬁes some prespeciﬁed covariate balance criterion. The resulting inference based on ˆτ, as it turns out, inherits all guarantees from inference under complete randomization and, in addition, ensures less loss in asymptotic eﬃciency when the restriction is misspeciﬁed. It is therefore where µdenotes the qth element of µ, and U {S+ diag(µ/e)}U≥ 0. Further assume that ρ¯Y = ris correctly speciﬁed. Then NˆΨ− U VU= USU+ o(1) with Recall that (i)N(ˆY−¯Y )  N(0, V) under rls subject to (15) from Theorem 1, and (ii) ˆY−¯Y )  N(0, U VU) under rls subject to (14) when ρ6= 0 and ρ¯Y = ris correctly In addition, recall that the unadjusted and additive regressions can be viewed as restricted (∗ = n, f) from the ols ﬁts (c.f. Lemma 1). LetˆΨandˆΨbe the values ofˆΨfrom ﬁtting =ˆΨ(∗ = n, f), free of any distributional assumptions. This illustrates the equivalence Rerandomization, on the other hand, oﬀers an alternative way to incorporate covariate informaour recommendation for covariate adjustment in multi-armed experiments when covariate data are available before units are exposed to treatments. We relegate the detailed theory to the Supplementary Material, and illustrate its ﬁnite-sample performance by simulation in Section 6. The results extend the existing literature on rerandomization and its uniﬁcation with regression adjustment to multi-armed experiments (Morgan and Rubin 2012; Branson et al. 2016; Li et al. 2018, 2020; Li and Ding 2020; Zhao and Ding 2021c), and highlight the utility of rerandomization for providing additional protection against model misspeciﬁcation. Factorial experiments are a special type of multi-armed experiments, featuring treatments as combinations of two or more factors (Box et al. 2005; Wu and Hamada 2009; Dasgupta et al. 2015; Zhao and Ding 2021a; Pashley and Bind 2021). The treatment-based regressions hence provide a principled way of studying factorial experiments, enabling inference of arbitrary average treatment eﬀects of interest by least-squares ﬁts. Despite their generality and nice theoretical guarantees, however, they are not the dominant choice for analyzing factorial data in practice. Factor-based regressions, as a more popular approach, regress the observed outcome directly on the factors themselves, and interpret the coeﬃcients as the corresponding factorial eﬀects of interest. This enables not only direct inference of the treatment eﬀects based on regression outputs, but also ﬂexible unsaturated speciﬁcations to reduce model complexity. saturated speciﬁcations that include all possible interactions between the factors (Lu 2016a,b; Zhao and Ding 2021b). The resulting regressions contain at least 2 eﬃcients for a K-factor study under the additive and fully interacted speciﬁcations, respectively, subjecting subsequent inference to substantial ﬁnite-sample variability even when K is moderate. We extend the discussion to factor-unsaturated regressions, and establish their properties for covariate adjustment from the design-based perspective. The resulting theory is not only of practical relevance in itself given the rising popularity of factorial experiments, but also illustrates the value of rls for studying estimators from general ols regressions. We will focus on 2 periments and standard factorial eﬀects for notational simplicity. The results extend to general factorial eﬀects in general factorial experiments with minimal modiﬁcation (Zhao and Ding 2021a, Section A). Consider a 2 Inherit the notation from Example 3. The Q = 2 {−1, +1} The existing literature on covariate adjustment for factor-based regressions focuses on factor- , where z∈ {−1, +1} indicates the level of factor k. There are 2 characterizing the main eﬀect or |K|-way interaction of the factor(s) in K for |K| = 1 and |K| ≥ 2, respectively (Wu and Hamada 2009; Dasgupta et al. 2015). The (τ special cases with P where τ K ∈ P The standard factorial eﬀects are hence orthogonal in terms of the contrast vectors that deﬁne them. Example 8 below gives the formulas for the main eﬀects and two-way interactions; see Dasgupta et al. (2015) and Li et al. (2020) for formulas for the higher-order interactions. Example 8. The standard main eﬀect of factor k equals comparing the average potential outcomes when factor k is at level −1 and level +1, respectively. The standard interaction eﬀect between factors k and k comparing the average potential outcomes when the two factors take the same and diﬀerent levels, respectively. The (τ Let Z K ∈ P literature takes as the standard speciﬁcation for factor-based regression analysis, and estimates τ ols coeﬃcient of Z control experiment and the Y special cases with K = 1 and K = 2, respectively. We call (18) the factor-saturated unadjusted Let P= {K : ∅ 6= K ⊆ [K]} denote the set of the 2−1 non-empty subsets of [K] = {1, . . . , K}. = c¯Y denotes the main eﬀect or interaction corresponding to K ∈ P. Then C= {c: } is a (Q − 1) × Q contrast matrix with ∈ {−1, +1} indicate the level of factor k received by unit i. Let Z=Zfor , representing the interaction between the factors in K. The classical experimental design regression, which includes all possible interactions between elements of (Z covariates further motivates as the additive and fully interacted variants, respectively. panel of Table 1 summarizes them. tively, vectorized as Let ∗ = n, f, l to signify the unadjusted, additive, and fully interacted speciﬁcations, respectively, and use the tilde (˜τ) to signify outputs from factor-based regressions. Proposition 3 below follows from the invariance of ols to non-degenerate linear transformation of the regressor vector, and justiﬁes the Wald-type inference of τ Zhao and Ding 2021a), whereas that on ˜τ Proposition 3. ˜τ and their treatment-based counterparts for estimating τ most eﬃcient among {C ˜τ(∗ = n, f), with ˜τ zero correlation condition. Despite the conceptual straightforwardness and nice theoretical guarantees, the factor-saturated regressions (18)–(20) involve 2 jecting subsequent inference to substantial ﬁnite-sample variability even when K is moderate (Zhao and Ding 2021a). Oftentimes it is only the K main eﬀects along with the K(K − 1)/2 two-way interactions that are of interest, with the higher-order eﬀects believed to be small. A common practice is then to include only the relevant terms, and estimate the eﬀects of interest from ﬁrstor second-order speciﬁcations like Y Equations (18)–(20) deﬁne three factor-saturated speciﬁcations for factor-based analysis of the factorial experiment, paralleling (4)–(6) under the treatment-based formulation. The upper Let ˜τ(∗ = n, f, l) be 2 times the coeﬃcients of Zfrom the ols ﬁts of (18)–(20), respec- ˜Ωbe the ehw covariance of ˜τfrom the corresponding ols ﬁt. As a convention, we use Proposition 3 is numeric, and ensures the equivalence between the factor-saturated speciﬁcations as a factor-unsaturated variant of (18), targeting speciﬁcally the eﬀects associated with the factorial combinations in F included in and excluded from the factor-unsaturated speciﬁcations, respectively. The ﬁrst- and second-order speciﬁcations above are both special cases with F {{k}, {k, k Equations (21)–(23) deﬁne three factor-unsaturated variants of (18)–(20), respectively, as arguably the most commonly used speciﬁcations in practice. The lower panel of Table 1 summarizes them. Of interest is the impact of such simpliﬁcation on subsequent inference. We answer this question in Section 5.5 below. Deﬁne as the eﬀects of interest and nuisance eﬀects corresponding to F More generally, for Fas an arbitrary subset of Pwith F= P\F6= ∅, deﬁne } : k 6= k∈ [K]}. The additive and fully interacted variants are then (∗ = n, f, l) be 2 times the coeﬃcients of Zfrom the ols ﬁts of (21)–(23), respectively, vectorized as We use the subscript “r” to signify that (21)–(23) are restricted variants of (18)–(20), respectively, assuming that the coeﬃcients of {Z is justiﬁed by the equivalence between restricted speciﬁcations and rls; see Example S1 in the Supplementary Material. respectively. They are all special cases of below states the numeric correspondence between ˜τ Proposition 4. ˜τ the deﬁnition of V Let U be the estimators of τ covariance of ˜τ Corollary 1. Assume complete randomization, Condition 4, and τ (ii) Further assume Condition 3. Then when the nuisance eﬀects excluded are indeed absent. Further assume Condition 3 with constant treatment eﬀects. Corollary 1(ii) establishes the asymptotic eﬃciency of ˜τ {˜τ condition, which ensures that the additive adjustment is asymptotically as eﬃcient as the fully interacted adjustment to begin with. The additional, correct knowledge on the nuisance eﬀects LetˆY,ˆY, andˆYbe the coeﬃcient vectors of tfrom the rls ﬁts of (6) subject to The design-based properties of ˜τthen follow from those ofˆYin Theorems 2 and 3. Recall and µbe the values of U and µat ρ= C, respectively. Let N(˜τ− τ)  N(0, CUVUC) for ∗ = n, f, l, withΩbeing asymptotically conservative for estimating the true sampling covariance. Corollary 1(i) justiﬁes the Wald-type inference based on the factor-unsaturated speciﬁcations , ˜τ: ∗ = n, f, l} for estimating τ. Intuitively, Condition 3 implies the equal correlation then secures extra precision on top of that over the otherwise optimal ˜τ the value of factor-unsaturated regressions in combination with covariate adjustment for improving eﬃciency. pends critically on the actual absence of the nuisance eﬀects. This can never be veriﬁed exactly in reality, and subjects subsequent inference to possibly non-diminishing biases. This suggests the merit of the factor-saturated additive regression (19) as a trade-oﬀ between asymptotic bias, asymptotic eﬃciency, and ﬁnite-sample performance. The resulting inference is always consistent, and ensures asymptotic eﬃciency under equal correlations. Simulation in Section 6 further demonstrates its ﬁnite-sample advantage over the asymptotically more eﬃcient fully interacted counterpart (20). ment group sizes. The resulting ˜τ the intuition in Condition 5 and Proposition 5 below. (ii) ˜τ whether τ model misspeciﬁcation echos the emphasis of the classical experimental design literature on equal treatment group sizes and orthogonality of the factorial eﬀects. in (24)–(26) to be correctly speciﬁed, and can no longer exceed that of ˜τ Proposition 5(ii). In particular, the condition (C with as ˜τ both correctly speciﬁed, and ensures that ˜τ One key limitation of the factor-unsaturated speciﬁcations is that the consistency of ˜τde- One surprising, and arguably extremely valuable, exception is when the design has equal treat- 6= 0, thanks to the orthogonality of Cin deﬁning the standard factorial eﬀects. We formalize Letˆβbe the value ofˆβassociated withˆY, withˆβ= 0. = CˆY= ˜τ. Further assume complete randomization and Condition 4. Then N(˜τ− τ)  N(0, CVC) for ∗ = n, f, l, with ˜τ˜τandΩbeing asymptotically conservative for estimating the true sampling covariance. ∼ ˜τif (C⊗ I)γ = 0; ˜τ∼ ˜τ∼ ˜τunder Condition 2; ˜τ∼ ˜τ(∗ = n, f, l) under Condition 1. The identity ˜τ= CˆY hˆβi is numeric, and ensures the consistency of ˜τregardless of The asymptotic eﬃciency of ˜τ, nevertheless, still requires the associated restriction on γ ˆβin (26) is correctly speciﬁed, and ensures that ˜τattains the same asymptotic eﬃciency . Condition 2 implies that the restrictions associated withˆβandˆβin (25) and (26) are . Condition 1 implies that the restrictions associated withˆβ,ˆβ, andˆβin (24)–(26) are all correctly speciﬁed, and ensures that ˜τ which ensure consistency at the cost of possible additional eﬃciency over ˜τ We focused on speciﬁcations (18)–(23) because of their conceptual intuitiveness and prevalence in practice. The same results extend to general speciﬁcations like Y the Supplementary Material. the standard factorial eﬀects. Applications in social and biomedical sciences also often encode the factor levels by {0, 1}. The resulting speciﬁcations, despite prevalent in practice, cannot recover the standard factorial eﬀects directly as regression coeﬃcients (Zhao and Ding 2021a). The invariance of ols to non-degenerate linear transformation of the regressor vector, on the other hand, ensures that all results so far extend to the {0, 1}-coded regressions for estimating a diﬀerent set of factorial eﬀects with minimal modiﬁcation. We relegate the details to the Supplementary Material. We now illustrate the ﬁnite-sample properties of the proposed method via simulation. Consider a 2factorial experiment with Q = 4 treatment levels, q ∈ T = {(−−), (−+), (+−), (++)}, and a ﬁnite population of N = 100 units, i = 1, . . . , N. We choose the moderate sample size on purpose to illustrate the limitation of the factor-saturated fully interacted regression in ﬁnite samples. vector as x (−+), (+−), (++), and Y condition of zero individual interaction eﬀects from Example 7, and ensures that restriction (13) is correctly speciﬁed with τ randomization and rerandomization to illustrate the additional eﬃciency by covariate adjustment in the design stage. For (N of N rerandomization based on contrasts of the covariate means. Speciﬁcally, let be two linear contrasts of the ˆx(q)’s. They correspond to the c main eﬀects τ . This illustrates the asymptotic bias-variance trade-oﬀ regarding the use of equal-sized designs, Zxfor arbitrary F, F⊆ Pwith minimal modiﬁcation. We relegate the details to In addition, we focused on speciﬁcations under the {−1, +1} coding system for inference of Inherit the notation from Example 2. For each i, we draw a J = 20 dimensional covariate Fix {Y(q), x: q ∈ T }in the simulation. We consider inference under both complete q’s to obtain the treatment assignments under complete randomization, and proceed with Table 2: Six factor-based regressions and their respective restrictions relative to (20). We use “N”, “F”, and “L” to indicate the unadjusted, additive, and fully interacted adjustment schemes, respectively, with the suﬃx “ us” indicating the factor-unsaturated variants. N us (21): Y in the realized allocation. Building on Branson et al. (2016) and Li et al. (2020), we accept the initial complete randomization under rerandomization if and only if the Mahalanobis distance of ˆδ = ( of freedom. The resulting procedure has an acceptance rate of approximately 0.01; see Section S1 in the Supplementary Material and Li et al. (2020). are special cases of regressions (18)–(23) at K = 2 and F between rls and ols on the corresponding restricted speciﬁcation ensures that the ols ﬁt of (23) is equivalent to the rls ﬁt of (20) subject to (13), which is correctly speciﬁed. The ols ﬁts of (18), (19), (21), and (22), on the other hand, are equivalent to ﬁtting (20) subject to restrictions that are misspeciﬁed, summarized in the last column of Table 2. domizations. The results under rerandomization are summarized over the subsets of randomizations that satisfy the covariate balance criterion. Figure 1(a) corresponds to potential outcomes generated from (β correlation condition that justiﬁes the additive regression (19) and its factor-unsaturated variant (22). Figure 1(b) corresponds to potential outcomes generated from β gesting reasonable closeness to the equal correlation condition such that both (19) and (22) are approximately correctly speciﬁed. speciﬁed regression (23) (“L us”) shows the smallest variability in Figure 1(a), with rerandomization bringing little extra improvement compared with complete randomization. The factor-unsaturated additive regression (22) (“F us”) is only approximately correctly speciﬁed in Figure 1(b), but already delivers even better ﬁnite-sample performance than the correctly speciﬁed (23) thanks to the ˆδ,ˆδ)∈ Ris less or equal to the 0.01 quantile of the χdistribution with 2J = 40 degrees Consider six models for estimating τ= (τ, τ, τ)via ols, summarized in Table 2. They and Bto indicate the levels of factors A and B for unit i for intuitiveness. The equivalence Figure 1 shows the distributions of the diﬀerences between 2 times the ols coeﬃcients of , AB) and the true values of (τ, τ, τ) over 100, 000 independent initial complete ran- The message is coherent across diﬀerent values of β’s and in line with the theory. The correctly more parsimonious model. The fully interacted regression (“L”), despite being correctly speciﬁed and asymptotically the most eﬃcient among the three factor-saturated speciﬁcations, shows substantial variability in all cases without rerandomization. The four misspeciﬁed regressions, namely “N”, “F”, “N us”, and “F us”, on the other hand, show much stabler performance even in Figure 1(a), where the equal and zero correlation conditions are considerably violated. This illustrates the robustness of the proposed method to misspeciﬁcation of the restriction. Rerandomization, on the other hand, brings visible improvements to the misspeciﬁed regressions in all cases. Based on the asymptotic analysis and simulation, we recommend using restricted least squares on the fully interacted regression for covariate adjustment in multi-armed experiments when the sample size is moderate relative to the number of covariates or treatment levels. Assume the restriction on the average potential outcomes is correctly speciﬁed and separate from that on the correlations between potential outcomes and covariates. The resulting inference is consistent for estimating the ﬁnite-population average treatment eﬀects regardless of whether the restriction on the correlations is correctly speciﬁed or not, and ensures additional eﬃciency over the ols counterpart if the restriction on the correlations is indeed correctly speciﬁed under constant treatment eﬀects. Simulation studies further show that it can have better ﬁnite-sample performance than the ols counterpart even when the restriction is moderately misspeciﬁed. ing restriction on only the correlations. The resulting estimator ensures consistency, yet can be at most as eﬃcient as the ols counterpart asymptotically. Importantly, all results are design-based, and hold without assuming any stochastic models for the potential outcomes. When prior knowledge on the average potential outcomes is less reliable, we recommend impos-