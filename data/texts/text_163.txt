 neering and design optimization problems. It is not uncommon that the objective functions are as a black box, the evaluation of which usually involve time-consuming and/or costly physical experiments. Data-driven evolutionary optimization can be used to search for a set of non-dominated trade-oﬀ solutions, where the expensive objective functions are approximated as a surrogate model. In this paper, we propose a framework for implementing batched data-driven evolutionary multi-objective optimization. It is so general that any oﬀ-the-shelf evolutionary multi-objective optimization algorithms can be applied in a plug-in manner. In particular, it has two unique components: 1) based on the KarushKuhn-Tucker conditions, a manifold interpolation approach that explores more diversiﬁed solutions with a convergence guarantee along the manifold of the approximated Pareto-optimal set; and 2) a batch recommendation approach that reduces the computational time of the optimization process by evaluating multiple samples at a time in parallel. Experiments on 136 benchmark test problem instances with irregular Pareto-optimal front shapes against six state-of-the-art surrogate-assisted EMO algorithms fully demonstrate the eﬀectiveness and superiority of our proposed framework. In particular, our proposed framework is featured with a faster convergence and a stronger resilience to various PF shapes. Keywords: Multi-objective optimization, surrogate modeling, Karush–Kuhn–Tucker conditions, evolutionary algorithm Real-world problems in science, engineering and design often involve multiple conﬂicting objectives, as known as multi-objective optimization problems (MOPs). For example, in the optimal design of a water distribution system, many indicators need to be considered to achieve a trade-oﬀ between capital and/or operational cost and performance type beneﬁts such as pressure deﬁcit, reliable conﬁgurations under abnormal conditions and network resilience index. There does not exist a global optimal solution that optimizes all conﬂicting objectives. Instead, multi-objective optimization mainly aim to ﬁnd a set of trade-oﬀ alternatives that compromise among diﬀerent objectives before being handed over for multi-criterion decision-making. Evolutionary algorithms (EAs) have been widely recognized as a major approach for multi-objective optimization given its population-based property for approximating a set of non-dominated solutions in a single run [1]. Over the past three decades and beyond, many eﬀorts have been dedicated to the developments of evolutionary multi-objective optimization (EMO) algorithms. According to their environmental selection mechanisms, the existing EMO algorithms can be classiﬁed into three categorizes: 1) dominance-based methods, e.g., elitist non-dominated sorting genetic algorithm (NSGA-II) [2], 2) indicator-based methods, indicator-based EA (IBEA) [3], and 3) decomposition-based methods, e.g., multi-objective EA based on decomposition (MOEA/D) [4, 5]. Department of Computer Science, University of Exeter, EX4 4QF, Exeter, UK In practice, it is not uncommon that the objective functions of real-world problems are as a black box and are expensive to evaluate, either computationally or economically. For example, computational ﬂuid dynamic simulations can take from minutes to hours to carry out a single function evaluation (FE) [6]. Due to the population-based and iterative nature, EAs usually require a vast amount of FEs to obtain reasonably acceptable solutions. This is unrealistic when FEs are expensive thus it signiﬁcantly hinders a wider uptake of EAs in real-world scenarios. To alleviate this issue, surrogate models, built by data collected from expensive FEs, have emerged as a powerful tool to assist EAs for solving expensive optimization problems, also known as data-driven evolutionary optimization consists of three intertwined design components. • The ﬁrst one is the surrogate modeling of the expensive objective functions. Many oﬀ-the- • The other one is the surrogate-assisted search process either directly driven by the surrogate • The last one is the model management that mainly aims to select promising solution(s) output In practice, many physical experiments can be carried out in parallel given the availability of more than one infrastructure. For example, laboratory technicians often perform experiments with duplicated setups in parallel to mitigate empirical bias. Likewise, in automated machine learning, training and validating machine learning models are usually distributed into multiple cores or GPUs for hyperparameter optimization. An eﬀective parallelization, also known as batch recommendations/evaluations in data-driven evolutionary optimization, are of practical importance to signiﬁcantly save the computational time by reducing the number of iterations. However, this line of research is relatively lukewarm in the data-driven evolutionary optimization community [11, 20, 21]. As discussed in [22], it is unrealistic to have a regular Pareto-optimal front (PF) in real-world MOPs. On the contrary, due to the complex and non-linear relationship between objectives, it is not uncommon to have an irregular PF featured as disconnected, incomplete, degenerated, and/or badly-scaled. Although there have been growing interests for handling MOPs with irregular PFs in the EMO community (e.g., [23–25]), it has rarely been considered in the context of data-driven EMO, except for [26]. To address the above issues, this paper proposes a batched data-driven EMO framework based on manifold interpolation for solving expensive MOPs with various PF shapes. It consists of the following four major design components. • Surrogate modeling: GPR is used to build the surrogate model for each computationally • Evolutionary search: This step searches for an approximated PF based on the surrogate • Manifold interpolation: Based on the Karush-Kuhn-Tucker (KKT) conditions [27], this shelf machine learning approaches, e.g., support vector machine (SVM) [9], Gaussian process regression (GPR) or Kriging model [10–12] and radial basis function networks (RBFN) [13–15], can serve this purpose. objective functions or the uncertainty inferred from the model, also known as the acquisition function, e.g., expected improvement [16], upper conﬁdence bound [17] and probability of improvement [18], in GPR-assisted EAs [19]. from the search process for conducting expensive FEs. These newly evaluated solutions will thus be used to update the surrogate model accordingly. expensive objective function. objective functions. In particular, any existing EMO algorithm can be used to serve this purpose where we use NSGA-II, IBEA and MOEA/D for proof-of-concept purposes. step is designed to interpolate new candidate solutions along the manifold of the approximated surrogate Pareto-optimal set with regard to the non-dominated solutions obtained in the evolutionary search step. • Batch recommendation: Two types of simple and eﬀective batch recommendation mechanisms In our experiments, we generate six algorithm instantiations of our proposed framework based on the combinations of three baseline EMO algorithms and two batch recommendations mechanisms. Extensive experiments on 136 benchmark test problem instances with irregular PFs fully demonstrate the eﬀectiveness and superiority of our proposed algorithms against six state-of-the-art data-driven EMO algorithms. In particular, our proposed framework is featured with a faster convergence and a stronger resilience to various PF shapes. The rest of this paper is organized as follows. Section 2 ﬁrst gives some essential preliminaries including deﬁnitions pertinent to this paper along with a pragmatic overview of the existing developments in data-driven EMO. Section 3 delineates the technical details of our proposed framework step by step. The experimental results are presented and analyzed in Section 5. At the end, Section 6 concludes this paper and sheds some lights on potential future directions. In this section, we ﬁrst give some basic concepts pertinent to this paper. Thereafter, we brieﬂy overview some selected developments of data-driven EMO. The MOP considered in this paper is deﬁned as: where x = (x deﬁnes the search space. F : Ω → R Deﬁnition 3. The set of all Pareto-optimal solutions is called the Pareto-optimal set Theorem 1 (KKT conditions [27]). Let x {g(x) ≤ 0} independent. There exists vectors α = (α where α Remark 1. The objective and constraint functions are assumed to be continuously diﬀerentiable in the KKT conditions. Remark 2. The MOP (1) considered in this paper does not consider constraints, thus we ignore theP are proposed to pick up multiple candidate solutions from the non-dominated solutions obtained in the manifold interpolation step for expensive FEs. In particular, one is directly derived from the native environmental selection mechanism of the EMO algorithm used in the evolutionary search step while the other is based on the individual Hypervolume contribution. (x) ≤ f(x) for all i ∈ {1, ··· , m} and F(x) 6= F(x). ∈ Ω such that x x} and their corresponding objective vectors form the Pareto-optimal front ≥ 0, ∀i ∈ {1, ··· , m} andα= 1. λ∇g(x) part of equation (2) in the latter derivations. Figure 1: A conceptual illustration of the tangent vector(s) v of a point x on a manifold along with its corresponding tangent space T Corollary 1. The PF is a (m − 1)-dimensional piecewise continuous manifold under the KKT conditions. For any solution x section of the PF and {F( in R Deﬁnition 4. Let M be a continuously diﬀerentiable manifold, γ : (−, ) → M be a continuously diﬀerentiable curve on this manifold and it passes through x ∈ M where  > 0. Use t ∈ (−, ) to parameterize γ as γ(t) where γ(0) = x, the tangent vector of γ(0), denoted as v, is deﬁned as: where f ◦ γ(t) : (−, ) → M → R is a composite mapping. Deﬁnition 5. The set of all tangent vectors at x is called the tangent space of M at x, denoted as Theorem 2. Let M be a smooth manifold and x ∈ M, then dim(T returns the corresponding dimensionality. Remark 3. Fig. 1 gives a conceptual illustration of the tangent vector(s) v of a point x on a oneand a two-dimensional manifold, respectively, along with its corresponding tangent space T particular, the number of tangent vectors is dim(T Given a set of training data D = {(x by assuming f (x Gaussian noise. For each testing input vector z predicted as [29]: where X = (x covariance vector between X and z function, also known as a kernel, is used to measure the similarity between a pair of data samples x and x [28], so as the PS. ∈ Ω. This paper uses the Mat´ern 5/2 kernel without loss of generality and it is deﬁned as: where ρ is a positive hyper-parameter of the covariance function and d = Euclidean distance between x and x f(z), and the predicted variance V[g(x hyperparameters are learned by maximizing the log marginal likelihood function deﬁned as: In this paper, we assume that the mean function is a constant 0 and the inputs are noiseless. This section provides a pragmatic overview of the current developments of data-driven EMO. Interested readers are referred to some survey papers for details [7, 8, 30]. ParEGO [10] is one of the earliest attempts that extends the classic eﬃcient global optimization (EGO) algorithm to the context of multi-objective optimization. During each iteration, it randomly generates a weight vector to constitute a scalarizing function of the original MOP. It uses a Kriging model to ﬁt a surrogate model of the underlying scalarizing function, based on which an EA is used to search for the next point of merit by optimizing the expected improvement. In [31], Emmerich et al. proposed to use Hypervolume measure as an alternative of scalarizing function to derive a couple of acquisition functions for multi-objective EGO. The similar idea is further exploited in [32] and [33]. Later, Zhang et al. [11] proposed a MOEA/D version of EGO, dubbed MOEA/D-EGO. It applies the GPR to ﬁt a surrogate model for each expensive objective function, based on which they derived the estimated mean and variance of the corresponding scalarizing function. Then, a regular MOEA/D routine is used to search for the approximated PF. In addition, they developed a batch recommendation mechanism to pick up more than one candidate solution for expensive FEs at the end of each iteration. In [12], K-RVEA is proposed for expensive many-objective optimization problems. To tackle the problems with irregular PFs, Habib et al. [26] proposed HSMEA that takes advantages of the interplay of multiple surrogate models and two sets of reference vectors. In addition, it applies a local search to further exploit high quality inﬁll solutions. To have a well balance between exploration and exploitation, Wang et al. proposed to tune the hyperparameters of the acquisition function in EGO according to the search dynamics on the ﬂy [34]. In addition to EGO, some other machine learning models have also been studied in data-driven EMO. For example, Voutchkov and Keane [35] proposed a simple idea to directly apply a GPR model to replace the expensive objective functions in NSGA-II. At the end of each iteration, the current best candidate solutions in terms of ranking and space ﬁlling properties are chosen for conducting expensive FEs. In view of the high computational complexity of GPR, Guo et al. [21] proposed a heterogeneous ensemble model based on least square SVM and RBFN for surrogate modeling. To identify the inﬁll solution(s) for expensive FEs, an ensemble generation method is proposed to quantify the uncertainty of sample points. In [13–15], RBFN are used as the surrogate model to drive the search process. Instead of a regression model, Pan [36] and Zhang et al. [37] proposed to use a classiﬁcation model to drive the surrogate search routine. Diﬀerently, Loshchilov [9] and Seah et al. [38] proposed to ﬁt a surrogate model that predicts the Pareto dominance relation between pairs of solutions. Diﬀerent from the above mentioned works, another emerging area is to use transfer learning techniques to boost the search process. For example, Luo et al. [39] proposed to use a multi-task GPR model to build multiple surrogate models simultaneously for diﬀerent subregions of the PF. In addition, a new inﬁll criterion based on the surrogate landscape is proposed to determine the next candidate solution for conducting the expensive FE. Min et al. [40] proposed to use the transfer stacking technique to jump start the underlying problem-solving routine by leveraging the model built for other related problems. In [41], Yang et al. proposed an EA assisted by two surrogate models. One model aims to guide the algorithm to quickly ﬁnd a promising subregion in the search space and the other one focuses on leveraging good solutions according to the knowledge transferred from the ﬁrst model. In the classic multi-objective optimization literature, the KKT conditions have been applied to solve bi-objective design optimization problems [42]. Later, this idea was generalized to MOPs with any number of objectives in theory [28,43]. It is worth noting that all these approaches are developed upon the assumption that the objective functions are analytically accessible and diﬀerentiable. In addition, they only considered a local expansion of an known Pareto-optimal solution. Another line of research is [44] that developed a proximity measure based on KKT optimality theory. This measure was originally designed to evaluate the convergence of a set of non-dominated solutions with regard to the PS. Later, it has also been used as either a driving force or a termination criterion of a local search procedure in NSGA-III [45–47] The ﬂowchart of our proposed batched data-driven EMO framework based on manifold interpolation is shown in Fig. 2. It starts with an initialization step based on an experimental design method [48]. In this paper, we use the classic Latin hypercube sampling to serve this purpose without loss of generality. Then, we evaluate the objective function values of these initial samples and store them in the training dataset. During the main loop, the surrogate modeling step builds a surrogate model for each expensive objective function based on the up-to-date training dataset. In particular, we apply the GPR as the surrogate model in view of its continuously diﬀerentiable characteristics. As for the other three steps, we will delineate their implementations in the following paragraphs. The evolutionary search step aims to approximate the PF based on the surrogate model built in the surrogate modeling step. We argue that any existing EMO algorithm can be used as the surrogate optimizer in this step. In particular, we directly use the surrogate model to replace the expensive objective functions in the EMO algorithm. This paper applies three iconic EMO algorithms, i.e., NSGA-II, IBEA and MOEA/D, for a proof-of-concept purpose. For the sake of being self-contained, we brieﬂy describe their working mechanisms as follows. This is one of most popular dominance-based EMO algorithms in the literature. It uses the Pareto dominance to promote the convergence and the crowding distance to maintain the population diversity. The general working mechanism of NSGA-II is given as follows. Step 2: Use crossover and mutation to generate a population of oﬀspring Q. Figure 2: Flowchart of the our proposed batched data-driven EMO framework. F, F, ···. time equals or exceeds N, where P =F. In particular, Fis the last acceptable nondomination front. If the size of P equals N, then let P = P and go to Step 6; otherwise go to Step 5. Remove the last |P|− |P| solutions from P and let P = P. Step 6: If the stopping criterion is met, then stop and output P. Otherwise, go to Step 2. The basic idea of IBEA is to transform a MOP into a single-objective optimization problem in terms of a binary performance indicator. Then it directly uses this indicator in the environmental selection process. The general working mechanism of IBEA is given as follows. Step 2: Use crossover and mutation to generate a population of oﬀspring Q and let P = P Step 4: If the stopping criterion is met, then stop and output P. Otherwise, go to Step 2. Remark 4. The ﬁtness value of a solution x is calculated as: where κ is a user deﬁned scaling factor and we set κ = 0.05 [3]. I(·, ·) is a binary quality indicator and we use the I where I Hypervolume of the space that is dominated by B but not by A. The basic idea of MOEA/D is to decompose the original MOP into several subproblems and it uses a population-based technique to solve these subproblems in a collaborative manner. Given a weight vector w, this paper uses the Tchebycheﬀ function [49] as a subproblem: where z three-step process. Step 3: If the stopping criterion is met, then stop and output the population. Otherwise, go to Step Step 3.1: Find the solution x= argminF (x) and remove it from P, i.e., P = P \{x}. Step 3.2: Update the ﬁtness values of solutions in P, i.e., ∀x ∈ P, F (x) = F (x)+e. Let P = P and go to Step 4. (A) is the Hypervolume of the objective space dominated by A and I(A, B) evaluates the is the ideal point. The general working mechanism of MOEA/D is given as the following their neighborhood structure. Randomly assign each solution to a weight vector. Step 2.1: Randomly select a required number of mating parents from w’s neighborhood. Step 2.2: Use crossover and mutation to reproduce an oﬀspring x. Step 2.3: Use xto update the subproblems within the neighborhood of w. Remark 5. In Step 1, we use the Das and Dennis’s method [50] to initialize a set of evenly distributed weight vectors from a canonical simplex. The neighborhood structure B(i) of each weight vector w i ∈ {1, ··· , N}, contains its T closest weight vectors, where T = 20 as suggested in [51]. Remark 6. In Step 2.1, to improve the exploration ability, there is a small probability δ = 0.1 to select mating parents from the whole population as suggested in [51]. Remark 7. Each subproblem is associated with a unique solution. In Step 2.3, x particular subproblem w if and only if g(x associated with w. Remark 8. In Step 2.3, x than merely in B(i). After the evolutionary search step, we obtain a population of solutions P that approximate the surrogate PF. Here we assume that these solutions are Pareto-optimal thus they all satisfy the KKT conditions. According to Corollary 1, ∀x ∈ P, the PS segment with regard to an open neighborhood Ξ(x) is a (m −1)-dimensional manifold, denoted as M basic idea of this manifold interpolation step is to interpolate a set of solutions S = { where v In the following paragraphs, we will derive a closed form method to calculate the tangent vectors. To facilitate our derivation, as in Deﬁnition 4, we use a parametric form x(t) where t ∈ (−, ) to represent each solution on a smooth curve passing through x on M According to Corollary 1, we have ∀x(t) ∈ Ξ(x) satisﬁes the KKT conditions. We assume that there exist a time-varying parameter vector α(t) = (α where α M→ R on the manifold as in Deﬁnition 4 where i ∈ {1, ··· , m}. By taking the derivatives of equation (12) at t = 0, we have: Given that where J (f(x(0)), ··· , f m − 1 diﬀerent x is the i-th tangent vector at x and η∈ (0, 1] is a random scaling factor along that direction. (t) ≥ 0 andα(t) = 1. f(x(t)) is actually a composite mapping f◦ x(t) : (−, ) → Figure 3: Examples of interpolated solutions (denoted as grey circles) generated by the manifold interpolation. Remark 9. Let us rewrite equation (13) as follows: The left hand side of equation (15) is thus a linear combination of {∇f subspace spanned by them. We take the inverse of H Remark 10. As shown in equation (11), this manifold interpolation step implements a random walk along the tangent space of x. In principle, the generated solutions constitute a piece-wise linear approximation to the corresponding PS and PF segments within a neighborhood. Fig. 3 gives two examples of manifold interpolation at a given point on the 2-objective ZDT3 and the 3-objective DTLZ2. To constitute the Jacobian matrix and the Hessian tensor used in equation (14), we need to access the ﬁrst- and second-order derivatives of the underlying objective functions. In this paper, since the objective functions are modeled by the GPR, which is continuously diﬀerentiable, we can naturally derive the ﬁrst- and second-order derivatives of the predicted mean function with regard to a candidate solution x as: where the ﬁrst- and second-order derivatives of k calculated as: where d is the vector of distances between P and x. In summary, the working mechanism of this manifold interpolation step is given as follows. Step 1: Initialize the candidate solution set S = ∅. Step 3: Use the GPR model to predict the objective function values of solutions in S. Step 4: Output the non-dominated solutions in S. This step is also known as the inﬁll criterion in the surrogate-assisted EA literature. It aims to pick up ξ ≥ 1 promising solutions from C = P functions. These newly evaluated solutions are then used to update the training dataset for the next iteration. Diﬀerent from most, if not all, works using GPR as the surrogate model, our inﬁll criterion does not rely on an uncertainty quantiﬁcation measure, also known as acquisition function in the Bayesian optimization literature [52]. Furthermore, selecting a batch of samples to evaluate can signiﬁcantly reduce the overhead for surrogate modeling. More speciﬁcally, we propose two alternative ways to implement this batch evaluation step. • The ﬁrst one is based on the individual Hypervolume contribution (IHV), independent of the • The other one is directly derived from the native environmental selection of the baseline EMO Step 2.1: Calculate the tangent vectors of x∈ P by solving the system of linear equations Step 2.2: Use equation (11) to generate a set of N =candidate solutions S = {ˆx|ˆx= Step 2.3: Remove invalid solutions in S outside of Ω. Step 2.4: S = SS. underlying baseline algorithm. We calculate the IHV of each candidate solution x ∈ C as: where HV(C) evaluates the Hypervolume (HV) [53] of C. Then, the top ξ solutions in C with the largest IHV are picked up for the expensive evaluations. algorithm used in the evolutionary search step. – If the baseline algorithm is NSGA-II, we propose a four-step process for the batch recommendation. Step 1: Identify the non-dominated solutions in C and store them in C. Step 2: Use N evenly distributed weight vectors to divide the objective space into N subregions Step 3: Pick up the best solution with the largest crowding distance for each subregion to Step 4: Pick up the top ξ solutions from˜C with the largest crowding distances. – If the baseline algorithm is IBEA, we can directly use its ﬁtness function to choose ξ best solutions. – If the baseline algorithm is MOEA/D, we propose the following three-step process for the batch recommendation. Step 1: For each subproblem g(·|w, z) where i ∈ {1, ··· , N }, identify the best solution xin Step 2: Calculate the ﬁtness improvement on each subproblem with respect to the previous As introduced in Section 3.1, any existing EMO algorithm can be used in the evolutionary search step. With regard to the two batch recommendation methods introduced in Section 3.3, we propose six algorithm instances for a proof-of-concept purpose, dubbed as DMI-x-IHV by using the IHV for the batch recommendation or DMI-x by using the native environmental selection, respectively, where x is either NSGA-II, IBEA or MOEA/D. This section introduces the experimental settings for validating the eﬀectiveness of our proposed batched data-driven EMO framework compared against some state-of-the-art algorithms. In our empirical study, we only consider benchmark test problems with irregular PF shapes to constitute our benchmark suite [54–89]. More speciﬁcally, it consists of ZDT3 [90], DTLZ7 [91], minus DTLZ2 [92], mDTLZ2 [93], WFG2 [94], WFG41 to WFG48 [95]. Furthermore, based on ZDT3, DTLZ7 and WFG2, we develop a series of problems with a controllable number disconnected regions and imbalanced sizes. Their mathematical deﬁnitions are as follows. • ZDT3? • DTLZ7? Step 3: Pick up the top ξ solutions of which the associated subproblems having the largest where • WFG2? Note that the A determines the number of disconnected regions of the PF. α controls the overall shape of the PF where α > 1, α < 1 and α = 1 leads to a concave, a convex and a linear PF, respectively. β inﬂuences the location of the disconnected regions. In our experiments, we instantiate 7 test problem instances, the settings used in our experiments are given in Table 1. Fig. 4 gives the illustrative examples of their PFs. The number of objectives is set to m = 2 for the ZDT and m = 3 for the DTLZ problems. As for the WFG problems, we consider both 2- and 3-objective cases. The number of variables is set as n ∈ {5, 10, 20, 30} respectively for each benchmark test problem. In total, there are 136 test problem instances considered in our experiments. To validate the competitiveness of our proposed algorithms, we compare their performance with six state-of-the-art algorithms in the literature, including ParEGO [10], MOEA/D-EGO [11], K-RVEA [12], EIM [20], TSMEA [96] and HSMEA [26]. We do not intend to delineate their working mechanisms here while interested readers are referred to their original papers for details. The parameter settings are listed as follows. • Number of function evaluations (FEs): The initial sampling size is set to 11 × n − 1 for all • Reproduction operators: The parameters associated with the simulated binary crossover and • Kriging models: As for the algorithms that use Kriging for surrogate modeling, the corresponding whereP where x∈ [0, 1], i ∈ {1, ··· , n}. where the deﬁnitions of s linear(·), r nonsep(·), r sum(·), convexand disc(·) can be found in [94]. algorithms and the maximum number of FEs is set as 150 and 250 for m = 2 and 3, respectively. polynomial mutation are set as p= 1.0, η= 20, p=, η= 20. As for those use diﬀerential evolution for oﬀspring reproduction, we set CR = F = 0.5. hyperparameters of the MATLAB Toolbox DACE [97] is set to be within the range [10, 10]. • Batch size ξ: It is set as ξ = 10 for our proposed algorithms and ξ = 5 is set in MOEA/D-EGO, • Number of repeated runs: Each algorithm is independently run on each test problem for 31 In our experiments, we use the HV as the performance metric to assess the performance of diﬀerent peer algorithms. To have a statistical interpretation of the signiﬁcance of comparison results, we use the following three statistical measures in our empirical study. • Wilcoxon signed-rank test [98]: This is a non-parametric statistical test that makes little assump- • Scott-Knott test [100]: Instead of merely comparing the raw HV values, we apply the Scott-Knott Note that both Wilcoxon signed-rank test and A generating clusters. We seek to answer the following research questions (RQs) through our empirical study in the following paragraphs. • RQ1: How is the performance comparison among our proposed six algorithm instances? • RQ2: How is the performance of our best, medium and worst algorithm instances compared • RQ3: What is the beneﬁt of manifold interpolation? • RQ4: What are the impacts of hyperparameters? K-RVEA and HSMEA. be generated by the manifold interpolation step and it is set as˜N = 100 in our experiments. times with diﬀerent random seeds. tion about the underlying distribution of the data and has been recommended in many empirical studies in the EA community [99]. In particular, the signiﬁcance level is set to p = 0.05 in our experiments. test to rank the performance of diﬀerent peer techniques over 31 runs on each test problem. In a nutshell, the Scott-Knott test uses a statistical test and eﬀect size to divide the performance of peer algorithms into several clusters. In particular, the performance of peer algorithms within the same cluster are statistically equivalent. Note that the clustering process terminates until no split can be made. Finally, each cluster can be assigned a rank according to the mean HV values achieved by the peer algorithms within the cluster. In particular, since a greater HV value is preferred, the smaller the rank is, the better performance of the technique achieves. eﬀect size [101]: To ensure the resulted diﬀerences are not generated from a trivial eﬀect, we apply Aas the eﬀect size measure to evaluate the probability that one algorithm is better than another. Speciﬁcally, given a pair of peer algorithms, A= 0.5 means they are equivalent. A> 0.5 denotes that one is better for more than 50% of the times. 0.56 ≤ A< 0.64 indicates a small eﬀect size while 0.64 ≤ A< 0.71 and A≥ 0.71 mean a medium and a large eﬀect size, respectively. against state-of-the-art algorithms in the literature? Figure 5: Violin plots of Scott-Knott test ranks achieved by each of the six algorithm instances of our proposed framework (the smaller rank is, the better performance achieved). Figure 6: Total Scott-Knott test ranks achieved by each of the six algorithm instances of our proposed framework (the smaller rank is, the better performance achieved). The statistical comparison results of HV values, based on the Wilcoxon signed-rank test, among six algorithm instances introduced in Section 3.4 are given in Tables 1 to 4 of our supplementary materials close to each other; while the best algorithm alternates across diﬀerent test problem instances. To facilitate a better ranking among these algorithms, we apply the Scott-Knott test to classify them into diﬀerent groups according to their performance on each test problem instance. Due to the large number of test problem instances used in our experiments, it will be messy if we list all ranking results (136 ∗ 6 = 816 in total) obtained by the Scott-Knott test collectively. Instead, to have a better interpretation of the comparison among diﬀerent algorithm instances, we pull all the Scott-Knott test results together and show their distribution and variance as violin plots in Fig. 5. In addition, to facilitate an overall comparison, we further summarize the Scott-Knott test results obtained across all test problem instances for each algorithm instance and show them as the bar charts in Fig. 6. From these results, we can see that using the IHV in the batch recommendation has shown to be consistently better than the native environmental selection mechanism in NSGA-II, IBEA and MOEA/D. In particular, we clearly see that DMI-MOEA/D-IHV is the best algorithm instance of our proposed framework given that 1) its performance has been classiﬁed into the best group in most comparisons as the violin plots shown in Fig. 5; and 2) it obtains the smallest summation rank as shown in Fig. 6 (it is at least 30% better than the other ﬁve peer algorithms). DMI-NSGA-II is the worst algorithm instance, the inferior results obtained by which can be attributed to the use of the crowding distance. In particular, due to a large number of candidates solutions generated by the manifold interpolation, the overly crowded local niche makes the crowding distance less discriminative. As the example shown in Fig. 8, since the interpolated solutions are heavily crowded, the crowding distance always recommends the one lying in the boundary of the interpolated region whereas the internal . From these results, we can see that the HV values obtained by diﬀerent algorithms are Figure 7: Percentage of the large, medium, small, and equal A paring DMI-MOEA/D-IHV with other ﬁve peer algorithm instances. solutions are ignored. In this case, it compromises the extra diversity provided by the manifold recommendation step. However, by using the IHV as an alternative of the crowding distance in the batch recommendation, the performance of DMI-NSGA-II-IHV is signiﬁcantly promoted while it even obtains a better ranking than DMI-MOEA/D and DMI-IBEA. Figure 8: Illustrative example of the drawback of using the crowding distance in DMI-NSGA-II. At the end, we choose DMI-MOEA/D-IHV as a representative algorithm to compare the diﬀerence of its performance with respect to the other ﬁve peer algorithms by using the A Since the calculation of A piecemeal A the equivalent, small, medium and large eﬀect size, respectively, with respect each of the other ﬁve peer algorithms (note that there is barely equivalent case in these comparisons). From the statistical results shown in Fig. 7, it is interesting to note that DMI-MOEA/D-IHV has shown dominantly better results comparing to DMI-NSGA-II and DMI-NSGA-II-IHV where the large eﬀect sizes are all over 90%. In contrast, the eﬀect sizes with regard to DMI-IBEA, DMI-IBEA-IHV and DMI-MOEA/D are relatively comparable. Answers to RQ1: We have the following takeaways from our experiments. 1) DMI-MOEA/D-IHV is the best algorithm instance of our proposed framework while DMI-NSGA-II-IHV and DMI-NSGA-II are the medium and worst ones respectively. 2) Owing to the unique characteristics of HV for measuring convergence and diversity simultaneously, the IHV has shown to be a better mechanism for guiding the batch recommendation. 3) In contrast, the crowding distance used in NSGA-II is too coarse-grained to pick up representative solutions from a large amount of candidates; 4) MOEA/D is the best baseline surrogate optimizer in the evolutionary search step while NSGA-II is the worst both for using the IHV and the native environmental selection in the batch recommendation. Figure 9: Non-dominated solutions found by diﬀerent algorithms with the best HV values on ZDT31 (n = 30). Figure 10: Non-dominated solutions found by diﬀerent algorithms with the best HV values on DTLZ72 (n = 30). Similar to Section 5.1, we ﬁrst pull all statistical comparison results of HV values, based on the Wilcoxon signed-rank test, among each of our six algorithm instances as introduced in Section 3.4 with regard to the other six state-of-the-art peer algorithms as introduced in Section 4.2 in Tables 1 to 4 of our supplementary materials. From these results, we ﬁnd that the HV values obtained by our algorithm instances are better than the other six peer algorithms in most comparisons, even for DMI-NSGA-II, our least competitive algorithm instance. To have a better visual interpretation of the superiority achieved by our algorithm instances, let us look into the population distribution of the non-dominated solutions against the other six peer algorithms. Due to the page limit, we only show a couple of examples in Figs. 9 to 11 while the complete results can be found in the supplementary materials. From these plots, it is clear to see that our proposed algorithms not only converge well to the PF, but are also resilient to the PF shapes. Especially for those with disconnected PF segments, our proposed algorithms can approximate all segments with a reasonable diversity. In contrast, the other peer algorithms are either struggling on converging to the PF or hardly approximate all disconnected PF segments. It is interesting to note that all algorithms have shown comparable results on WFG41 to WFG48 problems with two objectives. But the performance of the other six peer algorithms degrade signiﬁcantly when they go to the three-objective cases. Another interesting observation is that the increase of the number of variables do not downgrade the performance of our proposed algorithms. As in Section 5.1, we apply the Scott-Knott test to sort the performance of each algorithm instance against the other six peer algorithms on all test problem instances. To facilitate a better interpretation of these massive comparison results, for each of our six algorithm instance, we pull 136 × 7 × 6 = 5, 712 comparison results collected from the Scott-Knott test together and show their distribution and variance as the violin plots in Fig. 12. From these results, we further conﬁrm that our six algorithm instances are always better than the other peer algorithms in the corresponding comparisons. Speciﬁcally, DMI-MOEA/D and DMI-MOEA/D-IHV are consistently ranked in the ﬁrst place Figure 11: Non-dominated solutions found by diﬀerent algorithms with the best HV values on WFG48 (n = 30). Figure 12: Violin plots of Scott-Knott test ranks achieved by each of the six algorithm instances of our proposed framework versus the other six state-of-the-art peer algorithms (the smaller rank is, the better performance achieved). Figure 13: Percentage of the large, medium, and small A each of our proposed six algorithm instances against other six state-of-the-art peer algorithms. in all comparisons with regard to the other six peer algorithms. In contrast, the other four algorithm instances only have very few cases that are not ranked in the best place, even for DMI-NSGA-II. Again, we evaluate the A the other six state-of-the-art peer algorithms on each test problem instance. As in Section 5.1, we calculate the percentage of diﬀerent eﬀect sizes obtained by each algorithm instance against the other peer algorithms, respectively. Note that since there are very few equivalent cases, we only present the results of large, medium and small A Figure 14: Percentage of the large, medium, and small A each of our proposed six algorithm instances against its ablated variant without using the manifold interpolation step. conﬁrm the overwhelming advantage observed from the Scott-Knott test where the percentage of the large eﬀect size is always close to 100% in all comparisons. Answers to RQ2: We have the following takeaways from our experiments. 1) All algorithm instances of our proposed framework have shown consistently better performance over the state-of-the-art surrogate-assisted EMO algorithms in the literature, even for DMI-NSGA-II, our worst algorithm instance. 2) The overwhelmingly better performance achieved by our proposed framework can be attributed to the manifold interpolation step that help interpolates the approximated PS manifold thus signiﬁcantly increases the population diversity for exploring disconnected regions. The empirical study in Section 5.2 has shown overwhelmingly better performance of our proposed framework against the selected state-of-the-art surrogate-assisted EMO algorithms. Referring to Fig. 2, we can see the manifold interpolation step is the unique component of our proposed framework. To address RQ3, we plan to investigate the usefulness of this manifold interpolation step through an ablation study. To this end, we compare the performance between the algorithm instances under our proposed batched data-driven EMO framework against the corresponding ablated counterpart without using the manifold interpolation step. Accordingly, it is denoted as the one without the DMI preﬁx. From the statistical comparison results of HV values, based on the Wilcoxon signed-rank test, shown in Tables 5 and 6 in the supplementary materials along with the A we have witnessed a clear performance degradation when ablating the manifold interpolation step without any exception. It is worth noting that their performance is worse than most of the selected state-of-the-art algorithms considered in Section 5.2 by referencing Tables 1 to 4 in the supplementary materials. As an example shown in Fig. 15, we can see that non-dominated solutions obtained by MOEA/D-IHV cannot fully approximate all disconnected PF segments. Without using the manifold interpolation step, MOEA/D-IHV is merely guided by the surrogate model which is highly likely to be guided to some local regions. This can be explained as the evolutionary population is far away from the PF at the early stage of the evolution. In contrast, the manifold interpolation step brings more diversiﬁed candidates in the survival competition. Let us consider an illustrative example shown in Fig. 16. Without using the manifold interpolation, MOEA/D-IHV can only obtain the solution, denoted as the green square, lying the same PF segment of previously evaluated solutions. On the other hand, because of the interpolated solutions, DMI-MOEA/D-IHV is able to explore under discovered PF segment as spotted by the red square. Moreover, since the interpolated solutions are along the currently approximated PF rather than purely random solutions, they are prone to have a promising convergence property. Figure 15: Comparative example of DMI-MOEA/D-IHV against its counterpart where the manifold interpolation is ablated on ZDT31 (n = 30). Figure 16: Illustrative example of the eﬀectiveness of having manifold interpolation step. Answers to RQ3: The manifold interpolation step is essential in our proposed framework. It not only brings suﬃcient diversity to expand the population, the interpolated solutions also have a promising convergence property given that they are interpolated along the approximated PS manifold. As a result, it enables our algorithms to have a faster convergence rate and a better ability to approximate diﬀerent disconnected PF segments. In our proposed batched data-driven EMO framework, there are two hyper-parameters including the batch size ξ and the number of interpolated solutions address RQ4, we choose DMI-MOEA/D-IHV as the baseline and empirically investigate its performance under diﬀerent ξ = {5, 10, 20} and From the statistical comparison results of HV values, based on the Wilcoxon signed-rank test, shown in Tables 7 and 8 in the supplementary materials along with the A we can see that the performance of DMI-MOEA/D-IHV is the comparable when setting ξ = 5 and ξ = 10 where 81% of the comparison results are statistically equivalent. Given a limited amount of FEs, a smaller ξ leads to more iterations as in our proposed framework thus it is more time consuming. Fig. 18 gives the comparison of CPU wall clock time among diﬀerent ξ settings. From this ﬁgure, we can see that DMI-MOEA/D-IHV is multiple times slower when ξ = 5 than those of ξ = 10 and ξ = 20. In addition, as an example shown in Fig. 19, using a too small ξ may compromise the chance for exploring under discovered PF segment(s) as solution #7 (denoted as ×) lying in a new segment. On the other hand, although it is faster when picking up more solutions in the bath recommendation step by setting a larger ξ, the surrogate model becomes less resilient to local optima due to the reduced iterations for updating the surrogate model. As the comparison results of A Figure 17: Percentage of the large, medium, small, and equal A comparing DMI-MOEA/D-IHV with our recommended ξ and Figure 19: Illustrative example of batch recommendation results between ξ = 5 and ξ = 10. Specifically, Solutions #1 to #5 (denoted as ×) are recommended when ξ = 5 while solutions #1 to #10 are recommended by setting ξ = 10. to see the large performance degradation when increasing ξ to 10. As the comparison results shown in Tables 9 and 10 in the supplementary materials along with the A is signiﬁcantly degraded when having too small interpolated solutions (i.e., not make statistically meaningful diﬀerence when we further increase time is signiﬁcantly increased in the batch recommendation step when having a large amount of interpolated solutions. Answers to RQ4: We have the following takeaways from our experiments. 1) The batch size ξ can inﬂuence the performance of DMI-MOEA/D-IHV where a too small ξ makes the chosen solutions to be less representative with regard to the PF whereas a too large ξ renders the surrogate model less resilient to local optima. 2) The performance of DMI-MOEA/D-IHV is not sensitive to the number of interpolated solutions Figure 18: Collected comparisons of CPU wall clock time when using diﬀerent ξ settings. eﬀect size shown in Fig. 17, it is interesting to note that the performance of DMI-MOEA/D-IHV This paper proposed a batched data-driven EMO framework for solving computationally expensive MOPs. It has three distinctive features. First, this framework is so general that any existing EMO algorithm can be applied in a plug-in manner as the surrogate optimizer in the evolutionary search step. Second, based on the KKT conditions, its manifold interpolation step interpolates along the approximated PS manifold to generate more diversiﬁed candidate solutions with a convergence guarantee. Last but not the least, it provides two types of approach in the batch recommendation step to evaluate multiple promising solutions for expensive FEs in parallel. Extensive experiments on 136 benchmark test problem instances with various irregular PFs fully demonstrate the eﬀectiveness and overwhelming superiority against six state-of-the-art EMO algorithms. In particular, our ablation study validates that the manifold interpolation step is essential within our proposed framework. Data-driven evolutionary optimization has been an emerging area given the pressing requirements of sample-eﬃcient real-world applications in various disciplines. In view of the strong performance and simple architecture of our proposed batched data-driven EMO framework, we envisage several aspects for future endeavors as follows. • This paper only considers problems with two- and three- objectives given the already over- • In addition to the scalability in the objective space, the increase of the number of variables, as • Real-world problems are usually accompanied with various constraints, the existing of which • Last but not the least, many exciting real-world applications, ranging from engineering design Figure 20: Collected comparisons of CPU wall clock time when using diﬀerent˜N settings. whelming superiority against the selected state-of-the-art. One of the future directions is to extend it for many-objective optimization problems. A typical challenge is the ineﬀectiveness of the sampling strategy suggested in equation (11) for high-dimensional problems. On the other hand, sampling too many candidate solutions during the manifold interpolation step incurs signiﬁcantly mounting complexity in the batch recommendation step. known as large-scale multi-objective optimization, also brings in signiﬁcant challenges in both surrogate modeling and evolutionary optimization. One tentative way to combat the curseof-dimensionality is divide-and-conquer that decomposes the original large-scale problem into smaller ones. render the search space to be teared up into fragments. These lead to challenges in sampling and surrogate modeling since infeasible solutions tend to be useless in model building. to machine learning, are featured with multiple conﬂicting objectives and computationally expensive FEs. It is impactful to apply data-driven evolutionary optimization for those complex black-box problems. K. Li was supported by UKRI Future Leaders Fellowship (MR/S017062/1), EPSRC (2404317) and Amazon Research Awards.