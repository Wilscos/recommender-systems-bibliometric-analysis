packages:pcalg(with add-ons can be used with observational data and in the presence of mixed data (i.e., data where some variables are continuous, while others are categorical), a known time ordering between variables, and missing data. Throughout, we point out the relative strengths and limitations of each package, as well as give practical recommendations. We hope this guide helps anyone who is interested in performing constraint-based causal discovery on their data. 3.2 Mixed measurement scales . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 3.3 Repeated measurements and time ordering . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 3.4 Missing data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 3.5 Additional topic: Causal eﬀect estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 Causal graphs provide an intuitive, yet theoretically founded, way of representing causal relationships between variables. The aim of causal discovery is to learn a graph from data. Broadly, causal discovery algorithms belong to one of three classes: (1) constraint-based approaches, e.g. the PC algorithm (Spirtes et al., 2000), (2) score-based approaches, e.g. greedy equivalence search (Chickering, 2002), or (3) approaches based on functional causal models, e.g. LiNGAM (Shimizu et al., 2006). Constraint-based approaches, which are the focus of this guide, place the problem of causal discovery within the framework of a series of conditional independence hypothesis tests. These algorithms attempt to generate causal graphs with structures consistent with the conditional independence relationships found in the data. An advantage of constraint-based algorithms is that they are rather ﬂexible in terms of the conditional independence tests that could be used. In addition, causal suﬃciency can sometimes be relaxed (Spirtes et al., 2000). A notable disadvantage, however, of constraint-based algorithms is that any error(s) made are propagated through the algorithm (e.g., an edge mistakenly deleted early in the PC algorithm cannot be recovered later). While the “gold standard” for discovering causal relationships is a randomized controlled trial, investigators often are interested in questions that can only be answered with observational data for practical and/or ethical reasons. Observational cohort data introduces a number of challenges for causal discovery. For example, missing data are ubiquitous in cohort studies because of dropout, incomplete assessments, or missed visits. When data are not missing completely at random, conditional independences found in a complete case analysis (i.e., after deleting any incomplete data rows) may diﬀer from those that would be found if the data were complete, even if the sample size is large. Therefore, causal discovery algorithms may generate incorrect graphs in the presence of missing data. When the cohort is followed over time, this can introduce additional complexities. For example, it is known that events in the future cannot cause those in the past, and repeated measurements from the same individual will be correlated over time. This so-called temporal ordering and repeated measures data must be accounted for in the causal discovery algorithms. Further, cohort studies usually collect information on many diﬀerent variables that can be continuous, binary, ordinal, or categorical; however, many causal discovery algorithms cannot accommodate such “mixed” data and require that all variables considered either be continuous or binary. While there are many introductory papers on causal discovery (Kalisch and Bühlmann, 2014; Spirtes and Zhang, 2016; Heinze-Deml et al., 2018; Malinsky and Danks, 2018; Glymour et al., 2019), none focuses on the actual implementation of the various algorithms in standard software. Therefore, information on the available causal discovery software packages are scattered across the literature (usually as software manual or Rpackage vignette), which makes it more diﬃcult for users to compare and contrast them. In this paper, we aim to provide a practical guide for carrying out causal discovery via three of the most popular software implementations: the Java-based TETRAD software package (Scheines et al., 1998), the (Scutari, 2010), and the tpc(Witte, 2021) andmicd constraint-based PC algorithm and how it is implemented in each software package. The paper is organized as follows. In Section 2, we provide a brief introduction to basic causal discovery terminology, followed by introductions to function(s) within each package that are used to implement the PC algorithm and their required inputs. In Section 3.1, we provide background on the simulated data we are using in the examples throughout the guide. In Sections 3.2, 3.3, and 3.4, we expand on Section 2 by illustrating how each causal discovery software package can be used in the presence of mixed data, time ordering, and missing data, respectively. A special focus is on how the new packages a brief discussion of causal eﬀect estimation after learning a causal graph in Section 3.5, and some general advice and recommendations in Section 4. At a basic level, the goal of causal discovery is to generate potential causal graphs from data, statistical algorithms, and background knowledge. A graph consists of nodes and edges, which correspond to the variables in the graph and the arrows between these variables, respectively. A graph that consists only of directed edges and contains no cycles (i.e., one cannot start at a node and arrive back at the same node on the graph by following the direction of the edges on the graph) is called a directed acyclic graph (DAG). A causal DAG is a DAG in which the presence of an edge between nodes indicates a belief that there is a direct causal relation; the absence of an edge between nodes indicates the absence of a direct causal relation. Another Rpackagepcalg(Kalisch et al., 2012; Hauser and Bühlmann, 2012) with its add-ons (Foraita et al., 2020; Witte et al., 2021). For simplicity, we will focus only on the feature of a causal DAG is that all causes (even if unmeasured) are on the graph. For causal discovery, we therefore need to decide whether we believe that all relevant variables have been measured, in the sense that if two variables in the data share a common cause, then that common cause needs to be included in the data as well. This assumption is called causal suﬃciency and is required by PC and many other causal discovery algorithms. If causal suﬃciency cannot be assumed, other constraint-based algorithms such as the ‘Fast Causal Inference’ (FCI) algorithm (Spirtes et al., 2000) can still be applied, but they produce a less informative output. Constraint-based causal discovery algorithms such as PC, on which we focus in this guide, build the graph based on conditional independences in the data, which are inferred using conditional independence testing. Since several DAGs can imply the same set of conditional independences (they are then said to be Markov equivalent and form a Markov equivalence class), PC is not able to distinguish between them. Therefore, even under ideal circumstances (inﬁnite sample size, all assumptions are true), the output of PC is not a DAG, but a completed partially directed acyclic graph (CPDAG) containing both directed and undirected edges. An undirected edge indicates that the algorithm determined that two nodes were related to each other, but it could not determine which node causes the other. If background knowledge is used during the search (e.g. in the form of required edges or a partial node ordering), then the output of PC is an estimated maximally oriented partially directed acyclic graph (MPDAG), which has the same interpretation as an estimated CPDAG. Depending on the software used, the output of PC may also contain bi-directed edges. These occur when diﬀerent conditional independence tests produce conﬂicting results. In contrast to the undirected edges, whose orientation cannot be determined even with an inﬁnite sample size, the bi-directed edges always point to conﬂicts that are due to the ﬁnite data. Below, we discuss what options for conﬂict resolution are oﬀered by the diﬀerent software packages. An important parameter of PC and similar algorithms is the p-value threshold, usually called conditional independence test performed by the algorithm returns a p-value, which is then used in order to make a yes-no decision: If the p-value of a particular test is smaller than dependence, otherwise an independence is concluded. Since concluding independence usually means deleting an edge from the estimated graph, First released in 2009, the functions to implement causal discovery algorithms and estimate causal eﬀects. In this guide, we consider version 2.7-3. (see www.cran.r-project.org/web/packages/pcalg/index.html for the latest version, along with vignettes). Inpcalg, the PC algorithm is implemented in the pc(suffStat, indepTest, alpha, labels, p, fixedGaps = NULL, fixedEdges = NULL, NAdelete = TRUE, m.max = Inf, u2pd = c("relaxed", "rand", "retry"), skel.method = c("stable", "original", "stable.fast"), conservative = FALSE, maj.rule = FALSE, solve.confl = FALSE, numCores = 1, verbose = FALSE) At a high level, the user must provide (indepTest) along with a p-value threshold statistic’). Depending on the chosen dataset itself. Users may also write their own package for handling missing data. The variable names are provided in ignored. Forbidden and required adjacencies may be speciﬁed in pcalgpackage (Kalisch et al., 2012; Hauser and Bühlmann, 2012) contains many nodesAandBare forbidden to be adjacent, then no edge of any orientation will appear between them in the estimated CPDAG or MPDAG, but it is not possible to specify that e.g. is allowed. If an adjacency between nodes estimated CPDAG or MPDAG, but the orientation is determined by the algorithm. TheNAdeleteinput determines what happens if the which is the default option, then each that an edge is deleted. The next inputs determine exactly which version of PC is used. Setting the eﬀect that only conditional independence tests up to a certain order (i.e., number of variables in the conditioning set) are performed. This can be useful if the runtime would be prohibitively long otherwise, or if the higher-order tests are believed to be too unreliable. We recommend sticking to the default (i.e., no restrictions) at least to start with. We further recommend setting = "stable", maj.rule = TRUE, solve.confl = TRUE on the order in which the variables appear in the dataset (see Colombo and Maathuis (2014) for details on the problem and the solution). This has the eﬀect that edges remain undirected whenever there is conﬂicting information about their orientation (when plotting the estimated graph using the these edges are shown as bi-directed edges). By specifying numCoresto an integer value larger than 1, parts of thus saving runtime without altering the output. Finally, into the console. Additional details on the Thetpc()function from the pc() with the following input structure: tpc(suffStat, indepTest, alpha, labels, p, forbEdges = NULL, m.max = Inf, conservative = FALSE, maj.rule = TRUE, tiers = NULL, context.all = NULL, context.tier = NULL, verbose = FALSE) In contrast topc(),tpc() "stable", solve.confl = TRUE specify directed edges that should not appear in the estimated CPDAG or MPDAG, e.g., forbid allowA ← B), or forbid both, with the eﬀect that there will be no edge between graph. This is analogous to the blacklist option of bnlearn discussed in the next section. The most important diﬀerence to options, which are explained below in Section 3.3.1. Thebnlearn(Bayesian network learning and inference) package (Scutari, 2010) was ﬁrst released in 2007. In this guide, we are using version 4.6.1. See the homepage (www.bnlearn.com) for helpful information. The PC algorithm is implemented through the pc.stable() function: pc.stable(x, cluster = NULL, whitelist = NULL, blacklist = NULL, test = NULL, The inputs topc.stable() inpcalg. For example, the a maximal conditioning set size ( detailed log output (debug = TRUE tpcpackage, available at www.github.com/bips-hb/tpc, is a modiﬁed version of does not support parallel computing, andu2pd = "relaxed", skel.method = have some similarities and many diﬀerences compared to thepc()function pc.stable()function also allows the user to set a p-value threshold (alpha), directly into the function ( (test) to be used can be chosen from among several inbuilt options; it is not possible to provide a user-built function. Thewhitelistandblacklist included in the estimated CPDAG or MPDAG, respectively. In contrast to pc.stable()also considers the speciﬁed orientations, making it possible e.g. to forbid A ← B, or to speciﬁcally force A ← B into the output. Overall,pc.stable()oﬀers fewer options for ﬁne-tuning the algorithm compared to package or TETRAD (see next section). Conﬂicts are dealt with by comparing p-values, where decisions corresponding to smaller p-values are given preference over those with larger p-values. Using this heuristic, pc.stable()always produces an order-independent output. However, there is no theoretical reason why the orientations obtained this way should be more likely than the alternative orientations not chosen. TETRAD is a Java program for causal discovery and structural equation modeling developed by researchers from the Center for Causal Discovery (CCD) (Scheines et al., 1998; Cooper et al., 2015) (www.ccd.pitt.edu/tools). Unlike user interface (GUI), and it is possible to perform causal discovery without writing any code, but R and Python interfaces are available from the CCD website as well. In this guide, we used GUI-based TETRAD version 6.9.0. To implement the PC algorithm in TETRAD, one must ﬁrst add a “Data” and “Search” box to the GUI and connect them with an arrow, see Figure 1. Then, the user can double click on the “Data” icon, and select File x) rather than the data’s suﬃcient statistics. The conditional independence test pc.stable()function can be found by typinghelp(pc.stable)into theRconsole. This brings up another GUI that allows for the speciﬁcation of various data features, like missing data markers, as shown in Figure 2. The user must validate the data with TETRAD before it is loaded. During the validation process, TETRAD checks for potential issues, like accidentally including a bookkeeping row (e.g., the variable names) as a data observation or not correctly labeling missing data values. If issues are found, TETRAD will display the row number(s) and issue(s) found so they can be corrected. After all validation checks are passed, the data can be loaded and search can be performed. When setting up a causal search, the ﬁrst thing that must be done after clicking on the “Search” icon is selecting the search algorithm, see Figure 3. Here, we tell TETRAD that we want to use the PC algorithm. In addition, we specify the conditional independence test to be used. The options to choose from depend on the measurement scales of the data; in Figure 3, the options for a dataset containing both numeric and discrete variables are shown. After choosing the algorithm, users can further specify options related to how the search should be performed, including how conﬂicts between edges are handled, maximal conditioning sets, p-value thresholds, and bootstrapping options, see Figure 4. More information on all options can be obtained by hovering the mouse over text in the “Search” box or by consulting the manual at www.github.com/cmu-phil/tetrad. Table 1 provides an overview of the capabilities of issues with cohort data. Details are discussed below after we introduced our synthetic cohort data. To make our examples easily replicable, we constructed synthetic data which is included in the which is modeled after real cohort data. The Identiﬁcation and Prevention of Dietary and Lifestyle-induced Health Eﬀects in Children and Infants (IDEFICS) study was a European prospective cohort study designed to investigate the relationship between non-communicable chronic diseases and dietary, lifestyle, behavioral, and socioeconomic factors among preschool and primary school aged children (Ahrens et al., 2006). The I.Family study (Ahrens et al., 2017) began as an extension of the IDEFICS study, with its baseline being the second IDEFICS follow-up visit. The cohort includes longitudinal data across the key development phases from toddler to adult. For this tutorial, we have mimicked IDEFICS/I.Family data in the following way: From the list of all IDEFICS/I.Family variables, we chose two baseline characteristics (sex and country), one genetic factor (high-risk alleles of the fat mass and obesity associated (FTO) gene), one early life factor (birth weight) and 10 variables that were measured in each of the three waves. See Table 2 for more information on all chosen variables. We speciﬁed the causal DAG in Figure 5 based on assumed causal mechanisms and on associations in the data. For the rest of this paper, we will refer to the DAG in Figure 5 as the true DAG, as it is the model generating the data used for illustration. We equipped the true DAG with a joint distribution by specifying how each variable Figure 3: Selecting a search algorithm in TETRAD. Table 1: Overview ofpcalg measurement scales, time-ordered variables, and missing data. pcalg/tpc/micdConditional Gaussian test bnlearnConditional Gaussian test ,tpc,micd,bnlearn, and TETRAD with respect to their ability to handle mixed Table 2: Variables in example dataset. Transformations were chosen such that the marginal distribution after transformation was roughly symmetric. baseline characteristics genetic factors early life factors time-dependent variables the values of its parents. For multinomial main eﬀects linear regression; for ordered categorical dataX, a main eﬀects Poisson model. In order to have realistic coeﬃcients, we estimated them from the IDEFICS/I.Family data. Using this data-generating process, we generated 5000 artiﬁcial observations (dataset dat_cohortin thetpc real data and found that the means and standard deviations were similar. The datasetdat_cohort_dis missing values. All three datasets will be used as examples in this guide. A causal discovery analysis using the real IDEFICS data is performed in Foraita et al. (2021). Cohort studies collect a mix of continuous or discrete measurements. For example, a typical epidemiologic cohort study will record participants’ age (continuous), race (categorical), and sex (binary), in addition to many other variables. Using “mixed data,” where variables are not all on the same measurement scale, in causal discovery, requires suitable tests for the mixed scales. Independence between purely continuous variables is usually tested with a partial correlation test, e.g., Fisher’s z-test or the partial correlation t-test, while independence testing between discrete variables is carried out with a use for mixed data. Andrews et al. (2018) proposed a likelihood ratio test (‘Conditional Gaussian test’) based on the Conditional Gaussian assumption, and Andrews et al. (2019) suggested to transform the categorical variables into 0-1 dummy variables and treat them as normally distributed afterwards (‘Degenerate Gaussian test’). Other, non-parametric options exist but are more involved and not covered here. To illustrate how each causal discovery implementation handles mixed data, it suﬃces to consider cross-section (i.e., baseline) data. Later, longitudinal data will be considered. package). We compared the marginal distributions of all variables to those in the where the continuous data have been discretized, and a datasetsdat_misswith ## install required packages #install.packages("pcalg") #install.packages("bnlearn") #devtools::install_github("bips-hb/tpc") #devtools::install_github("bips-hb/micd") ## load required packages library(bnlearn) library(pcalg) library(micd) library(tpc) ## load cohort data and create cross-sectional version of the dataset data("dat_cohort") dat_cross <- dat_cohort[ ,1:14] ## load discretized data and create cross-sectional version of the dataset data("dat_cohort_dis") dat_cross_dis <- dat_cohort_dis[ ,1:14] As mentioned previously, a required input to the independence tests will be carried out. A conditional independence test for mixed data, in thepcalgadd-onmicd It implements the likelihood-ratio test proposed by Andrews et al. (2018), which assumes that the variables in the test follow a Conditional Gaussian distribution. The following code runs data; the resulting graph estimate is shown in Figure 6. pcalg_fit_mix <- pc(suffStat = dat_cross, indepTest = mixCItest, alpha = 0.01, mygraph <- function(pcgraph){ g <- as.bn(pcgraph, check.cycles = FALSE) graphviz.plot(g, shape = "ellipse") mygraph(pcalg_fit_mix) Alternatively, one could bin all the continuous variables into discrete groups, and then use the function from thepcalg we use a version of our simulated dataset in which all variables have been discretized: suffStat <- list(dm = dat_cross_dis, adaptDF = FALSE) pcalg_fit_dis <- pc(suffStat = suffStat, indepTest = disCItest, alpha = 0.01, mygraph(pcalg_fit_dis) Figure 7 shows the result. Here, we see that considerable fewer edges were detected compared to Figure 6, presumably due to the lower power of the test that does not presume a linear dependence. (Foraita et al., 2020; Witte et al., 2021), available at www.github.com/bips-hb/micd. labels = colnames(dat_cross), u2pd="relaxed", skel.method = "stable", maj.rule = TRUE, solve.confl = TRUE) package, which implements aGtest (Kalisch et al., 2012). In the following code, labels = colnames(dat_cross_dis), u2pd = "relaxed", skel.method = "stable", maj.rule = TRUE, solve.confl = TRUE) Figure 6: Output of the PC algorithm on our synthetic mixed data, as run by the pc() function in pcalg. Figure 7: Output from the pc() function in pcalg, but ﬁt to data where all variables are discrete. ftoeducation_t0media_devices_t0sugar_t0wellbeing_t0 age_t0 media_time_t0mvpa_t0 Thebnlearnpackage oﬀers many built-in choices for the required test (mi-cg) for mixed (Conditional Gaussian) variables similar to the one implemented in diﬀerence is that inbnlearn and edges between continuous and discrete variables will always be oriented towards the continuous variable in the estimated CPDAG or MPDAG. If no test is speciﬁed in continuous and discrete variables, then mi-cg is automatically selected. In the following code, we run pc.stable() on the same synthetic mixed data as before: bnlearn_fit_mix <- pc.stable(dat_cross, test = "mi-cg", alpha = 0.01) graphviz.plot(bnlearn_fit_mix, shape = "ellipse") Figure 8: Output from the pc.stable() function in bnlearn. The output is shown in Figure 8. Compared to Figure 6, one sees more directed edges (in fact, all edges are directed, but this does not have to be the case in general). This is because of how conﬂicts – it chooses one direction where continuous and discrete variables are always oriented towards the continuous variable. Two tests for mixed data are currently implemented in TETRAD: the Conditional Gaussian test by Andrews et al. (2018) and the Degenerate Gaussian test by Andrews et al. (2019), where categorical variables are internally converted into dummy variables and then treated as continuous. Figure 3 shows the “Search” box where the selection is made. The output of TETRAD using the Conditional Gaussian test and all the settings shown in Figure 4 is in Figure 9. , it is assumed that continuous variables cannot be parents of discrete variables, Figure 9: Output of the conditional Gaussian test with cross-sectional mixed data in TETRAD Alternatively, data can be discretized or converted to a numeric scale by inserting a second “Data” box between the ﬁrst “Data” box and the “Search” box, and choosing “Discretize Dataset” or “Convert Numerical Discrete To Continuous”, respectively (screenshots not shown). In longitudinal cohort studies, it is common that at least a subset of variables is measured at every study visit. The resulting partial temporal ordering of the variables should be accounted for in order to improve the result of causal discovery. There are diﬀerent strategies for incorporating temporal constraints, depending on the assumptions one is willing to make about the data. In this guide, we focus on an option that is relatively close to the unmodiﬁed version of the PC algorithm: We restrict edges to be oriented in accordance with the ﬂow of time, but leave the algorithms unmodiﬁed otherwise. This strategy is followed, for example, in la Bastide-van Gemert et al. (2014). Many other strategies for including time constraints have been discussed in the literature. For example, Rahmadi et al. (2018) assume that the repeated measurements are equally spaced and that the causal relations among the repeatedly measured variables do not change over time, an assumption that is sometimes called stationarity. This allows them to pool the data from the diﬀerent time points. A whole branch of the literature is concerned with causal discovery from time series data, where it is usually assumed that the data constitute instantaneous measurements, and hence directed edges within time points are not allowed (see Scutari (2020) for a review). However, we believe that this assumption is not realistic for typical cohort data. Further, repeated measurements of the same variable should be considered as being time ordered; however, properly accounting for subject-level correlation is an active area of research. Time-ordered measurements are accommodated by tpc. It implements the following two modiﬁcations ﬁrst suggested by Spirtes et al. (2000): Arrows between time points are always oriented from the earlier to the later time point, and conditional independence tests are generally restricted such that the variables in the conditioning set must not lie in the future of both variables whose conditional independence is to be tested. Further, it is possible in variables known to be exogenous, i.e., known to have no incoming edges. In our data example, we specify context.all = c("country", "sex") fromcountryandsex "age_t1", "age_t2") their own tier, but not into variables from other tiers. The resulting graph estimate is shown in Figure 10. tpcto specify context variables in the spirit of Mooij et al. (2020). These are to all other variables into the graph. Further, we usecontext.tier = c("age_t0", to mark these three variables as context variables that have edges into variables in ## specify tiers: (1) country, sex; (2) FTO gene; (3) birth weight; ## (4) all t0 variables; (5) all t1 variables, (6) all t2 variables tiers <- rep( c(1,2,3,4,5,6), times = c(2,1,1,10,10,10) ) pcalg_fit <- tpc(suffStat = dat_cohort, indepTest = mixCItest, alpha = 0.01, mygraph(pcalg_fit) Figure 10: Output of tpc() after specifying the ordering of variables based on background knowledge. Thepc.stable()function in directions that are forbidden. Below, we repeat the call to measurement scales” section, but we use the full longitudinal data. We also specify that there cannot be any edges between variables that go backwards in time using the sexhave edges into everything else, and that variables within their own tier, as in the previous section. Note that if we try to force the continuous age variables to have edges into the discrete education variables, we get an error. This is due to the assumption that continuous variables do not have discrete children, which is speciﬁed. The output is shown in Figure 11. bnlearnhas ablacklistinput, which is used to specify edges and edge bl1 <- tiers2blacklist(split(names(dat_cohort), tiers)) bl2 <- data.frame(from = names(dat_cohort), bl3 <- data.frame(from = c("country","sex"), to = c("sex","country")) bl <- rbind(bl1, bl2, bl3) wl1 <- data.frame(from = rep( c("country","sex"), each = 29 ), wl2 <- data.frame(from = "age_t0", wl3 <- data.frame(from = "age_t1", wl4 <- data.frame(from = "age_t2", wl <- rbind(wl1, wl2, wl3, wl4) # causal discovery bnlearn_fit <- pc.stable(dat_cohort, alpha = 0.01, graphviz.plot(bnlearn_fit, shape = "ellipse") Figure 11: Output ofpc.stable() black and white lists. "media_time_t0","mvpa_t0","sugar_t0","wellbeing_t0")) "media_time_t1","mvpa_t1","sugar_t1","wellbeing_t1")) "media_time_t2","mvpa_t2","sugar_t2","wellbeing_t2")) blacklist = bl, whitelist = wl) In TETRAD, users can ensure correct temporal ordering by adding a “Knowledge” box to the causal search pipeline, see Figure 12. This is equivalent to specifying the tiers in to specify required and forbidden edges between variables, much like the white and black lists of bnlearn. Even though our data has three time points, we will illustrate the steps needed in TETRAD using only the ﬁrst two time points. Sorting variables into tiers is a straightforward process – one need only click on a variable in the “Not in Tier” box, and drag it to the appropriate Tier, see Figure 13. If desired, there are additional options for each tier, like specifying that there are no causal relationships between variables within a tier (“Forbid Within Tier”) or that variables within a particular tier can only have causal relationships with variables in the next tier (“Can Cause Only Next Tier”). In our data, we believe that country and sex inﬂuence every other variable. To tell TETRAD this information, we use a “required” group, see Figure 14. Just like in the prior analyses with specify that the variables not outside of them, and that country, sex, and the age variables do not inﬂuence each other (screenshots not shown). It turns out that without these knowledge-based speciﬁcations, TETRAD will not produce any output as it struggles to perform all of the required conditional independence tests. With two time points and 24 variables, we found that TETRAD took approximately 24-36 hours to complete the search. Users with many variables and/or time points could experience substantial run times, and this should be factored into any analysis plans. Figure 15 is the output of our search. Overall, TETRAD returned many edges between variables; however, we also note that not all of the required edges are found in the graph (e.g., there is no edge between andfiber_t0even though we required it). This is a known issue with TETRAD, and the developers are actively addressing it. In the meantime, we advise users of TETRAD to review all output carefully to ensure it matches what was expected given one’s background knowledge. Whenever a participant in a cohort study misses a study visit, drops out of the study, or cannot complete all scheduled study visit assessments, missing data points are created. Until recently, most causal discovery algorithms have ignored missing values and only ad-hoc methods were applied. A simple but problematic method is to eliminate missing values in a pre-processing step, by either removing any data rows with missing values (‘list-wise deletion’ or ‘complete case analysis’) or by replacing missing values e.g., by the column mode or median (‘single imputation’). Both are problematic: List-wise deletion induces a selection bias in general under most missingness mechanisms. The problem with single imputation is that the uncertainty in the imputed values is not accounted for, which leads to biased results of the conditional independence tests in PC and other algorithms. Figure 12: Adding a "Knowledge" box in TETRAD. age_t0andage_t1have edges into all other variables in their respective tiers, but Figure 14: TETRAD also allows for forbidden and required relationships to be speciﬁed. This is similar to thecontext.allandcontext.tier pc.stable(). Figure 15: TETRAD output after specifying a time ordering between variables using tiers, required groups, and forbidden groups. An alternative to list-wise deletion is test-wise deletion, where the decision to remove or retain an observation is made for each conditional independence test separately (Strobl et al., 2018, Tu et al. (2020), Witte et al. (2021)). For example, if the data row for individual row is removed for all conditional independence tests that include the well-being variable, but is retained otherwise. In test-wise deletion, more of the overall sample can be retained, which can lead to a higher power for some tests compared to list-wise deletion. Just as list-wise deletion, however, test-wise deletion suﬀers from a selection bias for some missingness mechanisms (Tu et al., 2020, Witte et al. (2021)). A valid imputation procedure under the missing at random (MAR) assumption (Rubin, 1976) is multiple imputation, where each missing value is replaced by several diﬀerent plausible values to account for the uncertainty about the missing values (Rubin, 1987). The conditional independence tests in the causal discovery algorithm then need to be adapted in order to handle the multiply imputed data. This is described in more detail in Foraita et al. (2020) and Witte et al. (2021). Multiple imputation relies on the MAR assumption and on correctly speciﬁed imputation models. Based on the missing data patterns seen in IDEFICS/I.Family, we created a dataset with 1-10% missing data for most variables. Exceptions were that country, age, sex, and body mass index were never missing, while ﬁber intake and physical activity measurements were missing 50-60% of the time. In order to reduce the runtime of the multiple imputation procedure, we only consider baseline and time 0 in the data examples below. Themicdadd-on topcalg wise deletion is performed by simply replacing disCItwd, ormixCItwd imputed data using e.g., the forest option for generating the imputations ( second step,pc()is run with oﬀers functions for performing test-wise deletion and multiple imputation. Test- , respectively. For a multiple imputation analysis, the ﬁrst step is to generate multiply micepackage (van Buuren and Groothuis-Oudshoorn, 2011) with the random indepTest = gaussMItest,disMItest, ormixMItest, respectively. Figures 16 and 17 show the graphs estimated using code: ## load incomplete data and create cross-sectional version of the dataset data("dat_miss") dat_miss_cross <- dat_miss[ ,1:14] pcalg_fit_twd <- tpc(suffStat = dat_miss_cross, indepTest = mixCItwd, mygraph(pcalg_fit_twd) Figure 16: Output oftpc() speciﬁed via indepTest = mixCItw. ## install required package # install.packages("mice") ## load required package library(mice) ## generate multiply imputed data using random forest imputation alpha = 0.01, labels = colnames(dat_miss_cross), maj.rule = TRUE, tiers = tiers[1:14], context.all = c("country", "sex"), context.tier = c("age_t0")) when the input data has missing values. The function applies test-wise deletion, mi_object <- mice(dat_miss_cross, m = 10, method = "rf", print = FALSE) mi_dat <- complete(mi_object, action = "all") ## apply PC pcalg_fit_mi <- tpc(suffStat = mi_dat, indepTest = mixMItest, mygraph(pcalg_fit_mi) Figure 17: Output oftpc() forest imputation. Inbnlearn, thepc.stable() our call topc.stable() is shown in Figure 18. It is diﬀerent from the graph estimated using test-wise deletion in diﬀerent implementations of the Conditional Gaussian conditional independence test and the diﬀerent ways in which the packages handle conﬂicts. alpha = 0.01, labels = colnames(dat_miss_cross), maj.rule = TRUE, tiers = tiers[1:14], context.all = c("country", "sex"), context.tier = c("age_t0")) when the input is a list of multiply imputed datasets generated via random function performs test-wise deletion if the data is incomplete. Here, we repeat from before, but use our dataset with missing data. The resulting graph estimate bl1 <- tiers2blacklist(split(names(dat_miss_cross), tiers[1:14])) bl2 <- data.frame(from = names(dat_miss_cross), to = "age_t0") bl3 <- data.frame(from = c("country","sex"), to = c("sex","country")) bl <- rbind(bl1, bl2, bl3) wl1 <- data.frame(from = rep( c("country","sex"), each = 11 ), wl2 <- data.frame(from = "age_t0", wl <- rbind(wl1, wl2) bnlearn_fit_twd <- pc.stable(dat_miss_cross, alpha = 0.01, graphviz.plot(bnlearn_fit_twd, shape = "ellipse") Figure 18: Output of “‘pc.stable()“‘ in “‘bnlearn“‘ when the input data has missing values. Here, the function performs test-wise deletion. For score-based causal discovery, Structural Expectation Maximization algorithm. It deals with missing values by iteratively completing the data and searching for the graphical structure (Friedman, 1997). Asbnlearn, TETRAD performs test-wise deletion by default if the data is incomplete, and it warns users of this when selecting a search algorithm (see Figure 19). Figure 20 shows the graph estimated by TETRAD using the same incomplete data as before. Alternatively, list-wise deletion or single imputation may be performed by inserting a second “Data” box between the “Data” box and the “Search” box, and choosing one of the options listed under ‘Missing Values’ (not recommended). Again, one will notice that not all required "media_time_t0","mvpa_t0","sugar_t0","wellbeing_t0")) edges are present in the output graph, and we reiterate the importance of checking all TETRAD output against background knowledge to ensure that the output theoretically makes sense. Figure 19: TETRAD warns users that test-wise deletion will be used when the data have missing values So far in this guide, we have focused on how software can be used to learn the structure of a graph in the face of common issues with observational data. In many studies, however, one would ideally like to supplement this by quantifying (i.e., estimating) the overall (direct or indirect) causal eﬀects that correspond to directed edges and directed paths found. To that end, causal discovery algorithms can be extended by the “Intervention calculus when the DAG is Absent” (IDA) algorithm to estimate causal eﬀects. The original IDA algorithm assumes that one’s data was generated from a multivariate Gaussian distribution, and also assumes that the data is faithful to an underlying causal DAG. Because the equivalence class represented by a CPDAG or MPDAG contains more than one DAG, the IDA algorithm does not estimate a single causal eﬀect of rather, it estimates multiple possible causal eﬀects. These can be summarized as appropriate for the study question of interest (e.g., taking the minimum and maximum provides bounds for the causal eﬀect). Inpcalg, theida()function performs the IDA algorithm. The function requires that a valid CPDAG or MPDAG be provided as input. If the graph is not valid, one will receive an error and must manually alter the graph based on subject matter knowledge until it is valid. Causal discovery is a useful tool that is not as widely known and implemented in public health and related ﬁelds, possibly because applying existing causal discovery tools to observational cohort data can be not straightforward. In this guide, we have provided details on how to use three software packages – bnlearn, and TETRAD – to learn the causal structure between variables in the presence of mixed data, time ordering, and missing data. While these packages can be used in these situations, their default capabilities are limited. Therefore, we also demonstrated how the new packages for causal discovery using cohort data, particularly when it comes to time ordered variables and missing data. Where possible, we highlighted key diﬀerences and similarities between the packages. Figure 20: Output of TETRAD when the input data has missing values. TETRAD performs test-wise deletion. As mentioned brieﬂy at the beginning of this guide, Python wrappers and packages exist for causal discovery as well. In fact, there are Python implementations of the the implementations in them in this guide; however, we encourage users more comfortable in Python programming to learn more about them. In terms of practical recommendations, we encourage analysts to choose software that meets their needs. For example, thebnlearn time ordering between variables is reﬂected in any output graph. At the same time, functionality for resolving edge conﬂicts, which may lead analysts to prefer another software. Similarly, thetpcpackage relies on much of the functionality of If the analyst prefers or requires a graphical interface for causal discovery, the only available software is TETRAD. Regardless of which software is chosen, we also encourage analysts to consider performing their causal discovery analysis with multiple packages. Obtaining similar results across packages could lend plausibility to the overall results, while any diﬀerences seen could help pinpoint potential issues or help with the interpretation of the ﬁndings. Replication ﬁles are available on the institute’s Github account at www.github.com/bips-hb/PracticalGuide. R. We have not tested these Python implementations and have therefore not included package has straightforward black and white list options that can ensure that