FHNW University of Applied Sciences and Arts Northwestern Switzerland, Intelligent Information Systems Research Group, Riggenbachstrasse 16, 4600, Olten, Switzerland Digitalisation leads to a transformation of internal business processes, but also very notably of customer-facing services. While most attention is paid to services in the B2C domain, there is also a rising interest in digitalising knowledgeintensive services in the B2B domain, such as consultancy in general [24] and IT consultancy in particular [29]. Such transformation implies that a digital service takes over (partially) the role of a human consultant and that companies can use that service to help themselves to the required advice. Obviously, such digital services will be able to give advice only for restricted domains – often, advice will consist in recommending items from a predeﬁned set of solution components. Thus, digital consulting services can be thought of as recommender systems. This article is an extended version of the peer-reviewed publication by Witschel and Martin [32] and comprises parts from the MSc thesis of the ﬁrst author Pande [25]. {charuta.pande,hansfriedrich.witschel,andreas.martin}@fhnw.ch Abstract. Besides the typical applications of recommender systems in B2C scenarios such as movie or shopping platforms, there is a rising interest in transforming the human-driven advice provided e.g. in consultancy via the use of recommender systems. We explore the special characteristics of such knowledge-based B2B services and propose a process that allows to incorporate recommender systems into them. We suggest and compare several recommender techniques that allow to incorporate the necessary contextual knowledge (e.g. company demographics). These techniques are evaluated in isolation on a test set of business intelligence consultancy cases. We then identify the respective strengths of the different techniques and propose a new hybridisation strategy to combine these strengths. Our results show that the hybridisation leads to a substantial performance improvement over the individual methods. Keywords: Recommender Systems · Case-based reasoning · Hybrid recommenders. As we have laid out in our previous work [32], a recommender that suggests solution components to companies are diﬀerent in several respects from the typical B2C recommenders that help users in ﬁnding e.g. books, movies or music that ﬁts their preferences (see also [12]): – Requirement-driven: A consultancy recommender needs to consider busi- – Interdependent items: The recommended items are not simple, atomic – No proﬁles: While typical B2C recommenders are used repeatedly by the Despite some of these diﬀerences, one can establish a “digital consultancy process” that will make it possible to apply traditional recommender techniques that have been designed for classical preference-based B2C scenarios. Such a process is based on the following considerations (see also Figure 1): 1. Many companies share the same requirements, just like many persons share 2. Later, the similarity of context and requirements manifests itself in accepting Following this iterative process will allow us to assess the similarity of company contexts by comparing queries of a company to those of previous users of the service – with an increasing degree of accuracy as the query is iteratively extended. Since similarity is at the heart of both content-based and collaborative ﬁltering approaches [3], being able to assess similarities is an important prerequisite for applying these approaches. In addition, we build up company proﬁles during the process which makes it possible to apply content-based ﬁltering. The ness requirements, not personal preferences and independent products (such as books, movies etc.), but interdependent and sometimes complex components of a larger solution. same person, a digital consultancy service has no chance to build up customer proﬁles through repeated interactions – companies will usually access the service only once. Thus, a proﬁle of the company needs to be acquired within a single session by the recommender – one can regard it as forming a query that describes the situation of the company seeking advice. preferences. The similarity of requirements often depends on the companies’ demographics (e.g. size, industry etc.). Thus, a ﬁrst step in the digital consultancy process may be to capture company demographics and regard them as an initial company proﬁle or initial query. This allows from the beginning to establish a certain similarity between companies. similar suggestions from the recommender. Since solutions will be complex, one may construct a repeated interaction with the recommender in the form of iterations: after entering the company demographics (step 1), the business user receives a ﬁrst set of recommendations and selects from those some ﬁrst elements of a solution. These elements are added to the initial company proﬁle to form an extended query and the recommender is invoked again. This process is repeated, each time with a more verbose query (we will later use the term “query verbosity” to refer to the growing amount of information that the query contains). iterative reﬁnement makes it also possible to take into account the interdependence of solution elements by identifying, in each new step, new elements that ﬁt to the already selected elements. Although collaborative and content-based ﬁltering become applicable through our iterative process, they may not be the best choice because a) collaborative ﬁltering does not lend itself readily to incorporating company demographics (or other forms of general context) and b) because both do not foresee the use of human-provided knowledge about the business domain which might be helpful. In fact, previous research has argued for the use of case-based reasoning (CBR) in business recommenders [6] because CBR is a proven way of re-using solutions to business problems. Constraint-based recommenders [12] are another family of algorithms that have been put forward as a good way of satisfying business requirements. In our previous work [32], we used a graph, as a simple, ﬂexible and easily extensible means of representing both historic user choices and explicit human knowledge about a business domain, together with a random walk approach to generate recommendations. We found that especially explicit knowledge about associations between solution elements improves the recommender performance. On the other hand, taxonomic knowledge, e.g. about relationships between industries, did not help. While our previous work was able to beneﬁt from a graph’s ﬂexibility and ease of incorporating new domain knowledge easily [32,22], it is not perfectly suited to accommodate and make use of all possibly relevant attributes of a company’s context. For instance, it does not easily allow to represent and compare numeric attributes (such as company size) or simple string attributes containing longer passages of text. Thus, the goal of our extended research was to explore options of Fig. 1. Iterative process for business consultancy recommenders combining graph-based random walks with other forms of recommenders, above all CBR-based ones. We performed our recommender experiments in the domain of IT consultancy, more precisely business intelligence (BI) consultancy. Typically, companies using a BI consultancy service – before being able to tackle the “technical” elements of a BI solution – initially seek advice regarding – Suitable key performance indicators (KPIs) that can be used to monitor and – Adequate dimensions to describe the values of KPIs, e.g. to characterise – Suitable representations, e.g. charts or tables that help to analyse KPI values Here, we focus on the ﬁrst two types of solution elements. Obviously, the question of which dimensions should be chosen depends on the KPIs to be monitored. Choice of KPIs, in turn, is often determined by the (type of) industry of a company – e.g. companies who produce energy tend to have KPIs that diﬀer substantially from those of, say, architects. KPIs are also usually determined by the business process (e.g. sales) that should be analysed. Given the application scenario that we just sketched, our main research goal in this work is to construct a new hybrid recommender that optimally supports the requirements of a B2B consultancy service. We investigate hybridisation because 1. despite the existence of some previous work, we do not yet have reliable 2. we do know that diﬀerent recommenders have diﬀerent strengths and weak- We will ﬁrst investigate the performance of algorithms individually and then – by a more detailed analysis of their strengths and weaknesses on the data – propose and evaluate some hybridisation strategies that will lead to superior performance by joining the strengths of the best-suited recommenders. measure the company’s success in achieving its goals. A typical KPI might be “sales revenue”. sales by product that was sold, channel through which it was sold and/or date when it was sold along dimensions (e.g. a chart showing temporal evolution of sales revenue for diﬀerent products) knowledge about which type of recommender is best suited for the task and nesses in general that aﬀect their ability to represent and accommodate certain types of knowledge and/or inputs and their ability to deal with lack of such knowledge (“cold-start problems”). Digitalising consultancy services has been discussed recently for the domain of IT consulting. In [29], a “computer-executed consulting (CEC) service” is proposed, which replaces, most notably, the two steps of a) interviewing client representatives and b) creating a report that summarises the interview results. The digital service is designed by human consultants and consists of a) a series of questionnaires (replacing the interviews) and b) an automated report creation module. Obviously, there is a rough correspondence between these components and the step of a) formulating a query and b) getting recommendations for that query in Figure 1. The proposed CEC service is general-purpose. Therefore, although it mentions the need for more intelligence in the report creation module and the option of using recommender systems, it does not discuss any details of how to use recommenders. Application of recommender systems has been discussed for more speciﬁc consultancy tasks such as optimisation of product assortments [31], selection of cloud or web services [35,18,34] or adaptation of conditions in agriculture [19]. In all these cases, the set of possible items that can be recommended is known and well-deﬁned and the task consists in selecting and possibly orchestrating the items. In its simplest interpretation, the term “orchestration” means simply that the selected services should be well aligned with each other, e.g. for optimal cross-selling opportunities [31] or for obtaining a consistent complex cloud service conﬁguration [34]. This is also the case for our BI consultancy service, see Section 1.1 and [32]. In terms of algorithms, business-oriented recommender systems have to deal with complexity in terms of company contexts (input) and solutions (output). Attempts to deal with such complexity can be divided into several categories: – Augmentations of content-based ﬁltering (CBF): approaches in this category model both the input and the output complexities and establish the degree to which both of them match. For instance, constraint-based recommenders [12,13] help to model product features and constraints to be expressed about them and then ensure constraint satisfaction. Other approaches use tree-like structures to model items and user preferences [33] or use multiple levels on which queries and items are matched (such as recommending ﬁrst providers and then actual services in a service recommender, [23]). In CBF, additional knowledge can be incorporated, e.g. into the function that determines the similarity between an item and the user proﬁle. Often, this is knowledge about user context, item features and/or domain-speciﬁc constraints. For instance, [11] and [2] use ontologies to represent and reason about item features and to apply this knowledge in a sophisticated similarity measure that takes into account “hidden relationships” [2]. Middleton et al. [21] use an ontology to represent user proﬁles and engage users in correcting the proﬁles before assessing proﬁle-item similarities. – Augmentations of collaborative ﬁltering: Case-based recommenders [6,5] can – Graph-based recommenders [4,37,22] have been put forward because of their Obviously, all of these approaches employ and model various types of knowledge. An overview of the diﬀerent kinds of knowledge that recommenders may use can be found in [12,32]. What distinguishes the business recommenders from most others is the use of domain knowledge. Often, this knowledge is obtained from human experts as discussed in [12,27,32]. Finally, forming hybrid recommenders [9,10] is an active ﬁeld of research since combinations of diﬀerent approaches can often help to combine the strengths and/or avoid the weaknesses of the combined approaches. For instance, contentbased ﬁltering can be combined with collaborative ﬁltering (CF), e.g. to mitigate the so-called cold-start problems associated with CF, i.e. problems with recommending newly introduced items or serving new users: new items can be recommended immediately by content-based techniques as long as they have a meaningful description that can be matched against user proﬁles. Besides cold start problems, hybridisation can be used e.g. to augment similarity in collaborative ﬁltering with the reasons behind user preferences and thus give it a stronger CBR ﬂavour [7]. Further possibly complementary strengths and weaknesses of knowledge-based and knowledge-weak recommenders are discussed in [8]. Overall, there is a rather large number of suggestions for enriching recommenders with contextual knowledge. However, as outlined in Section 1.2, we see a gap in exploring which of these suggestions is best suited to support scenarios of business consultancy. We furthermore see a need to gain a deeper understanding of the (complementary) strengths and weaknesses of the mentioned approaches that will lead to successful hybridisation strategies. be seen as a special form of collaborative ﬁltering since they recommend items used in solutions of companies that are similar to the current company. However, instead of only considering already chosen items, case-based recommenders’ similarity measures take into account context variables that describe e.g. company demographics and other relevant aspects of the company’s problem and/or initial situation. ability to accommodate a wide variety of forms of contexts in a ﬂexible way without much eﬀort. Random walks [14,17] are a predominant type of algorithm to provide recommendations based on graph structures. Because of their simplicity, graphs also have limitations, e.g. in modeling and matching simple string-valued attributes of input cases or in modeling certain forms of complex solution structures. The possibility to use graph-based recommenders to “mimick” traditional recommender approaches, such as collaborative or content-based ﬁltering, has been explored in [20]. For this, one needs to assign diﬀerent weight to diﬀerent types of graph relations. As mentioned in Section 1.2, the main goal of our research is to ﬁnd a recommender form that optimally supports B2B consultancy services. To study such services, we worked together with a company that provides business intelligence (BI) consultancy, as described in Section 1.1. As described in our previous work [32], our research started by interviewing two consultants to understand how they work and which knowledge they require to make the necessary recommendations to their customers. We also obtained some documents that were used to document the outcomes of meetings and workshops with customers. This was the basis for us to deﬁne the structure of consultancy cases: it gave us an insight into the demographic and contextual variables (attributes) that consultants need to know about each company. It also allowed us to grasp roughly the kind of reasoning that they employed to transfer their experiences to new cases. The corresponding ﬁndings are summarised in Section 4. We then constructed a case base out of the past experience of the consultancy and identiﬁed cases that represent the business context of customers; each business process that a company wanted to analyse resulted in a separate case. Overall, this resulted in a case base with 82 entries. To support our extended research, we performed a second round of interviews to gain further awareness of how consultants currently assess (implicitly or explicitly) the similarity between customer cases. More precisely, we asked them to which degree they take into account each attribute in the case (e.g. the industry, the core business processes to be analysed, the target group, the goal of the consultation), i.e. we elicited the importance they assign to each attribute while deriving recommendations for their customers. Next, we used the gathered knowledge to conﬁgure a selection of recommender algorithms that we wanted to compare: – Collaborative ﬁltering, using both item-based and user-based k-nearest neigh- – A random walk algorithm based on a “case graph” as described in [32]. – A CBR-based recommender that applies similarity-weighted scoring to the A precise description of recommender conﬁgurations can be found in Section 5. bour algorithms, as provided by the LibRec library [15]. elements contained in similar cases. The weights mentioned above were used here to deﬁne the contribution of the local similarities within the global similarity function in CBR. We then designed an experimental setup [25] to compare the initial recommender conﬁgurations, as well as our new hybrid recommender strategies. This setup consists in a leave-one-case-out evaluation: for each case C, we used the case base as the training data by omitting C. Out of C, we constructed queries Q and gradually more verbose queries containing an increasing number of randomly chosen KPIs from the case C. The random selection of the input elements is not realistic as this information is usually provided by the customer. However, we did not have any information about the order in which customers added elements to their solution in the past and thus had to resort to this strategy. For the evaluation of recommender outputs, we used the knowledge of originally chosen elements in C as a deﬁnition of relevance: for a query Q observed whether a recommender was able to retrieve (and rank highly) the elements in the original case C. That is, for each ranking of recommended items that a recommender produced in response to a query Q average precision [28] of these rankings by treating all elements originally contained in C as relevant and all others as irrelevant. As mentioned above, this experimental setup was used ﬁrst to evaluate each recommender in isolation. We then analysed the strengths and weaknesses of each recommender (see Section 6) and formed new hybrid recommender strategies (see Section 7) that we evaluated with the same experimental environment to see whether the hybridisation could bring about an improvement (see Section 8). As mentioned in Section 3.1, we performed two rounds of interviews with consultants to understand their current work and knowledge processing procedures. Here, we summarise the ﬁndings from both rounds of interviews (see also [32] for more details on the ﬁrst round): – Customers often come to the meetings with some important KPIs and di- – In terms of company demographics, consultants consider the industry of a at diﬀerent verbosity levels: simple queries with no input elements mensions (i.e. solution elements) already in mind. However, the degree to which customers have initial ideas can vary greatly. We have reﬂected this variance by creating queries at diﬀerent verbosity levels. customer as the main criterion for ﬁnding similar past cases. Further relevant variables that we elicited were the target group of the solution (e.g. only management or all employees) and the goal of the BI project (expressed in natural language). Finally, consultants use of course all known customer preferences from initial meetings (see above), i.e. any already known solution elements to remember past cases with similar elements. – In the second round of interviews, we asked the consultants to quantify – When talking to a customer from a yet unknown industry, consultants tried Based on the interview ﬁndings, we created suitable conﬁgurations of the recommenders to be used in the experiments [25], as described in the following subsections. Since the association between solution elements (which we will call items for simplicity) and cases is binary – an item is either part of the case’s solution or not – we can describe this situation as one of “implicit feedback recommendation” [36]. It means that the user-item matrix does not contain true ratings, but binary entries – in our case, we replaced users with customers. The business process was also mentioned by consultants as an important variable. Because of its importance, we chose not to use it simply as a ranking criterion for the retrieval of similar cases, but as a ﬁlter: for a given company, we created separate cases for each business process the company wanted to analyse and retrieved only cases with the same business process (analogously, we built separate case base graphs for the graph recommender, see below). the relative importance of these types of attributes. Although quantifying something as abstract as a variables contribution to a similarity score is a hard task, we were able to verify in some preliminary experiments that the chosen weights gave quite good results as compared to other potential weight conﬁgurations. The resulting weights are shown in Table 1. to remember cases of customers from similar industries. Since our attempts to use an industry taxonomy for improved similarity assessment in a graphbased recommender were not particularly successful, we did not consider this kind of reasoning in this work. However, we did use the industry taxonomy to deﬁne a local similarity measure for industries within a CBR-based recommender (see Section 5.3). However, this does not require to change the way in which Collaborative Filtering algorithms work on the matrix. In our experiment, we used the user-based userknn and the item-based itemknn implementations from the LibRec package [15]. Since userknn and itemknn do not allow us to make use of the additional attributes listed in Table 1, “simple” queries that do not contain any items (verbosity level 0) could not be designed. We also expect the collaborative ﬁltering algorithms to have inferior results for low verbosity queries. The conﬁguration for the graph-based recommender was re-used from [32], where the case graph incorporated the explicit knowledge acquired from the consultants. In this technique, the case graph was built by creating a node for each case and connecting it to a node representing the industry as well as to nodes representing solution elements. As mentioned in Section 4, we built a separate graph for each business process to be analysed. Target group and goal were not represented in this approach: since there are only three possible target groups, the corresponding nodes would have had a very high degree, thus diluting the PageRank scores. Since goals are string attributes, a node representation was not straightforward for them (although future work might consider extracting salient terms and representing them as nodes). The recommended elements were scored using the PageRank with Priors algorithm [30] on that graph. The scores represent the probability of reaching a node in the case graph (e.g. the elements to be recommended) through a random walk that is biased towards the input elements in the query. For verbosity level 0, the random walk-based recommender uses only the industry node as a query – we also expect suboptimal results here. In the case of the CBR recommender, primarily three factors were considered in the conﬁguration: – Similarity measures depending on attribute type: based on the taxonomytree approach proposed by [1], the industry attribute uses the industry taxonomy derived by [32] that categorizes the customers of the consultancy based on their similarities (e.g. customers that are likely to share KPIs and dimensions). For the attributes goal (free text) and KPI, we could apply the TF-IDF [16] similarity measure by creating a corpus of goals and KPIs respectively from the case base for the computation of inverse document frequencies (IDF). Although KPIs are not free text, applying TF-IDF is appropriate to disregard repeated terms like ”Number of”, ”Amount”, since they do not add signiﬁcant value to the recommendations. Lastly, for the attribute target group, we calculated the Jaccard coeﬃcient [16] as a case – The number n of the most relevant (top) cases retrieved: The number of – For that weighted average, we used the weights assigned to the local simi- The retrieved ranking of matching cases was ﬁrst ﬁltered by business process such as to return only cases with matching process before applying the local similarity measures. The goal of our ﬁrst experiment was to identify a recommendation technique that performs well for diﬀerent query verbosity values [25]. The results of Experiment 1 are shown in Table 2. Note that the verbosity refers to the absolute number of solution elements that the query contained. From the results, we can see very clearly that the Collaborative Filtering algorithms obviously suﬀer too much from their inability to accommodate contextual knowledge. Their performance is substantially worse than that of the other recommenders. Regarding, those, we observed that the performance of the CBR recommender is better than the graph-based recommender, however, there is no improvement in the performance of the CBR recommender above a certain query verbosity. Thus, one can see that retrieving a single case is restrictive for the recommendations since only a limited number of elements are available which in turn creates a recall problem. The performance of the graph-based recommender, on the other hand, steadily improves as more elements are added to the query. In order to enable the CBR recommender to stretch its (better) performance to any size of the query, we repeated the leave-one-case-out evaluation may have more than one target audience from the possible values ”employees”/”middle management”/”top management”. the retrieved cases played a signiﬁcant role in calculating the scores of the recommended elements, which in turn determine the ranking. For an element appearing in any of the retrieved cases R(Q) for a query Q, the score of that element is the sum of the scores of all the retrieved cases in which the element occurs: Obviously, the larger the case base, the larger we can choose n, i.e. the maximum size of R(Q). For a rather small case base like ours, we expect that smaller values of n will work better since larger values will likely imply a “topic drift” by including rather dissimilar cases. The score of the case sim(C, C) was generated by the CBR recommender using the global similarity function, which is the weighted average of the local similarity measuresP [26]: sim(C, C) =wsim(C, C). larity measures simshown in Table 1. by retrieving more number of most relevant cases. With the top two retrieved cases, the performance of the CBR recommender improved further, however, again only up to a certain query verbosity. By retrieving more and more cases, it was possible to overcome the recall problem and achieve a steady improvement in the performance of the CBR recommender, similar to the graph-based recommender. Nonetheless, one can observe that retrieving more cases also introduces more noise, consequently decreasing the overall performance of the CBR recommender. Thus, increasing the number of retrieved cases seems to be neither the optimal nor a generic solution to the recall problem of the CBR recommender because of its severe precision-degrading eﬀect. Table 2. Experiment 1: MAP values for individual recommendation techniques for diﬀerent conﬁgurations Overall, to achieve an optimum performance, the CBR recommender needs to be conﬁgured to retrieve a low number of most relevant cases. Yet, if a customer needs a solution with more elements than are available in the (small number of) retrieved cases, the CBR recommender fails to expand its range of recommendations. The graph-based recommender, on the other hand, can leverage the whole range of elements available in the case base and hence seems to be a better solution for increasing recall without adding too much noise. We, therefore, see a beneﬁt in combining the graph-based and CBR recommendation techniques using a hybrid strategy. In Section 2, we saw that Hybrid recommender systems are commonly used to overcome the weaknesses of individual recommendation techniques. Of the seven hybrid recommender strategies described by [10], strategies like switching, cascade or mixed are not ideal (and the others are not applicable), as the results show that CBR recommender is clearly the better performer. Since we would like the graph-based recommender to contribute by adding more relevant elements user-item-Graph-CBR knnknnbased where CBR is limited, we adopted the weighted combination method because it allows to ”overrule” the decisions of the CBR by adjusting the importance (weight) given to either CBR or graph-based recommender. A representation of the weighted hybrid strategy adopted by us is shown in Figure 2. For designing the hybrid strategy, we built upon the CBR conﬁguration to retrieve the most relevant two cases, as this conﬁguration achieved the optimum performance in the previous experiment. We now explore if the recall issue of CBR can be resolved by adding some component of the graph-based recommendations. We ﬁrst normalised the scores of the individual recommendation techniques using min-max normalisation, since the graph-based and CBR recommenders have their own (diﬀerent) scoring mechanisms, as described in Section 5. We then combined the normalised scores of both recommenders and calculated the hybrid weighted score using Equation 2. where | · | refers to min-max score normalisation. Because of the CBR recommender’s strength in dealing with sparse, i.e. lowverbosity query and the relative strength of the graph-based recommender in handling high-verbosity queries, we made the mixture parameter α dependent on the query verbosity, i.e. the number of referred elements |q| in the query q: Here, ¯c refers to half the average size of all cases in the case base in terms of their number of referred elements (KPIs) and serves as the ”verbosity threshold”. Since CBR was the better performer of the two recommendation techniques, we designed Equation 3 such that the weight of the CBR recommender (α) is never 0. On the other hand, we do not set β to 1 as this would give a full weight to CBR, which we already know has limitations performing as a ”pure” recommender. Additionally, from the results of Experiment 1, we concluded that a CBR-heavy hybrid recommender would perform better for queries below the verbosity threshold and vice-versa, also taken care in Equation 3. Figure 3 shows the dependency between α and query verbosity |q| graphically, for β = 0.3 and ¯c = 14. We can see how β acts as the “minimum CBR contribution” and that below the verbosity threshold, less and less weight is given to CBR as verbosity increases. Table 3. Experiment 2: MAP values for individual recommendation techniques and hybrid strategy Query size (verbosity) With this setup, we carried out the second experiment - leave-one-case-out evaluation for diﬀerent query verbosity, using the hybrid strategy. Our goal, now, was to ﬁnd the appropriate combination of weights that could overcome the recall issue of CBR without impacting its performance. After every run, we compared the mean average precision for each recommendation technique with that of the hybrid strategy, as seen in Table 3. Fig. 3. Mixture parameter α as a function of query verbosity q To ﬁnd the right combination of the graph-based and CBR recommender, we experimented with diﬀerent values of β, starting with a very low value. The lower values of β indicate a higher weight to the graph-based recommender. The performance of the hybrid recommender appears to be better than either of the individual recommendation techniques, however, the precision issue of the graph recommender still shows its negative impact for very low values of β. The verbosity threshold for our experiments was at 14, and it can be observed that the performance suddenly dips at 15 input elements for β=0.1 (where MAP = 0.843 for a verbosity of 10 and MAP = 0.804 for verbosity 15). On the other hand, although a high β resolves the precision problem, the performance is not optimum because for e.g. β = 0.9, the graph recommender’s ability to provide more recall is not suﬃciently leveraged. From the results for β=0.3, one can conclude that the right value of β can cure both the recall problem of the CBR recommender and the precision problem of the graph recommender, and thus gives an optimum performance among the individual recommendation techniques and the various conﬁgurations of the hybrid strategy put together. In this work, we considered the application of recommender systems to business consultancy. We have argued how certain consultancy tasks can be formulated as recommendation problems, especially in the domain of IT consultancy – e.g. selection and orchestration of web services or selection of Key Performance Indicators and dimensions for Business Intelligence (BI) solutions. Since such problems are in several respects diﬀerent from the typical, purely preference-based B2C recommenders, we have addressed the question which (combinations of) recommendation techniques are most suitable for these new B2B scenarios. We worked with data from the BI consultancy domain and performed experiments with a range of known recommender techniques. These techniques oﬀer a varying degree of possibility to feed – besides the item choices that a company makes – contextual knowledge, such as company demographics, into the algorithm. This ranges from none (collaborative ﬁltering) over limited (graph-based random walks) to full coverage (CBR-based recommender). Our initial comparison showed that – as one might expect – the CBRbased recommendation beneﬁts from its ability to accommodate more contextual knowledge and provides the best results. However, we also recognised a limitation: CBR-based recommenders have a free parameter, namely n, the number of most similar cases to use for the identiﬁcation of possible solution elements. We found that, for the rather small case base in our experiments, small values of n performed better. Obviously, a larger n implies more noise coming from more dissimilar cases. In our previous work [32], we already observed that including cases e.g. from diﬀerent, but similar industries can be dangerous. On the other hand, limiting n also limits the potential recall of the recommender, i.e. some useful items from less similar cases are excluded. Obviously, a graph-based approach – although less precise – oﬀers a natural way to include more items, also from the more dissimilar cases. We, therefore, explored the combination of CBR-based recommendation with a graph-based recommender in order to combine its strengths in terms of precision with the graph-based recommender’s strength in providing more relevant items in the lower ranks. We followed a weighted hybridisation strategy. The weight was dynamic, giving more and more importance to the graph recommender with the growing size of the query. This makes sense since contextual knowledge becomes less important as we know more and more about already chosen items. Because of the superior performance of the CBR recommender, we also designed the weighting so as to ensure that there is always a certain minimum weight given to it. It turned out that indeed this minimum weight should not be 0. We found that the weighted hybrid performed – at all levels of query verbosity – better than any of the individual recommenders. Although we have only tested the hybrid on one particular data set, we believe that we can carefully conclude from this that a CBR recommender’s problems in balancing between precision and recall can be overcome by combining it with another recommender that is less limited by case boundaries and can contribute better recall at lower ranks. The graph-based recommender was able to achieve that in our experiments. In future work, we plan to apply our approach also to diﬀerent domains and data sets. In that context, it will also be important to study more closely the relationship between the size and characteristics of the case base and the optimal choice of the parameter n of the case-based recommender.