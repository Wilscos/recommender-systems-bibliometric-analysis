Multi-armed bandit (MAB) algorithms are widely adopted in scenarios of decision-making under uncertainty (Lattimore and Szepesv regret minimization and best-arm identiﬁcation, and this paper is more closely related to the latter. (Kaufmann, Capp kbelieved to have the highest pre-deﬁned set of groups that may be non-overlapping (Gabillon et al. 2011) or overlapping (Scarlett, Bogunovic, and Cevher 2019). overlapping) groups of arms, but the goal is to identify the group whose worst arm (in terms of the mean reward) is as high as possible. To motivate this problem setup, we list two potential applications: More generally, this problem captures the notion of a group only being as strong as its weakest link, and is closely related to widely-studied robust optimization problems (e.g., (Bertsimas, Nohadani, and Teo 2010)). works. The related work on multi-armed bandits and best-arm identiﬁcation is extensive; we only provide a brief outline here with an emphasis on the most closely related works. 2012; Jamieson and Nowak 2014; Kaufmann, Capp others. These works are commonly distinguished according to whether the time horizon is ﬁxed (ﬁxed-budget setting) or the target error probability is ﬁxed (ﬁxed-conﬁdence setting), and the latter is more relevant to our work. In particular, we will utilize anytime conﬁdence bounds from (Jamieson and Nowak 2014) in our upper bounds, as well as a fundamental change-of-measure technique from (Kaufmann, Capp bounds. Department of Mathematics & Institute of Data Science, National University of Singapore In this paper, we introduce a multi-armed bandit problem termed max-min grouped bandits, in which the arms are arranged in possibly-overlapping groups, and the goal is to ﬁnd a group whose worst arm has the highest mean reward. This problem is of interest in applications such as recommendation systems, and is also closely related to widely-studied robust optimization problems. We present two algorithms based successive elimination and robust optimization, and derive upper bounds on the number of samples to guarantee ﬁnding a max-min optimal or near-optimal group, as well as an algorithm-independent lower bound. We discuss the degree of tightness of our bounds in various cases of interest, and the difﬁculties in deriving uniformly tight bounds. The most basic form of best-arm identiﬁcation seeks to identify the arm with the highest mean (e.g., see In this paper, we introduce a distinct problem setup in which we are again given a collection of (possibly •In recommendation systems, the groups may correspond to packages of items than can be offered or advertised together. If the users are highly averse to poor items, then it is natural to model the likelihood of clicking/purchasing as being dictated by the worst item. •In a resource allocation setting, suppose that we would like to choose the best group of computing machines (or other resources), but we require robustness because the slowest machine will be bottleneck when it comes to running jobs. Then, we would like to ﬁnd the group whose worst-case machine is the best. Before describing our main contributions, we provide a more detailed overview of the most related existing The standard best-arm identiﬁcation problem was studied in (Audibert, Bubeck, and Munos 2010; Gabillon et al. Viswanathan 2013), where the arms are partitioned into disjoint groups, and the goal is to ﬁnd the best arm in each group. A generalization of this problem to the case of overlapping groups was provided in (Scarlett, Bogunovic, and Cevher 2019). Another notable setting in which multiple arms are returned is that of subset selection, where one seeks to ﬁnd a subset of and Kalyanakrishnan 2013; Kaufmann, Capp substantially different from the max-min grouped bandit problem that we consider. 2019). This setting consists of disjoint groups with a partial ordering, and the knowledge of the group structure (but not their order) is given as prior information. However, different from our setting, the goal is still to ﬁnd the best overall arm (or more precisely, minimize the corresponding regret notion). In addition, the results of (Jedor, Perchet, and Louedec 2019) are based on the arm means satisfying certain partial ordering assumptions between the groups (e.g., all arms in a better group beat all arms in a worse group), whereas we consider general instances without such restrictions. See also (Bouneffouf et al. 2019; Ban and He 2021; Singh et al. 2020) and the references therein for other MAB settings with a clustering structure. considerable attention on continuous domains (Bertsimas, Nohadani, and Teo 2010; Chen et al. 2017; Bogunovic et al. 2018), as well as set-valued domains with submodular functions (Krause et al. 2008; Orlin, Schulz, and Udwani 2018; Bogunovic et al. 2017). Robust maximization problems generically take the form and in Sec. 4 we will explicitly connect our setup to the kernelized robust optimization setting studied in (Bogunovic et al. 2018). However, based on what is currently known, this connection will only provide relatively loose instanceindependent bounds when applied to our setting, and the bounds derived in our work (both instance-dependent and instance-independent) will require a separate treatment. The paper is outlined as follows: We ﬁrst describe the problem aspects that are the same as the regular MAB problem. We consider a collection A “ t1, . . . , nu observes the corresponding reward stochastic rewards, in which for each unknown distribution with mean G P G groups. Without loss of generality, we assume that each arm is in at least one group. We are interested in identifying the max-min optimal group, deﬁned as follows: To reduce notation, we deﬁne non-unique, we simply take any one of them chosen arbitrarily. A notable grouped best-arm identiﬁcation problem was studied in (Gabillon et al. 2011; Bubeck, Wang, and Another setup of interest is the recently-proposed categorized bandit problem (Jedor, Perchet, and Louedec Finally, we note that our setup can be viewed as a MAB counterpart to robust optimization, which has received •In Sec. 2, we formally introduce the max-min grouped bandit problem, and brieﬂy discuss a naive approach. •In Sec. 3, we present an algorithm based on successive elimination, and derive an instance-dependent upper bound on time required to ﬁnd the optimal group. •In Sec. 4, we show that our setup can be cast under the framework of kernel-based robust optimization, and use this connection to adapt an algorithm from (Bogunovic et al. 2018). We additionally derive an instance-independent regret bound (i.e., a bound on the suboptimality of the declared group relative to the best). •In Sec. 5, we return to considering instance-dependent bounds, and complement our upper bound with an algorithm-independent lower bound. •In Sec. 6, we further discuss our bounds, including highlighting cases where they are tight vs. loose, and the difﬁculty in deriving uniformly tight bounds. •In Sec. 7, we present numerical experiments investigating the relative performance of the algorithms considered. Different from the standard MAB setup, we assume that there is a known set of groupsG, where each group is a non-empty subset ofA. We allow overlaps between groups, i.e., a given arm may appear in multiple outputs a recommendation performance measures, namely, the error probability and the simple regret Throughout the paper, we will make use of several assumptions that are either standard in the literature, or simple variations thereof. We start with the following. Assumption 1. sub-Gaussian with parameter ErX identiﬁcation problem, i.e., an identiﬁability assumption. Assumption 2. There exists a unique group G also ubiquitous in instance-dependent studies of MAB problems, but are somewhat different here compared to other settings. and the worst arm of group quantities will play a key role in our analysis: In Sec. 3, we will present an algorithm such that, with high probability, arm number of pulls dependent on ∆ AfterTrounds (whereTmay be ﬁxed in advance or adaptively chosen based on the rewards), the algorithm s “ µand Eres ď exppλR{2q for all λ P R. We will consider Gaussian and Bernoulli rewards as canonical examples of distributions satisfying Assump. 1. The next assumption serves as a natural counterpart to that of having a unique best arm in the standard best-arm With this assumption in mind, we now turn to deﬁning fundamental gaps between the arm means. These are Recall thatjpGqis the worst arm in a groupG P G. We deﬁne the difference between the worst arm ofG • ∆:“ minµ´ µis the minimum distance between (the mean reward of)jand the worst arm jpGqin any of the groups containingj. This gap determines whenjcan be removed (i.e., no longer pulled) if it is not a worst arm in any group. • ∆:“ min∆is the minimum distance between the worst arm in the optimal groupGand the worst arm in any of the groups containingj. This gap determines when all the groups thatjis in can be ruled out as being suboptimal. Ifjis not in the optimal groupG, the removal of these groups also amounts tojbeing removed, whereas if j is in G, this value becomes zero. • ∆:“ min∆is a ﬁxed constant indicating the distance between the worst arm in the optimal group Gand the best among the worst arms in the remaining suboptimal groups. This gap determines when the optimal group is found (and the algorithm terminates). Following the deﬁnitions above, we deﬁne the overall gap associated with each arm j as follows: A simple algorithm to solve the max-min grouped bandit problem is to treat it as a combination of search problems. We can consider each group separately, and identify the worst arm for each group via a “best”-arm identiﬁcation algorithm (trivially adapted to ﬁnd the worst arm instead of the best) such as UCB or LUCB (Jamieson and Nowak 2014). We can then rank the worst arms in the various groups to ﬁnd the optimal group. groups during the search. For instance, consider a setting in which 0.01 ą µ 0.01 ´ 0.00999 of arms from needing to know the precise ordering of arms within either group. As is ubiquitous in MAB problems, our analysis relies on conﬁdence bounds. Despite our distinct objective, our setup still consists of regular arm pulls, and accordingly, we can utilize well-established conﬁdence bounds for stochastic bandits. Many such bounds exist with varying degrees of simplicity vs. tightness, and to ease the exposition, we do not seek to optimize this trade-off, but instead focus on one representative example given as follows. Bernoulli rewards. apply a union bound, which leads to the following upper/lower conﬁdence bound of arm j in round t: Hence, with probability at least 1 ´ To derive the performance bounds for our algorithms, we further require the following lemma: Lemma 2. ∆ P p0, 1q, we have where γ “ 8p1 ` Elimination-based algorithms are widely used in MAB problems. In the standard best-arm identiﬁcation setting, the idea is to sample arms in batches and then eliminate those known to be suboptimal based on conﬁdence bounds, However, this method may be highly suboptimal, as it ignores the comparisons between arms from different “ tk ` 1, . . . , nu. Suppose thatµ“ 1 ą ... ą µ“ 0.9 ą µ“ 0.8andµ“ 0.1 ą ... ą µ“ “ 0.00999. We observe that ﬁnding the worst arm inGis highly inefﬁcient due to the narrow gap of (Law of Iterated Logarithm (Jamieson and Nowak 2014)) LetZ, Z, . . .be i.i.d sub-Gaussian random In accordance with this result, we henceforth assume thatR ďin Assump. 1, which notably always holds for Since the error probability is dependent on the entire set ofnarms, we further replaceδbyin Lemma 1 and (Inversion ofUpt, δq(Jamieson and Nowak 2014)) For any P p0, 1q,δ P p0,logp1 ` qq, and until only one arm remains. In the max-min setting that we consider, we can use a similar idea, but we need to carefully consider the conditions under which an arm no longer needs to be pulled. We proceed by describing this and giving the relevant deﬁnitions. For each group G, we deﬁne the set of potential worst arms as This deﬁnition will allow us to eliminate arms that are no longer potentially worst in any group. We additionally consider a set of candidate potentially optimal groups C This deﬁnition allows us to stop considering any groups that are already believed to be suboptimal. With these deﬁnitions in place, pseudo-code for the successive elimination algorithm is shown in Alg. 1. Algorithm 1 Successive Elimination algorithm Require: Arms pa Theorem 1. Sec. 2, given the optimal group and uses a number of arm pulls satisfying where γ “ 8p1 ` that after the conﬁdence width falls below long as the conﬁdence bounds are valid. Applying Lemma 2 and summing over the arms then gives the desired result. solve for δ, and it readily follows that the right-hand side of (15) has the standard O In this section, we ﬁrst discuss how the max-min grouped bandit problem is related to the problem of adversarially robust optimization. We then demonstrate that a robust optimization algorithm known as STABLEOPT (Bogunovic et al. 2018) can be adapted to our setting with instance-independent regret guarantees. We will work in epochs indexed byi, and lettdenote the number of arm pulls up to the start of thei-th epoch. Finally, the set of candidate arms (i.e., arms that we still need to continue pulling) is given by We now state our main result regarding this algorithm. The proof is given in Appendix A, and is based on considering the gap∆associated with each arm; we show While the error termδ“in Thm. 1 is somewhat complicated, one can ﬁx “(say) and`˘ Connection to adversarially robust optimization the form adversary. where “distance” function (but need not be a true distance measure). 2018), while also highlighting the looseness in directly applying the results therein to our setting. Adapting STABLEOPT problem (16) selects deﬁned conﬁdence bounds following: and the algorithm samples arm j arm via the bounds in (Bogunovic et al. 2018), we use those in (8)–(9). uniformly at random, or one may prefer to break ties in (17) by taking the group that attains the lower LCB score in (18). Instance-independent regret bound challenging, though would be of interest for future work. We instead focus on instance-independent bounds. Since there always exist instances for which ﬁnding the best group requires an arbitrarily long time (e.g., see Sec. 5), we instead measure the performance using the simple regret, whose deﬁnition is repeated from (3) as follows: where of G Here and subsequently, we deﬁne are in r0, 1s, and for later convenience we similarly deﬁne T implicit constant factor, but give the precise constants in the proof. Theorem 2. variant of STABLEOPT yields with probability at least 1 ´ Opδq that 2017) to deduce an upper bound of the right-hand side, in particular relying on Lemma 2. maxminfpx, cq, wherexis chosen by the algorithm, andccan be viewed as being chosen by an The main focus in (Bogunovic et al. 2018) is ﬁnding an -stable optimal input for some function f: ∆pxq “ tx´ x : x P Dand dpx, xq ď uis the perturbed region aroundx, anddp¨, ¨qis a generic In Appendix D, we discuss a partial reduction to a grouped max-min problem presented in (Bogunovic et al. Intuitively, this criterion selects the optimistic estimate of the best group and its pessimistic estimate for the worst UCBandLCBvalues computed in each round. Instead of using the general RKHS-based conﬁdence The method for breaking ties in (17)–(18) does not impact our analysis. For instance, one could break ties Tis the time horizon, andGis the group returned afterTrounds. For STABLEOPT, the theoretical choice is given by (Bogunovic et al. 2018) With these deﬁnitions in place, we have the following result; we state a simpliﬁed form with ﬁxedand an The proof is given in Appendix B, and is based on initially following the max-min analysis of (Bogunovic et al. To compare Thm. 2 with Thm. 1, it helps to consider the following corollary. Corollary 1. satisfy outputs G worst-case instance. Moreover, a standard reduction to ﬁnding a biased coin (e.g., (Mannor and Tsitsiklis 2004)) reveals that any algorithm must use the preceding number of arm pulls (or more) on worst-case instances, at least up to the replacement of case the number of arm pulls given in Thm. 1 can be signiﬁcantly smaller. We expect that STABLEOPT also enjoys instance-dependent guarantees (see Sec. 7 for some numerical evidence), though Thm. 2 does not show it. We follow the high-level approach of (Kaufmann, Capp assumption adopted therein. Assumption 3. their mean in the limit as µ cleaner form that can be compared directly to the upper bounds. Assumption 4. means µ also Bernoulli rewards under the additional requirement of means strictly bounded away from zero and one (e.g., µP p0.01, 0.99q for all j). only a small amount) to form a different instance with a different optimal group; see Lemma 4 in the appendix. An additional technical challenge here is that even if the perturbed instance is non-identiﬁable due to the new max-min arm appearing in multiple groups. To circumvent this issue, we introduce the following deﬁnition for the algorithm’s success. Deﬁnition 1. instances if it satisﬁes the following: the conﬁdence bounds are valid, the algorithm never terminates. Theorem 3. with respect to the instances satisfying Assump. 1, Assump. 3, and Assump. 4. Fix any identiﬁable instance A “ pa algorithm is run on instance A, we have the following: ∆ě ∆for allj “ 1, . . . , nand some∆ą 0. Then, with probability at least1 ´Opδq, the algorithm`˘ This result matches the scaling in Thm. 1 whenever∆“ ∆for allj, which can be viewed as a minimax On the other hand, it is also of interest to understand instances that are not of the worst-case kind, in which µP p0, 1q. Any two distributionsP, PP Pare mutually absolutely continuous, andDpP}Pq Ñ 0 The following assumption is not necessary for the bulk of our analysis, but will allow us to state our results in a and µ, it holds that DpP}Pq ď˜Cpµ´ µq. As is well-known from previous works, the above assumptions are satisﬁed in the case of Gaussian rewards, and We use the widely-adopted approach of considering a base instance, and perturbing the arm means (ideally •For any identiﬁable instance in the class, the algorithm almost surely terminates, and returns the max-min optimal group (i.e., G) with probability at least 1 ´ δ. • For any non-identiﬁable instance in the class, the algorithm may or may not terminate, but has a probability at most δ of returning a group that is not max-min optimal. We note that successive elimination in Sec. 3 satisﬁes these conditions; in the non-identiﬁable case, as long as , ..., aqwith distributionspP, ..., Pqand a speciﬁed groupingG “ pG, ..., Gq. Then, when the different optimal group, and then quantifying the number of arm pulls required to distinguish the two instances. This turns out to be straightforward when steps to deduce such a bound depending on the number of groups-per-arm (which could alternatively be upper bounded trivially by |G|), stated as follows and proved in Appendix C. Corollary 2. there exists an integer pulls is lower bounded by where ∆ Cases with near-matching behavior. dictated by our upper and lower bounds are near-matching. This is because any behavior is not necessarily observed, as we discuss below. bounds for the standard best-arm identiﬁcation problem (Jamieson and Nowak 2014; Kaufmann, Capp Garivier 2016), with items-per-group and groups-per-item are bounded, say by some absolute constant. In this case, the second term in (24) is dictated by ofj R G one with the smallest combined with groups-per-item, it follows that Cases where the bounds are not tight. number of pulls for arms in a given group pulled enough. It turns out that we can identify weaknesses in both of these, and it is likely that neither bound can consistently be identiﬁed as “tighter” than the other. arm • For each j P G, the average number of pulls satisﬁes where˜C appears in Assump. 4, and ∆and ∆are deﬁned in Sec. 2.1. The proof is given in Appendix C, and is based on shifting the given instance to create a new instance with a While Thm. 3 does not directly state a lower bound on the total number of pulls, we can perform some further In the following section, we discuss the strengths and weaknesses of our bounds in detail. “ maxt∆, ∆u, which matches ∆` ∆(see the lower bound) to within a factor of two. Regardingj R G, it is useful to note that∆“ min∆, and∆appears in Cor. 2. Hence, the gaps between worst arms play a fundamental role in both the upper and lower bounds. However, near-matching As an initial positive case, under the trivial groupingG “ tt1u, t2u, . . . , tnuu, our bounds reduce to near-tight More generally, our upper and lower bounds have near-matching dependencies when both the number of in the upper bound. To see this, ﬁrst note that within each group, the arm with the smallest∆is the “ 0). Thus,j “ jpGqincurs the most pulls inG, and has∆“ maxt∆, ∆u. The deﬁnition of∆ To see a potential weakness in the upper bound in Thm. 1, consider an instance with|G| “ 2and only a single jin the optimal groupG, and a large number of arms in the suboptimal group. For the arms in the suboptimal group signiﬁcantly smaller mean reward. In this case, it is feasible to quickly identify selecting a small number of arms (namely, sampling them a relatively small number of times. Hence, it is not necessary to sample every arm in other hand, our proposed elimination algorithm immediately starts by pulling every arm, which may be highly suboptimal if |G has one low-mean arm. In this case, the total number of arm pulls should clearly increase linearly with the number of arms, but the lower bound in Thm. 3 does not capture this fact; it only states that both in G Difﬁculties in obtaining uniformly tight bounds grouped bandit problem is connected to problem of good-arm identiﬁcation (Katz-Samuels and Jamieson 2020), and that improved algorithms might randomly select subsets of arms within the groups (possibly starting with a small subset and expanding it when further information is needed). In fact, in the examples we gave, if the mean reward of with a mean below that of 2020). Even this sub-problem required a lengthy and highly technical analysis in (Katz-Samuels and Jamieson 2020), and the difﬁculty appears to compound further when there are multiple non-overlapping groups, and even further when overlap is introduced. Thus, we believe that the development of near-matching upper and lower bounds is likely to be challenging in general. Discussion on identiﬁability assumptions contrast, we do not require a unique worst arm within every group; multiple such arms only amounts to more ways in which the suboptimal group can be identiﬁed as such. requiring to identify a group whose worst arm mean is within The changes in the analysis are entirely analogous to similar ﬁndings in the standard best-arm identiﬁcation problem (e.g., see (Gabillon et al. 2012)), so we do not go into detail. In this section, we present some basic experimental results comparing the algorithms considered in the previous sections. In each experiment, we generate 10 instances, each containing 100 arms and 10 possibly overlapping groups. The arm rewards are Bernoulli distributed, and the instances are generated to ensure a pre-speciﬁed minimum gap value (∆) as per (5), and we consider arm means are given in Appendix E. Empirical error rates (or simple regret values) are computed by performing 10 trials per instance, for a total of 100 trials. These bounds are primarily adopted for theoretical convenience, so in our experiments we adopt the more practical choice of Appendix E. natural stopping condition for STABLEOPT is to stop when highest max-min LCB value exceeds all other groups’ max-min UCB values. However, this often requires an unreasonably large number of pulls, due to the existence of UCB values that are only slightly too low for the algorithm to pull based on. We therefore relax this rule be only requiring it to hold to within a speciﬁed tolerance, denoted by values in Appendix E. the current best guess of the max-min optimal group. We choose to return the group with the best max-min LCB score, though the max-min empirical mean would also be reasonable. G, suppose that half of them have a mean reward signiﬁcantly above that ofj, and the other half have a In contrast, the main looseness is clearly in the lower bound if we modify the above example so thatGonly should be pulled sufﬁciently many times. jwere to be revealed to the algorithm, the remaining task of determining whetherGcontains an arm The unique optimal group assumption could be removed by introducing a tolerance parameter, and only that are belowget capped toin the upper bound Thm. 1. Our lower bounds can also be adapted accordingly. Conﬁdence bounds.Both Successive Elimination and STABLEOPT rely on the conﬁdence bounds (8)–(9). ˆµ˘?withc “ 1. The theoretical bounds, as well as difference choices ofc, are explored in Stopping conditions.Successive Elimination is deﬁned with a stopping condition, but STABLEOPT is not. A We will also explore the notion of simple regret, and to do so, both algorithms require a method for declaring Effect of ∆. for Successive Elimination. that STABLEOPT can adapt to easier instances in the same way as Successive Elimination; obtaining theory to support this would be interesting for future work. by comparing its empirical performance with Successive Elimination. Within each group, we identify the worst arm using the UCB algorithm with the same stopping rule as that of STABLEOPT described above, and among the arms identiﬁed, the one with the highest LCB score is returned. Fig. 2 supports our discussion in Sec. 2.2, as we observe that this naive approach requires considerably more arm pulls, and does not appear to improve even as due to stringent stopping conditions, and an investigation of the average simple regret reveals that the algorithms in fact learn much faster despite not yet terminating, especially for STABLEOPT, and especially when see Fig. 3 (error bars show half a standard deviation). These results again support the hypothesis that STABLEOPT naturally adapts to easier instances, though our theory only handles the instance-independent case. promising groups, whereas Successive Elimination always treats every non-eliminated arm equally. of conﬁdence width vs. our practical choice of also the STABLEOPT stopping parameter η). We have introduced the problem of max-min grouped bandits, and studied the number of arm pulls for both an elimination-based algorithm and a variation of StableOpt (Bogunovic et al. 2018). In addition, we provided an algorithm-independent lower bound, and identiﬁed some of the potential weaknesses in the bounds and discussed the difﬁculties in overcoming them. We believe that this leaves open several interesting avenues for further work. Figure 1: Plot of total arm pulls used for Successive Elimination and STABLEOPT for ∆ P t0.1, 0.2, 0.4u. Figure 2: Comparison of Successive Elimination and the naive group-wise strategy for ∆ P t0.1, 0.2, 0.4u. From Fig. 1, we observe that the number of arm pulls decreases when the gap∆increases, particularly Comparison to the Naive Approach.We demonstrate that the simple group-wise approach is indeed suboptimal Simple Regret.As seen above, the total number of pulls comes out to be fairly high for both algorithms. This is A possible reason why StableOpt performs better in Fig. 3 is that it more quickly steers towards the more Effect of Conﬁdence Width.In Appendix E, we present further experiments exploring the theoretical choice We ﬁrst formally state the correctness of the algorithm. Lemma 3. qq, with probability at least 1 ´ Proof. We show that with probability at least 1 ´ and the base case E implying that arm, and this holds in particular for implies the ﬁnal minimum in (27) can be restricted to m arms among all groups as J where (29) is an application of (28) to of the conﬁdence bounds, and (32) holds because for each candidate group G P C (Correctness of SE) Suppose that Assump. 1 and Assump. 2 hold. Given P p0, 1qandδ P p0,logp1 ` We deﬁne an event under which the optimal groupGremains a candidate group, and its worst arm pGq remains a candidate worst arm in Gin epoch i: At the beginning of Alg. 1,m“ Gfor allG P GandGP G “ C. HencejpGq P t1, 2, ..., nu “ A, First, the validity of the conﬁdence bounds gives for all G that It remains to show thatGalways remains a candidate potentially optimal group. Denoting the set of worst due to the fact that j must contain only the optimal group Upt, δq Ñ 0 We bound the number of pulls separately for each arm, considering the cases showing that Lemma 2 and sum over the arms to obtain the result. First observe that if that this is the case for all exactly the same number of times after each epoch. Case 1 (j P G being pulled in either of the following scenarios: 1. j is no longer a potential worst arm in any group; 2. G Recall the deﬁnitions of related to ∆ 1. If ∆ By the deﬁnition ofCand (32), we conclude thatGP Cafter thei-th epoch. Combining this withjpGq P , we then have jpGq P A, implying that Eholds. Since the algorithm stops when|C| “ 1andGP Cfor alli, we conclude that the returned setˆC “ C ast Ñ 8, the algorithm will never continue running forever when the conﬁdence bounds remain valid. Having established high-probability correctness in Lemma 3, it remains to bound the number of arm pulls. We henceforth suppose that the conﬁdence bounds are valid, as we already considered in the proof of Lemma 3. is found to be the optimal group, and the algorithm terminates. “ mint∆, ∆u. From the intuition behind each gap value deﬁned in Sec. 2, we note that scenario 1 above is “ ∆, then for all G with j P G, we have where (34) and (40) apply the assumption|UCBpjq ´ LCBpjq| ă, (35) and (39) use the conﬁdence bounds, and (36) and (38) use the deﬁnition of∆. From (40), we have thatjis removed fromAand is no longer pulled. 2. If ∆ Case 2 (j R G 1. j is no longer a potential worst arm in any group; 2. G 3. All the groups G where j P G are no longer candidate groups. The gap values associated with these conditions are is found only after all suboptimal groups are removed. Therefore, the second scenario will never be satisﬁed before the third condition is satisﬁed, and we have ∆ reward satisfying µ Hence, from A where (49) and (55) apply the assumption (51) and (53) use the deﬁnition of where is no longer pulled. “ ∆, then for G ‰ G, we have where (41) and (47) apply the assumption|UCBpjq ´ LCBpjq| ă, (42) and (46) use the conﬁdence bounds, and (43) and (45) use the deﬁnition of∆. Then, (47) implies that all of the non-optimal groups are removed from C, so the algorithm terminates and j is no longer pulled. is found to be the optimal group, and the algorithm terminates; For brevity, we use the shorthandj“ jpGqin the remainder of this section. If the armjhas a mean ∆” ∆. In this case, by the same reasoning as (34)–(40), the ﬁrst condition is satisﬁed andjis removed By the same reasoning, if µă µ, then ∆“ ∆. In this case, for all G ‰ Gwith j P G, we have j P G, we obtain that all of these suboptimal groups are eliminated, and hence scenarios 3 is satisﬁed andj this with Lemma 2, we obtain the bound on number of arm pulls T Summing over the n arms, we obtain the bound on the total number of arm pulls in (15). The ﬁrst steps of the proof follow those of (Bogunovic et al. 2018). With probability at least the conﬁdence bounds in (8)–(9) are uniformly valid, and we henceforth condition on this being the case. For the group G where (58) and (60) use the validity of the conﬁdence bounds, (59) and (61) use the selection rules for and (63) uses the deﬁnitions of the conﬁdence bounds. where (64) follows from (58), (65) bounds the minimum by the average, and (66) follows from the argument leading to (63). is highest when each arm is pulled the same number of times (up to rounding), i.e., Having handled both cases, we conclude that armjis no longer pulled whenUpTptq,q ă. Combining and corresponding arm jP Gselected in round t, we have: Using the choice of Gin (20), we further have: We observe from (7) thatUpt,qdecreases monotonically with respect tot.Therefore,řUpTpt ´ 1q,q where (68) uses the deﬁnition of (70) deﬁnes C log log T choice of  P p0, 1q. We make use of a fundamental result introduced in (Kaufmann, Capp been applied to numerous bandit settings. The following statement is somewhat different from that in (Kaufmann, Capp Lemma 4. two distinct bandit instances such that for any arm pair mutually absolutely continuous. For any stopping time event E depending only on the reward history up to the stopping time and satisfying P where and P deﬁned notion of success; in our case, this is the identiﬁcation of group is the best according to instance probability for all x P r0, 1s (Kaufmann, Capp řUpt,q˘, where we recall that Up0, δq “ 1. Hence: Combining (66) and (72) and letting P p0, 1qbe an arbitrary ﬁxed constant gives the desiredOlog`˘˘`˘ regret bound. The termin the error probability is at mostOpδqregardless of the ´e, and Garivier 2016), and the differences are explained in Sec. C.2. (Implicit in (Kaufmann, Capp´e, and Garivier 2016)) LetA “ pa, ..., aqandA“ pa, ...., aqbe dpx, xq “ xlog`p1 ´xqlogis the binary relative entropy function, withdp0, 0q “ dp1, 1q “ 0, denotes the probability under instance A. High-probability guarantees for MAB problems are based on attaining a small error probability for a suitablyδ P0,, as long as the best group inAis not max-min optimal inA. Sincedpx, 1 ´ xq ě log Then, given a “base” instance suboptimal, ideally with each arm pulls. Lemma 4 is slightly different from that in (Kaufmann, Capp assumed to be almost-surely ﬁnite under rather than allowing all of r0, 1s. stopping time is used for two purposes: To apply Wald’s lemma to a sum of log-likelihood ratios under instance A, and to prove that requires the stopping time to be almost-surely ﬁnite under Garivier 2016) establishes that if or equivalently explicitly assume that P As suggested by Lemma 4, we prove Thm. 3 by taking the given instance with optimal group or more of its arms (from µ second best group. We consider the two cases in the theorem statement as follows. Case 1 (j P G alli ‰ j Speciﬁcally, we choose and mean with Hence, no matter how small the new instance. number of pulls of j P G since arbitrarily small, we obtain the desired bound (22). Case 2 (j R G arm’s mean up, even by an arbitrarily large amount, may fail to make to shift all arms with mean at most we can perform an arbitrarily small perturbation similar to Appendix A of (Scarlett, Bogunovic, and Cevher 2019). As a result, G where α is arbitrarily small, we obtain the lower bound (23) on the total number of arm pulls within group G. To understand this difference, we note that in (Kaufmann, Capp´e, and Garivier 2016), the almost-sure ﬁnite Without loss of generality, assume that in the original instance,G“ Gis the optimal group, andGis the , and whereµchanges to another valueµ; the corresponding distributions are denoted byPandP. ∆in Sec. 2.1, the choiceα “ 0would makeµexactly equal toµ(the subtraction of∆aligns the µ, and the subtraction of∆“ µpGq ´ µpGqfurther shifts this toµ). Hence, applying Lemma 4 withEbeing the event of outputtingG,we obtain the following lower bound for DpP}Pq “ 0for alli ‰ j. Upper bounding the denominator via Assump. 4 and using the fact thatαcan be `p1 `αqpµ´µqfor arbitrarily smallα ą 0. For any arms inGwith mean exactlyµ, PandPare the distributions in the original and modiﬁed instances. Applying Assump. 4 and the fact that The ﬁrst term in (24) follows immediately by summing over establish the second term. since the deﬁnition of ∆ each group-wise lower bound produces a valid lower bound on total arm pulls for the instance instance with overlapping groups, we cannot simply sum the group-wise lower bounds in this way. This is because the overlaps between groups can cause potential double (or triple, etc.) counting of the summation. disjoint groups). Dividing the group-wise bound by the lower bound on total arm pulls upon adding up the group-wise bounds. Thus, we can weaken (77) to with the important difference that it is now valid to further sum over groups; doing so gives the second term in (24) as desired. Recall that the general STABLEOPT formulation is given in (16). A connection between (16) and a certain grouped max-min problem was already discussed in (Bogunovic et al. 2018), focusing on non-overlapping groups. In particular, it was noted that the interplay between we can replace px, δq by pG, jq and transform (16) as follows: Space (RKHS) corresponding to some kernel function can choose the 0-1 kernel kpj, j bound on the regret after suboptimal. This is because both the squared RKHS norm (Bogunovic et al. 2018) scale linearly with suitably adapting the analysis in a manner more directly targeted at our setup, as detailed in Sec. 4 and Appendix B. Here we describe more precisely how the groups are generated in our experiments, and how the arm means are assigned. on average. For any subsequently non-allocated arms, we assign it to a uniformly random group. In addition, for any empty group, we assign 10 uniformly random arms into it. By the deﬁnition ∆“ µ´ µ, the inequality (23) gives for any G ‰ Gthat We observe that (77) provides a group-wise lower bound. In a disjoint grouping setup, a simple summation over To resolve this issue, we use the assumption that each arm can be in at mostmgroups (withm “ 1amounting to The theory in (Bogunovic et al. 2018) assumed thatfpxqhas a bounded norm in a Reproducing Kernel Hilbert While we can apply the main result of (Bogunovic et al. 2018) to deduce an instance-independentO We allocate each arm into each group independently with probability1{10, so that each group contains 10 arms We arbitrary choose the ﬁrst group to be the optimal one, and set its worst armjto have a mean reward of0.5 jis chosen to ensure thatGis unique). We further choose the second group to be a suboptimal group whose Figure 5: Comparisons of number of arm pulls for various STABLEOPT stopping condition, and ∆ (gap value).) worst arm uniform in relevant worst arm in the relevant group G. Theoretical Conﬁdence Bounds. theoretical choice in Sec. 2.3. The comparison is given in Fig. 4, where we observe that the former requires fewer arm pulls and is less prone to runs with an unusually high number of pulls, suggesting that the theoretical choice may be overly conservative. For both choices, there were no failures (i.e., returning the wrong group) in any of the runs performed, both here and in the experiments in Sec. 7. jmeets the gap value exactly, i.e.µ´ µ“ ∆. Then, we generate other groups’ worst arms to be r0, µs. Finally, we choose the means for the remaining arms to be uniform inrµ, 1s, wherejis the set to one), and η, the conﬁdence width beyond which STABLEOPT terminates (previously set to 0.01). (due to more conservative conﬁdence bounds), but appears to impact STABLEOPT more. However, the second row indicates that this is at least partly due to the stringent stopping condition, since the less stringent choice brings the two algorithms back closer together. this in Table 1. For the most part, the algorithms return the correct group on all 100 trials, but STABLEOPT indeed starts to produce errors when both c and η are chosen too aggressively, particularly c “ 1 and η “ 0.02. increasing behavior for both values of small simple regret, but that more care is needed (compared to Successive Elimination) in choosing the conﬁdence bounds and stopping rule when the goal is exact best-group identiﬁcation. Acknowledgment. number R-252-000-A74-281. Varying c and η.Here we explore the effect of varyingc, the constant in the conﬁdence width?(previously In the top row of Fig. 5, we see that increasingcnaturally increases the number of arm pulls for both algorithms A caveat here is that increasingηputs STABLEOPT at a higher risk of returning the wrong group; we investigate Finally, in Fig. 6, we plot the simple regret withc “ 2, in contrast toc “ 1used in Fig. 3 and Fig.??. Again, cnaturally increases the number of arm pulls for both algorithms, but we observe the same general