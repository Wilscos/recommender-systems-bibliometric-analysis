Transportation networks in major metropolitan areas carry several million car trips and commutes per day, giving rise to a chaotic and highly volatile environment for the average commuter. As a result, navigation apps like Google Maps, Waze and MapQuest have seen an explosive growth in their user base, routinely receiving upwards of 10 per second during rush hour – and going up to 10 the US and China [ and without causing any “ex-post” regret at the user end; otherwise, if a user could have experienced better travel times along a non-recommended route, they would have no incentive to follow the app recommendation in the ﬁrst place. In the language of congestion games [35], this requirement is known as a “Wardrop equilibrium”, and it is typically represented as a high-dimensional vector describing the traﬃc ﬂow along each path in the network [44]. Ideally, this traﬃc equilibrium should be computed before making a routing recommendation in order to minimize the number of disgruntled users in the system. In practice however, this is rarely possible: the state of the network typically depends on random, unpredictable factors that may vary considerably from one epoch to the next – e.g., due to road incidents, rain, fog and/or other weather conditions – so it is generally unrealistic to expect that such a recommendation can be made in advance. Instead, it is more apt to consider an online recommendation paradigm that unfolds as follows: Of course, the crux of this paradigm is the optimization algorithm used to update traﬃc ﬂow proﬁles from one epoch to the next. Any such algorithm would have to satisfy the following sine qua non requirements: ii) iii) iv) To put these desiderata in context, we begin below by reviewing the most relevant works in this direction. Related work. who showed that a variant of the exponential weights ( converges to equilibrium at an was subsequently extended to routing games with stochastic cost functions by Krichene et al. mean Wardrop equilibria (again, in the Cesàro sense). However, if the learning rate of the At each time slott= 1,2, . . . , T, a control interface – such as Google Maps – determines a traﬃc assignment proﬁle and routes all demands received within this slot according to this proﬁle. The interface observes and records the travel times of the network’s users within the time slot in question; based on this feedback, it updates its candidate proﬁle for the next epoch and the process repeats. Universal convergence rate guarantees in terms of the number of epochs: The distance from equilibrium of the candidate traﬃc assignment afterTepochs should be as small as possible in terms ofT. However, learning methods that are well-suited for rapidly ﬂuctuating environments may be too slow in static environments (i.e., when cost functions do not vary over time); conversely, methods that are optimized for static environments may fail to converge in the presence of randomness. As a result, it is crucial to employ universal algorithms that achieve the “best of both worlds” in terms of convergence speed. Fast convergence in terms of the size of the network: The algorithm’s convergence speed must be at most polynomial in the sizeGof the underlying graph (i.e., its number of edgesEplus the number of verticesV). In turn, since the number of pathsPin the network is typically exponential inG, the algorithm’s convergence speed must be at most polylogarithmic in P . Scalable per-iteration complexity: An algorithm can be implemented eﬃciently only if the number of arithmetic operations and total memory required at each iteration remains scalable as the network grows in size. In practice, this means that that the algorithm’s per-itration complexity must not exceed O(G). Parameter-freeness: In most practical situations, the parameters of the model – e.g., the distribution of random events or the smoothness modulus of the network’s cost functions – cannot be assumed known, so any routing recommendation algorithm must likewise not require such parameters as input. 22], who showed thatExpWeightalso enjoys anO(log PT) convergence rate to ExpWeight algorithm is not chosen appropriately in terms of T , the method may lead to non-convergent, chaotic behavior, even in symmetric congestion games over a 2-link Pigou network [37]. From an optimization viewpoint, nonatomic congestion games with stochastic cost functions correspond to convex minimization problems with stochastic ﬁrst-order oracle feedback. In this setting, the Krichene et al. convergence speed of Blum et al. a smooth convex potential – known as the Beckmann–McGuire–Winsten (BMW) potential [6] – this rate can be improved to of Nesterov Nesterov coupling it with a “mirror descent” template in the spirit of [ proposed an accelerated method with an exponential projection step that is particularly well-suited for congestion problems. In fact, as we show in the sequel, it is possible to design an accelerated exponential weights method – which we call an O(log P Importantly, despite its optimality in the static regime, altogether in stochastic problems; moreover, the method’s step-size must also be tuned with prior knowledge of the problem’s smoothness parameters (which are not readily available to the optimizer). The universal primal gradient descent ( a work-around to resolve the latter issue, but it relies on a line-search mechanism that cannot be applied to stochastic problems, so it does not resolve the former. Instead, a partial solution for the stochastic case is achieved by the accelerated stochastic approximation ( algorithm of Lan regimes; however: a) the running time a function of the accuracy threshold required; and b) of the smoothness modulus of the game’s cost functions (which cannot be computed ahead of time). To the best of our knowledge, the ﬁrst parameter-free algorithm with optimal rate interpolation guarantees is the AcceleGrad algorithm of Levy et al. developed for unconstrained problems (and assumes knowledge of a compact set containing a solution of the problem). The UnixGrad proposal of Kavis et al. the desired adaptation in constrained problems, but under the requirement of a bounded Bregman diameter. This requirement rules out the inﬁnite diameter under the entropy regularizer that generates the so the convergence speed of UnixGrad ends up being polynomial in the number of paths in the network – and since the latter scales exponentially with the size of the network, UnixGrad is unsuitable for networks with more than 30 or so nodes. Finally, another major challenge in terms of scalability is the algorithm’s per-iteration complexity, i.e., the memory and processing requirements for making a single update. In regard to this point, the per-iteration complexity of the and UnixGrad algorithms is linear in the number of paths exponential in the size of the network. The only exception to this list is the (non-accelerated) ExpWeight iteration via a technique known as “weight-pushing” [ technique is by no means universal: it was speciﬁcally designed for the and it is not applicable to any of the universal methods discussed above (precisely because of the acceleration mechanism involved). [30]. On the downside, if applied directly to our problem, the algorithm of [30]has a catastrophic Θ(P) dependence on the number of paths; however, by T) rate in static environments. Our contributions. in at least two of the axes mentioned above: either they are slow / non-convergent outside the speciﬁc regime for which they were designed, or they cannot be implemented eﬃciently (see also Table 1 for an overview). Consequently, our paper focuses on the following question: Is it possible to design a scalable, paramater-free traﬃc assignment algorithm which is simultaneously order-optimal in both static and stochastic environments? To provide a positive answer to this question, we take a two-step approach. Our ﬁrst contribution is to design an adaptive exponential weights algorithm – dubbed – which is simultaneously order-optimal, in both environments. Informally, we have: Informal Version of Theorem 3. convergence guarantees after T epochs: ii) In the above, the logarithmic dependency on AdaWeight successfully solves the challenge of achieving optimal convergence rates in both static and stochastic environments, while remaining parameter-free and “anytime” (i.e., there is no need to tune the algorithm in terms of that simultaneously achieves these desiderata. On the other hand, a crucial drawback of level, i.e., it updates at each stage a state variable of dimension per-iteration complexity is typically exponential in improved algorithm, which we call and which emulates the instead of maintaining a state variable per path, node, with dimension equal to the node’s out-degree. Second, the recommended path for any particular user of the navigation interface is constructed “bottom-up” via a sequence of routing probabilities updated at each node, so there is no need to ever keep in memory (or update) a path variable. This process looks similar to the weight-pushing technique of [ down the per-iteration complexity of the mechanism of weight-pushing; and since these averaging steps are downright essential for the universality ofAdaWeight executing these averaging steps is based on the following observation: although the averaged recommendations proﬁles cannot be “weight-pushed”, the induced edge-load proﬁles (i.e., the mass of traﬃc induced on each edge) can. This observation allows us to introduce a novel dynamic programming subroutine – called PushPullMatch – which computes eﬃciently these averaged loads and then uses them to reconstruct a set of routing recommendations that are consistent with these loads. In this way, by combining the routine, In static networks,AdaWeightconverges to a Wardrop equilibrium at a rate of In stochastic networks, it converges to a mean Wardrop equilibrium at a rate of√ AdaLightonly requiresO(G) memory and processing power per update, all the while retaining the sharp convergence properties of the more detail, we have: Informal Version of Theorem 4. a rate of environments; moreover, the total amount of arithmetic operations required per epoch is where G is the size of the network. This result shows that AdaWeight convergence properties of convey the ideas involved, we also describe the it is not scalable per se). Paper outline. congestion game setup, the relevant equilibrium notions, and our learning model. Subsequently, to set the stage for our main results, we present in Section 3 the classic exponential weights algorithm as well as the AcceleWeight variant which achieves an convergence rate in static environments; both algorithms are non-adaptive, and they are used as a baseline for our adaptive results. Our analysis proper begins in Section 4, where we present the we present the local ﬂow setup used to construct the convergence guarantees. Finally, in Section 6, we report a series of numerical experiments validating our theoretical results in real-life transport networks. We begin in this section by introducing the basic elements of our model. 2.1. consider a class of nonatomic routing games deﬁned by the following three primitives: (i) an underlying network structure; (ii) the associated set of traﬃc demands; and (iii) the network’s cost functions. The formal deﬁnition of each of these primitives is as follows: Table 1:Overview of related work in comparison to theAdaLightalgorithm (this paper). For the purposes of this table,Grefers to the size of the underlying graph whilePrefers to the number of relevant paths in the network (soPis typically exponential inG). The “anytime” property refers to whether the number of iterationsTmust be ﬁxed at the outset and included as a parameter in the algorithm; if not, the algorithm is labeled “anytime”. Finally, the “parameteragnostic” property refers to whether any other parameters – such as the Lipschitz modulus of the network’s cost functions – need to be known beforehand or not. All estimates are reported in the O(·) sense. The game.Building on the classic congestion framework of Beckmann et al.[6], we 1. Network structure: 2. Traﬃc demands and ﬂows: 3. Congestion costs: the world” – that takes values in some ambient probability space (Ω In this general setting, the only assumption that we will make for the game’s cost functions is as follows: P-almost all ω ∈ Ω. Assumption 1 represents a very mild regularity requirement that is satisﬁed by most congestion models that occur in practice – including BPR, polynomial, or regularly-varying latency functions, cf. [ treat Assumption 1 as a standing, blanket assumption and we will not mention it explicitly in the sequel. setE. The focal point of interest is a set of distinct origin-destination (O/D) pairs O, D)∈ V × Vindexed byi ∈ N={1, . . . , N}. For eachi ∈ N, we assume given a directed acyclic subgraphG≡(V, E) ofGthat determines the set of routing paths fromOtoD, and we writePfor the corresponding set of paths joiningOtoDinS G. For posterity, we will also writeP=Pfor the set of all routing paths in the network, andP=|P|andP=|P|for the respective cardinalities; likewise, weP will writeG=|V|+|E|for the size ofG, andG=Gfor the total size of the network. that is to be routed fromOtoDviaP; we also writeM=kM k=Mand M=kM k=maxMfor the total and maximum traﬃc demand associated to the network’s O/D pairs respectively. Now, to route this traﬃc, the set of feasible traﬃc assignment proﬁles – or ﬂows – is deﬁned asP i.e., as the product of scaled simplicesF=QM∆(P). In turn, each feasible ﬂow proﬁle f ∈ F induces on each edge e ∈ E the corresponding traﬃc load i.e., the accumulated mass of all traﬃc going throughe. It is also worth noting here that the path indexp ∈ Pcompletely characterizes theO/Dpairi ∈ Nto which it belongs; when we want to make this relation explicit, we will write finstead of f. depending on the total traﬃc on the edge and/or any other exogenous factors. Formally, we will collectively encode all exogenous factors in a state variableω ∈Ω – the “state of we will assume that each edgee ∈ Eis endowed with a cost functionc: R×Ω→ R which determines the costc(`(f);ω) of traversinge ∈ Ewhen the network is at state ω ∈Ω and traﬃc is assigned according to the ﬂow proﬁlef ∈ F. Analogously, the cost to traverse a pathp ∈ Pwill be given by the induced path-cost functionc: F ×Ω→ R deﬁned asX 2.2. functions (as modeled by To elaborate further on this, it will be convenient to deﬁne the mean cost function of edge e ∈ E as and consider the corresponding (random) ﬂuctuation process i.e., the deviation of the network’s cost functions at state magnitude of these deviations may then be quantiﬁed by the randomness parameter where Assumption 1). Informally, larger values of implying in turn that the traﬃc assignment problem becomes more diﬃcult to solve; on the other hand, if distinction plays a key role in the sequel so we formalize it as follows: Deﬁnition 1 is static; otherwise, if σ > 0, we say that the environment is stochastic. The dependence of the network’s cost functions on exogenous random factors is the main diﬀerence of our setup with standard congestion models in the spirit of Beckmann et al. and Nisan et al. seen as special cases of our framework: Example 2.1 deterministic routing models of Blum et al. Example 2.2 process, Krichene et al. ﬁxed, but cost measurements are only accurate up to a random, zero-mean error. In our framework, this can be modeled by simply assuming a familly of cost functions of the form c(f; ω) = ¯c Besides these standard examples, our model is suﬃciently ﬂexible to capture other random factors such as weather conditions, traﬃc accidents, road incidents, etc. For instance, to model the diﬀerence between dry and wet weather, one can take Ω = consider a set of cost functions with the congestion costs are higher when the roads are wet. However, to maintain the generality of our model, we will not focus on any particular application. 2.3. an instance of a routing game, deﬁned formally as a tuple Γ is shorthand for the network’s cost functions analyzing the game, each individual instance Γ positive probability only to a single game Γ ω ∈ Ω, but with congestion costs given by the mean cost functions Regimes of uncertainty and examples.The advent of uncertainty in the game’s cost ess supdenotes the essential supremum over Ω with respect toP(soσ ≤2Hby (Static and Stochastic Environments).Whenσ= 0, we say that the environment (Deterministic routing games).The static regime described above matches the . In these models, the network only has a single (deterministic) state so, trivially, Notions of equilibrium.In the above framework, each state variableω ∈Ω determines ≡Γ(G, N, P, ¯c) which has the same network and routing structure as every Γ, Motivated by the route recommendation problem described in the introduction, we will focus on traﬃc assignment proﬁles where Wardrop’s unilateral optimality principle [ average, i.e., all traﬃc is routed along a path with minimal mean cost. Formally, we have: Remark 1. Deﬁnition 2 means that, on average, no user has an incentive to deviate from the recommended route; obviously, when the support of usual deﬁnition of a Wardrop equilibrium [ important and we discuss it in detail in the next section. Importantly, the problem of ﬁnding an equilibrium ﬂow of a (ﬁxed) routing game Γ admits a potential function – often referred to as the Beckmann–McGuire–Winsten ( potential [6, 14]. Speciﬁcally, for a given instance ω ∈ Ω, the BMW potential is deﬁned as and it has the fundamental property that equilibria of Γ property can be extended to the mean game Γ where the randomness is “averaged over”. Clearly, the most direct candidate for a potential function in this case is the mean potential Since turn, continuously diﬀerentiable and convex on not known, we will not assume that Φ (and/or its gradients) can be explicitly computed in general. Nevertheless, building on the deterministic characterization of Beckmann et al. we have the following equivalence between mean equilibria and minimizers of Φ: Accordingly, a ﬂow proﬁle it is a minimizer of Φ over Eq(Γ) = arg min In view of Proposition 1, Φ provides a natural merit function for examining how close a given ﬂow proﬁle ﬂow proﬁles Clearly, the sequence in question converges to the speed of this convergence is also captured by will be stated in terms of Gap(T ). (Mean equilibrium ﬂows).We say thatf∈ Fis a mean equilibrium ﬂow if cis continuous and non-decreasing for alle ∈ E, the meanBMWpotential Φ is, in First, apply the dominated convergence theorem (saying that gradients and expec-hi f∈ F,t= 1,2, . . ., we deﬁne the associated equilibrium gap afterTepochs as 2.4. as follows: ii) Concurrently, the state ω iii) In what follows, we will analyze diﬀerent learning algorithms for updating sequence of events, and we will examine their equilibrium convergence properties in terms of the equilibrium gap function no prior knowledge of the enviroment, the distribution of random events, the network’s cost functions, etc., so we will pay particular attention to the dependence of each algorithm’s guarantees on these (otherwise unknown) parameters. In the rest of our paper, we discuss a series of routing algorithms and their equilibrium convergence guarantees. To set the stage for our main contributions, we begin by presenting two learning methods that are order-optimal in the two basic regimes described in the previous section: ii) static environments. Both methods rely crucially on the (rescaled) logit choice map components as 3.1. tial weights algorithm of Blum et al. [8] in standard pseudocode form: Algorithm 1: Exponential weights (ExpWeight) We then have the following equilibrium convergence result: Sequence of events.With all this in hand, the sequence of events in our model unfolds At each time slott= 1,2, . . ., the navigation interface selects a traﬃc assignment proﬁle f∈ F and it routes all demands received within this time slot according to f. The interface observes the realized congestion costsC=c(`(f);ω) along each edge e ∈ E; subsequently, it uses this information to update the routing proﬁlef, and the process repeats. The “vanilla” exponential weights (ExpWeight) method of Blum et al.[8]for stochastic environments. An accelerated exponential weights algorithm – which we callAcceleWeight– for )for the proﬁle thereof. Exponential weights in stochastic environments.We begin by presenting the exponen- Suppose thatExpWeight(Algorithm 1) is run forTepochs with a ﬁxedq√ proﬁle The proof of Theorem 1 relies on standard techniques, so we omit it; for a series of closely related results, we refer the reader to Krichene et al. 2.14 and Theorem 4.1 that it is order-optimal in stochastic environments [ speed is logarithmic in On the downside, the convergence rate obtained for Algorithm 1 concerns the timeaveraged ﬂow practical applications. Second, Theorem 1 is not an “anytime” convergence result in the sense that the algorithm’s learning rate valid otherwise). This issue can be partially resolved either via a doubling trick [ the cost of restarting the algorithm ever so often) or by using a variable learning rate of the form convergence speed). However, in either case, the rate time averages, not the actual recomendations. 3.2. the static regime, i.e., when there are no exogenous variations in the network’s cost functions (σ= 0); in this case, it is reasonable to expect that the ExpWeight is Lipschitz smooth, so the optimal convergence speed in static environments is [9, 31]. Proposition 2. particular, its smoothness modulus is of the longest path in P. Given that Φ is smooth, the iconic accelerated gradient algorithm of Nesterov ¯f= (1/T )Pfenjoys the equilibrium convergence rate: ExpWeightachieves anO1Tconvergence speed in the number of epochsT, so γ∝1/t(at the cost of introducing an additionallog Tfactor in the algorithm’s Accelerated exponential weights in static environments.We now turn our attention to ∈ F, combining Proposition 1 and Assumption 1 yields k∇Φ(f) − ∇Φ(f)k= max|¯c(f) − ¯c(f “oﬀ the shelf”, the constants involved would be linear in and hence exponential in the size of the network. Instead, building on ideas by Allen-Zhu and Orecchia the acceleration mechanism of Nesterov template. The resulting accelerated exponential weights ( in pseudocode form as follows: Algorithm 2: Accelerated exponential weights (AcceleWeight) At a high level, replaces Euclidean projections with the logit map following convergence guarantee: Theorem 2. rithm 2) in a static environment (σ = 0) enjoys the equilibrium convergence rate The proof of Theorem 2 is based on techniques that are widely used in the analysis of accelerated methods so, to streamline our presentation, we relegate it to Appendix A. Theorem 2 conﬁrms that, in the static regime, with an optimal important to note that Theorem 2 conﬁrms that, in static environments, accelerated exponential weights achieves a much faster convergence rate than this improvement comes with several limitations: First and foremost, as we discuss in Section 6, a universal method (i.e., an algorithm that is simultaneously order-optimal in both static and stochastic environments). Second, to obtain the accelerated rate AcceleWeight β(which is not realistically available to the learner), so the method is not adaptive. These are both crucial limitations that we seek to overcome in Sections 4 and 5. 3.3. on the per-iteration complexity of is that Algorithms 1 and 2 both require arithmetic operations and memory storage). This is ineﬃcient in large-scale networks where Pis exponentially large in either of these algorithms in practice. As discussed in Section 1, there exist variants of the exponential weights algorithm that can be implemented eﬃciently in via a dynamic programming procedure known as “weight-pushing” [ technique is limited to boosting the computation step involving the logit mapping (Line The sequence of ﬂow proﬁlesf, f, . . .generated byAcceleWeight(Algo- AcceleWeightfails to converge altogether in the stochastic regime, so it is not Per-iteration complexity of each method.We close this section with a short discussion 3 of Algorithm 1 and Line 3 of Algorithm 2) and cannot eﬃciently execute other steps ofAcceleWeight involved in the acceleration mechanism). To maintain the ﬂow of our discussion, we will revisit this issue in detail in Section 5. 4.1. the situation so far, we have seen that ExpWeight attains an is order-optimal in the stochastic case but suboptimal in static environments; by contrast, AcceleWeight guarantees in the presence of randomness and uncertainty. Consequently, neither of these algorithms meets our stated objective to concurrently achieve order-optimal guarantees in both the static and stochastic cases (and without requiring prior knowledge of the problem’s smoothness modulus). To resolve this gap, we propose below an adaptive exponential weights method – for short – which achieves these objectives by mixing the acceleration template of with the dual extrapolation method of Nesterov AdaWeight below: Algorithm 3: Adaptive exponential weights (AdaWeight) The main novelty in the deﬁnition of the of two “extrapolation” sequences, generated primal (ﬂow) and dual (score) variables respectively. These leading states are subsequently averaged, and the method proceeds with an adaptive step-size rule. In more details, AdaWeight relies on three key components: 4. AdaWeight: Adaptive learning in the presence of uncertainty Adaptivity of AdaWeight in optimizing equilibrium-convergence rates.To summarize√ A dual extrapolation mechanism for generating the leading sequences in Lines 4 and 7; these sequences are central for anticipating the loss landscape of the problem. An acceleration mechanism obtained from the (α)-weighted average steps in Lines 5 and 8; in the analysis,αwill grow ast, so almost all the weight will be attributed to the state closest to the current one. The combination of the weighted average iterates and adaptive learning rate in is shared by the UnixGrad algorithm proposed by Kavis et al. rate interpolation in constrained problems. However, UnixGrad requires the problem’s domain to have a ﬁnite Bregman diameter – and, albeit compact, the set of feasible ﬂows Fhas an inﬁnite diameter under the entropic regularizer that generates the template. Therefore, UnixGrad is not applicable to our routing games. This is the reason for switching gears to the “primal-dual” approach oﬀered by the dual extrapolation template; this primal-dual interplay provides the missing link that allows AdaWeight to simultaneously enjoy order-optimal convergence guarantees in both settings while maintaining the desired polynomial dependency on the problem’s dimension. In light of the above, our main convergence result for AdaWeight is as follows: Theorem 3. 3) running with convergence rate: E[Gap(T )] ≤ Speciﬁcally, in the static case, AdaWeight enjoys the sharper rate: In the above expressions, given by O(log P ). Theorem 3 characterizes the convergence speed of AdaWeight according to the number of learning iterations states (as deﬁned in enjoys a convergence rate of order convergence rate is accelerated to become more accurate over time, Theorem 3 also allows us to achieve a smooth trade-oﬀ in the convergence rate. For example, if of convergence carries a dependence of the order of O In view of these result, Theorem 3 conﬁrms that desiderata: (i) it achieves simultaneously optimal guarantees in both stochastic and static environments in the number of learning iterations (i.e., (ii) the derived rates maintain a polynomial dependency in terms of the network’ s combinatorial primitives; and (iii) it requires no prior tuning by the learner. Moreover, unlike ExpWeight, the convergence of that is implemented in epoch t and not the average ﬂow. The per-iteration complexities of AdaWeight. Algorithm 3, while having a simple presentation, takes iteration. Therefore, implementing AdaWeight is ineﬃcient. Although AdaWeight shares certain elements of the to obtain an implementation of AdaWeight having a polynomial per-iteration complexity An adaptive sequence of learning rates (cf. Line 10) in the spirit of Rakhlin and Sridharan [39], Kavis et al.[20]and Antonakopoulos et al.[2]. This choice is based on the ansatz that, if the algorithm encounters coherent gradient updates (which can only occur in static environments), it will eventually stabilize to a strictly positive value; otherwise, it√ will decrease to zero at a Θ(1/t) rate. This property is crucial to interpolate between the stochastic and static regimes. Letf, f, . . . ,be the sequence of ﬂows recommended by AdaWeight (Algorithm in the network’s size. This is due to the complicated averaging steps in AdaWeight (Lines 7 and 8 of Algorithm 3). In Section 5, we re-discuss this in more details and we propose another algorithm, called AdaLight, that maintains all desired features of AdaWeight and achieves an eﬃcient per-iteration complexity (i.e., sub-quadratic in the size of the underlying graph). 4.2. non-adaptive optimal algorithms (AcceleWeight and ExpWeight). For this reason, the proof of Theorem 3 is technically involved. Particularly, the primal-dual averaging method that we use in AdaWeight create sequences of ﬁltration-dependent step-sizes; while this is the key element allowing AdaWeight to achieve the best-of-both-worlds, previously known approaches in deriving the convergence analyses (as in non-adaptive algorithmic schemes – ExpWeight and AcceleWeight – and/or in UnixGrad) are not applicable in this case. To handle this new challenge, we propose a completely new way to treat the learning rate in order to make the derived bounds summable. To ensure the comprehensibility, in this section, we ﬁrst present a sketch of proof explaining the high-level idea before presenting the complete proof with all technical details. 4.2.1. Sketch of proof (Theorem 3). Let point of our proof is the following result: (15) appears in several previous works [ proof of (15) in B. Recall that as AdaWeight is run, observed and used. Therefore, instead ofP estimation of The key question becomes “Which upper-bound of convergence rates in (14)?” To answer the question above, we note that AdaWeight is built on the dual extrapolation template with two phases: the test phase and the recommendation phase. This allows us to upper-bound phases (i.e., where rameters of the game. Importantly, the terms in the right-hand-size of summable: they are bounded by the summation of two terms and bound choice of adaptive sequence of learning rate η Tcomponents in this summation are positive and hence, this summation is actually of order O(1) (i.e., it does not depend on costs with respect to the actual gradients of the potential. This term is of order Proof of Theorem 3.AdaWeight is not merely a “convex combination” of the two is a standard result in working with theα-weighted averaging technique that also αhC, z− fi. In the stochastic case, we can prove thatR(f) is an unbiased (f) can be translated via(15)into an upper-bound of the left-hand-sides of(14). ˜zandz) and the diﬀerence between the costs measured in these phases (i.e., ). Particularly, we have g(η) andg(η) are certain functions that also depend on other pa- P(α)k[C−˜C] − [∇Φ(f) − ∇Φ(˜f)]k. Here, the ﬁrst term arises when we kz− ˜zkusing the smoothness of the BMW potential Φ. Moreover, by our special when we choose indicated in (14). 4.2.2. Proof with technical details (Theorem 3). In this section, we work with the entropy regularizer the exponential weights template. Trivially, k·k gate of brevity, we will also deﬁne ﬂows Algorithm 3, we understand that it is run with α First, we prove the following proposition (corresponding to Equation Proposition 3. Run Algorithm 3, for any f ∈ F, we have: where A Proof of Proposition 3. Consider an “intermediate” point terms deﬁnes R Here, the last inequality comes from the deﬁnition of Fenchel coupling and the fact that ˜z= Λ(η of [11]) to the KL-divergence, Combining the two inequalities derived above, we have: Now, we look for upper-bounds of the three terms in the right-hand-side of we trivially have norm, where we deﬁneκ:=MN. We will also work with the Fenchel conjuh, deﬁned ash(w):=maxhf, wi − h(f), and its Fenchel coupling, deﬁned (f, w) =h(f)+h(w) − hf, wifor anyf ∈ Fand anyw ∈ R. For the sake of maxkf − fk. We also denote the Kullback–Leibler divergence between two fandfbyKL(f kf). Note also that throughout this section, when we mention := h(f) − min h +. αhC, y− fiandαhC, z− yi. These terms sum up toαhC, z− fiwhich (f). First, from the update rule of win Algorithm 3, we have w). Now, apply the three-point inequality with Bregman divergence (Lemma 3.1 k ˜z)−1ηKL(zk ˜z)−1ηKL(ykz) = h∇h(˜z)−∇h(z), z−yi ≥ α˜C, z− y. Combine this with the strong convexity of h, we obtain: Moreover, from the update rule of we have: Now, let us deﬁne the noises of the observed costs follows: Equation (17) involves the diﬀerence of the actual gradients of the BMW potential these diﬀerences are equal). For the sake of brevity, we deﬁne the following terms in order to analyze the gap between these diﬀerences: κ= min We aim to construct the upper-bounds the last two terms in the right-hand-side of terms of κ kf − fk+kw − wkfor any f, f, w, w∈ R,we have f, in comparison with the corresponding gradients of the BMW potential Φ as ,˜f, ω, . . . , f,˜f, ωis the ﬁltration up to time epoch t − 1. f)− ∇Φ(˜f) and the diﬀerence of costs atfand˜f, i.e.,C−˜C(in the static case, and ξ. Particularly, from (17), we can prove the following proposition: Proof of Proposition 4. Apply this and Lemma 2 of [20], we have Combine this with the fact that and choose an increasing sequence of α Here, the last equality comes from the fact that 0 (by law of total expectation). Combine step-size α Finally, recall that D ≤ results into (29), we obtain (14) and conclude the proof. 5. AdaLight: Adaptive learning with efficient per-iteration complexity In this section, our main focus is to design an algorithm that not only has the adaptive optimality of AdaWeight but also has a per-iteration complexity that is scalable in the network’s size. To do this, in Section 5.1, we ﬁrst introduce an alternative routing paradigm, called local ﬂows. In Section 5.2 and Section 5.3, we then propose the AdaLight algorithm and analyze its convergence properties and its per-iteration complexities. In the sequel, we will additionally use the following set of notation. For any (directed) edge goes from denote the set of incoming edges to andParent components are positive. Therefore, E[R(f)] ≤ h(f) − min h + σA42(α)+ 32β2κ(A) (f)]. Particularly, we have: = t, ∀t, we have: Φ(f) − Φ(f)≤1Th(f) − min h + σA42T+ 32β2κ(A). (29) 2M,σ ≤2Hand the deﬁnition ofA(cf. Proposition 4), we haveA≤hi 2 log+ 13:=Afor the constantAdeﬁned in Theorem 3. Plug these e ∈ E, we denote byvandvthe tail vertex and head vertex oferespectively, i.e.,e vtov. For any vertexvand any sub-graphG, letInandOutrespectively the sake of brevity, we also write and dim 5.1. consider a novel route-recommendation paradigm that unfolds as follows: ii) (in In this paradigm, the recommendations are made based on “local” decisions at each vertex. In average, among the mass of routed on edge deﬁned as follows. Local ﬂow.P v. We also use the notations across all the vertices and X Traﬃc loads induced by local ﬂows. ﬂow proﬁle the load of as follows: We deﬁne the total load induced on e as ` The Section 2. Particularly, x ∈ X is implemented. Finally, corresponding to the local routing paradigm described above, we re-adjust the learning model at each time epoch t = 1, 2, . . . as follows: i) The navigation chooses a local ﬂow proﬁle x ii) Concurrently, the state ω iii) The congestion costs c 5.2. called AdaLight. This method will be implemented in the local ﬂow learning model described in the previous section. To build AdaLight, our starting point is the AdaWeight method. In Algorithm 3, there are two major types of ﬂows updating: the ﬂows mapping ﬂows. In Algorithm 3, it takes each iteration. To improve the per-iteration complexity, we can leverage the weight-pushing technique [ we can ﬁnd the local ﬂow proﬁles inducing the same loads (and costs) as the logit-mapped ﬂows Local ﬂows routing paradigm.On the deﬁned network structure (cf. Section 2), let us The control interface determines at each vertexva proﬁlex∈∆(Out) for eachO/D pair i. It then makes a route recommendation for eachi-type traﬃc by choosing the vertices G) one by one such that if the verticesO, v, . . . , vis chosen, then a vertex v∈ Outwill be chosen with probabilityxwhereeis the edge going fromvto For each pairiand vertexv, we deﬁne the setX:=x∈[0,1]: x= 1. We call the elements ofXthelocal ﬂowscorresponding toiandQ O/Dpairs,X:=Xfor the set of local ﬂow proﬁles ofi-type traﬃc acrossQQ x ∈ X, we denote the mass ofi-type traﬃc arriving atvbyµ(x) and denote i-type traﬃc routed oneby`(x). Formally, they can be computed (recursively) `(x) = x· µ(x), and µ(x):=M, if v = OP`(x) , if v 6= O(30) congestion coston each edgeeis determined by the cost functioncas deﬁned in AdaLight algorithm.In this section, we propose a new equilibrium learning method Λ, and the ﬂows˜fandfobtained from averaging between two pre-computed 18,42]: by assigning weights on edges and use dynamic programming principles, ˜zandz. However,the weight-pushing technique fails to derive local ﬂow proﬁles matching the averaged ﬂows and then taking the average will not incur the same costs as implementing the average of the two ﬂows. Recall that these averaging steps are the key elements allowing the adaptability of AdaWeight, the key challenge now is to implement eﬃciently these steps. Facing up this challenge, we make the following observation: while the averaged ﬂows of AdaWeight are not “weight-pushable”, their induced loads are. In this perspective, there arise two new challenges. First, we need to eﬃciently compute the load proﬁles induced by the averaged ﬂows (without explicitly computing these ﬂows). To do this, we introduce a sub-routine called work forward (unlike the classical weight-pushing that starts from the destination and works backward). Second, we need to derive local ﬂow proﬁles that matches these averaged loads. We refer to this as completely novel contributions. Taking an overall view, AdaLight is a combination of the weight-pushing technique (to handle the logit-mapped ﬂows) and the pulling-forward and matching-load procedures (to handle the averaged ﬂows) into the AdaWeight template. For the sake of conciseness, we ﬁrst present a sub-algorithm in Section 5.2.1 and present a pseudo-code form of AdaLight in Section 5.2.2. 5.2.1. PushPullMatch sub-algorithm. In this section, we present a sub-algorithm, called PushPullMatch, that combines the three auxiliary routines: pushing-backward, pullingforward and matching-load. In Algorithm 4, we give a pseudo-code form of It takes four inputs: an “anchor local-load” proﬁle facilitate the presentation of AdaLight in Section 5.2). When it ﬁnishes, Algorithm 4 outputs a local ﬂow proﬁle and updates the anchor local-load proﬁle. Particularly, when we run PushPullMatch, it executes the following three phases for each O/D pair i: reversed topological order, i.e., we work backwardly from the destination to the origin. ii) iii) w); and two scalar numbersαandα(we use these notations to The pushing-backward phase: in this phase, we consider vertices inGone by one in a For each vertexv, we assign a score – called the backward score (denoted byBWscorein Algorithm 4) – depending on the weights ofv’s outgoing edges (i.e.,w, ∀e ∈ Out) and its children’s scores. Then, we “pushes” the backward score ofvto its parents so that, in their turns, we can compute their scores. Finally, based on the backward score of v, we compute a local ﬂow z∈ X. The pulling-forward phase: in this phase, we consider vertices inGone by one in a topological order, i.e., we work forwardly from the origin to the destination. On each vertexv, we assign a score – called the forward score (denoted byFWscorein Algorithm 4) – computed from the loads induced byzon the incoming edges ofvthat are “pulled" fromv’s parents. Then, for anye ∈ Out, we derive`(z) and compute another term – called`(x) – by taking the average of`(z) and the anchor loadr. Finally, we update the anchor load-proﬁle r (that will be used later in AdaLight). The matching-load phase: in this phase, we once again consider vertices inGin a topological order. For eachv, we compute a local ﬂowx∈ Xthat matches precisely 5.2.2. Pseudo-code of AdaLight. Having all the necessary preparations, we now present the AdaLight method. The key diﬀerence that makes AdaLight stand out from AdaWeight is that it uses the sub-algorithm PushPullMatch to eﬃciently compute the corresponding local ﬂows instead of working with the We present a pseudo-code form of AdaLight in Algorithm 5. Similar to AdaWeight, AdaLight follows two phases: the test phase and the recommendation phase: ii) the load`(x), ∀e ∈ Outobtained in the pulling-forward phase. To do this, we need to computeµ(x) – the mass ofi-type traﬃc arriving atvinduced byx– this can be done by pulling the loads corresponding toxfrom the parents ofv. The local ﬂow proﬁles x, i ∈ N constitute the output of PushPullMatch. In the test phase, we run PushPullMatch with the anchor load proﬁlerand the weight proﬁleηwas inputs (here,ηis a learning rate). At the end of the test phase, the cost˜Cat a “test” local ﬂow is derived and used to update the test-weight proﬁle˜w. In the recommendation phase, we re-run PushPullMatch but this time, with the test weightη˜wobtained previously in the test phase as input. Moreover, we will also use the output of PushPullMatch to update the anchor load-proﬁler. At the end of the Finally, we observe that in each iteration of Algorithm 5, it is required to compute the term eﬃciently: for any eis assigned with a weight classical Bellman-Ford algorithm [7, 17] that takes only O(|V|) rounds of computations. Algorithm 5: Adaptive local weights (AdaLight) 5.3. erties of AdaLight is formally presented in the following theorem: Theorem 4. (i.e., Algorithm 5) running with α ii) Result (i) of Theorem 4 shows that AdaLight also converges toward an equilibrium with the same rate as AdaWeight: an and an of Theorem 4 that AdaLight recommends a sequence of local ﬂows that induce the same BMW-potential values as the sequence of ﬂows recommended by AdaWeight which, in turn, approaches the potential value at an equilibrium (see Proposition 5 below). Note that recommendation phase, we obtain the local ﬂow proﬁlex, route the traﬃc accordingly, then update the weight proﬁle wby using the incurred costs. maxP|C−˜C|for updating the learning rateη. This can also be done in ← output of PushPullMatch(r, ηw, α,Pα) // compute a test local flow , r← outputs of PushPullMatch(r, η˜w, α,Pα) // compute local flow AdaLight: convergence results and per-iteration complexities.The convergence prop- Letx, x, . . .be the sequence of local ﬂow proﬁles recommended by AdaLight The sequence of ﬂow proﬁlesf, ∀t= 1,2, . . .wheref:=MQxfor anyi ∈ N and p ∈ P enjoys the following equilibrium convergence rate: and speciﬁcally, in the static case, it enjoys the convergence rateGap(T ) ≤ Olog(P )/T. Moreover, each iteration of AdaLight requires only anO(|N||V||E|)number of computations. O((log P)/T) rate in the static regime. More precisely, we shall see in the proof although the ﬂow is not needed for routing the traﬃc in practice (only the local ﬂow x Moreover, Result (ii) of Theorem 4 shows the main diﬀerence between using AdaLight and using AdaWeight: the per-iteration (space and time) complexities of AdaLight are polynomial in terms of the network’s primitive parameters (numbers of of vertices and numbers of edges). Therefore, unlike AdaWeight, AdaLight can run eﬃciently even in large networks. 5.4. Proof of Theorem 4. First, we prove that we can prove a stronger result as follows: Proof. paths in denote induction (following any topological order of vertices), we can prove that v ∈ V the following equality holds for any v and e ∈ Out Apply Proposition 5, since by deﬁnition of the cost functions, they induce the same costs, i.e., any state ω ∈ Ω. Second, we prove that the recommendations of AdaLight and AdaWeight coincide. Let us ﬁrst focus on the recommendation phase of Algorithm 5. Particularly, assume that at time epoch the anchor ﬂow ˜wused in Algorithm 5 and the weightP from costs) as the ﬂow proﬁle f To do this, we observe that the following equality holds true for any p ∈ P PushPullMatch(r Here, the last equality comes directly from the update rule of z Now, combine are precisely the loads induced by (cf. Section 5.1), we have that the term precisely these loads. xinduce the same load proﬁles, i.e., `(x) = `(f) for any e. Proof of Proposition 5. Fix anO/Dpairi ∈ N. LetPandPdenotes the set of Ggoing fromOtovand the set of paths going fromvtoDrespectively. Let usPQ . From this result, the deﬁnition of the load proﬁle in(30)and the deﬁnition ofH, t, the anchor local-load proﬁlerin Algorithm 5 matches the load induced by ˜w=˜wfor anyp ∈ Pandi ∈ N. We will prove that the local ﬂow proﬁlexoutputP PushPullMatch(r, η˜w, α,α) induces the same load proﬁles (and the same and with the local ﬂow proﬁlezcomputed in the pushing-backward phase ofP Due to the arguments above and the assumption on the relation of `(x) computed at Line 12 of ﬂow proﬁle the loads induced by x (which is the output of PushPullMatch). As a conclusion, since we set the loads (and hence, the costs) induced by by Algorithm 3. Using a similar line of arguments, we can also deduce that the local ﬂow proﬁle For this reason, the assumptions we made on To sum up, we have proved that the ﬂow proﬁles deﬁned in Theorem 4 have the same loads as the local ﬂow proﬁles recommended by AdaLight that, in turn, coincide with the loads incurred by the recommended ﬂows of AdaWeight. This leads to the fact that AdaLight (Algorithm 5) inherits the convergence rates of AdaWeight (Algorithm 3). This concludes the proof of Result (i) of Theorem 3. Finally, we justify the per-iteration complexity of AdaLight. . It is trivial to see that when PushPullMatch is run, at any vertex takes out-degree of In this section, we report the results of several numerical experiments that we conducted to justify the theoretical convergence results of AdaWeight and AdaLight. Particularly, in Section 6.1, we present the experiments on a toy example to highlight the advantages ofAdaWeight show the superiority in performance of with real-world data pose several additional computational challenges; we also discuss these challenges and provide quick-ﬁx solutions. The codes of our experiments are available at dongquan-vu/Adaptive_Distributed_Routing. 6.1. with 4 vertices and 4 edges. Speciﬁcally, the edges in this network are arranged to form 2 parallel paths going from an origin vertex, namely each time epoch, a traﬃc demand (i.e., inﬂow) of size M = 10 is sent from O to D. In the experiments presented below, we run Weight in each algorithm at each time minimum among all thus, of these algorithms, we will compute and plot out the evolution (when the gaps (cf. Equation (10)) of the ﬂows derived from these algorithms that are analyzed in Theorem 1, Theorem 2 and Theorem 3 (we denote these gaps by GapExpWeight First, we consider a static environment. Particularly, the costs on edges are determined via ﬁxed linear cost functions such that when being routed with the same load, one path has a higher cost than the other. We plot out the evolution of GapExpWeight ting, all these terms converge toward 0; in other words, all three algorithms converge towards fcomputed at Line 8 of Algorithm 3. Finally, from the updating rule of the local ﬂow xat Line 17 of PushPullMatch, we deduce that these loads match precisely with ˜xcomputed in Algorithm 5 also matches the ﬂow proﬁle˜fcomputed in AdaWeight. O(max{In, Out}) rounds of computations whereInandOutare the in-degree and ) time. We conclude that each iteration of AdaLight requires only anO(|N||V||E|) Experiments on small-size networks.We ﬁrst consider a toy-example of on a network T= 10e5epochs. We record the values of the BMW potentialcat outputs of frepresents the equilibrium ﬂow. In order to track down the convergence properties equilibria of the game. Importantly, we observe that enjoy an accelerated convergence speed that is much faster than that of coincides with theoretical results in the previous sections. Note that if AcceleWeight is run with a badly-tuned initial step-size that in Fig. 1, and from the time-averaged ﬂow proﬁles of outputs of time-averaged ﬂows are not the ﬂows recommended by ExpWeight. Second, we consider a stochastic setting. Particularly, the costs on edges are altered by adding noises generated randomly from a zero-mean normal distribution. To have a better representation of these uncertainties, we run each algorithm in 5 diﬀerent instances of the noises’ layouts. We take the averaged results among these instances and plot out the evolution of this setting, we observe that while AcceleWeight fails to do so. Moreover, in this stochastic environment, the accelerated rate is no longer obtainable: (of order and AcceleWeight. 6.2. using a real-world dataset collected and provided in [ contains the road networks of diﬀerent cities in the world. The congestion model in this dataset is assumed to follow the BPR cost functions whose coeﬃcients are estimated a priori. The purpose of our experiments is to measure the equilibrium convergence of our proposed methods with the presence of uncertainties and no knowledge on the cost functions. Due to their per-iteration complexity, the naive implementations of leWeight and when being run in these real-world networks. Therefore, to deal with these large-scale networks, we consider the distributed model (presented in Section 5.1) and run place of e−8), it requires a long warming-up phase and might converge slowly. We also observe Gap(T), this comes from the fact thatGapExpWeight(T) is computed O(1/T)). This conﬁrms the theoretical results ofAdaWeight,ExpWeight Experiments on real-world datasets.In this section, we present several experiments AdaWeight. As a benchmark, we consider a variant ofExpWeightimplemented Figure 1:Convergence speed ofAdaWeight,ExpWeight, AcceleWeight in a parallel network. with the classical weight-pushing technique. These implementations enjoy a per-iteration complexity that is polynomial in terms of the networks’ sizes. Before presenting the obtained experimental results (in Section 6.2.2), we ﬁrst address a computational issue in using weight-pushing ideas in large-scale networks. As far as we know, this issue has not been reported in any previous works (prior to this work, weight-pushing is mostly analyzed theoretically and real-world implementations have not been provided). We formally address this computational issue and introduce a quick-ﬁx solution in Section 6.2.1 (readers who are eager to see the numerical experiments can skip this section). 6.2.1. Computational issues of weight-pushing with large weights. The PushPullMatch sub-algorithm that we constructed in Section 5.2 involves the pushing-backward phase where a backward score (denoted by this score can be computed eﬃciently. In practice though, when the magnitude of costs values are large, the input weights of PushPullMatch is proportional to the negative accumulation of costs (that decreases quickly to involves a division of two inﬁnitesimally small numbers; this is often unsolvable by computers. To resolve this issue, instead of keeping track of Particularly, ﬁx an denote of Algorithm 4, it can be computed by logscore The expression in the magnitude of costs and backward phase of PushPullMatch can be computed as 6.2.2. Experimental results. We consider several instances in the dataset [ the urban traﬃc networks of diﬀerent cities. The primitive parameters of these networks are summarized in Table 2. More information on these networks are given at com/bstabler/TransportationNetworks mostly for social-costs optimization; in our knowledge, no work has used this dataset for equilibrium searching problems. logscore:=log(BWscore) andedgescore=logscore+w, then from Line 5 = logexplogscore+ w = max(edgescore) + logexpedgescore− max(edgescore). For our experiments, in each network, we run time epochs. Static environment. First, we consider the static setting where in each time epoch, for each network, the costs on edges are determined by a BPR function with coeﬃcients given by the dataset. The results are reported in Fig. 2, particularly as follows: i)In Fig. 2a, Fig. 2c, Fig. 2e and Fig. 2g, we plot out the evolution of GapExpWeight Importantly, the results in these large-scale networks show the superiority of (and make several side-comments as follows. First, the evolution of involve less ﬂuctuations than that in the small-size network considered in Section 6.1. This phenomenon is trivially explicable: in the toy-example with only two paths, any small changes in the implemented ﬂow proﬁle might lead to a large impact on the costs; in real-world instances, moving a mass of traﬃc from one path to the others does not make so much diﬀerences in the total induced costs accumulated from a large number of paths. Second, as we consider networks with larger sizes, both warming-up phase (where recommendations and eventually converge. Albeit the case, this warming-up phase is still reasonably small and it does not restrict the applicability of our proposed algorithms. ii)To validate the rate of convergence (in terms of terms Fig. 2h. In these plots, that the convergence speed of T· Gap Stochastic environment. In this setting, the cost of edges are altered by adding random noises generated from zero-mean normal distributions. For validation purposes, for each network, we run the averaged results across these instances in Fig. 3. i)In Fig. 3a, Fig. 3c, Fig. 3e and Fig. 3g, we plot out the evolution of Gap and setting, the convergence rate of AdaLight (also of AdaWeight) and ExpWeight are of the same order. ii)To justify the convergence speed of the considered algorithms, in Fig. 3b, Fig. 3d, Fig. 3f and Fig. 3h, we plot our the terms terms approach horizontal lines as convergence of result is consistent with our theoretical results. On the elapsed time of the largest network instance in our experiments (Anaheim), it only takes 4 seconds to ﬁnish one round of learning iteration and to output a route recommendation (the computations are conducted on a machine with the following specs: Intel Core(TM) i7-9750H CPU 2.60GHz and 8GB RAM). For most of the applications in urban traﬃc routing, the scale of time between ﬂuctuations of networks’ states is often much larger than this elapsed time (it might take hours or even days for a signiﬁcant change to happen). This highlights the implementability and practicality of our proposed methods, even in networks with much larger sizes. AdaWeight) in the convergence speed in comparison withExpWeight. We also T· GapAdaLight(T) andT· GapExpWeight(T) in Fig. 2b, Fig. 2d, Fig. 2f and ). On the other hand,ExpWeightdoes not reach this convergence order (and hence, ExpWeight(T ) continue increasing). (T). These terms tend to zero asTincreases; this conﬁrms thatExpWeight AdaLightconverge toward equilibria in this stochastic setting. Moreover, in this (a) SiouxFalls: Log-log plot of Gap(T ) (c) Eastern-Massachusetts: Log-log plot of Gap(T ) (e) Berlin-Friedrichshain: Log-log plot of Gap(T ) (g) Anaheim: Log-log plot of Gap(T ) Figure 2: Convergence speed of AdaLight (AdaWeight) and ExpWeight in static environments. (a) SiouxFalls: Log-log plot of Gap(T ) (c) Eastern-Massachusetts: Log-log plot of Gap(T ) (e) Berlin-Friedrichshain: Log-log plot of Gap(T ) (g) Anaheim: Log-log plot of Gap(T ) Figure 3: Convergence speed of AdaLight (AdaWeight) and ExpWeight in stochastic environments. as deﬁned in Section 4.2 and let in hand, our proof of Theorem 2 will proceed in two basic steps: Step 1: Establish an energy function. algorithms [1, 22], we will consider the energy fuction where between f Our goal in the sequel will be to prove that ∆ and the strong convexity of h, we have Therefore, the last term in (A.5) vanishes and we can rewrite (A.5) as This shows that ∆ Gap(t) = Φ(f)− minΦ andKL(fkz) denotes the Kullback–Leibler divergence and z. Step 2: Upper-bounding the equilibrium gap. By iterating (A.7), we readily obtain and hence Thus, combining Equations (A.8), (A.11) and (A.12) and recalling that the strongly-convexity constant of ﬁnally obtain Gap(T ) ≤ Here, the last equality is achieved via telescopic sum. Now, when we choose indicated in Theorem 3), we notice that κβγ≥κβγ+ 1/2. Therefore, telescoping this last bound, we get MPfor allp ∈ P,i ∈ N. We thus geth∇h(f), f− fi= 0 soKL(fkf) = )−h(f)≤ max h −min h. Moreover, by a straightforward calculation, we getmax h= log(M) and min h = Mlog(P/M), so −f. As a consequence,