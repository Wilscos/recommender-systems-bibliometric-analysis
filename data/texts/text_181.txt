In this position paper, we discuss the merits of simulating privacy dynamics in recommender systems. We study this issue at hand from two perspectives: Firstly, we present a conceptual approach to integrate privacy into recommender system simulations, whose key elements are privacy agents. These agents can enhance users’ proles with dierent privacy preferences, e.g., their inclination to disclose data to the recommender system. Plus, they can protect users’ privacy by guarding all actions that could be a threat to privacy. For example, agents can prohibit a user’s privacy-threatening actions or apply privacy-enhancing techniques, e.g., Dierential Privacy, to make actions less threatening. Secondly, we identify three critical topics for future research in privacy-aware recommender system simulations: (i) How could we model users’ privacy preferences and protect users from performing any privacy-threatening actions? (ii) To what extent do privacy agents modify the users’ document preferences? (iii) How do privacy preferences and privacy protections impact recommendations and privacy of others? Our conceptual privacy-aware simulation approach makes it possible to investigate the impact of privacy preferences and privacy protection on the micro-level, i.e., a single user, but also on the macro-level, i.e., all recommender system users. With this work, we hope to present perspectives on how privacy-aware simulations could be realized, such that they enable researchers to study the dynamics of privacy within a recommender system. Additional Key Words and Phrases: Simulations; Privacy Dynamics; Privacy Agents; Recommender Systems 1 INTRODUCTION Through the increasing interest in novel evaluation methods for state-of-the-art recommender systems, research recognized that monitoring a recommender system from a static point of view is often not optimal. As an alternative, observing the dynamics of a recommender system via simulations showed its merit. However, modeling the complex and dynamic processes within a recommender system requires lots of engineering eorts. Hence, several popular simulation frameworks for recommender systems exist [ kind of eect within a recommender system. In this regard, recent simulation studies focus on, e.g., the evolution of popularity bias and feedback loops [8, 14], or the confounding of user behavior [2, 10]. In this paper, we present a modied simulation scheme for privacy-aware simulations, which makes it possible to discover the dynamics of privacy within a recommender system. Specically, we propose privacy agents that enhance existing simulations with the ability to model privacy preferences and protect the privacy of users in a recommender system. A privacy agent bridges the gap between a user’s preference model [ and this way, the privacy agent serves two purposes. Firstly, it models a user’s privacy preferences, e.g., a user’s decision to disclose only certain information to the recommender system. Secondly, it protects a user from leaking sensitive information by guarding the user’s interactions with the recommender system. For example, when a user selects documents from the recommendation list and gives feedback to the recommender system, sensitive information could get leaked [13]. Typically, users have only minor knowledge of privacy threats and are unaware of privacy-enhancing techniques suitable to protect their privacy. Here, privacy agents provide a remedy, since they intervene and apply state-of-the-art privacy-enhancing techniques, e.g., Encryption [5] or Dierential Privacy [3], to protect users from performing any privacy-threatening actions. Moreover, we state three important issues, that are – as we think – crucial for designing privacy-aware recommender system simulations through privacy agents. Specically, we briey discuss (i) how adequate privacy agents could be developed, (ii) to what extent the privacy agents impact users’ preferences and thus, drift from reality, and (iii) how one user’s privacy agent could positively or negatively inuence the recommendations and privacy of other users. We think that similar to eects like, e.g., popularity bias, also privacy should not only be studied from a static point of view but by monitoring its dynamics in a recommender system. Thus, with our conceptual privacy-aware recommender system simulation approach presented in this position paper, we aim to give a future perspective on how the important aspect of privacy could be simulated. We hope that privacy-aware simulations complement insights gained by static evaluations and reveal interesting dynamics of users’ privacy within a recommender system. 2 CURRENT PERSPECTIVE: PRIVACY-AGNOSTIC SIMULATIONS Over the last years, a plethora of research emerged that simulates users and their interactions with a recommender system to grasp the dynamic nature of such systems. Issues to which recommender system simulations have been applied to include studying eects like item coverage or feedback loops, and analyzing the evolution of user preferences. In particular, [4,9] show that recommender systems tend to focus on a small set of documents when generating recommendations. This means that the evolution of the recommender system causes fewer documents to be covered. Plus, [9] provides a theoretical framework to model the recommender system’s iterative behavior to investigate the presence of dierent biases. In the same vein, [14] analyze the emergence of popularity bias via recommender system simulations. In particular, the authors discuss the eect of dierent choice models and the kind of feedback users give to the recommender system on the emergence of popularity bias. In addition to feedback loops, [8] study lter bubbles and shed light on their eects on the dynamics of user interests. In summary, recent research utilized recommender system simulations to cover topics like popularity bias, feedback loops, lter bubbles, item discovery, and the evolution of user preferences. However, we highlight that research works – to the best of our knowledge – only use privacy-agnostic simulations. A schematic overview of such a privacy-agnostic recommender system simulator is given in Figure 1, which is motivated by [7]. In the Document Database, all documents that are available for recommendation are stored. Each user is described by an individual User Model, which includes the user’s document preferences and rating data. This is slightly dierent from the Observable User Model, which represents the recommender system’s model of the user. Thus, this is the recommender system’s knowledge about the user, which is a subset of the User Model. The User Choice Model denes how the user selects documents from the recommended list. For example, some users could seek serendipitous or novel recommendations, while other users would select documents based on familiarity. Depending on the received recommendations, users may change their interest in a certain direction and thus, shift the trajectory of the simulation. Thus, the User Transition Matrix measures how a user’s preferences change over time. Finally, the Recommender System Agent generates a Recommendation List and receives the user’s Feedback. Fig. 1. Scheme of a typical privacy-agnostic recommender system simulator (motivated by [ generates a Recommendation List from documents within the Document Database, based on its knowledge (i.e., Observable User Model) about a user (i.e., User Model). Then, the user chooses documents from the Recommendation List via a User Choice Model and gives Feedback to the Recommender System Agent. Plus, the documents chosen from the Recommendation List could lead to transitions in the User Model (i.e., User Transition Matrix). Open Issue. Despite their recent popularity, privacy-agnostic simulations miss the important concept of privacy. For example, they are unaware of users’ concerns and preferences regarding privacy. Furthermore, the eects of privacy protection, e.g., not disclosing data to the recommender system, are only studied in a static setting [ factors, we believe that also privacy should be studied from a dynamic perspective. Hence, privacy-aware simulations are necessary to shed light on the dynamics of users’ privacy within a recommender system. 3 FUTURE PERSPECTIVE: PRIVACY-AWARE SIMULATIONS In this work, we propose privacy agents that enhance the existing recommender system simulation scheme in Figure 1 by incorporating users’ privacy preferences and privacy protections, and thus, enable privacy-aware simulations. As illustrated in Figure 2, each privacy agent attaches to one user’s User Model to (i) model what and how much data the user discloses (i.e., privacy preferences), or (ii) protects the user’s privacy by guarding what and how much data is disclosed (i.e., privacy protection). Furthermore, the privacy agent also attaches to the User Choice Model and (i) models how the user selects documents in line with its privacy concerns (i.e., privacy preferences) or (ii) prohibits the user from selecting documents that would reveal sensitive information (i.e., privacy protection). Privacy Agent. Firstly, it models a user’s privacy preferences, e.g., not disclosing all data to the recommender system. Secondly, it protects a user’s privacy by proposing what data to share and how documents to select from the Recommendation List to not compromise privacy. For example, the privacy agent could not only model a user’s inclination to disclose data to the recommender system but also apply privacy-enhancing techniques to parts of the data, e.g., Encryption [ additionally, can protect users from performing actions that would increase the risk of a privacy breach. Open Research Questions. With our proposed privacy-aware recommender system simulation scheme, we aim to incorporate privacy to enable more realistic simulations. However, through the introduction of privacy-aware 5] or Dierential Privacy [3]. In summary, the privacy agent can model users’ privacy preferences and, Fig. 2. Our proposed scheme of a privacy-aware recommender system simulator. Sensitive data about the user (i.e., User Model) could get leaked through the information available to the recommender system (i.e., Observable User Model) and the user’s selection from the Recommendation List as defined by the User Choice Model. We introduce a privacy agent that aaches itself to the User Model and the User Choice Model to (i) model privacy preferences, or (ii) protect privacy. simulations, several open research questions arise. Specically, we highlight three questions that we think are of strong relevance, and thus, worth discussing among researchers. (1)How could we develop privacy agents that model users’ privacy preferences, and protect users from performing any privacy-threatening actions? To model users’ privacy preferences, one could rely on questionnaires or construct articial privacy models to model users with dierent privacy preferences. An additional question is how the privacy agents should decide on how to protect users’ privacy. In detail, the agents could measure the privacy threat of users’ actions by considering the users’ privacy preferences but also by measuring the actions’ danger from dierent perspectives (an actions’ danger could change depending on the attack scenario), and then apply a suitable privacy-enhancing technique, e.g., Dierential Privacy [3], Encryption [5], or data retention. (2)To what extent do the privacy agents modify the trajectory of the recommender system? This means, how are users’ preferences manipulated when improving privacy? Privacy agents could protect privacy by manipulating the user data available to the recommender system or by manipulating the way the user selects documents from the Recommendation List. Since the recommender system relies on these user interactions, the privacy agents inuence what recommendations are generated. The recommendations can substantially inuence users’ preferences [14], and thus, it follows that protecting privacy by introducing privacy agents could also inuence the User Models. Therefore, we think it is important to discuss to what extent the privacy agents’ impact the User Models and how this could be prohibited. (3)How does modeling and protecting a user’s privacy impact the recommendation quality and privacy of other users in the recommender system? When a privacy agent intervenes to protect a user’s privacy, a collaborative recommender system receives less-quality data from this user, which impacts the recommendations of other users within the system. This could lead to other users being pushed to disclose more about themselves to receive high-quality recommendations. Therefore, (i) monitoring the consequences of users’ privacy agents, and (ii) making users aware of the consequences on other users seem to be two interesting aspects worth studying. 4 CONCLUSION & OUTLOOK In this position paper at hand, we presented our perspective on privacy-aware recommender system simulations to study privacy in recommender systems from a dynamic point of view. In particular, we proposed to enhance existing privacy-agnostic simulation schemes by adding a privacy agent for each user. Firstly, the privacy agents model users’ privacy preferences, e.g., their inclination to disclose data to the recommender system. Secondly, they guard users’ interactions with the recommender system and apply privacy-enhancing techniques to protect users from leaking sensitive data through making privacy-threatening actions. Moreover, we discussed open research questions that are, in our opinion, strongly relevant for establishing privacy-aware simulations via privacy agents. For future research, we suggest testing our privacy-aware simulation scheme by incorporating privacy agents into dierent simulation frameworks. Furthermore, in analogy to users collaboratively generating recommendations, we propose to research how privacy agents could collaborate to increase recommendation quality and privacy of all users simultaneously (i.e., optimize the privacy-accuracy trade-o). Acknowledgements. This work was supported by the H2020 project TRIPLE (GA: 863420) and the “DDAI” COMET Module within the COMET — Competence Centers for Excellent Technologies Programme, funded by the Austrian Federal Ministry (BMK and BMDW), the Austrian Research Promotion Agency (FFG), the province of Styria (SFG) and partners from industry and academia. The COMET Programme is managed by FFG.