<title>Prescriptive Process Monitoring: Quo Vadis?</title> <title>1 Introduction</title> Process mining is a family of techniques that facilitate the discovery and analysis of business processes based on execution data. Process mining techniques use event logs extracted from enterprise information systems to, for instance, discover process models or to check the conformance of a process with respect to a reference model [42]. In this setting, an event log is a dataset capturing the execution of a process step by step, including timestamps, activity labels, <title>arXiv:2112.01769v1  [cs.AI]  3 Dec 2021</title> case identiﬁers, resources, and other contextual attributes related to each case or each step within a case. Over time, the scope of process mining has extended to encompass techniques that predict the outcome of ongoing cases of a process based on machine learning models constructed from event logs [24]. Predictions, however, only become useful to users when they are combined with recommendations [28]. In this setting, prescriptive process monitoring is a family of methods to recommend interventions during the execution of a case that, if followed, optimize the process with respect to one or more performance indicators [35]. For instance, an intervention might improve the probability of the desired outcome (e.g. on-time delivery) or mitigate negative outcomes (e.g. delivery delays) [27]. Diﬀerent prescriptive process monitoring methods have been proposed in the literature. These methods vary in relation to – among others – their predictive modeling approach and the interventions they prescribe. In some cases, two diﬀerent methods aim at achieving the same objective but in diﬀerent ways. For instance, to avoid an undesired outcome, one method prescribes assigning resources for the next task [36], whereas another recommends the next task to be executed [23]. The beneﬁts of prescriptive process monitoring can only be fully realized if these methods prescribe eﬀective interventions and if these prescriptions are followed [9]. At present, though, the variety and fragmentation of prescriptive monitoring methods makes it diﬃcult to understand which method is likely to be most eﬀective or more likely to be accepted by end users in a given business situation. There is no overview that captures existing prescriptive monitoring methods, what objectives they pursue, which interventions they prescribe, which data they require, or the extent to which these methods have been validated in real-life settings. Research overviews and classiﬁcation frameworks have been put forward in the related ﬁeld of predicative monitoring [11,28] and automated resource allocation [4,34], but not in the ﬁeld of prescriptive process monitoring. To address this gap, we study three research questions: – Given that prescriptive process monitoring methods aim at prescribing interventions that produce business value, i.e., achieve an objective, we formulate the ﬁrst research question as RQ . What is the objective for using prescriptive process monitoring methods in the process? – The second research question aims at discovering how the objectives can be achieved: RQ . What are the interventions prescribed by prescriptive process monitoring methods? – Finally, we explore the data required by the proposed methods: RQ . What data do prescriptive process monitoring methods require? To answer these questions, we conduct a Systematic Literature Review (SLR) following the guidelines proposed by Kitchenham et al. [22]. We identiﬁed 36 papers that we analyze these papers to develop a multi-dimensional framework to characterize prescriptive monitoring methods. The contribution of the paper is twofold. We ﬁrst develop a framework that classiﬁes the prescriptive process monitoring methods according to their objective, metric, intervention types, techniques, data inputs, and policies to trigger the interventions. Second, we provide insights into potential areas for future research in this ﬁeld. The rest of this paper is structured as follows. Section 2 discusses related work. In Section 3, we elaborate on the protocol of the SLR, while in Section 4 we present our ﬁndings. In Section 5 we present the proposed framework, followed by concluding remarks in Section 6. <title>2 Related Work</title> Methods for prescriptive process monitoring prescribe interventions that can change the outcomes of an ongoing process case. For instance, if a method detects that an undesired outcome is probable to unfold, an alarm is raised that can lead to an intervention [37]. This intervention could come in the form of an action performed by a process worker, such as calling a customer, that helps to mitigate or prevent the negative outcome from materializing [37]. Interventions often entail an intervention cost (e.g., time spent executing an action) and a cost of undesired outcome (e.g., the order is canceled) [13]. Thus, it is essential to deﬁne a policy for when the prescription is generated. The example above [13] considers the probability of a negative outcome and evaluates the cost model and the mitigation eﬀectiveness before triggering interventions. A few previous studies focus on areas that are related to prescriptive process monitoring. Di Francescomarino et al. [11] introduce a value-driven framework that allows companies to identify when to apply predictive process monitoring methods. Another classiﬁcation of predictive process monitoring methods is that of M´arquez-Chamorro et al. [28], where the focus is on methods to train predictive models. In Mertens et al. [26], the authors evaluate predictive methods used to recommend follow-up activities in the healthcare domain. While prescriptive process monitoring methods incorporate predicted outputs, our work only focuses on prescriptive methods and prescribed interventions. Pufahl et al. [34] present an SLR on automatic resource allocation. Similarly, Arias et al. [4] give an overview of resource allocation methods, but with a particular focus on human resources. However, the former work reviews prescriptive methods in general, and the latter two focus on a speciﬁc intervention, namely, resource allocation. In this paper, we enrich such works by considering all types of potential interventions in process-aware methods. <title>3 SLR Method</title> We aim to review the existing body of work on prescriptive process monitoring methods. More speciﬁcally, what the objectives for using such methods are (RQ ), what interventions the methods prescribe (RQ ), and what data the methods require (RQ ). Therefore, we use the systematic literature review (SLR) method as it aids us to identify relevant literature in a speciﬁc research area [22]. We follow the guidelines proposed by Kitchenham et al. [22], who proposes three main steps: (1) planning the review, (2) conducting it, and (3) reporting the ﬁndings. For the ﬁrst step (planning), we identiﬁed research questions and developed the review protocol [22]. The research questions were deﬁned and motivated above. We developed a search string for the review protocol, identiﬁed suitable electronic databases, and deﬁned inclusion and exclusion criteria. Finally, we deﬁned the data extraction strategy. In the search string, we included “process mining” to scope the study to methods that rely on event logs. We derived the term “prescriptive” from the research questions. We also included the terms “recommender” and “decision support”, as we found these to be sometimes used instead of “prescriptive”. Accordingly, we formulated the search string: To derive the framework, we started with clustering the methods according to what they were aiming to improve (RQ ), e.g., ”cycle time minimization”, ”cost optimization”. We then noted that the methods formed two more prominent groups that, in the end, served as the main categorization of the framework, i.e., the objectives. Within the groups, we followed the research questions to classify the methods further, such as according to the interventions they trigger (RQ ), the input data they require (RQ ). <title>4 SLR Results</title> In the following sections, we present the results of our review. First, we describe the objectives of prescriptive process monitoring methods that we found (RQ ). Then, we present the interventions prescribed to achieve the objectives (RQ ), and, ﬁnally, we outline the data used to do so (RQ ). From our review, we identiﬁed two main objectives that prescriptive process monitoring methods aim to achieve. The ﬁrst objective reduces the defect rate, whereas the second relates to optimizing quantitative case performance. The objective of reducing defect rate is expressed with binary metrics. For instance, the objective is achieved by reducing the risk of cost overrun [8]. The objective of optimizing is expressed as, for instance, reducing cycle time [45]. As to the objective of reducing the defect rate, ﬁve papers discuss undesired temporal outcomes, such as the violation of the planned cycle time or deadline [16,36,43,20,23]. For instance, Gr¨oger et al. [16] describe the example of a manufacturing process, where the target is to avoid exceeding the allowed limits for cycle time. Another set of studies focuses on avoiding or mitigating an undesired categorical outcome [37,13,27,35,14,39,25,17]. For example, Ghattas et al. [14] try to avoid the customer rejecting the delivery in a bottle manufacturing process. In the domain of healthcare, examples of undesired outcomes are patients entering a critical stage [39], or medical mistakes due to patient restrictions [25]. One paper aims to eliminate or mitigate process risks, i.e., faults in the process that may arise if not addressed [8]. The second main objective considers optimizing quantitative case performance. Most papers consider optimizing the temporal perspective (15 out of 20), such as cycle or processing time. More speciﬁcally, in [45,21,31,40], reducing cycle time is deﬁned as the main objective. For instance, Thomas et al. [40] describe a method to minimize the cycle time of an environmental permit application process. Others focus on processing time, i.e., time spent by a resource resolving a task [12]. For instance, in Park et al. [33] the aim is to reduce the processing time of manual tasks in a loan application process. Another set of methods aim at increasing quality. For example, a method seeks to increase perceived service quality for the users of a ﬁnancial web service [44]. Finally, two papers [15,38] describe methods that aim to improve revenues, e.g., by increasing customer lifetime value [15] Prescriptive process monitoring methods prescribe actions to take, i.e., interventions. These interventions can be categorized according to the process perspective of the prescribed intervention. Our review indicates that interventions commonly concern control ﬂow and resource perspectives. A common intervention perspective is control ﬂow, such as prescribing the next task to perform [23,18,6,29]. More speciﬁcally, in de Leoni et al. [23], the next best task is prescribed to the professional who helps a customer in ﬁnding a new job, whereas in Weinzierl et al. [44], the next step is presented to the end-user. Following the prescribed intervention can improve execution time, customer satisfaction or service quality. In other studies, a sequence of next steps is prescribed as an intervention. For instance, in one method, the appropriate treatment of a blood infusion is prescribed for patients based on their personal information [10], whereas another method prescribes steps to be taken in a trauma resuscitation process [47]. Such interventions aim to improve treatment quality. Another group of methods focuses on the resource perspective, e.g., which resource should perform the next task. For instance, Wibisono et al. [45] prescribe which police oﬃcer is best suited for the next task in a driving license application process based on their predicted performance. In another method, a mechanic is recommended to carry out car repairs because s/he is predicted to ﬁnish it within a deﬁned time given their schedule and experience [36]. Some papers propose prescribing multiple interventions for one case [35,30,5]. For example, an intervention to make an oﬀer to a client is prescribed together with a suggestion for a speciﬁc clerk to carry out the task [35]. Similarly, in an IT service management process, recommending the next task and the specialist to perform it can help to resolve open cases quicker [30]. When reviewing the identiﬁed papers, we noted that interventions could be divided into two aspects; intervention frequency and intervention basis. Intervention frequency captures when interventions are prescribed. In this sense prescriptive monitoring methods can be continuous or discrete. If the method is continuous, it prescribes an intervention for multiple or all activities of an ongoing case. For example, the best-suited resource for each next task is prescribed [45]. Discrete interventions, in comparison, prescribe actions to be taken only when a need is detected. For instance, in Metzger et al. [27], interventions are triggered only when it is detected that the probability of a negative outcome exceeds a deﬁned threshold. The intervention basis describes whether a method is prediction-based or similarity-based. Prediction-based methods predict the outcomes of an ongoing case and then prescribe an intervention. Similarity-based methods in comparison provide recommendations solely based on an analysis of historical traces. For instance, one method predicts the possible outcomes if a task is performed as the next step [23]. The next step is prescribed based on which option leads to a greater metric improvement. In contrast to this method, a set of actions are prescribed based on the similarity rate of a current ongoing case and similar previous cases in another method [41]. Prescriptive process monitoring methods we identiﬁed use control ﬂow, resource, temporal, and domain-speciﬁc data. Some methods focus on a single type of data, but other methods combine data input from diﬀerent types. As expected, methods that prescribe interventions impacting control ﬂow, such as the next task to execute, commonly use control ﬂow data. For example, in Conforti et al. [8], the authors apply decision trees on data, such as task duration and frequency, to predict the risk of a case fault, e.g., exceeding the maximum cycle time and costs overrun. Goossens et al. [15] prescribe the next task by using the sequence of events as a key feature. Data on resources are used to trigger interventions related to diﬀerent prescription perspectives. For instance, one method predicts the execution time of past resource performance [46]. The data on resource performance is used to reallocate pending work items to the resources with higher eﬃciency. In another method, the authors use resource roles and capabilities combined with domainspeciﬁc features, such as vehicle type, to recommend which mechanic should be assigned the next task [36]. The data is used to predict which resource would improve the probability of the vehicle repair being ﬁnished within a deﬁned time. Temporal data, e.g. day of the week, is also used to prescribe interventions. Such data is commonly used in combination with other data, such as control ﬂow or resources. For instance, the best-suited resource to execute the next task is recommended utilizing the period of the day (morning, afternoon, or evening), inter-arrival rate, and task queue data as input [45]. In another method, temporal information (month, weekday, hour) of the last event and the inactive period before the most recent event in the log are used to evaluate the eﬀectiveness of an intervention to reduce cycle time [7]. Domain-speciﬁc features, such as materials used in a manufacturing process [14], patient demographics and treatment attributes in a patient treatment process [47], are also utilized as data input. For instance, data about previously treated patients and data on the current patient is used to assess the predicted outcome of alternative next tasks [25]. This method recommends the task that has the best-predicted outcome for the patient to reduce the risk of medical mistakes, such as prescribing the wrong medication. <title>5 Framework and Implications</title> In this section, we present a framework for characterizing existing work on prescriptive process monitoring. Furthermore, we discuss the implications of our review and conclude with the limitations of the study. The proposed framework (Figure 1) characterizes prescriptive process monitoring methods from ten aspects, derived from the review results (cf. Section 4). The framework reads from left to right and begins with the aspect of objective. Other aspects include the interventions to reach the objective, the input required, the techniques used in the methods and the policies used to trigger interventions. The main aspect of the framework is the Objective. Our analysis shows that the identiﬁed methods can be divided into two categories according to the objective they pursue (cf. Section 4.1). The ﬁrst category aims to reduce the percentage of cases with a negative outcome (i.e. the defect rate). Methods in the second category aim to optimize a performance dimension captured via a quantitative performance metric deﬁned at the level of each case (e.g. cycle time). The next aspect of the framework is the Target: the metric used to assess if the performance is improved by the prescribed interventions. For the objective of reducing the defect rate, the target may be a count of a categorical case outcome (e.g., customer complaints) or of a temporal outcome (deadline violations). Quantitative performance targets include cycle time, labor cost, or revenue. The next two columns (Prescription perspective, Intervention) capture the interventions that the methods prescribe to pursue the deﬁned objective. Thus, Prescription perspective describes to which process aspect the intervention concerns, e.g., resource or control ﬂow. We also included the category ”multiple” for methods that describe several interventions. Then, the aspect Intervention lists the actual interventions (cf. section 4.2). For instance, actual intervention can be which resource to assign to the next task. The following four columns deﬁne the data (Input perspective, Feature encoding), techniques (Modeling technique), and policies (Policy) to trigger interventions. Namely, Input perspective describes the types of features, i.e., input data, required for a speciﬁc method (cf. section 4.3). Thus, the categories we elicited are (C) control ﬂow (e.g., activities, sequence, and frequencies), (R) resources (e.g., performers of activities), (T) temporal features (time-related), and (D) domain-speciﬁc (features that depend on the domain or type of process). The aspect Feature encoding explains how features are further reﬁned by a prescriptive method. For instance, resource-perspective features can be encoded as resource experience, resource performance, or resource workload. The aspect Modeling technique relates to the technique used in the method to predict the outcome of the process or the metric performance based on the input. Next, Policy relates to the conditions under which an intervention is prescribed. For example, under a similarity-based policy, an intervention is prescribed based on the similarity of the current case to previous cases. Some methods take a set of rules as their policy. For example, the need for an intervention is detected when the probability of a negative outcome exceeds a deﬁned threshold, but also the eﬀectiveness of the intervention is assessed before prescribing it. The aspect Intervention frequency shows whether a method is continuous (prescribes actions at every step) or discrete (only when the need is detected). Additionally, Intervention basis describes whether a method builds on the prediction of how the current case will continue or its similarity to the past cases (cf. section 4.2). Finally, the aspect Example (see full version of the framework) can be used as a reference to how the introduced method with its inputs, technique, and policies was used to trigger interventions to reach the objective of a process in a speciﬁc domain. Existing methods could be explored from the framework by objective, target, and prescribed process perspective. As such, if one seeks to minimize the cycle time of a process, the aim is to optimize quantitative case performance (Objective), more speciﬁcally, cycle time (Target). The framework shows that this can be achieved by prescribing interventions related to the control-ﬂow or resources of the respective process (Prescription perspective). If we follow the resource perspective, the framework shows that a set of methods can recommend, for example, resources for the next task or a whole team for a speciﬁc request (Intervention). For instance, two methods [45,1] propose to recommend resources for the next task as an intervention. However, they have diﬀerent input perspectives and techniques. Continuing with selecting control ﬂow and temporal as the input perspectives, it leads to the method which uses the predicted (Intervention basis) highest resource performance (Policy) to continuously (Intervention frequency) prescribe a resource for the next task. The presented framework provides an overview of existing prescriptive process monitoring methods by categorizing them according to their objectives and targets. The framework also presents diﬀerent methods available and diﬀerent ways these methods enable reaching particular objectives. The overview unveils several gaps and associated implications for future research. First, we observe that in the vast majority of previous studies, the proposed prescriptive process monitoring methods have been tested using synthetic and/or real-life event logs. However, the validation of the method is done using a real-world or synthetic observational event log, but not in real-life settings. An attempt to test the eﬀectiveness of interventions in real-life settings was made by Dees et al. [9]. Their study showed that the predictions were rather accurate, but the interventions did not lead to the desired outcomes. Thus, validations of methods should be done in real-life settings to ensure their usefulness in practice, as also previously highlighted by [28]. Second, the current state-of-the-art in the ﬁeld is focused on identifying cases in which interventions should be applied and ﬁnding the point in time an intervention should be triggered during the execution of a case. In contrast, little attention has been given to the problem of discovering which interventions could be applied to optimize a process with respect to a performance objective. Discrete methods leave it up to the users (stakeholders) to deﬁne the possible intervention(s) a priori (e.g., [23,37]). Those methods that use observational event logs from BPI challenges , rely on winner reports to identify the possible interventions (e.g., [35,37]). Continuous methods, on the other hand, focus on recommending the next task(s) (e.g., [15,6,47]) or resource allocation (e.g., [3,1,21]). Thus, one direction for further research is designing methods to support the discovery of interventions from business process event logs, or from textual documentation, or other unstructured or structured metadata about the process. Related to the above problem of discovering interventions, another gap in existing research relates to the problem of designing and tuning policies for prescriptive process monitoring. Existing prediction-based methods (e.g., [36,16]) prescribe an intervention when the probability of a negative outcome exceeds a deﬁned threshold. However, because the predictive models upon which methods rely are based on correlation (as opposed to causal relations), the prescriptions produced by this method might not address the cause of the negative outcome or poor performance (e.g. the cause of delay). In this respect, we note that only a few existing methods take into account causality in policy design (e.g., [35,7]). Thus, developing policy design techniques that take into account causality is another direction for further research. As discussed in [9,23], the choice of whether or not to apply an intervention or which intervention to apply often depends on contextual factors. Some interventions may lead to prove ineﬀective or counter-productive, for example, due to second-order eﬀects. For example, an intervention wherein a customer is contacted pro-actively in order to prevent a customer complaint may actually heighten the probability of a complaint [9]. Similarly, assigning a resource to a case that is running late might lead to other cases being neglected, thus creating delays elsewhere and thus leading to a higher ratio of delayed cases. Detecting such second-order eﬀects requires human judgment and iterative policy validation (e.g. via AB testing). In this respect, it is striking that existing prescriptive process monitoring methods do not take into account the need to interact with human decision-makers. A crucial step in this direction is the ability to explain why the prescriptive monitoring system recommends a given intervention. There are two aspects to this question. First, explaining the prediction that underpins a given prescription (prediction explanation), and second, explaining the policy that is used to trigger the prescription (policy explanation). A possible direction to enhance the applicability of prescriptive monitoring methods in practice is to integrate explainability mechanisms into them. While several proposals have been made to enhancement the explainability of predictive process monitoring methods [19], the question of policy explanation in the area of prescriptive process monitoring is unexplored. In other words, current methods do not incorporate a mechanism to explain why an intervention is recommended by the method for a given case and in a given state. Besides the above gaps, the SLR highlights that the majority of methods in the ﬁeld aim to improve processes along the temporal perspective (e.g. cycle time, processing time, deadline violations). In comparison, other performance dimensions are represented in only a few examples (quality in [10,44,47], revenue in [15,38]). Thus, another research direction is to investigate other performance objectives that could be enhanced via prescriptive process monitoring. Finally, our review also highlights a lack of common terminology in the ﬁeld. This might be due to the novelty of the research ﬁeld of prescriptive process monitoring. The literature refers to methods with a wide range of names. As such, the terms ”proactive process adaptation”, ”on-the-ﬂy resource allocation”, ”next-step recommendation” are all used to describe the development and application of prescriptive process monitoring methods. This highlights the need for common terminology. SLRs have a number of typical pitfalls and threads to validity [22,2]. First, there is a potential risk of missing relevant publications during the search. We mitigated this risk by conducting a two-phase search that included a broad range of key terms, as well as backward referencing. Another potential threat is to exclude relevant publications during screening. We mitigated this threat by using explicitly deﬁned inclusion and exclusion criteria. Furthermore, all unclear cases were examined and discussed by all authors of this paper. Third, there is a threat of data extraction bias as this step involves a degree of subjectivity. We discussed each paper in the ﬁnal list and reﬁned the data extraction when needed to minimize this risk. <title>6 Conclusion</title> This paper provided a snapshot of the research ﬁeld of prescriptive process monitoring via an SLR and outlined a framework for characterizing methods in this ﬁeld. The framework characterizes existing methods according to their objective, target metric, intervention type, technique, data input, and policy used to trigger interventions. The framework was derived from and used to characterize the 36 relevant studies identiﬁed by the SLR. Based on the SLR, we identiﬁed research gaps and associated research avenues. In particular, the SLR highlighted: (i) a lack of in vivo validation of the proposed methods; (ii) a lack of methods for discovering suitable interventions and assessing their potential eﬀectiveness; (iii) little emphasis on explainability and feedback loops between the prescriptive monitoring system and the endusers; and (iv) a narrow focus on temporal metrics and comparatively little work on applying prescriptive monitoring to other performance dimensions. Acknowledgments. This research is funded by the Estonian Research Council (PRG1226) and the European Research Council (PIX Project). <title>References</title>