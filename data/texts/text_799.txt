The homepage recommendation on most E-commerce applications places items in a hierarchical manner, where different channels display items in different styles. Existing algorithms usually optimize the performance of a single channel. So designing the model to achieve the optimal recommendation list which maximize the Click-Through Rate (CTR) of whole homepage is a challenge problem. Other than the accuracy objective, display diversity on the homepage is also important since homogeneous display usually hurts user experience. In this paper, we propose a two-stage architecture of the homepage recommendation system. In the ﬁrst stage, we develop efﬁcient algorithms for recommending items to proper channels while maintaining diversity. The two methods can be combined: user-channel-item predictive model with diversity constraint. In the second stage, we provide an ordered list of items in each channel. Existing re-ranking models are hard to describe the mutual inﬂuence between items in both intrachannel and inter-channel. Therefore, we propose a Deep & Hierarchical Attention Network Re-ranking (DHANR) model for homepage recommender systems. The Hierarchical Attention Network consists of an item encoder, an itemlevel attention layer, a channel encoder and a channel-level attention layer. Our method achieves a signiﬁcant improvement in terms of precision, intra-list average distance(ILAD) and channel-wise Precision@k in ofﬂine experiments and in terms of CTR and ILAD in our online systems. Homepage recommendation is a common task in the industry, especially on E-commerce platforms, such as Amazon and Aliexpress. In many cases, the homepage has a hierarchical architecture containing multiple channels, and each channel contains several items, as shown in ﬁgure 1. A channel, such as Top Sellers and Deal of the Day, is a collection of items gathered according to certain attributes of items. Items can be recommended to multiple channels according to their corresponding attributes. Existing algorithms only consider the accuracy and diversity of a single channel and are hard to produce the optimal recommendation list of the whole homepage. Thus designing a model for optimal recommendation on the whole list is a challenge problem. In addition to the recommendation accuracy, the differences of users’ preferences for channels and the diversity of the whole homepage have an important impact on homepage Figure 1: The hierarchical structure of homepage. recommendation. Firstly, we discuss whether users have different preferences for channel. Based on behavioral data, such as the frequencies of browsing in each channel, we classify users into three groups. As expected, users can be clustered into three different groups based on their different channel preferences. Therefore, instead of user–item predictive model, we require to create a user–channel–item predictive model for CTR prediction. Besides, in order to design an accurate recommender for CTR prediction, modeling the mutual inﬂuence between items is an important topic for the researchers of E-commerce recommender systems. Secondly, diversiﬁcation has become one of the leading topics of recommender system research. We ﬁnd it is necessary to manage diversity in homepage recommender systems. Furthermore, we discuss whether users have different levels of tolerance for item repetitions belonging to each category. We calculate the CTR under different number of phones’, clothes’, food’s and jewelry’s recurring during a month, as shown in ﬁgure 2, which turns out that users’ tolerance for reappearance of different category is different. For example, the CTR is the highest when the number of phones’ recurring equals to 2, however, it is the highest when the number of clothes’ recurring equals to 3, so we suggest to set speciﬁc threshold for each category. Existing methods are sub-optimal because it is hard to tackle the above issues. Although several re-ranking mod- Figure 2: Distributions of CTR under different number of phones’, clothes’, food’s and jewelry’s reappearances. els have been proposed to model the mutual inﬂuence between items, they do not speciﬁcally consider the homepage structure, which usually exhibits a hierarchical architecture. Also, existing re-ranking methods do not consider avoiding repeated appearances of the same item in multiple channels. Although there exists abundant methods to deal with diversiﬁcation in ranking, they do not ﬁt well with homepage recommendation applications, because it is hard to balance accuracy and diversity given multiple channels. Besides, these methods are not as adequate for modeling the relationship between items as Deep List-wise Context Models. They only use pairwise dissimilarities to characterize the overall diversity property of the list, which may not capture complex relationships among items. For example, in maximal marginal relevance (MMR) (Carbonell and Goldstein 1998) method , the score of an item under consideration is proportional to its relevance minus a penalty term that measures its similarity to the items previously selected. To summarize, the main contributions made in this paper are as follows: • We propose an efﬁcient two-stage architecture of homepage recommender. To the best of our knowledge, it is the ﬁrst to explicitly introduce the homepage structure into re-ranking task in large-scale online system. • We design a user-item-channel predictive model for CTR prediction as well as diversiﬁed assignment. Speciﬁcally, we propose a general framework that employs linear programming to recommend items to proper channels under a whole class of diversity constraints. • We provide an optimal recommendation list in each channel by re-ranking. In order to describe the mutual inﬂuence between items in both intra-channel and interchannel, we propose a Deep & Hierarchical Attention Network Re-ranking (DHANR) model for homepage recommender systems. • Our proposed method can be speciﬁc to determine how many items should be recommended for each category. It is better to set a speciﬁc threshold for each category, as the tolerance of the user to the multiple occurred items in each channel is different. • We conduct extensive ofﬂine and online experiments on an E-commerce Recommendation System. We observe a superior performance of our proposed model. First we review related work on various re-ranking approaches, and then discuss existing measures of diversity in the recommender systems. Re-ranking Methods. Typically, a ranking function is learned from the labeled dataset to optimize the global performance, which produces accurate ranking score or maximum CTR (Burges et al. 2005; Burges 2010; Cao et al. 2007; Friedman 2001; Joachims 2006; Taylor et al. 2008; Xia et al. 2008). However these methods do not explicitly consider the mutual inﬂuence between items. Several deep list-wise context models (Ai et al. 2018; Yin et al. 2016; Zhuang, Ou, and Wang 2018; Pei et al. 2019; Bello et al. 2018) have been proposed to model the mutual inﬂuence between items. These works tend to model the mutual inﬂuences between items explicitly to reﬁne the initial list given by the previous ranking algorithm, which is known as reranking. The main objective is to build the scoring function by encoding the information of all items in the list into feature space. The methods for encoding the feature vectors contain RNN-based and transformer-based(Kang and McAuley 2018). The RNN-based models include GlobalRerank (Zhuang, Ou, and Wang 2018), Seq2Slate (Bello et al. 2018) and DLCM (Ai et al. 2018), and the transformerbased model including PRM (Pei et al. 2019). They feed the initial list into RNN-based or transformer-based structure sequentially and output the encoded vector at each time step, to model the mutual inﬂuences between items. Seq2Slate (Bello et al. 2018) and GlobalRerank (Zhuang, Ou, and Wang 2018) use the decoder structure to generate the re-ranked list. Seq2Slate (Bello et al. 2018) uses the pointer network(Vinyals, Fortunato, and Jaitly 2015) to generate re-ranked list sequentially. GlobalRerank (Zhuang, Ou, and Wang 2018) uses RNN with the attention mechanism(Vaswani et al. 2017) as the decoder. PRM (Pei et al. 2019) directly optimizes the whole recommendation list by employing a transformer structure to efﬁciently encode the information of all items in the list. Diversity Methods. A common speciﬁc deﬁnition of diversity in the literature is the average pairwise dissimilarity between recommended items. There are a wide range of methods for managing diversity in ranking(Carbonell and Goldstein 1998; Borodin, Lee, and Ye 2012; Qin and Zhu 2013; Chen, Zhang, and Zhou 2018; Wilhelm et al. 2018; Hijikata, Shimizu, and Nishida 2009; Lathia et al. 2010; McNee, Riedl, and Konstan 2006; Vargas et al. 2014; Yu, Lakshmanan, and Amer-Yahia 2009; Zhang and Hurley 2008; Ziegler et al. 2005). Most methods deﬁne set-wise diversity metrics and involve a tunable parameter to adjust the trade-off between relevance and diversity, such as maximal marginal relevance (MMR)(Carbonell and Goldstein 1998), max-sum diversiﬁcation (MSD) (Borodin, Lee, and Ye 2012) and entropy regularizer (Entropy) (Qin and Zhu 2013). The maximal marginal relevance (MRR)(Carbonell and Goldstein 1998) model was one of the pioneering work for promoting diversity in information retrieval tasks. The trust-region based optimization method(Yuan 2000) aims to maximize the diversity of recommendation list, while maintaining an acceptable level of matching quality. Entropy regularizer (Entropy) (Qin and Zhu 2013) method is incorporated in the contextual combinatorial bandit framework to diversify the online recommendation results. There are also methods using a DPP-based (Borodin 2009; Gillenwater 2014; Kulesza and Taskar 2012) approach for recommending relevant and diverse items to users. For example, a fast greedy maximum a posteriori(MAP) inference algorithm for determinantal point process (Chen, Zhang, and Zhou 2018) was proposed to improve recommendation diversity. We propose a two-stage architecture for the homepage recommender. The overview of our method is shown in ﬁgure 3. The ﬁrst stage includes a recommendation process that puts items into proper channels under diversity constraints. In the second stage, we propose the DHANR model to provide an ordered list of items in each channel. Personalized recommendation with diversity considerations is an important task for modern recommender systems. Our framework deals with this problem. A user–channel–item Predictive Model For CTR Prediction. In order to model the differences of users’ preferences for channels, we create a user–channel–item predictive model to predict the CTR in each channel. Typically, ranking in recommender system only considers the user-item pair features. In our deep network, we also consider the channel features, which are used as the input for the context network. Thus, the outputs of the model are user–channel–item tripartite structure scores. Popular model structures, such as DNN, DeepFM, DCN, can be used here. Diversity Measure. We choose to deﬁne diversity with respect to attributes of items, such as category, brand and style. How to set the thresholds for each type of recommended item requires further consideration. For example, how many items related with food can be displayed on the homepage. We calculate the conditional probability of CTR given the number of items belong to category c equals to k as: CT R=P r[click = 1, cnt(category = c) = k]P r[cnt(category = c) = k](1) where cnt(category = c)) means the number of the items belong to category c. The k maximizes the above formula is expressed by T. This Tmeans the maximum of items belonging to category c can be displayed on homepage during one exposure. Optimizing Allocation with Linear Programming. We model the problem to ﬁnd the optimal CTR of the whole page, under the diversity constraints, as a linear programming problem. The goal is to obtain the maximal CTR of the whole homepage while satisfying all diversity constraints, which can be formulated as the following, where Ω =, Xis the decision variable indicating whether the algorithm allocates the j-th item to the i-th channel. Ris the CTR of item j in channel i, which is calculated by user–channel–item Predictive Model. The ﬁrst restriction means that each item only can be assigned to at most one channel. The second restriction ensures that V be allocated to the i-th channel. Vis the number of recommended items in the i-th channel. h is the hyperparameter which controls the number of items input into re-ranking models. The third restriction is the constraints on diversiﬁed exposures, which ensures that the number of items belong to category c displayed on the homepage should not exceed the diversity constraint threshold T. For example, the items related with food cannot be displayed on homepage more than 3 positions. Besides, we introduce a slack variable ξto control the strength of diversity constraints. The fourth restriction ensures the number of items belonging to the same category displayed on each channel should not exceed the bound B. The resulting linear program can be solved efﬁciently and optimally with standard algorithms like interior point methods. Then we allocate items to the channels accordingly. The output item lists contain V Deep & Hierarchical Attention Network Re-ranking (DHANR) Model In this section, we create a re-ranking model to optimize the order of items in each channel. In order to model the mutual inﬂuence between items in both intra-channel and interchannel as well as the differences of users’ preferences, we build a Deep & Hierarchical Attention Network Re-ranking (DHANR) model to predict the CTR in each channel. The optimal recommendation list in each channel can be obtained by ranking items by their re-ranking scores. The architecture of our DHANR Model is shown in ﬁgure 4 (a). The model consists of two categories of components: the deep component and the hierarchical attention component. The deep component has been introduced in user-channel-item model. The detailed structure of the hierarchical attention network component is shown in ﬁgure 4 (b). The input of this network is the item lists generated by previous user-channel-item and allocation method. Our hierarchical attention network consists of an item encoder, an item-level attention layer, a channel encoder and a channellevel attention layer. we embed the items vectors, then adopting Transformer-like encoder to integrate the mutual inﬂuences of item-pairs in each channel. The self-attention mechanism is suitable in our re-ranking task as it directly models the mutual inﬂuences for any two items regardless the distances between them. The self-attention function is deﬁned as: where Q, K, V are matrices and represent queries, keys and values respectively. dis a scaling factor and represent the dimensionality of matrix k. To model more complex mutual inﬂuences, we use the multihead attention. Our encoding module consists of Nblocks of Transformer encoder. Each block contains an self-attention layer and a Feed-Forward Network (FFN) layer. We use the aforementioned encoding method to generate a richer representation of items in each channel, that is h. nism and an item level context vector rto extract items that are important to the channel and aggregate the representations of those informative items to form a channel vector. adopt an encoder as illustrated in the item encoder to integrate the mutual inﬂuences of channel-pairs in a similar way as the item encoder and obtain a richer representation of channels, h. mechanism and introduce a channel level context vector v to extract overall homepage representation. Finally, the vectors generated by the deep component and by the hierarchical attention component are concatenated together to feed into a multilayer perceptron (MLP). In this section, we ﬁrst introduce the datasets and baselines used for evaluation. Then we compare our methods with baselines on these datasets to evaluate the effectiveness of our model. To the best of our knowledge, there does not exist publicly available re-ranking homepage datasets with context information for recommendation. Therefore, we construct an E-commerce Re-ranking dataset from a real-world Ecommerce platform. The dataset contains the user clickthrough data of the homepage. The size of training and testing set is about 320 millions and 80 millions respectively. These channels have 3, 4, and 3 items, and the number of items is about 8M. Compared with channel 3, channel 1 and channel 2 have 1.07% and 1.14% higher CTR. As there are two stages in our method, we conduct the study to understand the contributions of each stage. In the ﬁrst stage, the algorithm for CTR prediction and recommending items to proper channels under diversity constraints is denoted as UCI-AA. We use following methods as our baselines in the ﬁrst stage. fed into multiple layer perception. Then, an output layer predicts the probability whether the user will click the item with a sigmoid function. ing a separate model for each channel. redundancy while maintaining relevance. modular relevance term and a supermodular sum of distance diversity term. which recommends items to proper channels under diversity constraints based on CTR score as predicted in userchannel-item model. The UCI-AA method determines the set of items under each channel, but it has not determined the order of items in each channel. In the second stage, we add the hierarchical attention network to re-ranking, which is denoted as UCI-AA-DHANR. We choose DLCM(Ai et al. 2018) and PRM (Pei et al. 2019) as our baseline methods in the second stage, as other re-ranking methods mentioned in related work can not be parallelized in online inference and the time complexities are unacceptable. to encode the local context information into a global vector. Combing the global vector and each feature vector, it learns a more powerful scoring function than the model without re-ranking. dation list by employing a Transformer structure to efﬁciently encode the information of all items in the list. on the UCI-AA model, we propose a Deep & Hierarchical Attention Network Re-ranking (DHANR) model for describing the mutual inﬂuence between items in both intrachannel and inter-channel. Evaluation Metrics For ofﬂine evaluation, we use precision to compare different methods for the homepage recommendation: where U is the set of all user requests in the dataset, R is the set of items recommended to user request u, Cdenotes the set of items clicked. Furthermore, in order to compare the performance of our DHANR Model with other reranking methods, we use P recision@kto evaluation the performance in each channel, which is deﬁned as the the fraction of clicked items in the top-k recommended items for all test samples in each channel. Since we are optimizing the recommendation of multiple channels as a whole, tion. where Sis the ordered list of items given by the re-ranking model for each request u ∈ U and S the indicator function on whether item i is clicked or not. Also, we compare the diversity of our method with other diversity methods. Diversity metric is measured by the intralist average distance (ILAD), which deﬁned as follows: where Sdenotes the similarity between two items i and j, for fair comparison, we deﬁne Sby the Jaccard similarity between the categories of two items i and j. For online A/B tests, we use CTR and diversity as metrics. CTR is the click through rate and can be calculated by IPV/PV. PV and IPV are deﬁned as the total number of items viewed and clicked by the users, respectively. Experimental Settings In the experiments, for both baselines and our methods, we use the same value for those critical hyper parameters. The learning rate of Adam optimizer is 0.0001. pis set to 0.01. The batch size is set to 512. For the deep network, we set the hidden layers as 3, the number of units in each hidden layer is set to 512, 256, 128 respectively, and we use ReLUs as the activation function. The rest of the settings belonging to the customized parts of our model will be listed at the corresponding parts in the Hyper-Parameters Investigation section. The experiments are repeated 10 times with independent data. 80% as training data, 20% as test data. We display the mean performance in the following tables in ofﬂine and online performance sections. The standard deviation is within the range of [0.002, 0.009] . Ofﬂine Performance In this section, we conduct ofﬂine evaluations on an Ecommerce dataset. We conduct the study to ﬁnd how each stage in our model contributes to the performance. In the ﬁrst stage, the percent difference in precision and diversity for the various approaches during a week is described in table 1. In the second stage, we illustrate the Precision@1, Precision@2 of our DHANR model and other re-ranking methods in each channel, as listed in table 3. We also conduct the Hyper-Parameters Investigation. Model analysis Table 1 shows that our UCI-AA model achieves stable and signiﬁcant performance improvements comparing with all baselines. UCI-AA outperforms MSD by 5.7% at Precision and 15.1% at Diversity, as well as outperforms MMR by 5.4% at Precision and 12.5% at Diversity. The gap gets larger when comparing with DNN, which has 9.3% increase at Precision and 25.6% increase at Diversity. DNN(single) achieves the worst performance due to training single-scene models does not take advantage of the rich user and item information from all channels. Among all the compared diversity methods, our proposed UCI-AA almost always achieve the best performance in every channel, which mainly comes from the powerful encoding of user’ preferences for channels and the effective controlling of diversiﬁed exposures. In general, we see that the model tends to demote listings with more diversity. The diversity score distribution of the categories and brands in ﬁgure 5 is quite revealing. The plot clearly shows our method frequently produce recommendations with different categories and brands. Further more, with re-ranking method, UCI-AA-DHANR extend 5.6% at Precision over UCI-AA. table 2 shows that on average, UCI-AA-DHANR achieves 11.5% improvements on Precision@1 and 6.2% improvements on Precision@2 comparing with UCI-AA due to the powerful encoding of mutual inﬂuence between items in both intra-channel and inter-channel. Among all the compared reranking methods, our proposed DHANR almost always achieve the best performance in every channel. For further illustration, in order to validate that the DHANR model is able to learn meaningful information with respect to characteristics of items and channels, we visualize the average attention weights between items on category. As shown in ﬁgure 6, the items with similar categories tend to have larger attention weights. We can conclude that the DHANR model can successfully capture mutual-inﬂuences of items. For example, “men’s clothing” has more inﬂuences on “women’s clothing” than on “consumer electronics”. Besides, the channels with similar items tend to have larger attention weights. Hyper-Parameters Investigation In UCI-AA model, we test the impact of trade-off parameter U in expression (3). Figure 5: Diversity score distribution of the recommender systems, based on the similarity of (a) category, (b) brand The results are shown in ﬁgure 7. As U increases, the diversity constraint become stronger. Precision improves at ﬁrst, achieves the best value when U ≈ 2, and then decreases a little bit. Diversity is monotonously increasing as U increases. Therefore, we set U as 2. In addition to the tradeoff parameter U, we also try different bounds(B = 1; 2; 3) which restrict the number of items from the same category that can be displayed on each channel and different hyperparameters (h = 0; 1; 2; 3). Due to limited space, we will not put the experimental data. The best performance is achieved when B is 2 and h is 1. In DHANR model, we try different settings(h = 1; 2; 3) in the multi-head attention layer and different settings of block number(N improvements are observed in the DHANR model, which are listed in table 2. We conduct online experiments (A/B testing) on the Ecommerce Recommendation online System. The online performance of methods, measured in terms of CTR and diversity, is summarized in table 4. Table 4 shows the performance improvements in online A/B test compared to a DNN model without re-ranking method. From table 4 we can conclude that by taking moderate amount of diversity into consideration, better performance can be achieved. All three methods, MMR, MSD and our UCI-AA model, increase the CTR and diversity. However, MMR and MSD do not improve the online metrics as much as our method. On average, our model outperforms DNN-based LTR without re-ranking models by 5.62% and Table 2: Ofﬂine P recision@1& P recision@2of Methods and Hyper-Parameters Investigation in DHANR model during a week. Table 3: Performance improvements in online A/B test compared to a DNN without re-ranking method during a week. Figure 6: Average attention weights related to items’ attributes. 26.23% in terms of CTR and Diversity. We can also conclude that re-ranking helps to increase the online metrics, as improvement can be observed regardless of the re-ranking methods. However, DLCM and PRM do not improve the online metrics as much as our method. Our model outperforms other algorithms in each channel. In this paper, we propose a method to improve the precision and diversity for the homepage recommendation problem. Instead of optimizing evaluation metrics in a single channel, we take the homepage structure into consideration and design a two-stage architecture algorithm. During the ﬁrst stage, we developed a general framework that employs linear programming to recommend items to proper channels Figure 7: Impact of trade-off parameter U . under a whole class of diversity constraints. Then in the second stage, a DHANR model is proposed to reﬁne the order of items in each channel. To verify the effectiveness of our method, we conduct ofﬂine and online experiments. Both the online and ofﬂine experiments demonstrate that our method could greatly improve the performance on realworld datasets. Though we achieved our initial goal of increasing diversity and relevance of recommended items to users, there still remain many unexplored frontiers. One idea is to use Bandit algorithms to estimate the optimal number of items for each category.