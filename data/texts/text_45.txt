We synthesize the reported results and recommendations of recent workshops and seminars that convened to discuss open questions within the important intersection of robotics, human-robot interaction, and spoken dialogue systems research. The goal of this growing area of research interest is to enable people to more effectively and naturally communicate with robots. To carry forward opportunities networking and discussion towards concrete, potentially fundable projects, we encourage interested parties to consider participating in future virtual and in-person discussions and workshops. Advances in robotics and human-language technologies are accelerating, from robots that vacuum ﬂoors to more natural dialogue with Alexa devices. A newly forming Special Interest Group for Spoken Language Interaction with Virtual Agents and Robots (SLIVAR) aims to bring these two broad areas together with the goal of empowering people to communicate with robots the way that humans largely communicate with each other: natural human language, particularly spoken dialogue. As robots permeate the world from industry to households, their widespread adoption will be tied to the ability for non-technical, lay people to interact with them as easily as possible. Imagine a robot that can perform its task of vacuuming the ﬂoor, but also informing a nearby human that it bumped into an object that happens to be a long-lost TV remote, or that its dust bin is full and needs help being emptied. Better still, robots that can learn about their environment and the people with whom they will interact will be more adaptable to many settings and a diversity of users, and what better way to learn about the world than to ask a person? DeﬁnitionsA robot is an actuated mechanism programmable in two or more axes with a degree of autonomy, moving within its environment, to perform intended tasks that serve the needs of a user (Eskenazi and Zhao, 2020).A spoken dialogue system (SDS) is a an automated system that is able to converse with a human with voice. Robot complexitiesRobots are embodied and can interact with the physical world. Some have wheels, others feet; arms, others lifts; some are designed to appear to have human-like physical characteristics, others are purposefully designed not to. The variance in robot morphology, functionality, and target audience varies widely. Most robots are designed with speciﬁc hardware for narrow tasks. Common application areas for robots include industrial robotics, health care robots, and household consumer robots. Design and testing of robots is engineering and time-intensive; robots have constraints on battery power, available sensors, functionality, locomotion, and ease of use. Spoken language complexitiesMost natural language processing research is text-focused. Language model advancements based on transformers are impressive, but the ﬁeld often underestimates the richness and complexity of spoken language, especially in a co-located setting with other physical entities such as a robot. As natural as it is for people to engage in dialogue with each other, engaging in dialogue with a machine is not a natural expectation. Spoken interaction is complex and messy. People speak with accents that make speech recognition difﬁcult, not to mention common spoken dialogue artifacts such as false starts, repetitions, prosody, ﬁlled time-buying strategies, laughter and other extra-linguistic vocalizations. To further illustrate how challenging spoken dialogue can be, Schlangen (2020) gives an example of a fairly mundane dialogue between two people walking together in a park: fountain. poodle. It was too tall. I think it was a labradoodle. If one of the participants in this dialogue, say Bert, were to be replaced by an automated system, then Bert would need to be able to handle deictic references to external objects (a), identify what a dog is (a), know that poodles and labradoodles are types of dogs to the degree that Bert knows the difference between two similar types and can express conﬁdence in that knowledge (f; requiring negotiation skills, as noted by Schlangen), be able to talk about events that took place in the past about an entity that is no longer perceptually available (d-e), and use anaphoric references such as the word it (b). While it is true that developing working systems requires ample data and engineering, handling these types of phenomena together in a single system is not low-hanging fruit for research. It is our observation that these kinds of dialogue artifacts are not well-known in the broader research community, to say nothing of higher-level pragmatic issues such as allusions. Challenges to endowing robots with spoken language abilitiesDue to the above-mentioned complexities of robots and spoken language, it is not enough to plug existing SDS systems into existing robot platforms and expect any degree of natural, robust, or even useful communication. Focusing just on automatic speech recognition (ASR) as a part of SDS, ASR in a setting with a robot is wrought with its own challenges: the robot actuators could make noise and the changing acoustics of the room due to the robot’s location could affect speech recognition, to say nothing of the fullduplex nature of co-located spoken interaction; i.e., the robot needs to always be listening even if it’s talking or carrying out an action. Beyond speech recognition, natural language understanding (NLU) is challenging even if speech recognition is perfect because people don’t usually speak in complete, grammatical sentences and the fact that words and phrases refer to real, physical things that could be co-present with the human and the robot or abstractly refer to a known entity. The NLU plays an important role of mapping from speech or transcription to a computable semantic abstraction, one that is often tied to the task. What should the robot say, and when? Should the robot stick to the task or offer freer chat cababilities? Natural language generation (NLG) is very challenging because what the system says is how the system informs the user of its state or move the dialogue forward towards a shared task goal. It’s not enough to say something grammatical, it also needs to be coherent and contribut to the unfolding dialogue. Challenges for speech and human-robot interactionOn the same argument that one cannot simply attach the best-performing ASR to a robot and expect natural communication, one cannot simply put humans and robots in the same room to work together on some task and expect successful outcomes, even on narrowly-deﬁned tasks. Part of the problem is that the abilities of robots is limited, but the other and perhaps more vexing problem is on the side of the humans: when humans are confronted with robots and told to work with them, even in lab settings, humans immediately have expectations of what the robots should do, and humans also go so far as to anthropomorphize robots for gender, age, social status, among other things (in some cases, only based on how the robots appear, not how they behave), and these expectations and perceptions have implications for the kinds of things robots can do with humans. This intricate area of how humans perceive robots and the nuances of how robots and humans interact with each other (using speech or any other means) is the focus of the ﬁeld of human-robot interaction (HRI). Both SDS and robots take actions, and in order to take actions they must make decisions. For a dialogue state tracker. Robots likewise have modules that make high-level decisions on goals and low-level decisions on how to reach those goals, like move an arm or move a camera. Should decisions about what the system should say and what it should do be made jointly, or separately? It is our goal that the lessons learned from roboticists, SDS researchers (including speech, but also textual modalities) and HRI researchers can join forces to work towards humans and robots collaborating on terms that are (at least to some degree) safe and natural for the humans involved. The purpose of this paper is to synthesize what has happened recently in this cross-cutting research area to identify and overcome the complexities, challenges, and open questions to language communication with robots. In the following section, we outline some recent work including workshops and publications that contribute to the discussion, then propose next steps for the growing SLIVAR community. Two U.S. National Science Foundation workshops were convened in October, 2019: Future Directions Workshop, Toward User-Oriented Agents: Research directions and Challenges (Eskenazi and Zhao, 2020) which focused on the role of intelligent agents and how to make them more user-oriented. The participants of the workshop identiﬁed broad areas and themes for future directions (taking note of common pitfalls (Balentine, 2007)) including applications, infrastructure, dynamic views of useragent interaction, and made several recommendations in building low-cost dialogue systems, multimodal, grounded, and situated interaction, robust and ﬂexible dialogue management, and intelligent agents as good actors. The second workshop Spoken Language Interaction with Robots (Marge et al., 2020, 2022) focused on speech and the complexities thereof when robots are involved. The participants identiﬁed recommendations relating to eight different themes: 1.First, meeting human needs requires work on new challenges in speech technology and user experience design. 2.Second, this requires better models of the social and interactive aspects of language use. 3.Third, for robustness, robots need higherbandwidth communication with users and better handling of uncertainty, including simultaneous consideration of multiple hypotheses and goals. 4.Fourth, more powerful adaptation methods are needed, to enable robots to communicate in new environments, for new tasks, and with diverse user populations, without extensive re-engineering or the collection of massive training data. 5.Fifth, since robots are embodied, speech should function together with other communications modalities, such as gaze, gesture, posture and motion. 6.Sixth, since robots operate in complex environments, speech components need access to rich yet efﬁcient representations of what the robot knows about objects, locations, noise sources,the user, and other humans. 7.Seventh, since robots operate in real time, their speech and language processing components must also. 8.Eighth, in addition to more research, we need more work on infrastructure and resources, including shareable software modules and internal interfaces, inexpensive hardware, baseline systems, and diverse corpora. A Dagstuhl (Germany) Seminar convened in January 2020 on the topic of SLIVAR.This resulted in organization of other events such as a special session on robots and dialogue (RoboDial 2.0) at the SIGDIAL 2020 conference,a workshop on natural language generation at the HRI 2020 conference, and a workshop ROBOTDIAL at the IJCAI 2020 conference.The primary goal of the Dagstuhl Seminar was to provide discussion and establish a community. Discussions revolved around ethics, usability, scenarios for human-agent / human-robot groups, evaluation, architectures, and situated language understanding. Other recent, related events include a AAAI Symposium on Natural Communication for Human-Robot Collaboration (2017), and RoboNLP workshops including spatial language understanding. While many have contributed in different ways to the convergence between robotics, SDS, and HRI research, two recent articles highlight recent trends, challenges, and opportunities at these important crossroads. Tellex et al. (2020) surveys the use of natural language from a robotics point of view including natural language issues that are common on robots and current state of the art with focus on tasks such as robot navigation. Kragic et al. (2018) makes the case that though there has been progress, things like full autonomy, learning in collaboration with people, and safe and ﬂexible performance in varied environments remain elusive. Kennington et al. (2020) identiﬁed 5 basic requirements for robot-ready SDS. These requirements are largely at the level of framework and processing; not all tasks and applications will need all of the requirements, nor is the list comprehensive (see Opportunities Section below), but a goal that robust and natural dialogue will need and as a starting point for the opportunities that follow in the next section: 1. modular: robot components are modular and individual modules must be able to integrate with SDS modules 2. multimodal: robots are situated dialogue partners having many sensors along with the grated together 3. distributive: robot and SDS modules are often computationally expensive; modules should be able to easily communicate with each other in a distributed environment 4. incremental: modules must be able to process input quickly and immediately 5. aligned: sensors must be temporally aligned; i.e., synchronized in time 4.1 Infrastructure •Common Tools and Platforms: A common research platform should be developed or extended for intelligent agent research. •Corpora: The collection of situated and multimodal corpora is an important future direction. •Shared Tasks: With a shared infrastructure and corpora, shared tasks will promote effective and comparable research. •Evaluation: Metrics need to be designed that account for the nuances of dialogue with intelligence agents like robots. •Science and Engineering: Work to elucidate the fundamental questions in real-time social interaction, both scientiﬁc and engineering. 4.2 Multimodal, grounded and situated interaction •The range of modalities used in today’s dialog systems should be broadened, for example by including prosody, haptics, or motion capture as input modalities. •Situated dialog should play a central role in future dialog systems research. •The advances of continuous (i.e., incremental) speech processing should be generalized to incremental multimodality. 4.3 Audio and Speech Processing •Better exploit context and expectations in speech recognition. •Consider creating a speech recognition system focused on the issues encountered in robotics (e.g., splitting speech signals and speech in noise where the noise may come from the robot and/or the surrounding environment). •Better exploit prosody, emotion, and mental state from the speech signal. •Use audio scene and sound event analysis to better understand the environment. 4.4 Mutual understanding between robot and human •Develop language understanding models for robots that resolve referential ambiguities, particularly to physically-present objects and locations in situated dialogue. •Dynamically increase the ﬁdelity of how robots represent the state of the human interlocutor. •Inference and understanding should be based on the user’s goals and beliefs. •Explore the broader space of clariﬁcation and recovery strategies in spoken language interaction with co-present agents, including when and how. •Research should be highly interdisciplinary, including linguistics, pragmatics and reasoning. •Focus on language not only as a way to achieve human-like behaviors, but also as a way to support limited but highly usable communications abilities. •Work to better characterize the list of communicative competencies most needed for robots in various scenarios •Research should be inspired by human dialog techniques in order to efﬁciently address others goals. Discourse context (as well as physical context) should be preferred to making explicit representations. •Explicit representations of context should be designed in a way that enables them to be shared with other domains, tasks and applications. •Agents should support different user style of interaction preferences • Include partially-redundant functionality. • Make components robust to uncertainty. •Focus not only on improving better core components, but also on cross-cutting issues and those that have fallen between the cracks •Make systems and components adaptable to users. •Applications are often narrow, but should be as generalizable as possible. •Applications are dependant on the target user pool / audience. •Applications should be sensitive to aspects of the individual user (e.g. their satisfaction, their cognitive or behavioral. change, their speaking proﬁciency) •Move research from generic, static views of the user, the agent and their relationship to personalized and dynamic models •Move from human-computer to multi-party, where the agent learns about different humans. •Research emphasize scenarios that involve longer conversations (beyond 1-2 turns) and/or more frequent interactions. from the same user or groups of users. •Deliberately engineer user perceptions and expectations. Low-Resource Conditions •A systematic way to introduce prior knowledge as an input to data-driven models. •Community effort to make pretraining and transferable models well-documented, thoroughly tested and widely available. •Open-source, robust and reusable tools for solved tasks, e.g. wizard-of-oz interface, data collection tools, human evaluation platform). •A principled approach for system design, data collection, resources management, and evaluation for new AI projects with limited/no data •New machine learning methods that can better utilize knowledge from other domains or unannotated data. •Shared tasks that standardize the evaluation of dialog agents under low resources setting, and regular benchmark comparison across various methods. 4.9 Intelligent Agents as Good Actors •Research plans within scientiﬁc proposals should raise and address at least one ethical issue. •Education of students and newcomers to the ﬁeld on ethical issues. •Develop outreach efforts for increasing public awareness in collaboration with target user demographics. •For every NSF/government proposal or grant that includes the release of data, the data should have a data sheet. 4.10 Policy •Fund spoken language interaction with robots as its own area of research. • Prefer evaluation-based on use cases. •Support many kinds of research and development activities. •Work to overcome the barriers to data sharing. •Explore novel public-private partnerships for open source software Taken together, we highlight some of the opportunities and complementary goals from within the ﬁelds of SDS, HRI, and robotics in Figure 1. The ﬁgure shows a human interacting with a robot in a colocated environment with two objects; the dashed lines show perceptions, solid lines and arrows show relations; colors denote areas of research that has been conducted in the respective ﬁelds which complement the goals of SLIVAR. There are ample opportunities to collaborate and work on gratifying and impactful projects at the human-robot frontier. We intend to convene a workshop in the near future to work towards these goals by building relationships and identifying speciﬁc research projects. Acknowledgements I want to thank Maxine Eskenazi for helpful feedback and suggestions.