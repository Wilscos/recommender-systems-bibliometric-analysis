Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers Abstract—Recent years have seen the vast potential of Graph Neural Networks (GNN) in many ﬁelds where data is structured as graphs (e.g., chemistry, recommender systems). In particular, GNNs are becoming increasingly popular in the ﬁeld of networking, as graphs are intrinsically present at many levels (e.g., topology, routing). The main novelty of GNNs is their ability to generalize to other networks unseen during training, which is an essential feature for developing practical Machine Learning (ML) solutions for networking. However, implementing a functional GNN prototype is currently a cumbersome task that requires strong skills in neural network programming. This poses an important barrier to network engineers that often do not have the necessary ML expertise. In this article, we present IGNNITION, a novel open-source framework that enables fast prototyping of GNNs for networking systems. IGNNITION is based on an intuitive high-level abstraction that hides the complexity behind GNNs, while still offering great ﬂexibility to build custom GNN architectures. To showcase the versatility and performance of this framework, we implement two state-of-theart GNN models applied to different networking use cases. Our results show that the GNN models produced by IGNNITION are equivalent in terms of accuracy and performance to their native implementations in TensorFlow. Graph Neural Networks (GNN) [1] have recently become a hot topic among the Machine Learning (ML) community. The main novelty behind these models is their unique ability to learn and generalize over graph-structured information. This has enabled the development of groundbreaking applications in different ﬁelds where data is fundamentally represented as graphs (e.g., chemistry, physics, biology, recommender systems, social networks) [2]. The last few years have seen an increasing interest among the networking community to exploit the potential of GNN, as many fundamental networking problems involve the use of graphs (e.g., topology, routing). As such, we have already witnessed some successful GNN-based applications for networking (e.g., routing optimization [3], [4], virtual network function placement [5], resource allocation in wireless networks [6], job scheduling in data center networks [7]). In particular, GNN is the only ML technique that demonstrated the capability to effectively operate in other networks unseen during the training phase. This is thanks to the generalization power of GNNs over graphs which, in the networking ﬁeld, represents a cornerstone for the development of a new generation of ML-based solutions that can be trained in a controlled network testbed (e.g., at the vendor’s lab) and, once trained, be ready for deployment in any customer network (topologies of arbitrary size and structure), without the need for re-training on premises [3]. Nowadays, designing and implementing a GNN model involves dealing with complex mathematical formulation and using ML libraries with tensor-based programming, such as TensorFlow, or PyTorch. At the same time, GNN models for networking often rely on non-standard GNN architectures (e.g., heterogeneous graphs with sequential dependencies between different element types [3], [4]), which makes their implementation even more difﬁcult. This represents a critical entry barrier for network researchers and engineers that could beneﬁt from the use of GNN, but lack the necessary ML expertise to implement these models. In this article, we present IGNNITION, a TensorFlow-based framework for fast prototyping of GNNs (see Fig. 1). This framework is open source, and mainly targets networking experts and researchers with little background on neural network programming. With IGNNITION, users can easily design their own GNN models — even for the most complex network scenarios — via an intuitive, human-readable YAML ﬁle. Based on this input, the framework automatically generates an efﬁcient TensorFlow implementation of the GNN, without the need for writing a single line of TensorFlow code. To achieve this, we propose a high-level abstraction we call the Multi-Stage Message Passing graph (MSMP graph). This novel abstraction covers a broad deﬁnition of GNN, offering great ﬂexibility to design a wide variety of existing GNN variants, and generate new custom architectures combining individual components of them (e.g., messagepassing functions). Likewise, MSMP graphs enable to hide the complex mathematical formulation and the tensor-wise operations behind the implementation of GNNs. IGNNITION provides a YAML-based codeless interface that network engineers and practitioners can leverage to implement custom GNN models applied to networking. In this context, coding these types of models with general-purpose GNN libraries (e.g., [1], [8]–[12]) is arguably more complex for non experts in neural network programming, as they often require using lower-level abstractions, and some of these libraries even lack sufﬁcient ﬂexibility to implement nonstandard GNN architectures applied to networking [8], [11]. More in detail, IGNNITION offers the following main features: MSMP graphs and YAML ﬁles — that abstracts away both the mathematical formulation of the GNN and its implementation. variants and custom message-passing architectures via the novel MSMP graph abstraction. equivalent to native TensorFlow code, as performance is crucial for network applications. and enhanced visualizations of the implemented GNNs, to help network engineers troubleshoot their models. on the well-known NetworkX library, to feed GNN models with data from different sources and in various formats (e.g., network monitoring logs). to facilitate the implementation of non-standard features commonly used in GNN-based networking applications (e.g., support for heterogeneous graphs with possible sequential dependencies [3], [4]). As a result, with IGNNITION, network researchers and engineers with limited knowledge on neural network programming should be able to quickly produce a fully functional prototype of a GNN model tailored to a particular application. The input of a GNN is a graph, which comprises a set of nodes and edges connecting them. Each node v has an associated hidden state vector hof predeﬁned size that encodes its internal state. At the beginning of the GNN execution, hidden state vectors are initialized with some node-related features included in the input graph. After this, a message-passing algorithm is executed according to the connections of the input graph. This messagepassing process comprises three main phases (see Fig. 2): 1) Message exchange 2) Aggregation 3) Update First, each node sends a message to all its neighbors in the graph. This message is the result of combining the hidden states of the sender node hand the receiver neighbor h Fig. 2: Phases of a message-passing iteration: Message exchange, Aggregation, and Update through the so-called Message function (M). After this, each node aggregates all the messages collected from its neighbors into a single ﬁxed-size vector m(a.k.a., the aggregated message). To do this, nodes use a common Aggregation function (Aggr), which in standard GNNs is typically an element-wise summation over all the messages collected on the node. Lastly, each node applies an Update function (U ) that combines its own hidden state hwith the node’s aggregated message m. This message passing is repeated a number of iterations T , until the nodes’ hidden states hconverge to some ﬁxed values. After the message-passing phase, a Readout function is used to produce the output of the GNN model. This function takes as input the nodes’ hidden states and converts them into the ﬁnal predictions of the model. Note that the output of the Readout function can be either a set of global graph-level properties or speciﬁc node-level features. An essential aspect of GNN is that the internal functions that shape its architecture are modeled by neural networks (NN). Particularly, the Message, Update, and Readout functions are typically approximated by three independent NNs (e.g., feedforward NN, Recurrent NN). These NNs are then dynamically assembled within the GNN architecture according to the nodes and connections of the input graphs. During training, the aforementioned NNs (e.g., the Message NN) optimize jointly their internal parameters, effectively learning the target function from the perspective of each individual node in the graph. As a result, after training, the GNN is able to make accurate predictions on graphs with different sizes and structures not seen before. Note that beyond the generic GNN description provided in this section, there is a rich body of literature with different GNN architectural variants (e.g., Graph Convolutional Networks, Gated Neural Networks, Graph Attention Networks, Graph Recurrent Networks, GraphSAGE) [2], while all of them share the basic principle of an initial message-passing phase followed by a ﬁnal readout. We refer the reader to [1], [2] for more generic background on GNN. In the networking ﬁeld, GNN models need to be highly customized to accommodate speciﬁc networking use cases. Particularly, it is common to ﬁnd non-standard messagepassing architectures [3], [4], [6] that stem from the need to explicitly model the circular dependencies between various network elements, based on the actual behavior of real network infrastructures. As a result, state-of-the-art GNN models for networking often consider heterogeneous graphs as input Fig. 3: MSMP graphs — Generic example and RouteNet [3]. — with different element types (e.g., forwarding devices, links, paths) —, and custom message-passing deﬁnitions divided in multiple stages [3], [13], where in each stage a speciﬁc set of elements (e.g., paths) share their hidden states with some other elements (e.g., devices). Existing general-purpose GNN libraries offer high-level abstractions to simplify the implementation of custom GNN models. Among the most popular libraries, DGL [10] provides support for heterogeneous graphs, offering ﬂexibility to deﬁne GNNs with differentiated message, aggregation, and update functions for each element type of input graphs, as well as combining components from well-known GNN architectures (e.g., Graph Convolutional Networks, Graph Attention Networks). Likewise, PyTorch Geometric [9] provides preimplemented GNN layers that can be combined to create complex GNN architectures. However, the higher-level abstractions of these libraries do not provide direct support for implementing multi-stage message passing deﬁnitions, with ﬂexibility to deﬁne message exchanges between different element types at different execution stages, which is a common architectural framework among state-of-the-art GNN models for networking [3], [13]. This eventually requires the use of lower-level abstractions to implement these types of models. In light of the above, IGNNITION introduces a novel high-level abstraction called the Multi-Stage Message Passing graph (MSMP graph), which is carefully designed to facilitate the implementation of GNN models applied to networking. With MSMP graphs, users can deﬁne their custom GNN architectures through a visual graph representation, abstracting them from the complex mathematical formulation behind their designs.Particularly, a GNN can be deﬁned by a set of element types (hereafter, graph entities) and how they relate to each other in a sequential order, allowing the deﬁnition of multistage message passing schemes in a natural and intuitive way. Figure 3 (left) illustrates a generic example of an MSMP graph with three graph entities (e1, e2 and e3). In this scheme, two message-passing stages can be differentiated: First, elements of type e1 and e2 send their hidden states to their neighbors of type e3, according to their connections in the input graph. Then, in a second stage e3 elements share their states with their linked elements of type e1 and e2. Likewise, Figure 3 (right) depicts the MSMP graph of RouteNet [3]. In this case, the GNN model considers two graph entities (links and paths), and implements a two-stage message-passing scheme that explicitly represent the circular dependencies between these two entities. The implementation of the Message, Aggregation, Update, and Readout functions is later deﬁned by the user via an intuitive model description ﬁle in YAML, as described in the next section of this article. An MSMP graph description eventually describes a message-passing iteration of the GNN. Then, IGNNITION automatically unrolls this deﬁnition a number of iterations T deﬁned by the user. At the same time, the MSMP graph abstraction offers a ﬂexible modular design, which supports a wide range of existing GNN variants (e.g., Message-Passing NNs, Graph Convolutional Networks, Gated NNs, Graph Attention Networks, Graph Recurrent Networks) [2], as well as custom combinations with individual components of them (e.g., message, aggregation, update, normalization). To the best of our knowledge, this abstraction supports all the state-of-the-art GNN models applied to networking at the time of this writing. This section provides an overview of IGNNITION. In particular, we describe below the four main building blocks that shape this framework: 1) Model Description Interface 2) Dataset Interface 3) Core Engine 4) Debugging Assistant The ﬁrst step to build a GNN with IGNNITION is to describe the model architecture using the MSMP graph abstraction, introduced in the previous section. This can be done through a codeless interface, by ﬁlling a short YAML ﬁle. More speciﬁcally, this ﬁle contains the following information: Entities Deﬁnition: First, the user deﬁnes the different entities (i.e., element types) to consider in the networking scenario and, consequently, in the corresponding MSMP graph. In the networking context, an entity represents a set of network elements, which can be physical (e.g., routers, links), or logical (e.g., paths, virtual network functions). As an example, Fig. 4 shows the deﬁnition of an entity in the YAML model description ﬁle. There, the user indicates the entity name (e.g., path), the size of the hidden state vectors (e.g., 32 elements), and the method and features used to initialize these vectors. The initialization can be deﬁned as a ﬂexible pipeline of operations that supports elaborate methods used in state-ofthe-art models (e.g., normalization, initial feature embedding). Feature names (e.g., trafﬁc) are used as unique identiﬁers to then feed the model with any input dataset, as shown later in this section. Message Passing: After deﬁning the entities, the user completes the MSMP graph by describing the message-passing operations in the GNN model. These are based on the relationships between the graph entities previously deﬁned. To do so, the user deﬁnes a single message-passing iteration, which can be divided into multiple stages. In each stage, a set of entities share their hidden states with other speciﬁc entities, thus offering ﬂexibility to deﬁne the source and destination entities participating in each message-passing stage. For example, in the generic MSMP graph of Fig. 3 (left), the message passing is divided in two stages. In the ﬁrst one, Fig. 4: Example of a YAML model description ﬁle. the following message exchanges are executed: e1→e3, and e2→e3; while the second stage performs the reverse messagepassing operations: e3→e1, and e3→e2. In the model description ﬁle, this can be deﬁned as a series of YAML objects describing the several stages. For each stage, the user deﬁnes the names of the source and destination entities, and the Message, Aggregation and Update functions to be applied. IGNNITION provides great ﬂexibility to implement these functions, using any type of NN (e.g., multilayer perceptron, recurrent, convolutional), or other operations such as element-wise sum, average, max, min, product, or even direct variable assignments, which are often used in state-of-the-art GNN models for networking [3], [13]. A full description of all the options available can be found at [14]. As an example, Fig. 4 shows the deﬁnition of Stage 1 in the message passing of RouteNet [3] (see the corresponding MSMP graph in Fig. 3-right). Note that, in case of using NNs (e.g., in the Update function), the user can deﬁne a name (e.g., recurrent 1) that is then used to describe the NN details in a separate section of the ﬁle, as detailed later in this section. Readout: After the message passing, the user deﬁnes the Readout function, producing either per-node or global graphlevel outputs. In IGNNITION, the Readout is deﬁned via a ﬂexible pipeline of instructions that may combine pooling operations, neural networks, and other less common operations used in state-of-the-art GNN models applied to networking. Pooling operations (e.g., element-wise sum, mean) transform a variable-size set of nodes’ hidden states into a single ﬁxed-size embedding vector, which is often used to make global graphlevel predictions. Likewise, neural network operations take as input nodes’ hidden states — or the embeddings resulting from previous operations — and pass them through a NN. More information about the Readout deﬁnition can be found at [14]. Neural Networks Deﬁnition: Lastly, the user can deﬁne all the neural networks previously referenced in a separate section (e.g., Message, Update, Readout NNs). For this purpose, IGNNITION supports all the native functions of the wellknown Keras library [15]. Thus, to deﬁne for instance a multilayer perceptron, the user should specify in the YAML ﬁle at least the ﬁelds required by Keras, which are the number and type of layers and some basic parameters (e.g., neurons per layer). For other undeﬁned parameters, IGNNITION uses the Keras default values, thus considerably simplifying the deﬁnition of the NN. This YAML-based interface provides ﬂexibility to implement any NN as long as it is supported by Keras, which is widely considered as one of the most complete low-level NN programming libraries. The Dataset Interface is intended to decouple the GNN model description from the input data. Similar to other GNN libraries, such as DGL [10] or PyTorch Geometric [9], IGNNITION enables to directly process data with the well-known NetworkX library. This Python library already implements a plethora of functions that automatize the deﬁnition of graphs from datasets, which enables to easily feed the GNN model with datasets from different sources and in various formats (e.g., NetFlow/IPFIX measurement reports, router conﬁguration logs). This module implements the main logic behind IGNNITION. Once the model has been designed and the datasets have been properly formatted — as explained above — the user can call different functionalities from the Core Engine: ging purposes) The Core Engine internally implements a generic deﬁnition of the MSMP graph abstraction, thus covering the broad spectrum of GNN architectures supported by such abstraction. To generate the model implementation, the Core Engine proceeds in a similar way to traditional compilers, ﬁrst performing a lexical analysis, then a syntactical analysis, and ﬁnally a semantic analysis. These three steps enable to detect unexpected structures in the model deﬁnition (in YAML ﬁles) and trigger numerous error-checking messages to help users debug their models. After validating all the input information, IGNNITION automatically generates the GNN model implementation directly in TensorFlow. This enables to work internally with the efﬁcient computational graph produced by this ML library. As a result, IGNNITION implementations have comparable performance to models directly coded in TensorFlow, as shown later in the evaluation of this article. One of the biggest challenges when designing a GNN model with traditional ML libraries is to identify potential bugs and ﬁx them. Typically, having a clear picture of the resulting GNN model is a cumbersome and time-consuming task. For this reason, IGNNITION incorporates an advanced debugging system that assists the user in different ways. First, it automatically produces an interactive visual representation of the internal GNN architecture. To this end, it relies on Tensorboard — a TensorFlow-based visualization toolkit — allowing the user to dynamically visualize its GNN model at different levels of granularity. Standard visualizations of TensorBoard show the resulting computational graph of the model. However, it is difﬁcult to identify the different building blocks of the GNN from the tensor operations shown in this graph (e.g., message, aggregation, update functions, messagepassing iterations). IGNNITION implements a layer on top of this computational graph (using scope variables) that differentiates the main building blocks of the GNN at different levels of hierarchy, which makes it easier to identify the internal functions. For example, after implementing RouteNet [3] with IGNNITION the user can navigate through the resulting TensorBoard graph and easily identify the two message-passing stages of this model (see Fig. 3-right): links→paths, and paths→links. Moreover, by zooming in on the visualization, the user can easily ﬁnd the internal functions and how they are implemented (e.g., Message, Aggregation, Update). Additionally, the debugging assistant incorporates several advanced error-checking mechanisms to ensure the correct deﬁnition of the model and to provide guidance to ﬁx badly deﬁned ﬁelds in YAML ﬁles (e.g., wrong NN descriptions, entities deﬁnitions, missing features in the datasets). GNNs have been successfully applied to a plethora of networking use cases, such as routing optimization [3], [4], virtual network function placement [5], resource allocation in wireless networks [6], job scheduling in data center networks [7], MPLS conﬁguration, or Multipath TCP. A more comprehensive list of relevant GNN-based applications for communication networks can be found at [13]. Figure 5 illustrates the general workﬂow for producing with IGNNITION a GNN model adapted to a particular network problem. First, the user — e.g., a network engineer — needs to identify the main elements involved in the networking problem to be addressed (e.g., devices, links, apps, paths) and, according to the purpose of the GNN model (e.g., Trafﬁc Engineering), deﬁne potential dependencies between these different elements. In the networking context, we can often ﬁnd circular dependencies between different elements that can be naturally encoded in GNNs as a sequence of messagepassing stages. These elements and dependencies shape the input graphs of the GNN, thus deﬁning the structure of the samples in the train, validate and/or test datasets used for the model. Afterward, the user can deﬁne the architecture of the GNN. In IGNNITION, this can be done by ﬁlling the YAML model description ﬁle, leveraging the novel MSMP graph abstraction. Lastly, IGNNITION generates an efﬁcient implementation of the model in TensorFlow that can be trained with the generated datasets. As an example, we brieﬂy describe below how we can implement with IGNNITION two state-of-the-art GNN models that introduce some non-standard architectural patterns. Fig. 5: General workﬂow to produce GNN models for networking with IGNNITION. RouteNet [3] was proposed as a network modeling tool that predicts path-level performance metrics (e.g., delay, jitter) given a network state snapshot as input, which is deﬁned by: a network topology, a routing conﬁguration, and a trafﬁc matrix. This GNN is then used to optimize the routing conﬁguration in networks, by combining the model with an optimizer. To this end, RouteNet considers input graphs with two different entities (links and paths) that have circular dependencies between them, and encodes its input parameters as features within the initial hidden states of these elements. As a result, this GNN model implements a two-stage message-passing scheme combining the hidden states of these entities, which can be naturally deﬁned by an MSMP graph (see Fig. 3-right). Graph-Query Neural Network (GQNN) The GQNN model [4] addresses a different problem: supervised learning of traditional routing protocols with GNN, such as shortest path or max-min routing. To this end, this GNN model uses a novel architecture with two graph entities: routers and interfaces, being the latter the several network interfaces of each router in the network. This model considers a single-stage message-passing scheme where routers and interfaces share their hidden states simultaneously. As output, it determines whether the interfaces are used to transmit trafﬁc or not (i.e., [0,1]), which eventually deﬁnes the routing conﬁguration of the network. GQNN introduces a particularity in the Readout deﬁnition, which uses a non-standard operation pipeline with an element-wise product and then a NN to produce the ﬁnal prediction. With IGNNTION, this can be easily deﬁned in the YAML model description ﬁle as a pipeline with a product operation and then a NN function. For more information on how to implement a GNN prototype with IGNNITION, we refer the reader to [14]. There, the user can ﬁnd an easy-to-follow quick-start tutorial, where a basic GNN model is built to compute the shortest path routing conﬁguration given a network topology with weights on links. Also, IGNNITION includes a library with state-ofthe-art GNN models applied to different networking use cases, which is under continuous development by the community of this open-source project. As mentioned earlier, IGNNITION internally implements GNN models in TensorFlow, thus leveraging the efﬁcient computational graphs produced by this ML library. This section aims to showcase this aspect by making a direct comparison of IGNNITION implementations with respect to implementations directly coded in TensorFlow. As an example, we consider the two state-of-the-art GNN models described in the previous section (RouteNet and GQNN). For the evaluation, we use the implementations of these models in IGNNITION — publicly available at [14] — and, as a reference, their native implementations in TensorFlow, and reproduce some of the experiments made in their corresponding papers [3], [4]. Note that IGNNITION does not provide additional compiling optimizations. Instead, in the evaluation we reproduce the same scheme used in the original TensorFlow implementation. We use the datasets of the original evaluations of RouteNet, and GQNN (with 300,000, and 40,000 samples respectively), where 80 percent of the samples are randomly selected for training and 20 percent for evaluation. We ﬁrst evaluate the accuracy achieved by the models, to check that both implementations achieve the same results under equal training conditions. Our experimental results show that the IGNNITION implementation of RouteNet yields a Mean Relative Error of 2.62 percent, and the implementation of GQNN an accuracy of 98.07 percent. Both numbers are in line with the results obtained by the original TensorFlow implementations. Likewise, we evaluate the execution cost of both types of implementations. Figure 6 depicts the average execution time per sample during training and inference. In line with the previous results, we can observe that the execution times of IGNNITION implementations are equivalent to those of the original models implemented in TensorFlow. Note that all these experiments were made in a controlled testbed, considering the same computing resources for all cases. These results reveal the capability of IGNNITION to produce efﬁcient GNN models, while offering substantial time savings for non-ML experts to implement them. Moreover, users can leverage additional functionalities such as the visual representations of the debugging system and the advanced error-checking mechanisms to easily ﬁx potential bugs. Several GNN libraries have emerged in recent years, motivated by the outstanding applications of GNNs to a plethora of relevant real-world problems. Among the most popular opensource libraries, we can ﬁnd: DGL [10], PyTorch Geometric [9], or Graph Nets [1]. Also, NeuGraph [12] has recently become a popular GNN library that focuses on parallelizing the execution of GNN models, although it is not open source. These libraries provide high-level abstractions to code standard GNN layers (e.g., Graph Convolutional Networks, Graph Attention Networks) that can be concatenated. However, these higher-level abstractions do not provide direct support for implementing multi-stage message passing iterations, where in each stage speciﬁc graph entities share their hidden states Fig. 6: Evaluation of the execution time of IGNNNITION vs. native TensorFlow implementations (training and inference). with some other entities, which is a common architectural pattern for modeling circular dependencies in GNN models for networking [3], [13]. As an example, DGL provides several built-in functionalities to deal with heterogeneous graphs. Nevertheless, these functionalities do not handle directly the implementation of message-passing deﬁnitions where different graph entities share their hidden states sequentially. As a result, it is eventually needed to use lower-level abstractions to implement these types of models. Lastly, some other popular libraries, such as GraphGym [8] or Spektral [11], provide higher-level abstractions compared to the previous libraries. However, these libraries do not support many non-standard GNN architectures used in networking (e.g., [3], [4]). In contrast, IGNNITION provides a codeless interface that users can leverage to easily implement GNN prototypes. This interface is based on the novel MSMP graph abstraction proposed along with this framework, which is inspired by the architectural patterns commonly used in GNN models for networking. In particular, this abstraction naturally introduces the deﬁnition of non-standard message-passing architectures considering heterogeneous graphs with sequential dependencies between different sets of elements. In this article, we have introduced IGNNITION, an opensource framework based on TensorFlow that enables fast prototyping of Graph Neural Networks for networking applications. IGNNITION works over a novel high-level abstraction called the Multi-Stage Message Passing graph (MSMP graph), which isolates users from the complex mathematical formulation and implementation in traditional ML libraries (e.g., TensorFlow, PyTorch). MSMP graphs are ﬂexible enough to support state-of-the-art GNN architectures with non-standard messagepassing strategies. We implemented with IGNNITION two state-of-the-art GNNs for networking, to showcase the versatility of this framework. Likewise, we validated that the performance of the GNN models produced by IGNNITION is equivalent to that of native TensorFlow implementations, as efﬁciency is a must for networking applications. This open-source project has received funding from the European Union’s Horizon 2020 research and innovation programme within the framework of the NGI-POINTER Project funded under grant agreement No. 871528. This article reﬂects only the author’s view; the European Commission is not responsible for any use that may be made of the information it contains. The work was also supported by the Spanish MINECO under contract TEC2017-90034-C2-1R (ALLIANCE) and the Catalan Institution for Research and Advanced Studies (ICREA).