Trip recommendation is a signiﬁcant and engaging locationbased service that can help new tourists make more customized travel plans. It often attempts to suggest a sequence of points of interest (POIs) for a user who requests a personalized travel demand. Conventional methods either leverage the heuristic algorithms (e.g., dynamic programming) or statistical analysis (e.g., Markov models) to search or rank a POI sequence. These procedures may fail to capture the diversity of human needs and transitional regularities. They even provide recommendations that deviate from tourists’ real travel intention when the trip data is sparse. Although recent deep recursive models (e.g., RNN) are capable of alleviating these concerns, existing solutions hardly recognize the practical reality, such as the diversity of tourist demands, uncertainties in the t r ip generation, and the complex visiting preference. Inspired by the advance in deep learning, we introduce a novel self-supervised representation learning framework for trip recommendation – SelfTrip, aiming at tackling the aforementioned challenges. Speciﬁcally, we propose a two-step contrastive learning mechanism concerning the POI representation, as well as trip representation. Furthermore, we present four trip augmentation methods to capture the visiting uncertainties in trip planning. We evaluate our SelfTrip on four real-world datasets, and extensive results demonstrate the promising gain compared with several cutting-edge benchmarks, e.g., up to 4% and 10% improvements on Osaka regarding Fand pair-F. The ubiquitousness of GPS-integrated mobile devices and the wide use of location-based services have enabled the generation of massive volumes of geo-tagged data, which offers unprecedented opportu nities to explore huma n m oving intentions and corresp ondingly conduct various downstream location-based applications, e.g. POI recommendation (Yu et al. 2020), friend recommendation (Wu et al. 2019), trajectory classiﬁcation (Gao et al. 2017), and trip recommendation (He, Qi, and Ramamohanarao 2019), to name a few. Especially, trip r ecommendation (a.k.a, itinerary recommendation) has drawn widespread attention from researchers and practitioners in recent years, aiming at suggesting a sequence of point-of-interests (POIs) while meet- Corresponding Author(qianggao@swufe.edu.cn). Preprint ing a set of user-provided constraints (e.g., starting and end ing points, the number of POIs to be visited). Trip recommendation is signiﬁcantly different from traditio nal route planning in that the latter is usually to search for the shortest or a minimum cost-based route. In contrast, trip recommen dation takes more into consideration the diversity and personalized needs of a POI sequence, which is also not constrained by the road network (Wang, Wu, and Zhao 2021). Therefore, trip recommendation is a mor e challenging task in location-based recommendation services. A conventional solution for tr ip recommendation is to employ an orienteering-based method to maximize the user-speciﬁc query constraints, which is inspired by the navigation operation. Speciﬁcally it mines and incorporates prior knowledge extracted from historical trips (e.g., the attractiveness of POIs and POI categories) to offer a sequence of POIs via POI generation (Lim et al. 2015; Chen, Ong, and Xie 2016; Taylor, Lim, and Chan 2018). For example, (He, Qi, and Ramamohanarao 2019) uses an integer linear programming to explore the exact optimal trips. However, heuristic solution s usually either rely on the local tr a nsitional distribution between POIs or only pursue the shortest time budget, leading to the failure in resp ect of estimating the conditional distribution of human transition regularity, considering the d iversity of human demands, and exploiting the high-ordered relations. Complement to these, human mobility actually conta ins m a ny explicit a nd implicit characteristics, e.g, the semantic proximity of POIs and the spatial-temporal dependencies. In this aspect, another solution was to leverage deep representation learning methods to explore the nature of human character istics, e.g, contextaware POI embedding (He, Qi, and Ramamohanarao 2019; Ho and Lim 2021) a nd recursive trip modeling (Zhou et al. 2020a; Ho and Lim 2021; Gao et al. 2021). Under real datasets, they have empirically demonstrated superior performance over traditional methods, which inspires us to tap the charm of deep representation lear ning to be competent for trip recommendation. However, trip recommendatio n is still facing several challenges, including: (1) The heterogeneity of user demands: Due to the diversity of travel plans requested by users, it is impossible for us to pe rceive or grasp the needs of all users. The reality is often that we only observe p artial q uery records and their corresponding trips. (2) The uncertainty in trips: Although we can provide tourists with a deﬁnite travel route according to a given query, it is difﬁcult f or us to understand user’s underlying true travel preference based on a small amount of available trip data, as well as the he terogen e ity of individual preferen ces, which brings the risk of uncertainty dur ing trip recommendation. (3) The complex visiting patterns: Due to the data sparsity issue, it is intricate to explore the higher-ordered transitional regularities, especially the long-term dependencies. Recent self-supervised learning tech niques, e.g., contrastive lear ning, have achieved considerab le success for deep representation learning in natural language processing, computer vision, and recommender systems (Liu et al. 2021). They are capable of discovering implicit supervised signals together with mu ltiple versions of data augmentation strategies for promoting representation learning. Motivated by this, we propose a novel self-supervised framework, namely SelfTrip (Self-supervised Representation Learning for Trip Recommendation), to remedy the aforem e ntioned concerns. In our SelfTrip, we design a novel POI representation learning mod ule based on contrastive learning, where a causal random walk strategy is proposed to enrich the diversity of query demands. To alleviate the uncertainties in trip data, we leverage four trip data augmentation methods to stimulate human travel behaviors, whereafte r a contrastive trip presentation learning module is proposed. Finally, we model the trip data with a conditional (query-based) recursive m odule for trip generation, where a destination-enabled supervised signal regarding the trip destination is incorporated to constrain POI generation bias. In summary, our work make the following contributions: • To the best of our knowledge, SelfTrip is a mong the ﬁrst framework to respectively improve the representation of POI and human mobility with two contrastive lear ning schemes. • We investigate the complex interactions between queries and potentially visiting POIs on a huge query-based POI sequence set. Accordingly, the self-su pervised POI learning is proposed to formulate the context-aware POI representation. • We design four data augm e ntation strategies to mimic human travel behaviors based on th e sparse trip data. In the sequel, we present a self-supervised trip learning to enhance the tr ip inference, where we also inco rporate a destination-enabled supervised signal to constrain the POI prediction. • Experimental results co nducted on four r e al-world datasets demonstrate that our SelfTrip signiﬁcan tly outperforms several cutting-e dge benchmark s. In this section, we introduce basic d e ﬁnitions an d the problem formulation. We also present the contrastive loss used later in our SelfTrip. Deﬁnition 1: Trip. Let L denote a set of POIs and T re present a set of historical trips. Without loss of generality, we use a triplet l :< id, lo, la > to represent a POI l ∈ L, where id, lo and la represent the POI id, longitude and latitude, respectively. Formally, a trip is a POI sequence ordered by chec k-in time, e .g., < l, t>→< l, t>→ · · · →< l, t>, where < l, t> denotes a POI lin a trip was visited at time t. Deﬁnition 2: Query. In this study, a query q is a quintuple < l, t, l, t, N > that consists of the source POI l, starting tim e t, the destination POI l, ending time t, and the number of POIs N to visit. Trip Recommendation. Given historical trips T , the trip recommendation system can return a trip T = (l, l, · · · , l) if a tourist provides a query q :< l, t, l, t, N >, where l= land l= l. It can be formally described as follows: Contrastive Loss. As a widely used technique in selfsupervised learning, contrastive learning aims to construct positive samples and negative samples based on the original data, which makes similar samples closer in the projection space while dissimilar sam ples are relatively further away. Amon g which Noise Co ntrastive Estimation (NCE) becomes very popular in various applications ( Oord, Li, and Vinyals 2018; Yan et al. 20 21; Aitchison 2021). Its overall objective is d eﬁned as: where x refers to the ‘anchor’, xand xrespectively represent the positive and negative sample. g and J respectively denote the lea rning function (e.g., deep neural networks) and the number of negative samples. We turn to introduce our proposed SelfTrip. First, we present an overview of the architecture design, whereaf ter elaborating the POI learning and trip learning procedures. Finally, we describe the training details of SelfTrip. Figure 1: The overview of the SelfTrip framework. Architecture As Fig.1 shows, SelfTrip mainly contains two components: (I) Self-supervised PO I Learning aims to embed each POI into a low-dimensional space. This is an essential action fo r trip recommendation, which not only mitigates the problem of the curse of dimensionality but also is capable of exploring the semantic relationsh ips between queries and POIs. (II) Self-supervised Trip Learning ﬁrst formulates a context-aware query vector, and then randomly selects designed trip augmentation methods to generate variants of an original trip. Next we present a query-based GRU (Gated Recurrent Unit) as the basic encoder for contrastive learning. Besides, we use this encoder as the trip generator in the formal training process. Self-supervised POI Learning The intuitive idea of trip recomm endation is to use a qu ery provided by a user to search out a sequence of POIs, thus we expect to design such an embedding module that can preserve interac tions between the query and POIs as much as possible. However, it is not easy to full capture their interactions due to the scale of the training dataset and th e sparsity of query records. To this end, we ﬁrst construct a POI graph to describe the interactions among POIs. Then we adopt a simple interaction aug mentation strategy to integrate potential geographical preferences of tourists. To obtain more possible queries, we propose a novel query-ba sed sampling approach to p roduce mor e reasonable trips from the constructed POI graph. In the end, we present a contrastive POI learning method to learn possible interactions between queries and POIs. Augmented POI graph. To extract query-POI interactions, we transform historical trips into a basic POI g raph G(L, E), where E denotes a set of edg e s reﬂecting the successive visiting behaviors. To incorporate potential geographica l preferences of tourists, we collect each POI’s geographica l ne ighbors by setting a distance threshold, and correspond ingly building an edge between this POI and all of its ge ographical ne ighbors that are within this th reshold. To constrain the scale of neighbors, we set the distance threshold to 3 km. Finally, we obtain an augmented POI graph G(L, E), where E $ E. Causal Random Walks. Before we sample trips from G, we create a transition matrix A to describe the interaction probability between pairs of POIs (we actually refe r to such two POIs as the source POI and destination POI ) accor ding to G. More speciﬁcally, given any two nodes land l, (l∈ L, l∈ L), the transition probability from lto lis calculated by: Where fdenotes the frequency of edge l→ lappeared in E, and fis the frequency of lappeared in E. Thus, we ﬁnally ob ta in the transition matrix A corresponding to G(L, E). Next, we use the causal random walk strategy to generate a set of POI sequences based on Gand A. There exist L POIs in T , thereby we traverse all unique POI pairs (e.g., < l, l>) from the graph Gand obtain a set of query candidates Q = {< l, l> |i 6= j, l∈ L, l∈ L}. Actually, there exist at most |T | queries when and only wh e n the query of each trip in T is different, meanwhile, we usually confront |T | ≪ |Q| due to the shortage of training data. Thus, we use Gand A to generate M POI sequences correspond ing to each query candidate in Q, which enables to alleviate the lack of query records in given trip data. More speciﬁcally, given a query < l, l> (< l, l>∈ Q), we simulate a ran dom walk with a length budget α. Let ℓ= (κ ≥ 1) be the κth node in a walk, where w e set ℓ=l. Correspon dingly, node ℓis generated by the distribution P (ℓ|ℓ), wh e re P (ℓ|ℓ) ∈ A. Once ℓ= land κ ≤ α, we store the generated POI sequence {ℓ, ℓ, · · · , ℓ} and proceed to the next walk. If ℓ= lor κ ≥ α, we will drop the current POI sequence and proceed to the next walk directly. Th e reason we set a length budget α is that peo ple cannot have enough time to take a long trip or it is unrealistic to generate a long trip for the tourist to visit. Due to the constraint of α, the generated POI sequences will have different lengths, which, to some extent, allows us to cater to the real scenarios of visiting behaviors. In th e end, we will collect a larger set o f POI sequence S, and use it as the training set for the following POI representation learn ing. Contrative POI Learning. We now use the contrastive learning to train the POI repre sentation for capturing the potential interactions between queries and POIs. And we expect to maximize the similarity between a given query and the POI sample d in the same POI sequence while minimizing the similarity between a given query and the POI sampled from a different sequence. Given a POI sequence S= {l, l, · · · , l} sampled from S, we set up a learnable matrix v ∈ Ras the initial POI embeddings, where d denotes the embedding size. Next, we set las the source POI an d las the de stin a tion POI, and using a simple averaging operation to formulate a query representation q, where q=(v(l) + v(l)) (v∈ Rrefers to the le anable ma trix corresponding to user query). We regard qas the ‘anchor’ and randomly select a POI l in Sas the positive sample while random ly select a POI lfrom another sequence as the negative sample in which it is associated with a que ry that is distinct from q. For simplicity, let q denote the or iginal pair (l, l). Recall Eq.(2), we randomly sample k − 1 negative samples to cater to the training requirements o f contrastive learning, i.e., {l|l∈ S \ S}. Therefore, the objective for trip Sis: E[s (v(l), q) − logexp(sv(l), q)), where ‘\’ deﬁnes subtraction operation of set and s refers to the cosine function. Finally, we use the optimal v as the POI embeddings. Self-supervised Trip Learning In this section, we ﬁrst show how to formulate a dense query representation and trip representation. Then, we present four trip augmentation strategies for sparse trips and describe how to train our trip representation with contrastive learning. In the end, we introduce the tra ining mechanism of SelfTrip. Query Encoder. To accommodate the input of our SelfTrip, it is necessary to transform a given quer y q :< l, t, l, t, N > into a couple of dense representations. Hence, we ﬁrst encode the source POI and de stination POI in the query in to dense representations. Since we have trained the POI embeddings v from the above, we can directly use it to obtain the corresponding dense representations for l and l, whereas they can be deﬁned as v(l) and v(l). Inspired by previous work s on time information processing (Gao et al. 2021), an hour-level representation strategy is adopted to encode tand t, which splits the day into 24 discrete time intervals and uses simplest one-hot encoding method to represent the 24 hour-level intervals. For example, a tourist whose ending time tcan be represented as u(t) ∈ R, where dis the embedding dimension. Traditional methods usually use a simple concatenation operation to mingle those dense r e presentations into an uniﬁed vector to represent the given query q. To capture the interactions of l, t, l, and t, we design a transformed operation to obtain a ﬁnal representation for query q: q = LeakyRelu([v(l)ku(t)]([v(l)ku(t)]K) (5) Where k denotes the concatenation operation, W∈ Ris a learnable matrix, b∈ Ris the bias, and K∈ Ris a third-order tensor. Trip Enco der. We now introduce how to model a given query q and its associated tr ip T by a query-based recurrent neu ral network. That is to say, we aim to incorporate the query information into the trip representa tion in a rec ursive manner. We ﬁrst obtain the context-aware q to represent the given q. For trip T = {l, l, · · · , l}, we transform each discrete POI to dense representation by looking up the optimized v, and obtain th e basic trip representation T = {v(l), v(l), · · · , v(l)}. Next, we employ the query-based GRU to capture the dependenc ies among the POIs in T . Taking l∈ T as an example, its hidden state can be formulated as: where f(·) denotes a dense layer. In the end, we can obtain the hidden state of each POI, i. e., h, · · · , h. Trip Augmentation. As a prerequisite, trip representation with self-supervised learning needs to set multi-views of real training trips as the positive samples. Inspired by recent contrastive text generation (Yan et al. 2021) and contrastive item augmen ta tion (Zhou et al. 2020b). We present four strategies for trip data augmentation which aims to mimic the human real visiting behaviors. They are: • POI Mask. It is a simple but realistic strategy. For instance, the tourist Bob would choose some of POIs to visit although we provide him a longer trip. T hus, we randomly mask some POIs in a given POI sequence to generate a new trip. • Shufﬂing. Although we provide the tourist with a possible itine rary, he/she may chan ge their v isiting plan during tr avelling due to the personal interests. For instance, SelfTrip provides an itinerary < A, B, C > for tourist Bob, when Bob prepares to visit B after visiting A, he may decide to visit C ﬁrst because he considers C more attractive to him or C is an urgent need. To simulate the realistic human moving intention, we change the order of a given sequence of POIs to form a new trip a nd add it to our training set. • Feature Cutoff. Since we use the dense repre sentation to tackle the discrete POI or trip, the feature cutoff attempts to erase so me feature dimensions to generate an augmentation view of input data. To be speciﬁc, it only applies to the POI embeddings before we model trip learning. • Dropout. Dropout is a widely used approach to alleviate the over-ﬁtting issue during neural network m odeling (Hinton et al. 2012). Hence, we use it to randomly drop part of values out in each POI embedding by a certain probab ility (e.g., the dropout rate is 0.5) and set each correspo nding value to zero. To accommodate the following contrastive trip learning, we feed each trip T in T in to the augmentation layer and randomly select two strategies for augmentation. For example, using the augmentation layer to generate two views of T, Contrastive Tr ip Learning. Notably, using larger minibatch is a common method for contra stive learning, we thus choose m queries {q}and their corre sponding trips {T}from the training set to satisfy the requirement of mini-batch. Next, we use trip augmentation layer to generate the augmented trip set {ˆT}and {ˆT}, whe re each Tis associated withˆTandˆT. Correspondingly, we can obtain the context-aware query set {q}by Eq. (5). As for augmented trips, we use the Trip Encod er to obta in the hidden states of these trips, and employ the ﬁnal state of each augmented trip as input of contrastive learning. For instance, we respec tively use hand hto represent the ﬁnal states ofˆTandˆT, and use them to rep resent these two trips, denoted by˜Tand˜Tfor consistency. Similarly, we can formulate the dense representations o f other augmen ted trips, denoted by {˜T}and {˜T}. Now, we can treat any <˜T,˜T> as the positive pair, while r egarding the remain (m − 1) pairs as the negative. Thus, the objective regarding Tcan be deﬁned as: In practical implemen tation, we c a n train the trips {T} in a parallel manner by: where I is the identity matrix (den oting the elem ents in diagonal are positive scores while others are negative scores) and ⊙ denotes the element-wise Hadamard pro duct. In the end, the overall loss function is: In the sequel, we will use the warmed-up Q uery Encoder and Trip Encoder for the following formal tra ining. Formal Training We have used the self-supervised learning to embed each discrete POI to a low-dimensional vector, where the correlations among the query and POIs are incorporated. And we also used the self-supervised learning to pre-train model with contrastive loss. Now we turn towards using the warmed-up model for supervised trip tra ining. Recall the objective of Eq.(1), SelfTrip is to generate the tr ip in a recursive manner as follows: ˜l= GRU([v(l)kf(q)], h)W+ b where Wand bare the lea rnable parameters. Traditionally, we can form the ﬁnal objective as: where θ refers to the parameters in SelfTrip. However, trip recommendation is signiﬁcantly different from tradition al trajectory prediction tasks in that the latter works in a multiround next POI generation manner (Zhou et al. 2019). Actually, we usually neglect a supervised signal that each predicted POI is also constrained by the destina tion. Although such a constraint or interaction is unknown, we attempt to use a simple neural n etwork (i.e., fully connected neural ne twork) to stimulate such unknown interaction between the predicted POI and the destination. As Fig. 2 shows, we involve a destination-oriented signal to constrain the trip generation during the model train ing process. For a given query q :< l, t, l, t, N >, we assume that we have obtained a current hidden state h. The n we use a one-layer fully connected neural network to build the relationship between h and the destination by: where Wand brefer to the learnable parameters. Thus, we rewrite the Eq.(11) as: L(θ, γ) = L(θ) + L where γ refers to Wand b. Notably, the length N in query q will be considered as recursive rounds. We conduct experiments on four real-world datasets to demonstra te the effectiveness of our SelfTrip. In detail, we ﬁrst introdu c e the datasets, benchmarking algorithms and evaluation metrics, followed by the model settings. Then, we present our results including overall performance comparison, the perf ormance of individual module, study of query and trip augmentation, and p a rameter sensitivity. Datasets. As Table 1 shows, we use four real-world trip datasets, including Toronto, Osaka, Glasgow, and Edinburgh, from Flickr as our experimental data, wh ic h have been widely used in prior stu dies (Chen, Ong, and Xie 2016; He, Qi, and Ramamohanarao 2019; Gao et al. 2021). To improve the quality of data, we do some regular data prepossessing, including ﬁltering out short trajectories which contain less than th ree POIs, normalizing the timestamp into hour-level (i.e., mapping each timestamp into 24 intervals). Following (Chen, Ong, and Xie 2016; He, Qi, and Ramamohanarao 2019; Gao et al. 2021), we also adopt leave-one-ou t c ross validation to evaluate all methods. Benchmarks. We compa re our SelfTrip with several recently developed representation learning-based methods, including: • Ma rkov (Chen, Ong, and Xie 2016): It is a common and intuitive method where a POI tr ansition matrix is constructed to recommend a trajectory. • POIRank (Chen, Ong, and Xie 2016): It recommend s a trajectory by ﬁrst ranking POIs via a RankSVM method, and then connecting them based on their ranking scores. • Ma rkov-Rank (Chen, Ong, and Xie 2016): It constructs a POI transition matrix, and recommends a trajectory based on Markov transitions and POI ranking. • CATHI (Zhou et al. 2019): It is a recurrent neural network-based trajectory plann ing method in an end-toend manner. We leverage an encoder to mo del the given query and use the decoder for trip recommendation. • C-ILP (He, Qi, and Ramamohanarao 2019): It uses word2vec-based method to learn context-aware POI rep resentation, followed by in teger linear programming (ILP) for trip generation. • DeepTrip (Gao et al. 2021): It is an end-to-en d trip recommendation method, while using a GAN-style neural network to approximate the similarity betwe en the query and the trip. • NASR+ (Wang, Wu, and Zhao 2021): It is a deep neural network-based A* algorithm for route planning constrained by the road n etwork. Since the check-in data is not constrained by the road network, we only use its RNN module enhanced by the attention mechanism for a fair compariso n. Metrics. For performan ce compariso n among all methods, we follow prior studies (Lim et al. 2015; He, Qi, and Ramamohanarao 2019) to use two wellestablished metrics: (i) Fscore to measure the quality of a recommen ded sequence – which is, the harmonic mean of Prec isio n and Recall of elements in a sequence; (ii) pairs-Fscore (Chen, Ong, and Xie 2016; Gao e t al. 2021), considers both POI correctness and sequential order by calculating the Fscore of every pair of POIs, whether they are adjacent or not in a traje c tory. Notably, the values of both pairs-Fand Fare between 0 and 1. The higher the value, the better the recommended results, e.g., a value of 1 means that both POIs and their visiting order in the recommended trajectory are exactly the same as the g round truth. Experimental Settings. We reproduce the benchmarks and implement our SelfTrip in Python while deep learning methods are acce le rated by one NIVDIA RTX 3090 GPU. As for our SelfTrip, length budge t α is 6, the batch size is 8, the dimensionality of POI is 250, the initial learning ra te is 0.1, the hidden size in contrastive trip representation is 256, and the optimizer is Adam (Kingma and Ba 2014). Results Overall Performance. Table 2 shows the performance compariso n of our SelfTrip with several representative benchm arks. Note that we use the bold font to hig hlight the best performance. Generally, our SelfTrip signiﬁcantly outperforms all benchmarks across four datasets, with an average imp rovement of 2.03%, 6.85% over the best benchmark with respect to Fand pairs-F, respectively. Among the benchmarks including Markov, POIRank and MarkovRank, the results demonstrate that investigating explicit knowledge, e.g., the human transition regularity an d POI co-occurrences, do help in understanding human mobility. However, those methods that either statistically model POI transitions with Markov chain or learn a ranking of POI s with traditional machine le a rning methods (e.g., RankSVM) cannot automatically explore more complex mobility regularity and handle the data sparsity issue, resulting in an unsatisfactory performance for trip recommendation. In particular, they perform worse than these recent deep repre sentation learning-based methods, such as DeepTrip and NASR+. As for Self Trip, it performs the best, the plausible reason is that the trip augmentation can address the data sparsity problem and consider the heterogen eity of user demands during POI embedding and trip representation learning. Meanwhile, we investigate th e inherent interactions between que ries and POIs as the prerequisites for representation learning, which allows us to simulate possible human query demands and trip preference. Module Performance. To investigate the capability of POI learnin g, we co mpare our self-su pervised POI lear ning with four popular embedding metho ds, and they a re: (1) Random refers to the application of random matrix sampled from Gaussian distribution for POI embeddings; (2) Deepwalk (Perozzi, Al-Rfou, and Skiena 2014) uses random walk method to gener ate the POI sequence s on POI graph, and leverages word2vec to formulate the POI embeddings; (3) GAE (Kipf and We lling 2016) utilizes the graph autoencoder to generate node (POI) embeddings; (4) VGAE (Kipf and Welling 2016) is a variant of GAE, integrating the variational Bayes mechanism. As Fig. 3(a) shows, we observe that our method signiﬁcantly outperforms these four embedding methods, and Dee pwalk achieves the second best. But Deepwalk is worse than SelfTrip because it only focuses on the surrounding context of a given POI. Note that we observe similar patterns for other datasets and omit to report due to the spa c e limitation. To explore the impac t of que ry encoder, contrastive trip learning and the destination-enable d supervised signal. We provide fou r variants of SelfTrip. The ﬁrst one is a base model which removes the above thre e parts an d uses a simple concate nation operation for query encoding, called SelfTrip-Base; the second one r e moves the contrastive learning c ompon ent in SelfTrip, namely SelfTrip-CL; the third one removes the destination-enabled supervised signal, called SelfTrip-WL, and the last one uses a simple concatenation operation for query encoding, called SelfTrip-Q. As Fig. 3(b) shows, SelfTrip performs the best. We ﬁnd that these three components do help promote performa nce gains, which further indicates that the sparsity of trip d ata, the p otential destination correlation and query context are important factors in trip recommendation. Impact of Augmentation. Query Augmentation. In this paper, we propose causal random walks to augm ent the query records. Whether such a method improves the recommendation performa nce is still a question, especially when the user provides a query demand that never appears before. To answer this question, we re-split e ach dataset to new training data ( about 80%) and new testing data (about 20%) wher e quer ie s in testing data do n ot app ear in the training data . As Table 3 shows, SelfTrip- denotes without using the augmented queries in SelfTrip. The results demonstrate that query augm entation signiﬁcantly achieves encouraging gains, especially for the Fscores regarding Osaka. Trip Augmentation. To evaluate the effect of trip augmentation methods, we empirically show the testing results with different c ouples of tr ip augmentation. As Fig 4 shows, each cell represents a different couple, where the diagonal means that we only use a single strategy and ‘ N one’ means we do not use any augmentation methods. We observe that single augmen ta tion method obtains the worse performance while dropout and POI mask are more efﬁcient in trip augm e ntation. Therefore, we will en deavor to choose more efﬁcient coupling and explore more augm e ntation methods for data augmen ta tion in the future. Sensitivity of Hyper-paramet ers. As Fig 5 shows, we investigate the sensitivity of some key hy per-parameters, e.g., hidden size and the number of negative samples in trip learning. Figure 5: Hyper-parameter tuning on Toronto. Trip Recommendation. Conventionally, one of the c ommon solutions for trip recommendation is using the simple heuristic models to understand the tra nsitional patterns of different POIs. Chen et al. prop osed a probabilistic method by mining the implied in formation (e.g., transitional matrix) from historical POIs and trips (Chen, Ong, and Xie 2016). Gu et al. investigated the attractive routes to make a trip recommendation c onsidering user experience, where a gravity model is leveraged to evaluate the rating score of ea c h attractive route (Gu et al. 2020). In addition to these, o ther existing works considered the trip recommendation as a variant of the orienteering problems (OP), maximizing the collected scores from the generated path (Taylor, Lim, and Chan 2018; He, Qi, and Ramamohanarao 2019). However, they are not good at estimating user diverse demands and historical travel preferences with the limit of data scale, resulting in the inability to learn the real distribution of human travel patterns. Recent researchers used deep repre sentation learning to explore complex relations fro m POIs and trips, such as semantic proximity of POIs and long-term dependencies in trips (He, Qi, and Ramamohanarao 2019; Ho and Lim 2021; Gao et al. 2021). He et al. and Ho et al. adopted the popular POI emb edding method for trip recommendation, modeling the probability distribution of the co-occurring POIs ( He, Qi, and Ramamohanarao 2019; Ho and Lim 2021). DeepTrip is a regularized latent variable method to understand human travel patterns, leveraging a trained model for trip recommendation (Gao et al. 2021). Although the success of deep representation learning, those methods only relied on historical trips, which still suffer the sparsity and insufﬁcient representation issues. In contrast, SelfTrip is a self-supervised fram ework with data augmentation that can better alleviate the sparsity of queries and trips. Self-supervised Representation Learning Recent selfsupervised learning, which has shown excellent performance in representation learning, brings a new opportunity to address the limit of labeled data scale due to its capability of avoiding the work of tagging large-scale datasets. And it generally can be categorized into two domains, i.e., generative-based and contrastive-based (Wu et al. 2020). For example, variational Bayesian and adversar ia l network attract numerous researchers’ attention since they can selftrain with the whole data without any label inf ormation. Generative-based methods h ave been widely applied in mobility-based tasks (Liu et al. 2020; Wang et al. 2019), including trip recommendation (Gao et al. 2021). However, generative-based approaches need to reconstruct accurate local details to learn sample features, while the emerging contrastive learning focuses on implicit multi-views of samples and con struct an addition a l contrastive loss to distill inherent informa tion fr om the data itself by mutual information m a ximization principle (He et al. 2020; Oo rd, Li, and Vinyals 2018; Xie et al. 2021). Although the emerging application of contrastive learning ha s been widely used in CV and NLP, our self-supervised learning framework is among the ﬁrst work to capture implicit supervised signals fro m both POIlevel and trip-level, which distinguishe s from previous studies. In this paper, we present a systematic self-supervised learning framework to train the POI repre sentation and trip representation for trip recommendation, where a novel model SelfTrip is proposed. We implement a self-supervised learning with data augmen tation including query au gmentation and trip augmentation to capture the inhe rent interactions between queries and trips. The empirica l results demonstrate that our SelfTrip achieves the best performance. Besides, our proposed self-supervised POI learning signiﬁcantly outperforms existing widely used embedding methods. In the future, we consider in c orporating other featu res (e.g., social characteristics) to explore human diverse preference.