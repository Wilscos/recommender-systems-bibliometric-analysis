Noname manuscript No. (will be inserted by the editor) Anthony Peruma · Steven Simmons · Eman Abdullah AlOmar · Christian D. Newman · Mohamed Wiem Mkaouer · Ali Ouni Abstract An essential part of software maintenance and evolution, refactoring is performed by developers, regardless of technology or domain, to improve the internal quality of the system, and reduce its technical debt. However, choosing the appropriate refactoring strategy is not always straightforward, resulting in developers seeking assistance. Although research in refactoring is well-established, with several studies altering between the detection of refactoring opportunities and the recommendation of appropriate code changes, little is known about their adoption in practice. Analyzing the perception of developers is critical to understand better what developers consider to be problematic in their code and how they handle it. Additionally, there is a need for bridging the gap between refactoring, as research, and its adoption in practice, by extracting common refactoring intents that are more suitable for what developers face in reality. In this study, we analyze refactoring discussions on Stack Overﬂow through a series of quantitative and qualitative experiments. Our results show that Stack Overﬂow is utilized by a diverse set of developers for refactoring assistance for a variety of technologies. Our observations show ﬁve areas that developers typically require help with refactoring– Code Optimization, Tools and IDEs, Architecture and Design Patterns, Unit Testing, and Database. We envision our ﬁndings better bridge the support between traditional (or academic) aspects of refactoring and their real-world applicability, including better tool support. Keywords Empirical Study · Software Maintenance and Evolution · Stack Overﬂow · Refactoring Refactoring is a disciplined technique and a fundamental activity in software development. From the most structurally simplistic task of renaming an identiﬁer to more complex structural changes such as extracting and moving a method, developers refactor their code to improve the internal quality of their systems while still preserving the system’s behavior [56]. According to its deﬁnition, refactoring is applied to enforce best design practices or to cope with design defects. Thus, academic research has been recommending refactoring to either ﬁx code and test smells (e.g., long methods, God classes, etc.) [55,63] or improve structural metrics (e.g., coupling, cohesion, cyclomatic complexity, etc.) [51,48]. However, recent surveys have shown the lack of adoption of refactoring tools in practice [71,62], in part due to the lack of support for the types of problems developers face when refactoring. One potential problem is that while refactorings tend to be applied alongside other development and maintenance tasks [76,30], automated refactoring tools do not fully take this aspect into account. In addition, this interleaving of actions indicates that there may be some relationship between refactoring and other development tasks, meaning that these other tasks are essential for comprehending the refactoring. Unfortunately, there is still a lack of thorough understanding of the rationale behind applying a refactoring or the problems developers face when determining which refactorings to apply and how to apply them in practice. on the examination of project artifacts such as commit logs (focusing mainly on a selected set of opensource projects) [80,77,27, 81] or interviewing a selected set of developers [62, 92]. However, interviews are a limited resource and may not fully generalize due to the necessarily limited number of people they gather information from. In addition, the natural language analysis of commit logs is not always a feasible approach because developers typically use high-level descriptions; rarely mentioning speciﬁc refactorings or project-speciﬁc reasoning for why changes have been made beyond high-level reasoning, such as improving readability/comprehension of the code, eliminating code/design smells, and ﬁxing defects [80, 81,71]. As a result, prior work has highlighted the challenges in correlating rationale obtained from various software artifacts with refactoring activities [80,81,71]. For instance, while we know that developers refactor to improve readability, it is still unclear how a developer identiﬁes a readability issue, how the developer plans to perform this improvement, and how we can accurately obtain this information from software artifacts that are updated in response to these changes. rationale behind refactoring; the most popular programming-speciﬁc question and answer forum on the internet, Stack Overﬂow, is one of them. With over 19 million questions [9] and one million users (as of January 2019) [18], Stack Overﬂow provides developers with a mechanism to seek advice and help from the community on a wide range of software development topics. Hence, through this study, we are presented with a diverse and representative view of developer discussions around refactoring; thereby, gaining a realworld understanding of not only the volume of discussions around refactoring but also the topics that are of most interest and challenging to developers. The ﬁeld of software refactoring research is continually evolving. For instance, the initial deﬁnition of refactoring indicates that the driver to refactor source code arises from the degradation of the internal quality of a system [67]. However, through empirical [28] and developer-based [92] studies, it is apparent that code smells may not be the only reason developers apply refactorings. Given that it is common for academic research to recommend refactoring based on the presence of code smells, there is a clear need for a stronger understanding of the other drivers of refactorings so that appropriate recommendations can be made in those contexts as well. Quote 1 is an example of a developer seeking help with a code change task that was caused as a consequence of several factors: high complexity metrics and poor readability. They found some advice pointing at the Strategy design pattern as a solution, but are unsure of whether it is overkill for this problem or not. In this context, several studies have proposed solutions to ﬁx brain methods or reduce cyclomatic complexity. However, little is known on how to address a problem that contains both of these characteristics. Therefore, there is a need to investigate techniques that can approach these types of issues holistically. Prior work has tried to ﬁll this gap by interviewing and surveying developers. However, these studies are still limited in how much they can tell us about the general population of developers. The question is: Are developers applying refactorings in the same environments, on problems with the same characteristics and context, as researchers assume? To answer this question, we need to understand refactoring as it is discussed in day-to-day development activities. Thus, we focus our attention on real-world challenges developers currently face when refactoring their systems. For instance, consider the example in Quote 2. The majority of refactoring-related research focuses on statically typed programming languages, such as Java. However, dynamically typed languages such as Python and other software artifacts such as databases and conﬁguration ﬁles may also need to be part of some refactorings, such as the rename refactoring. “My mission is to refactor a switch statement that was poorly written (it makes the cyclomatic complexity spike). In short, there is a class that parses a ﬁle for various values. I have read up on the topic and while there seems to be plenty of help, it all seems to be pointing at the Strategy design pattern, which (I believe) would overkill my problem. In my project, there are multiple classes like this, with some of them having upwards of 25 case statements.” Prior studies that have examined the rationale behind the application of refactoring activities relied There are other sources of information, besides commit messages and interviews, for understanding the “I have a bunch of classes I want to rename. Some of them have names that are small and that name is reused in other class names, where I don’t want that name changed. Most of this lives in Python code, but we also have some XML code that references class names... Does anyone have experience with Python refactoring tools ? Bonus points if they can ﬁx class names in the XML documents too.” Quote 2: An example of a refactoring challenge a developer faces when refactoring Python code. [21]. candidate to mine for real-world discussions around programming-related challenges. The diversity of the user base presents us with an opportunity to study what and how developers refactor their systems effectively. The content we mine from Stack Overﬂow will assist us in gauging the extent to which current research in refactoring is lacking and understand the reasons for gaps between the application of automated refactoring and the way developers perceive it [92]. Furthermore, as this study captures the state of realworld refactoring at this current point in time, it becomes an ideal candidate for future replication-based studies to determine the extent to which real-world refactoring has evolved, such as the technologies and challenges developers face when refactoring their systems. The goal of this study is to understand the trends and challenges around developer discussions on software refactoring concepts and activities. We envision our ﬁndings used as input by practitioners, researchers, and educators in understanding the current state of refactoring trends and challenges and determine the extent to which traditional (or academic) viewpoints of refactoring need revising based on real-world applicability. Additionally, IDE and tool vendors that oﬀer refactoring support will ﬁnd our results helpful in improving their instruments to better support developers. Hence, we ﬁrst start by examining the volume of refactoring posts and user contributions. Through this examination, we reveal how popular and valuable Stack Overﬂow is in the developer community in discussing refactoring topics. Once we establish this volume, our next task is to determine the topics of discussion. We achieve this in three steps by analyzing the natural language text in the body of a question. We ﬁrst identify common phrases; then, we look for speciﬁc refactoring terminology in the body. Finally, our third step is grouping similar questions based on the terms they utilize and then determining the category (or topic) of these groupings. The ﬁnal analysis of this study utilizes the identiﬁed categories to determine the type of questions that are challenging to answer. Thus, we deﬁne and address the following research questions: this research question, we gain insights into the growth in refactoring related discussions throughout the years. This question explores the volume of questions and answers on Stack Overﬂow, along with the community members responsible for creating these posts. Additionally, we examine the tags that accompany refactoring questions, which presents us with high-level information into the areas that involve refactoring. question utilizes natural language techniques to identify the key terms and phrases developers utilize in crafting refactoring questions. Our analysis presents a real-world and granular view of the problematic or challenging software refactoring areas developers require assistance. This research question presents us with the opportunity to understand the refactoring topics that are popular among developers and topics that are diﬃcult to answer on Stack Overﬂow. Additionally, we also examine unanswered questions. This study provides the community of researchers and practitioners with insights on the discussion of refactoring on Stack Overﬂow. More speciﬁcally, are contributions are outlined below: – Mining and extraction of 9,489 Stack Overﬂow questions related to refactoring. Quote 1: A developer runs into challenges trying to improve the quality metrics of the code. [14]. As one of the premier online question and answer resources for developers, Stack Overﬂow is an ideal RQ: How have refactoring discussions on Stack Overﬂow grown over the years? Through RQ: What do developers discuss in refactoring based Stack Overﬂow posts? This research RQ: Which topics are the most popular and diﬃcult among refactoring-related questions? – A series of quantitative and qualitative experiments on the extracted questions to show the growth and We also make available our dataset for replication and extension purposes [13]. Before discussing the research works related to our study, we ﬁrst present a brief overview of the state of research in the ﬁeld. Since developers discuss multiple aspects of refactoring on StackOverﬂow, we believe it is essential that readers comprehend the ﬁeld’s evolution to understand the extent to which academia address practical challenges developer face. The spectrum of research exploring the practice of refactoring covers a wide variety of dimensions. One of the earliest studies, by Mens and Tourwe [67], provides an overview of existing research in the ﬁeld of software refactoring. They discuss the existing literature in terms of refactoring activities and techniques, refactoring tool support, and the impact of refactoring on the software process. Further studies on refactoring focus on studying the impact of refactoring on quality (e.g., [70, 42,29,75,47,106]), identifying refactoring opportunities (e.g., [54,74]), recommending refactoring operations (e.g., [68,43,73]), and implementing refactoring tools (e.g., [84, 66,61,103,91,69]). to studies investigating the rationale and motivations of why developers refactor code or research into discussions around tools/technologies that developers rely on for refactoring code. To this extent, we group our set of related works into two groups. The ﬁrst group contains studies that mine Stack Overﬂow posts and report on refactoring-based discussions among developers. The second group of studies is based on developer interviews or analysis of project artifacts to understand developer refactorings. Pinto and Kamei [82] mine Stack Overﬂow posts to study discussions around refactoring tools. From a tool features perspective, the authors observe that developers prefer tools that provide refactoring recommendations and support for database and multi-language refactoring. Additionally, ﬁndings from this study show that in addition to usability issues, the lack of trust in tools is one of the major barriers to adoption. In their study on code smells and antipattern discussions on Stack Overﬂow, Tahir et al. [99] observe that the majority of answers to these questions did not provide refactoring recommendations; instead, the answers provide details around the code smell/antipattern. Furthermore, developers do not frequently refer to refactoring operations by name in the posts and refer to some design patterns as potential refactoring solutions. In a subsequent study [98], the authors performed a large-scale study that explores how developers discuss code smells and antipatterns in Stack Exchange. The authors show that most of the questions focus on the following code smells: Duplicated Code, Spaghetti Code, God Class, and Data Class. As for the programming languages, most of the discussions focus on popular languages like C#, JavaScript, and Java. Although Java has greater tooling support, other platforms such as C# and JavaScript are lacking in support. Findings by Tian et al. [102], from their study on architecture smells, show the lack of tools for refactoring architecture smells. The authors also highlight that even though there exist specialized tools to refactor architecture smells, these tools are not mentioned in the Stack Overﬂow posts; instead, developers mention the use of common code smell detection tools. Additionally, the authors also observe that time and costs involved with detecting and refactoring architecture are very concerning for most developers. In a preliminary study specializing in the refactoring of Java 8 streams for parallelization, Tang et al. mined Stack Overﬂow posts for discussions around Java 8 streams [100]. As part of their ﬁndings, the authors mention that 5% of questions around Java 8 streams remain unanswered. A preliminary study by Choi et al. [49] on code clones shows that most discussions are related to refactoring with the need for more support for clone refactoring tools. Openja et al. [72] utilize topic modeling to study release engineering questions. More speciﬁcally, the authors examine popular topics among developers and those that are diﬃcult to answer. In this study, the authors identify 38 topics from which questions around security are both challenging and popular. trends of refactoring discussions between developers, such as: – The frequently occurring set of tags and terminology in questions, which also include an analysis of the use of refactoring speciﬁc terminology. – The primary topics for refactoring questions, including the popular and challenging topics, along with an analysis of unanswered questions. As our study is around developer discussions on refactoring, our discussion of related work is limited described above is that our study is not limited to a speciﬁc programming language, paradigm, or technology. We retrieve and analyze any post related to the concept of refactoring. Arnaoudova et al. [36] surveyed 71 developers to understand the importance of rename refactoring operations. The ﬁndings show that developers consider renaming refactoring a challenging activity, and they frequently perform rename operations on the source code. In their study of utilizing the commit log to contextualize renaming operations, Peruma et al. [80] observe developers perform renames as part of addressing defects and unit tests. The authors also highlight that the commit log alone cannot be utilized to gain insights into renaming operations. In a preliminary study on the refactorings of Android apps, Peruma [77] performs a topic modeling analysis on the commit log. The author shows that developers refactor apps for reasons such as improving code readability, ﬁxing defects, and enhancing the app’s design. A survey with developers at Microsoft by Kim et al. [62] shows that there are costs and risks involved with the performance of refactoring activities and also the need for more tool-based support. Furthermore, the survey results show that developers do not consider refactoring to be conﬁned to only behavior preserving transformations; this is in contrast to the academic deﬁnition. In their study, Danilo et al. [92] identify that changes in requirements are one of the key reasons that drive developers to refactor code. The authors also show that ‘Extract Method’ is a frequently occurring refactoring operation and identify 11 motivations for applying this operation. Additionally, the authors also identify that developers are concerned about introducing duplicate code. Finally, the authors also indicate that developers more frequently apply refactorings manually than using a tool. They also report that a lack of trust in tools is a key concern among developers. Murphy-Hill et al. [71] note that the majority of refactoring operations are performed manually. However, the rename operation is frequently performed using a tool. Additionally, the authors also indicate that there exist instances where developers utilize tools to perform refactorings in batches. Examining commit messages, the authors show that it is not feasible to determine if a refactoring was applied based on the message in the commit log. refactorings by analyzing the history of 150 open-source systems. Particularly, they analyze 551 pull requests containing refactoring operations and produce a refactoring taxonomy that generalizes existing literature. In a large-scale empirical study on refactoring, AlOmar et al. [30] explore what motivates developers to apply refactorings by mining and automatically classifying a set of 111,884 commits containing refactoring activities extracted from 800 open-source Java projects. Their ﬁndings show that ﬁxing code smells is not the main driver for developers to refactor their code. Developers refactoring for various reasons (e.g., feature addition, bugﬁx), going beyond its traditional deﬁnition. Furthermore, recent studies [29,75] show that there is a misperception between the state-of-the-art structural metrics widely used as indicators for refactoring and what developers consider to be an improvement in their source code. The authors identiﬁed (among software quality models) metrics that align with the vision of developers on the quality attributes they explicitly state they want to improve. A number of studies have recently focused on the documentation of refactoring. AlOmar et al. [27,28,30] have explored how developers document their refactoring activities in commit messages; this activity is called Self-Aﬃrmed Refactoring (SAR). In particular, SAR indicates developers’ explicit documentation of refactoring operations intentionally introduced during a code change. Based on their empirical investigation, developers tend to use a variety of textual patterns to document their refactoring activities, besides ’refactor’, such as ’redesign’, ’reorganize’, and ’polish’. These patterns can be either (1) generic, providing a high-level description of the refactoring, or (2) speciﬁc by explicitly mentioning the rationale behind the applied refactoring operations. Our research methodology follows a mixed-methods approach, where we collect and analyze both quantitative and qualitative data [101]. This approach provides insight into relationships between qualitative and quantitative data and allows us to present representative samples from the dataset to complement our ﬁndings. More speciﬁcally, our approach utilizes well-established statistical measures, including unsupervised machine learning and natural language processing techniques which we apply to our dataset to report While our study also mines Stack Overﬂow posts, the key diﬀerence between our study and the works More recently, Pantiuchina et al. [76] present a mining-based study to investigate why developers perform on trends and patterns of refactoring posts. Additionally, we also manually review a statistically signiﬁcant sample of refactoring posts (body and metadata) to gain further insight into developers’ refactoring challenges to supplement and correlate our quantitative ﬁndings. obtaining a recent and representative Stack Overﬂow dataset, (2) identifying and extracting refactoring posts, (3) analyzing the refactoring posts (textual content and metadata). In summary, our study utilizes SOTorrent [38] to obtain Stack Overﬂow posts. From this dataset, we extract all refactoring posts (based on the tag and title of the post) and analyze these discussion posts via both manual inspection and automated mechanisms to help answer our research questions. In the following subsections, we describe in detail the elements and activities that were part of our methodology. Furthermore, we have the complete dataset available on our website for replication and extension purposes [13]. For our study, we utilized the March 2020 release of the SOTorrent dataset available on Google BigQuery The SOTorrent dataset is constructed using a data dump provided by Stack Overﬂow. The dataset contains the version history of each post along with other relevant metadata such as the author of the post, score, view count, answer count, etc. Provided below, we brieﬂy describe the attributes in the dataset that we utilized in our experiments. – Posts: There are three types of posts – (1) question, (2) answer, and (3) accepted answer. A question – Tags: As part of creating a question, the developer needs to associate the question with one to ﬁve tags– – Score: Associated with posts, this metric is based on the Upvotes the post receives. The higher the – View Count: Associated with only questions, this metric corresponds to the number of times the post Figure 1 outlines the methodology for our study. Our methodology involves three key activities– (1) post contains details about the problem/challenge faced by the developer. A question consists of a title and body ﬁeld; the title is a plain text ﬁeld, while the body supports a limited set of formatting. Responses to a question can fall into one of two categories: an accepted answer or a non-accepted answer. A response post contains only a body ﬁeld. While a question can have only one accepted answer, it can have more than one non-accepted answer. An accepted answer indicates that the developer asking the question considers this speciﬁc answer as a solution to the question asked. In other words, an accepted answer acts as a means of informing the community that the speciﬁc answer was the intended solution for the question. Only the developer asking the question can mark an answer as an acceptable answer. a word or phrase that describes the question. Only questions can be associated with tags. Tags permit site users to access a particular set of questions that is of interest to them. Stack Overﬂow discourages the creation of arbitrary tags and instead recommends the use of predeﬁned tags. score value, the more useful the post to the community. was viewed. – Favorite Count: Associated with only questions, this metric indicates the number of times site users Even though SOTorrent contained all Stack Overﬂow posts, our research focused on refactoring related discussions. To this end, we performed an extraction of relevant question-based posts from SOTorrent. Our process involved retrieving questions that had either been tagged with a word containing the term ‘refactor’ or contained the term in the title. For each extracted question, we also extracted all answerbased posts (including accepted answers) associated with the question. We excluded searching for the term ‘refactor’ in the body of the post as we observe that such an action leads to an increase of false positives in our dataset. Looking at such posts, we observe developers mentioning the term ‘refactor’ in passing, even though the post is not about the actual refactoring of code. For instance, in question– Quote 3, the developer requests help to solve a runtime exception without refactoring the code. Additionally, in some instances, the developer refactors the code to make it easier to comprehend the problem [16]. Furthermore, as mentioned by Rosen and Shihab [86], the title succinctly describes the primary purpose of the question. Our study of refactoring posts includes a quantitative and qualitative approach. Our quantitative approach involves executing database queries and custom code/scripts, including a topic modeling analysis using an unsupervised machine learning algorithm. In the qualitative approach, two or more of the authors manually analyzed a statistically signiﬁcant sample set of the data. Depicted in Figure 2, we summarize the type of research approach we utilize to answer each research question and the data on which it is applied. In Section 4, we elaborate in detail on our analysis approach to answering each research question. have marked the post as a favorite. “The problem I have is that for a series of incoming messages...which leads to exceptions within the DLL...Is there any way around this, given that refactoring the DLL isn’t an option.” - Question Metadata- Question Body- Challenging & - Descriptive Statistics- Refactoring Popular Questions - CorrelationsKeywords Frequency- Descriptive Statistics - Question Tags- Question Body- Unanswered - Categorization- Keywords, N-Grams Questions Fig. 2: Summary of the research approach we utilize to answer each research question (RQ). In this section, we report on the results of our experiments. Our analysis contains three Research Questions (RQs), with certain RQs comprising of sub-RQs. In RQ individuals that ask and respond to questions, respectively, and the tags associated with questions. RQ looks at identifying the rationale behind the refactoring posts. Speciﬁcally, the RQ examines the frequently occurring phrases in the body of a post and groups questions into categories (or topics) based on the textual content of the question. Finally, in RQ challenging topics. results; then, we present our ﬁndings. Further, where applicable, we also include examples to posts on Stack Overﬂow to provide the reader with more clarity on our observations. Finally, even though some tables and ﬁgures in the RQs show a subset of the data, we have the complete dataset available on our website for replication and extension purposes [13]. This RQ is composed of three sub-RQs exploring the growth of refactoring posts on Stack Overﬂow over the years. As a question and answer site, RQ on the site. In RQ of refactoring-related questions and answers. Finally, in RQ creating refactoring questions and the growth of these tags throughout the years. Motivation & Approach: In this sub-RQ, we examine the growth of refactoring questions on Stack Overﬂow. The purpose of this sub-RQ is to understand the extent to which developers require help and advice on refactoring related problems and how often they receive the assistance they seek. To do this, we extract all questions that had the term ‘refactor’ in either the title or tag. Next, for each question, we extracted all answers (i.e., accepted and non-accepted) associated with the question. Findings: In total, we extracted 9,489 refactoring-related questions, from which, 828 (∼8.73%) of the questions did not have an associated answer. Regarding accepted answers, 6,112 (∼64.41%) of the questions had an accepted answer. Table 1 provides a summary of the collected data. this chart, for each year, the orange bars are questions without an accepted answer, while the blue bars are questions with an accepted answer. The gray bars represent all questions (i.e., questions with and without an accepted answer). Our count of questions with an accepted answer is constrained to question-accepted answer pairs created in the same year. It should be noted that Stack Overﬂow was launched in September 2008, and our dataset contains posts up to March 2020; hence our analysis excludes posts created in these two years. A ﬁrst glance at this chart shows that, other than for the year 2019, the number of questions with an accepted answer outnumber questions without an accepted answer. However, also shown in this For each RQ, we ﬁrst explain the primary motivation(s) and the approach we undertake to produce the : How have refactoring discussions on Stack Overﬂow grown over the years? : How have refactoring posts grown throughout the years? Figure 3 shows a yearly breakdown of refactoring questions with and without an accepted answer. In Year chart is that as the years progress, the number of questions with accepted answers decreases while questions without accepted answers increases. this analysis, we look at how long it takes for a question to receive a response (regardless of it being an accepted answer) and how long it takes to receive an accepted answer. When examining the time duration between question-accepted answer pairs, we consider all refactoring posts in our dataset and do not restrict our analysis to pairs created in the same year. For completeness, we present the median values with and without outliers (removed via the Tukey Fences approach [58]). The median time between a question and its ﬁrst answer is 0.27 hours with outliers and 0.19 hours without outliers. The median time between a question and an accepted answer is 0.41 hours with outliers and 0.27 hours without outliers. Additionally, in Figure 4, we also show histograms of time duration values (without outliers) most responses to refactoring questions occur within the ﬁrst hour of the developer asking the question. see that questions and accepted answers share a similar pattern between the YOY growth for questions and accepted answers. While the number of questions and accepted answers have increased, the volume by which they increased has been falling. Furthermore, to measure the extent of the relationship between these two variables, we conducted a Pearson correlation test [97]. This particular test is also known as a parametric correlation test as it depends on a normal distribution of the data, which we conﬁrmed via a Next, we look at the time duration between a developer asking a question and receiving a response. In Looking at the year-over-year (YOY) growth around refactoring discussions (refer to Figure 5), we Fig. 4: Distribution of time (in hours) from when a question is asked until the reception of an answer. Shapiro-Wilk normality test [97]. The Pearson correlation test yielded a statistically signiﬁcant (i.e., p-value < 0.05) correlation coeﬃcient of 0.872, equating to a strong correlation. pattern throughout the years. Hence, while we see a dip in questions in 2017, there has been a gradual uptick in the subsequent years. This is an interesting phenomenon and would require further research to explain this pattern. Motivation & Approach: After looking at the general trend of refactoring questions, this sub-RQ looks at the involvement of the Stack Overﬂow community in refactoring discussions. We investigate if a selected set of community members is responsible for asking and answering refactoring questions. To answer this sub-RQ, we capture the unique members posting questions and answers. More speciﬁcally, we utilize the OwnerUserId ﬁeld to identify the creator of a post (i.e., question and answer). Findings: In the ﬁrst part of our analysis, we look at the volume of unique users posting questions and answers. Looking at questions, we observe that 7,795 distinct users are responsible for creating all 9,489 refactoringrelated questions. When it comes to answers, we found that 4,610 distinct users are associated with accepted answers, while 10,566 distinct users are associated with non-accepted answers. From the whole set of distinct users posting questions, most (≈ 82.64%) of the users post only questions. A similar pattern emerges when we look at the distinct set of users posting non-accepted answers; most Finally, from the two charts, we observe a phenomenon where the number of questions forms a wave-like : What is the distribution of questions and answers among developers? Next, as shown in Table 2, we look at the distribution of these unique users for each type of post. (≈ 79.65%) of these users only post non-accepted answers. However, looking at the set of distinct users posting accepted answers, we see more of an even distribution. mark their answer as an accepted answer. Therefore, we next look at such instances for refactoring posts. When it comes to accepted answers, we observe that 6.50% (or 389) of question-accepted answer pairs have the same user creating the question and accepted answer. For non-accepted answer-question pairs, approximately 2.30% (or 322) instances have the question creator also posting an answer. distinct users asking questions would ask, at most, only one question (≈ 88.69%). We observe similar patterns for accepted and non-accepted answers. In these two instances, approximately 85.64% and 83.82% of the distinct users create a single accepted and non-accepted answer post, respectively. Table 3 shows the top ﬁve distributions for each type of post. Motivation & Approach: Tags are an essential part of Stack Overﬂow posts; they enable developers to categorize their questions and also help experts quickly access the questions that they specialize in. In this sub-RQ, we explore the types In Stack Overﬂow, it is possible for the user who asks a question to answer their question and even Our ﬁnal analysis looks at the volume of posts that a user creates. We observe that the majority of : What are the tags that are associated with refactoring questions? of tags that developers associate with refactoring questions. Our analysis of tags will help determine the concepts and technologies associated with refactoring challenges developers face. These ﬁndings provide a high-level overview, which we elaborate on in the subsequent RQs. To obtain the data for this sub-RQ, we extract all tags from all refactoring posts Findings: In total, our dataset contains 3,053 distinct tags. Not surprisingly, the most frequently occurring tag in our dataset is ‘refactoring’. We observe 6,808 (∼21.89%) questions containing the ‘refactoring’ tag. Since this study is on refactoring, going forward, our analysis of tags will exclude counting the ‘refactoring’ tag and instead focus on the other tags added by developers to refactoring posts to understand the area of refactoring better. instances), C# (1,512 or 7.50% instances), JavaScript (946 or 4.69% instances), Ruby on Rails (591 or 2.93% instances), and Ruby (569 or 2.82% instances). These top ﬁve tags accounted for 27.82% of the tags in the dataset. Additionally, most of the frequently occurring programming language tags in our dataset also appear in the list of top programming languages from 2016 to 2018 [93,94,95,96]. languages refactoring tags in the dataset. When reviewing the tags for each year, we observe that these tags were part of a frequently occurring set of tags each year. In Figure 6, we plot the volume by which questions associated with each tag either grow or shrink year-by-year (we ignore the years 2008 and 2020 as data is not available for the entire year). From this graph, we observe questions tagged with C# show a steep decline from 2012, while at the same time, we see the volume of Java tagged posts being more-or-less constant. We also observe a constant increase in JavaScript tagged posts throughout the years; similarly, though relatively low in volume compared to C# and Java posts, we also observe a steady increase in Python tagged posts. Furthermore, our ﬁndings on the rise of dynamically typed languages and the fall of statically typed languages are also in alignment with the Popularity of Programming Language Index [12]. cant sample of tags. To this extent, two authors reviewed 547 of the frequently occurring tags; this sample corresponds to a conﬁdence level of 99% and a conﬁdence interval of 5%. When reviewing the utilized tags, each author made notes for each tag. Comparing notes, the authors discussed and settled on the ﬁnalized set of annotation categories. The ﬁnalized set consists of seven categories– Tools, Programming Languages, Framework/Library/API, Algorithms and Programming Concepts, Design/Architecture, Operating Systems, and Other. Presented in Figure 7, is a breakdown of the volume of instances for each tag category. concepts, which include code quality (e.g., ‘code-cleanup’), data types (e.g., ‘arrays’), and programming concepts (e.g., ‘recursion’) among others. The next most popular category is frameworks/libraries/APIs (118 instances or 21.61%). Some of the tags under this category include javascript-based frameworks and libraries (e.g., ‘reactjs’), web frameworks (e.g., ‘django’), non-web libraries such as testing (e.g. , ‘junit’), objectrelational mapping (e.g., ‘hibernate’), and others (e.g., ‘pandas’). Tags falling under the tools category (88 instances or 16.12%) include questions around IDEs (e.g., ‘eclipse’), database (e.g., ‘mysql’), and plugins (e.g., ‘resharper’), among others. The majority of the tags under programming languages (56 instances or 10.26%) include those that support a multi-paradigm model such as ‘java’, ‘c#’, and ‘python’; the next most common paradigm is declarative (e.g., ‘sql’ and ‘html’). The design/architecture category includes tags related to patterns (e.g., ‘model-view-controller’). The popular tags in the operating system category are mobile-based (i.e., ‘android’ and ‘ios’). Finally, the tag ‘iphone’ is the most popular tag in the other category, containing six instances or 1.10%. The top ﬁve tags were all related to programming languages (or web frameworks)– Java (1,529 or 7.58% Next, as part of our analysis, we look at the yearly growth of the six most popular programming To determine the diﬀerent categories these tags fall under, we manually reviewed a statistically signiﬁ- The majority of the tags (236 instances or 43.22%) are related to general algorithms and programming Summary for RQ. Stack Overﬂow is a popular venue for developers to receive solutions for their refactoring questions, usually receiving a response in a short timeframe. Furthermore, while most questions involve statically typed languages, speciﬁcally Java and C#, we see a rise in questions around dynamically typed languages such as JavaScript and Python. This ﬁnding shows a need for refactoring support from researchers and tool developers for dynamically typed languages and their unique issues. Finally, our tags analysis shows that most questions are around algorithm and programming concepts, followed by questions around speciﬁc frameworks/libraries. As a question and answer site, the fundamental purpose of Stack Overﬂow is to facilitate developers to utilize natural language to either describe the problem they require help with or provide advice/solutions to these problems. Prior work has shown that the language used to describe refactorings can vary heavily [27,28]. For instance, the word ‘refactoring’ is not always used (e.g., clean-up is a common alternative). Furthermore, the context surrounding the refactoring being applied can aﬀect the particular alternative phrase that a developer chooses to use instead of the term ‘refactoring’. Thus, in RQ2, we explore the language used by developers to discuss refactorings through questions and answers. The outcomes from this question are meant to support a more robust analysis of refactoring rationale by revealing how developers discuss refactorings and what terminology frequently correlates in refactoring-related discussion topics. This RQ is composed of three sub-RQs. In RQ refactoring posts. In the second part of the research question, we utilize a refactoring taxonomy, known as Self-Aﬃrmed Refactoring (SAR) [27], to deﬁne refactoring opportunities. This taxonomy contains internal structural metrics (coupling, complexity, etc.), external quality attributes (code comprehension, readability, reusability, etc.), and code smells (duplicate code, long methods, etc.). Existing studies have shown the existence of posts discussing the removal of code smells [99,98], but little is known about how developers discuss the other types. Therefore, In RQ discussions around their refactoring. Finally, in RQ developers by grouping related questions. Motivation & Approach: The prior research questions show that developers do indeed encounter real-world challenges when refactoring their systems, and, at a high-level, our analysis of tags also indicates areas associated with refactoring challenges. However, since developers need to select the tags from a predeﬁned list, we are limited in understanding more speciﬁc refactoring areas. Hence, in this sub-RQ, we extract the top keywords as bigrams from question posts. Bigrams correspond to a sequence of two adjacent words in a sentence. We did look at trigrams, but we could not locate sets of common terms. Unlike unigrams, bigrams provide a certain level of context for terms, which helps our analysis by reducing the chance of making false presumptions. Additionally, we also examine the existence of speciﬁc refactoring terms. These terms correspond to refactoring operations deﬁned in Fowler’s catalog of refactoring operations (e.g., extract method, move method, rename attribute, etc.) [56]. Findings: In Table 4, we present the top ten frequently occurring bigrams in question posts. This table shows that the IDE ‘visual studio’ plays an important part in refactoring discussions. Since this particular IDE can support multiple types of programming languages, it has become popular among developers in implementing systems [20]. The mention of the IDE falls into two categories– (1) developers asking for assistance in performing a refactoring operation using the IDE, or (2) developers mentioning the IDE when providing context around the refactoring challenge they encounter. Furthermore, the bigram ‘refactoring tool’ also emphasizes the importance and reliance of tools and IDEs in refactoring activities. We also observe discussions around the refactoring of test suites showing that interest in refactoring source code among developers is not just limited to production code. The bigram ‘legacy code’ highlights a common reason why developers request support with refactoring. In the subsequent sub-RQ’s (RQ further contextualize most of these bigrams and provide exemplar posts from where they were extracted. we investigate if developers use these terms in their questions. These are the terms deﬁned in Fowler’s catalog of refactoring operations [56]. We observe that the bigram ‘extract method’ frequently occurs in question posts. However, we should also note that we also encounter instances where developers talk about extracting other types of identiﬁers, such as classes, interfaces, and variables. For move operations, once more, we observe that developers frequently mention the ‘move method’ operation. However, we also observe instances of moving classes and ﬁles. We also observe the terms ‘common’ and ‘code’ associated with the refactoring operation terms ‘extract’ and ‘move’, showing that developers discuss refactoring operations without using the standard terms deﬁned in the catalog or refactoring operations. Looking at : What do developers discuss in refactoring based Stack Overﬂow posts? : What are the frequent terms utilized by developers in refactoring discussions? Since the names of refactoring operations do not occur in the top ten frequently occurring bigrams list, inline operations, once more, methods were mentioned frequently for inlining. However, looking at rename operations, we observe more occurrences of ﬁles, classes, packages, and variables than methods. Finally, push-up and pull-down operations did not yield anything signiﬁcant (similar to ﬁndings by Danilo et al. [92]). Overﬂow for refactoring discussions. These bigrams are phrases associated with refactoring operations, showing that developers are aware of refactoring concepts. Going one step forward, in the next sub-RQ, we explore the use of other known software engineering refactoring phrases. 4.2.2 RQ with the challenges faced by developers in Stack Overﬂow posts? Motivation & Approach: The concept of Self-Aﬃrmed Refactoring (SAR) introduced by AlOmar et al. [27,28] explores how developers document their refactoring activities such as the intent behind the refactoring type of operations performed. In their work, the authors identify recurring patterns in SAR commit messages and deﬁne three SAR categories, (1) internal quality attributes, (2) external quality attributes, and (3) code smells. In our work, we use these SAR terminology patterns in addition to other keywords related to code smells reported in literature [56,99] that belong to each of the three SAR categories as indicators of refactoring activityrelated discussions. In other words, we string match SAR patterns in question posts to see the extent to which they contribute to challenges developers face when they refactor. We also extract the bigrams from question posts to better understand the context of SAR patterns and help us in our analysis. We are particularly interested in extracting the intent behind the refactoring in questions to capture what typically triggers developers to refactor their code. Findings: Table 5 depicts the list of SAR patterns, ranked based on their frequency, we identify in questions. We observe that developers frequently mention key internal quality attributes (such as inheritance, cohesion, etc.) and a wide range of external quality attributes (such as readability and performance), and a variety of code smells that might impact code quality. Upon closer inspection of the generic refactoring patterns, we notice that developers use a variety of patterns to discuss refactorings such as ‘clean up’ or ‘redesign’, although ‘refactor’ is the most used keyword (29.09%). Additionally, these patterns are mainly linked to code elements at diﬀerent levels of granularity (e.g., ‘add an attribute’, ‘create an interface’, ‘refactor the method’). Further, we observe that developers mention the motivation driving refactorings that are not restricted only to ﬁxing code smells, as in the original deﬁnition of refactoring in Fowler’s book [56]. We also observe that developers tend to report the executed refactoring operations using keywords such as ‘extract’ or ‘rename’. consistently mentioned (41.86%). It is apparent from some of the posts that developers intend to introduce best practices (e.g., the use of object-oriented design principles, the application of inheritance, polymorphism, and optimization of software quality metrics to reduce code complexity). Further, developers refactor This sub-RQ highlights common bigrams in refactoring posts to understand why developers utilize Stack : To what extent do traditional refactoring opportunities, known in existing literature, match To improve the internal design, the optimization of dependency seems to be the dominant focus that is the code to improve the dominant modularization driving forces (i.e., cohesion and coupling) to maximize intra-class connectivity and minimize inter-class connectivity. hance nonfunctional attributes. Terms such as ‘readability’, ‘eﬃciency’, and ‘performance’ represent the developers’ main focus, with 16.37%, 13.85%, and 11.52%, respectively. Although multiple studies [75, 53, 32] have been analyzing code comprehension and using metrics to measure readability, there is no mention of these readability tools/models (i.e., [50,89,46, 83]) in the questions. For instance, developers refactor the code to improve its reusability. More recently, AlOmar et al. [31] show that the number of methods significantly increases when developers refactor the code to improve reusability. Also, developers make changes such as extracting methods to improve testability as they test parts of the code separately. Developers also extract methods to improve code readability. most popular anti-pattern that developers intend to refactor (28.75%). While there are also various tools for detecting and potentially refactoring code clones [60,87,66], we could not locate any reference to them. Also, developers perform refactorings to eliminate speciﬁc code smells (e.g., spaghetti code, long method, feature envy, etc.) that are known to deteriorate the quality of the source code. For example, based on our manual analysis, we observe that developers discuss performing ‘Extract Method’ refactoring to remove a code smell, which corresponds to a long method (i.e., a bad smell). Developers also indicate the generic pattern ‘code smell’ in addition to the speciﬁc name of the code smell under correction. ers when crafting questions on Stack Overﬂow. While these phrases/terms are indicative of refactoring activities, they are speciﬁc to SAR patterns and, at a high-level, do not provide context as to where or what is associated with the terms. Hence, in the following sub-RQ, we group all related terms (i.e., SAR and non-SAR pattern terms) to determine the primary categories that cause developers to seek assistance when refactoring. We perform this grouping on the entire set of questions on our dataset via the use of an unsupervised machine learning technique to determine the refactoring topics associated with refactoring questions. Motivation & Approach: The prior sub-RQs looked at common and SAR pattern terms in refactoring posts. In this sub-RQ, we go a step forward by grouping related terms to identify and understand the diﬀerent areas (or topics) that developers require assistance with and understand the motivation behind refactoring. the common phrases developers utilize when describing their problem/challenge. Next, we perform a topic modeling analysis to identify the key topics associated with refactoring related questions. Finally, we manually analyze a statistically signiﬁcant sample of questions to gain more insight and context around the detected topics. Topic modeling is an unsupervised machine learning procedure that infers the topics (or thematic structure) discussed in large volumes of unlabeled and unstructured text documents [57]. N-grams are sets of co-occurring words (or letters), within a given window, that are available in a textual document and are useful in understanding a word in its context [59]. textual data. Some of our key pre-processing activities included: expansion of word contractions (e.g., ‘I'm’ → ‘I am’), removal of URLs, code blocks, stopwords, alphanumeric words, and punctuations, retaining only nouns, verbs, adjectives, and adverbs and lemmatization of words. We opted to use lemmatization over stemming, as the lemma of a word is a valid English word [64]. In addition to the default set of stopwords supplied by NLTK [44], we added our own set of custom stop words. To derive the set of custom stop words, we generated and manually analyzed the set of frequently occurring words in our corpus. Examples of custom stop words include ‘thanks’, ‘question’, ‘answer’, etc. We utilize the Latent Dirichlet Allocation (LDA) [45] algorithm for our topic modeling analysis. Our use of LDA for the topic modeling analysis follows prior research based on Stack Overﬂow posts [72,105,39, 41,86,104,23,108, 40,33,26,37,22] that have shown the eﬀectiveness of LDA in similar contexts. Essentially, LDA builds a statistical model that groups related words together from a corpus of textual documents where each grouping of frequently co-occurring words represents a topic. As the topics are not labeled, subject matter experts are then needed to determine each topic’s name based on the analysis of the list of words. A mandatory input for the LDA algorithm is the number of topics to be generated. A low value will result in high-level or general topics, while a high value Concerning external quality attribute-related questions, we observe the mention of refactorings to en- Finally, for code smell-focused refactoring questions, we observe that duplicate code represents the This sub-RQ shows that SAR patterns documented in commit messages are also utilized by develop- : What are the topics around software refactoring that are being asked by developers? We tackle this research question from three fronts. First, we perform an n-gram analysis to identify Prior to our topic modeling and n-gram analysis, we perform a set of pre-processing activities on the will produce more detailed topics, some of which will be noise. Hence, to arrive at the optimal number of topics, we iteratively extracted topics from two to ﬁfty in increments of one. Each LDA execution cycle (i.e., model creation) was subjected to ten passes and one hundred iterations. In each cycle, we extracted the topic coherence [85], perplexity score [45], and topic visualization [90] of the model. Finally, to determine the optimal number of topics for our LDA analysis, we relied on a combination of topic coherence, perplexity, visualization, and manual analysis. The complete set of coherence and perplexity values for each of the ﬁfty models and an interactive visualization for the optimum model is available on our project website. Concerning our manual and visual analysis– we look at the topics and terms generated in each execution cycle of the LDA algorithm to discover patterns in the topics such as similarities and overlapping of topics, topics that are consistent between each execution cycle, the prevalence of each topic, distribution and relevance of words by topics, etc. Finally, since the LDA process does not result in meaningful names for the topics it generates, we manually examined the list of generated terms to determine the appropriate topic names. For our manual analysis, we undertook a collaborative approach– we looked at the terms that represent each topic, came to an agreement on the name of the topics, and identiﬁed the topics generated by noisy terms. Additionally, we also looked at the terms that are unique to each topic and the terms shared among topics (including the overall frequency of the term). Table 5: Frequency of Self-Aﬃrmed Refactoring (SAR) patterns in questions posts. Table 6: LDA topics with their frequency of occurrence and a partial set of their corresponding words. Findings: From our LDA analysis, we observe that the most optimal model yields ﬁve topics, associated with Stack Overﬂow refactoring questions: Code Optimization, Architecture and Design Patterns, Unit Testing, Tools and IDEs, and Database. To understand the distribution of each topic in the dataset, we assigned the most dominant topic to each question. Our results show that Code Optimization is the most frequently occurring topic (at 43.72% or 4,142 questions). We present, in Table 6, the distribution for each topic in the dataset. Additionally, the table also shows a partial set of words (unigrams and bigrams) associated with each topic. adequately help in determining the rationale for the topic. These topic-based words alone do not indicate the problems developers encounter or the advice they solicitor around refactoring. Hence, we perform a manual analysis of a stratiﬁed statistically signiﬁcant set of questions. Using a conﬁdence level of 95% and an interval of 10% for each topic, we constructed a sample size of 430 posts that were analyzed by two authors. In this process, two authors annotated the dataset with the rationale behind the topic. Next, the authors exchanged the annotated datasets for review. During the review, if the reviewer disagreed with a speciﬁc annotation, the instance was marked for discussion. Finally, the annotator and reviewer discussed and looked at resolving the identiﬁed conﬂicts. takeaways for relevant stakeholders. Additionally, to provide context around topics, we include representative examples to Stack Overﬂow posts in the form of quotes. Program comprehension is a crucial-enough concern for developers that they turn to the community for assistance with improving the analyzability or readability of their source code. To this end, a common challenge developers face is reducing lines of code. Our analysis of exemplar posts (e.g., Quote 4) shows that developers seek assistance with performing refactoring operations involving code extraction and advice on any patterns that they should follow. Speciﬁcally, some common challenges include simplifying or replacing switch statements and loops, compacting logic, and removing duplicate code. In most instances, developers are dealing with code that consists of a series of complicated logic conditions that require signiﬁcant and careful refactoring so as to not result in a break of functionality. Within this topic, we also observe situations where developers reach out to the community for help with resolving runtime and behavioral issues they encounter after making readability improvements to their code. Thus, showing that improving program comprehension is not always straightforward– it can be both time-consuming and error-prone. readability, such as ‘repeated’, ‘helper method,’ and ‘avoid duplication’; further highlighting that developers seek assistance with improving code reusability as a means of improving overall program comprehension. More speciﬁcally, this improvement often leads to optimization of switch-case statements and eliminating duplicate code, and possibly even improve the eﬃciency and performance of the system. Finally, it is worth noting that even though developers seek help with refactoring their code, they rarely utilize established While examining the words occurring in a topic helps in determining the name of the topic, it does not For each of the detected topics, we describe our ﬁndings and summarize the key challenge(s) and the Next, observing the frequent terms in this topic (refer to Table 6), we encounter terms related to refactoring terminology (e.g., ‘Extract Method’) when describing their problem; instead, they tend to be more colloquial in their description. “I wrote a function to handle selecting and using items to regain the player’s health in a text adventure. What would be the best way to shrink the following code? Any feedback or constructive criticism would be greatly appreciated.” to improve readability, and reusability, speciﬁcally around reducing the complexity caused by lengthy switch-case statements, loops, and duplicate code. This challenge presents the research community with two important opportunities: 1) to conduct studies around the automatic detection and refactoring of lengthy conditional code blocks (such as switch-case statements), and 2) to understand and measure the inﬂuence of diﬀerent code structures, patterns, and architectures on comprehension (i.e., what is the best way to refactor a large group of nested conditional statements?). This challenge is related to prior work, which shows that readability metrics are currently struggling to measure real readability [53]. This topic deals with questions about activities related to tool-based refactoring. Tools are a vital part of software development. They provide developers with the means to automate time-consume code changes, thereby improving developer productivity and potentially eliminating the injection of defects. Predominately, questions around this topic are related to renaming activities. This aligns with the previous topic where we observe developers seeking assistance to optimize their code to improve program comprehension. However, questions around tool-based renaming are not just related to a straightforward renaming of a source code identiﬁer. Instead, developers seek assistance with renaming other software engineering artifacts such as packages, database elements, ﬁles, and content within other non-source code ﬁles such as XML or performing bulk/batch-based renaming operations (e.g., Quote 5). In most instances, the questions are around using the rename functionality of their IDE. other refactoring operations such as move operations, type changes, duplicate checking/elimination. Once again, these questions are speciﬁc to the developer’s project and, in most cases, nontrivial. Additionally, developers seek advice for recommendations for tools/IDEs for refactoring speciﬁc programming languages or for conﬁguring tools (such as disabling/enabling speciﬁc IDE refactoring features). In their study of the usability of refactoring tools, Eilertsen and Murphy [52] highlight the need for tools to support developers in guiding tools in the execution of refactoring operations. This corroborates our ﬁndings, where most questions around tool usage are speciﬁc to a developer’s source code. Furthermore, many of the standard refactoring operations available by the tool do not meet the developer’s unique refactoring needs. Lastly, from Table 6, we observe that questions involve using popular IDEs, speciﬁcally Visual Studio, IntelliJ IDEA, and Android Studio. “I have script ﬁles ready to create a database. I also have coding standards/conventions to be set against those scripts. Is there a best/Easy way to rename these (according to coding standards I have) such that when I rename a database object, other objects that reference the renamed object should automatically updated with the new name.” toring activities. However, the developer’s expectation goes beyond the general/standard features oﬀered by the tools. The primary challenge is with seeking assistance with renaming other software engineering artifacts outside of identiﬁer names. These are artifacts such as packages, database elements, ﬁles, and How can I refactor this Python code to make it more readable and compact? Quote 4: Sample question for the code optimization topic highlighting the need for assistance with In summary, this topic shows that developers primarily seek assistance with simplifying code structures While most questions we observe are around renaming, we also encounter questions about performing Rename/Refactor database elements - only scripts exists but not database Quote 5: Sample question for the tools/IDEs topic showing developers seeking assistance using In summary, this topic shows that developers understand the beneﬁts of using tools to automate refacothers. Based on this, vendors should enhance their IDE’s renaming facility to support renaming other software elements/artifacts (e.g., database elements) related to renamed source code identiﬁers. Furthermore, the research community needs to investigate models and techniques that can learn from and adapt to a developer’s codebase. Such as providing better recommendations and improved detection of opportunities to refactor artifacts outside of code. Especially those artifacts that have direct links to entities in the code that are touched by a refactoring. As part of their evolution, industrial systems typically undergo architecture refactoring to maintain their structural quality [88]. A review of a sample set of posts on this topic shows that reusability is a crucial motivator for developers to refactor their systems. Developers primarily seek assistance with reducing the complexity of their systems, which in most accounts are legacy systems. Typically such systems have been online for a considerable period and undergone many updates by multiple developers. To this extent, the questions revolve around asking for assistance with adhering to design principles such as SOLID, DRY, SRP, and KISS. When asking for assistance, developers knowingly admit that their codebase violates speciﬁc design principles such as the existence of large modules (i.e., low cohesion) and duplicate or near-duplicate code. For instance, in Quote 6, the developer realizes that a method in their class performs more actions than it should and seeks advice on how best to refactor the method to adhere to the single responsibility principle. Such code negatively impacts both program comprehension and unit testing. Also, similar to the other topics, there exist situations where structurally based refactoring leads to issues to which developers turn to the community for assistance. system using concrete and well-tested solutions and at the same time promote code reuse, performance, reliability, and extensibility. Additionally, the vocabulary of the pattern conveys the purpose of the pattern and thereby aids in communication between developers. Finally, Table 6 shows some of the common patterns developers mention in their post (e.g., ‘singleton’, ‘factory’, and ‘view controller’). “I’ve got controller code like this all over my ASP.NET MVC 3 site... we have caching, user reputation handling, auditing, all in one. Doesn’t really belong in one spot does it. Hence the problem with the current code, and the problem with trying to ﬁgure out how to move it away.” Quote 6: Sample question for the architecture/design patterns topic where a developer requires assistance source code often results in the structure of the codebase violating established design principles and patterns. Developers face challenges refactoring their code to revert these violations and seek assistance from the community around applying SOLID, DRY, SRP, and KISS principles to their codebase. For the research community, this presents an opportunity to investigate how to provide stronger advice to developers attempting to stick to best practices. One potential avenue is to look at heuristics or AI model-based approaches to pointing out violations of, for example, DRY. Unit testing is an essential part of ensuring the quality of a system. Similar to production code, developers also refactor their test cases to meet internal quality requirements and/or to support the refactored production code. In most instances, developers face challenges with writing test cases, primarily to accommodate refactored production code. Since there can be more than one test method to evaluate a single production method, an update to the structure of production code usually involves extensive updates to the test suite. For example, in Quote 7, the developer runs into issues with the test suite after refactoring the system under test (i.e., production code) and seeks advice from the community on the appropriate approach that needs to be followed to update test cases. API usage (e.g., mocking), the majority of the questions revolve around the developer’s speciﬁc project code. Finally, the presence of the terms complexity, maintainability, and testability in the Self-Aﬃrmed Refactoring patterns list (refer to Table 5) shows that developers recognize the importance of writing code that is test friendly. By reducing the cohesiveness and cyclomatic complexity of their production code, By following well-established architecture/design principles and patterns, developers construct their with making their code more robust by adhering to the single responsibility principle [3]. In summary, this topic shows that as a system evolves, the accumulation of updates made to the Furthermore, it should be noted that while we do encounter questions around test conﬁguration and developers will ﬁnd it much easier to construct test cases that achieve a high degree of modularization (i.e., responsibility) and code coverage. “There were requirements changes and I had to change some classes behavior and API Changing one class behavior eventually led to changing a few others. I didn’t know how to start this process from the test side, so I started changing the code. I ended up with lots of compilation errors in the test code and after I ﬁxed them some did not pass. But the thing is, I don’t even know if the tests cover what they used to cover before... TDD is supposed to give me a safety net while refactoring. Isn’t it? As it currently appears in my case it doesn’t give me that.” Quote 7: Sample question for the unit testing topic where a developer requires assistance updating the However, evolving a test suite alongside production code can be challenging, and developers seek assistance incorporating these changes into the test suite. For instance, there can be multiple test methods (i.e., test cases) associated with a single production method. Hence, the refactoring of a single production method will require multiple updates to the test suite. The research and vendor communities can support developers with tools that either give recommendations or automatically refactor test suites when developers refactor the system under test. Traditionally refactoring has been primarily focused on improving the quality of program source code. However, these are not the only software engineering artifacts that developers refactor in real-world systems [67]. One such artifact is a database. A database is a crucial part of most software systems, and a highly optimized database ensures better performance in terms of speed and resource utilization, among other attributes [34].To this extent, most questions in this topic revolve around the refactoring of SQL queries to resolve challenges around performance and maintainability. In terms of performance, developers look for help reducing memory and query execution time by optimizing queries to return only the required set of records. From a maintainability perspective, improving analyzability or program comprehension is a crucial concern among developers. Like optimizing source code, developers seek assistance with reducing the complexity and length of queries. As an example, in Quote 8, the developer seeks assistance to improve the performance of a query and at the same time indirectly states that the complexity and readability of the query needs improving. Further, we also observe developers seeking assistance with performing batch/bulk rename operations to database elements. Finally, developers also require help improving the reusability or modularization of queries by removing duplicate code and adherence to the single responsibility principle. “I am getting performance issues because in the subqueries, I need to join on the same tables for each subqueries which is an heavy operation. Consider the below (ugly) example... so to me it sounds like the joins in subqueries is overkill even if it is working ﬁne (very slow...)” Quote 8: Sample question for the database topic where a developer requires assistance improving the scripts and these queries tend to grow in length and complexity. As such, this negatively impacts code readability, design principles, and system performance. The research/vendor community should provide developers with tools that automatically refactor or suggest changes to database elements based on source code refactoring and vice versa. Additionally, research into the readability of SQL scripts will lead to metrics and tools that developers can utilize in their implementation workﬂow. In summary, test cases, like production code, are subject to evolution during the system’s lifetime. Performance issue - refactor select subqueries which are doing the same joins In summary, from this topic, we observe that developers prefer to implement business logic within SQL Motivation & Approach: The purpose of this RQ is to understand the types of refactoring questions asked by developers that are challenging to answer. Additionally, we also look at the type of questions that the Stack Overﬂow community considers popular (or attractive). To this extent, this RQ builds on the results of the prior RQ to understand the speciﬁc refactoring topics that are considered popular or challenging by the community. popularity of a topic by looking at the average view count, favorite count, and score of questions associated with each topic. The higher the average value for each metric, the more popular the topic. When it comes to topic diﬃculty, we look at the questions that do not have any answers, do not have an accepted answer, and the median time the community takes to provide an acceptable answer to a question. Since an answer can only be set as an accepted answer by the developer who asks the question, there can be situations where the person asking the question forgets to mark a provided answer as an acceptable answer. Hence, we look at the percentage of questions with no answers and those that have accepted answers. Findings: From Table 7, we see that the topic Tools and IDEs is the most popular among the ﬁve refactoring topics while Database is the least popular topic. Even though the total number of Tools and IDEs questions are less than Code Optimization questions, the average view count metrics of the former are higher than the latter (by a percentage diﬀerence of approximately 91.33%). This indicates that developers are more frequently searching for, and thereby viewing, questions around refactoring tools and IDEs, perhaps, looking for help with a similar problem they are experiencing. questions that are not part of our refactoring dataset) with the goal of comparing the popularity of refactoring questions against all other types of questions. In general, non-refactoring Stack Overﬂow questions have an average view count of 2361.42, an average favorite count of 0.62, and an average score of 2.08. Looking at the two sets of values, we see that refactoring questions have more favorites than general questions. At the same time, the view count is much higher for general Stack Overﬂow questions than refactoring Summary for RQ. Our analysis of refactoring discussions shows questions revolving around ﬁve topics– Code Optimization, Tools and IDEs, Architecture and Design Patterns, Unit Testing, and Database. The primary driver behind these questions is the need to improve non-functional quality attributes in the code, of which improving maintainability is a key concern. Improving readability (such as reducing lengthy conditional statements) and reusability is of utmost concern for developers and is not only related to source code. Furthermore, synchronizing refactoring changes across software engineering artifacts (such as unit tests and databases) is also challenging for developers. Additionally, we highlight takeaways under each topic for the key stakeholders. : Which topics are the most popular and diﬃcult among refactoring-related questions? Our study of popularity and diﬃculty of topics is similar to prior research [108,37,22]. We measure the Additionally, we also look at the same metrics for all non-refactoring Stack Overﬂow questions (i.e., Table 8: Pearson correlation analysis between the popularity and diﬃculty of refactoring topics.Bold questions (a percentage diﬀerence of approximately 158.313%). The score metric for both these two types of questions is similar. Once more, looking at Table 7, we observe that the topic Tools and IDEs has the most number of questions without both an accepted answer or any answer for that matter, and takes around 0.40 hours to receive an accepted answer. Hence, this seems to be the most challenging type of question for developers to answer. Topics falling under Code Optimization are less challenging to answer, as only 6.69% of these questions do not have an answer, while 31.12% of the questions do not have an accepted answer. Furthermore, it takes around 0.23 hours for such questions to receive an accepted answer. Similar to the prior work mentioned above, we perform a correlation analysis of the three popularity metrics (i.e., average view, favorite, and score) against the three diﬃculty metrics (median time to obtain an accepted answer, percentage of questions without any answers, and without an accepted answer). A Shapiro-Wilk normality test [97] on these variables shows that the data follows a normal distribution; therefore, we Pearson correlation test [97]. Table 8 shows the results of our correlation analysis. This table shows a strong positive statistically signiﬁcant correlation (i.e., p-value < 0.05) for the diﬃculty metric percentage of questions without an accepted answer and the popularity metrics average views and score. Additionally, there is a strong positive relationship between views and posts without any answers. The remaining popularity and diﬃculty metrics do not show any statistically signiﬁcant correlations. From this, we see that questions without an accepted answer are considered to be diﬃcult, yet interesting enough that they garner views and scores from the developer community. This phenomenon is observable with the topic metrics in Table 7. In our ﬁnal analysis, we examine unanswered questions (i.e., questions without an accepted and nonaccepted answer post). To this extent, two of the authors manually reviewed a stratiﬁed statistically significant sample of 259 unanswered questions. This sample represents a conﬁdence level of 95% and an interval of 10% for each topic, from a total of 784 unanswered questions. As part of the review, the authors examined the unanswered questions for ambiguity, incompleteness, or lack of concrete examples (source code, diagrams, etc.) to determine the lack of developer interaction with these questions. ments instead of answer posts. The content of these comments, in most situations, provides the author of the question with high-level suggestions on addressing the question or requests more clariﬁcation about the question. Since the volume of content permitted in a comment is restricted when compared to an answer post other Stack Overﬂow questions/answers, API documentation, and blog posts (e.g., [17]). With regards to clariﬁcations, we observe developers utilizing comments as a means to have a back-and-forth discussion for clarity on the problem faced by the developer (e.g., [4]). Additionally, in some comments, the respondents simply state that there is no solution for the developer’s issue (e.g., [6]) or is a known or reported bug (e.g., [1]). We also observe that a minority of unanswered questions are answered by the developer asking the question; the answer either appears as a comment or as an edit to the question (e.g., [7]). Finally, it The examination of these questions reveals that a majority were not ignored per se but received com- , most suggestions in comments were brief and tend to provide hyperlinks to other resources such as was interesting to note that there exist some unanswered questions that were not refactoring related (i.e., the developer misuses the refactoring term or tag in the question), showing that most of the developers understand the purpose of refactoring and its application (e.g., [2]). Hence, the majority of unanswered questions were not actually ignored by the community but responded to through comments. help in solving issues speciﬁc to the developer’s project, such as altering the standard ﬁnd-and-replace or refactoring operation for a particular purpose (e.g., [2]). We also observe that most questions around improving or implementing code reusability are often focused on identifying best practices [11], which is usually considered an opinion-based question by the Stack Overﬂow community. Such questions are often discouraged by the community as there is no commonly accepted answer and thus end up going unanswered even if they are comparatively coherent (i.e., it is clear what the author’s problem and intent were). At times, such questions are suggested to be migrated to another site, most commonly Code Review Stack Exchange Our ﬁndings show that Stack Overﬂow is a popular venue for developers to seek assistance with refactoring challenges for various technologies. Developers can post refactoring questions related to a range of technologies and artifacts, and usually receive a response in a short period of time. By performing a manual analysis of a statistically signiﬁcant set of question posts, in our RQs, we supplement our quantitative ﬁndings and obtain an accurate understanding of the challenges developers face when refactoring their systems. Furthermore, our ﬁndings empower educators to update their course curriculum to reﬂect real-world settings better. For instance, 1) instilling the need for students to practice test-driven development in projects, 2) the importance of conducting early and frequent reviews of all types of software engineering artifacts, and 3) ensuring that these artifacts capture the non-functional goals of the system (especially around readability and reusability). In this section, through a series of takeaways, we discuss how our ﬁndings support the community. While the research community has made considerable strides in refactoring related research, our ﬁndings demonstrate the challenges developers face in real-world projects. These ﬁndings highlight the gaps between the academic deﬁnition of refactoring and its actual usage in real-world settings. Furthermore, they provide the research community with opportunities to further evolve the ﬁeld. Adaptation of refactoring operations for multiple programming language and artifact types Researchers have traditionally based their refactoring studies on statically typed programming languages (especially Java). However, our ﬁndings show that while this does beneﬁt developers in real-world scenarios, there are opportunities for researchers to evolve the ﬁeld further and increase the diversity of their research. To this extent, there is a need to adapt traditional refactoring operations to support dynamic language types (e.g., Python and JavaScript), which are rising in popularity. Further, the research community should also examine the possibility of deriving refactoring operations speciﬁc to dynamic languages. Additionally, programming source code ﬁles are not the only artifacts that developers associate with quality. Our ﬁndings show challenges with improving the quality around other related artifacts such as database elements (tables, columns, queries, etc.) and test suites, which are not frequently studied in research—further highlighting opportunities to evolve the refactoring ﬁeld. Improve and extend the applicability of readability quality metrics Examining the questions’ body, we observe that most of the questions around tools were asking for , an aﬃliated site, to be better addressed. Summary for RQ. Questions around refactoring tools/IDEs are popular and challenging to answer, while questions around optimization of code snippets are the least diﬃcult to answer. Questions that do not have an (accepted) answer usually have responses from the community as comments, which are usually high-level suggestions to address the issue or a request for clariﬁcation. Our ﬁndings show that improvements to readability are a critical concern for developers. While the research community has made considerable strides in producing readability metrics and models [46,89], the community needs to better collaborate with established vendors in integrating their contributions with popular tools and IDEs to promote the usage of their artifacts. Additionally, our ﬁndings highlight speciﬁc avenues for readability research, such as optimizing/eliminating lengthy switch-case statements and conditional loops and understanding their inﬂuence on comprehension. Our ﬁndings also show that developers seek assistance with improving the readability of database artifacts, such as SQL queries and table/column names. While database vendors and the research community have provided developers with material to optimize the setup and performance of database systems, there is not much support around readability improvements to database elements. Developers speciﬁcally struggle with performing bulk renaming of database elements and improving the readability of long and complex queries. Expand the study and applicability of reusability beyond source code Along the lines of readability, developers also seek assistance with improving reusability, and like readability, the reusability assistance is not limited to source code. In addition to removing duplicate code from source code, developers also seek assistance with improving the reusability of database queries. To this extent, the research community should investigate refactoring at an architectural level to provide developers with information and recommendations around the structure of their codebase to improve reusability. Furthermore, there is also an opportunity to conduct research around reusability metrics and models for database artifacts. Like the research community, tool and IDE vendors play a vital part in ensuring developers write and maintain quality code. Hence, there are speciﬁc ﬁndings from our study which vendors can utilize to enhance their tools/IDEs. Our study shows that developers either mention the IDE/tool when providing context to their problem or ask questions speciﬁcally around the IDE/tool. Automatic synchronization between project artifacts. We observe a trend that while source code is central to refactoring, developers struggle with updating other artifacts (e.g., test cases, databases) due to refactoring of the source code. For instance, a single production method can be evaluated by more than one test method. Hence, refactoring of production code can result in multiple updates to the test suite. Likewise, renames to database tables/columns should cascade to SQL scripts and the data access layer in the source code. To this extent, IDE’s should provide users with the ability to either synchronize refactorings across artifacts automatically or at the very least recommend refactoring opportunities in the related artifacts. Enhanced rename refactoring functionality. Our ﬁndings show that as most questions revolve around renames, IDE/tool vendors should consider incorporating the rename refactoring work by Peruma et al. [81,79], Liu et al. [65], Arnaoudova et al. [36], and Allamanis et al. [25] into their products to better provide developers with an automated approach to identifying, appraising and suggesting high-quality identiﬁer names. Enhance the user experience. In addition to providing extensive and innovative refactoring functionality in their tools/IDEs, vendors must ensure that their products also exhibit an optimal user experience. Usability and trustworthiness are an essential part of refactoring tool adoption and are among the reasons for the lack of usage [71,52]. Our study corroborates these ﬁndings where we observe developers requiring help to conﬁgure tools or ﬁnding a tool for a speciﬁc purpose. Developers can also utilize our ﬁndings to ensure they follow a disciplined approach to software implementation. Our ﬁndings can be incorporated into the project’s software development process as checklists/guidance that developers need to adhere to before certiﬁcation of a release/deployment. Organizational managers can also utilize our ﬁndings to ensure that their development team is trained in the necessary skills required for refactoring and has access to the appropriate tools. Extend coding standards utilized in projects to support naming standards for all project artifacts. While it is common for project teams to utilize organizational or technology-speciﬁc coding standards, teams should ensure that the standards in use apply to all types of project artifacts utilized in the project. For instance, while general standards deﬁne the naming standards for source code identiﬁer names (e.g., method names should begin with a verb), they do not deﬁne the naming standards for database table/column names. Furthermore, teams should also be made aware of the concept of linguistic anti-patterns [35] and how to detect and correct such occurrences in the code [78]. Integrating code quality tools into the build process for the early detection of poor coding practices. Using code quality tools (e.g., code/design smell detectors [24]) during implementation will supplement the review tasks by automating the time-consuming task of detecting poor-programming practices (e.g., duplicate code, poor identiﬁer naming, high cyclomatic complexity). Furthermore, there should be necessary checks in the project’s process to ensure that developers can only ignore speciﬁc quality rules after providing valid justiﬁcation. Perform frequent and early peer-reviews on all project artifacts. Peer reviews should not be limited to source code. Other artifacts such as architecture/design documents, test suites, and database artifacts should also undergo peer-reviews. Early reviews of such artifacts will ensure that the implemented system meets its non-functional goals. For instance, code reviews will help address readability issues before it accumulates to be a serious concern. Architectural and design artifacts will ensure that the system follows appropriate design principles, such as addressing reusability and modularization. Likewise, reviews of database queries will help in addressing readability and performance issues. Furthermore, these database-related reviews will also help to ensure the extent to which business logic is contained within SQL scripts (i.e., stored procedures) versus in the source code. This section discusses the threats that may potentially impact the validity of our study. We group the treats into three categories– Internal, External, and Construct [107]. Internal Validity: These are factors that inﬂuence our results. We constructed our dataset by extracting and analyzing questions with the ‘refactor’ tag or contain the term ‘refactor’ in the title. There is the possibility that we may have excluded synonymous terms/phrases. However, even though this approach reduces the number of posts in our dataset, it also decreases false positives. Our approach ensures that we analyze posts that are explicitly geared towards refactoring challenges faced by developers. In other words, these are posts where developers were explicitly considering a refactoring action and were aware that they were attempting refactoring. Additionally, as the goal of this study is to understand the refactoring challenges faced by developers, our analysis is focused on the questions posted by developers. As with similar studies, our study is limited to analyzing only the most recent version of a post. Our analysis also does not take into account comments associated with a post, as comments are not considered as answers; comments in Stack Overﬂow are considered as temporary “Post-It” notes, and not every user has the privilege of creating a comment External Validity: These are factors that impact the generalizability of our ﬁndings. Even though there are several technology-based question and answer websites, our scope (and analysis) focuses exclusively on Stack Overﬂow– the largest such site on the Stack Exchange network of computer programming topics. Furthermore, from RQ refactoring question and answer posts asked and answered by a diverse set of developers relating to various technologies. Additionally, the SOTorrent dataset, containing the Stack Overﬂow dump, has been widely used in similar knowledge sharing based studies. While we recognize that developer surveys/interviews are also viable mechanisms to study refactoring challenges, our study captures questions posted by 7,795 distinct Stack Overﬂow users. Furthermore, our ﬁndings provide either a starting or comparison point for future participatory-based research. Finally, while it is true that our ﬁndings capture the state of refactoring at the time we conducted our study, our results present snapshots of the data, which future studies can leverage to examine (e.g., via replication-based studies) the evolution of the ﬁeld and also the state of Stack Overﬂow. Construct Validity: Here we identify the extent to which our experiments are designed to measure what they are supposed to measure. For RQ’s that involves a qualitative analysis (such as annotations), we manually analyze a sample set of posts. However, these samples are statistically signiﬁcant and followed a peer-review process to counter any bias in annotating. Further, since the review process involved a discussion between the annotators for each conﬂicting annotation, there was no need for calculating the inter-annotator agreement as the ﬁnalized dataset was conﬂict-free. The use of LDA in our topic modeling algorithm can be considered as a threat. However, as mentioned in the RQ (Section 4.2.3), this algorithm has been heavily utilized in similar studies. Furthermore, our selection of ﬁve topics is based on our analysis of ﬁfty topics (in increments of one); our analysis included evaluating topic coherence, perplexity score, and visualization. Additionally, we also manually review a statistically signiﬁcant sample of questions associated with each of the ﬁve topics. Finally, even though we utilize the Pearson correlation coeﬃcient to measure the relationship between variables, there are other statistical measures, such as Cohen’s d and ANOVA, which can also be applied to the data. Software refactoring is an essential activity in the maintenance and evolution of software. However, given the complexity of a system and the experience of the developer maintaining the system, performing refactoring operations can prove to be challenging. Hence, developers usually seek assistance from the community through question-and-answer websites such as Stack Overﬂow. by developers on Stack Overﬂow. Our quantitative approach involved applying statistical measures on the mined data, while the qualitative analysis involved a manual review of a statistically signiﬁcant sample of questions. Our results show that Stack Overﬂow is a popular online resource for developers to seek assistance with refactoring challenges. Our ﬁndings show that while most developers seek assistance with traditional statically typed languages (speciﬁcally Java and C#), there is a growing increase in refactoring dynamically typed code such as Python and JavaScript. Looking at the topics developers need assistance with, we observe that most questions are around optimizing source code to improve readability and reusability. However, source code is not the only artifact that developers refactor. Other artifacts, speciﬁcally databaserelated elements, are also subject to refactoring. Furthermore, developers ﬁnd it challenging to propagate refactoring changes between related project artifacts. Tools are also a popular discussion topic among developers, speciﬁcally around the renaming of content within non-source code ﬁles and advanced refactoring automation. From our ﬁndings, we highlight a series of actionable takeaways for relevant stakeholders that will evolve the ﬁeld of refactoring and improve developer productivity. developers from both open-source and industry. The survey will explore their general and speciﬁc challenges when performing refactoring activities; this includes (but is not limited to) software engineering artifacts, tools, and technologies associated with refactoring activities. This survey will complement and validate our current Stack Overﬂow study to provide the software engineering community with a more comprehensive view of refactoring practices. We would like to thank the reviewers at ESE for their detailed and invaluable feedback. In this empirical study, we perform a quantitative and qualitative analysis of refactoring questions asked For our future work, we plan on conducting a structured survey with both junior and senior software