GE WANG, Department of Computer Science. University of Oxford, UK JUN ZHAO, Department of Computer Science. University of Oxford, UK MAX VAN KLEEK, Department of Computer Science. University of Oxford, UK NIGEL SHADBOLT, Department of Computer Science. University of Oxford, UK Parental control apps, which are mobile apps that allow parents to monitor and restrict their children’s activities online, are becoming increasingly adopted by parents as a means of safeguarding their children’s online safety. However, it is not clear whether these apps are always benecial or eective in what they aim to do; for instance, the overuse of restriction and surveillance has been found to undermine parent-child relationship and children’s sense of autonomy. While previous research has categorised and taken inventory of key features of popular parental control apps, they have not systematically analysed the ways such features were designed or realised in such apps, or in particular how aspects of such designs might relate to parents and children’s experiences with such apps. In this work, we investigate this gap, asking specically: how might children’s and parents’ perceptions be related to how parental control features were designed? To investigate this question, we conducted an analysis of 58 top Android parental control apps designed for the purpose of promoting children’s online safety, nding three major axes of variation in how key restriction and monitoring features were realised: granularity, feedback/transparency, and parent-child communications support. To relate these axes to perceived benets and problems, we then analysed 3264 app reviews to identify references to aspects of the each of the axes above, to understand children’s and parents’ views of how such dimensions related to their experiences with these apps. Our ndings led towards 1) an understanding of how parental control apps realise their functionalities dierently along three axes of variation, 2) an analysis of exactly the ways that such variation inuences children’s and parents’ perceptions, respectively of the usefulness or eectiveness of these apps, and nally 3) an identication of design recommendations and opportunities for future apps by contextualising our ndings within existing digital parenting theories. CCS Concepts: models; Empirical studies in HCI. Additional Key Words and Phrases: Children online safety; parental controls; mobile apps; parental mediation ACM Reference Format: Ge Wang, Jun Zhao, Max Van Kleek, and Nigel Shadbolt. 2021. Protection or Punishment? Relating the Design Space of Parental Control Apps and Perceptions About Them to Support Parenting for Online Safety. Proc. ACM Hum.-Comput. Interact. 5, CSCW2, Article 343 (October 2021), 26 pages. https://doi.org/10.1145/3476084 • Human-centered computing → Walkthrough evaluations;HCI theory, concepts and 1 INTRODUCTION Children are spending an unprecedented amount of time online each day via their smartphones and tablets. In the UK, for instance, 96% of children aged 5-15 are online, and more than half of ten-year-olds have their own smartphones or tablets [ essential enabler for children to learn, have fun, and grow—-especially during a pandemic—there are, of course, signicant risks associated with children going online, especially as they engage in new digital activities [ time [ content, among others [ risks, a new genre of apps, known as parental control apps have emerged. These tools are designed to act as technical mediation support for parents to facilitate access to, and control over, their children’s online activities as a means of protecting them from such harms [ rapidly grown in popularity over the past few years. The global parental control software market is anticipated to grow from $1.52Bn USD in 2017 to $2.53Bn USD by the end of 2023 [1]. This rapid adoption and increasing reliance on parental control apps has raised corresponding questions about their ecacy — how such apps t into existing parenting strategies, and the eects such apps are having on parents and their children. Only a few empirical studies of these apps have thus far been conducted, and have started to reveal some shortcomings of these apps. Wisniewski et al. (2017) [ analysis of features of 75 popular parental control apps for teenagers. A following-up analysis of reviews on these apps by children found many reasons they disliked parental control apps, including the ways they overly restricted them and disenfranchised them of autonomy and privacy, but also identied positive aspects, such as for managing screen time and keeping them from harmful content [ control apps not just towards supporting more eective parental mediation, but ensuring that such measures do not inadvertently introduce new harms or take away valuable opportunities and benets of digital environments for children. To understand where and how such improvements might be achieved, we used Wisniewski et al. (2017) [ Android parenting control apps to examine how features on the current app market maps to the TOSS framework, and then we further analysed the ways these features were specically realised. We found three primary axes of feature variation relating to granularity, which refers to the level of control an app enables parents to do or the level of information given to the parents, feedback/transparency, which refers to the dierent designs that support varied level of information given to the children, and nally parent-child communications support, which reect how apps supported or stimulated discussions between parents and children about their online activities. These axes of variation oer an orthogonal way of organising the current parental app design space in comparison to TOSS, allowing us to focus on the dierent designs used to support each function. To then understand how each of these axes relate to how apps eectively support or create problems for children, we conducted a thematic analysis of both children’s and parents’ reviews regarding how their perceptions varied across the ways features were implemented. The contributions of this paper are threefold, as follow: 1) rst, it extends Wisniewski and Ghosh’s [ an understanding of how parental control apps realise their functionalities dierently along these three axes of variation, 2) second, by relating such axes to positive and negative reviews of apps, we identify how the design of features may inuence children’s and parents’ perceptions of them, and nally 3) we identify gaps in the current parental control app design space, contextualising 53,70,73], as well as more direct risks including cyber bulling, inappropriate or harmful 75] derived a Teen Online Safety Strategies Framework (TOSS) and applied it for an 75] as the baseline for our research. In this paper we rst analysed 58 popular 75] TOSS framework by introducing three orthogonal axes of variation, which contributes our ndings to digital parenting theories. From this, we derive at least two approaches that more autonomy-supportive parental control apps might be achieved. The rst, by simply designing app features to fall along each of the three axes within our identied “zone of best practice”–designs perceived most positively by both parents and children. Second, to complement and pair restriction and monitoring features in an age and skill-appropriate manner, e.g. to gradually allow children to move from strictest monitoring and restriction features to gain more autonomy as they develop necessary skills associated with recognising and mitigating online risks, and to prioritise the use of verbal agreements, thus reframing the use of restriction and monitoring features as a means of scaolding children’s online skills. 2 RELATED WORK 2.1 Children’s Online Safety Children’s online safety has been a broad topic that is closely related to our research. Livingstone et al. [43 as participant) and conduct (child as actor), in which children may experience online risks of four types - aggressive (violent content, harassment, and hostile peer activity), sexual (pornographic content, sexual abuse online, ‘sexting’), values (hateful content, ideological persuasion, potentially harmful user-generated content) and commercial (embedded marketing, personal data misuse, copyright infringement). Similarly, the UK Online Harms White Paper [ of online harms as explicit harms (e.g. harassment and cyberstalking), harms with a less clear denition (e.g. cyberbullying and trolling), and underage exposure (e.g. inappropriate material). A survey done by Ofcom in 2019 showed that data-related harms (e.g. data collection in obscure ways), security harms (e.g. scams/fraud) and content/contact harms (e.g. oensive language) were the most commonly reported online harms experienced by children [54]. Children’s online safety has become an even more critical issue when it comes to their mobile online safety, due to the ubiquitous nature of mobile devices. Existing online safety problems including stranger danger, online inappropriate content, bullying problems have been amplied. Children now have instant access to the internet [ harder for them to keep track of their children’s online activities when their children were using devices of their own [ age. In their initial years (3-5), children’s mobile use are still mainly adult-guided. Several studies indicate that it is not uncommon for parents to rely on technology to keep their children busy or entertained, regularly using a smartphone to replace babysitting [ stage do not always understand the dierence between fantasy and reality [ children (6-11), they are gaining increasing independent use of devices [ stage are learning about the complexities of relationships and becoming socially more sophisticated. Contacting their friends through mobile devices become an essential part of their lives, due to the need to t in and be accepted by the peer group [ ‘tech tantrums’ - reward loops and auto-plays make it dicult for them to manage their online usage because their evolutionary biology (need to react) is exploited by random rewards and interventions [3]. For children between 12-15, phone becomes a key social information and education tool. They start to become more heavily involved in social media platforms through their devices. A recent report showed that by the age of 13 already (the minimum age to open an account on many social media platforms) , more than half of them have a social media prole [ at this stage are undergoing signicant neuro-psychological changes, leading to dierences in how they perceive emotions and make decisions [ by the content they see as they tend to be characterised by idealism, with a tendency towards ] categorised the dierent types of online risks under content (child as receiver), contact (child polarised thinking [ mobile platforms, only with risks becoming even more exacerbated and pervasive. 2.2 Theoretical Frameworks For Children’s Online Safety Safeguarding children during their use of technologies has been a long concern for parents. With more of these theories being embedded in technical designs and empirically evaluated, we are seeing a transition of focus from the parent-centred approach that emphasises on restrictions and family rules, to the more child-centred approach that encourages self-autonomy and empathy. 2.2.1 Parental Mediation Theory: From Pre-Internet Era to Digital Parenting. The basis of work focusing on ways that parents can regulate their children’s media habits is grounded in parental mediation theory. Pre-dating the Internet era, the focus of parental mediation was on children’s TV consumption [50, 71] and how parents can prevent or mitigate harmful eects of children’s exposure to increasing amounts of TV content, in particular, that containing violent and inappropriate themes. It set up three mediation strategies: restrictive mediation, setting rules and regulations about children’s television viewing, co-view, simply watching television with children, and active mediation, or talking with children about the content they saw on television. With increasing concern over risks beyond media exposure, parental mediation theory has been adapted to incorporate these broader concerns regarding children’s online safety. It was refocused to the goal of minimising online risks in general while maximising opportunities for children [ required considerable renements to the constructs of existing theories. Restrictive mediation, for instance, was recast to refer to parents setting the family’s rules and boundaries around online activities. While the restriction of television media consumption was relatively easy as parents can take guidance from television program classication [ more eort from parents as it involves a great more of diversity. This modern version of restrictive mediation now also includes some technical means, such as using software restrictions to limit access to content or screen time [ nication and refers more specically to parents’ active eorts to guide, interpret, and discuss online harms and risk copings with children [ strategy - monitoring children’s activities online. 2.2.2 Teen Online Safety Strategies Framework (TOSS). The TOSS (Teen Online Safety Strategies Framework) proposed by Wisniewski et al. [ between a parent-centred and a child-centred mediation approach, see Figure 1. TOSS is a theoretically derived conceptual framework of teen online safety strategies, comprised of two main strategies - parental control, which was originally derived from parental mediation theory; and teen self-regulation - the framework extends the mediation theory by introducing a complementary set of strategies centred around the child/teenager orientated around teen self-regulation. As shown in Figure 1, the parental control strategies contain three sub-strategies, including monitoring, restriction, and active mediation. The teen self-regulation strategies comprised selfmonitoring, in which children self-regulate their behaviors through self-observation; impulse control, which refers to children exhibiting their short-term desires in favor of the long-term consequences; and risk-coping, dened to be a self-regulatory process that occurs after one found themselves in risks, which typically involves processes such as problem-solving, advice-seeking and acquiring social support. Although originally developed for analysing teen online safety strategies, the TOSS framework is equally valuable for analysing children online safety strategies, especially the parental control side of the framework. Furthermore, the framework provides a useful way for analysing parental control apps practices. In the original paper the framework was proposed, the authors used the TOSS framework to analyse features that support parental control strategies and teen self-regulation strategies [ through monitoring and restricting teens online. The framework provides the conceptual basis of our work here, which relies on both Parental Mediation Theory and TOSS. In particular, we used the TOSS framework as the baseline for our app analysis. Fig. 1. How parental mediation theory changes through the digital age and how it connects to the TOSS framework 2.2.3 Mediation Strategies: A Dynamic Process. Both the parental mediation theory and TOSS categorised the online safety strategies into distinct types. Previous research argued that the parental mediation theory tends to address restriction, monitoring, and active mediation strategies independently of each other [ mediation type should be signicantly better or worse than the others. They instead found that parent-child conicts depend more on the styles in which parents provide mediation, regardless it’s restriction, monitoring, or active [8, 72]. For example, Valkenburg et al [72] suggested that active, monitoring or restrictive mediation strategies are not in themselves good or bad; their eectiveness may depend on the style in which parents apply these strategies to their children. Examples of such styles were adapted from a self-determination theory viewpoint [ pressuring children to think and behave in certain ways through, for example, guilt induction or criticism [ child’s feelings and perspective seriously providing a convincing rationale for behavioural requests and rule-making” [ acquiesce to their children [20]. Similarly, studies on families showed that parents do not use active and restrictive mediation strategies independently of each other. Instead, parents who were motivated to play an active part in their children’s online activities also tend to implement monitoring and restriction through various active ways [ may be better conceived as a dynamic process that should integrate into the daily interactions between parents and children, rather than as a set of distinct strategies implemented separately [68]. 2.2.4 Online Safety as Skill Development. Parental mediation theory can be dated back to developmental psychology research in the early 20th century on how children’s developmental could be guided by interpersonal communication [ 75], and they found that the apps strongly favored features that promote parental control 20]; or autonomy-supportive, which refers to “structure and guidance but takes the Bandura’s social learning theory [ involvement may mitigate the negative behaviour of children. There has been another line of work that also originated from interpersonal communication studies, but place at the center of the investigation the children and their interactive experiences with adults. Vygotsky [ children’s potential for cognitive development using the term ‘zone of proximate development’. This ‘zone’ describe the things that’s beyond the children’s current capabilities, but is ‘just about’ to be grasped by them as long as they are given sucient ‘scaolding’ - guidance and support from more knowledgeable others. A survey of 215 parents and their teens showed that increased parental control was associated with more (not fewer) online risks [ of 18 U.S. families with children ages 5-11 found that children largely relied on their parents for online risks support, and parental scaolding via conversations and interactions was an essential part of their rick coping skills development [ UK showed children were well capable of grasping the key ideas of online risks and develop coping skills, when sucient scaolding is given [78]. 2.3 Parental Control Apps For Children’s Online Safety With the increase of digital technologies in families’ life, parental controls mobile apps are commonly used by parents to mediate their children’s online usage. Research has been trying to assess how eective these apps are for safeguarding children online. A review of 75 parental control apps [ showed that restriction and monitoring approaches were most common across the commercial market of these parental control apps. A further study on users’ perspectives found that children mainly felt these apps were overly restrictive and invasive of their privacy and negatively impacting their relationship with their parents [ patterns of parent’s reviews versus children’s reviews on parental control apps and found that tensions were more likely to occur when apps failed to solve problems regarding children’s safety [4]. Apart from users’ perceptions, existing literature also suggested there are signicant privacy concerns around these apps. In a study done on 46 parental control apps, researchers found that 72% of them share data with third parties without mentioning their presence in privacy policies [19]. Following these understandings, researchers are beginning to explore new ways to enable this safeguarding. For instance, Ghosh et al. [ that integrates positive family values and aims to strike a balance between teen’s privacy and their online safety. Hashish et al. [31] designed We-Choose, a tool for controlling content on the smart tablets for children between six to eight years. It supports collaborative rule-setting by facilitating discussion on the appropriateness of apps and helping children to review their choices . Ko et al. [33 both parents and children to participate in co-learning of digital media use. However, we still lack a systematic understanding of how various parental mediation theories are currently realised or designed in the commercial market. 3 METHODS We used two pipelines to explore our research questions (see Figure 2), to analyse app feature designs and their app reviews. Through this, we wanted to review how parental control is currently realised to identify gaps in the market and further see how these features are perceived by users. We particularly aligned our app feature coding with the qualitative feature analysis conducted by Wisniewski et al. in 2017 [ and led to an identication of 42 app features (e.g. website monitoring, or app activity blocking) that are mapped to the TOSS conceptual framework (see Figure 1). Our methodology was based ] developed FamiLync, a tool that facilitates participatory parental mediation by encouraging on and extended the work by Wisniewski et al [ app data acquisition and then introduced particular analysis about how each of the feature was realised in the current apps. Our intention to replicate here was not just to establish a baseline for our further analysis but also because replication is especially valuable in HCI to analyse quickly evolving phenomena, especially the design of mobile apps. Fig. 2. Our methodology: we started by replicating the method by Wisniewski et al [ as baseline for our analysis. We then extended our data analysis beyond their methodologies by 1) analysing how the app features are realised; and 2) conducting a thematic analysis on parents’ and children’s reviews of these features in order to identify their positive v.s. negative perceptions. 3.1 Collecting Apps In July through August of 2020, we sought to identify popular Android parental control applications (“apps”) that promote children’s online safety on Google Play. In order to eectively compare our analysis with Wisniewski et al.’s [ keywords (since our research focused on children instead of teens, we replaced the words “teen” and “adolescent” with “child”). We performed keyword searches using the terms “online safety,” “family safety,” “child safety,” “child online safety,” “parental controls,” “parental monitoring,” “child monitoring,” “cyberbullying,” and “sexting.” Similar to the original method used by Wisniewski et al [75], we also included all ‘similar apps’ that were suggested by the search results, and read each app description & app screenshots to ensure returned results met the inclusion criteria, which was that the app had to be designed to support the parental mediation of children’s online activities. We generated an initial list of 241 apps. During our process of nding and ltering through these apps, we found that the popularity (in number of downloads) of these apps assumed a long tail distribution: nearly 80% of these 241 apps had fewer than 20 downloads, while the more popular apps had multi-thousands of downloads. Since our intentions were to examine features and design elements in the most popular apps, we kept the top 66 apps with at least 10K+ downloads. Among these 66 apps, we further removed the following: three that required subscriptions to use, two that required SIM cards (which was not installed on the test device), and three focused on parental control of IoT devices. Our nal app list included 58 apps. Out of these 58 apps, only 27 of the apps were identical to Wisniewski’s original app list in 2017. The full list of apps can be found in Appendix. 3.2 Analysing App Features In analysing apps, our goals were twofold: to identify key features that these apps have, and, second, to identify whether such apps varied in terms of the ways that such features were realised. We rst generated descriptions of app features by applying a walkthrough method [ playing as a parent and then as a child using the app. This method is similar to the more commonly used cognitive walkthroughs (CWs) in usability evaluation [ by-screen navigation through each app, role-playing as a particular kind of user. However, there are two important dierences: unlike cognitive walkthroughs, our objective was not to identify usability problems, but to identify and descriptively characterise the features of each app. Second, instead of starting with extremely concrete tasks, we started with the goal of approaching each app as a methodical new user might, trying all features provided and systematically exploring their options. To do this, we installed each app on our devices, in turn. For parenting apps that came in pairs (corresponding to a parent child version), we installed the parent app on an Android tablet, and the corresponding child app on an Android mobile phone. For those apps that were singular apps, we set up the app in parent mode on the tablet, and installed set up the app in child mode on the mobile phone. The tablet used for analysis was a Huawei MediaPad M5 with 32GB of storage running Android 9 and the phone we used was a Samsung Galaxy S20 with 16 GB of storage running Android 9. Then, two researchers role-played a parent and then a child, on each respective app, walking through the app a screen at a time to identify features each app provided. Each feature was examined to identify all options and functionality. Then, a short textual description was generated for each. 3.2.1 Identifying Distinct Features Using TOSS Categories. - We rst analysed these descriptions using a “top-down” approach, applying the codebook from Wisniewski et al [ focused on teen self-regulation, we felt it still appropriate as a starting point for two reasons; rst, most such apps did not explicitly designate use by teens only (vs younger children); second, the emerging literature on online safety of younger children suggested that establishing safetyrelated skills and self-regulation was increasingly pressing in children’s younger years due to their increased activity online [ the TOSS framework as self-regulation strategies for all children [ feature description against the TOSS feature codebook. If a particular feature did not correspond to an existing code, we made a note with a description of its functionality and added it as a new separate feature into our code book. Cohen’s kappa was calculated to be high ( out sample of 20% of the apps. 3.2.2 Feature Design Analysis. - To explore feature variation, we revisited the feature descriptions and performed a second round of coding, focusing on how features was realised. This analysis phase was, again, performed by two researchers who sub-divided the apps. Codes were reconciled, rened, and combined, and then anity-clustered based on across all TOSS strategies. This process yielded 22 clusters corresponding to three axes: 6 along granularity, 8 along feedback/transparency, and 8 along parent-child communications support, as we describe in detail in Section 4.2. 3.3 Collecting App Reviews The second analysis pipeline focused on app user reviews; to complement our app analysis, we sought to collect user reviews of each of the 58 apps to understand users’ opinions. We scraped all reviews for 58 apps (including the child app versions) using open source scraping tools [ This resulted in an initial data set of 93,404 reviews from all 58 apps. Duplicate reviews were then removed, yielding 81,488 reviews. 3.3.1 Selecting app reviews pertaining to specific features. Due to the immense number of reviews being spams, irrelevant, or simple statements without justication like “It’s good”, we sought to keep only user reviews that expressed a view about specic TOSS features justication. Thus, we developed the NLP pipeline to achieve this. Our pipeline was based on that by Guzman et al. [ was done to only keep the nouns, adjectives and verbs in the reviews. We then used the bigram nding algorithm provided by the NLTK toolkit [ features (A bigram is a two-word phrase that co-occurs unusually often). We ltered the bigrams by only considering those that appeared more than ve times and had less than three words distance between them. We then clustered bigrams whose pairs of words were synonyms using Wordnet [ (identied in Section 3.2.1). For example, both bigrams clusters <limit time> and <limit screen> would belong to the SCREENTIME-BLOCK feature, which is about limiting screen time. This gave us an indication whether an app feature was indeed discussed in a review, and hence made it a potentially ‘meaningful’ review. We then traced back to the original reviews where these bigrams that can be mapped to a TOSS app feature were extracted from. The author then went through all of these reviews to manually verify that the corresponding TOSS feature was indeed mentioned in the review, remove any inconsistent ones and the ones not about a specic feature. We ended up with a review data set consisting of 3,264 reviews in total. To identify perception dierence between children and parents, we used a similar method to Ghosh et al [ parents and children respectively. Examples indicating a child’s perspective included: “my parent”, “my mom”, “my dad”, “I’m a kid”, “I’m xx years old”. The two authors manually reviewed the automatically generated results. Out of the 3,264 reviews, we identied 746 child reviews and 2,518 parent reviews. We now have a data set consisting of review around each TOSS features, from children, and parents, respectively. 3.4 Analysing App Reviews We conducted a thematic content analysis on the nal ltered set of reviews to identify what perspectives parents and children hold in terms of the apps and their features. So far, the review dataset has been labelled with the TOSS app feature (e.g. monitoring website) discussed by each review (for ltering meaningful reviews), and the type of user contributing the review (parent vs. child). Here, we would like to rst identify the feature designs discussed in each review, and then analyse the perceptions from parents and children about each feature design — positive or negative. First, the researchers used a top-down approach to read through each review to categorise reviews around feature designs (i.e. how a feature is implemented) we previously compiled in Section 3.2.2. Then, for reviews around each type of feature designs (e.g. ALL-OR-NOTHING), we used a grounded, thematic approach [ disliked that feature design. (The nal codebook for reviews data can be found in Appendix) The thematic coding process was performed by two researchers who sub-divided the reviews. The hold out sample was 50 reviews (roughly around 35%) for each feature design (e.g. coarse granularity, low feedback/transparency), with a Cohen’s kappa of 0.77. 47]. After that, we manually reviewed each bigrams cluster to map it to each TOSS feature 23]. This means that we also used certain keywords and phrases to identify posts by Fig. 3. Comparing our TOSS feature analysis results with Wisniewski 2017. We found that in practice, active mediation features were oen grounded in monitoring and restriction features; Also, restriction and monitoring features came in a great variety of details that was not captured by TOSS (*Previously TEEN SELF-REGULATION in Wisniewski 2017 original code book) 4 RESULTS 4.1 App Feature Analysis Applying the TOSS framework [ supported both Monitoring and Restriction strategies. Figure 3 juxtaposes the number of occurrences of such features we found in our 58 apps against those reported in the original TOSS paper [ As visible in the gure, the prevalence of restriction and monitoring features in apps generally increased compared to the original analysis, suggesting that parental control apps have become more featureful since 2017. Moreover, we identied several new features for supporting Active Mediation than in the original study. This includes providing information about apps to help parents decide whether an app is suitable for their child ( technology usage rules together ( 3. In terms of teen/child self regulation, we found several features supporting Self-Monitoring, including sending reports to children regarding their mobile usage ( activity logs to children ( LOG-C meaningful Risk-Coping strategies (apart from sending SOS requests). During the analysis process, we found considerable variation among the designs of how the features that belonged to a single code were realised. For instance, among apps that oered functionality logging children’s app usage ( of the child’s activities within, and across, particular apps, whilst others only logged events of a specic type, such as ‘suspicious activities’. This variation was what inspired us to examine the design axes of variation which we describe in section 4.2. ).In line with prior work, we did not nd any features belonging to Impulse Control, or any Third, we found some features supporting child-empowerment that did not correspond to any of the three existing TOSS strategies for self-regulation. Examples included features designed to provide a means for children to inspect their restriction/monitoring policies ( well as features that oer children with detailed information about an app, enabling them to decide what app to use for themselves (APP INFO-C). Finally, with respect to app features supporting Active Mediation, we found that rather than being standalone, such features were often contextualised within other restriction and monitoring features. Examples included messaging features that let children request more screen time, or access to a restricted app. Like these, most forms of mediative support concerned restrictions or monitoring activities. Another type of support included interfaces that encouraged parents to collaboratively discuss and negotiate restriction and monitoring policies with their child (CO-CONFIG), instead of encouraging parents to set such policies without their child’s involvement (e.g., BLOCK was most often associated with tips around restriction or monitoring strategies. 4.2 Feature Design Variations When looking at how features are specically realised we identied that they fell into three axes of variation, including granularity, which refers to the level of control an app enables parents to do or the level of information given to the parents, feedback/transparency, which refers to the dierent designs that support varied level of information given to the children, and nally parentchild communication support, which reect how apps supported or stimulated discussions between parents and children about their online activities. These axes of variation oer an orthogonal way of organising the current parental app design space in comparison to TOSS, allowing us to focus on the dierent designs used to support each function. We identied 6 feature designs along granularity, 8 feature designs along feedback/transparency, and 8 feature designs along communications support that reported that variation of designs of TOSS features, as summarised in Figure 4. 4.2.1 Axes 1: Granularity. We observed that the level of control/information provided by apps for the parents spanned from very coarse level of granularity, e.g. control/monitor based on an ALL-OR-NOTHING highly granular feature designs including allowing parents to congure control/monitor on a per app basis (CONTROL/MONITOR-PER-APP). (1) ). Even (PARENTING-TIPS), the closest to being a standalone active mediation feature, (Coarse) ALL-OR-NOTHING : This is a most widely supported design (appearing in 40% of all apps) that spans across all TOSS features. Parents had to either block all contents and request access to every detail (e.g., every video watched, website visited, the apps opened, even logging google search &keyword queries.) about children’s online activities, or gaining no access about children’s activities at all, leaving no middle ground in between. (Medium) CONTROL-CATEGORY/AGE: In comparison to the all-or-nothing approach, this category allows parents to control children’s access based on app/website categories. Such “dangerous” activities, messages, or content. (6) 4.2.2 Axis 2: Feedback/Transparency. By feedback/transparency, we refer to the designs (specically of monitoring features) that support variation of the level of information given to children. While being closely related to the self-monitoring strategies in TOSS framework, this axis extended and enriched it by adding design variation details and discussed designs that supports children’s autonomy online. The variation of these designs ranges from very low feedback/transparency - providing no information on the screen rules and things being monitored, to high feedback/transparency supporting children with resources (e.g. expert reviews, ratings) to let them decide for themselves what to use. (6) why that might be bad for children (rather than simply terminating the activity or giving a (8) what apps to use for themselves. categories were usually derived directly from app store listings or website ratings, and seen to aord parents the convenience of setting broad policies without concerns over specic apps or websites. (Medium) MONITOR-CATEGORY: Provide only high-level summaries of activities children performed on the phone, such as a list of top contacts, apps used, and time spent on the device per day. These high-level summaries were sometimes grouped by app category. (Medium) CONTROL/MONITOR-CONTACT-LIST: At this level, parents are given a chance to provide customised control by providing a list of a pre-approved contact (or “suspicious” contact list); and when children contact people on that list, parents will be acknowledged (or showed with texts etc.) (Medium) MONITOR-SUSPICIOUS: Similarly, this control of suspicious content can be automatically achieved by apps, which report and alert parents only based on “suspicious” or (High) CONTROL/MONITOR-PER-APP: At the highest granularity of control, parents are required to congure settings on a per-app (or website) basis. (Low) RULES-NO-SHOW: A considerate amount of apps (14%) provided no indication about the restrictions enforced on children’s phones, leaving them with no idea of the things they could still do on their phones. (Low) MONITOR-NO-SHOW: Nearly a third of the apps in our data set did not acknowledge children about how their information were being monitored by their parents. (Low) ONLY-RULES-AT-MOMENT: This design shows prompts at the moment e.g. when children were attempting to access a website on blocking list. However, children weren’t informed with the screen rules in advance. (Medium) RULES-PAGE, provides a means for children to view/inspect the restrictions policies, giving them more transparency than the designs above. (Medium) MONITOR-PAGE, provides some rudimentary information to children about which activities were being monitored, such as browsing history, app use history, device use time, or messaging. (High) RULES-EXPLAINED, identied in a small number of apps reviews (6%), oers a clear explanation for children when an activity or action exceeded or violated a restriction and generic system error or a blank screen). (High) MONITOR-SELF-TRACK, provides children feedback about their activities as they used the device, such as how much time they had left (total screen time or on an app). (High) SHOW-KIDS-INFO, again identied in only 6% of all apps, oers children with detailed information of each app, including expert reviews and ratings, enabling children to decide 4.2.3 Axis 3: Communications Support. As this dimension is pertained to the ways apps supported or stimulated discussions between parents and children about their online activities, it is closely related to previously dened active mediation in TOSS framework. However, in practice, active mediation features are more about active ways in which restriction/monitoring can be implemented. This dimension portrayed the variation of such design details. This was done in two ways: rst, through features that encouraged communication around the restriction and monitoring policies, and through coaching using discussion aides. (1) (5) was suitable for their children’s use, to understand potential risks, and other issues about the 4.3 Thematic Analysis of Reviews This section presents an overview of the primary themes pertaining to the reasons children and parents, respectively, liked or disliked feature designs provided by parental control apps, and how their perspectives varied across the axes of dierent ways in which features were realised. 4.3.1 feature designs varied in granularity inuenced users’ perceptions of features. For coarse granularity, we specically refer to the features that are based on to either block all contents/shown with every detail (e.g., every video watched, website visited, the apps opened,even logging google search & keyword queries.) about children’s online activities, or having no access at all, leaving no middle ground in between. Both parents and children, children in particular, expressed grievances on these features: Disliked being overly surveilled and restricted [C] regarding parents to set up overly restrictive controls and excessive surveillance. Kids expressed resentment at the extent of both the restrictions and their surveillance, and reected on the eects lives, welfare, and activities: (Low) NO-MEANS: More than half of the apps (54%) oered no means for children to negotiate screen rules with their parents, and their only choice was to accept and obey. (Medium) SEND-MESSAGE: In comparison to the complete lack of communication support, these designs make it simple for children to send a message to their parents asking for permission to perform a particular restricted activity, or to grant an exception or extension to a particularly restrictive policy. These features have been identied in 18% of our apps. (Medium) REWARD: Provide extrinsic reward incentives for children to earn additional screen time, app categories and content, or access to ordinarily restricted activities. (Medium) BOTH DEVICE: We found one app that coach or prompt parents and children to spend time with each other, e.g., using a family time lock screen feature for both parents and children’s phones to lock both devices out for a duration of time per day to encourage both to spend oine time without the distraction of a screen. (Medium) APP-INFO: Provide specic information to help parents ascertain whether an app apps they might want to discuss. (Medium) AGE-GROUP-INFO: Help parents to compare their children’s online activities (usually screen time) in comparison with other kids of the same age group. (High) CO-CONFIG: Provide explicit support that encourages parents and children to set screen rules together, which included interfaces designed to serve as boundary negotiating artifacts [37] for a joint resolution of activity restrictions and monitoring policies. (High) PARENTING-TIPS: Oer advice to parents, include strategies ranging from how to apply restriction/monitoring policies to their children, to how to talk about sensitive issues such as bullying, stranger danger, online pornography, and sexting. Coarse Granularity. We rst start with perceptions around granularity - how dierent ALL-OR-NOTHINGwas the view that these designs not only enabled but nudged Kids reected on a variety of secondary eects of excessive restrictions and surveillance. One child discussed that they felt that, beyond violating their privacy, it was particularly wrong that their parents’ access to their messages would compromise their friends’ privacy as well: The pervasiveness and constancy of surveillance made it feel to one as if these apps enabled their parents to “stalk” them: Even when not restricted, the perception that their social communications were being surveilled by their parents had a chilling eect that indirectly forced them to cease communicating and be cut o from their friends. Several comments discussed longer-term eects such restrictions were having on their well-being. One view was that restrictions were directly and immediately harmful because they broke essential lines of social support. Beyond cutting o lines of social support, restrictions were seen to prevent kids from apps and activities that they normally used to cope with boredom and isolation, further undermining wellbeing: Beyond the social and emotional aspects of children’s lives, a few comments connected these restrictions to developmental and educational harms-namely, how such restrictions impeded learning by depriving them of experiences and learning opportunities: We don’t want to know everything [P] ALL-OR-NOTHING things while leaving them with too few choices. Parents expressed resentment in terms of wanting to be able to do more tailored controls based on children’s individual needs: With regard to monitoring features, parents showed confusion and some reported lost in the vast amount of information given by the apps: We do want to know everything [P] to know every single detail of their children’s lives, and that led on to them expressing multiple opposing views around children’s rights to privacy - whether children deserved any rights to This literally blocks everything, I can’t even read e-books on my phone. This is insane. Now they can see EVERYTHING! From my browsing history to what apps I downloaded, even my texts! Worst app ever! they can eves drop on your convos and stu that you dont want them to hear [...] not only is it a violation of my privacy that i didnt permit, but it is of friends too that parents dont know about I hate this app my mom is like stalking my life!! I can’t talk with my friends anymore, everything will be recorded! This is stupid. absolutely awful. this will ruin people’s lives. I had severe depression and the only thing keeping me from killing my self was my friend who I could only talk to online. Now I’m ne but if I lose contact with that friend I will most likely get my depression back. Horrible and stupid app. I can’t play a lot of games, and I can’t watch YouTube. I’ve sat in my room for weeks doing nothing and practically getting depressed because there is literally NOTHING I can do! The internet is where kids discover and learn new things. And by restricting it, you’re denying them that ability. You either completely stop your kids from using their phone, or absolutely no rules. It’s just so silly, don’t they know kids these days need to do homework ONLINE? I don’t want to know everything! What’s the point of showing all these location info to me? I’m not a control freak! I just want to protect him from the crazy stus online, that’s all! privacy at all. One stated that since parents were paying for the phone, they should be able to set the rules: In some cases, parents also talked about how their duty as parents to keep kids safe outweighed any claim to rights: A more lenient version of this was the view that rights to autonomy/privacy should be an earned privilege, not a fundamental right: Others viewed their children as being too young to make decisions for themselves until they become adults, regardless of their age: 4.3.2 are highly granular - for this, we specically refer to the designs that allow parents the freedom to congure apps, websites, videos on a “per item" basis ( Parents were now able (sometimes even required) to rene the specic controls/monitoring they want. Lost in choices due to lack of support [P] they’d like to be able to do more rened congurations when they mediate their children’s online activities. However, when actually oered with these choices, several of the parents’ comments expressed confusion and disappointment regarding these designs. One common complaint was that they simply don’t have the time to go through each settings one by one, and they don’t have the time to review each app to see if it needs to be banned: In some cases, parents talked about how frustrated they were as they felt they were indirectly accused as irresponsible parents, and they were “nudged” to go back to banning everything: In most cases, parents expressed their needs for supporting resources that help them make restriction/monitoring rules: 4.3.3 parents to mediate their children’s online activities, without being too coarse or requires too much eort. Designs like this includes control/monitor based on app/website categories or age ratings; or control/monitor of contacts based on a parent-pre-approved contact; or apps reported and alerted parents only based on “suspicious” or “dangerous” activities, messages, or content. Don’t listen to these spoiled children. I pay the bills. I control the phone. You want to control you pay the bills! Very very simple equation! It’s a shame how kids here actually can fathom the thought of “rights” while living in their parents’ home. Who made that joke up? When it comes to social media, kids don’t need privacy. It’s not even about the child as much as it is about others preying on them. I would hope none of the negative reviews are from parents. You should monitor everything your children do. That is our job as parents. If you want more trust privacy, prove you can handle it with good choices to show your parents you are trustworthy! It’s not that we don’t trust them, but studies show they can’t make decisions or assess risk like adults can until age 25 or so. High Granularity. The other extreme along the granularity axis is the feature designs that I’m a working mum with a full time job with three kids. Although I appreciate the app designers’ eorts in letting us make the decision. It’s just not practical for us working parents to go through all the apps one by one. I don’t see the point in letting us choose which videos for children to watch. One, I can’t sit through everything they watch, I have a job. Two, 5-year-olds quickly get bored of the old ones and they want more. This so-called “renement” just gave me two choices: either let them watch whatever they want (God knows what’s on there), or bans the whole platform. I really wish there’s something like an app version of the tv age guide. Medium Granularity. Feature designs of medium granularity oer a middle ground for Protection, not punishment: achieving a successful middle ground [P] erally positive about the apps that oer feature designs of medium granularity, and they saw achieving a successful middle ground being essential for striking a balance between protection and respect for their children. This was seen not only as convenient for parents, but also supporting setting of boundaries in a more exible manner. Similarly, both parents and children appreciated how some apps enabled dierent children, especially older ones, with dierent level of freedom: And when such balance was achieved, parents generally saw the parental control apps as eective at helping them support their primary goal, which was to keep their children safe. These parents felt such apps gave them “peace of mind”: Reasonable safe zone [C] protection and punishment, children regarded them as eective and reasonable at protecting them from dangers online: 4.3.4 feedback/transparency, and how users’, especially children’s perceptions varied across dierent designs along this axis. The designs came in various details along their ability of supporting children to have sucient feedback and transparency, thus to allow them to learn and understand the screen rules, as well as learn more about their own activities online. For low feedback/transparency, we refer to the designs that support very little or no means for children to become acknowledged of these things. Typical designs include apps provided no indication about the restrictions enforced on children’s phones, leaving them with no idea of the things they could or could not do on their phones; apps did not acknowledge children about what information of them can be seen by parents; and apps only showed prompts at the moment when children were attempting to access content, however, they did not inform children with the screen rules in advance. Insecure, and not respected[C] their dislike of feature designs that supported no feedback/transparency, which were sadly the most common feature designs. Rules without prior acknowledgment were sometimes presumed to be annoying by children. For example, both parents and children brought up that prior warnings on time remaining are important. Otherwise, children will feel upset due to the sudden cut-o. Children complained about how some app did not let them know what their screen rules were when such system was missing, and children found themselves in the position of having to work things out based on trial-and-error: In terms of monitoring, children felt insecure when not knowing what their parents can see about them: 4.3.5 includes designs not only provided children with means of viewing/inspecting the restriction policies but also oered a clear explanation on why the screen rules were made and why accessing restricted content might be bad for them. In terms of monitoring, features designs that support I love how this app allows us to reach balance. The app only alerts us when it detects something unusual, we can adjust the things he could access as he gets older. I love this app. I have a 10 year old son that I just recently found out was doing inappropriate things on the Internet with his phone, like viewing porn [...] but with this app I Have some peace of mind. I have full control of what he downloads and views [...] all form [sic] my device. Not too bad, I guess a bit boundary is necessary, at least I still have access to things I love. This is just great. It allows age-appropriate control, so giving us more freedom as we get older. Low Feedback/Transparency. A second axis of feature design variation we looked at is I constantly get these error messages with blank pages, is that part of the screen rules or just an error? Can they see all my texts too? That would be creepy. High Feedback/Transparency. Feature designs that were of high feedback/transparency high feedback/transparency include the ones that provided children with feedback about their activities (allowing children to do self-monitoring), and oered children with detailed information about each app, including expert reviews and ratings and enabling children to decide what apps are good to use for themselves. Keeping them safe and productive [C] supported children’s understanding of their online boundaries. In terms of restriction, both parents and children brought up how they liked apps oering children with clear screen rule pages so their children would be better informed instead of suering from being turned down at the moment when they were trying to do some online activities. In particular, many kids pointed out how they liked being oered with explanations on why a website/app was blocked, which made them feel less confused and more respected as a consequence: When children understood why the apps were for, they reported more positively about the apps. Several of the comments by children pointed out that the apps helped to keep them safe online from inappropriate things: Other children who suered from addiction online appreciated how the apps dragged them out of that cycle: Beyond the positive impacts online, children also appreciated how the apps helped with their time oine. Some children commented that they were now able to become more productive and spend more time with their families: Supporting them to make own decisions [C] designs that oer them with detailed information (including expert reviews and ratings) of each app. They talked about how they cherish being respected to make their own decisions on what is best for themselves: 4.3.6 communications support. Specically, we looked at how features were perceived dierently due to the variation of communications support designs they came in with. For little communications support, we refer to the designs that rst, did not oer any explanation helping children to understand their screen rules, and also, oered none or very little means for children to negotiate screen rules with their parents, leaving them with the only choice - to accept and obey. Role of Parenting Apps: Unnecessary, Punishment, or Lazy Parenting [C] pose of these apps were not communicated with children, several of the children’s comments expressed confusion or questioned the role these apps in keeping them safe. One child viewed that these apps were fundamentally redundant because they were already old enough or competent enough to keep themselves safe: Not the best but denitely better than the previous one. Now I know why the websites are blocked. They give you reasons and things like that. I mean, I disagree with them all the time, but at least they tried to show some respect! I know this may sound crazy from the kids view, but I love this now! It ts me and my phone perfectly, and my mom knows that I am safe on my phone without having to go to any other horrible apps. This is AWESOME! I’m a kid so I got this app in order to keep myself in check on my screen time because I am an internet addict. I’m so much happier now! It makes it absolutely impossible to get around! When my mom and dad put this on my phone and tablet at rst I hated it. but then I realised with a limited amount of time I spent more time with my family and do actual work. I hope this inspires you to limit yourself with the amount of time you spend staring at useless junk. They tell you what others said about this app, but let you decide to use it or not – it’s my call. No/Lile Communications Support. A third axis of feature design variation was parent-child Other kids lamented that these apps were unnecessary because kids could be told what to do and trusted to keep what they were told. In a sense, the use of apps to force represented a failure of trust. The perception that parents were not trusting them made children question the point of these apps. In some cases, children regarded the use of these apps as purely for punishment. Some children continued to criticise the bad parenting styles that these apps nudged their parents into. Apart from parents being overly-protective (as we previously reported), children also accused parents of being lazy and using the apps as substitutes for parenting. 4.3.7 came in two ways: rst, through features that encouraged communications around the restriction and monitoring policies and through coaching using discussion aides. These includes designs such as apps enabling children to negotiate their rules with their parents, apps providing explicit support that encouraged parents and children to set screen rules together, and apps oering advice to parents - strategies ranging from how to apply restriction/monitoring policies to their children to how to talk about sensitive issues. Feeling of being respecte d [C] negotiate with their parents, they felt they were part of the decision and they generally respected the rules more. In particular, they loved the co-conguration designs that allowed them to sit down with their parents to reach mutual agreement on their boundaries: Supports, rather than enacts parenting[P] towards feature designs that supported or coached them on conversations with their children. And they found designs like parenting tips particularly useful. Some parents felt that they were supported by the app without being hijacked by it. 5 DISCUSSION 5.1 Connecting Feature Designs to Parental Mediation Theory Given the potential for both detrimental and benecial eects of restriction and monitoring, and the likelihood that these strategies will remain important aspects of many parents’ mediation strategies for the foreseeable future, can we strike a balance? Specically, how might apps play a role in fostering a more responsible, considered, and appropriate use of these strategies? To answer I’m a 4.0 student. Who is able to manage her school work and screen time by herself thank you very much. I’m old enough to know what’s good and bad, I can’t change the settings and there no way to let my mom know that. How bout you try and talk to them about your phone usage rst, see if they’ll make a change for you rst, then go from there. Think twice before you destroy you kid’s trust like this. I understand there’s kids who need to get their head straight. But for those like me who are focused in school and a well-rounded kid, I feel all you need to do is talk to them. If you are a parent that wants this app I would reconsider getting this and punish your child a dierent way. Instead of us being punished, parents should be blamed for dictating their children to use this app. Yes, it’s good to be one step ahead, but having an app to do it for you? You might as well call child protective services if you’re that lazy. High Communications Support. Designs that were of high communications support mainly My parents sat down with me to go through this “setting rules together” thing, and I can send a request to them whenever I felt the restrictions are unfair. Love it! This is a great tool. Easy to communicate. Easy to adjust. I use this tool to help, but in noway does it replace being a good parent watching over their child. It should not be the only arrow in your quiver, and you should not expect it to do your parenting for you. these questions, we rst reect on whether some of our ndings related to the feature design space described in Section 4.2 might help. The three axes deal with very dierent aspects of parenting support and thus take each in turn. Starting with the rst axis, granularity was associated with the degree and detail with which parents could control and monitor children’s activities. This axis was directly related to the “restrictive mediation” from parental mediation theory [ leads to increased conicts between parents and children . Nathanson [ might exhibit more disobedience and rebelliousness against parents under restrictive mediation . Ghosh et al. [ more likely to be controlled and monitored by their parents. These previous ndings reinforce our analysis, such that a balance between restriction and children’s autonomy is much needed. The use and application of highly granular restrictions provides more exibility for the parents but they can also be seen as overly demanding - parents need to be familiar with all the apps and websites their children could possibly access. On the other hand, the coarsest (all-or-nothing) controls were generally seen as less desirable because such apps denied children access to basic, risk-free, and unproblematic aspects of their devices that they deemed essential. The former takes a parent-centric view whilst permits limited inputs from children; and the latter is a close representation of an authoritarian parental approach [ mutual trust and the development of children’s self-autonomy [ granularity” identied in this research (e.g controlling by categories) were deemed most favoured by many parents because of the simplicity such granularities aord. Such abstractions encourage slightly less parental involvement because of the way they homogenise the treatment of dierent apps in the same category; without requiring parents to be deeply involved with the particular risks, details or benets of specic apps. With respect to transparency/feedback, this axis dealt with the extent to which children remain informed of their own online activities and screen policies. By clearly establishing what was being restricted, monitored, and why, children could understand the boundaries of their parents’ control so that they could negotiate their activities within and around such barriers. As such, this axis was most directly aligned with aspects of active self-regulation [ - through empowering children with information and choices about their own behaviors online, as well as supporting resources such as information or expert ratings on particular apps, children were given the opportunity to make more responsible decisions for themselves - one of the key outcomes from an active mediation approach [ as more privacy-invasive and autonomy restrictive, making it less clear or visible when and what parents would be watching. Much like Bentham’s panopticon [ as undermining children’s rights by creating a perpetual spectre of possible observation. Regarding communications support, this axis was most closely related to the “active mediation” from parental mediation theory, in which communication is the core [ found that active mediation was associated with lower levels of aggression children [ active mediation may reduce online risks without hindering children’s online opportunities [ Kuppens et al. [ with parents were more likely to regard control/monitoring as legitimately in their best interests . While being closely related to active mediation, this axis was more than that. It dealt with providing supports for parent-child interactions in several forms; one was parental informational support, which comprised both general parenting advice pertaining to ways to talk to children about their online activities and risks, and specic information about particular apps and activities. Other support includes encouraging the co-setting of restrictions and monitoring practices, allowing 24] also found that teens who were victimized online and had peer problems were children to be involved in the conguration of such activities, and can have signicant benets in terms of how they view such activities as a result [36]. We contend that granular restrictions and monitoring support active/authoritative parenting by increasing the exibility and means by which parents can remain in-the-loop of, and control over, children’s activities. However, we argue that our nding shows that this is only true for apps which also had a high degree of transparency/feedback (axis 2), as well as high (axis 3). Such capabilities are essential for enabling children to understand restrictions, monitored activities, and goals (transparency/feedback), providing a means of understanding of the context and purpose of these restrictions, and a means of digitally facilitating discussion, negotiation, or relaxation of such policies (communications support). Without such feedback, monitoring and restrictions are most directly aligned to and detailed monitoring without associated feedback, transparency, or support for negotiation or communications. Parental mediation theory categorised parental mediation strategies into distinct types, namely restrictive, monitoring and active [ mediation as a continuous, dynamic process is supported by recent empirical and theoretical literature, including work by Symonds et al. [ as a dynamic integrative process that brings strategies into the daily interactions between parents and children. Other studies that support this view similarly found that parents tended not to use restrictive, monitoring, or active mediation strategies independently, but in ways that supported each other [ were most eective when they were implemented in an active way. Our ndings reinforced this new look of the parental mediation approaches: restrictive and active mediations are not in and of themselves good or bad; rather, their eectiveness may be highly dependent on the style in which parents apply these strategies with their children [ axes (granularity, transparency/feedback, communications support) align perfectly with these arguments - instead of considering features as separate categories, the axes of variation reect the designs on how strategic elements can be combined, and implemented in a lesser or greater extent overlapping and reinforcing each other, in an overall dynamic process. 5.2 Revisiting the TOSS Framework Our analysis oered empirical evidence that suggests that the ways in which features are designed inuence users’ perceptions of features in parental control apps. In particular, we found that parents and children’s perceptions of features varied signicantly across the three axes designs variation. For example, for a single restriction feature such as APP-BLOCK, when implemented dierently, such with features for supporting parents-child negotiation, were viewed more positively than when apps oered no such means at all. Instead of viewing app features as belonging to separate independent mediation strategies as TOSS does, we prefer to view such features as playing variable roles in mediation strategies articulated by many factors including their design. We feel that our axes of variation can be seen as an extension to the TOSS framework, orthogonal to its categorisation of features by strategy, that provides a view to the ways such features should be designed. In particular, by looking at the areas along each of the axes that correspond to the most positive comments, we can identify a Zone of Best Practice, corresponding to the regions of the feature design space viewed most positively by parents and children. For granularity, the designs that were of medium level of granularity were perceived as helping to strike a balance between protecting children online, while leaving them with enough space to learn and explore online - such designs include congurations on categorical level or age ratings, managing contacts based on a parent-pre-approved list, or only alerting parents when “suspicious” or “dangerous” activities were identied. For feedback/transparency, the most 8,44], while Chen et al. [14] suggested that mediation such as restriction and monitoring Fig. 5. Revisiting the TOSS Framework. a). The TOSS framework looks at what features are supported b). Our Axes of Variation complement the TOSS framework by adding orthogonal dimensions of how features were implemented. c). As a result, our three axes of variation allow us to identify a Zone of Best Practice, this also shows that most of the apps on the current market fall outside of this zone. welcomed designs were those that provided support for children to remain informed of their screen rules, their own activities online, and support them to make decisions for themselves online good design practices include panels that show children explicit information on their own online activities, pop ups that explain why certain screen rules were made for them, and info panels that oer children with detailed information of each app, thus enabling themselves to decide what apps to use. For communications support, the most welcomed designs were those that encourage negotiation between parents and children, and support parents with information and resources to start those conversations - e.g. co-conguration panels that encourage parents and children to set screen rules together, pop up parenting tips that oer advice to parents. Unfortunately, our analysis also found that most existing apps fell outside this zone for many of their features. 5.3 Opportunities for more autonomy-supportive parental mediation One of the major problems with restriction and monitoring is the extent to which these strategies reduce children’s autonomy and violate their privacy. How might apps be made to be more autonomy-supportive, especially in the long term? Our view is that the inherent problem with the parental control apps we reviewed is that they were focused exclusively on eective restriction and monitoring, instead of digital parenting. Instead of framing restrictions and monitoring as protective measures to be used in perpetuity, for instance, a digital parenting app might not only include support for other TOSS strategies (such as impulse control), but also re-frame restriction and monitoring as a means of skills scaolding [ (maximum restrictions and monitoring) for the very young and most vulnerable, such apps could then align the gradual removal of restrictions and monitoring measures with milestones as children get older, or demonstrate the ability to recognise and cope with online risks. Then, as their needs for autonomy and privacy needs change, typically peaking by mid-teenage years [ should probably reach a minimum at such an age. However, if children require special support such scaolds could be seen as exible as needed. Such a re-framing would address several of the children’s comments we found, especially relating to children seeing restrictions as pointless and infantilising, and supporting them as they grow older, so as to not be seen to hold them back. Another re-framing that might provide protection against overuse of restriction and monitoring is to frame such measures as options of last resort, after other more autonomy-conrming strategies fail. Primary autonomy-conrming strategies for older children might instead include, for example, simple verbal agreements about limits on online activity which require children to take responsibility for their actions. Such a shift would be in line with the literature on autonomy-supportive parental mediation, which requires a “convincing rationale for rule-making” [ requiring a convincing rationale to justify the use of restriction and monitoring features might ensure that they are used only as necessary. 6 LIMITATIONS AND FU TURE WORK There are several important limitations of this work; the rst pertains to the app analysis; our sample of parental control apps were taken only from the Android UK Google Play store, and thus may vary signicantly by region. Due to a feasibility constraints we were only able to analyse 58 of these apps, out of the massive growing pool available. The second most signicant limitation is that we based our analysis on reviews available in the wild. There are obvious limitations of trying to use reviews as “vessels of truth”; namely, they could be fabricated by bots, or, even if genuine, could represent a skewed non-representative sample of particularly angry or passionate people. We attempted to mitigate some of these possibilities several ways, one was by using a process of ltering reviews to carefully select only those discussing specic aspects of apps. Moreover, we avoided deriving any conclusions through quantitative measures which would be distorted; instead, we used reviews only to collate reasoned perspectives about features. Nonetheless caution should still be exercised using any app reviews for deriving any sort of denitive conclusions about causal relationships, for instance, relating app use to children’s welfare or safety. Our contributions thus should be interpreted as a high-level understanding of the design space of features of parental control apps, with evidence that might suggest regions most promising for further exploration. Our future work would involve actually working with parents and children to get more direct inputs. We hope our contributions could guide others navigate the space of parental control apps, for running eld studies of the eectiveness of specic feature designs. Apart from that, this work adopted a ground-up approach as well as being guided by the TOSS framework, instead of a value-driven approach. Therefore, we did not take a full consideration of the dierent cultural and parenting styles intrinsically embedded in dierent cultures and societal values, which would benet from future work. 7 CONCLUSION Parental control apps are being increasingly seen as the answer to online safety concerns parents have for their children [ with them new kinds of harms associated with excessive restrictions and privacy invasion [ This paper is the rst to contribute an understanding of the design space of the mediation features of current parental control apps. Then, to identify how such variation might articulate the use of these apps in practice, we analysed reviews corresponding to features at various points along each of the axes. Our ndings suggest that apps providing the most transparency and feedback, the greatest support for parent-child communications, and exible categories are most likely to be perceived by both parents and children in positive ways instead as punitive and detrimental. Contextualising our ndings in parental control theory, we derive at least two approaches that more autonomy-supportive parental control apps might be achieved. The rst, by simply designing app features to fall along each of the three axes within our identied “zone of best practice”–designs perceived most positively by both parents and children. Second, to complement and pair restriction and monitoring features in an age and skill-appropriate manner. This includes gradually allowing children to move from strictest monitoring and restriction features to gain more autonomy, as they develop necessary skills associated with recognising and mitigating online risks. 8 ACKNOWLEDGMENTS This work was supported by the ReEnTrust project from the Engineering and Physical Sciences Research Council (grant number EP/R033633/1) and Oxford Univeristy COVID-19 Rebuilding Research Momentum Fund (0010067). Fig. 7. Final Codebook for Reviews. Reviews were first organised using Feature Designs Codebook we previously compiled in Section 3.2.2. Then, we used a grounded, thematic approach [ about why a parent or a child liked or disliked that feature design.