The expanding and accelerating pace of technology development continuously reshap es the technological landscape [ zations that develop, implem e nt or sell a given technology is an impo rtant business challenge, sh ould a technology be n ovel or established [ ronment, market actors are incre a singly confronted by an information overload issue, as an ever raising amount of heterogeneous and u nstructured market information needs to be collected, stored, cleaned, structured and analyzed [ analysis of the complex network of organizations and technologies is a key business intelligence necessity not only for public entities, but also for private investors [ Cyber-Defence Campus, armasuisse Science and Technology, EPFL Abstract. Mapping the technology landscape is crucial for market actors to take informed investment decisions. However, given the large amount of data on the Web and its subsequent information overload, manually retrieving information is a seemingly ineffective and incomplete approach. In this work, we propose an end-to-end recommendation based retrieval approach to support automatic retrieval of technologies and their associated companies from raw Web data. This is a two-task setup involving (i) technology classiﬁcation of entities extracted from company corpus, and (ii) technology and company ret r ieval based on classiﬁed technologies. Our proposed framework approaches the ﬁrst t ask by leveraging DistilBERT which is a state-of-the-art language model. For the retrieval task, we introduce a recommendation-based retrieval technique to simultaneously support retrieving related companies, technologies related to a speciﬁc company and companies relevant to a technology. To evaluate these tasks, we also construct a data set that includes company documents and entities extracted from these documents together with company categories and t echnology labels. Experiments show that our approach is able to return 4 times more relevant companies while outperforming traditional retrieval baseline in retrieving technologies. Keywords: Technology monitoring · Information retrieval · Entity-based retrieval · Technology classiﬁer · Recommender system Such a n inf ormation retrieval necessity has triggered various business intelligence and technology monitoring procedures, which have been either developed by in-house R&D efforts of organizations o r by academic actors (e.g., [ consist of non-automated approaches that struggle to tackle the information overload challenge, as they do not provide a reliable, systematic and scalab le information retrieval meth odology f or mapping the technology m a rket and determine w hich c ompanies are developing/comme rcializing which technology [ are mainly based on frameworks that ﬁnd documents matching que ry terms instead of ﬁnding entities per se [ the technological landscape and ﬁnding new technologies. Even though related works have partially investigate d such an issue, to the best of our knowledge, no work has provided an end-to-end automated information retrieval f ramework for ﬁnd ing technology related en tities and ma pping the tech nological landscap e through a recomm endation based perspective. In this work, we develop such a framework in order to map the industrial technology landscape, which would be highly applicable in several domains where a comprehensive understanding of the la ndscape is requir ed. For instanc e , in cybersecurity, by mapping the technolog ical landscape of cybersecurity, decision -makers will be provid ed relevant information for taking mor e informed pur chase decisions[ Similarly, in the stock market, having a comparative analysis on technological advances of competing c ompanies is cr ucial for making correct investme nt decisions. Our fram ework is a two step approach that ﬁrst classiﬁes the entities into tec hnologies before performing company and technolo gy retrieval. We use DistilBERT, which is a state-of- the-art language m odel, to construct the entity em beddings allowing us to achieve high accuracy in technology classiﬁcation. For re trieval, we propose a recommendation based approach that takes into account both the technologies, companies and their relationship. Th is recomme ndation approach enables better retrieval results in comparison with state-of-the-art learning based recommendation approaches such as GMF [ return 4 times more relevant companies in company to company retrieval in comparison with traditiona l tf-idf retrieval approach. The remainder of this article proceeds as follows. Section by emphasizing different methodologies of information retrieval for technology monitoring, and the research gaps. Section 3 details the data collectio n. Section 4 presents the infor mation retrieval model and framework. Section methodology and the technology classiﬁcation we use. Section 6 pre sents the techno logy retrieval method we used. Section 7 presents the emp irical evaluation, while Section 8 conclu des and set the path for fu rther research. The information overload triggered by the big data er a has motivated researchers a nd practitioners to develop numerous automated information retrieval meth ods by using different yet often complementary app roaches [ widely u sed in ﬁelds as digital libraries [16], information ﬁltering and rec ommender systems [ 14,27], MLP [14] and NCF [14]. Our results show that our appro ach is able to 6,15], media search [2 6] and search engines [2]. In the ﬁeld of tec hnology monitoring and forecasting – and more speciﬁcally in the speciﬁc context o f technology landscape monitoring –, numerous works have bee n published , involvin g the extraction of patents [ media analy sis [ keyword-based or a entity-based approach. Most of th e existing methods are keywordbased in which the queries and the data are mostly plain texts [ Hossari et al. (2019) proposed an auto mated framework fo r detectin g the existence of new technologies in texts, and extract terms used to describe new technologies [17]. Aharonson & Schilling developed a fra mework that captures the distance between patents, and a company’s technological footprint. Their framework also enables to measure the proximity of technological footprints between organizations [ (2008) presented a three-layer mode l for technology forecasting based on text mining techniques, incorporating a collection layer, an analysis layer an d a representation layer, before overlapping a semantic web based ap proach in order to map the industrial technology landscape [ a piece of text to an entity in a knowled ge base such that retrieval is don e on the entities instead of the raw texts. Woon and Madnick ( 2008) developed an information re trieval framework for visualizing the technology landscape by exploring the use of term cooccurence frequencie s as an indicator of semantic clo seness between pairs of entities [21]. In the ﬁeld of energy related tec hnologies, Mikheev (201 8) developed an ontology based data access framework under a semantic approach to query complex data sets, creating an automated ma pping procedure to connect data to ontology entities [ applying a semantic approach, Sitarz et al. (2012) developed an automated framework for ide ntifying thematic groups of scientiﬁc publications based o n clustering o f sets of co-occurence words and and ﬁnancial-analysis techniques for trends detection and forecasting [ In our setting, we opt for the entity-based app roach as it allows u s to handle different mentions of the same entity while enabling better retrieval accuracy due to external informa tion from the knowledge base. However, to the best of our knowledge, little h a s been done when it come s to apply info rmation retrieval methodologies with the aim of presenting a holistic and comprehensive monitoring and mapping of the industrial technology landscap e. I n order to do so, a technique needs to consider both the technologies and companies at the same time. The following steps have to be undertake n: (i) an entity ﬁshing approach needs to be applied fo r extracting and classifying technology e ntities; (ii) then, these technology entities need to be linked to speciﬁc companies; (iii) and ﬁnally, these entities must be ranked according to their level of relevance. Demartini et al. (200 9) provided a formal model for entity ﬁshing and ranking [10]. Yet, to the best of our knowledge, no such work has been deployed in the context of technology landscape monitoring. Similarly, Balog et al. (2012) developed a framework for assessing the strength of association between a topic and a person ( i.e., expertise retrieval) [ Yet, to the best of our knowledge, no such framework has been applied in the context of technology landscape monitoring for linking technology entities and company entities. To the best of our knowledge, there is n o public dataset available for the technology retrieval and classiﬁcation task. As a result, we aim to create and publish such a dataset to further re search in this ﬁeld. We have deﬁned the following requirements for our dataset. First, the dataset should be multilingual as the technology retrieval task should be language independent. Sec ond, the dataset sh ould be rea listic an d coming from realworld data as th is would enable objective evaluation of any proposed approach. In the f ollowing, we discuss our data construction process. The dataset is constructed by ﬁrst cr awling differen t data sources that are publicly available on the In ternet. As we aim to develop a language-agnostic framework, we decide to construct a dataset based on Swiss comp a nies as Switzer land is a multilingua l country with French, German and Italian as ofﬁcial lang uages while English is a working language. For ea ch company, we intend to collect all possible documents that are related to th e company’s actual activities. This involves the following data sources: the company’s website, the company’s job postings, the patents and th e company’s tweets. In addition, to maintain an u p-to-date dataset about the co mpanies, we periodically crawl data from th e above data sources. The above data sources are selected as they could provide different perspectives r egar ding a company’s technology offering. The statistics o f the dataset shown in To collect the data, we ﬁrst need a list of Swiss companies. We obtain the list of companies registered in Switzerland from the federal Central Business Name Index (Zeﬁx) Additional inform a tion regarding given company is then extracted from the corresponding cantonal commercial register record. These rec ords provide, among others, in formation on location, people, type of company. Websites. As commercial registers do not provide the information on regar ding websites of the registered companies, we need to ﬁnd the company’s website based on the company’s name. We ﬁrst clean the company name (e.g. removing Ltd.) before performing Google search. The information extracted from commercial registers in com bination with th e results of the previously mentioned search are then put through the Note that there are overlapping companies and terms among different data sources. https://zeﬁx.ch Table 1. classiﬁer to link th e company to a corre ct website. We the n crawl the pag es from the detected website, using their text for entity extraction. Patents. We use Patents data from United States Patent and Trademarks Ofﬁce ( U SPTO). PatentView directly into o ur system. The p atents are linked to the companie s based on the location and assignee information, while the title and the ab stract of the patents are used to extract the entities. Jobs. The Indeed per canto n search for jobs, retrieving for each job the following info rmation: title, description, company name and the original posting. Job’s title and description are used for technology annotation, while the linking to the company is based on it’s name and location. Tweets. For each company, we look up its Twitter handle from Crunchbase which is a commercia l database of company information. Fr om the handle, we collect the latest 3000 tweets for each com pany using sempi.tech which is a social listening framework. We use these twee ts for entity extraction. From the documents collected in the previous step, we use DBPedia Spotlight (DBPS)[ an open source tool to automatically annotate the mentions of the DBPedia entities within the text content. Dbpedia is a multi-domain ontology derived from Wikipedia. Each DBPedia entity is an URI with the preﬁx http://dbpedia.org/resource/ followed by the identiﬁer of the corresponding Wikipedia article. DBPS allows us to not only extract entities but also link the entities to their corresponding DBPedia entities. DBPS is also capable of handling multiple lang uages, which is importan t in our setting. For each data so urce, we perform entity extraction independently. The output of this step is a list of entities and their corr e sponding number of appearance in the data source of a company. We store the output in JSON line format where each line is a triple of company, DBPedia entity a nd number of entity occurrences. Note that while our da ta sources are heteroge neous as they com e from different domains, DBPS allows us to standardize them. Whether it is a website, a patent, a job posting or a tweet, DBPS extracts all the candidate technology mentions while ignoring irreleva nt data. The se tec hnology mentions are the input to any technology classiﬁcation or retrieva l techn ique. Technology labeling. To support the evaluation of a technology cla ssiﬁer, we also provide a list of Wikipedia terms and their labels whether a term is about a technology or not. Even though Tech nology is one of Wikipedia’s Main Topic Classiﬁcation ( MTC) categories, one can not rely on this concept to extract all technology related articles, as th e ca tegories within the Wikipedia graph are very loosely re late d("is rela te d to"). https://patentsview.org http://indeed.ch provides half yearly data dump of the USPTO database, which we inject We approach the labeling in a top-down approach where we aim to label the MTC categories. First, Wikipedia directed categories graph was clea ned by removing hidden categories, admin and user pages, followed by regular expression ﬁlters removing categories referring to c ompanies, brands, currencies etc. We than calculate the shortest p ath to each of the 28 MTC, and retain the categories having the shorte st pa th to Technology, Science, or En gineering topic s. This p rocess resulted in the list of 7876 categories. These categories were than m a nually labe le d as technolo gy or non technolo gy, re sulting with 13 56 categories be ing labeled a n technology. This is the only manual step in our data construction process. An article is the n considered to be a technology if it is directly connected to a categor y labeled as such. Company categorization. Crunchbase maintains a database of companies and their detail information where the data are manually curated b y Crunch base staff and online contributors activities. For instance, Roche which is a pharmaceutical co mpany based in Switzerland is categorized as Biotechnology, Health Care, Health Diagnostics and Pharmaceutical. From the comp anies collected in the above steps, we crawl Crunchbase to obtain their categories. The categories can be considered a s pseudo-labels for our com -com and tech-com retrieval tasks. We develop a uniﬁed framework to classify entities into technologies and to perform technology related retrieval. This requires solving two tasks of technology classiﬁcation and technology retrieval. Our framework considers a set of companies C = { c E = {e served through severa l data sources. For each data source, we measure this connection by the number of times the entity e these conne ctions for a speciﬁc data source by an interaction matrix M where M the occurren ce frequency of the entity e these matrices by M = {M Tasks. We have 3 retrieval tasks: company to technology (com-tech) retrieval, company to company (com-com) retrieval and technology to company ( te ch-com) retrieval. Comtech and com-com retr ieval are co nnected as both require an accurate repre sentation of a company by its techno logies. Two companies a re similar if they h ave similar technology representation. Similarly, for tech-com retrieval, we need a good representation of a technology by its companies. There is a mutual reinforcing relationship between company and technology representation. A good co mpany representation require s knowing similar technologies while knowing company similarity is helpful in constructing a good tec hnology representation. This means we need a common model to app roach these three different retrieval tasks. crunchbase.com . Each company is associated with several categories describing its main , · · · , e}. The connection b etween an entity eand a company ccan be ob- Our framework takes as input the entities extracted from the company cor pora. These entities are identiﬁed using entity extraction frameworks such as DBPedia-spotlight. Each entity is associated with its description. This information is used in the second step to classify the entities into technologies or not. Our technolo gy classiﬁers are constructed using BERT as a feature extra c tor. The tec hnologies obtained from the previou s step are used as input for the retrieval step. We reformulate the retrieval problem as a recommendation problem based o n collaborative ﬁlterin g where the tec hnologies are “recommended” to a compa ny if the technologies a re considered to be r elated to the company’s a ctivities. Casting this as a recommendation prob le m has several beneﬁts. The relevan cy of a tec hnology to a comp any can be measured more accurately if similar compan ie s in the same domain are conside red. This also me a ns that missing technologies in a company corpus can be recovered by considering similar co mpanies. We propose a technology recomm endation model that extends traditional matrix factoriza tion by integrating both the technology meaning and the interactions between technologies and com panies. As th e input entities to our system are extracted using an entity extraction fr a mework such as DBPedia-sp otlight [ ested only in technologies. To this end, we develop a technology classiﬁer to ﬁler out unrelated entities. Note that DBPedia-spotlight also performs entity linkin g where each entity is linked to a DBPedia page or a Wikip e dia article describing this entity. We leverage this description to construct our technology classiﬁer. For e a ch entity, w e extract its abstract which we deﬁne to be the description fr om DBPedia or the ﬁrst paragraph of its Wikipedia article whichever available. BERT-based encoder. We use DistilBERT [ model while being light-weight and fast to train to construct abstract embeddings. We use these abstract embed dings as representations for the entities. We pass each a bstract Fig. 1. From data sources to company and technology retrieval through DistilBERT to obtain the token embedding of the [CLS] token, which is commonly used as the sentence or paragraph emb edding. We denote this token embedding as zwhere e de notes an entity. Although DistilBERT is a distilled version of BERT which was trained on Eng lish wikipedia, distillation may inc ur information lost. To this end, we propose to ﬁne-tune DistilBERT to better capture the abstract meaning which usually co ntain several scientiﬁc terminology, therein, obtaining better entity representation. We ﬁne-tune DistilBERT for our technology c la ssiﬁcation in an end-to-end manner where we fee d the abstracts through the model to obtain the abstract embeddings. These abstract embeddings are then fed through a linear classiﬁer to g e t the tec hnology predictions. The parameters of DistilBERT and the linear classiﬁer are updated together in an end-toend man ner using SGD [ observe that with ﬁnetuning, we are ab le to achieve better accuracy. Embedding reﬁnement. To fur ther increase the capa city of our classiﬁer, we pass z through several layers including a dropout layer to reduce overﬁtting. More precisely, zis passed through a multi-layer neural network with 2 blocks where each block is a linear layer followed by a BatchNorm layer and a sigmoid non-line arity. A block can be formulated a s follows: Between 2 blo c ks, we also use a dropout layer to reduce overﬁtting. We observe that be reﬁning the embedding this way, we can achieve better accu racy than non-reﬁnement. The case for retrieving as recommending. There are several requirements for the retrieval model of this task. First, the technologies retrieved for a company must be derived from the techno logies mentioned in the comp any’s corpus as these technologies are the most likely ones to reﬂect the company’s actual activities. As each technolo gy has a different level of releva ncy to the c ompany, com-tech retrieval considering only observed technologies is a technology ranking problem. Second, it is safe to assume that a company’s corpus may not con ta in all the technologies the comp any is working on. Companies may not publicly me ntion a technology to keep a competitive advantage or it could simply be due missing da ta . For these reasons, the com-tech retrieval is also a technology discovery problem. To solve both problems at the same time, we propose a recommendation model that identiﬁes potentially related technologies of a company by looking at similar companies while measuring the relevancy between every pair of technology and company for ranking technologies. Recommendation model. Given a set of companies C = {c technologies T = {t recommendation m odel takes as input a com-tech interaction matrix M ∈ R M=f(c, t), if there is a mention of tin any data sour ce of C∅, if there is no mention of tin C The fun c tion f(c can be measured by the number of times t weighting schem e. In our setting, we measure the importance per d ata source usin g tf-idf before combining all data sources: where f idf value of t which captures our perceived releva nce of the data source to our retrieval tasks. A high value of f (c technology t word “vaccine” but it does not necessarily mean that a certain company is developing a vaccine. This example shows that answering com-tech retrieval by only looking at the company corp us could b e problematic. We can have the same argument for M This does not mean the co mpany c the company is working on this technology but it has not mentioned it yet in the corpus. The above com-te ch interaction mode l is akin to c ollaborative ﬁlter ing with implicit feedback [ recommendation problem where we need to estimate the unobserved entries of M . The estimation is usually done by learning a model estimated score of M between c Semantic-aware matrix factorization. We propose a semantic-aware recommendation model extending tra ditional matrix factorization (MF) a pproach. In MF, eac h comp a ny and each technology is represented by an embe dding in a shar e d latent space. The technology and the company em beddings are learned such that they can reconstruct the interaction matrix M . More precisely, let c company c score M However, MF considers the technologies to be independent even if they are semantically related such as “deep learning” an d “machine learning”. To this end, we propose to incorporate the m eaning of the technologies into MF while extending the model capacity by passing the technology embedding through seve ral linear la yers. In the following, we describe in detail the layers of our architecture. Semantic embedding: We capture the technology meaning using BERT [ feature extractor over the technology abstract: where s MLP layers: The sem a ntic techno logy embedding is passed through several MLP layers to further reduce the size of the embedding while increasing the model capacity. (c, t) is the im portance function of data source k which is m e asured by the tfconsiderin g each company as a “document”. wis its associated weight . For instance, during the pandemic, there could be several mentions of the 27,14]. To a nswer the com-tech retrieval problem, we ﬁrst need to solve the and t, Θ denotes the para meters of f . and tec hnology trespectively. Then, MF a ims to estimate the relevan cy by: is the semantic tec hnology emb edding and ais the abstract of technology t. where W Combination layer: To obtain the ﬁnal technolo gy embedding t semantic technology embedding s by summing them: t ters in comparison with concatenation while it is also inspired by transformer arch itec ture [36,11] where position a l e ncodings are add e d to the word embeddings. Model learning. To learn the parameters, traditional MF uses the squared loss betwee n the predicted and actual interaction score: L ever, such a method does not con sid er the unobserved entries directly. To this end, we follow the pairwise learning appro ach that aims to optimize the relative ranking between technologies. We use the margin hinge loss which is deﬁned as fo llows: where c ple meanin g c Recommendation-ba sed Retrieval. Then, the com-tech retr ieval problem can be answered by ranking the technolo gies T with respect to a company c based on their interaction scores. More precisely, let N to be the com-tech interaction matrix after the unobser ved entrie s are estimated . The top-k com-tech retrieval result for a company c is a list of technologies ordered by their interaction scores N . Datasets. We evaluate our model on the constructed dataset described in Section 3. As our dataset is crawl con stantly which m akes it difﬁcult for evaluation, we ﬁx the dataset used in the experiments to be the data c ollected bef ore 01/04/2020. This snapshot and the code are publicly available at Metrics. To evaluate the results of com -com retr ieval, we leverage the company categorisation from Crunchbase. We measure the quality of com-com retrieval by the number of overlapp ing categories between the qu ery company and the results. Mor e precisely, let C(c) denote the set of categories of compa ny c. We deﬁne the retrieval accuracy for a company c considering top-k most relevant results as follows: This metric can be extended to a set of companies C as P @k(C) = , b, σ a re the weight matrix, the b ia s and the non-linearity. , tis an ob serve d pair of company and technology while tis a negative sam, tis an un observed entry of the interaction matrix M . While it is “straightforward” to evaluate the search results for com-com, the evaluation for com-tech and tech-com is more challenging as there is no available ground truth. For tech-com search, we follow the approach of com-com retrieval where we label ea ch technology by the Crunchb ase categories. This is akin to consider each tec hnology as a “co mpany”. The number of technologies to be labelled is usually small as we are inter ested in only important technologies. To this end, we have labeled 11 9 technologies wh ic h are considered important in the cybersecur ity domain [ accuracy P @k(t) for a technology t is deﬁned similarly as in Equation 2. On the other hand, for com-tech retrieval, this approach is not practical as for eac h company, the list of retrieved technologies is very large. To this end, we opt for a qualitative evaluation. Baselines. For technology classiﬁcation, we c onstruct a baseline using SVM on tf-idf featurization. More prec isely, we construct a vector representing a Wikipedia category by combining the vector distances of a category to each o f the Wikipedia’s MTC and its TF-IDF we ighted bag of words (BOW) repre sentation. The weighted BOW representation of the given category is created from the stem med text obtained by co ncatenating the abstracts of all Wikipedia articles directly connected to it. Mutual inform ation based feature reduc tion than resulted in a vector of the length 1000. These vectors are used as the input f eatures for the classiﬁer. For retrieval, we ﬁrst compare with a tf-idf retrieval approa c h where the tf-idf values are a lso the relevancy of the technologies in com-tech retrieval. For com-com retrieval, it is an tf-idf weighted version of Jaccard similarity where ea c h company is represented by its set of technologies. We also comp are our recommendation-based retrieval approach with other re commendation models including GMF [ best of our knowledge, there is no public implementation of te chnology classiﬁcation and retr ieval techniques. The above baselines represent the best starting points for these tasks. Environments. Ou r experiments ran on an Intel Xeon CPU E 5-2620 v4 @ 2.10GHz server with a Titan V GPU with 12GB VRAM and 128GB RAM. Our model was implemented using Pytorch 1.7.1 and Spotlight as the recommendation framework and DistilBERT from Huggin gFace as the language model. Quality of technology classiﬁers. In this experiment, we analyz e the correc tness of our techn ology classiﬁers. We compare our proposed classiﬁer using BERT with the baseline classiﬁers based on tf-idf and othe r BERT models. For this experiment, we compare these app roaches on three metrics: accuracy, f1-score and AUC. We use k -fold cross validation with a 80-20 split. The results show in step. Our proposed approach outper forms the baselines on all metrics. The difference between using tf-idf as fea ture and BERT is 0.1, 0.02 and 0.04 for F1-score, accuracy and AUC respec tively. This is expected as large language models trained on large text corpora are able to capture word meanings better. We also observe that ﬁne-tuning improves accuracy in comp arison with using BERT without ﬁne-tuning. 14,27], MLP [14] and NCF [14]. The above baselines are selected as to the In this experiment, we analyze our proposed recommendation-based retrieval model. We compare our model with a tf-idf based retrieval where each technology is a ssoc iated with a tf-idf value while each company is represented by a tf-idf vector. We also compare ou r approach with several recommendation models includin g 1) Generalized MF [27] which is a ge neralized version of MF, 2) MLP [14] which is a multi-layer recommendation model starting from random vectors and 3) NCF [14] or Neural Collaborative Filtering which is a recommendation model based on deep learning. The experimental results shown in Table 3 show tha t ou r proposed model based on BERT embeddings as initial technology embeddings are better th a n the baselines. The difference betwe en our worst model and the best b aseline is 0.6 at top-5 for comcom retrieval and 1.8 at top-5 for tech-com retrieval. Th is ca n be explained by the fact that our models ca n capture the meaning of the technologies while the baselines consider the technologies to be independent. Among our proposed mod els, adding the raw tech nology embedding from MF with the BERT technology embedding is better than using the BERT embedding alone. We can attribute this to the larger capacity of our model which helps in capture the interaction matrix better. Effects of margin. We vary the margin of the hinge loss from 0.001 to 0 .1 to analyze its effects on the retrieval results. The experimental results are shown in observe that the number of overlappin g categorie s ten ds to incre a se with the margin. For instance, the number of overlapping categ ories for top-5 com-c om retrieval is 3. 73 when the margin is 0.001 but it in c reases to 4.95 when the margin is 0.1. This is expected MF+BERT 4.458 7.004 8.447 8.845 2.197 3.684 5.105 6.289 as with the larger margin, our model tends to generalize as it aims to capture common technologies between the com panies. We observe this phenomenon clearly f rom that we o btain more speciﬁc technologies with smaller margin. With larger margins, generic technologies that are shared among different c ompanies are more representative than more speciﬁc ones. This experiment conﬁrm s our ability to co ntrol the speciﬁcity of the retr ieval results by c hanging the margin of the hinge loss. Embedding size. In this experiment, we analyse th e effects of the embedding size on the retr ieval results. We vary the embedding size from 32 to 512. Results in shows that as the emb edding size increases, we c a n retrieve companies better for both tech-com and com-co m retrieval tasks. This is exp e cted as increasing embedding size also improves the m odel cap acity. However, there is a trade-off in increasing embedding size as it incurs lo nger training tim e as shown in time betwe e n embedding size o f 32 and 512 is 3 times. However, even with the largest embedd ing size, the training time per epoch is still very fast - only around 1.5 second. Having evaluated the individual components of our solution, we turn to its end-to-end performance in comparison with the baseline. Fig. 4. Training time per epoch. approa c h with a tf-idf based retrieval approach which uses tf-idf as feature for technology classiﬁer and technology retrieval. Ou r approach leads to signiﬁca ntly better retrieval results in both retr ieval tasks. Our model is nearly 4 times better th a n the baseline in the com-co m retrieval at top-5 while the difference is 0.18 for tech-c om retrieval. First, this can be attributed to our approach’s better techn ology classiﬁer by using language model. Second, our recommen dation retrieval model considers both the companies, techno logies and their relationships as the same time, while the techn ologies and compan ie s in the tf-id f m odel are handled independently. This enab le s our model to leverage the similarity of companies to support technology retrieval and vice versa. In this expe riment, we analyze the retrieva l results qualitatively. Table 5 shows the comtech retrieval results where we search f or cyber security companies. For com-tech retrieval, as discussed above, we are able to contro l the speciﬁcity of the results by changing the margin. In ad dition, our proposed model is able to return less noise in comparison with tf-id f one as tf-idf model may retu rn non-technological terms due to the qu ality of its classiﬁer. This phenomenon can be seen for instance in the search for Inte rHype Sarl which is a cyber security company. For com-com and tech-com retrieval, due to space constraint, we do not include them. However, we observe th at our model can return companies that are in the same domains as the queried company o r technology. This is in line w ith the quantitative result observed in previous experiments. In this pape r, we propose an end-to-end framework to ﬁrst extract and c lassify technological mentions from company corpuses and then, retrieve related technologie s and compan ie s. Our technology classiﬁer is based on DistilBERT model with ﬁnetuning and reﬁnement to achieve better accuracy while our rec ommendation-based retrieval model enables more relevant results. In the future works, we aim to allow users to reformu late queries to better capture users intentions. Another possible re search directio n is to c ombine technology cla ssiﬁcation and entity extraction for more accurate results.